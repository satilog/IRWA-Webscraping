[{"Q_Title":"Validate SSL certificates with Python","A_Content":"  From release version 2.7.9/3.4.3 on, Python by default attempts to perform certificate validation.  This has been proposed in PEP 467, which is worth a read: https://www.python.org/dev/peps/pep-0476/  The changes affect all relevant stdlib modules (urllib/urllib2, http, httplib).  Relevant documentation:  https://docs.python.org/2/library/httplib.html#httplib.HTTPSConnection     This class now performs all the necessary certificate and hostname checks by default. To revert to the previous, unverified, behavior ssl._create_unverified_context() can be passed to the context parameter.   https://docs.python.org/3/library/http.client.html#http.client.HTTPSConnection     Changed in version 3.4.3: This class now performs all the necessary certificate and hostname checks by default. To revert to the previous, unverified, behavior ssl._create_unverified_context() can be passed to the context parameter.   Note that the new built-in verification is based on the system-provided certificate database. Opposed to that, the requests package ships its own certificate bundle. Pros and cons of both approaches are discussed in the Trust database section of PEP 476.     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"12","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  I have added a distribution to the Python Package Index which makes the match_hostname() function from the Python 3.2 ssl package available on previous versions of Python.  http://pypi.python.org/pypi/backports.ssl_match_hostname/  You can install it with:  pip install backports.ssl_match_hostname   Or you can make it a dependency listed in your project's setup.py. Either way, it can be used like this:  from backports.ssl_match_hostname import match_hostname, CertificateError ... sslsock = ssl.wrap_socket(sock, ssl_version=ssl.PROTOCOL_SSLv3,                       cert_reqs=ssl.CERT_REQUIRED, ca_certs=...) try:     match_hostname(sslsock.getpeercert(), hostname) except CertificateError, ce:     ...      ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  You can use Twisted to verify certificates.  The main API is CertificateOptions, which can be provided as the contextFactory argument to various functions such as listenSSL and startTLS.  Unfortunately, neither Python nor Twisted comes with a the pile of CA certificates required to actually do HTTPS validation, nor the HTTPS validation logic.  Due to a limitation in PyOpenSSL, you can't do it completely correctly just yet, but thanks to the fact that almost all certificates include a subject commonName, you can get close enough.  Here is a naive sample implementation of a verifying Twisted HTTPS client which ignores wildcards and subjectAltName extensions, and uses the certificate-authority certificates present in the 'ca-certificates' package in most Ubuntu distributions.  Try it with your favorite valid and invalid certificate sites :).  import os import glob from OpenSSL.SSL import Context, TLSv1_METHOD, VERIFY_PEER, VERIFY_FAIL_IF_NO_PEER_CERT, OP_NO_SSLv2 from OpenSSL.crypto import load_certificate, FILETYPE_PEM from twisted.python.urlpath import URLPath from twisted.internet.ssl import ContextFactory from twisted.internet import reactor from twisted.web.client import getPage certificateAuthorityMap = {} for certFileName in glob.glob(\"/etc/ssl/certs/*.pem\"):     # There might be some dead symlinks in there, so let's make sure it's real.     if os.path.exists(certFileName):         data = open(certFileName).read()         x509 = load_certificate(FILETYPE_PEM, data)         digest = x509.digest('sha1')         # Now, de-duplicate in case the same cert has multiple names.         certificateAuthorityMap[digest] = x509 class HTTPSVerifyingContextFactory(ContextFactory):     def __init__(self, hostname):         self.hostname = hostname     isClient = True     def getContext(self):         ctx = Context(TLSv1_METHOD)         store = ctx.get_cert_store()         for value in certificateAuthorityMap.values():             store.add_cert(value)         ctx.set_verify(VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT, self.verifyHostname)         ctx.set_options(OP_NO_SSLv2)         return ctx     def verifyHostname(self, connection, x509, errno, depth, preverifyOK):         if preverifyOK:             if self.hostname != x509.get_subject().commonName:                 return False         return preverifyOK def secureGet(url):     return getPage(url, HTTPSVerifyingContextFactory(URLPath.fromString(url).netloc)) def done(result):     print 'Done!', len(result) secureGet(\"https://google.com/\").addCallback(done) reactor.run()      ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  PycURL does this beautifully.  Below is a short example. It will throw a pycurl.error if something is fishy, where you get a tuple with error code and a human readable message.  import pycurl  curl = pycurl.Curl() curl.setopt(pycurl.CAINFO, \"myFineCA.crt\") curl.setopt(pycurl.SSL_VERIFYPEER, 1) curl.setopt(pycurl.SSL_VERIFYHOST, 2) curl.setopt(pycurl.URL, \"https://internal.stuff/\")  curl.perform()   You will probably want to configure more options, like where to store the results, etc. But no need to clutter the example with non-essentials.  Example of what exceptions might be raised:  (60, 'Peer certificate cannot be authenticated with known CA certificates') (51, \"common name 'CN=something.else.stuff,O=Example Corp,C=SE' does not match 'internal.stuff'\")   Some links that I found useful are the libcurl-docs for setopt and getinfo.   http://curl.haxx.se/libcurl/c/curl_easy_setopt.html http://curl.haxx.se/libcurl/c/curl_easy_getinfo.html      ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  Here's an example script which demonstrates certificate validation:  import httplib import re import socket import sys import urllib2 import ssl  class InvalidCertificateException(httplib.HTTPException, urllib2.URLError):     def __init__(self, host, cert, reason):         httplib.HTTPException.__init__(self)         self.host = host         self.cert = cert         self.reason = reason      def __str__(self):         return ('Host %s returned an invalid certificate (%s) %s\\n' %                 (self.host, self.reason, self.cert))  class CertValidatingHTTPSConnection(httplib.HTTPConnection):     default_port = httplib.HTTPS_PORT      def __init__(self, host, port=None, key_file=None, cert_file=None,                              ca_certs=None, strict=None, **kwargs):         httplib.HTTPConnection.__init__(self, host, port, strict, **kwargs)         self.key_file = key_file         self.cert_file = cert_file         self.ca_certs = ca_certs         if self.ca_certs:             self.cert_reqs = ssl.CERT_REQUIRED         else:             self.cert_reqs = ssl.CERT_NONE      def _GetValidHostsForCert(self, cert):         if 'subjectAltName' in cert:             return [x[1] for x in cert['subjectAltName']                          if x[0].lower() == 'dns']         else:             return [x[0][1] for x in cert['subject']                             if x[0][0].lower() == 'commonname']      def _ValidateCertificateHostname(self, cert, hostname):         hosts = self._GetValidHostsForCert(cert)         for host in hosts:             host_re = host.replace('.', '\\.').replace('*', '[^.]*')             if re.search('^%s$' % (host_re,), hostname, re.I):                 return True         return False      def connect(self):         sock = socket.create_connection((self.host, self.port))         self.sock = ssl.wrap_socket(sock, keyfile=self.key_file,                                           certfile=self.cert_file,                                           cert_reqs=self.cert_reqs,                                           ca_certs=self.ca_certs)         if self.cert_reqs & ssl.CERT_REQUIRED:             cert = self.sock.getpeercert()             hostname = self.host.split(':', 0)[0]             if not self._ValidateCertificateHostname(cert, hostname):                 raise InvalidCertificateException(hostname, cert,                                                   'hostname mismatch')   class VerifiedHTTPSHandler(urllib2.HTTPSHandler):     def __init__(self, **kwargs):         urllib2.AbstractHTTPHandler.__init__(self)         self._connection_args = kwargs      def https_open(self, req):         def http_class_wrapper(host, **kwargs):             full_kwargs = dict(self._connection_args)             full_kwargs.update(kwargs)             return CertValidatingHTTPSConnection(host, **full_kwargs)          try:             return self.do_open(http_class_wrapper, req)         except urllib2.URLError, e:             if type(e.reason) == ssl.SSLError and e.reason.args[0] == 1:                 raise InvalidCertificateException(req.host, '',                                                   e.reason.args[1])             raise      https_request = urllib2.HTTPSHandler.do_request_  if __name__ == \"__main__\":     if len(sys.argv) != 3:         print \"usage: python %s CA_CERT URL\" % sys.argv[0]         exit(2)      handler = VerifiedHTTPSHandler(ca_certs = sys.argv[1])     opener = urllib2.build_opener(handler)     print opener.open(sys.argv[2]).read()      ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  Or simply make your life easier by using the requests library:  import requests requests.get('https://somesite.com', cert='/path/server.crt', verify=True)   A few more words about its usage.     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  M2Crypto can do the validation. You can also use M2Crypto with Twisted if you like. The Chandler desktop client uses Twisted for networking and M2Crypto for SSL, including certificate validation.  Based on Glyphs comment it seems like M2Crypto does better certificate verification by default than what you can do with pyOpenSSL currently, because M2Crypto checks subjectAltName field too.  I've also blogged on how to get the certificates Mozilla Firefox ships with in Python and usable with Python SSL solutions.     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  Jython DOES carry out certificate verification by default, so using standard library modules, e.g. httplib.HTTPSConnection, etc, with jython will verify certificates and give exceptions for failures, i.e. mismatched identities, expired certs, etc.  In fact, you have to do some extra work to get jython to behave like cpython, i.e. to get jython to NOT verify certs.   I have written a blog post on how to disable certificate checking on jython, because it can be useful in testing phases, etc.  Installing an all-trusting security provider on java and jython. http://jython.xhaus.com/installing-an-all-trusting-security-provider-on-java-and-jython/     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  I was having the same problem but wanted to minimize 3rd party dependencies (because this one-off script was to be executed by many users). My solution was to wrap a curl call and make sure that the exit code was 0. Worked like a charm.     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Validate SSL certificates with Python","A_Content":"  pyOpenSSL is an interface to the OpenSSL library. It should provide everything you need.     ","Language":"Python","Tags":["python","https","ssl-certificate","verification"],"URL":"https://stackoverflow.com/questions/1087227/validate-ssl-certificates-with-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I need to write a script that connects to a bunch of sites on our corporate intranet over HTTPS and verifies that their SSL certificates are valid; that they are not expired, that they are issued for the correct address, etc.  We use our own internal corporate Certificate Authority for these sites, so we have the public key of the CA to verify the certificates against.  Python by default just accepts and uses SSL certificates when using HTTPS, so even if a certificate is invalid, Python libraries such as urllib2 and Twisted will just happily use the certificate.  Is there a good library somewhere that will let me connect to a site over HTTPS and verify its certificate in this way?  How do I verify a certificate in Python?     ","Q_Votes":"74"},{"Q_Title":"Can Python print a function definition?","A_Content":"  If you are importing the function, you can use inspect.getsource:  >>> import re >>> import inspect >>> print inspect.getsource(re.compile) def compile(pattern, flags=0):     \"Compile a regular expression pattern, returning a pattern object.\"     return _compile(pattern, flags)   This will work  in the interactive prompt, but apparently only on objects that are imported (not objects defined within the interactive prompt). And of course it will only work if Python can find the source code (so not on built-in objects, C libs, .pyc files, etc)     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1562759/can-python-print-a-function-definition","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"    In JavaScript, one can print out the definition of a function.  Is there a way to accomplish this in Python?    (Just playing around in interactive mode, and I wanted to read a module without open().  I was just curious).       ","Q_Votes":"73"},{"Q_Title":"Can Python print a function definition?","A_Content":"  If you're using iPython, you can use function_name? to get help, and function_name?? will print out the source, if it can.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1562759/can-python-print-a-function-definition","A_Votes":"71","_type":"dict","isAccepted":"No","Q_Content":"    In JavaScript, one can print out the definition of a function.  Is there a way to accomplish this in Python?    (Just playing around in interactive mode, and I wanted to read a module without open().  I was just curious).       ","Q_Votes":"73"},{"Q_Title":"Can Python print a function definition?","A_Content":"  While I'd generally agree that inspect is a good answer, I'd disagree that you can't get the source code of objects defined in the interpreter.  If you use dill.source.getsource from dill, you can get the source of functions and lambdas, even if they are defined interactively. It also can get the code for from bound or unbound class methods and functions defined in curries... however, you might not be able to compile that code without the enclosing object's code.  >>> from dill.source import getsource >>>  >>> def add(x,y): ...   return x+y ...  >>> squared = lambda x:x**2 >>>  >>> print getsource(add) def add(x,y):   return x+y  >>> print getsource(squared) squared = lambda x:x**2  >>>  >>> class Foo(object): ...   def bar(self, x): ...     return x*x+x ...  >>> f = Foo() >>>  >>> print getsource(f.bar) def bar(self, x):     return x*x+x  >>>       ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1562759/can-python-print-a-function-definition","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    In JavaScript, one can print out the definition of a function.  Is there a way to accomplish this in Python?    (Just playing around in interactive mode, and I wanted to read a module without open().  I was just curious).       ","Q_Votes":"73"},{"Q_Title":"Can Python print a function definition?","A_Content":"  This is the way I figured out how to do it:      import inspect as i     import sys     sys.stdout.write(inspect.getsource(MyFunction))   This takes out the new line characters and prints the function out nicely     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1562759/can-python-print-a-function-definition","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    In JavaScript, one can print out the definition of a function.  Is there a way to accomplish this in Python?    (Just playing around in interactive mode, and I wanted to read a module without open().  I was just curious).       ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  There are several different answers I can give here, from your specific question to more general concerns. so from most specific to most general:  Q. Can you put multiple statements in a lambda?  A. No.  But you don't actually need to use a lambda.  You can put the statements in a def instead. ie:  def second_lowest(l):     l.sort()     return l[1]  map(second_lowest, lst)   Q. Can you get the second lowest item from a lambda by sorting the list?  A. Yes.  As alex's answer poinst out, sorted() is a version of sort that creates a new list, rather than sorting in-place, and can be chained.  Note that this is probably what you should be using - it's bad practice for your map to have side effects on the original list.  Q. How should I get the second lowest item from each list in a sequence of lists.  A. sorted(l)[1] is not actually the best way for this.  It has O(N log(N)) complexity, while an O(n) solution exists.  This can be found in the heapq module.  >>> import  heapq >>> l = [5,2,6,8,3,5] >>> heapq.nsmallest(l, 2) [2, 3]   So just use:  map(lambda x: heapq.nsmallest(x,2)[1],  list_of_lists)   It's also usually considered clearer to use a list comprehension, which avoids the lambda altogether:  [heapq.nsmallest(x,2)[1] for x in list_of_lists]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Putting the statements in a list may simulate multiple statements:  E.g.:  lambda x: [f1(x), f2(x), f3(x), x+1]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Time traveler here. If you generally want to have multiple statements within a lambda, you can pass other lambdas as arguments to that lambda.  (lambda x, f: list((y[1] for y in f(x))))(lst, lambda x: (sorted(y) for y in x))   You can't actually have multiple statements, but you can simulate that by passing lambdas to lambdas.  Edit: The time traveler returns! You can also abuse the behavior of boolean expressions (keeping in mind short-circuiting rules and truthiness) to chain operations. Using the ternary operator gives you even more power. Again, you can't have multiple statements, but you can of course have many function calls. This example does some arbitrary junk with a bunch of data, but, it shows that you can do some funny stuff. The print statements are examples of functions which return None (as does the .sort() method) but they also help show what the lambda is doing.  >>> (lambda x: print(x) or x+1)(10) 10 11 >>> f = (lambda x: x[::2] if print(x) or x.sort() else print(enumerate(x[::-1]) if print(x) else filter(lambda (i, y): print((i, y)) or (i % 3 and y % 2), enumerate(x[::-1])))) >>> from random import shuffle >>> l = list(range(100)) >>> shuffle(l) >>> f(l) [84, 58, 7, 99, 17, 14, 60, 35, 12, 56, 26, 48, 55, 40, 28, 52, 31, 39, 43, 96, 64, 63, 54, 37, 79, 25, 46, 72, 10, 59, 24, 68, 23, 13, 34, 41, 94, 29, 62, 2, 50, 32, 11, 97, 98, 3, 70, 93, 1, 36, 87, 47, 20, 73, 45, 0, 65, 57, 6, 76, 16, 85, 95, 61, 4, 77, 21, 81, 82, 30, 53, 51, 42, 67, 74, 8, 15, 83, 5, 9, 78, 66, 44, 27, 19, 91, 90, 18, 49, 86, 22, 75, 71, 88, 92, 33, 89, 69, 80, 38] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] (0, 99) (1, 98) (2, 97) (3, 96) (4, 95) (5, 94) (6, 93) (7, 92) (8, 91) (9, 90) (10, 89) (11, 88) (12, 87) (13, 86) (14, 85) (15, 84) (16, 83) (17, 82) (18, 81) (19, 80) (20, 79) (21, 78) (22, 77) (23, 76) (24, 75) (25, 74) (26, 73) (27, 72) (28, 71) (29, 70) (30, 69) (31, 68) (32, 67) (33, 66) (34, 65) (35, 64) (36, 63) (37, 62) (38, 61) (39, 60) (40, 59) (41, 58) (42, 57) (43, 56) (44, 55) (45, 54) (46, 53) (47, 52) (48, 51) (49, 50) (50, 49) (51, 48) (52, 47) (53, 46) (54, 45) (55, 44) (56, 43) (57, 42) (58, 41) (59, 40) (60, 39) (61, 38) (62, 37) (63, 36) (64, 35) (65, 34) (66, 33) (67, 32) (68, 31) (69, 30) (70, 29) (71, 28) (72, 27) (73, 26) (74, 25) (75, 24) (76, 23) (77, 22) (78, 21) (79, 20) (80, 19) (81, 18) (82, 17) (83, 16) (84, 15) (85, 14) (86, 13) (87, 12) (88, 11) (89, 10) (90, 9) (91, 8) (92, 7) (93, 6) (94, 5) (95, 4) (96, 3) (97, 2) (98, 1) (99, 0) [(2, 97), (4, 95), (8, 91), (10, 89), (14, 85), (16, 83), (20, 79), (22, 77), (26, 73), (28, 71), (32, 67), (34, 65), (38, 61), (40, 59), (44, 55), (46, 53), (50, 49), (52, 47), (56, 43), (58, 41), (62, 37), (64, 35), (68, 31), (70, 29), (74, 25), (76, 23), (80, 19), (82, 17), (86, 13), (88, 11), (92, 7), (94, 5), (98, 1)]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Use sorted function, like this:  map(lambda x: sorted(x)[1],lst)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Or if you want to avoid lambda and have a generator instead of a list:  (sorted(col)[1] for col in lst)     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Using begin() from here: http://www.reddit.com/r/Python/comments/hms4z/ask_pyreddit_if_you_were_making_your_own/c1wycci  Python 3.2 (r32:88445, Mar 25 2011, 19:28:28)  [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]] >>> begin = lambda *args: args[-1] >>> list(map(lambda x: begin(x.sort(), x[1]), lst)) [345, 465, 333]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  You can in fact have multiple statements in a lambda expression in python. It is not entirely trivial but in your example, the following works:  map(lambda x: x.sort() or x[1],lst)   You have to make sure that each statement does not return anything or if it does wrap it in (.. and False). The result is what is returned by the last evaluation.  Example:   >>> f = (lambda : (print(1) and False) or (print(2) and False) or (print(3) and False)) >>> f() 1 2 3      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  A Hacky way to combine multiple statements into a single statement in python is to use the \"and\" keyword as a short-circuit operator.  Then you can use this single statement directly as part of the lambda expression.   This is similar to using \"&&\" as the short-circuit operator in shell languages such as bash.  Also note: You can always fix a function statement to return a true value by wrapping the function.  Example:  def p2(*args):     print(*args)     return 1 # a true value  junky = lambda x, y: p2('hi') and p2('there') and p2(x) and p2(y)  junky(\"a\", \"b\")   On second thought, its probably better to use 'or' instead of 'and' since many functions return '0' or None on success.  Then you can get rid of the wrapper function in the above example:  junky = lambda x, y: print('hi') or print('there') or print(x) or print(y)  junky(\"a\", \"b\")   'and' operate will evaluate the expressions until it gets to the first zero return value. after which it short-circuits.   1 and 1 and 0 and 1   evaluates: 1 and 1 and 0, and drops 1  'or' operate will evaluate the expressions until it gets to the first non-zero return value. after which it short-circuits.  0 or 0 or 1 or 0   evaluates 0 or 0 or 1, and drops 0     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  I'll give you another solution, Make your lambda invoke a function.  def multiple_statements(x, y):     print('hi')     print('there')     print(x)     print(y)     return 1  junky = lambda x, y: multiple_statements(x, y)  junky('a', 'b');      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  You can do it in O(n) time using min and index instead of using sort or heapq.  First create new list of everything except the min value of the original list:  new_list = lst[:lst.index(min(lst))] + lst[lst.index(min(lst))+1:]   Then take the min value of the new list:  second_smallest = min(new_list)   Now all together in a single lambda:  map(lambda x: min(x[:x.index(min(x))] + x[x.index(min(x))+1:]), lst)   Yes it is really ugly, but it should be algorithmically cheap. Also since some folks in this thread want to see list comprehensions:  [min(x[:x.index(min(x))] + x[x.index(min(x))+1:]) for x in lst]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  This is exactly what the bind function in a Monad is used for.   With the bind function you can combine multiple lambda's into one lambda, each lambda representing a statement.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  There actually is a way you can use multiple statements in lambda. Here's my solution:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]  x = lambda l: exec(\"l.sort(); return l[1]\")  map(x, lst)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Yes. You can define it this way and then wrap your multiple expressions with the following:  Scheme begin:   begin = lambda *x: x[-1]  Common Lisp progn:  progn = lambda *x: x[-1]     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Is it possible to have multiple statements in a python lambda expression?","A_Content":"  Let me present to you a glorious but terrifying hack:  import types  def _obj():   return lambda: None  def LET(bindings, body, env=None):   '''Introduce local bindings.   ex: LET(('a', 1,            'b', 2),           lambda o: [o.a, o.b])   gives: [1, 2]    Bindings down the chain can depend on   the ones above them through a lambda.   ex: LET(('a', 1,            'b', lambda o: o.a + 1),           lambda o: o.b)   gives: 2   '''   if len(bindings) == 0:     return body(env)    env = env or _obj()   k, v = bindings[:2]   if isinstance(v, types.FunctionType):     v = v(env)    setattr(env, k, v)   return LET(bindings[2:], body, env)   You can now use this LET form as such:  map(lambda x: LET(('_', x.sort()),                   lambda _: x[1]),     lst)   which gives: [345, 465, 333]     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/862412/is-it-possible-to-have-multiple-statements-in-a-python-lambda-expression","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am a python newbie trying to achieve the following:  I have a list of lists:  lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]   I want map lst into another list containing only the second smallest number from each sublist. So the result should be:  [345, 465, 333]   For example if I were just interested in the smallest number, I could do:  map(lambda x: min(x),lst)   I wish I could do this:  map(lambda x: sort(x)[1],lst)   but sort does not chain. (returns None)  neither is something like this allowed:  map(lambda x: sort(x); x[1],lst) #hence the multiple statement question   Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)     ","Q_Votes":"73"},{"Q_Title":"Django template Path","A_Content":"  I know this isn't in the Django tutorial, and shame on them, but it's better to set up relative paths for your path variables. You can set it up like so:  import os  PROJECT_PATH = os.path.realpath(os.path.dirname(__file__))  ...  MEDIA_ROOT = PROJECT_PATH + '/media/'  TEMPLATE_DIRS = (     PROJECT_PATH + '/templates/', )   This way you can move your Django project and your path roots will update automatically. This is useful when you're setting up your production server.  Second, there's something suspect to your TEMPLATE_DIRS path. It should point to the root of your template directory. Also, it should also end in a trailing /.  I'm just going to guess here that the .../admin/ directory is not your template root. If you still want to write absolute paths you should take out the reference to the admin template directory.  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/' )   With that being said, the template loaders by default should be set up to recursively traverse into your app directories to locate template files.  TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )   You shouldn't need to copy over the admin templates unless if you specifically want to overwrite something.  You will have to run a syncdb if you haven't run it yet. You'll also need to statically server your media files if you're hosting django through runserver.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/3038459/django-template-path","A_Votes":"154","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm following the tutorial on http://docs.djangoproject.com/en/dev/intro/tutorial02/#intro-tutorial02 in a Windows 7 environment. My settings file is:  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/admin' )   I got the base_template from  the template admin/base_site.html from within the default Django admin template directory in the source code of Django itself (django/contrib/admin/templates) into an admin subdirectory of myapp directory as the tutorial instructed.   It doesn't seem to take affect for some reason. Any clue of what might be the problem? Do I have to do a sync db?     ","Q_Votes":"73"},{"Q_Title":"Django template Path","A_Content":"  If using Django settings as installed, then why not just use its baked-in, predefined BASE_DIR and TEMPLATES? In the pip installed Django(v1.8), I get:   BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))    TEMPLATES = [     {         'BACKEND': 'django.template.backends.django.DjangoTemplates',         'DIRS': [             ### ADD YOUR DIRECTORY HERE LIKE SO:             BASE_DIR + '/templates/',         ],         'APP_DIRS': True,         'OPTIONS': {             'context_processors': [                 'django.template.context_processors.debug',                 'django.template.context_processors.request',                 'django.contrib.auth.context_processors.auth',                 'django.contrib.messages.context_processors.messages',             ],         },     }, ]      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/3038459/django-template-path","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I'm following the tutorial on http://docs.djangoproject.com/en/dev/intro/tutorial02/#intro-tutorial02 in a Windows 7 environment. My settings file is:  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/admin' )   I got the base_template from  the template admin/base_site.html from within the default Django admin template directory in the source code of Django itself (django/contrib/admin/templates) into an admin subdirectory of myapp directory as the tutorial instructed.   It doesn't seem to take affect for some reason. Any clue of what might be the problem? Do I have to do a sync db?     ","Q_Votes":"73"},{"Q_Title":"Django template Path","A_Content":"  For Django 1.6.6:  BASE_DIR = os.path.dirname(os.path.dirname(__file__)) TEMPLATE_DIRS = os.path.join(BASE_DIR, 'templates')   Also static and media for debug and production mode:  STATIC_URL = '/static/' MEDIA_URL = '/media/' if DEBUG:     STATIC_ROOT = os.path.join(BASE_DIR, 'static')     MEDIA_ROOT = os.path.join(BASE_DIR, 'media') else:     STATIC_ROOT = %REAL_PATH_TO_PRODUCTION_STATIC_FOLDER%     MEDIA_ROOT = %REAL_PATH_TO_PRODUCTION_MEDIA_FOLDER%   Into urls.py you must add:  from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from django.conf import settings  from news.views import Index  admin.autodiscover()  urlpatterns = patterns('',     url(r'^admin/', include(admin.site.urls)),     ...     )  urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)   In Django 1.8 you can set template paths, backend and other parameters for templates in one dictionary (settings.py):  TEMPLATES = [     {         'BACKEND': 'django.template.backends.django.DjangoTemplates',         'DIRS': [             path.join(BASE_DIR, 'templates')         ],         'APP_DIRS': True,         'OPTIONS': {             'context_processors': [                 'django.template.context_processors.debug',                 'django.template.context_processors.request',                 'django.contrib.auth.context_processors.auth',                 'django.contrib.messages.context_processors.messages',             ],         },     }, ]   Official docs.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/3038459/django-template-path","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm following the tutorial on http://docs.djangoproject.com/en/dev/intro/tutorial02/#intro-tutorial02 in a Windows 7 environment. My settings file is:  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/admin' )   I got the base_template from  the template admin/base_site.html from within the default Django admin template directory in the source code of Django itself (django/contrib/admin/templates) into an admin subdirectory of myapp directory as the tutorial instructed.   It doesn't seem to take affect for some reason. Any clue of what might be the problem? Do I have to do a sync db?     ","Q_Votes":"73"},{"Q_Title":"Django template Path","A_Content":"  I also had issues with this part of the tutorial (used tutorial for version 1.7).  My mistake was that I only edited the 'Django administration' string, and did not pay enough attention to the manual.  This is the line from django/contrib/admin/templates/admin/base_site.html:  <h1 id=\"site-name\"><a href=\"{% url 'admin:index' %}\">{{ site_header|default:_('Django administration') }}</a></h1>   But after some time and frustration it became clear that there was the 'site_header or default:_' statement, which should be removed. So after removing the statement (like the example in the manual everything worked like expected).  Example manual:  <h1 id=\"site-name\"><a href=\"{% url 'admin:index' %}\">Polls Administration</a></h1>      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/3038459/django-template-path","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm following the tutorial on http://docs.djangoproject.com/en/dev/intro/tutorial02/#intro-tutorial02 in a Windows 7 environment. My settings file is:  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/admin' )   I got the base_template from  the template admin/base_site.html from within the default Django admin template directory in the source code of Django itself (django/contrib/admin/templates) into an admin subdirectory of myapp directory as the tutorial instructed.   It doesn't seem to take affect for some reason. Any clue of what might be the problem? Do I have to do a sync db?     ","Q_Votes":"73"},{"Q_Title":"Django template Path","A_Content":"  Smart solution in Django 2.0.3 for keeping templates in project directory (/root/templates/app_name):  settings.py  BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) TEMP_DIR = os.path.join(BASE_DIR, 'templates') ... TEMPLATES = [ {     'BACKEND': 'django.template.backends.django.DjangoTemplates',     'DIRS': [TEMP_DIR], ...   in views.py just add such template path:  app_name/html_name      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/3038459/django-template-path","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm following the tutorial on http://docs.djangoproject.com/en/dev/intro/tutorial02/#intro-tutorial02 in a Windows 7 environment. My settings file is:  TEMPLATE_DIRS = (     'C:/django-project/myapp/mytemplates/admin' )   I got the base_template from  the template admin/base_site.html from within the default Django admin template directory in the source code of Django itself (django/contrib/admin/templates) into an admin subdirectory of myapp directory as the tutorial instructed.   It doesn't seem to take affect for some reason. Any clue of what might be the problem? Do I have to do a sync db?     ","Q_Votes":"73"},{"Q_Title":"Regex to find urls in string in Python [duplicate]","A_Content":"  import re  url = '<p>Hello World</p><a href=\"http://example.com\">More Examples</a><a href=\"http://example2.com\">Even More Examples</a>'  urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', url)  >>> print urls ['http://example.com', 'http://example2.com']      ","Language":"Python","Tags":["python","regex","url"],"URL":"https://stackoverflow.com/questions/6883049/regex-to-find-urls-in-string-in-python","A_Votes":"165","_type":"dict","isAccepted":"Yes","Q_Content":"       Possible Duplicate:   What is the best regular expression to check if a string is a valid URL?       Considering a string as follows:  string = \"<p>Hello World</p><a href=\"http://example.com\">More Examples</a><a href=\"http://example2.com\">Even More Examples</a>\"   How could I, with Python, extract the urls, inside the anchor tag's href? Something like:  >>> url = getURLs(string) >>> url ['http://example.com', 'http://example2.com']   Thanks!     ","Q_Votes":"73"},{"Q_Title":"Regex to find urls in string in Python [duplicate]","A_Content":"  The best answer is...  Don't use a regex  The expression in the accepted answer misses many cases. Among other things, URLs can have unicode characters in them. The regex you want is here, and after looking at it, you may conclude that you don't really want it after all. The most correct version is ten-thousand characters long.  Admittedly, if you were starting with plain, unstructured text with a bunch of URLs in it, then you might need that ten-thousand-character-long regex. But if your input is structured, use the structure. Your stated aim is to \"extract the url, inside the anchor tag's href.\" Why use a ten-thousand-character-long regex when you can do something much simpler?  Parse the HTML instead  For many tasks, using Beautiful Soup will be far faster and easier to use:  >>> from bs4 import BeautifulSoup as Soup >>> html = Soup(s, 'html.parser')           # Soup(s, 'lxml') if lxml is installed >>> [a['href'] for a in html.find_all('a')] ['http://example.com', 'http://example2.com']   If you prefer not to use external tools, you can also directly use Python's own built-in HTML parsing library. Here's a really simple subclass of HTMLParser that does exactly what you want:  from html.parser import HTMLParser  class MyParser(HTMLParser):     def __init__(self, output_list=None):         HTMLParser.__init__(self)         if output_list is None:             self.output_list = []         else:             self.output_list = output_list     def handle_starttag(self, tag, attrs):         if tag == 'a':             self.output_list.append(dict(attrs).get('href'))   Test:  >>> p = MyParser() >>> p.feed(s) >>> p.output_list ['http://example.com', 'http://example2.com']   You could even create a new method that accepts a string, calls feed, and returns output_list. This is a vastly more powerful and extensible way than regular expressions to extract information from html.     ","Language":"Python","Tags":["python","regex","url"],"URL":"https://stackoverflow.com/questions/6883049/regex-to-find-urls-in-string-in-python","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"       Possible Duplicate:   What is the best regular expression to check if a string is a valid URL?       Considering a string as follows:  string = \"<p>Hello World</p><a href=\"http://example.com\">More Examples</a><a href=\"http://example2.com\">Even More Examples</a>\"   How could I, with Python, extract the urls, inside the anchor tag's href? Something like:  >>> url = getURLs(string) >>> url ['http://example.com', 'http://example2.com']   Thanks!     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  First, check tgray's and Lundstrm's advice.  Then, some things you may want to know:   Python is dynamically typed, so unlike C#, you will not check type, but behavior. You may want to google about duck typing. It implies you do not have to deal with boxing and unboxing. Python is fully object oriented, but the syntax does not enforce this paradigm. You can write Python without using the word \"class\". The GUI library featured with Python can't compare with C#'s. Check PyQt, GTK or wxPython libraries. Python has a lot of concepts you may not be familiar with: list comprehensions, generators (\"yield\" does exist in C#, but it is not used much), decorators, metaclasses, etc. Don't be afraid; you can program in Python without them. They are just smart tools, not mandatory. Like in C#, the Python standard library is huge. Always look at it when you encounter any problem. It is most likely that someone solved it already. Python use LATE binding and variable labels. It's far too early for somebody starting with the language to worry about it, but remember that one day you will encounter a behavior with variables that SEEMS illogical, and you'll have to check that. For the moment:   Just remember to never do the following:  def myfunc(my_list=[]) :    # bla   Instead:  def myfunc(my_list=()) :    my_list = list(my_list)   And you'll be good. There is a good reason for that, but that's not the point :-)   Python is cross platform, enjoy writing on Mac, and run on Linux, if you wish. Python is not provided with a complex IDE (you got IDLE :-)). If you are a Visual Studio addict, check Glade. This is not as advanced as Visual Studio, but it's still a good RAD. If you want to develop some web application in Python, remember that Python is not .NET. You must add a web framework to it if you want to compare. I like Django. Python does not need a huge IDE to work with. SciTE, Notepad++, IDLE, Kate, gedit... Lightweight editors are really sufficient. Python enforces indentation using spaces and line break, you can't change that. You should avoid using tabs for indenting and choose spaces instead. The equivalent of empty bracelets {} is the keyword \"pass\". Python does not enforce private variables. You can define a private var using \"__\" (two underscores) at the beginning of the variable name, but it's still bypassable in some tricky ways. Python usually assume programmers are grown adults that know what they do and communicate. Python uses iteration. A lot. A lot of a lot. And so the itertools module is you best friend. Python has no built in delegates. The delegate module is not what you think. For event-driven programming, use a GUI lib (or code the pattern yourself, it's not that difficult). Python has an interpreter: you can test almost anything, live. It should always be running next to your text editor. Python basic interpreter is not much, try IPython for something tasty. Python is autodocumented: use docstrings in your own code and consult other's using \"help()\" in the python interpreter   Module basics:   sys: manipulate system features os: set credential, manipulate file paths, rename, recursive file walk, etc shutil: batch file processing (such as recursive delete) re: regexp urllib and urllib2: HTTPscripting like downloading, post / get resquests, etc. datetime: manipulate date, time AND DURATION thread: you guess it zlib: compression pickle: serialization xml: parsing / Writing XML with SAX or DOM   There are hundreds of modules. Enjoy.  Some typical ways to do things in Python:  Loops:  Python coders use massively the equivalent of the foreach C# loop, and prefer it to any others:  Basic iterations:  for item in collection:     print str(item)   \"collection\" can be a string, a list, a tuple... Any iterable: any object defining the .next() method. There are a lot of iterables in Python. E.g: a typical Python idiom to read files:  for line in open(\"/path/to/file\") :     print line   A shortcut to the for loop is called \"list comprehension\". It's a way to create an new iterable in one line:  Creating a filtered list with list comprehension:  my_list = [item for item in collection if condition]   Creating a new list with a list comprehension:  my_list = [int(item) * 3 for item in collection]   Creating a new generator with a list comprehension:  my_list = (int(item) * 3 for item in collection)   Same as above, but the values will be generated on the fly at the first iteration then lost. More information about it here.  Ordinary for loop  If you want to express a usual for loop, you can use the xrange() function. for (int i = 0; i < 5; i++) becomes:  for i in xrange(0,5) :   do while equivalent  There is no \"Do While\" in Python. I never missed it, but if you have to use this logic, do the following:  while True : # Yes, this is an infinite loop. Crazy, hu?    # Do your stuff    if condition :       break   Unpacking  Swapping variables:  a, b = b, a   Multiple assignations:  The above is just a result of what we call \"unpacking\" (here applied to a tuple). A simple way to explain it is that you can assign each value of any sequence directly to an equal number a variables, in one row:  animal1, animal2, animal3, animal4 = [\"cow\", \"dog\", \"bird\", \"fish\"]   This has a lot of implications. While iterating on a multidimensional array, you normally get each sub sequence one by one then use it, for example:  agenda = [(\"steve\", \"jobs\"), (\"linus\", \"torvald\"), (\"bill\", \"gates\"),(\"jon\", \"skeet\")] for person in agenda:     print person[0], person[1]   But with unpacking, you can assign the values directly to variables as well:  agenda = [(\"steve\", \"jobs\"), (\"linus\", \"torvald\"), (\"bill\", \"gates\"),(\"jon\", \"skeet\")] for name, lastname in agenda:     print name, lastname   And that's why if you want to get an index while iterating, Python coders use the following idioms (enumerate() is a standard function):  for index, value in enumerate(sequence) :     print index, value   Unpacking in functions calls  This is advanced use, and you can skip it if it bothers you.  You can unpack values using the sign \"*\" to use a sequence directly in a function call. E.g:  >>> foo(var1, var1, var3) :     print var1, var2     print var3 >>> seq = (3.14, 42, \"yeah\") >>> foo(*seq) 3.14 42 yeah   There is even more than that. You can unpack a dictionary as named variables, and write function prototypes with *, ** to accept an arbitrary number of arguments. But it not used enough to deserve to make this post even longer :-).  String formatting:  print \"This is a %s on %s about %s\" % (\"post\", \"stackoverflow\", \"python\") print \"This is a %(subject)s on %(place)s about %(about)s\" % {\"subject\" : \"post\", \"place\" : \"stackoverflow\", \"about\" : \"python\"}   Slicing an iterable:  You can get any part of an iterable using a very concise syntax:  print \"blebla\"[2:4] # Print \"eb\" last = string[:-1] # Getting last element even = (0,1,2,3,4,5,6,7,8,9)[::2] # Getting evens only (third argument is a step) reversed = string[::-1] # Reversing a string   Logical checks:  You can check the way you do in C#, but there are \"Pythonic\" ways (shorter, clearer :-)):  if 1 in (1, 2, 3, 4) : # Check en element is in a sequence  if var : # check is var is true. Var == false if it's False, 0, (), [], {} or None  if not var : # Contrary of above  if thing is var: # Check if \"thing\" and \"var\" label the same content.  if thing is None : # We use that one because None means nothing in Python (almost null)   Combo (print on one line all the words containing an \"o\" in uppercase ):  sentence = \"It's a good day to write some code\" print \" \".join([word.upper() for word in sentence.split() if \"o\" in word])   Output: \"GOOD TO SOME CODE\"  Easier to ask for forgiveness than permission  Python coders usually don't check if something is possible. They are a bit like Chuck Norris. They do it. Then catch the exception. Typically, you don't check if a file exists, you try to open it, and roll back if it fails:  try :     f = open(file) except IOerror :     print \"no file here !\"   Of course Chuck Norris never uses excepts since he never fails.  The else clause  \"Else\" is a world of many uses in Python. You will find \"else\" after \"if\", but after \"except\" and \"for\" as well.  for stuff in bunch :     # Do things else :     # This always happens unless you hit \"break\" in the loop   This works for \"while\" loop too, even if we do not use this loop as much.     try :       # A crazy stuff    except ToCrazyError :       # This happens if the crazy stuff raises a ToCrazyError Exception    else :       # This will happen if there is no error so you can put only one line after the \"try\" clause    finally :       # The same as in C#     If you are curious, here is a bunch of advanced quick and dirty (but nice) Python snippets.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"151","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"   Refrain from using classes. Use dictionaries, sets, list and tuples. Setters and getters are forbidden. Don't have exception handlers unless you really need to - let it crash in style. Pylint can be your friend for more pythonish coding style. When you're ready - check out list comprehensions, generators and lambda functions.      ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  If you are not new to programming, I would recommend the book \"Dive into Python\" by Mark Pilgrim. It explains Python in a way that makes it easy to understand how Python techniques and idioms can be applied to build practical applications.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  Start by reading The Zen of Python  You can read it at the link above, or just type import this at the Python prompt. =)  Take advantage of Python features not offered* by C#  Such as duck-typing, metaclasses, list comprehension, etc.*  Write simple programs just to test these features. You'll get used (if not addicted) to them in no time.  Look at the Python Standard Library  So you don't reinvent the wheel. Don't try to read the whole thing, even a quick look at the TOC could save you a lot of time.    * I know C# already has some of these features, but from what I can see they're either pretty new or not commonly used by C# developers. Please correct me if I'm wrong.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  In case you haven't heard about it yet, Dive Into Python is a great place to start for anyone learning Python.  It also has a bunch of Tips & Tricks.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  If you are someone who is better learning a new language by taking small incremental steps then I would recommend using IronPython.  Otherwise use regular CPython and don't do any more C# coding until you feel like you have a grasp of Python.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  I would suggest getting a good editor so that you don't get bitten by whitespace.  For simplicity, I just use ActivePython's packages Link, which include an editor and all of the win32api libraries.  They are pretty fun to get into if you have been using C#.  The win32api in Python can be a little bit simpler.  You don't need to do the whole DDLImport thing.  Download ActivePython (which comes with CPython), open it up, and start entering some stuff at the console.  You will pick it up fairly easy after using C#.  For some more interesting Python tidbits, try ActiveState code, which has all sorts of recipes, which can allow you to very simply see different things that you can do with Python.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  I'm pretty much in your shoes too, still using C# for most of my work, but using Python more and more for other projects.  @e-satis probably knows Python inside-out and all his advice is top-notch. From my point of view what made the biggest difference to me was the following:  Get back into functional. not necessarily spaghetti code, but learning that not everything has to be in an object, nor should it be.  The interpreter. It's like the immediate window except 10^10 better. Because of how Python works you don't need all the baggage and crap C# makes you put in before you can run things; you can just whack in a few lines and see how things work.  I've normally got an IDLE instance up where I just throw around snippets as I'm working out how the various bits in the language works while I'm editing my files... e.g. busy working out how to do a map call on a list, but I'm not 100% on the lambda I should use... whack in a few lines into IDLE, see how it works and what it does.  And finally, loving into the verbosity of Python, and I don't mean that in the long winded meaning of verbosity, but as e-satis pointed out, using verbs like \"in\", \"is\", \"for\", etc.  If you did a lot of reflection work in C# you'll feel like crying when you see how simple the same stuff is in Python.  Good luck with it.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  If you have programming experience and don't feel like spending money I'd recommend How to Think Like a Computer Scientist in Python.       ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"Advice for C# programmer writing Python [closed]","A_Content":"  And then something you can benefit from:  IPython shell: Auto completion in the shell. It does batch operations, adds a ton of features, logging and such. >>> Play with the shell - always!  easy_install / pip: So nice and an easy way to install a 3rd party Python application.     ","Language":"Python","Tags":["c#","python"],"URL":"https://stackoverflow.com/questions/683273/advice-for-c-sharp-programmer-writing-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've mainly been doing C# development for the past few years but recently started to do a bit of Python (not Iron Python).  But I'm not sure if I've made the mental leap to Python...I kind of feel I'm trying to do things as I would in C#.  Any advice on how I can fully take advantage of Python?  Or any tips\\tricks, things to learn more about, things to watch out for?     ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  T = [L[i] for i in Idx]      ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"159","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  If you are using numpy, you can perform extended slicing like that:  >>> import numpy >>> a=numpy.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']) >>> Idx = [0, 3, 7] >>> a[Idx] array(['a', 'd', 'h'],        dtype='|S1')   ...and is probably much faster (if performance is enough of a concern to to bother with the numpy import)     ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  T = map(lambda i: L[i], Idx)      ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  A functional approach:  a = [1,\"A\", 34, -123, \"Hello\", 12] b = [0, 2, 5]  from operator import itemgetter  print(list(itemgetter(*b)(a))) [1, 34, 12]      ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  I wasn't happy with any of these approaches, so I came up with a Flexlist class that allows for flexible indexing, either by integer, slice or index-list:  class Flexlist(list):     def __getitem__(self, keys):         if isinstance(keys, (int, slice)): return list.__getitem__(self, keys)         return [self[k] for k in keys]   Which, for your example, you would use as:  L = Flexlist(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']) Idx = [0, 3, 7] T = L[ Idx ]  print(T)  # ['a', 'd', 'h']      ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"In Python, how do I index a list with another list?","A_Content":"  L= {'a':'a','d':'d', 'h':'h'} index= ['a','d','h']  for keys in index:     print(L[keys])   I would use a Dict add desired keys to index      ","Language":"Python","Tags":["python","list","indexing"],"URL":"https://stackoverflow.com/questions/1012185/in-python-how-do-i-index-a-list-with-another-list","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I would like to index a list with another list like this  L = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] Idx = [0, 3, 7] T = L[ Idx ]   and T should end up being a list containing ['a', 'd', 'h'].  Is there a better way than  T = [] for i in Idx:     T.append(L[i])  print T # Gives result ['a', 'd', 'h']      ","Q_Votes":"73"},{"Q_Title":"Python simple if or logic statement","A_Content":"  If key isn't an int or float but a string, you need to convert it to an int first by doing  key = int(key)   or to a float by doing  key = float(key)   Otherwise, what you have in your question should work, but  if (key < 1) or (key > 34):   or  if not (1 <= key <= 34):   would be a bit clearer.     ","Language":"Python","Tags":["python","if-statement","logic"],"URL":"https://stackoverflow.com/questions/7141208/python-simple-if-or-logic-statement","A_Votes":"150","_type":"dict","isAccepted":"Yes","Q_Content":"    How would you write, in python:  if key < 1 or key > 34:   I've tried every way I can think of, and am finding it very frustrating.     ","Q_Votes":"73"},{"Q_Title":"Python simple if or logic statement","A_Content":"  Here's a boolean thing:  if (not suffix == \"flac\" )  or (not suffix == \"cue\" ):   # WRONG! FAILS     print  filename + ' is not a flac or cue file'   but   if not (suffix == \"flac\"  or suffix == \"cue\" ):     # CORRECT!          print  filename + ' is not a flac or cue file'   (not a) or (not b) ==  not ( a and b ) ,  is false only if a and b are both true  not (a or b) is true only if a and be are both false.     ","Language":"Python","Tags":["python","if-statement","logic"],"URL":"https://stackoverflow.com/questions/7141208/python-simple-if-or-logic-statement","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    How would you write, in python:  if key < 1 or key > 34:   I've tried every way I can think of, and am finding it very frustrating.     ","Q_Votes":"73"},{"Q_Title":"Python simple if or logic statement","A_Content":"  you can simply use   if (key<1) or (key>34):  your problem will be solved     ","Language":"Python","Tags":["python","if-statement","logic"],"URL":"https://stackoverflow.com/questions/7141208/python-simple-if-or-logic-statement","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How would you write, in python:  if key < 1 or key > 34:   I've tried every way I can think of, and am finding it very frustrating.     ","Q_Votes":"73"},{"Q_Title":"How to make a class property?","A_Content":"  Here's how I would do this:  class ClassPropertyDescriptor(object):      def __init__(self, fget, fset=None):         self.fget = fget         self.fset = fset      def __get__(self, obj, klass=None):         if klass is None:             klass = type(obj)         return self.fget.__get__(obj, klass)()      def __set__(self, obj, value):         if not self.fset:             raise AttributeError(\"can't set attribute\")         type_ = type(obj)         return self.fset.__get__(obj, type_)(value)      def setter(self, func):         if not isinstance(func, (classmethod, staticmethod)):             func = classmethod(func)         self.fset = func         return self  def classproperty(func):     if not isinstance(func, (classmethod, staticmethod)):         func = classmethod(func)      return ClassPropertyDescriptor(func)   class Bar(object):      _bar = 1      @classproperty     def bar(cls):         return cls._bar      @bar.setter     def bar(cls, value):         cls._bar = value   # test instance instantiation foo = Bar() assert foo.bar == 1  baz = Bar() assert baz.bar == 1  # test static variable baz.bar = 5 assert foo.bar == 5  # test setting variable on the class Bar.bar = 50 assert baz.bar == 50 assert foo.bar == 50   The setter didn't work at the time we call  Bar.bar, because we are calling TypeOfBar.bar.__set__, which is not Bar.bar.__set__.  Adding a metaclass definition solves this:  class ClassPropertyMetaClass(type):     def __setattr__(self, key, value):         if key in self.__dict__:             obj = self.__dict__.get(key)         if obj and type(obj) is ClassPropertyDescriptor:             return obj.__set__(self, value)          return super(ClassPropertyMetaClass, self).__setattr__(key, value)  # and update class define: #     class Bar(object): #        __metaclass__ = ClassPropertyMetaClass #        _bar = 1  # and update ClassPropertyDescriptor.__set__ #    def __set__(self, obj, value): #       if not self.fset: #           raise AttributeError(\"can't set attribute\") #       if inspect.isclass(obj): #           type_ = obj #           obj = None #       else: #           type_ = type(obj) #       return self.fset.__get__(obj, type_)(value)   Now all will be fine.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"55","_type":"dict","isAccepted":"Yes","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How to make a class property?","A_Content":"  If you define classproperty as follows, then your example works exactly as you requested.  class classproperty(object):     def __init__(self, f):         self.f = f     def __get__(self, obj, owner):         return self.f(owner)   The caveat is that you can't use this for writable properties.  While e.I = 20 will raise an AttributeError, Example.I = 20 will overwrite the property object itself.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How to make a class property?","A_Content":"  I think you may be able to do this with the metaclass.  Since the metaclass can be like a class for the class (if that makes sense).  I know you can assign a __call__() method to the metaclass to override calling the class, MyClass().  I wonder if using the property decorator on the metaclass operates similarly.  (I haven't tried this before, but now I'm curious...)  [update:]  Wow, it does work:  class MetaClass(type):         def getfoo(self):         return self._foo     foo = property(getfoo)      @property     def bar(self):         return self._bar  class MyClass(object):     __metaclass__ = MetaClass     _foo = 'abc'     _bar = 'def'  print MyClass.foo print MyClass.bar   Note: This is in Python 2.7.  Python 3+ uses a different technique to declare a metaclass.  Use: class MyClass(metaclass=MetaClass):, remove __metaclass__, and the rest is the same.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How to make a class property?","A_Content":"  [answer written based on python 3.4; the metaclass syntax differs in 2 but I think the technique will still work]  You can do this with a metaclass...mostly. Dappawit's almost works, but I think it has a flaw:  class MetaFoo(type):     @property     def thingy(cls):         return cls._thingy  class Foo(object, metaclass=MetaFoo):     _thingy = 23   This gets you a classproperty on Foo, but there's a problem...  print(\"Foo.thingy is {}\".format(Foo.thingy)) # Foo.thingy is 23 # Yay, the classmethod-property is working as intended! foo = Foo() if hasattr(foo, \"thingy\"):     print(\"Foo().thingy is {}\".format(foo.thingy)) else:     print(\"Foo instance has no attribute 'thingy'\") # Foo instance has no attribute 'thingy' # Wha....?   What the hell is going on here? Why can't I reach the class property from an instance?  I was beating my head on this for quite a while before finding what I believe is the answer. Python @properties are a subset of descriptors, and, from the descriptor documentation (emphasis mine):     The default behavior for attribute access is to get, set, or delete the   attribute from an objects dictionary. For instance, a.x has a lookup chain   starting with a.__dict__['x'], then type(a).__dict__['x'], and continuing    through the base classes of type(a) excluding metaclasses.   So the method resolution order doesn't include our class properties (or anything else defined in the metaclass). It is possible to make a subclass of the built-in property decorator that behaves differently, but (citation needed) I've gotten the impression googling that the developers had a good reason (which I do not understand) for doing it that way.  That doesn't mean we're out of luck; we can access the properties on the class itself just fine...and we can get the class from type(self) within the instance, which we can use to make @property dispatchers:  class Foo(object, metaclass=MetaFoo):     _thingy = 23      @property     def thingy(self):         return type(self).thingy   Now Foo().thingy works as intended for both the class and the instances! It will also continue to do the right thing if a derived class replaces its underlying _thingy (which is the use case that got me on this hunt originally).  This isn't 100% satisfying to me -- having to do setup in both the metaclass and object class feels like it violates the DRY principle. But the latter is just a one-line dispatcher; I'm mostly okay with it existing, and you could probably compact it down to a lambda or something if you really wanted.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How to make a class property?","A_Content":"  As far as I can tell, there is no way to write a setter for a class property without creating a new metaclass.  I have found that the following method works. Define a metaclass with all of the class properties and setters you want. IE, I wanted a class with a title property with a setter. Here's what I wrote:  class TitleMeta(type):     @property     def title(self):         return getattr(self, '_title', 'Default Title')      @title.setter     def title(self, title):         self._title = title         # Do whatever else you want when the title is set...   Now make the actual class you want as normal, except have it use the metaclass you created above.  # Python 2 style: class ClassWithTitle(object):     __metaclass__ = TitleMeta     # The rest of your class definition...  # Python 3 style: class ClassWithTitle(object, metaclass = TitleMeta):     # Your class definition...   It's a bit weird to define this metaclass as we did above if we'll only ever use it on the single class. In that case, if you're using the Python 2 style, you can actually define the metaclass inside the class body. That way it's not defined in the module scope.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How to make a class property?","A_Content":"  If you only need lazy loading, then you could just have a class initialisation method.  EXAMPLE_SET = False class Example(object):    @classmethod     def initclass(cls):        global EXAMPLE_SET         if EXAMPLE_SET: return        cls.the_I = 'ok'        EXAMPLE_SET = True     def __init__( self ):       Example.initclass()       self.an_i = 20  try:     print Example.the_I except AttributeError:     print 'ok class not \"loaded\"' foo = Example() print foo.the_I print Example.the_I   But the metaclass approach seems cleaner, and with more predictable behavior.  Perhaps what you're looking for is the Singleton design pattern. There's a nice SO QA about implementing shared state in Python.     ","Language":"Python","Tags":["python","properties","class-method"],"URL":"https://stackoverflow.com/questions/5189699/how-to-make-a-class-property","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    In python I can add a method to a class with the @classmethod decorator.  Is there a similar decorator to add a property to a class?  I can better show what I'm talking about.  class Example(object):    the_I = 10    def __init__( self ):       self.an_i = 20     @property    def i( self ):       return self.an_i     def inc_i( self ):       self.an_i += 1     # is this even possible?    @classproperty    def I( cls ):       return cls.the_I     @classmethod    def inc_I( cls ):       cls.the_I += 1  e = Example() assert e.i == 20 e.inc_i() assert e.i == 21  assert Example.I == 10 Example.inc_I() assert Example.I == 11   Is the syntax I've used above possible or would it require something more?  The reason I want class properties is so I can lazy load class attributes, which seems reasonable enough.     ","Q_Votes":"75"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  To answer your first question, numpy.correlate(a, v, mode) is performing the convolution of a with the reverse of v and giving the results clipped by the specified mode. The definition of convolution, C(t)= - < i <   aivt+i where - < t < , allows for results from - to , but you obviously can't store an infinitely long array. So it has to be clipped, and that is where the mode comes in. There are 3 different modes: full, same, & valid:    \"full\" mode returns results for every t where both a and v have some overlap.  \"same\" mode returns a result with the same length as the shortest vector (a or v).  \"valid\" mode returns results only when a and v completely overlap each other. The documentation for numpy.convolve gives more detail on the modes.   For your second question, I think numpy.correlate is giving you the autocorrelation, it is just giving you a little more as well. The autocorrelation is used to find how similar a signal, or function, is to itself at a certain time difference. At a time difference of 0, the auto-correlation should be the highest because the signal is identical to itself, so you expected that the first element in the autocorrelation result array would be the greatest. However, the correlation is not starting at a time difference of 0. It starts at a negative time difference, closes to 0, and then goes positive. That is, you were expecting:    autocorrelation(a) =  - < i <   aivt+i where 0 <= t <     But what you got was:    autocorrelation(a) =  - < i <   aivt+i where - < t <   What you need to do is take the last half of your correlation result, and that should be the autocorrelation you are looking for. A simple python function to do that would be:  def autocorr(x):     result = numpy.correlate(x, x, mode='full')     return result[result.size/2:]   You will, of course, need error checking to make sure that x is actually a 1-d array. Also, this explanation probably isn't the most mathematically rigorous. I've been throwing around infinities because the definition of convolution uses them, but that doesn't necessarily apply for autocorrelation. So, the theoretical portion of this explanation may be slightly wonky, but hopefully the practical results are helpful. These pages on autocorrelation are pretty helpful, and can give you a much better theoretical background if you don't mind wading through the notation and heavy concepts.     ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"87","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  Using the numpy.corrcoef function instead of numpy.correlate to calculate the statistical correlation for a lag of t:  def autocorr(x, t=1):     numpy.corrcoef(numpy.array([x[0:len(x)-t], x[t:len(x)]]))      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  Auto-correlation comes in two versions: statistical and convolution. They both do the same, except for a little detail: The former is normalized to be on the interval [-1,1]. Here is an example of how you do the statistical one:  def acf(x, length=20):     return numpy.array([1]+[numpy.corrcoef(x[:-i], x[i:]) \\         for i in range(1, length)])      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  As I just ran into the same problem, I would like to share a few lines of code with you. In fact there are several rather similar posts about autocorrelation in stackoverflow by now. If you define the autocorrelation as a(x, L) = sum(k=0,N-L-1)((xk-xbar)*(x(k+L)-xbar))/sum(k=0,N-1)((xk-xbar)**2) [this is the definition given in IDL's a_correlate function and it agrees with what I see in answer 2 of question #12269834], then the following seems to give the correct results:  import numpy as np import matplotlib.pyplot as plt  # generate some data x = np.arange(0.,6.12,0.01) y = np.sin(x) # y = np.random.uniform(size=300) yunbiased = y-np.mean(y) ynorm = np.sum(yunbiased**2) acor = np.correlate(yunbiased, yunbiased, \"same\")/ynorm # use only second half acor = acor[len(acor)/2:]  plt.plot(acor) plt.show()   As you see I have tested this with a sin curve and a uniform random distribution, and both results look like I would expect them. Note that I used mode=\"same\" instead of mode=\"full\" as the others did.      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  Your question 1 has been already extensively discussed in several excellent answers here.  I thought to share with you a few lines of code that allow you to compute the autocorrelation of a signal based only on the mathematical properties of the autocorrelation. That is, the autocorrelation may be computed in the following way:   subtract the mean from the signal and obtain an unbiased signal compute the Fourier transform of the unbiased signal compute the power spectral density of the signal, by taking the square norm of each value of the Fourier transform of the unbiased signal compute the inverse Fourier transform of the power spectral density normalize the inverse Fourier transform of the power spectral density by the sum of the squares of the unbiased signal, and take only half of the resulting vector   The code to do this is the following:  def autocorrelation (x) :     \"\"\"     Compute the autocorrelation of the signal, based on the properties of the     power spectral density of the signal.     \"\"\"     xp = x-np.mean(x)     f = np.fft.fft(xp)     p = np.array([np.real(v)**2+np.imag(v)**2 for v in f])     pi = np.fft.ifft(p)     return np.real(pi)[:x.size/2]/np.sum(xp**2)      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  I think there are 2 things that add confusion to this topic:   statistical v.s. signal processing definition: as others have pointed out, in statistics we normalize auto-correlation into [-1,1].  partial v.s. non-partial mean/variance: when the timeseries shifts at a lag>0, their overlap size will always < original length. Do we use the mean and std of the original (non-partial), or always compute a new mean and std using the ever changing overlap (partial) makes a difference. (There's probably a formal term for this, but I'm gonna use \"partial\" for now).   I've created 5 functions that compute auto-correlation of a 1d array, with partial v.s. non-partial distinctions. Some use formula from statistics, some use correlate in the signal processing sense, which can also be done via FFT. But all results are auto-correlations in the statistics definition, so they illustrate how they are linked to each other. Code below:  import numpy import matplotlib.pyplot as plt  def autocorr1(x,lags):     '''numpy.corrcoef, partial'''      corr=[1. if l==0 else numpy.corrcoef(x[l:],x[:-l])[0][1] for l in lags]     return numpy.array(corr)  def autocorr2(x,lags):     '''manualy compute, non partial'''      mean=numpy.mean(x)     var=numpy.var(x)     xp=x-mean     corr=[1. if l==0 else numpy.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]      return numpy.array(corr)  def autocorr3(x,lags):     '''fft, pad 0s, non partial'''      n=len(x)     # pad 0s to 2n-1     ext_size=2*n-1     # nearest power of 2     fsize=2**numpy.ceil(numpy.log2(ext_size)).astype('int')      xp=x-numpy.mean(x)     var=numpy.var(x)      # do fft and ifft     cf=numpy.fft.fft(xp,fsize)     sf=cf.conjugate()*cf     corr=numpy.fft.ifft(sf).real     corr=corr/var/n      return corr[:len(lags)]  def autocorr4(x,lags):     '''fft, don't pad 0s, non partial'''     mean=x.mean()     var=numpy.var(x)     xp=x-mean      cf=numpy.fft.fft(xp)     sf=cf.conjugate()*cf     corr=numpy.fft.ifft(sf).real/var/len(x)      return corr[:len(lags)]  def autocorr5(x,lags):     '''numpy.correlate, non partial'''     mean=x.mean()     var=numpy.var(x)     xp=x-mean     corr=numpy.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)      return corr[:len(lags)]   if __name__=='__main__':      y=[28,28,26,19,16,24,26,24,24,29,29,27,31,26,38,23,13,14,28,19,19,\\             17,22,2,4,5,7,8,14,14,23]     y=numpy.array(y).astype('float')      lags=range(15)     fig,ax=plt.subplots()      for funcii, labelii in zip([autocorr1, autocorr2, autocorr3, autocorr4,         autocorr5], ['np.corrcoef, partial', 'manual, non-partial',             'fft, pad 0s, non-partial', 'fft, no padding, non-partial',             'np.correlate, non-partial']):          cii=funcii(y,lags)         print(labelii)         print(cii)         ax.plot(lags,cii,label=labelii)      ax.set_xlabel('lag')     ax.set_ylabel('correlation coefficient')     ax.legend()     plt.show()   Here is the output figure:    We don't see all 5 lines because 3 of them overlap (at the purple). The overlaps are all non-partial auto-correlations. This is because computations from the signal processing methods (np.correlate, FFT) don't compute a different mean/std for each overlap.  Also note that the fft, no padding, non-partial (red line) result is different, because it didn't pad the timeseries with 0s before doing FFT, so it's circular FFT. I can't explain in detail why, that's what I learned from elsewhere.     ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  I use talib.CORREL for autocorrelation like this, I suspect you could do the same with other packages:  def autocorrelate(x, period):      # x is a deep indicator array      # period of sample and slices of comparison      # oldest data (period of input array) may be nan; remove it     x = x[-np.count_nonzero(~np.isnan(x)):]     # subtract mean to normalize indicator     x -= np.mean(x)     # isolate the recent sample to be autocorrelated     sample = x[-period:]     # create slices of indicator data     correls = []     for n in range((len(x)-1), period, -1):         alpha = period + n         slices = (x[-alpha:])[:period]         # compare each slice to the recent sample         correls.append(ta.CORREL(slices, sample, period)[-1])     # fill in zeros for sample overlap period of recent correlations         for n in range(period,0,-1):         correls.append(0)     # oldest data (autocorrelation period) will be nan; remove it     correls = np.array(correls[-np.count_nonzero(~np.isnan(correls)):])            return correls  # CORRELATION OF BEST FIT # the highest value correlation     max_value = np.max(correls) # index of the best correlation max_index = np.argmax(correls)      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  A simple solution without pandas:  import numpy as np  def auto_corrcoef(x):    return np.corrcoef(x[1:-1], x[2:])[0,1]      ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  I think the real answer to the OP's question is succinctly contained in this excerpt from the Numpy.correlate documentation:  mode : {'valid', 'same', 'full'}, optional     Refer to the `convolve` docstring.  Note that the default     is `valid`, unlike `convolve`, which uses `full`.   This implies that, when used with no 'mode' definition, the Numpy.correlate function will return a scalar, when given the same vector for its two input arguments (i.e. - when used to perform autocorrelation).     ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"How can I use numpy.correlate to do autocorrelation?","A_Content":"  I'm a computational biologist, and when I had to compute the auto/cross-correlations between couples of time series of stochastic processes I realized that np.correlate was not doing the job I needed.  Indeed, what seems to be missing from np.correlate is the averaging over all the possible couples of time points at distance \\tau.  Here is how I defined a function doing what I needed:  def autocross(x, y):     c = np.correlate(x, y, \"same\")     v = [c[i]/( len(x)-abs( i - (len(x)/2)  ) ) for i in range(len(c))]     return v   It seems to me none of the previous answers cover this instance of auto/cross-correlation: hope this answer may be useful to somebody working on stochastic processes like me.     ","Language":"Python","Tags":["python","math","numpy","numerical-methods"],"URL":"https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to do auto-correlation of a set of numbers, which as I understand it is just the correlation of the set with itself.   I've tried it using numpy's correlate function, but I don't believe the result, as it almost always gives a vector where the first number is not the largest, as it ought to be.  So, this question is really two questions:   What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation?      ","Q_Votes":"74"},{"Q_Title":"Difference between subprocess.Popen and os.system","A_Content":"  If you check out the subprocess section of the Python docs, you'll notice there is an example of how to replace os.system() with subprocess.Popen():  sts = os.system(\"mycmd\" + \" myarg\")   ...does the same thing as...  sts = Popen(\"mycmd\" + \" myarg\", shell=True).wait()   The \"improved\" code looks more complicated, but it's better because once you know subprocess.Popen(), you don't need anything else. subprocess.Popen() replaces several other tools (os.system() is just one of those) that were scattered throughout three other Python modules.  If it helps, think of subprocess.Popen() as a very flexible os.system().     ","Language":"Python","Tags":["python","subprocess","system"],"URL":"https://stackoverflow.com/questions/4813238/difference-between-subprocess-popen-and-os-system","A_Votes":"64","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the difference between subprocess.Popen() and os.system()?     ","Q_Votes":"76"},{"Q_Title":"Difference between subprocess.Popen and os.system","A_Content":"  subprocess.Popen() is strict super-set of os.system().     ","Language":"Python","Tags":["python","subprocess","system"],"URL":"https://stackoverflow.com/questions/4813238/difference-between-subprocess-popen-and-os-system","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    What is the difference between subprocess.Popen() and os.system()?     ","Q_Votes":"76"},{"Q_Title":"Difference between subprocess.Popen and os.system","A_Content":"  Subprocess is based on popen2, and as such has a number of advantages - there's a full list in the PEP here, but some are:   using pipe in the shell better newline support better handling of exceptions      ","Language":"Python","Tags":["python","subprocess","system"],"URL":"https://stackoverflow.com/questions/4813238/difference-between-subprocess-popen-and-os-system","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    What is the difference between subprocess.Popen() and os.system()?     ","Q_Votes":"76"},{"Q_Title":"Difference between subprocess.Popen and os.system","A_Content":"  os.system is equivalent to Unix system command, while subprocess was a helper module created to provide many of the facilities provided by the Popen commands with an easier and controllable interface. Those were designed similar to the Unix Popen command.  system() executes a command specified in command by calling /bin/sh -c command, and returns after the command has been completed   where as  The popen() function opens a process by creating a pipe, forking, and invoking the shell.   If you are thinking, which one to use, then use subprocess definitely because you you have all facilities for execution, plus additional control over the process.     ","Language":"Python","Tags":["python","subprocess","system"],"URL":"https://stackoverflow.com/questions/4813238/difference-between-subprocess-popen-and-os-system","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    What is the difference between subprocess.Popen() and os.system()?     ","Q_Votes":"76"},{"Q_Title":"Difference between subprocess.Popen and os.system","A_Content":"  When running python (cpython) on windows the <built-in function system> os.system will execute under the curtains _wsystem while if you're using a non-windows os, it'll use system.  On contrary, Popen should use CreateProcess on windows and _posixsubprocess.fork_exec in posix-based operating-systems.  That said, an important piece of advice comes from os.system docs, which says:     The subprocess module provides more powerful facilities for spawning   new processes and retrieving their results; using that module is   preferable to using this function. See the Replacing Older Functions   with the subprocess Module section in the subprocess documentation for   some helpful recipes.      ","Language":"Python","Tags":["python","subprocess","system"],"URL":"https://stackoverflow.com/questions/4813238/difference-between-subprocess-popen-and-os-system","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What is the difference between subprocess.Popen() and os.system()?     ","Q_Votes":"76"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  Here is a much better (official) NumPy for Matlab Users link - I'm afraid the mathesaurus one is quite out of date.  The numpy equivalent of repmat(a, m, n) is tile(a, (m, n)).   This works with multiple dimensions and gives a similar result to matlab. (Numpy gives a 3d output array as you would expect - matlab for some reason gives 2d output - but the content is the same).  Matlab:  >> repmat([1;1],[1,1,1])  ans =      1      1   Python:  In [46]: a = np.array([[1],[1]]) In [47]: np.tile(a, [1,1,1]) Out[47]:  array([[[1],         [1]]])      ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  Note that some of the reasons you'd need to use MATLAB's repmat are taken care of by NumPy's broadcasting mechanism, which allows you to do various types of math with arrays of similar shape. So if you had, say, a 1600x1400x3 array representing a 3-color image, you could (elementwise) multiply it by [1.0 0.25 0.25] to reduce the amount of green and blue at each pixel. See the above link for more information.     ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  See NumPy for Matlab users.  Matlab:  repmat(a, 2, 3)   Numpy:  numpy.kron(numpy.ones((2,3)), a)      ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  Know both tile and repeat.  x = numpy.arange(5) print numpy.tile(x, 2) print x.repeat(2)      ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  This is how I understood it out of a bit of fiddling around. Happy to be corrected and hope this helps.  Say you have a matrix M of 2x3 elements. This has two dimensions, obviously.    I could see no difference between Matlab and Python while asking to manipulate the input matrix along the dimensions the matrix already has.  Thus the two commands  repmat(M,m,n) % matlab  np.tile(M,(m,n)) # python   are really equivalent for a matrix of rank 2 (two dimensions).     The matters goes counter-intuitive when you ask for repetition/tiling over more dimensions than the input matrix has. Going back to the matrix M of rank two and shape 2x3, it is sufficient to look at what happens to the size/shape of the output matrix. Say the sequence for manipulation is now 1,1,2.  In Matlab  > size(repmat(M,1,1,2)) ans =      2   3   2   it has copied the first two dimensions (rows and columns) of the input matrix and has repeated that once into a new third dimension (copied twice, that is). True to the naming repmat for repeat matrix.   In Python  >>> np.tile(M,(1,1,2)).shape (1, 2, 6)   it has applied a different procedure since, I presume, the sequence (1,1,2) is read differently than in Matlab. The number of copies in the direction of columns, rows and out-of-plane dimension are being read from right to left. The resulting object has a different shape from Matlab. One can no longer assert that repmat and tile are equivalent instructions.    In order to get tile to behave like repmat, in Python one has to make sure that the input matrix has as many dimensions as the elements are in the sequence. This is done, for example, by a little preconditioning and creating a related object N  N = M[:,:,np.newaxis]   Then, at the input side one has N.shape = (2,3,1) rather than M.shape = (2,3) and at the output side  >>> np.tile(N,(1,1,2)).shape (2, 3, 2)   which was the answer of size(repmat(M,1,1,2)). I presume this is because we have guided Python to add the third dimension to the right of (2,3) rather than to its left, so that Python works out the sequence (1,1,2) as it was intended in the Matlab way of reading it.  The element in [:,:,0] in the Python answer for N will contain the same values as the element (:,:,1) the Matlab answer for M.    Finally, I can't seem to find an equivalent for repmat when one uses the Kronecker product out of  >>> np.kron(np.ones((1,1,2)),M).shape (1, 2, 6)   unless I then precondition M into N as above. So I would argue that the most general way to move on is to use the ways of np.newaxis.    The game gets trickier when we consider a matrix L of rank 3 (three dimensions) and the simple case of no new dimensions being added in the output matrix. These two seemingly equivalent instructions will not produce the same results  repmat(L,p,q,r) % matlab  np.tile(L,(p,q,r)) # python   because the row, column, out-of-plane directions are (p,q,r) in Matlab and (q,r,p) in Python, which was not visible with rank-2 arrays. There, one has to be careful and obtaining the same results with the two languages would require more preconditioning.     I am aware that this reasoning may well not be general, but I could work it out only this far. Hopefully this invites other fellows to put it to a harder test.     ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"What is the equivalent of MATLAB's repmat in NumPy","A_Content":"  import numpy as np  np.repeat(['a','b'], [2,5]) >>> array(['a', 'a', 'b', 'b', 'b', 'b', 'b'], dtype='<U1')  np.repeat([1,2], [2,5]) >>> array([1, 1, 2, 2, 2, 2, 2])  np.repeat(np.array([1,2]), [3]).reshape(2,3) >>> array([[1, 1, 1],            [2, 2, 2]])  np.repeat(np.array([1,2]), [2,4]).reshape(3,2) >>> array([[1, 1],            [2, 2],            [2, 2]])  np.repeat(np.matrix('1 2; 3 4'), [2]).reshape(4,2) >>> matrix([[1, 1],             [2, 2],             [3, 3],             [4, 4]])      ","Language":"Python","Tags":["python","matlab","numpy"],"URL":"https://stackoverflow.com/questions/1721802/what-is-the-equivalent-of-matlabs-repmat-in-numpy","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1], [1 1 1]).  How would I accomplish this?     ","Q_Votes":"77"},{"Q_Title":"WhatsApp API (java/python) [closed]","A_Content":"  After trying everything, Yowsup library worked for me. The bug that I was facing was recently fixed. Anyone trying to do something with Whatsapp should try it.     ","Language":"Python","Tags":["java","python","api","bots","whatsapp"],"URL":"https://stackoverflow.com/questions/17135496/whatsapp-api-java-python","A_Votes":"34","_type":"dict","isAccepted":"Yes","Q_Content":"    I am looking for WhatsApp API, preferably a Python or Java library.  I've tried Yowsup, but could not get my number registered; I am based in India and I am not sure if that has got anything to do with it.  I did try WhatsAPI (Python library) but it is not working either.  Any suggestions about this? Any users of Yowsup here?     ","Q_Votes":"78"},{"Q_Title":"WhatsApp API (java/python) [closed]","A_Content":"  Yowsup provide best solution with example.you can download api from https://github.com/tgalal/yowsup let me know if you have any issue.     ","Language":"Python","Tags":["java","python","api","bots","whatsapp"],"URL":"https://stackoverflow.com/questions/17135496/whatsapp-api-java-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for WhatsApp API, preferably a Python or Java library.  I've tried Yowsup, but could not get my number registered; I am based in India and I am not sure if that has got anything to do with it.  I did try WhatsAPI (Python library) but it is not working either.  Any suggestions about this? Any users of Yowsup here?     ","Q_Votes":"78"},{"Q_Title":"WhatsApp API (java/python) [closed]","A_Content":"  This is the developers page of the Open WhatsApp official page: http://openwhatsapp.org/develop/  You can find a lot of information there about Yowsup.  Or, you can just go the the library's link (which I copied from the Open WhatsApp page anyway): https://github.com/tgalal/yowsup  Enjoy!     ","Language":"Python","Tags":["java","python","api","bots","whatsapp"],"URL":"https://stackoverflow.com/questions/17135496/whatsapp-api-java-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for WhatsApp API, preferably a Python or Java library.  I've tried Yowsup, but could not get my number registered; I am based in India and I am not sure if that has got anything to do with it.  I did try WhatsAPI (Python library) but it is not working either.  Any suggestions about this? Any users of Yowsup here?     ","Q_Votes":"78"},{"Q_Title":"WhatsApp API (java/python) [closed]","A_Content":"  WhatsApp Inc. does not provide an open API but a reverse-engineered library is made available on GitHub by the team Venomous on the GitHub. This however according to my knowledge is made possible in PHP. You can check the link here: https://github.com/venomous0x/WhatsAPI  Hope this helps      ","Language":"Python","Tags":["java","python","api","bots","whatsapp"],"URL":"https://stackoverflow.com/questions/17135496/whatsapp-api-java-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for WhatsApp API, preferably a Python or Java library.  I've tried Yowsup, but could not get my number registered; I am based in India and I am not sure if that has got anything to do with it.  I did try WhatsAPI (Python library) but it is not working either.  Any suggestions about this? Any users of Yowsup here?     ","Q_Votes":"78"},{"Q_Title":"WhatsApp API (java/python) [closed]","A_Content":"  From my blog  courtesy  There is a secret pilot program which WhatsApp is working on with selected businesses   https://faq.whatsapp.com/general/26000052   News coverage:   https://yourstory.com/2017/09/app-fridays-whatsapp-for-business-bookmyshow/ https://yourstory.com/2017/09/bookmyshows-product-team-decrypts-how-whatsapp-for-business-works/ http://indianexpress.com/article/technology/social/now-get-bookmyshow-ticket-confirmation-message-on-whatsapp-4844869/ http://gadgets.ndtv.com/apps/news/whatsapp-business-bookmyshow-pilot-1750740   For some of my technical experiments, I was trying to figure out how beneficial and feasible it is to implement bots for different chat platforms in terms of market share and so possibilities of adaptation. Especially when you have bankruptly failed twice, it's important to validate ideas and fail more faster.  Popular chat platforms like Messenger, Slack, Skype etc. have happily (in the sense officially) provided APIs for bots to interact with, but WhatsApp has not yet provided any API.  However, since many years, a lot of activities has happened around this - struggle towards automated interaction with WhatsApp platform:   Bots App Bots App is interesting because it shows that something is really tried and tested. Yowsup A project still actively developed to interact with WhatsApp platform. Yallagenie  Yallagenie claim that there is a demo bot which can be interacted with at +971 56 112 6652 Hubtype Hubtype is working towards having a bot platform for WhatsApp for business. Fred Fred's task was to automate WhatsApp conversations, however since it was not officially supported by WhatsApp - it was shut down. Oye Gennie A bot blocked by WhatsApp. App/Website to WhatsApp We can use custom URL schemes and Android intent system to interact with WhatsApp but still NOT WhatsApp API. Chat API daemon Probably created by inspecting the API calls in WhatsApp web version. NOT affiliated with WhatsApp. WhatsBot Deactivated WhatsApp bot. Created during a hackathon. No API claim WhatsApp co-founder clearly stated this in a conference that they did not had any plans for APIs for WhatsApp. Bot Ware They probably are expecting WhatsApp to release their APIs for chat bot platforms. Vixi They seems to be talking about how some platform which probably would work for WhatsApp. There is no clarity as such. Unofficial API This API can shut off any time.  And the number goes on...      ","Language":"Python","Tags":["java","python","api","bots","whatsapp"],"URL":"https://stackoverflow.com/questions/17135496/whatsapp-api-java-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for WhatsApp API, preferably a Python or Java library.  I've tried Yowsup, but could not get my number registered; I am based in India and I am not sure if that has got anything to do with it.  I did try WhatsAPI (Python library) but it is not working either.  Any suggestions about this? Any users of Yowsup here?     ","Q_Votes":"78"},{"Q_Title":"How do I run Selenium in Xvfb?","A_Content":"  open a terminal and run this command  xhost +. This commands needs to be run every time you restart your machine. If everything works fine may be you can add this to startup commands  Also make sure in your /etc/environment file there is a line   export DISPLAY=:0.0    And then, run your tests to see if your issue is resolved.  All please note the comment from sardathrion below before using this.     ","Language":"Python","Tags":["python","linux","user-interface","unix","selenium"],"URL":"https://stackoverflow.com/questions/6183276/how-do-i-run-selenium-in-xvfb","A_Votes":"31","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm on EC2 instance. So there is no GUI.  $pip install selenium $sudo apt-get install firefox xvfb   Then I do this:  $Xvfb :1 -screen 0 1024x768x24 2>&1 >/dev/null &  $DISPLAY=:1 java -jar selenium-server-standalone-2.0b3.jar 05:08:31.227 INFO - Java: Sun Microsystems Inc. 19.0-b09 05:08:31.229 INFO - OS: Linux 2.6.32-305-ec2 i386 05:08:31.233 INFO - v2.0 [b3], with Core v2.0 [b3] 05:08:32.121 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub 05:08:32.122 INFO - Version Jetty/5.1.x 05:08:32.123 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver] 05:08:32.124 INFO - Started HttpContext[/selenium-server,/selenium-server] 05:08:32.124 INFO - Started HttpContext[/,/] 05:08:32.291 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@1186fab 05:08:32.292 INFO - Started HttpContext[/wd,/wd] 05:08:32.295 INFO - Started SocketListener on 0.0.0.0:4444 05:08:32.295 INFO - Started org.openqa.jetty.jetty.Server@1ffb8dc   Great, everything should work now, right?  When I run my code:  from selenium import webdriver from selenium.common.exceptions import NoSuchElementException from selenium.webdriver.common.keys import Keys  browser = webdriver.Firefox()  browser.get(\"http://www.yahoo.com\")    I get this:  Error: cannot open display: :0      ","Q_Votes":"78"},{"Q_Title":"How do I run Selenium in Xvfb?","A_Content":"  You can use PyVirtualDisplay (a Python wrapper for Xvfb) to run headless WebDriver tests.  #!/usr/bin/env python  from pyvirtualdisplay import Display from selenium import webdriver  display = Display(visible=0, size=(800, 600)) display.start()  # now Firefox will run in a virtual display.  # you will not see the browser. browser = webdriver.Firefox() browser.get('http://www.google.com') print browser.title browser.quit()  display.stop()   more info    You can also use xvfbwrapper, which is a similar module (but has no external dependencies):  from xvfbwrapper import Xvfb  vdisplay = Xvfb() vdisplay.start()  # launch stuff inside virtual display here  vdisplay.stop()   or better yet, use it as a context manager:  from xvfbwrapper import Xvfb  with Xvfb() as xvfb:     # launch stuff inside virtual display here.     # It starts/stops in this code block.      ","Language":"Python","Tags":["python","linux","user-interface","unix","selenium"],"URL":"https://stackoverflow.com/questions/6183276/how-do-i-run-selenium-in-xvfb","A_Votes":"153","_type":"dict","isAccepted":"No","Q_Content":"    I'm on EC2 instance. So there is no GUI.  $pip install selenium $sudo apt-get install firefox xvfb   Then I do this:  $Xvfb :1 -screen 0 1024x768x24 2>&1 >/dev/null &  $DISPLAY=:1 java -jar selenium-server-standalone-2.0b3.jar 05:08:31.227 INFO - Java: Sun Microsystems Inc. 19.0-b09 05:08:31.229 INFO - OS: Linux 2.6.32-305-ec2 i386 05:08:31.233 INFO - v2.0 [b3], with Core v2.0 [b3] 05:08:32.121 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub 05:08:32.122 INFO - Version Jetty/5.1.x 05:08:32.123 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver] 05:08:32.124 INFO - Started HttpContext[/selenium-server,/selenium-server] 05:08:32.124 INFO - Started HttpContext[/,/] 05:08:32.291 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@1186fab 05:08:32.292 INFO - Started HttpContext[/wd,/wd] 05:08:32.295 INFO - Started SocketListener on 0.0.0.0:4444 05:08:32.295 INFO - Started org.openqa.jetty.jetty.Server@1ffb8dc   Great, everything should work now, right?  When I run my code:  from selenium import webdriver from selenium.common.exceptions import NoSuchElementException from selenium.webdriver.common.keys import Keys  browser = webdriver.Firefox()  browser.get(\"http://www.yahoo.com\")    I get this:  Error: cannot open display: :0      ","Q_Votes":"78"},{"Q_Title":"How do I run Selenium in Xvfb?","A_Content":"  The easiest way is probably to use xvfb-run:  DISPLAY=:1 xvfb-run java -jar selenium-server-standalone-2.0b3.jar   xvfb-run does the whole X authority dance for you, give it a try!     ","Language":"Python","Tags":["python","linux","user-interface","unix","selenium"],"URL":"https://stackoverflow.com/questions/6183276/how-do-i-run-selenium-in-xvfb","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    I'm on EC2 instance. So there is no GUI.  $pip install selenium $sudo apt-get install firefox xvfb   Then I do this:  $Xvfb :1 -screen 0 1024x768x24 2>&1 >/dev/null &  $DISPLAY=:1 java -jar selenium-server-standalone-2.0b3.jar 05:08:31.227 INFO - Java: Sun Microsystems Inc. 19.0-b09 05:08:31.229 INFO - OS: Linux 2.6.32-305-ec2 i386 05:08:31.233 INFO - v2.0 [b3], with Core v2.0 [b3] 05:08:32.121 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub 05:08:32.122 INFO - Version Jetty/5.1.x 05:08:32.123 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver] 05:08:32.124 INFO - Started HttpContext[/selenium-server,/selenium-server] 05:08:32.124 INFO - Started HttpContext[/,/] 05:08:32.291 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@1186fab 05:08:32.292 INFO - Started HttpContext[/wd,/wd] 05:08:32.295 INFO - Started SocketListener on 0.0.0.0:4444 05:08:32.295 INFO - Started org.openqa.jetty.jetty.Server@1ffb8dc   Great, everything should work now, right?  When I run my code:  from selenium import webdriver from selenium.common.exceptions import NoSuchElementException from selenium.webdriver.common.keys import Keys  browser = webdriver.Firefox()  browser.get(\"http://www.yahoo.com\")    I get this:  Error: cannot open display: :0      ","Q_Votes":"78"},{"Q_Title":"How do I run Selenium in Xvfb?","A_Content":"  This is the setup I use:  Before running the tests, execute:  export DISPLAY=:99 /etc/init.d/xvfb start   And after the tests:  /etc/init.d/xvfb stop  The init.d file I use looks like this:  #!/bin/bash  XVFB=/usr/bin/Xvfb XVFBARGS=\"$DISPLAY -ac -screen 0 1024x768x16\" PIDFILE=${HOME}/xvfb_${DISPLAY:1}.pid case \"$1\" in   start)     echo -n \"Starting virtual X frame buffer: Xvfb\"     /sbin/start-stop-daemon --start --quiet --pidfile $PIDFILE --make-pidfile --background --exec $XVFB -- $XVFBARGS     echo \".\"     ;;   stop)     echo -n \"Stopping virtual X frame buffer: Xvfb\"     /sbin/start-stop-daemon --stop --quiet --pidfile $PIDFILE     echo \".\"     ;;   restart)     $0 stop     $0 start     ;;   *)   echo \"Usage: /etc/init.d/xvfb {start|stop|restart}\"   exit 1 esac exit 0     ","Language":"Python","Tags":["python","linux","user-interface","unix","selenium"],"URL":"https://stackoverflow.com/questions/6183276/how-do-i-run-selenium-in-xvfb","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I'm on EC2 instance. So there is no GUI.  $pip install selenium $sudo apt-get install firefox xvfb   Then I do this:  $Xvfb :1 -screen 0 1024x768x24 2>&1 >/dev/null &  $DISPLAY=:1 java -jar selenium-server-standalone-2.0b3.jar 05:08:31.227 INFO - Java: Sun Microsystems Inc. 19.0-b09 05:08:31.229 INFO - OS: Linux 2.6.32-305-ec2 i386 05:08:31.233 INFO - v2.0 [b3], with Core v2.0 [b3] 05:08:32.121 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub 05:08:32.122 INFO - Version Jetty/5.1.x 05:08:32.123 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver] 05:08:32.124 INFO - Started HttpContext[/selenium-server,/selenium-server] 05:08:32.124 INFO - Started HttpContext[/,/] 05:08:32.291 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@1186fab 05:08:32.292 INFO - Started HttpContext[/wd,/wd] 05:08:32.295 INFO - Started SocketListener on 0.0.0.0:4444 05:08:32.295 INFO - Started org.openqa.jetty.jetty.Server@1ffb8dc   Great, everything should work now, right?  When I run my code:  from selenium import webdriver from selenium.common.exceptions import NoSuchElementException from selenium.webdriver.common.keys import Keys  browser = webdriver.Firefox()  browser.get(\"http://www.yahoo.com\")    I get this:  Error: cannot open display: :0      ","Q_Votes":"78"},{"Q_Title":"How do I run Selenium in Xvfb?","A_Content":"  If you use Maven, you can use xvfb-maven-plugin to start xvfb before tests, run them using related DISPLAY environment variable, and stop xvfb after all.     ","Language":"Python","Tags":["python","linux","user-interface","unix","selenium"],"URL":"https://stackoverflow.com/questions/6183276/how-do-i-run-selenium-in-xvfb","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm on EC2 instance. So there is no GUI.  $pip install selenium $sudo apt-get install firefox xvfb   Then I do this:  $Xvfb :1 -screen 0 1024x768x24 2>&1 >/dev/null &  $DISPLAY=:1 java -jar selenium-server-standalone-2.0b3.jar 05:08:31.227 INFO - Java: Sun Microsystems Inc. 19.0-b09 05:08:31.229 INFO - OS: Linux 2.6.32-305-ec2 i386 05:08:31.233 INFO - v2.0 [b3], with Core v2.0 [b3] 05:08:32.121 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub 05:08:32.122 INFO - Version Jetty/5.1.x 05:08:32.123 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver] 05:08:32.124 INFO - Started HttpContext[/selenium-server,/selenium-server] 05:08:32.124 INFO - Started HttpContext[/,/] 05:08:32.291 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@1186fab 05:08:32.292 INFO - Started HttpContext[/wd,/wd] 05:08:32.295 INFO - Started SocketListener on 0.0.0.0:4444 05:08:32.295 INFO - Started org.openqa.jetty.jetty.Server@1ffb8dc   Great, everything should work now, right?  When I run my code:  from selenium import webdriver from selenium.common.exceptions import NoSuchElementException from selenium.webdriver.common.keys import Keys  browser = webdriver.Firefox()  browser.get(\"http://www.yahoo.com\")    I get this:  Error: cannot open display: :0      ","Q_Votes":"78"},{"Q_Title":"Strip all the elements of a string list","A_Content":"  >>> my_list = ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n'] >>> map(str.strip, my_list) ['this', 'is', 'a', 'list', 'of', 'words']      ","Language":"Python","Tags":["python","list","strip"],"URL":"https://stackoverflow.com/questions/7984169/strip-all-the-elements-of-a-string-list","A_Votes":"151","_type":"dict","isAccepted":"Yes","Q_Content":"    I have to take a large list of words in the form:  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']   and then using the strip function, turn it into:  ['this', 'is', 'a', 'list', 'of', 'words']   I thought that what I had written would work, but I keep getting an error saying:     \"'list' object has no attribute 'strip'\"   Here is the code that I tried:  strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())      ","Q_Votes":"80"},{"Q_Title":"Strip all the elements of a string list","A_Content":"  list comprehension? [x.strip() for x in lst]     ","Language":"Python","Tags":["python","list","strip"],"URL":"https://stackoverflow.com/questions/7984169/strip-all-the-elements-of-a-string-list","A_Votes":"84","_type":"dict","isAccepted":"No","Q_Content":"    I have to take a large list of words in the form:  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']   and then using the strip function, turn it into:  ['this', 'is', 'a', 'list', 'of', 'words']   I thought that what I had written would work, but I keep getting an error saying:     \"'list' object has no attribute 'strip'\"   Here is the code that I tried:  strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())      ","Q_Votes":"80"},{"Q_Title":"Strip all the elements of a string list","A_Content":"  You can use lists comprehensions:  strip_list = [item.strip() for item in lines]   Or the map function:  # with a lambda strip_list = map(lambda it: it.strip(), lines)  # without a lambda strip_list = map(str.strip, lines)      ","Language":"Python","Tags":["python","list","strip"],"URL":"https://stackoverflow.com/questions/7984169/strip-all-the-elements-of-a-string-list","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I have to take a large list of words in the form:  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']   and then using the strip function, turn it into:  ['this', 'is', 'a', 'list', 'of', 'words']   I thought that what I had written would work, but I keep getting an error saying:     \"'list' object has no attribute 'strip'\"   Here is the code that I tried:  strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())      ","Q_Votes":"80"},{"Q_Title":"Strip all the elements of a string list","A_Content":"  This can be done using list comprehensions as defined in PEP 202  [w.strip() for w in  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']]      ","Language":"Python","Tags":["python","list","strip"],"URL":"https://stackoverflow.com/questions/7984169/strip-all-the-elements-of-a-string-list","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have to take a large list of words in the form:  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']   and then using the strip function, turn it into:  ['this', 'is', 'a', 'list', 'of', 'words']   I thought that what I had written would work, but I keep getting an error saying:     \"'list' object has no attribute 'strip'\"   Here is the code that I tried:  strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())      ","Q_Votes":"80"},{"Q_Title":"Strip all the elements of a string list","A_Content":"  All other answers, and mainly about list comprehension, are great. But just to explain your error:   strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())   a is a member of your list, not an index. What you could write is this:  [...] for a in lines:     strip_list.append(a.strip())   Another important comment: you can create an empty list this way:  strip_list = [0] * 20   But this is not so useful, as .append appends stuff to your list. In your case, it's not useful to create a list with defaut values, as you'll build it item per item when appending stripped strings.  So your code should be like:  strip_list = [] for a in lines:     strip_list.append(a.strip())   But, for sure, the best one is this one, as this is exactly the same thing:  stripped = [line.strip() for line in lines]   In case you have something more complicated than just a .strip, put this in a function, and do the same. That's the most readable way to work with lists.     ","Language":"Python","Tags":["python","list","strip"],"URL":"https://stackoverflow.com/questions/7984169/strip-all-the-elements-of-a-string-list","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have to take a large list of words in the form:  ['this\\n', 'is\\n', 'a\\n', 'list\\n', 'of\\n', 'words\\n']   and then using the strip function, turn it into:  ['this', 'is', 'a', 'list', 'of', 'words']   I thought that what I had written would work, but I keep getting an error saying:     \"'list' object has no attribute 'strip'\"   Here is the code that I tried:  strip_list = [] for lengths in range(1,20):     strip_list.append(0) #longest word in the text file is 20 characters long for a in lines:     strip_list.append(lines[a].strip())      ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  If the quotes you want to strip are always going to be \"first and last\" as you said, then you could simply use:  string = string[1:-1]     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"146","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  If you can't assume that all the strings you process have double quotes you can use something like this:  if string.startswith('\"') and string.endswith('\"'):     string = string[1:-1]   Edit:  I'm sure that you just used string as the variable name for exemplification here and in your real code it has a useful name, but I feel obliged to warn you that there is a module named string in the standard libraries.  It's not loaded automatically, but if you ever use import string make sure your variable doesn't eclipse it.     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"76","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  To remove the first and last characters, and in each case do the removal only if the character in question is a double quote:  import re  s = re.sub(r'^\"|\"$', '', s)   Note that the RE pattern is different than the one you had given, and the operation is sub (\"substitute\") with an empty replacement string (strip is a string method but does something pretty different from your requirements, as other answers have indicated).     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  IMPORTANT: I'm extending the question/answer to strip either single or double quotes. And I interpret the question to mean that BOTH quotes must be present, and matching, to perform the strip. Otherwise, the string is returned unchanged.  To \"dequote\" a string representation, that might have either single or double quotes around it (this is an extension of @tgray's answer):  def dequote(s):     \"\"\"     If a string has single or double quotes around it, remove them.     Make sure the pair of quotes match.     If a matching pair of quotes is not found, return the string unchanged.     \"\"\"     if (s[0] == s[-1]) and s.startswith((\"'\", '\"')):         return s[1:-1]     return s   Explanation:  startswith can take a tuple, to match any of several alternatives. The reason for the DOUBLED parentheses (( and )) is so that we pass ONE parameter (\"'\", '\"') to startswith(), to specify the permitted prefixes, rather than TWO parameters \"'\" and '\"', which would be interpreted as a prefix and an (invalid) start position.  s[-1] is the last character in the string.  Testing:  print( dequote(\"\\\"he\\\"l'lo\\\"\") ) print( dequote(\"'he\\\"l'lo'\") ) print( dequote(\"he\\\"l'lo\") ) print( dequote(\"'he\\\"l'lo\\\"\") )   =>  he\"l'lo he\"l'lo he\"l'lo 'he\"l'lo\"   (For me, regex expressions are non-obvious to read, so I didn't try to extend @Alex's answer.)     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  If string is always as you show:  string[1:-1]      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  Almost done. Quoting from http://docs.python.org/library/stdtypes.html?highlight=strip#str.strip     The chars argument is a string   specifying the set of characters to be   removed.   [...]     The chars argument is not a prefix or   suffix; rather, all combinations of   its values are stripped:   So the argument is not a regexp.  >>> string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"' >>> string.strip('\"') ' \" \" \"\"\\\\1\" \" \"\" ' >>>    Note, that this is not exactly what you requested, because it eats multiple quotes from both end of the string!     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  If you are sure there is a \" at the beginning and at the end, which you want to remove, just do:  string = string[1:len(string)-1]   or   string = string[1:-1]      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  Remove a determinated character from start and end from a string.  s = '/Hello World/' s.strip('/')  > 'Hello World'      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  find the position of the first and the last \" in your string  >>> s = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"' >>> l = s.find('\"') >>> r = s.rfind('\"')  >>> s[l+1:r] '\" \" \" \"\"\\\\1\" \" \"\" \"'      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  I have some code that needs to strip single or double quotes, and I can't simply ast.literal_eval it.  if len(arg) > 1 and arg[0] in ('\"\\'') and arg[-1] == arg[0]:     arg = arg[1:-1]   This is similar to ToolmakerSteve's answer, but it allows 0 length strings, and doesn't turn the single character \" into an empty string.      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  in your example you could use strip but you have to provide the space  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"' string.strip('\" ')  # output '\\\\1'   note the \\' in the output is the standard python quotes for string output  the value of your variable is '\\\\1'     ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"python How can I strip first and last double quotes","A_Content":"  Below function will strip the empty spces and return the strings without quotes. If there are no quotes then it will return same string(stripped)  def removeQuote(str): str = str.strip() if re.search(\"^[\\'\\\"].*[\\'\\\"]$\",str):     str = str[1:-1]     print(\"Removed Quotes\",str) else:     print(\"Same String\",str) return str      ","Language":"Python","Tags":["python","string","strip"],"URL":"https://stackoverflow.com/questions/3085382/python-how-can-i-strip-first-and-last-double-quotes","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I want to strip double quotes from  string = '\"\" \" \" \"\"\\\\1\" \" \"\" \"\"'   to become  string = '\" \" \" \"\"\\\\1\" \" \"\" \"'   I tried to use rstrip, lstrip and strip('[^\\\"]|[\\\"$]') but it did not work.  How can I do this? Thank you for helping me.     ","Q_Votes":"80"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  This should do it:  import math  def sigmoid(x):   return 1 / (1 + math.exp(-x))   And now you can test it by calling:  >>> sigmoid(0.458) 0.61253961344091512   Update: Note that the above was mainly intended as a straight one-to-one translation of the given expression into Python code. It is not tested or known to be a numerically sound implementation. If you know you need a very robust implementation, I'm sure there are others where people have actually given this problem some thought.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  It is also available in scipy: http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.logistic.html  In [1]: from scipy.stats import logistic  In [2]: logistic.cdf(0.458) Out[2]: 0.61253961344091512   which is only a costly wrapper (because it allows you to scale and translate the logistic function) of another scipy function:  In [3]: from scipy.special import expit  In [4]: expit(0.458) Out[4]: 0.61253961344091512   If you are concerned about performances continue reading, otherwise just use expit.  Some benchmarking:  In [5]: def sigmoid(x):   ....:     return 1 / (1 + math.exp(-x))   ....:   In [6]: %timeit -r 1 sigmoid(0.458) 1000000 loops, best of 1: 371 ns per loop   In [7]: %timeit -r 1 logistic.cdf(0.458) 10000 loops, best of 1: 72.2 s per loop  In [8]: %timeit -r 1 expit(0.458) 100000 loops, best of 1: 2.98 s per loop   As expected logistic.cdf is (much) slower than expit. expit is still slower than the python sigmoid function when called with a single value because it is a universal function written in C ( http://docs.scipy.org/doc/numpy/reference/ufuncs.html ) and thus has a call overhead. This overhead is bigger than the computation speedup of expit given by its compiled nature when called with a single value. But it becomes negligible when it comes to big arrays:  In [9]: import numpy as np  In [10]: x = np.random.random(1000000)  In [11]: def sigmoid_array(x):                                            ....:    return 1 / (1 + np.exp(-x))    ....:    (You'll notice the tiny change from math.exp to np.exp (the first one does not support arrays, but is much faster if you have only one value to compute))  In [12]: %timeit -r 1 -n 100 sigmoid_array(x) 100 loops, best of 1: 34.3 ms per loop  In [13]: %timeit -r 1 -n 100 expit(x) 100 loops, best of 1: 31 ms per loop   But when you really need performance, a common practice is to have a precomputed table of the the sigmoid function that hold in RAM, and trade some precision and memory for some speed (for example: http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/ )  Also, note that expit implementation is numerically stable since version 0.14.0: https://github.com/scipy/scipy/issues/3385     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"130","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  Here's how you would implement the logistic sigmoid in a numerically stable way (as described here):  def sigmoid(x):     \"Numerically-stable sigmoid function.\"     if x >= 0:         z = exp(-x)         return 1 / (1 + z)     else:         z = exp(x)         return z / (1 + z)   Or perhaps this is more accurate:  import numpy as np  def sigmoid(x):       return math.exp(-np.logaddexp(0, -x))   Internally, it implements the same condition as above, but then uses log1p.  In general, the multinomial logistic sigmoid is:  def nat_to_exp(q):     max_q = max(0.0, np.max(q))     rebased_q = q - max_q     return np.exp(rebased_q - np.logaddexp(-max_q, np.logaddexp.reduce(rebased_q)))   (However, logaddexp.reduce could be more accurate.)     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  another way  >>> def sigmoid(x): ...     return 1 /(1+(math.e**-x)) ... >>> sigmoid(0.458)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  I feel many might be interested in free parameters to alter the shape of the sigmoid function. Second for many applications you want to use a mirrored sigmoid function. Third you might want to do a simple normalization for example the output values are between 0 and 1.   Try:  def normalized_sigmoid_fkt(a, b, x):    '''    Returns array of a horizontal mirrored normalized sigmoid function    output between 0 and 1    Function parameters a = center; b = width    '''    s= 1/(1+np.exp(b*(x-a)))    return 1*(s-min(s))/(max(s)-min(s)) # normalize function to 0-1   And to draw and compare:  def draw_function_on_2x2_grid(x):      fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)     plt.subplots_adjust(wspace=.5)     plt.subplots_adjust(hspace=.5)      ax1.plot(x, normalized_sigmoid_fkt( .5, 18, x))     ax1.set_title('1')      ax2.plot(x, normalized_sigmoid_fkt(0.518, 10.549, x))     ax2.set_title('2')      ax3.plot(x, normalized_sigmoid_fkt( .7, 11, x))     ax3.set_title('3')      ax4.plot(x, normalized_sigmoid_fkt( .2, 14, x))     ax4.set_title('4')     plt.suptitle('Different normalized (sigmoid) function',size=10 )      return fig   Finally:  x = np.linspace(0,1,100) Travel_function = draw_function_on_2x2_grid(x)        ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  Another way by transforming the tanh function:    sigmoid = lambda x: .5 * (math.tanh(.5 * x) + 1)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  Good answer from @unwind. It however can't handle extreme negative number (throwing OverflowError).  My improvement:  def sigmoid(x):     try:         res = 1 / (1 + math.exp(-x))     except OverflowError:         res = 0.0     return res      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  Tensorflow includes also a sigmoid function: https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/sigmoid  import tensorflow as tf  sess = tf.InteractiveSession() x = 0.458 y = tf.sigmoid(x)  u = y.eval() print(u) # 0.6125396      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  A numerically stable version of the logistic sigmoid function.      def sigmoid(x):         pos_mask = (x >= 0)         neg_mask = (x < 0)         z = np.zeros_like(x,dtype=float)         z[pos_mask] = np.exp(-x[pos_mask])         z[neg_mask] = np.exp(x[neg_mask])         top = np.ones_like(x,dtype=float)         top[neg_mask] = z[neg_mask]         return top / (1 + z)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to calculate a logistic sigmoid function in Python?","A_Content":"  Use the numpy package to allow your sigmoid function to parse vectors.  In conformity with Deeplearning, I use the following code:  import numpy as np def sigmoid(x):     s = 1/(1+np.exp(-x))     return s      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    This is a logistic sigmoid function:    I know x. How can I calculate F(x) in Python now?  Let's say x = 0.458.  F(x) = ?     ","Q_Votes":"81"},{"Q_Title":"How to document class attributes in Python? [closed]","A_Content":"  To avoid confusion: the term property has a specific meaning in python.  What you're talking about is what we call class attributes.  Since they are always acted upon through their class, I find that it makes sense to document them within the class' doc string.  Something like this:  class Albatross(object):     \"\"\"A bird with a flight speed exceeding that of an unladen swallow.      Attributes:         flight_speed     The maximum speed that such a bird can attain.         nesting_grounds  The locale where these birds congregate to reproduce.     \"\"\"     flight_speed = 691     nesting_grounds = \"Throatwarbler Man Grove\"   I think that's a lot easier on the eyes than the approach in your example.  If I really wanted a copy of the attribute values to appear in the doc string, I would put them beside or below the description of each attribute.  Keep in mind that in Python, doc strings are actual members of the objects they document, not merely source code annotations. Since class attribute variables are not objects themselves but references to objects, they have no way of holding doc strings of their own. I guess you could make a case for doc strings on references, perhaps to describe \"what should go here\" instead of \"what is actually here\", but I find it easy enough to do that in the containing class doc string.     ","Language":"Python","Tags":["python","class","documentation","docstring","class-attributes"],"URL":"https://stackoverflow.com/questions/3051241/how-to-document-class-attributes-in-python","A_Votes":"58","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a lightweight class whose attributes are intended to be publicly accessible, and only sometimes overridden in specific instantiations.  There's no provision in the Python language for creating docstrings for class attributes, or any sort of attributes, for that matter.  What is the accepted way, should there be one, to document these attributes?  Currently I'm doing this sort of thing:  class Albatross(object):     \"\"\"A bird with a flight speed exceeding that of an unladen swallow.      Attributes:     \"\"\"      flight_speed = 691     __doc__ += \"\"\"         flight_speed (691)           The maximum speed that such a bird can attain.     \"\"\"      nesting_grounds = \"Raymond Luxury-Yacht\"     __doc__ += \"\"\"         nesting_grounds (\"Raymond Luxury-Yacht\")           The locale where these birds congregate to reproduce.     \"\"\"      def __init__(self, **keyargs):         \"\"\"Initialize the Albatross from the keyword arguments.\"\"\"         self.__dict__.update(keyargs)   This will result in the class's docstring containing the initial standard docstring section, as well as the lines added for each attribute via augmented assignment to __doc__.  Although this style doesn't seem to be expressly forbidden in the docstring style guidelines, it's also not mentioned as an option.  The advantage here is that it provides a way to document attributes alongside their definitions, while still creating a presentable class docstring, and avoiding having to write comments that reiterate the information from the docstring.  I'm still kind of annoyed that I have to actually write the attributes twice; I'm considering using the string representations of the values in the docstring to at least avoid duplication of the default values.  Is this a heinous breach of the ad hoc community conventions?  Is it okay?  Is there a better way?  For example, it's possible to create a dictionary containing values and docstrings for the attributes and then add the contents to the class __dict__ and docstring towards the end of the class declaration; this would alleviate the need to type the attribute names and values twice.  edit: this last idea is, I think, not actually possible, at least not without dynamically building the entire class from data, which seems like a really bad idea unless there's some other reason to do that.  I'm pretty new to python and still working out the details of coding style, so unrelated critiques are also welcome.     ","Q_Votes":"82"},{"Q_Title":"How to document class attributes in Python? [closed]","A_Content":"  You cite the PEP257: Docstring Conventions, in the section What is a docstring it is stated:     String literals occurring elsewhere in Python code may also act as documentation. They are not recognized by the Python bytecode compiler and are not accessible as runtime object attributes (i.e. not assigned to __doc__), but two types of extra docstrings may be extracted by software tools:      String literals occurring immediately after a simple assignment at the top level of a module, class, or __init__ method are called \"attribute docstrings\".   And this is explained in more details in PEP 258: Attribute docstrings. As explains above so. an attribute is not an object that can own a __doc__ so they won't appear in help() or pydoc. These docstrings can only be used for generated documentation.  But presently few tools use them.  The older Epydoc do use them and Sphinx introduced it in v0.6 and extended it in v1.1. Sphinx can use docstring on a line before an assignment or in a special comment following an assignment.  See the directive autoattribute in the Sphinx Manual  and the examples of attribute docstrings there.     ","Language":"Python","Tags":["python","class","documentation","docstring","class-attributes"],"URL":"https://stackoverflow.com/questions/3051241/how-to-document-class-attributes-in-python","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a lightweight class whose attributes are intended to be publicly accessible, and only sometimes overridden in specific instantiations.  There's no provision in the Python language for creating docstrings for class attributes, or any sort of attributes, for that matter.  What is the accepted way, should there be one, to document these attributes?  Currently I'm doing this sort of thing:  class Albatross(object):     \"\"\"A bird with a flight speed exceeding that of an unladen swallow.      Attributes:     \"\"\"      flight_speed = 691     __doc__ += \"\"\"         flight_speed (691)           The maximum speed that such a bird can attain.     \"\"\"      nesting_grounds = \"Raymond Luxury-Yacht\"     __doc__ += \"\"\"         nesting_grounds (\"Raymond Luxury-Yacht\")           The locale where these birds congregate to reproduce.     \"\"\"      def __init__(self, **keyargs):         \"\"\"Initialize the Albatross from the keyword arguments.\"\"\"         self.__dict__.update(keyargs)   This will result in the class's docstring containing the initial standard docstring section, as well as the lines added for each attribute via augmented assignment to __doc__.  Although this style doesn't seem to be expressly forbidden in the docstring style guidelines, it's also not mentioned as an option.  The advantage here is that it provides a way to document attributes alongside their definitions, while still creating a presentable class docstring, and avoiding having to write comments that reiterate the information from the docstring.  I'm still kind of annoyed that I have to actually write the attributes twice; I'm considering using the string representations of the values in the docstring to at least avoid duplication of the default values.  Is this a heinous breach of the ad hoc community conventions?  Is it okay?  Is there a better way?  For example, it's possible to create a dictionary containing values and docstrings for the attributes and then add the contents to the class __dict__ and docstring towards the end of the class declaration; this would alleviate the need to type the attribute names and values twice.  edit: this last idea is, I think, not actually possible, at least not without dynamically building the entire class from data, which seems like a really bad idea unless there's some other reason to do that.  I'm pretty new to python and still working out the details of coding style, so unrelated critiques are also welcome.     ","Q_Votes":"82"},{"Q_Title":"How to document class attributes in Python? [closed]","A_Content":"  You could abuse properties to this effect.  Properties contain a getter, a setter, a deleter, and a docstring.  Naively, this would get very verbose:  class C:     def __init__(self):         self._x = None      @property     def x(self):         \"\"\"Docstring goes here.\"\"\"         return self._x      @x.setter     def x(self, value):         self._x = value      @x.deleter     def x(self):         del self._x   Then you will have a docstring belonging to C.x:  In [24]: print(C.x.__doc__) Docstring goes here.   To do this for many attributes is cumbersome, but you could envision a helper function myprop:  def myprop(x, doc):     def getx(self):         return getattr(self, '_' + x)      def setx(self, val):         setattr(self, '_' + x, val)      def delx(self):         delattr(self, '_' + x)      return property(getx, setx, delx, doc)  class C:     a = myprop(\"a\", \"Hi, I'm A!\")     b = myprop(\"b\", \"Hi, I'm B!\")  In [44]: c = C()  In [46]: c.b = 42  In [47]: c.b Out[47]: 42  In [49]: print(C.b.__doc__) Hi, I'm B!   Then, calling Pythons interactive help will give:  Help on class C in module __main__:  class C  |  Data descriptors defined here:  |    |  a  |      Hi, I'm A!  |    |  b  |      Hi, I'm B!  which I think should be pretty much what you're after.   Edit: I realise now that we can perhaps avoid to need to pass the first argument to myprop at all, because the internal name doesn't matter.  If subsequent calls of myprop can somehow communicate with each other, it could automatically decide upon a long and unlikely internal attribute name.  I'm sure there are ways to implement this, but I'm not sure if they're worth it.     ","Language":"Python","Tags":["python","class","documentation","docstring","class-attributes"],"URL":"https://stackoverflow.com/questions/3051241/how-to-document-class-attributes-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a lightweight class whose attributes are intended to be publicly accessible, and only sometimes overridden in specific instantiations.  There's no provision in the Python language for creating docstrings for class attributes, or any sort of attributes, for that matter.  What is the accepted way, should there be one, to document these attributes?  Currently I'm doing this sort of thing:  class Albatross(object):     \"\"\"A bird with a flight speed exceeding that of an unladen swallow.      Attributes:     \"\"\"      flight_speed = 691     __doc__ += \"\"\"         flight_speed (691)           The maximum speed that such a bird can attain.     \"\"\"      nesting_grounds = \"Raymond Luxury-Yacht\"     __doc__ += \"\"\"         nesting_grounds (\"Raymond Luxury-Yacht\")           The locale where these birds congregate to reproduce.     \"\"\"      def __init__(self, **keyargs):         \"\"\"Initialize the Albatross from the keyword arguments.\"\"\"         self.__dict__.update(keyargs)   This will result in the class's docstring containing the initial standard docstring section, as well as the lines added for each attribute via augmented assignment to __doc__.  Although this style doesn't seem to be expressly forbidden in the docstring style guidelines, it's also not mentioned as an option.  The advantage here is that it provides a way to document attributes alongside their definitions, while still creating a presentable class docstring, and avoiding having to write comments that reiterate the information from the docstring.  I'm still kind of annoyed that I have to actually write the attributes twice; I'm considering using the string representations of the values in the docstring to at least avoid duplication of the default values.  Is this a heinous breach of the ad hoc community conventions?  Is it okay?  Is there a better way?  For example, it's possible to create a dictionary containing values and docstrings for the attributes and then add the contents to the class __dict__ and docstring towards the end of the class declaration; this would alleviate the need to type the attribute names and values twice.  edit: this last idea is, I think, not actually possible, at least not without dynamically building the entire class from data, which seems like a really bad idea unless there's some other reason to do that.  I'm pretty new to python and still working out the details of coding style, so unrelated critiques are also welcome.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  If you are using Python 2.6 or later you could use a class decorator, perhaps something like this (warning: untested code).  def class_decorator(cls):    for name, method in cls.__dict__.iteritems():         if hasattr(method, \"use_class\"):             # do something with the method and class             print name, cls    return cls  def method_decorator(view):     # mark the method as something that requires view's class     view.use_class = True     return view  @class_decorator class ModelA(object):     @method_decorator     def a_method(self):         # do some stuff         pass   The method decorator marks the method as one that is of interest by adding a \"use_class\" attribute - functions and methods are also objects, so you can attach additional metadata to them.  After the class has been created the class decorator then goes through all the methods and does whatever is needed on the methods that have been marked.  If you want all the methods to be affected then you could leave out the method decorator and just use the class decorator.     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"55","_type":"dict","isAccepted":"Yes","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  As others have pointed out, the class hasn't been created at the time the decorator is called. However, it's possible to annotate the function object with the decorator parameters, then re-decorate the function in the metaclass's __new__ method. You'll need to access the function's __dict__ attribute directly, as at least for me, func.foo = 1 resulted in an AttributeError.     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  As Ants indicated, you can't get a reference to the class from within the class.  However, if you're interested in distinguishing between different classes ( not manipulating the actual class type object), you can pass a string for each class. You can also pass whatever other parameters you like to the decorator using class-style decorators.  class Decorator(object):     def __init__(self,decoratee_enclosing_class):         self.decoratee_enclosing_class = decoratee_enclosing_class     def __call__(self,original_func):         def new_function(*args,**kwargs):             print 'decorating function in ',self.decoratee_enclosing_class             original_func(*args,**kwargs)         return new_function   class Bar(object):     @Decorator('Bar')     def foo(self):         print 'in foo'  class Baz(object):     @Decorator('Baz')     def foo(self):         print 'in foo'  print 'before instantiating Bar()' b = Bar() print 'calling b.foo()' b.foo()   Prints:  before instantiating Bar() calling b.foo() decorating function in  Bar in foo   Also, see Bruce Eckel's page on decorators.     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  The problem is that when the decorator is called the class doesn't exist yet. Try this:  def loud_decorator(func):     print(\"Now decorating %s\" % func)     def decorated(*args, **kwargs):         print(\"Now calling %s with %s,%s\" % (func, args, kwargs))         return func(*args, **kwargs)     return decorated  class Foo(object):     class __metaclass__(type):         def __new__(cls, name, bases, dict_):             print(\"Creating class %s%s with attributes %s\" % (name, bases, dict_))             return type.__new__(cls, name, bases, dict_)      @loud_decorator     def hello(self, msg):         print(\"Hello %s\" % msg)  Foo().hello()   This program will output:  Now decorating <function hello at 0xb74d35dc> Creating class Foo(<type 'object'>,) with attributes {'__module__': '__main__', '__metaclass__': <class '__main__.__metaclass__'>, 'hello': <function decorated at 0xb74d356c>} Now calling <function hello at 0xb74d35dc> with (<__main__.Foo object at 0xb74ea1ac>, 'World'),{} Hello World   As you see, you are going to have to figure out a different way to do what you want.     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  Here's a simple example:   def mod_bar(cls):     # returns modified class      def decorate(fcn):         # returns decorated function          def new_fcn(self):             print self.start_str             print fcn(self)             print self.end_str          return new_fcn      cls.bar = decorate(cls.bar)     return cls  @mod_bar class Test(object):     def __init__(self):         self.start_str = \"starting dec\"         self.end_str = \"ending dec\"       def bar(self):         return \"bar\"   The output is:   >>> import Test >>> a = Test() >>> a.bar() starting dec bar ending dec      ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  What flask-classy does is create a temporary cache that it stores on the method, then it uses something else (the fact that Flask will register the classes using a register class method) to actually wraps the method.  You can reuse this pattern, this time using a metaclass so that you can wrap the method at import time.  def route(rule, **options):     \"\"\"A decorator that is used to define custom routes for methods in     FlaskView subclasses. The format is exactly the same as Flask's     `@app.route` decorator.     \"\"\"      def decorator(f):         # Put the rule cache on the method itself instead of globally         if not hasattr(f, '_rule_cache') or f._rule_cache is None:             f._rule_cache = {f.__name__: [(rule, options)]}         elif not f.__name__ in f._rule_cache:             f._rule_cache[f.__name__] = [(rule, options)]         else:             f._rule_cache[f.__name__].append((rule, options))          return f      return decorator   On the actual class (you could do the same using a metaclass):  @classmethod def register(cls, app, route_base=None, subdomain=None, route_prefix=None,              trailing_slash=None):      for name, value in members:         proxy = cls.make_proxy_method(name)         route_name = cls.build_route_name(name)         try:             if hasattr(value, \"_rule_cache\") and name in value._rule_cache:                 for idx, cached_rule in enumerate(value._rule_cache[name]):                     # wrap the method here   Source: https://github.com/apiguy/flask-classy/blob/master/flask_classy.py     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  This is an old question but came across venusian.  http://venusian.readthedocs.org/en/latest/  It seems to have the ability to decorate methods and give you access to both the class and the method while doing so. Note tht calling setattr(ob, wrapped.__name__, decorated) is not the typical way of using venusian and somewhat defeats the purpose.  Either way... the example below is complete and should run.  import sys from functools import wraps import venusian  def logged(wrapped):     def callback(scanner, name, ob):         @wraps(wrapped)         def decorated(self, *args, **kwargs):             print 'you called method', wrapped.__name__, 'on class', ob.__name__             return wrapped(self, *args, **kwargs)         print 'decorating', '%s.%s' % (ob.__name__, wrapped.__name__)         setattr(ob, wrapped.__name__, decorated)     venusian.attach(wrapped, callback)     return wrapped  class Foo(object):     @logged     def bar(self):         print 'bar'  scanner = venusian.Scanner() scanner.scan(sys.modules[__name__])  if __name__ == '__main__':     t = Foo()     t.bar()      ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  Function doesn't know whether it's a method at definition point, when the decorator code runs. Only when it's accessed via class/instance identifier it may know its class/instance. To overcome this limitation, you may decorate by descriptor object to delay actual decorating code until access/call time:  class decorated(object):     def __init__(self, func, type_=None):         self.func = func         self.type = type_      def __get__(self, obj, type_=None):         func = self.func.__get__(obj, type_)         print('accessed %s.%s' % (type_.__name__, func.__name__))         return self.__class__(func, type_)      def __call__(self, *args, **kwargs):         name = '%s.%s' % (self.type.__name__, self.func.__name__)         print('called %s with args=%s kwargs=%s' % (name, args, kwargs))         return self.func(*args, **kwargs)   This allows you to decorate individual (static|class) methods:  class Foo(object):     @decorated     def foo(self, a, b):         pass      @decorated     @staticmethod     def bar(a, b):         pass      @decorated     @classmethod     def baz(cls, a, b):         pass  class Bar(Foo):     pass   Now you can use decorator code for introspection...  >>> Foo.foo accessed Foo.foo >>> Foo.bar accessed Foo.bar >>> Foo.baz accessed Foo.baz >>> Bar.foo accessed Bar.foo >>> Bar.bar accessed Bar.bar >>> Bar.baz accessed Bar.baz   ...and for changing function behavior:  >>> Foo().foo(1, 2) accessed Foo.foo called Foo.foo with args=(1, 2) kwargs={} >>> Foo.bar(1, b='bcd') accessed Foo.bar called Foo.bar with args=(1,) kwargs={'b': 'bcd'} >>> Bar.baz(a='abc', b='bcd') accessed Bar.baz called Bar.baz with args=() kwargs={'a': 'abc', 'b': 'bcd'}      ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  You will have access to the class of the object on which the method is being called in the decorated method that your decorator should return.  Like so:  def decorator(method):     # do something that requires view's class     def decorated(self, *args, **kwargs):         print 'My class is %s' % self.__class__         method(self, *args, **kwargs)     return decorated   Using your ModelA class, here is what this does:  >>> obj = ModelA() >>> obj.a_method() My class is <class '__main__.ModelA'>      ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Can a Python decorator of an instance method access the class?","A_Content":"  As Mark suggests:   Any decorator is called BEFORE class is built, so is unknown to the decorator. We can tag these methods and make any necessary post-process later. We have two options for post-processing: automatically at the end of the class definition or somewhere before the application will run. I prefer the 1st option using a base class, but you can follow the 2nd approach as well.   This code shows how this may works using automatic post-processing:  def expose(**kw):     \"Note that using **kw you can tag the function with any parameters\"     def wrap(func):         name = func.func_name         assert not name.startswith('_'), \"Only public methods can be exposed\"          meta = func.__meta__ = kw         meta['exposed'] = True         return func      return wrap  class Exposable(object):     \"Base class to expose instance methods\"     _exposable_ = None  # Not necessary, just for pylint      class __metaclass__(type):         def __new__(cls, name, bases, state):             methods = state['_exposed_'] = dict()              # inherit bases exposed methods             for base in bases:                 methods.update(getattr(base, '_exposed_', {}))              for name, member in state.items():                 meta = getattr(member, '__meta__', None)                 if meta is not None:                     print \"Found\", name, meta                     methods[name] = member             return type.__new__(cls, name, bases, state)  class Foo(Exposable):     @expose(any='parameter will go', inside='__meta__ func attribute')     def foo(self):         pass  class Bar(Exposable):     @expose(hide=True, help='the great bar function')     def bar(self):         pass  class Buzz(Bar):     @expose(hello=False, msg='overriding bar function')     def bar(self):         pass  class Fizz(Foo):     @expose(msg='adding a bar function')     def bar(self):         pass  print('-' * 20) print(\"showing exposed methods\") print(\"Foo: %s\" % Foo._exposed_) print(\"Bar: %s\" % Bar._exposed_) print(\"Buzz: %s\" % Buzz._exposed_) print(\"Fizz: %s\" % Fizz._exposed_)  print('-' * 20) print('examine bar functions') print(\"Bar.bar: %s\" % Bar.bar.__meta__) print(\"Buzz.bar: %s\" % Buzz.bar.__meta__) print(\"Fizz.bar: %s\" % Fizz.bar.__meta__)   The output yields:  Found foo {'inside': '__meta__ func attribute', 'any': 'parameter will go', 'exposed': True} Found bar {'hide': True, 'help': 'the great bar function', 'exposed': True} Found bar {'msg': 'overriding bar function', 'hello': False, 'exposed': True} Found bar {'msg': 'adding a bar function', 'exposed': True} -------------------- showing exposed methods Foo: {'foo': <function foo at 0x7f7da3abb398>} Bar: {'bar': <function bar at 0x7f7da3abb140>} Buzz: {'bar': <function bar at 0x7f7da3abb0c8>} Fizz: {'foo': <function foo at 0x7f7da3abb398>, 'bar': <function bar at 0x7f7da3abb488>} -------------------- examine bar functions Bar.bar: {'hide': True, 'help': 'the great bar function', 'exposed': True} Buzz.bar: {'msg': 'overriding bar function', 'hello': False, 'exposed': True} Fizz.bar: {'msg': 'adding a bar function', 'exposed': True}   Note that in this example:   We can annotate any function with any arbitrary parameters. Each class has its own exposed methods. We can inherit exposed methods as well. methods can be overriding as exposing feature is updated.   Hope this helps     ","Language":"Python","Tags":["python","decorator"],"URL":"https://stackoverflow.com/questions/2366713/can-a-python-decorator-of-an-instance-method-access-the-class","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Hi I have something roughly like the following.  Basically I need to access the class of an instance method from a decorator used upon the instance method in its definition.  def decorator(view):     # do something that requires view's class     print view.im_class     return view  class ModelA(object):     @decorator     def a_method(self):         # do some stuff         pass   The code as-is gives   AttributeError: 'function' object has no attribute 'im_class'   I found similar question/answers - Python decorator makes function forget that it belongs to a class and Get class in Python decorator - but these rely upon a workaround that grabs the instance at run-time by snatching the first parameter.  In my case I will be calling the method based upon the information gleaned from its class, so I can't wait for a call to come in.  Thank you.     ","Q_Votes":"82"},{"Q_Title":"Concurrent.futures vs Multiprocessing in Python 3","A_Content":"  I wouldn't call concurrent.futures more \"advanced\" - it's a simpler interface that works very much the same regardless of whether you use multiple threads or multiple processes as the underlying parallelization gimmick.  So, like virtually all instances of \"simpler interface\", much the same tradeoffs are involved:  it has a shallower learning curve, in large part just because there's so much less available to be learned; but, because it offers fewer options, it may eventually frustrate you in ways the richer interfaces won't.  So far as CPU-bound tasks go, that's waaaay too under-specified to say much meaningful.  For CPU-bound tasks under CPython, you need multiple processes rather than multiple threads to have any chance of getting a speedup.  But how much (if any) of a speedup you get depends on the details of your hardware, your OS, and especially on how much inter-process communication your specific tasks require.  Under the covers, all inter-process parallelization gimmicks rely on the same OS primitives - the high-level API you use to get at those isn't a primary factor in bottom-line speed.  Edit: example  Here's the final code shown in the article you referenced, but I'm adding an import statement needed to make it work:  from concurrent.futures import ProcessPoolExecutor def pool_factorizer_map(nums, nprocs):     # Let the executor divide the work among processes by using 'map'.     with ProcessPoolExecutor(max_workers=nprocs) as executor:         return {num:factors for num, factors in                                 zip(nums,                                     executor.map(factorize_naive, nums))}   Here's exactly the same thing using multiprocessing instead:  import multiprocessing as mp def mp_factorizer_map(nums, nprocs):     with mp.Pool(nprocs) as pool:         return {num:factors for num, factors in                                 zip(nums,                                     pool.map(factorize_naive, nums))}   Note that the ability to use multiprocessing.Pool objects as context managers was added in Python 3.3.  Which one is easier to work with?  LOL ;-)  They're essentially identical.  One difference is that Pool supports so many different ways of doing things that you may not realize how easy it can be until you've climbed quite a way up the learning curve.  Again, all those different ways are both a strength and a weakness.  They're a strength because the flexibility may be required in some situations.  They're a weakness because of \"preferably only one obvious way to do it\".  A project sticking exclusively (if possible) to concurrent.futures will probably be easier to maintain over the long run, due to the lack of gratuitous novelty in how its minimalistic API can be used.     ","Language":"Python","Tags":["python","python-3.x","multiprocessing"],"URL":"https://stackoverflow.com/questions/20776189/concurrent-futures-vs-multiprocessing-in-python-3","A_Votes":"84","_type":"dict","isAccepted":"No","Q_Content":"    Python 3.2 introduced Concurrent Futures, which appear to be some advanced combination of the older threading and multiprocessing modules.  What are the advantages and disadvantages of using this for CPU bound tasks over the older multiprocessing module?  This article suggests they're much easier to work with - is that the case?     ","Q_Votes":"82"},{"Q_Title":"When to use pip requirements file versus install_requires in setup.py?","A_Content":"  My philosophy is that install_requires should indicate a minimum of what you need.  It might include version requirements if you know that some versions will not work; but it shouldn't have version requirements where you aren't sure (e.g., you aren't sure if a future release of a dependency will break your library or not).  Requirements files on the other hand should indicate what you know does work, and may include optional dependencies that you recommend.  For example you might use SQLAlchemy but suggest MySQL, and so put MySQLdb in the requirements file).  So, in summary: install_requires is to keep people away from things that you know don't work, while requirements files to lead people towards things you know do work.  One reason for this is that install_requires requirements are always checked, and cannot be disabled without actually changing the package metadata.  So you can't easily try a new combination.  Requirements files are only checked at install time.     ","Language":"Python","Tags":["python","setuptools","pip","distribute","setup.py"],"URL":"https://stackoverflow.com/questions/6947988/when-to-use-pip-requirements-file-versus-install-requires-in-setup-py","A_Votes":"62","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm using pip with virtualenv to package and install some Python libraries.    I'd imagine what I'm doing is a pretty common scenario.  I'm the maintainer on several libraries for which I can specify the dependencies explicitly.  A few of my libraries are dependent on third party libraries that have transitive dependencies over which I have no control.  What I'm trying to achieve is for a pip install on one of my libraries to download/install all of its upstream dependencies.  What I'm struggling with in the pip documentation is if/how requirements files can do this on their own or if they're really just a supplement to using install_requires.  Would I use install_requires in all of my libraries to specify dependencies and version ranges and then only use a requirements file to resolve a conflict and/or freeze them for a production build?  Let's pretend I live in an imaginary world (I know, I know) and my upstream dependencies are straightforward and guaranteed to never conflict or break backward compatibility. Would I be compelled to use a pip requirements file at all or just let pip/setuptools/distribute install everything based on install_requires?  There are a lot of similar questions on here, but I couldn't find any that were as basic as when to use one or the other or using them both together harmoniously.     ","Q_Votes":"82"},{"Q_Title":"When to use pip requirements file versus install_requires in setup.py?","A_Content":"  here's what I put in my setup.py:  # this grabs the requirements from requirements.txt REQUIREMENTS = [i.strip() for i in open(\"requirements.txt\").readlines()]  setup(     .....     install_requires=REQUIREMENTS )      ","Language":"Python","Tags":["python","setuptools","pip","distribute","setup.py"],"URL":"https://stackoverflow.com/questions/6947988/when-to-use-pip-requirements-file-versus-install-requires-in-setup-py","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I'm using pip with virtualenv to package and install some Python libraries.    I'd imagine what I'm doing is a pretty common scenario.  I'm the maintainer on several libraries for which I can specify the dependencies explicitly.  A few of my libraries are dependent on third party libraries that have transitive dependencies over which I have no control.  What I'm trying to achieve is for a pip install on one of my libraries to download/install all of its upstream dependencies.  What I'm struggling with in the pip documentation is if/how requirements files can do this on their own or if they're really just a supplement to using install_requires.  Would I use install_requires in all of my libraries to specify dependencies and version ranges and then only use a requirements file to resolve a conflict and/or freeze them for a production build?  Let's pretend I live in an imaginary world (I know, I know) and my upstream dependencies are straightforward and guaranteed to never conflict or break backward compatibility. Would I be compelled to use a pip requirements file at all or just let pip/setuptools/distribute install everything based on install_requires?  There are a lot of similar questions on here, but I couldn't find any that were as basic as when to use one or the other or using them both together harmoniously.     ","Q_Votes":"82"},{"Q_Title":"When to use pip requirements file versus install_requires in setup.py?","A_Content":"  The Python Packaging User Guide has a page about this topic, I highly recommend you read it:   install_requires vs Requirements files   Summary:  install_requires is there to list the dependencies of the package that absolutely must be installed for the package to work. It is not meant to pin the dependencies to specific versions, but ranges are accepted, for example install_requires=['django>=1.8']. install_requires is observed by pip install name-on-pypi and other tools.  requirements.txt is just a text file, that you can choose to run pip install -r requirements.txt against. It's meant to have versions of all dependencies and subdependencies pinned, like this: django==1.8.1. You can create one using pip freeze > requirements.txt. (Some services, like Heroku, automatically run pip install -r requirements.txt for you.) pip install name-on-pypi does not look at requirements.txt, only at install_requires.     ","Language":"Python","Tags":["python","setuptools","pip","distribute","setup.py"],"URL":"https://stackoverflow.com/questions/6947988/when-to-use-pip-requirements-file-versus-install-requires-in-setup-py","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm using pip with virtualenv to package and install some Python libraries.    I'd imagine what I'm doing is a pretty common scenario.  I'm the maintainer on several libraries for which I can specify the dependencies explicitly.  A few of my libraries are dependent on third party libraries that have transitive dependencies over which I have no control.  What I'm trying to achieve is for a pip install on one of my libraries to download/install all of its upstream dependencies.  What I'm struggling with in the pip documentation is if/how requirements files can do this on their own or if they're really just a supplement to using install_requires.  Would I use install_requires in all of my libraries to specify dependencies and version ranges and then only use a requirements file to resolve a conflict and/or freeze them for a production build?  Let's pretend I live in an imaginary world (I know, I know) and my upstream dependencies are straightforward and guaranteed to never conflict or break backward compatibility. Would I be compelled to use a pip requirements file at all or just let pip/setuptools/distribute install everything based on install_requires?  There are a lot of similar questions on here, but I couldn't find any that were as basic as when to use one or the other or using them both together harmoniously.     ","Q_Votes":"82"},{"Q_Title":"When to use pip requirements file versus install_requires in setup.py?","A_Content":"  I only ever use a setup.py and install_requires because there is only one place to look at. It is just as powerful as having a requirements file and there is no duplication to maintain.     ","Language":"Python","Tags":["python","setuptools","pip","distribute","setup.py"],"URL":"https://stackoverflow.com/questions/6947988/when-to-use-pip-requirements-file-versus-install-requires-in-setup-py","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm using pip with virtualenv to package and install some Python libraries.    I'd imagine what I'm doing is a pretty common scenario.  I'm the maintainer on several libraries for which I can specify the dependencies explicitly.  A few of my libraries are dependent on third party libraries that have transitive dependencies over which I have no control.  What I'm trying to achieve is for a pip install on one of my libraries to download/install all of its upstream dependencies.  What I'm struggling with in the pip documentation is if/how requirements files can do this on their own or if they're really just a supplement to using install_requires.  Would I use install_requires in all of my libraries to specify dependencies and version ranges and then only use a requirements file to resolve a conflict and/or freeze them for a production build?  Let's pretend I live in an imaginary world (I know, I know) and my upstream dependencies are straightforward and guaranteed to never conflict or break backward compatibility. Would I be compelled to use a pip requirements file at all or just let pip/setuptools/distribute install everything based on install_requires?  There are a lot of similar questions on here, but I couldn't find any that were as basic as when to use one or the other or using them both together harmoniously.     ","Q_Votes":"82"},{"Q_Title":"'str' object has no attribute 'decode'. Python 3 error?","A_Content":"  You are trying to decode an object that is already decoded. You have a str, there is no need to decode from UTF-8 anymore.  Simply drop the .decode('utf-8') part:  header_data = data[1][0][1]   As for your fetch() call, you are explicitly asking for just the first message. Use a range if you want to retrieve more messages. See the documentation:     The message_set options to commands below is a string specifying one or more messages to be acted upon. It may be a simple message number ('1'), a range of message numbers ('2:4'), or a group of non-contiguous ranges separated by commas ('1:3,6:9'). A range can contain an asterisk to indicate an infinite upper bound ('3:*').      ","Language":"Python","Tags":["python","python-3.x","imaplib"],"URL":"https://stackoverflow.com/questions/28583565/str-object-has-no-attribute-decode-python-3-error","A_Votes":"81","_type":"dict","isAccepted":"Yes","Q_Content":"    Here is my code:  import imaplib from email.parser import HeaderParser  conn = imaplib.IMAP4_SSL('imap.gmail.com') conn.login('example@gmail.com', 'password') conn.select() conn.search(None, 'ALL') data = conn.fetch('1', '(BODY[HEADER])') header_data = data[1][0][1].decode('utf-8')   at this point I get the error message   AttributeError: 'str' object has no attribute 'decode'   Python 3 doesn't have decode anymore, am I right? how can I fix this?   Also, in:  data = conn.fetch('1', '(BODY[HEADER])')   I am selecting only the 1st email. How do I select all?     ","Q_Votes":"82"},{"Q_Title":"'str' object has no attribute 'decode'. Python 3 error?","A_Content":"  Begin with Python 3, all string is unicode object.    a = 'Happy New Year' # Python 3   b = unicode('Happy New Year') # Python 2   the code before are same. So I think you should remove the .decode('utf-8'). Because you have already get the unicode object.     ","Language":"Python","Tags":["python","python-3.x","imaplib"],"URL":"https://stackoverflow.com/questions/28583565/str-object-has-no-attribute-decode-python-3-error","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Here is my code:  import imaplib from email.parser import HeaderParser  conn = imaplib.IMAP4_SSL('imap.gmail.com') conn.login('example@gmail.com', 'password') conn.select() conn.search(None, 'ALL') data = conn.fetch('1', '(BODY[HEADER])') header_data = data[1][0][1].decode('utf-8')   at this point I get the error message   AttributeError: 'str' object has no attribute 'decode'   Python 3 doesn't have decode anymore, am I right? how can I fix this?   Also, in:  data = conn.fetch('1', '(BODY[HEADER])')   I am selecting only the 1st email. How do I select all?     ","Q_Votes":"82"},{"Q_Title":"'str' object has no attribute 'decode'. Python 3 error?","A_Content":"  Use it by this Method:  str.encode().decode()      ","Language":"Python","Tags":["python","python-3.x","imaplib"],"URL":"https://stackoverflow.com/questions/28583565/str-object-has-no-attribute-decode-python-3-error","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Here is my code:  import imaplib from email.parser import HeaderParser  conn = imaplib.IMAP4_SSL('imap.gmail.com') conn.login('example@gmail.com', 'password') conn.select() conn.search(None, 'ALL') data = conn.fetch('1', '(BODY[HEADER])') header_data = data[1][0][1].decode('utf-8')   at this point I get the error message   AttributeError: 'str' object has no attribute 'decode'   Python 3 doesn't have decode anymore, am I right? how can I fix this?   Also, in:  data = conn.fetch('1', '(BODY[HEADER])')   I am selecting only the 1st email. How do I select all?     ","Q_Votes":"82"},{"Q_Title":"'str' object has no attribute 'decode'. Python 3 error?","A_Content":"  I'm not familiar with the library, but if your problem is that you don't want a byte array, one easy way is to specify an encoding type straight in a cast:  >>> my_byte_str b'Hello World'  >>> str(my_byte_str, 'utf-8') 'Hello World'      ","Language":"Python","Tags":["python","python-3.x","imaplib"],"URL":"https://stackoverflow.com/questions/28583565/str-object-has-no-attribute-decode-python-3-error","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Here is my code:  import imaplib from email.parser import HeaderParser  conn = imaplib.IMAP4_SSL('imap.gmail.com') conn.login('example@gmail.com', 'password') conn.select() conn.search(None, 'ALL') data = conn.fetch('1', '(BODY[HEADER])') header_data = data[1][0][1].decode('utf-8')   at this point I get the error message   AttributeError: 'str' object has no attribute 'decode'   Python 3 doesn't have decode anymore, am I right? how can I fix this?   Also, in:  data = conn.fetch('1', '(BODY[HEADER])')   I am selecting only the 1st email. How do I select all?     ","Q_Votes":"82"},{"Q_Title":"'str' object has no attribute 'decode'. Python 3 error?","A_Content":"  It s already decoded in Python3, Try directly it should work.     ","Language":"Python","Tags":["python","python-3.x","imaplib"],"URL":"https://stackoverflow.com/questions/28583565/str-object-has-no-attribute-decode-python-3-error","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Here is my code:  import imaplib from email.parser import HeaderParser  conn = imaplib.IMAP4_SSL('imap.gmail.com') conn.login('example@gmail.com', 'password') conn.select() conn.search(None, 'ALL') data = conn.fetch('1', '(BODY[HEADER])') header_data = data[1][0][1].decode('utf-8')   at this point I get the error message   AttributeError: 'str' object has no attribute 'decode'   Python 3 doesn't have decode anymore, am I right? how can I fix this?   Also, in:  data = conn.fetch('1', '(BODY[HEADER])')   I am selecting only the 1st email. How do I select all?     ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  In the long run I think you'll appreciate having most of your imports at the top of the file, that way you can tell at a glance how complicated your module is by what it needs to import.  If I'm adding new code to an existing file I'll usually do the import where it's needed and then if the code stays I'll make things more permanent by moving the import line to the top of the file.  One other point, I prefer to get an ImportError exception before any code is run -- as a sanity check, so that's another reason to import at the top.   I use pyChecker to check for unused modules.     ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"53","_type":"dict","isAccepted":"Yes","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  There are two occasions where I violate PEP 8 in this regard:   Circular imports: module A imports module B, but something in module B needs module A (though this is often a sign that I need to refactor the modules to eliminate the circular dependency) Inserting a pdb breakpoint: import pdb; pdb.set_trace() This is handy b/c I don't want to put import pdb at the top of every module I might want to debug, and it easy to remember to remove the import when I remove the breakpoint.   Outside of these two cases, it's a good idea to put everything at the top.  It makes the dependencies clearer.     ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  Here are the four import use cases that we use   import (and from x import y and import x as y) at the top Choices for Import.  At the top.  import settings if setting.something:     import this as foo else:     import that as foo  Conditional Import.  Used with JSON, XML libraries and the like.  At the top.  try:     import this as foo except ImportError:     import that as foo  Dynamic Import.  So far, we only have one example of this.  import settings module_stuff = {} module= __import__( settings.some_module, module_stuff ) x = module_stuff['x']   Note that this dynamic import doesn't bring in code, but brings in complex data structures written in Python.  It's kind of like a pickled piece of data except we pickled it by hand.  This is also, more-or-less, at the top of a module     Here's what we do to make the code clearer:   Keep the modules short. If I have all my imports at the top of the module, I have to go look there to determine what a name is.  If the module is short, that's easy to do. In some cases having that extra information close to where a name is used can make the function easier to understand.  If the module is short, that's easy to do.      ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  One thing to bear in mind:  needless imports can cause performance problems.  So if this is a function that will be called frequently, you're better off just putting the import at the top.  Of course this is an optimization, so if there's a valid case to be made that importing inside a function is more clear than importing at the top of a file, that trumps performance in most cases.  If you're doing IronPython, I'm told that it's better to import inside functions (since compiling code in IronPython can be slow).  Thus, you may be able to get a way with importing inside functions then.  But other than that, I'd argue that it's just not worth it to fight convention.     As a general rule, I do this if there is an import that is only used within a single function.   Another point I'd like to make is that this may be a potential maintenence problem.  What happens if you add a function that uses a module that was previously used by only one function?  Are you going to remember to add the import to the top of the file?  Or are you going to scan each and every function for imports?  FWIW, there are cases where it makes sense to import inside a function.  For example, if you want to set the language in cx_Oracle, you need to set an NLS_LANG environment variable before it is imported.  Thus, you may see code like this:  import os  oracle = None  def InitializeOracle(lang):     global oracle     os.environ['NLS_LANG'] = lang     import cx_Oracle     oracle = cx_Oracle      ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  I've broken this rule before for modules that are self-testing.  That is, they are normally just used for support,  but I define a main for them so that if you run them by themselves you can test their functionality.  In that case I sometimes import getopt and cmd just in main, because I want it to be clear to someone reading the code that these modules have nothing to do with the normal operation of the module and are only being included for testing.     ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  As long as it's import and not from x import *, you should put them at the top. It adds just one name to the global namespace, and you stick to PEP 8. Plus, if you later need it somewhere else, you don't have to move anything around.  It's no big deal, but since there's almost no difference I'd suggest doing what PEP 8 says.     ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"Is it pythonic to import inside functions?","A_Content":"  Coming from the question about loading the module twice - Why not both?  An import at the top of the script will indicate the dependencies and another import in the function with make this function more atomic, while seemingly not causing any performance disadvantage, since a consecutive import is cheap.       ","Language":"Python","Tags":["python","conventions"],"URL":"https://stackoverflow.com/questions/1024049/is-it-pythonic-to-import-inside-functions","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    PEP 8 says:        Imports are always put at the top of the file, just after any module   comments and docstrings, and before module globals and constants.      On occation, I violate PEP 8. Some times I import stuff inside functions. As a general rule, I do this if there is an import that is only used within a single function.  Any opinions?  EDIT (the reason I feel importing in functions can be a good idea):  Main reason: It can make the code clearer.   When looking at the code of a function I might ask myself: \"What is function/class xxx?\" (xxx being used inside the function). If I have all my imports at the top of the module, I have to go look there to determine what xxx is. This is more of an issue when using from m import xxx. Seeing m.xxx in the function probably tells me more. Depending on what m is: Is it a well-known top-level module/package (import m)? Or is it a sub-module/package (from a.b.c import m)? In some cases having that extra information (\"What is xxx?\") close to where xxx is used can make the function easier to understand.      ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Given your factorGenerator function, here is a divisorGen that should work:  def divisorGen(n):     factors = list(factorGenerator(n))     nfactors = len(factors)     f = [0] * nfactors     while True:         yield reduce(lambda x, y: x*y, [factors[x][0]**f[x] for x in range(nfactors)], 1)         i = 0         while True:             f[i] += 1             if f[i] <= factors[i][1]:                 break             f[i] = 0             i += 1             if i >= nfactors:                 return   The overall efficiency of this algorithm will depend entirely on the efficiency of the factorGenerator.     ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"68","_type":"dict","isAccepted":"Yes","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  To expand on what Shimi has said, you should only be running your loop from 1 to the square root of n. Then to find the pair, do n / i, and this will cover the whole problem space.  As was also noted, this is a NP, or 'difficult' problem. Exhaustive search, the way you are doing it, is about as good as it gets for guaranteed answers. This fact is used by encryption algorithms and the like to help secure them. If someone were to solve this problem, most if not all of our current 'secure' communication would be rendered insecure.  Python code:  import math  def divisorGenerator(n):     large_divisors = []     for i in xrange(1, int(math.sqrt(n) + 1)):         if n % i == 0:             yield i             if i*i != n:                 large_divisors.append(n / i)     for divisor in reversed(large_divisors):         yield divisor  print list(divisorGenerator(100))   Which should output a list like:   [1, 2, 4, 5, 10, 20, 25, 50, 100]      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Although there are already many solutions to this, I really have to post this :)  This one is:   readable  short self contained, copy & paste ready quick (in cases with a lot of prime factors and divisors, > 10 times faster than Greg's solution) python3, python2 and pypy compliant   Code:  def divisors(n):     # get factors and their counts     factors = {}     nn = n     i = 2     while i*i <= nn:         while nn % i == 0:             if not i in factors:                 factors[i] = 0             factors[i] += 1             nn //= i         i += 1     if nn > 1:         factors[nn] = 1      primes = list(factors.keys())      # generates factors from primes[k:] subset     def generate(k):         if k == len(primes):             yield 1         else:             rest = generate(k+1)             prime = primes[k]             for factor in rest:                 prime_to_i = 1                 # prime_to_i iterates prime**i values, i being all possible exponents                 for _ in range(factors[prime] + 1):                     yield factor * prime_to_i                     prime_to_i *= prime      # in python3, `yield from generate(0)` would also work     for factor in generate(0):         yield factor      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  I think you can stop at math.sqrt(n) instead of n/2.   I will give you example so that you can understand it easily. Now the sqrt(28) is 5.29 so ceil(5.29) will be 6. So I if I will stop at 6 then I will can get all the divisors. How?  First see the code and then see image:  import math def divisors(n):     divs = [1]     for i in xrange(2,int(math.sqrt(n))+1):         if n%i == 0:             divs.extend([i,n/i])     divs.extend([n])     return list(set(divs))   Now, See the image below:  Lets say I have already added 1 to my divisors list and I start with i=2 so    So at the end of all the iterations as I have added the quotient and the divisor to my list all the divisors of 28 are populated.   Hope this helps. If you have any doubt don't hesitate to ping back and I will be glad to help you :).  Source: How to determine the divisors of a number Radius of circle - Both code and image     ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  I like Greg solution, but I wish it was more python like. I feel it would be faster and more readable;  so after some time of coding I came out with this.  The first two functions are needed to make the cartesian product of lists.  And can be reused whnever this problem arises.  By the way, I had to program this myself, if anyone knows of a standard solution for this problem, please feel free to contact me.  \"Factorgenerator\" now returns a dictionary. And then the dictionary is fed into \"divisors\", who uses it to generate first a list of lists, where each list is the list of the factors of the form p^n with p prime. Then we make the cartesian product of those lists, and we finally use Greg' solution to generate the divisor. We sort them, and return them.  I tested it and it seem to be a bit faster than the previous version. I tested it as part of a bigger program, so I can't really say how much is it faster though.  Pietro Speroni (pietrosperoni dot it)  from math import sqrt   ############################################################## ### cartesian product of lists ################################## ##############################################################  def appendEs2Sequences(sequences,es):     result=[]     if not sequences:         for e in es:             result.append([e])     else:         for e in es:             result+=[seq+[e] for seq in sequences]     return result   def cartesianproduct(lists):     \"\"\"     given a list of lists,     returns all the possible combinations taking one element from each list     The list does not have to be of equal length     \"\"\"     return reduce(appendEs2Sequences,lists,[])  ############################################################## ### prime factors of a natural ################################## ##############################################################  def primefactors(n):     '''lists prime factors, from greatest to smallest'''       i = 2     while i<=sqrt(n):         if n%i==0:             l = primefactors(n/i)             l.append(i)             return l         i+=1     return [n]      # n is prime   ############################################################## ### factorization of a natural ################################## ##############################################################  def factorGenerator(n):     p = primefactors(n)     factors={}     for p1 in p:         try:             factors[p1]+=1         except KeyError:             factors[p1]=1     return factors  def divisors(n):     factors = factorGenerator(n)     divisors=[]     listexponents=[map(lambda x:k**x,range(0,factors[k]+1)) for k in factors.keys()]     listfactors=cartesianproduct(listexponents)     for f in listfactors:         divisors.append(reduce(lambda x, y: x*y, f, 1))     divisors.sort()     return divisors    print divisors(60668796879)   P.S.  it is the first time I am posting to stackoverflow.  I am looking forward for any feedback.     ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Adapted from CodeReview, here is a variant which works with num=1 !  from itertools import product import operator  def prod(ls):    return reduce(operator.mul, ls, 1)  def powered(factors, powers):    return prod(f**p for (f,p) in zip(factors, powers))   def divisors(num) :     pf = dict(prime_factors(num))    primes = pf.keys()    #For each prime, possible exponents    exponents = [range(i+1) for i in pf.values()]    return (powered(primes,es) for es in product(*exponents))      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Old question, but here is my take:  def divs(n, m):     if m == 1: return [1]     if n % m == 0: return [m] + divs(n, m - 1)     return divs(n, m - 1)   You can proxy with:  def divisorGenerator(n):     for x in reversed(divs(n, n)):         yield x   NOTE: For languages that support, this could be tail recursive.     ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Here is a smart and fast way to do it for numbers up to and around 10**16 in pure Python 3.6,  from itertools import compress  def primes(n):     \"\"\" Returns  a list of primes < n for n > 2 \"\"\"     sieve = bytearray([True]) * (n//2)     for i in range(3,int(n**0.5)+1,2):         if sieve[i//2]:             sieve[i*i//2::i] = bytearray((n-i*i-1)//(2*i)+1)     return [2,*compress(range(3,n,2), sieve[1:])]  def factorization(n):     \"\"\" Returns a list of the prime factorization of n \"\"\"     pf = []     for p in primeslist:       if p*p > n : break       count = 0       while not n % p:         n //= p         count += 1       if count > 0: pf.append((p, count))     if n > 1: pf.append((n, 1))     return pf  def divisors(n):     \"\"\" Returns an unsorted list of the divisors of n \"\"\"     divs = [1]     for p, e in factorization(n):         divs += [x*p**k for k in range(1,e+1) for x in divs]     return divs  n = 600851475143 primeslist = primes(int(n**0.5)+1)  print(divisors(n))      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Assuming that the factors function returns the factors of n (for instance, factors(60) returns the list [2, 2, 3, 5]), here is a function to compute the divisors of n:  function divisors(n)     divs := [1]     for fact in factors(n)         temp := []         for div in divs             if fact * div not in divs                 append fact * div to temp         divs := divs + temp     return divs      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  Here's my solution. It seems to be dumb but works well...and I was trying to find all proper divisors so the loop started from i = 2.   import math as m   def findfac(n):     faclist = [1]     for i in range(2, int(m.sqrt(n) + 2)):         if n%i == 0:             if i not in faclist:                 faclist.append(i)                 if n/i not in faclist:                     faclist.append(n/i)     return facts      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  If you only care about using list comprehensions and nothing else matters to you!  from itertools import combinations from functools import reduce  def get_devisors(n):     f = [f for f,e in list(factorGenerator(n)) for i in range(e)]     fc = [x for l in range(len(f)+1) for x in combinations(f, l)]     devisors = [1 if c==() else reduce((lambda x, y: x * y), c) for c in set(fc)]     return sorted(devisors)      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  return [x for x in range(n+1) if n/x==int(n/x)]      ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"What is the best way to get all the divisors of a number?","A_Content":"  For me this works fine and is also clean (Python 3)  def divisors(number):     n = 1     while(n<number):         if(number%n==0):             print(n)         else:             pass         n += 1     print(number)   Not very fast but returns divisors line by line as you wanted, also you can do list.append(n) and list.append(number) if you really want to     ","Language":"Python","Tags":["python","algorithm","math"],"URL":"https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Here's the very dumb way:  def divisorGenerator(n):     for i in xrange(1,n/2+1):         if n%i == 0: yield i     yield n   The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)  I can find prime factors and their multiplicity fast enough.  I've an generator that generates factor in this way:  (factor1, multiplicity1) (factor2, multiplicity2) (factor3, multiplicity3) and so on...  i.e. the output of   for i in factorGenerator(100):     print i   is:  (2, 2) (5, 2)   I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make  for i in divisorGen(100):     print i   output this:  1 2 4 5 10 20 25 50 100     UPDATE: Many thanks to Greg Hewgill and his \"smart way\" :) Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D  UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for \"Divisor function\" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.     ","Q_Votes":"82"},{"Q_Title":"Mocking python function based on input arguments","A_Content":"     If side_effect is a function then whatever that function returns is   what calls to the mock return. The side_effect function is called with   the same arguments as the mock. This allows you to vary the return   value of the call dynamically, based on the input:  >>> def side_effect(value): ...     return value + 1 ... >>> m = MagicMock(side_effect=side_effect) >>> m(1) 2 >>> m(2) 3 >>> m.mock_calls [call(1), call(2)]    http://www.voidspace.org.uk/python/mock/mock.html#calling     ","Language":"Python","Tags":["python","unit-testing","mocking","mockito"],"URL":"https://stackoverflow.com/questions/16162015/mocking-python-function-based-on-input-arguments","A_Votes":"109","_type":"dict","isAccepted":"Yes","Q_Content":"    We have been using Mock for python for a while.   Now, we have a situation in which we want to mock a function  def foo(self, my_param):     #do something here, assign something to my_result     return my_result   Normally, the way to mock this would be (assuming foo being part of an object)  self.foo = MagicMock(return_value=\"mocked!\")   Even, if i call foo() a couple of times i can use  self.foo = MagicMock(side_effect=[\"mocked once\", \"mocked twice!\"])   Now, I am facing a situation in which I want to return a fixed value when the input parameter has a particular value. So if let's say \"my_param\" is equal to \"something\" then I want to return \"my_cool_mock\"  This seems to be available on mockito for python  when(dummy).foo(\"something\").thenReturn(\"my_cool_mock\")   I have been searching on how to achieve the same with Mock with no success?   Any ideas?     ","Q_Votes":"82"},{"Q_Title":"Mocking python function based on input arguments","A_Content":"  As indicated at Python Mock object with method called multiple times  A solution is to write my own side_effect   def my_side_effect(*args, **kwargs):     if args[0] == 42:         return \"Called with 42\"     elif args[0] == 43:         return \"Called with 43\"     elif kwarg['foo'] == 7:         return \"Foo is seven\"  mockobj.mockmethod.side_effect = my_side_effect   That does the trick     ","Language":"Python","Tags":["python","unit-testing","mocking","mockito"],"URL":"https://stackoverflow.com/questions/16162015/mocking-python-function-based-on-input-arguments","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    We have been using Mock for python for a while.   Now, we have a situation in which we want to mock a function  def foo(self, my_param):     #do something here, assign something to my_result     return my_result   Normally, the way to mock this would be (assuming foo being part of an object)  self.foo = MagicMock(return_value=\"mocked!\")   Even, if i call foo() a couple of times i can use  self.foo = MagicMock(side_effect=[\"mocked once\", \"mocked twice!\"])   Now, I am facing a situation in which I want to return a fixed value when the input parameter has a particular value. So if let's say \"my_param\" is equal to \"something\" then I want to return \"my_cool_mock\"  This seems to be available on mockito for python  when(dummy).foo(\"something\").thenReturn(\"my_cool_mock\")   I have been searching on how to achieve the same with Mock with no success?   Any ideas?     ","Q_Votes":"82"},{"Q_Title":"Mocking python function based on input arguments","A_Content":"  Side effect takes a function (which can also be a lambda function), so for simple cases you may use:  m = MagicMock(side_effect=(lambda x: x+1))      ","Language":"Python","Tags":["python","unit-testing","mocking","mockito"],"URL":"https://stackoverflow.com/questions/16162015/mocking-python-function-based-on-input-arguments","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    We have been using Mock for python for a while.   Now, we have a situation in which we want to mock a function  def foo(self, my_param):     #do something here, assign something to my_result     return my_result   Normally, the way to mock this would be (assuming foo being part of an object)  self.foo = MagicMock(return_value=\"mocked!\")   Even, if i call foo() a couple of times i can use  self.foo = MagicMock(side_effect=[\"mocked once\", \"mocked twice!\"])   Now, I am facing a situation in which I want to return a fixed value when the input parameter has a particular value. So if let's say \"my_param\" is equal to \"something\" then I want to return \"my_cool_mock\"  This seems to be available on mockito for python  when(dummy).foo(\"something\").thenReturn(\"my_cool_mock\")   I have been searching on how to achieve the same with Mock with no success?   Any ideas?     ","Q_Votes":"82"},{"Q_Title":"Mocking python function based on input arguments","A_Content":"  Just to show another way of doing it:  def mock_isdir(path):     return path in ['/var/log', '/var/log/apache2', '/var/log/tomcat']  with mock.patch('os.path.isdir') as os_path_isdir:     os_path_isdir.side_effect = mock_isdir      ","Language":"Python","Tags":["python","unit-testing","mocking","mockito"],"URL":"https://stackoverflow.com/questions/16162015/mocking-python-function-based-on-input-arguments","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    We have been using Mock for python for a while.   Now, we have a situation in which we want to mock a function  def foo(self, my_param):     #do something here, assign something to my_result     return my_result   Normally, the way to mock this would be (assuming foo being part of an object)  self.foo = MagicMock(return_value=\"mocked!\")   Even, if i call foo() a couple of times i can use  self.foo = MagicMock(side_effect=[\"mocked once\", \"mocked twice!\"])   Now, I am facing a situation in which I want to return a fixed value when the input parameter has a particular value. So if let's say \"my_param\" is equal to \"something\" then I want to return \"my_cool_mock\"  This seems to be available on mockito for python  when(dummy).foo(\"something\").thenReturn(\"my_cool_mock\")   I have been searching on how to achieve the same with Mock with no success?   Any ideas?     ","Q_Votes":"82"},{"Q_Title":"Mocking python function based on input arguments","A_Content":"  I know its quite an old question, might help as an improvement using python lamdba  self.some_service.foo.side_effect = lambda *args:\"Called with 42\" \\             if args[0] == 42 \\             else \"Called with 42\" if args[0] == 43 \\             else \"Called with 43\" if args[0] == 43 \\             else \"Called with 45\" if args[0] == 45 \\             else \"Called with 49\" if args[0] == 49 else None      ","Language":"Python","Tags":["python","unit-testing","mocking","mockito"],"URL":"https://stackoverflow.com/questions/16162015/mocking-python-function-based-on-input-arguments","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    We have been using Mock for python for a while.   Now, we have a situation in which we want to mock a function  def foo(self, my_param):     #do something here, assign something to my_result     return my_result   Normally, the way to mock this would be (assuming foo being part of an object)  self.foo = MagicMock(return_value=\"mocked!\")   Even, if i call foo() a couple of times i can use  self.foo = MagicMock(side_effect=[\"mocked once\", \"mocked twice!\"])   Now, I am facing a situation in which I want to return a fixed value when the input parameter has a particular value. So if let's say \"my_param\" is equal to \"something\" then I want to return \"my_cool_mock\"  This seems to be available on mockito for python  when(dummy).foo(\"something\").thenReturn(\"my_cool_mock\")   I have been searching on how to achieve the same with Mock with no success?   Any ideas?     ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  (to expand a bit on my comment)  Numpy developers follow in general a policy of keeping a backward compatible binary interface (ABI). However, the ABI is not forward compatible.  What that means:  A package, that uses numpy in a compiled extension, is compiled against a specific version of numpy. Future version of numpy will be compatible with the compiled extension of the package (for exception see below). Distributers of those other packages do not need to recompile their package against a newer  versions of numpy and users do not need to update these other packages, when users update to a newer version of numpy.  However, this does not go in the other direction. If a package is compiled against a specific numpy version, say 1.7, then there is no guarantee that the binaries of that package will work with older numpy versions, say 1.6, and very often or most of the time they will not.  The binary distribution of packages like pandas and statsmodels, that are compiled against a recent version of numpy, will not work when an older version of numpy is installed. Some packages, for example matplotlib, if I remember correctly, compile their extensions against the oldest numpy version that they support. In this case, users with the same old or any more recent version of numpy can use those binaries.  The error message in the question is a typical result of binary incompatibilities.  The solution is to get a binary compatible version, either by updating numpy to at least the version against which pandas or statsmodels were compiled, or to recompile pandas and statsmodels against the older version of numpy that is already installed.  Breaking the ABI backward compatibility:  Sometimes improvements or refactorings in numpy break ABI backward compatibility. This happened (unintentionally) with numpy 1.4.0. As a consequence, users that updated numpy to 1.4.0, had binary incompatibilities with all other compiled packages, that were compiled against a previous version of numpy. This requires that all packages with binary extensions that use numpy have to be recompiled to work with the ABI incompatible version.      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"61","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  For me (Mac OS X Maverics, Python 2.7)  easy_install --upgrade numpy   helped. After this you can install up-to-date packages pandas, scikit-learn, e.t.c. using pip:  pip install pandas      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  I found it to be a simple version being outdated or mismatch and was fixed with:   pip install --upgrade numpy pip install --upgrade scipy pip install --upgrade pandas   Or might work with the one liner:  pip install --upgrade numpy scipy pandas      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  I had a similar error with another library and realized that I had several versions of numpy installed on my system. The fix for me was to edit my PYTHONPATH and put the site-packages that contained the latest version of numpy in first position.     ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  As in here, for me only sudo pip install pandas==0.13.1 worked      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  I also encounter this error when use pandas to access MYSQL. This error message indicates a binary compatible issue and can be resolved by  using latest version of pandas and numpy package.  Here is my steps to resolve this issue, and it works well on my Ubuntu 12.04:  cd /tmp/ wget https://pypi.python.org/packages/source/p/pandas/pandas-0.12.0.tar.gz tar xzvf pandas-0.12.0.tar.gz cd pandas-0.12.0 easy_install --upgrade numpy      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  In my case, I had installed pandas-0.10.0.win-amd64-py2.7 but was checking to see if a bug had been fixed in a more recent version of pandas.  So I did an easy_install -U to force the upgrade, but then got the above error due to some incompatibilities with numpy etc... when I did   import pandas   To fix, I just reinstalled the pandas-0.10.0.win-amd64-py2.7 binary and everything works. I didn't see this answer (suggests to use pip) which may have helped me (though not sure) Install particular version with easy_install  Also this highlights why one should use virtualenv (which I wasn't).     ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  For me (Mac OS X Mavericks) it worked to install the version for python2.6:  sudo port install py26-scikit-learn   then run:  python2.6 myscript.py      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  The problem I solved on Webfaction was old numpy library(1.5) which was in conflict with my fresh      pip install pandas   installation in .virtualenv.   The problem was solved after I did pip install pandas out of the virtual environment. The idea came from discussion on https://github.com/pydata/pandas/issues/3711, thanks, cpcloud!     ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  I just meet this 'ValueError' issue and have addressed it. Definitely there's something wrong with numpy package.   But when I try to pip install --upgrade numpy it failed, so I uninstall and download the newest numpy.zip file. Then manually uncompress and python setup.py install it.  Luckly, it works!     ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  Like @user333700 said, required versions of libraries may not meet for each other. You get one library as another's dependency. Then without knowing it was already installed as dependency, you need that specific library and you install one version. With such ways dependencies may mess up.  I lived such a case and looked for a solution. Found this: https://stackoverflow.com/a/12975518/1694344  I had two different versions for egg-info file and folder name of numpy:  drwxr-xr-x. 19 root root   4096 Sep 25 15:00 numpy drwxr-xr-x.  2 root root   4096 Sep 22 11:25 numpy-1.13.1.dist-info -rw-r--r--.  1 root root   1630 Nov 20  2015 numpy-1.7.1-py2.7.egg-info   I removed them all and reinstalled numpy with pip.     ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"ValueError: numpy.dtype has the wrong size, try recompiling","A_Content":"  There are cases where you want to keep a specific NumPy version and the upgrade option mentioned here will not work.  An example that occurred to me was the Python distribution preinstalled with ArcGIS. For ArcPy to work in ArcGIS 10.5.1, that distribution needs to be Python 2.7.12 with NumPy 1.9.3 and any other version of NumPy is probably going to cause issues with your ArcPy functionality.   What you can do with this case is try to install a specific, older version of the problematic third-party library that is supposed to be compatible with the older NumPy version that ArcGIS has.   For instance, scikit-learn 0.19.1 would NOT operate with NumPy 1.9.3 and would result in the same error you mentioned. However, scikit-learn 0.15 works fine. You can test different versions to find the one that works. Just mention the version number through pip:  python -m pip install scikit-learn==0.15      ","Language":"Python","Tags":["python","numpy","install","pandas","statsmodels"],"URL":"https://stackoverflow.com/questions/17709641/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just installed pandas and statsmodels package on my python 2.7 When I tried  \"import pandas as pd\", this error message comes out. Can anyone help? Thanks!!!  numpy.dtype has the wrong size, try recompiling Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\__init__.py\", line 4, in <module>     from formulatools import handle_formula_data   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\formula\\formulatools.p y\", line 1, in <module>     import statsmodels.tools.data as data_util   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\__init__.py\", li ne 1, in <module>     from tools import add_constant, categorical   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\statsmodels-0.5.0-py2.7-win32.egg\\statsmodels\\tools\\tools.py\", line 14, in <module>     from pandas import DataFrame   File \"C:\\analytics\\ext\\python27\\lib\\site-packages\\pandas\\__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"numpy.pxd\", line 157, in init pandas.tslib (pandas\\tslib.c:49133) ValueError: numpy.dtype has the wrong size, try recompiling      ","Q_Votes":"82"},{"Q_Title":"Python, opposite function urllib.urlencode","A_Content":"  As the docs for urlencode say,     The urlparse module provides the   functions parse_qs() and parse_qsl()   which are used to parse query strings   into Python data structures.   (In older Python releases, they were in the cgi module).  So, for example:  >>> import urllib >>> import urlparse >>> d = {'a':'b', 'c':'d'} >>> s = urllib.urlencode(d) >>> s 'a=b&c=d' >>> d1 = urlparse.parse_qs(s) >>> d1 {'a': ['b'], 'c': ['d']}   The obvious difference between the original dictionary d and the \"round-tripped\" one d1 is that the latter has (single-item, in this case) lists as values -- that's because there is no uniqueness guarantee in query strings, and it may be important to your app to know about what multiple values have been given for each key (that is, the lists won't always be single-item ones;-).  As an alternative:  >>> sq = urlparse.parse_qsl(s) >>> sq   [('a', 'b'), ('c', 'd')] >>> dict(sq) {'a': 'b', 'c': 'd'}   you can get a sequence of pairs (urlencode accepts such an argument, too -- in this case it preserves order, while in the dict case there's no order to preserve;-).  If you know there are no duplicate \"keys\", or don't care if there are, then (as I've shown) you can call dict to get a dictionary with non-list values.  In general, however, you do need to consider what you want to do if duplicates are present (Python doesn't decide that on your behalf;-).     ","Language":"Python","Tags":["python","urllib"],"URL":"https://stackoverflow.com/questions/3542881/python-opposite-function-urllib-urlencode","A_Votes":"114","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I convert data after processing urllib.urlencode to dict? urllib.urldecode does not exist.     ","Q_Votes":"82"},{"Q_Title":"Python, opposite function urllib.urlencode","A_Content":"  urllib.unquote_plus() does what you want. It Replace %xx escapes by their single-character equivalent and replaces plus signs with spaces.  Example: unquote_plus('/%7Ecandidates/?name=john+connolly') yields '/~candidates/?name=john connolly'.     ","Language":"Python","Tags":["python","urllib"],"URL":"https://stackoverflow.com/questions/3542881/python-opposite-function-urllib-urlencode","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    How can I convert data after processing urllib.urlencode to dict? urllib.urldecode does not exist.     ","Q_Votes":"82"},{"Q_Title":"Python, opposite function urllib.urlencode","A_Content":"  Python 3 code for Alex's solution:  >>> import urllib.parse >>> d = {'a':'b', 'c':'d'} >>> s = urllib.parse.urlencode(d) >>> s 'a=b&c=d' >>> d1 = urllib.parse.parse_qs(s) >>> d1 {'a': ['b'], 'c': ['d']}   The alternative:  >>> sq = urllib.parse.parse_qsl(s) >>> sq [('a', 'b'), ('c', 'd')] >>> dict(sq) {'a': 'b', 'c': 'd'}   parse_qsl is reversible:  >>> urllib.parse.urlencode(sq) 'a=b&c=d'      ","Language":"Python","Tags":["python","urllib"],"URL":"https://stackoverflow.com/questions/3542881/python-opposite-function-urllib-urlencode","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    How can I convert data after processing urllib.urlencode to dict? urllib.urldecode does not exist.     ","Q_Votes":"82"},{"Q_Title":"TypeError: Missing 1 required positional argument: 'self'","A_Content":"  You need to instantiate a class instance here.  Use  p = Pump() p.getPumps()   Small example -   >>> class TestClass:         def __init__(self):             print \"in init\"         def testFunc(self):             print \"in Test Func\"   >>> testInstance = TestClass() in init >>> testInstance.testFunc() in Test Func      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/17534345/typeerror-missing-1-required-positional-argument-self","A_Votes":"117","_type":"dict","isAccepted":"Yes","Q_Content":"    I am new to python and have hit a wall. I followed several tutorials but cant get past the error:  Traceback (most recent call last):   File \"C:\\Users\\Dom\\Desktop\\test\\test.py\", line 7, in <module>     p = Pump.getPumps() TypeError: getPumps() missing 1 required positional argument: 'self'   I examined several tutorials but there doesn't seem to be anything different from my code. The only thing I can think of is that python 3.3 requires different syntax.  main scipt:  # test script  from lib.pump import Pump  print (\"THIS IS A TEST OF PYTHON\") # this prints  p = Pump.getPumps()  print (p)   Pump class:  import pymysql  class Pump:      def __init__(self):         print (\"init\") # never prints       def getPumps(self):                 # Open database connection                 # some stuff here that never gets executed because of error   If I understand correctly \"self\" is passed to the constructor and methods automatically. What am I doing wrong here?  I am using windows 8 with python 3.3.2     ","Q_Votes":"82"},{"Q_Title":"TypeError: Missing 1 required positional argument: 'self'","A_Content":"  You need to initialize it first:  p = Pump().getPumps()      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/17534345/typeerror-missing-1-required-positional-argument-self","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I am new to python and have hit a wall. I followed several tutorials but cant get past the error:  Traceback (most recent call last):   File \"C:\\Users\\Dom\\Desktop\\test\\test.py\", line 7, in <module>     p = Pump.getPumps() TypeError: getPumps() missing 1 required positional argument: 'self'   I examined several tutorials but there doesn't seem to be anything different from my code. The only thing I can think of is that python 3.3 requires different syntax.  main scipt:  # test script  from lib.pump import Pump  print (\"THIS IS A TEST OF PYTHON\") # this prints  p = Pump.getPumps()  print (p)   Pump class:  import pymysql  class Pump:      def __init__(self):         print (\"init\") # never prints       def getPumps(self):                 # Open database connection                 # some stuff here that never gets executed because of error   If I understand correctly \"self\" is passed to the constructor and methods automatically. What am I doing wrong here?  I am using windows 8 with python 3.3.2     ","Q_Votes":"82"},{"Q_Title":"TypeError: Missing 1 required positional argument: 'self'","A_Content":"  You can also get this error by prematurely taking PyCharm's advice to annotate a method @staticmethod.  Remove the annotation.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/17534345/typeerror-missing-1-required-positional-argument-self","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am new to python and have hit a wall. I followed several tutorials but cant get past the error:  Traceback (most recent call last):   File \"C:\\Users\\Dom\\Desktop\\test\\test.py\", line 7, in <module>     p = Pump.getPumps() TypeError: getPumps() missing 1 required positional argument: 'self'   I examined several tutorials but there doesn't seem to be anything different from my code. The only thing I can think of is that python 3.3 requires different syntax.  main scipt:  # test script  from lib.pump import Pump  print (\"THIS IS A TEST OF PYTHON\") # this prints  p = Pump.getPumps()  print (p)   Pump class:  import pymysql  class Pump:      def __init__(self):         print (\"init\") # never prints       def getPumps(self):                 # Open database connection                 # some stuff here that never gets executed because of error   If I understand correctly \"self\" is passed to the constructor and methods automatically. What am I doing wrong here?  I am using windows 8 with python 3.3.2     ","Q_Votes":"82"},{"Q_Title":"TypeError: Missing 1 required positional argument: 'self'","A_Content":"  I had a similar problem. A piece of my code looked like this:  class player(object):     def update(self):         if self.score == game.level:             game.level_up()  class game(object):     def level_up(self):         self.level += 1   It also gave me that error about missing self. I solved it by typing game.level_up(game) instead of game.level_up().  It should work for you too.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/17534345/typeerror-missing-1-required-positional-argument-self","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I am new to python and have hit a wall. I followed several tutorials but cant get past the error:  Traceback (most recent call last):   File \"C:\\Users\\Dom\\Desktop\\test\\test.py\", line 7, in <module>     p = Pump.getPumps() TypeError: getPumps() missing 1 required positional argument: 'self'   I examined several tutorials but there doesn't seem to be anything different from my code. The only thing I can think of is that python 3.3 requires different syntax.  main scipt:  # test script  from lib.pump import Pump  print (\"THIS IS A TEST OF PYTHON\") # this prints  p = Pump.getPumps()  print (p)   Pump class:  import pymysql  class Pump:      def __init__(self):         print (\"init\") # never prints       def getPumps(self):                 # Open database connection                 # some stuff here that never gets executed because of error   If I understand correctly \"self\" is passed to the constructor and methods automatically. What am I doing wrong here?  I am using windows 8 with python 3.3.2     ","Q_Votes":"82"},{"Q_Title":"Line continuation for list comprehensions or generator expressions in python","A_Content":"  [x  for  x  in  (1,2,3) ]   works fine, so you can pretty much do as you please. I'd personally prefer   [something_that_is_pretty_long   for something_that_is_pretty_long   in somethings_that_are_pretty_long]   The reason why \\ isn't appreciated very much is that it appears at the end of a line, where it either doesn't stand out or needs extra padding, which has to be fixed when line lengths change:  x = very_long_term                     \\   + even_longer_term_than_the_previous \\   + a_third_term   In such cases, use parens:  x = (very_long_term      + even_longer_term_than_the_previous      + a_third_term)      ","Language":"Python","Tags":["python","coding-style","list-comprehension","pep8"],"URL":"https://stackoverflow.com/questions/5809059/line-continuation-for-list-comprehensions-or-generator-expressions-in-python","A_Votes":"116","_type":"dict","isAccepted":"Yes","Q_Content":"    How are you supposed to break up a very long list comprehension?  [something_that_is_pretty_long for something_that_is_pretty_long in somethings_that_are_pretty_long]   I have also seen somewhere that people that dislike using '\\' to break up lines, but never understood why. What is the reason behind this?     ","Q_Votes":"82"},{"Q_Title":"Line continuation for list comprehensions or generator expressions in python","A_Content":"  I'm not opposed to:  variable = [something_that_is_pretty_long             for something_that_is_pretty_long             in somethings_that_are_pretty_long]   You don't need \\ in this case. In general, I think people avoid \\ because it's slightly ugly, but also can give problems if it's not the very last thing on the line (make sure no whitespace follows it). I think it's much better to use it than not, though, in order to keep your line lengths down.  Since \\ isn't necessary in the above case, or for parenthesized expressions, I actually find it fairly rare that I even need to use it.     ","Language":"Python","Tags":["python","coding-style","list-comprehension","pep8"],"URL":"https://stackoverflow.com/questions/5809059/line-continuation-for-list-comprehensions-or-generator-expressions-in-python","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    How are you supposed to break up a very long list comprehension?  [something_that_is_pretty_long for something_that_is_pretty_long in somethings_that_are_pretty_long]   I have also seen somewhere that people that dislike using '\\' to break up lines, but never understood why. What is the reason behind this?     ","Q_Votes":"82"},{"Q_Title":"Line continuation for list comprehensions or generator expressions in python","A_Content":"  You can also make use of multiple indentations in cases where you're dealing with a list of several data structures.  new_list = [     {         'attribute 1': a_very_long_item.attribute1,         'attribute 2': a_very_long_item.attribute2,         'list_attribute': [             {                 'dict_key_1': attribute_item.attribute2,                 'dict_key_2': attribute_item.attribute2             }             for attribute_item             in a_very_long_item.list_of_items          ]     }     for a_very_long_item     in a_very_long_list     if a_very_long_item not in [some_other_long_item         for some_other_long_item          in some_other_long_list     ] ]   Notice how it also filters onto another list using an if statement. Dropping the if statement to its own line is useful as well.     ","Language":"Python","Tags":["python","coding-style","list-comprehension","pep8"],"URL":"https://stackoverflow.com/questions/5809059/line-continuation-for-list-comprehensions-or-generator-expressions-in-python","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    How are you supposed to break up a very long list comprehension?  [something_that_is_pretty_long for something_that_is_pretty_long in somethings_that_are_pretty_long]   I have also seen somewhere that people that dislike using '\\' to break up lines, but never understood why. What is the reason behind this?     ","Q_Votes":"82"},{"Q_Title":"How to do math in a Django template?","A_Content":"  You can use the add filter:  {{ object.article.rating_score|add:\"-100\" }}      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/6285327/how-to-do-math-in-a-django-template","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to do this:  100 - {{object.article.rating_score}}    so for example, the output would be \"20\" if {{object.article.rating_score}} equaled \"80\". How to do this at the template level? I don't have access to the python code.     ","Q_Votes":"82"},{"Q_Title":"How to do math in a Django template?","A_Content":"  Use django-mathfilters. In addition to the built-in add filter, it provides filters to subtract, multiply, divide, and take the absolute value.  For the specific example above, you would use {{ 100|sub:object.article.rating_score }}.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/6285327/how-to-do-math-in-a-django-template","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I want to do this:  100 - {{object.article.rating_score}}    so for example, the output would be \"20\" if {{object.article.rating_score}} equaled \"80\". How to do this at the template level? I don't have access to the python code.     ","Q_Votes":"82"},{"Q_Title":"How to do math in a Django template?","A_Content":"  Generally it is recommended you do this calculation in your view. Otherwise, you could use the add filter.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/6285327/how-to-do-math-in-a-django-template","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I want to do this:  100 - {{object.article.rating_score}}    so for example, the output would be \"20\" if {{object.article.rating_score}} equaled \"80\". How to do this at the template level? I don't have access to the python code.     ","Q_Votes":"82"},{"Q_Title":"Can't compare naive and aware datetime.now() <= challenge.datetime_end","A_Content":"  By default, the datetime object is naive in Python, so you need to make both of them either naive or aware datetime objects. This can be done using:  import datetime import pytz  utc=pytz.UTC  challenge.datetime_start = utc.localize(challenge.datetime_start)  challenge.datetime_end = utc.localize(challenge.datetime_end)  # now both the datetime objects are aware, and you can compare them   Note: This would raise a ValueError if tzinfo is already set. If you are not sure about that, just use  start_time = challenge.datetime_start.replace(tzinfo=utc) end_time = challenge.datetime_end.replace(tzinfo=utc)   BTW, you could format a UNIX timestamp in datetime.datetime object with timezone info as following  d = datetime.datetime.utcfromtimestamp(int(unix_timestamp)) d_with_tz = datetime.datetime(     year=d.year,     month=d.month,     day=d.day,     hour=d.hour,     minute=d.minute,     second=d.second,     tzinfo=pytz.UTC)      ","Language":"Python","Tags":["python","django","datetime","comparison"],"URL":"https://stackoverflow.com/questions/15307623/cant-compare-naive-and-aware-datetime-now-challenge-datetime-end","A_Votes":"64","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to compare the current date and time with dates and times specified in models using comparison operators:  if challenge.datetime_start <= datetime.now() <= challenge.datetime_end:   The script errors out with:   TypeError: can't compare offset-naive and offset-aware datetimes   The models look like this:  class Fundraising_Challenge(models.Model):     name = models.CharField(max_length=100)     datetime_start = models.DateTimeField()     datetime_end = models.DateTimeField()   I also have django using locale date and times.  What I haven't been able to find is the format django uses for DateTimeField().  Is it naive or aware?  And how do I get datetime.now() to recognize locale datetime?     ","Q_Votes":"82"},{"Q_Title":"Can't compare naive and aware datetime.now() <= challenge.datetime_end","A_Content":"  datetime.datetime.now is not timezone aware.  Django comes with a helper for this, which requires pytz  from django.utils import timezone now = timezone.now()   You should be able to compare now to challenge.datetime_start     ","Language":"Python","Tags":["python","django","datetime","comparison"],"URL":"https://stackoverflow.com/questions/15307623/cant-compare-naive-and-aware-datetime-now-challenge-datetime-end","A_Votes":"60","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to compare the current date and time with dates and times specified in models using comparison operators:  if challenge.datetime_start <= datetime.now() <= challenge.datetime_end:   The script errors out with:   TypeError: can't compare offset-naive and offset-aware datetimes   The models look like this:  class Fundraising_Challenge(models.Model):     name = models.CharField(max_length=100)     datetime_start = models.DateTimeField()     datetime_end = models.DateTimeField()   I also have django using locale date and times.  What I haven't been able to find is the format django uses for DateTimeField().  Is it naive or aware?  And how do I get datetime.now() to recognize locale datetime?     ","Q_Votes":"82"},{"Q_Title":"Can't compare naive and aware datetime.now() <= challenge.datetime_end","A_Content":"  One line of code solution  if timezone_aware_var <= datetime.datetime.now(timezone_aware_var.tzinfo):     pass #some code   Explained version:  # Timezone info of your timezone aware variable timezone = your_timezone_aware_variable.tzinfo  # Current datetime for the timezone of your variable now_in_timezone = datetime.datetime.now(timezone)  # Now you can do a fair comparison, both datetime variables have the same time zone if your_timezone_aware_variable <= now_in_timezone:     pass #some code   Summary: You must add the timezone info to your now() datetime. However, you must add the same timezone of the reference variable; that is why I first read the tzinfo attribute.     ","Language":"Python","Tags":["python","django","datetime","comparison"],"URL":"https://stackoverflow.com/questions/15307623/cant-compare-naive-and-aware-datetime-now-challenge-datetime-end","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to compare the current date and time with dates and times specified in models using comparison operators:  if challenge.datetime_start <= datetime.now() <= challenge.datetime_end:   The script errors out with:   TypeError: can't compare offset-naive and offset-aware datetimes   The models look like this:  class Fundraising_Challenge(models.Model):     name = models.CharField(max_length=100)     datetime_start = models.DateTimeField()     datetime_end = models.DateTimeField()   I also have django using locale date and times.  What I haven't been able to find is the format django uses for DateTimeField().  Is it naive or aware?  And how do I get datetime.now() to recognize locale datetime?     ","Q_Votes":"82"},{"Q_Title":"Can't compare naive and aware datetime.now() <= challenge.datetime_end","A_Content":"  So the way I would solve this problem is to make sure the two datetimes are in the right timezone.   I can see that you are using datetime.now() which will return the systems current time, with no tzinfo set.   tzinfo is the information attached to a datetime to let it know what timezone it is in. If you are using naive datetime you need to be consistent through out your system. I would highly recommend only using datetime.utcnow()  seeing as somewhere your are creating datetime that have tzinfo associated with them, what you need to do is make sure those are localized (has tzinfo associated) to the correct timezone.  Take a look at Delorean, it makes dealing with this sort of thing much easier.       ","Language":"Python","Tags":["python","django","datetime","comparison"],"URL":"https://stackoverflow.com/questions/15307623/cant-compare-naive-and-aware-datetime-now-challenge-datetime-end","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to compare the current date and time with dates and times specified in models using comparison operators:  if challenge.datetime_start <= datetime.now() <= challenge.datetime_end:   The script errors out with:   TypeError: can't compare offset-naive and offset-aware datetimes   The models look like this:  class Fundraising_Challenge(models.Model):     name = models.CharField(max_length=100)     datetime_start = models.DateTimeField()     datetime_end = models.DateTimeField()   I also have django using locale date and times.  What I haven't been able to find is the format django uses for DateTimeField().  Is it naive or aware?  And how do I get datetime.now() to recognize locale datetime?     ","Q_Votes":"82"},{"Q_Title":"Can't compare naive and aware datetime.now() <= challenge.datetime_end","A_Content":"  Disable time zone. Use challenge.datetime_start.replace(tzinfo=None);   You can also use replace(tzinfo=None) for other datetime.  if challenge.datetime_start.replace(tzinfo=None) <= datetime.now().replace(tzinfo=None) <= challenge.datetime_end.replace(tzinfo=None):      ","Language":"Python","Tags":["python","django","datetime","comparison"],"URL":"https://stackoverflow.com/questions/15307623/cant-compare-naive-and-aware-datetime-now-challenge-datetime-end","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to compare the current date and time with dates and times specified in models using comparison operators:  if challenge.datetime_start <= datetime.now() <= challenge.datetime_end:   The script errors out with:   TypeError: can't compare offset-naive and offset-aware datetimes   The models look like this:  class Fundraising_Challenge(models.Model):     name = models.CharField(max_length=100)     datetime_start = models.DateTimeField()     datetime_end = models.DateTimeField()   I also have django using locale date and times.  What I haven't been able to find is the format django uses for DateTimeField().  Is it naive or aware?  And how do I get datetime.now() to recognize locale datetime?     ","Q_Votes":"82"},{"Q_Title":"How to get the concrete class name as a string? [duplicate]","A_Content":"   instance.__class__.__name__   example:  >>> class A():     pass >>> a = A() >>> a.__class__.__name__ 'A'      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/521502/how-to-get-the-concrete-class-name-as-a-string","A_Votes":"143","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Getting the class name of an instance?                                        8 answers                                          I want to avoid calling a lot of isinstance() functions, so I'm looking for a way to get the concrete class name for an instance variable as a string.  Any ideas?     ","Q_Votes":"82"},{"Q_Title":"How to get the concrete class name as a string? [duplicate]","A_Content":"  <object>.__class__.__name__      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/521502/how-to-get-the-concrete-class-name-as-a-string","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Getting the class name of an instance?                                        8 answers                                          I want to avoid calling a lot of isinstance() functions, so I'm looking for a way to get the concrete class name for an instance variable as a string.  Any ideas?     ","Q_Votes":"82"},{"Q_Title":"How to get the concrete class name as a string? [duplicate]","A_Content":"  you can also create a dict with the classes themselves as keys, not necessarily the classnames  typefunc={     int:lambda x: x*2,     str:lambda s:'(*(%s)*)'%s }  def transform (param):     print typefunc[type(param)](param)  transform (1) >>> 2 transform (\"hi\") >>> (*(hi)*)   here typefunc is a dict that maps a function for each type. transform gets that function and applies it to the parameter.  of course, it would be much better to use 'real' OOP     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/521502/how-to-get-the-concrete-class-name-as-a-string","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Getting the class name of an instance?                                        8 answers                                          I want to avoid calling a lot of isinstance() functions, so I'm looking for a way to get the concrete class name for an instance variable as a string.  Any ideas?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  iter() is an iterator over a sequence. [x] * n produces a list containing n quantity of x, i.e. a list of length n, where each element is x. *arg unpacks a sequence into arguments for a function call. Therefore you're passing the same iterator 3 times to zip(), and it pulls an item from the iterator each time.  x = iter([1,2,3,4,5,6,7,8,9]) print zip(x, x, x)      ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"90","_type":"dict","isAccepted":"Yes","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  The other great answers and comments explain well the roles of argument unpacking and zip().  As Ignacio and ujukatzel say, you pass to zip() three references to the same iterator and zip() makes 3-tuples of the integersin orderfrom each reference to the iterator:  1,2,3,4,5,6,7,8,9  1,2,3,4,5,6,7,8,9  1,2,3,4,5,6,7,8,9 ^                    ^                    ^                   ^                    ^                    ^             ^                    ^                    ^   And since you ask for a more verbose code sample:  chunk_size = 3 L = [1,2,3,4,5,6,7,8,9]  # iterate over L in steps of 3 for start in range(0,len(L),chunk_size): # xrange() in 2.x; range() in 3.x     end = start + chunk_size     print L[start:end] # three-item chunks   Following the values of start and end:    [0:3) #[1,2,3] [3:6) #[4,5,6] [6:9) #[7,8,9]   FWIW, you can get the same result with map() with an initial argument of None:  >>> map(None,*[iter(s)]*3) [(1, 2, 3), (4, 5, 6), (7, 8, 9)]   For more on zip() and map():  http://muffinresearch.co.uk/archives/2007/10/16/python-transposing-lists-with-map-and-zip/     ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  I think one thing that's missed in all the answers (probably obvious to those familiar with iterators) but not so obvious to others is -   Since we have the same iterator, it gets consumed and the remaining elements are used by the zip. So if we simply used the list and not the iter  eg.  l = range(9) zip(*([l]*3)) # note: not an iter here, the lists are not emptied as we iterate  # output  [(0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5), (6, 6, 6), (7, 7, 7), (8, 8, 8)]   Using iterator, pops the values and only keeps remaining available, so for zip once 0 is consumed 1 is available and then 2 and so on. A very subtle thing, but quite clever!!!     ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  iter(s) returns an iterator for s.  [iter(s)]*n makes a list of n times the same iterator for s.  So, when doing zip(*[iter(s)]*n), it extracts an item from all the three iterators from the list in order. Since all the iterators are the same object, it just groups the list in chunks of n.     ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  One word of advice for using zip this way. It will truncate your list if it's length is not evenly divisible. To work around this you could either use itertools.izip_longest if you can accept fill values. Or you could use something like this:  def n_split(iterable, n):     num_extra = len(iterable) % n     zipped = zip(*[iter(iterable)] * n)     return zipped if not num_extra else zipped + [iterable[-num_extra:], ]   Usage:  for ints in n_split(range(1,12), 3):     print ', '.join([str(i) for i in ints])   Prints:  1, 2, 3 4, 5, 6 7, 8, 9 10, 11      ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"How does zip(*[iter(s)]*n) work in Python?","A_Content":"  It is probably easier to see what is happening in python interpreter or ipython with n = 2:  In [35]: [iter(\"ABCDEFGH\")]*2 Out[35]: [<iterator at 0x6be4128>, <iterator at 0x6be4128>]   So, we have a list of two iterators which are pointing to the same iterator object. Remember that iter on a object returns an iterator object and in this scenario, it is the same iterator twice due to the *2 python syntactic sugar. Iterators also run only once.  Further, zip takes any number of iterables (sequences are iterables) and creates tuple from i'th element of each of the input sequences. Since both iterators are identical in our case, zip moves the same iterator twice for each 2-element tuple of output.  In [41]: help(zip) Help on built-in function zip in module __builtin__:  zip(...)     zip(seq1 [, seq2 [...]]) -> [(seq1[0], seq2[0] ...), (...)]      Return a list of tuples, where each tuple contains the i-th element     from each of the argument sequences.  The returned list is truncated     in length to the length of the shortest argument sequence.   The unpacking (*) operator ensures that the iterators run to exhaustion which in this case is until there is not enough input to create a 2-element tuple.  This can be extended to any value of n and zip(*[iter(s)]*n) works as described.     ","Language":"Python","Tags":["python","iterator"],"URL":"https://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    s = [1,2,3,4,5,6,7,8,9] n = 3  zip(*[iter(s)]*n) # returns [(1,2,3),(4,5,6),(7,8,9)]   How does zip(*[iter(s)]*n) work?  What would it look like if it was written with more verbose code?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"  It presents a prompt to the user (the optional arg of raw_input([arg])), gets input from the user and returns the data input by the user in a string. See the docs for raw_input().  Example:  name = raw_input(\"What is your name? \") print \"Hello, %s.\" % name   This differs from input()  in that the latter tries to interpret the input given by the user; it is usually best to avoid input() and to stick with raw_input() and custom parsing/conversion code.  Note: This is for Python 2.x     ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"  raw_input() was renamed to input() in Python 3.  From http://docs.python.org/dev/py3k/whatsnew/3.0.html     ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"  The \"input\" function converts the input you enter as if it were python code. \"raw_input\" doesn't convert the input and takes the input as it is given. Its advisable to use raw_input for everything. Usage:   >>a = raw_input() >>5 >>a >>'5'      ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"  raw_input is a form of input that takes the argument  in the form of a string whereas the input function takes the value depending upon your input. Say, a=input(5) returns a as an integer with value 5 whereas      a=raw_input(5) returns a as a string of \"5\"       ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"  Another example method, to mix the prompt using print, if you need to make your code simpler.  Format:-  x = raw_input () -- This will return the user input as a string  x= int(raw_input()) -- Gets the input number as a string from raw_input() and then converts it to an integer using int().  print '\\nWhat\\'s your name ?',  name = raw_input('--> ') print '\\nHow old are you, %s?' % name, age = int(raw_input()) print '\\nHow tall are you (in cms), %s?' % name, height = int(raw_input()) print '\\nHow much do you weigh (in kgs), %s?' % name, weight = int(raw_input())  print '\\nSo, %s is %d years old, %d cms tall and weighs %d kgs.\\n' %( name, age, height, weight)      ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"raw_input function in Python","A_Content":"     If I let raw_input like that, no Josh or anything else.   It's a variable,I think,but I don't understand her roll :-(   The raw_input function prompts you for input and returns that as a string. This certainly worked for me. You don't need idle. Just open a \"DOS prompt\" and run the program.  This is what it looked like for me:  C:\\temp>type test.py print \"Halt!\" s = raw_input(\"Who Goes there? \") print \"You may pass,\", s  C:\\temp>python test.py Halt! Who Goes there? Magnus You may pass, Magnus   I types my name and pressed [Enter] after the program had printed \"Who Goes there?\"     ","Language":"Python","Tags":["python","python-2.x"],"URL":"https://stackoverflow.com/questions/5563089/raw-input-function-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    What is the raw_input function? Is it a user interface? When do we use it?     ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  With this type of thing you need to be careful what your actual working directory is.  For example, you may not run the script from the directory the file is in.  In this case, you can't just use a relative path by itself.  If you are sure the file you want is in a subdirectory beneath where the script is actually located, you can use __file__ to help you out here.  __file__ is the full path to where the script you are running is located.  So you can fiddle with something like this:  import os script_dir = os.path.dirname(__file__) #<-- absolute dir the script is in rel_path = \"2091/data.txt\" abs_file_path = os.path.join(script_dir, rel_path)      ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"120","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  This code works fine:  import os   def readFile(filename):     filehandle = open(filename)     print filehandle.read()     filehandle.close()    fileDir = os.path.dirname(os.path.realpath('__file__')) print fileDir  #For accessing the file in the same folder filename = \"same.txt\" readFile(filename)  #For accessing the file in a folder contained in the current folder filename = os.path.join(fileDir, 'Folder1.1/same.txt') readFile(filename)  #For accessing the file in the parent folder of the current folder filename = os.path.join(fileDir, '../same.txt') readFile(filename)  #For accessing the file inside a sibling folder. filename = os.path.join(fileDir, '../Folder2/same.txt') filename = os.path.abspath(os.path.realpath(filename)) print filename readFile(filename)      ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  I created an account just so I could clarify a discrepancy I think I found in Russ's original response.  For reference, his original answer was:  import os script_dir = os.path.dirname(__file__) rel_path = \"2091/data.txt\" abs_file_path = os.path.join(script_dir, rel_path)   This is a great answer because it is trying to dynamically creates an absolute system path to the desired file.  Cory Mawhorter noticed that __file__ is a relative path (it is as well on my system) and suggested using os.path.abspath(__file__).  os.path.abspath, however, returns the absolute path of your current script (i.e. /path/to/dir/foobar.py)  To use this method (and how I eventually got it working) you have to remove the script name from the end of the path:  import os script_path = os.path.abspath(__file__) # i.e. /path/to/dir/foobar.py script_dir = os.path.split(script_path)[0] #i.e. /path/to/dir/ rel_path = \"2091/data.txt\" abs_file_path = os.path.join(script_dir, rel_path)   The resulting abs_file_path (in this example) becomes: /path/to/dir/2091/data.txt     ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  It depends on what operating system you're using. If you want a solution that is compatible with both Windows and *nix something like:  from os import path  file_path = path.relpath(\"2091/data.txt\") with open(file_path) as f:     <do stuff>   should work fine.  The path module is able to format a path for whatever operating system it's running on. Also, python handles relative paths just fine, so long as you have correct permissions.  Edit:  As mentioned by kindall in the comments, python can convert between unix-style and windows-style paths anyway, so even simpler code will work:  with open(\"2091/data/txt\") as f:     <do stuff>   That being said, the path module still has some useful functions.     ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  Not sure if this work everywhere.  I'm using ipython in ubuntu.  If you want to read file in current folder's sub-directory:  /current-folder/sub-directory/data.csv   your script is in current-folder simply try this:  import pandas as pd path = './sub-directory/data.csv' pd.read_csv(path)      ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  If the file is in your parent folder, eg. follower.txt, you can simply use open('../follower.txt', 'r').read()     ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  Python just passes the filename you give it to the operating system, which opens it. If your operating system supports relative paths like main/2091/data.txt (hint: it does), then that will work fine.  You may find that the easiest way to answer a question like this is to try it and see what happens.     ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  Try this:  from pathlib import Path  data_folder = Path(\"/relative/path\") file_to_open = data_folder / \"file.pdf\"  f = open(file_to_open)  print(f.read())   Python 3.4 introduced a new standard library for dealing with files and paths called pathlib. It works for me!     ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Open file in a relative location in Python","A_Content":"  I spend a lot time to discover because my code could not find my file running Python 3 on the Windows system. So I added . before / and everything worked fine:  from os import path  script_dir = os.path.dirname(__file__) file_path = os.path.join(script_dir, './output03.txt') print(file_path) fptr = open(file_path, 'w')      ","Language":"Python","Tags":["python","file","path"],"URL":"https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Suppose python code is executed in not known by prior windows directory say 'main' , and wherever code is installed when it runs it needs to access to directory 'main/2091/data.txt' .  how should I use open(location) function? what should be location ?  Edit :  I found that below simple code will work..does it have any disadvantages ?      file=\"\\2091\\sample.txt\"     path=os.getcwd()+file     fp=open(path,'r+');      ","Q_Votes":"82"},{"Q_Title":"Python naming conventions for modules","A_Content":"  Just nib. Name the class Nib, with a capital N. For more on naming conventions and other style advice, see PEP 8, the Python style guide.     ","Language":"Python","Tags":["python","naming-conventions"],"URL":"https://stackoverflow.com/questions/711884/python-naming-conventions-for-modules","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a module whose purpose is to define a class called \"nib\". (and a few related classes too.) How should I call the module itself? \"nib\"? \"nibmodule\"? Anything else?     ","Q_Votes":"82"},{"Q_Title":"Python naming conventions for modules","A_Content":"  I would call it nib.py. And I would also name the class Nib.  In a larger python project I'm working on, we have lots of modules defining basically one important class. Classes are named beginning with a capital letter. The modules are named like the class in lowercase. This leads to imports like the following:  from nib import Nib from foo import Foo from spam.eggs import Eggs, FriedEggs   It's a bit like emulating the Java way. One class per file. But with the added flexibility, that you can allways add another class to a single file if it makes sense.     ","Language":"Python","Tags":["python","naming-conventions"],"URL":"https://stackoverflow.com/questions/711884/python-naming-conventions-for-modules","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I have a module whose purpose is to define a class called \"nib\". (and a few related classes too.) How should I call the module itself? \"nib\"? \"nibmodule\"? Anything else?     ","Q_Votes":"82"},{"Q_Title":"Python naming conventions for modules","A_Content":"  I know my solution is not very popular from the pythonic point of view, but I prefer to use the Java approach of one module->one class, with the module named as the class. I do understand the reason behind the python style, but I am not too fond of having a very large file containing a lot of classes. I find it difficult to browse, despite folding.  Another reason is version control: having a large file means that your commits tend to concentrate on that file. This can potentially lead to a higher quantity of conflicts to be resolved. You also loose the additional log information that your commit modifies specific files (therefore involving specific classes). Instead you see a modification to the module file, with only the commit comment to understand what modification has been done.  Summing up, if you prefer the python philosophy, go for the suggestions of the other posts. If you instead prefer the java-like philosophy, create a Nib.py containing class Nib.     ","Language":"Python","Tags":["python","naming-conventions"],"URL":"https://stackoverflow.com/questions/711884/python-naming-conventions-for-modules","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I have a module whose purpose is to define a class called \"nib\". (and a few related classes too.) How should I call the module itself? \"nib\"? \"nibmodule\"? Anything else?     ","Q_Votes":"82"},{"Q_Title":"Python naming conventions for modules","A_Content":"  nib is fine.  If in doubt, refer to the Python style guide.  From PEP 8:     Package and Module Names   Modules should have short, all-lowercase names.  Underscores can be used   in the module name if it improves readability.  Python packages should   also have short, all-lowercase names, although the use of underscores is   discouraged.      Since module names are mapped to file names, and some file systems are   case insensitive and truncate long names, it is important that module   names be chosen to be fairly short -- this won't be a problem on Unix,   but it may be a problem when the code is transported to older Mac or   Windows versions, or DOS.      When an extension module written in C or C++ has an accompanying Python   module that provides a higher level (e.g. more object oriented)   interface, the C/C++ module has a leading underscore (e.g. _socket).      ","Language":"Python","Tags":["python","naming-conventions"],"URL":"https://stackoverflow.com/questions/711884/python-naming-conventions-for-modules","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I have a module whose purpose is to define a class called \"nib\". (and a few related classes too.) How should I call the module itself? \"nib\"? \"nibmodule\"? Anything else?     ","Q_Votes":"82"},{"Q_Title":"Python naming conventions for modules","A_Content":"  foo module in python would be the equivalent to a Foo class file in Java  or  foobar module in python would be the equivalent to a FooBar class file in Java     ","Language":"Python","Tags":["python","naming-conventions"],"URL":"https://stackoverflow.com/questions/711884/python-naming-conventions-for-modules","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have a module whose purpose is to define a class called \"nib\". (and a few related classes too.) How should I call the module itself? \"nib\"? \"nibmodule\"? Anything else?     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  I would do it as follows:   Split the sentence into words, normalise them, build a dictionary With each word, store how many times they occurred in tweets about the company, and how many times they appeared in tweets about the fruit - these tweets must be confirmed by a human When a new tweet comes in, find every word in the tweet in the dictionary, calculate a weighted score - words that are used frequently in relation to the company would get a high company score, and vice versa; words used rarely, or used with both the company and the fruit, would not have much of a score.      ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"36","_type":"dict","isAccepted":"Yes","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  What you are looking for is called Named Entity Recognition. It is a statistical technique that (most commonly) uses Conditional Random Fields to find named entities, based on having been trained to learn things about named entities.  Essentially, it looks at the content and context of the word, (looking back and forward a few words), to estimate the probability that the word is a named entity.   Good software can look at other features of words, such as their length or shape (like \"Vcv\" if it starts with \"Vowel-consonant-vowel\")  A very good library (GPL) is Stanford's NER  Here's the demo: http://nlp.stanford.edu:8080/ner/  Some sample text to try:     I was eating an apple over at Apple headquarters and I thought about   Apple Martin, the daughter of the Coldplay guy   (the 3class and 4class classifiers get it right)     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"71","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  I have a semi-working system that solves this problem, open sourced using scikit-learn, with a series of blog posts describing what I'm doing. The problem I'm tackling is word-sense disambiguation (choosing one of multiple word sense options), which is not the same as Named Entity Recognition. My basic approach is somewhat-competitive with existing solutions and (crucially) is customisable.  There are some existing commercial NER tools (OpenCalais, DBPedia Spotlight, and AlchemyAPI) that might give you a good enough commercial result - do try these first!  I used some of these for a client project (I consult using NLP/ML in London), but I wasn't happy with their recall (precision and recall). Basically they can be precise (when they say \"This is Apple Inc\" they're typically correct), but with low recall (they rarely say \"This is Apple Inc\" even though to a human the tweet is obviously about Apple Inc). I figured it'd be an intellectually interesting exercise to build an open source version tailored to tweets. Here's the current code: https://github.com/ianozsvald/social_media_brand_disambiguator  I'll note - I'm not trying to solve the generalised word-sense disambiguation problem with this approach, just brand disambiguation (companies, people, etc.) when you already have their name. That's why I believe that this straightforward approach will work.  I started this six weeks ago, and it is written in Python 2.7 using scikit-learn. It uses a very basic approach. I vectorize using a binary count vectorizer (I only count whether a word appears, not how many times) with 1-3n-grams. I don't scale with TF-IDF (TF-IDF is good when you have a variable document length; for me the tweets are only one or two sentences, and my testing results didn't show improvement with TF-IDF).  I use the basic tokenizer which is very basic but surprisingly useful. It ignores @ # (so you lose some context) and of course doesn't expand a URL. I then train using logistic regression, and it seems that this problem is somewhat linearly separable (lots of terms for one class don't exist for the other). Currently I'm avoiding any stemming/cleaning (I'm trying The Simplest Possible Thing That Might Work).  The code has a full README, and you should be able to ingest your tweets relatively easily and then follow my suggestions for testing.  This works for Apple as people don't eat or drink Apple computers, nor do we type or play with fruit, so the words are easily split to one category or the other. This condition may not hold when considering something like #definance for the TV show (where people also use #definance in relation to the Arab Spring, cricket matches, exam revision and a music band). Cleverer approaches may well be required here.  I have a series of blog posts describing this project including a one-hour presentation I gave at the BrightonPython usergroup (which turned into a shorter presentation for 140 people at DataScienceLondon).  If you use something like LogisticRegression (where you get a probability for each classification) you can pick only the confident classifications, and that way you can force high precision by trading against recall (so you get correct results, but fewer of them). You'll have to tune this to your system.  Here's a possible algorithmic approach using scikit-learn:   Use a Binary CountVectorizer (I don't think term-counts in short messages add much information as most words occur only once) Start with a Decision Tree classifier. It'll have explainable performance (see Overfitting with a Decision Tree for an example). Move to logistic regression Investigate the errors generated by the classifiers (read the DecisionTree's exported output or look at the coefficients in LogisticRegression, work the mis-classified tweets back through the Vectorizer to see what the underlying Bag of Words representation looks like - there will be fewer tokens there than you started with in the raw tweet - are there enough for a classification?) Look at my example code in https://github.com/ianozsvald/social_media_brand_disambiguator/blob/master/learn1.py for a worked version of this approach   Things to consider:   You need a larger dataset. I'm using 2000 labelled tweets (it took me five hours), and as a minimum you want a balanced set with >100 per class (see the overfitting note below) Improve the tokeniser (very easy with scikit-learn) to keep # @ in tokens, and maybe add a capitalised-brand detector (as user @user2425429 notes) Consider a non-linear classifier (like @oiez's suggestion above) when things get harder. Personally I found LinearSVC to do worse than logistic regression (but that may be due to the high-dimensional feature space that I've yet to reduce). A tweet-specific part of speech tagger (in my humble opinion not Standford's as @Neil suggests - it performs poorly on poor Twitter grammar in my experience) Once you have lots of tokens you'll probably want to do some dimensionality reduction (I've not tried this yet - see my blog post on LogisticRegression l1 l2 penalisation)   Re. overfitting. In my dataset with 2000 items I have a 10 minute snapshot from Twitter of 'apple' tweets. About 2/3 of the tweets are for Apple Inc, 1/3 for other-apple-uses. I pull out a balanced subset (about 584 rows I think) of each class and do five-fold cross validation for training.  Since I only have a 10 minute time-window I have many tweets about the same topic, and this is probably why my classifier does so well relative to existing tools - it will have overfit to the training features without generalising well (whereas the existing commercial tools perform worse on this snapshop, but more reliably across a wider set of data). I'll be expanding my time window to test this as a subsequent piece of work.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  You can do the following:   Make a dict of words containing their count of occurrence in fruit and company related tweets. This can be achieved by feeding it some sample tweets whose inclination we know. Using enough previous data, we can find out the probability of a word occurring in tweet about apple inc. Multiply individual probabilities of words to get the probability of the whole tweet.   A simplified example:  p_f = Probability of fruit tweets.  p_w_f = Probability of a word occurring in a fruit tweet.  p_t_f = Combined probability of all words in tweet occurring a fruit tweet       = p_w1_f * p_w2_f * ...  p_f_t = Probability of fruit given a particular tweet.  p_c, p_w_c, p_t_c, p_c_t are respective values for company.  A laplacian smoother of value 1 is added to eliminate the problem of zero frequency of new words which are not there in our database.  old_tweets = {'apple pie sweet potatoe cake baby https://vine.co/v/hzBaWVA3IE3': '0', ...} known_words = {} total_company_tweets = total_fruit_tweets =total_company_words = total_fruit_words = 0  for tweet in old_tweets:     company = old_tweets[tweet]     for word in tweet.lower().split(\" \"):         if not word in known_words:             known_words[word] = {\"company\":0, \"fruit\":0 }         if company == \"1\":             known_words[word][\"company\"] += 1             total_company_words += 1         else:             known_words[word][\"fruit\"] += 1             total_fruit_words += 1      if company == \"1\":         total_company_tweets += 1     else:         total_fruit_tweets += 1 total_tweets = len(old_tweets)  def predict_tweet(new_tweet,K=1):     p_f = (total_fruit_tweets+K)/(total_tweets+K*2)     p_c = (total_company_tweets+K)/(total_tweets+K*2)     new_words = new_tweet.lower().split(\" \")      p_t_f = p_t_c = 1     for word in new_words:         try:             wordFound = known_words[word]         except KeyError:             wordFound = {'fruit':0,'company':0}         p_w_f = (wordFound['fruit']+K)/(total_fruit_words+K*(len(known_words)))         p_w_c = (wordFound['company']+K)/(total_company_words+K*(len(known_words)))     p_t_f *= p_w_f     p_t_c *= p_w_c      #Applying bayes rule     p_f_t = p_f * p_t_f/(p_t_f*p_f + p_t_c*p_c)     p_c_t = p_c * p_t_c/(p_t_f*p_f + p_t_c*p_c)     if p_c_t > p_f_t:         return \"Company\"     return \"Fruit\"      ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  If you don't have an issue using an outside library, I'd recommend scikit-learn since it can probably do this better & faster than anything you could code by yourself. I'd just do something like this:  Build your corpus. I did the list comprehensions for clarity, but depending on how your data is stored you might need to do different things:  def corpus_builder(apple_inc_tweets, apple_fruit_tweets):     corpus = [tweet for tweet in apple_inc_tweets] + [tweet for tweet in apple_fruit_tweets]     labels = [1 for x in xrange(len(apple_inc_tweets))] + [0 for x in xrange(len(apple_fruit_tweets))]     return (corpus, labels)   The important thing is you end up with two lists that look like this:  ([['apple inc tweet i love ios and iphones'], ['apple iphones are great'], ['apple fruit tweet i love pie'], ['apple pie is great']], [1, 1, 0, 0])   The [1, 1, 0, 0] represent the positive and negative labels.  Then, you create a Pipeline! Pipeline is a scikit-learn class that makes it easy to chain text processing steps together so you only have to call one object when training/predicting:  def train(corpus, labels)     pipe = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3), stop_words='english')),                         ('tfidf', TfidfTransformer(norm='l2')),                         ('clf', LinearSVC()),])     pipe.fit_transform(corpus, labels)     return pipe   Inside the Pipeline there are three processing steps. The CountVectorizer tokenizes the words, splits them, counts them, and transforms the data into a sparse matrix. The TfidfTransformer is optional, and you might want to remove it depending on the accuracy rating (doing cross validation tests and a grid search for the best parameters is a bit involved, so I won't get into it here). The LinearSVC is a standard text classification algorithm.  Finally, you predict the category of tweets:  def predict(pipe, tweet):     prediction = pipe.predict([tweet])     return prediction   Again, the tweet needs to be in a list, so I assumed it was entering the function as a string.  Put all those into a class or whatever, and you're done. At least, with this very basic example.  I didn't test this code so it might not work if you just copy-paste, but if you want to use scikit-learn it should give you an idea of where to start.  EDIT: tried to explain the steps in more detail.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  Using a decision tree seems to work quite well for this problem. At least it produces a higher accuracy than a naive bayes classifier with my chosen features.  If you want to play around with some possibilities, you can use the following code, which requires nltk to be installed. The nltk book is also freely available online, so you might want to read a bit about how all of this actually works: http://nltk.googlecode.com/svn/trunk/doc/book/ch06.html  #coding: utf-8 import nltk import random import re  def get_split_sets():     structured_dataset = get_dataset()     train_set = set(random.sample(structured_dataset, int(len(structured_dataset) * 0.7)))     test_set = [x for x in structured_dataset if x not in train_set]      train_set = [(tweet_features(x[1]), x[0]) for x in train_set]     test_set = [(tweet_features(x[1]), x[0]) for x in test_set]     return (train_set, test_set)  def check_accurracy(times=5):     s = 0     for _ in xrange(times):         train_set, test_set = get_split_sets()         c = nltk.classify.DecisionTreeClassifier.train(train_set)         # Uncomment to use a naive bayes classifier instead         #c = nltk.classify.NaiveBayesClassifier.train(train_set)         s += nltk.classify.accuracy(c, test_set)      return s / times   def remove_urls(tweet):     tweet = re.sub(r'http:\\/\\/[^ ]+', \"\", tweet)     tweet = re.sub(r'pic.twitter.com/[^ ]+', \"\", tweet)     return tweet  def tweet_features(tweet):     words = [x for x in nltk.tokenize.wordpunct_tokenize(remove_urls(tweet.lower())) if x.isalpha()]     features = dict()     for bigram in nltk.bigrams(words):         features[\"hasBigram(%s)\" % \",\".join(bigram)] = True     for trigram in nltk.trigrams(words):         features[\"hasTrigram(%s)\" % \",\".join(trigram)] = True       return features  def get_dataset():     dataset = \"\"\"copy dataset in here \"\"\"     structured_dataset = [('fruit' if x[0] == '0' else 'company', x[2:]) for x in dataset.splitlines()]     return structured_dataset  if __name__ == '__main__':     print check_accurracy()      ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  Thank you for the comments thus far. Here is a working solution I prepared with PHP. I'd still be interested in hearing from others a more algorithmic approach to this same solution.   <?php  // Confusion Matrix Init $tp = 0; $fp = 0; $fn = 0; $tn = 0; $arrFP = array(); $arrFN = array();  // Load All Tweets to string $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, 'http://pastebin.com/raw.php?i=m6pP8ctM'); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); $strCorpus = curl_exec($ch); curl_close($ch);  // Load Tweets as Array $arrCorpus = explode(\"\\n\", $strCorpus); foreach ($arrCorpus as $k => $v) {     // init     $blnActualClass = substr($v,0,1);     $strTweet = trim(substr($v,2));      // Score Tweet     $intScore = score($strTweet);      // Build Confusion Matrix and Log False Positives & Negatives for Review     if ($intScore > 0) {         if ($blnActualClass == 1) {             // True Positive             $tp++;         } else {             // False Positive             $fp++;             $arrFP[] = $strTweet;         }     } else {         if ($blnActualClass == 1) {             // False Negative             $fn++;             $arrFN[] = $strTweet;         } else {             // True Negative             $tn++;         }     } }  // Confusion Matrix and Logging echo \"            Predicted             1     0 Actual 1   $tp     $fp Actual 0    $fn    $tn  \";  if (count($arrFP) > 0) {     echo \"\\n\\nFalse Positives\\n\";     foreach ($arrFP as $strTweet) {         echo \"$strTweet\\n\";     } }  if (count($arrFN) > 0) {     echo \"\\n\\nFalse Negatives\\n\";     foreach ($arrFN as $strTweet) {         echo \"$strTweet\\n\";     } }  function LoadDictionaryArray() {     $strDictionary = <<<EOD 10|iTunes 10|ios 7 10|ios7 10|iPhone 10|apple inc 10|apple corp 10|apple.com 10|MacBook 10|desk top 10|desktop 1|config 1|facebook 1|snapchat 1|intel 1|investor 1|news 1|labs 1|gadget 1|apple store 1|microsoft 1|android 1|bonds 1|Corp.tax 1|macs -1|pie -1|clientes -1|green apple -1|banana -10|apple pie EOD;      $arrDictionary = explode(\"\\n\", $strDictionary);     foreach ($arrDictionary as $k => $v) {         $arr = explode('|', $v);         $arrDictionary[$k] = array('value' => $arr[0], 'term' => strtolower(trim($arr[1])));     }     return $arrDictionary; }  function score($str) {     $str = strtolower($str);     $intScore = 0;     foreach (LoadDictionaryArray() as $arrDictionaryItem) {         if (strpos($str,$arrDictionaryItem['term']) !== false) {             $intScore += $arrDictionaryItem['value'];         }     }     return $intScore; } ?>   The above outputs:             Predicted             1     0 Actual 1   31     1 Actual 0    1    17   False Positives 1|Royals apple #ASGame @mlb @ News Corp Building http://instagram.com/p/bBzzgMrrIV/   False Negatives -1|RT @MaxFreixenet: Apple no tiene clientes. Tiene FANS// error.... PAGAS por productos y apps, ergo: ERES CLIENTE.      ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  In all the examples that you gave, Apple(inc) was either referred to as Apple or apple inc, so a possible way could be to search for:   a capital \"A\" in Apple an \"inc\" after apple words/phrases like \"OS\", \"operating system\", \"Mac\", \"iPhone\", ... or a combination of them      ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  To simplify answers based on Conditional Random Fields a bit...context is huge here. You will want to pick out in those tweets that clearly show Apple the company vs apple the fruit. Let me outline a list of features here that might be useful for you to start with. For more information look up noun phrase chunking, and something called BIO labels. See (http://www.cis.upenn.edu/~pereira/papers/crf.pdf)   Surrounding words: Build a feature vector for the previous word and the next word, or if you want more features perhaps the previous 2 and next 2 words. You don't want too many words in the model or it won't match the data very well.  In Natural Language Processing, you are going to want to keep this as general as possible.  Other features to get from surrounding words include the following:  Whether the first character is a capital  Whether the last character in the word is a period  The part of speech of the word (Look up part of speech tagging)  The text itself of the word  I don't advise this, but to give more examples of features specifically for Apple:  WordIs(Apple)  NextWordIs(Inc.)  You get the point. Think of Named Entity Recognition as describing a sequence, and then using some math to tell a computer how to calculate that.  Keep in mind that natural language processing is a pipeline based system. Typically, you break things in to sentences, move to tokenization, then do part of speech tagging or even dependency parsing.  This is all to get you a list of features you can use in your model to identify what you're looking for.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  There's a really good library for processing natural language text in Python called nltk. You should take a look at it.   One strategy you could try is to look at n-grams (groups of words) with the word \"apple\" in them. Some words are more likely to be used next to \"apple\" when talking about the fruit, others when talking about the company, and you can use those to classify tweets.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  Use LibShortText. This Python utility has already been tuned to work for short text categorization tasks, and it works well. The maximum you'll have to do is to write a loop to pick the best combination of flags. I used it to do supervised speech act classification in emails and the results were up to 95-97% accurate (during 5 fold cross validation!).  And it comes from the makers of LIBSVM and LIBLINEAR whose support vector machine (SVM) implementation is used in sklearn and cran, so you can be reasonably assured that their implementation is not buggy.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?","A_Content":"  Make an AI filter to distinguish Apple Inc (the company) from apple (the fruit). Since these are tweets, define your training set with a vector of 140 fields, each field being the character written in the tweet at position X (0 to 139). If the tweet is shorter, just give a value for being blank.  Then build a training set big enough to get a good accuracy (subjective to your taste). Assign a result value to each tweet, a Apple Inc tweet get 1 (true) and an apple tweet (fruit) gets 0. It would be a case of supervised learning in a logistic regression.  That is machine learning, is generally easier to code and performs better. It has to learn from the set you give it, and it's not hardcoded.  I don't know Python, so I can not write the code for it, but if you were to take more time for machine learning's logic and theory you might want to look the class I'm following.  Try the Coursera course Machine Learning by Andrew Ng. You will learn machine learning on MATLAB or Octave, but once you get the basics you will be able to write machine learning in about any language if you do understand the simple math (simple in logistic regression).  That is, getting the code from someone won't make you able to understand what is going in the machine learning code. You might want to invest a couple of hours on the subject to see what is really going on.     ","Language":"Python","Tags":["java","python","r","machine-learning","classification"],"URL":"https://stackoverflow.com/questions/17352469/how-can-i-build-a-model-to-distinguish-tweets-about-apple-inc-from-tweets-abo","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    See below for 50 tweets about \"apple.\" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.  Here are a couple of lines:  1|@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF . Finally.. A corp iTunes account! 0|@Zach_Paull: When did green skittles change from lime to green apple? #notafan @Skittles 1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No. 0|@STFUTimothy have you tried apple pie shine? 1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay   Here is the total data set: http://pastebin.com/eJuEb4eB  I need to build a model that classifies \"Apple\" (Inc). from the rest.  I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  import inspect  def foo(a, b, x='blah'):     pass  print(inspect.getargspec(foo)) # ArgSpec(args=['a', 'b', 'x'], varargs=None, keywords=None, defaults=('blah',))   However, note that inspect.getargspec() is deprecated since Python 3.0.  Python 3.0--3.4 recommends inspect.getfullargspec().  Python 3.5+ recommends inspect.signature().     ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"130","_type":"dict","isAccepted":"Yes","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  Arguably the easiest way to find the signature for a function would be help(function):  >>> def function(arg1, arg2=\"foo\", *args, **kwargs): pass >>> help(function) Help on function function in module __main__:  function(arg1, arg2='foo', *args, **kwargs)   Also, in Python 3 a method was added to the inspect module called signature, which is designed to represent the signature of a callable object and its return annotation:  >>> from inspect import signature >>> def foo(a, *, b:int, **kwargs): ...     pass  >>> sig = signature(foo)  >>> str(sig) '(a, *, b:int, **kwargs)'  >>> str(sig.parameters['b']) 'b:int'  >>> sig.parameters['b'].annotation <class 'int'>      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  #! /usr/bin/env python  import inspect from collections import namedtuple  DefaultArgSpec = namedtuple('DefaultArgSpec', 'has_default default_value')  def _get_default_arg(args, defaults, arg_index):     \"\"\" Method that determines if an argument has default value or not,     and if yes what is the default value for the argument      :param args: array of arguments, eg: ['first_arg', 'second_arg', 'third_arg']     :param defaults: array of default values, eg: (42, 'something')     :param arg_index: index of the argument in the argument array for which,     this function checks if a default value exists or not. And if default value     exists it would return the default value. Example argument: 1     :return: Tuple of whether there is a default or not, and if yes the default     value, eg: for index 2 i.e. for \"second_arg\" this function returns (True, 42)     \"\"\"     if not defaults:         return DefaultArgSpec(False, None)      args_with_no_defaults = len(args) - len(defaults)      if arg_index < args_with_no_defaults:         return DefaultArgSpec(False, None)     else:         value = defaults[arg_index - args_with_no_defaults]         if (type(value) is str):             value = '\"%s\"' % value         return DefaultArgSpec(True, value)  def get_method_sig(method):     \"\"\" Given a function, it returns a string that pretty much looks how the     function signature would be written in python.      :param method: a python method     :return: A string similar describing the pythong method signature.     eg: \"my_method(first_argArg, second_arg=42, third_arg='something')\"     \"\"\"      # The return value of ArgSpec is a bit weird, as the list of arguments and     # list of defaults are returned in separate array.     # eg: ArgSpec(args=['first_arg', 'second_arg', 'third_arg'],     # varargs=None, keywords=None, defaults=(42, 'something'))     argspec = inspect.getargspec(method)     arg_index=0     args = []      # Use the args and defaults array returned by argspec and find out     # which arguments has default     for arg in argspec.args:         default_arg = _get_default_arg(argspec.args, argspec.defaults, arg_index)         if default_arg.has_default:             args.append(\"%s=%s\" % (arg, default_arg.default_value))         else:             args.append(arg)         arg_index += 1     return \"%s(%s)\" % (method.__name__, \", \".join(args))   if __name__ == '__main__':     def my_method(first_arg, second_arg=42, third_arg='something'):         pass      print get_method_sig(my_method)     # my_method(first_argArg, second_arg=42, third_arg=\"something\")      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  Try calling help on an object to find out about it.  >>> foo = [1, 2, 3] >>> help(foo.append) Help on built-in function append:  append(...)     L.append(object) -- append object to end      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  Maybe a bit late to the party, but if you also want to keep the order of the arguments and their defaults, then you can use the Abstract Syntax Tree module (ast).  Here's a proof of concept (beware the code to sort the arguments and match them to their defaults can definitely be improved/made more clear):  import ast  for class_ in [c for c in module.body if isinstance(c, ast.ClassDef)]:     for method in [m for m in class_.body if isinstance(m, ast.FunctionDef)]:         args = []         if method.args.args:             [args.append([a.col_offset, a.id]) for a in method.args.args]         if method.args.defaults:             [args.append([a.col_offset, '=' + a.id]) for a in method.args.defaults]         sorted_args = sorted(args)         for i, p in enumerate(sorted_args):             if p[1].startswith('='):                 sorted_args[i-1][1] += p[1]         sorted_args = [k[1] for k in sorted_args if not k[1].startswith('=')]          if method.args.vararg:             sorted_args.append('*' + method.args.vararg)         if method.args.kwarg:             sorted_args.append('**' + method.args.kwarg)          signature = '(' + ', '.join(sorted_args) + ')'          print method.name + signature      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  If all you're trying to do is print the function then use pydoc.  import pydoc      def foo(arg1, arg2, *args, **kwargs):                                                                         '''Some foo fn'''                                                                                         pass                                                                                                   >>> print pydoc.render_doc(foo).splitlines()[2] foo(arg1, arg2, *args, **kwargs)   If you're trying to actually analyze the function signature then use argspec of the inspection module. I had to do that when validating a user's hook script function into a general framework.     ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  Use %pdef in the command line (IPython), it will print only the signature.  e.g. %pdef np.loadtxt   np.loadtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding='bytes')      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I read a function's signature including default argument values?","A_Content":"  Example code:  import inspect from collections import OrderedDict   def get_signature(fn):     params = inspect.signature(fn).parameters     args = []     kwargs = OrderedDict()     for p in params.values():         if p.default is p.empty:             args.append(p.name)         else:             kwargs[p.name] = p.default     return args, kwargs   def test_sig():     def fn(a, b, c, d=3, e=\"abc\"):         pass      assert get_signature(fn) == (         [\"a\", \"b\", \"c\"], OrderedDict([(\"d\", 3), (\"e\", \"abc\")])     )      ","Language":"Python","Tags":["python","arguments","inspect"],"URL":"https://stackoverflow.com/questions/2677185/how-can-i-read-a-functions-signature-including-default-argument-values","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Given a function object, how can I get its signature? For example, for:  def myMethod(firt, second, third='something'):     pass   I would like to get \"myMethod(firt, second, third='something')\".     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Hard one :-)  import email, getpass, imaplib, os  detach_dir = '.' # directory where to save attachments (default: current) user = raw_input(\"Enter your GMail username:\") pwd = getpass.getpass(\"Enter your password: \")  # connecting to the gmail imap server m = imaplib.IMAP4_SSL(\"imap.gmail.com\") m.login(user,pwd) m.select(\"[Gmail]/All Mail\") # here you a can choose a mail box like INBOX instead # use m.list() to get all the mailboxes  resp, items = m.search(None, \"ALL\") # you could filter using the IMAP rules here (check http://www.example-code.com/csharp/imap-search-critera.asp) items = items[0].split() # getting the mails id  for emailid in items:     resp, data = m.fetch(emailid, \"(RFC822)\") # fetching the mail, \"`(RFC822)`\" means \"get the whole stuff\", but you can ask for headers only, etc     email_body = data[0][1] # getting the mail content     mail = email.message_from_string(email_body) # parsing the mail content to get a mail object      #Check if any attachments at all     if mail.get_content_maintype() != 'multipart':         continue      print \"[\"+mail[\"From\"]+\"] :\" + mail[\"Subject\"]      # we use walk to create a generator so we can iterate on the parts and forget about the recursive headach     for part in mail.walk():         # multipart are just containers, so we skip them         if part.get_content_maintype() == 'multipart':             continue          # is this part an attachment ?         if part.get('Content-Disposition') is None:             continue          filename = part.get_filename()         counter = 1          # if there is no filename, we create one with a counter to avoid duplicates         if not filename:             filename = 'part-%03d%s' % (counter, 'bin')             counter += 1          att_path = os.path.join(detach_dir, filename)          #Check if its already there         if not os.path.isfile(att_path) :             # finally write the stuff             fp = open(att_path, 'wb')             fp.write(part.get_payload(decode=True))             fp.close()   Wowww! That was something. ;-) But try the same in Java, just for fun!  By the way, I tested that in a shell, so some errors likely remain.  Enjoy  EDIT:  Because mail-box names can change from one country to another, I recommend doing m.list() and picking an item in it before m.select(\"the mailbox name\") to avoid this error:     imaplib.error: command SEARCH illegal in state AUTH, only allowed in   states SELECTED      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"148","_type":"dict","isAccepted":"Yes","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  I'm not an expert on Perl, but what I do know is that GMail supports IMAP and POP3, 2 protocols that are completely standard and allow you to do just that.   Maybe that helps you to get started.      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  #!/usr/bin/env python \"\"\"Save all attachments for given gmail account.\"\"\" import os, sys from libgmail import GmailAccount  ga = GmailAccount(\"your.account@gmail.com\", \"pA$$w0Rd_\") ga.login()  # folders: inbox, starred, all, drafts, sent, spam for thread in ga.getMessagesByFolder('all', allPages=True):     for msg in thread:         sys.stdout.write('.')         if msg.attachments:            print \"\\n\", msg.id, msg.number, msg.subject, msg.sender            for att in msg.attachments:                if att.filename and att.content:                   attdir = os.path.join(thread.id, msg.id)                   if not os.path.isdir(attdir):                      os.makedirs(attdir)                                   with open(os.path.join(attdir, att.filename), 'wb') as f:                        f.write(att.content)   untested   Make sure TOS allows such scripts otherwise you account will be suspended There might be better options: GMail offline mode, Thunderbird + ExtractExtensions, GmailFS, Gmail Drive, etc.      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Take a look at Mail::Webmail::Gmail:  GETTING ATTACHMENTS  There are two ways to get an attachment:  1 -> By sending a reference to a specific attachment returned by get_indv_email  # Creates an array of references to every attachment in your account my $messages = $gmail->get_messages(); my @attachments;  foreach ( @{ $messages } ) {     my $email = $gmail->get_indv_email( msg => $_ );     if ( defined( $email->{ $_->{ 'id' } }->{ 'attachments' } ) ) {         foreach ( @{ $email->{ $_->{ 'id' } }->{ 'attachments' } } ) {             push( @attachments, $gmail->get_attachment( attachment => $_ ) );             if ( $gmail->error() ) {                 print $gmail->error_msg();             }         }     } }   2 -> Or by sending the attachment ID and message ID  #retrieve specific attachment my $msgid = 'F000000000'; my $attachid = '0.1'; my $attach_ref = $gmail->get_attachment( attid => $attachid, msgid => $msgid );   ( Returns a reference to a scalar that holds the data from the attachment. )     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Within gmail, you can filter on \"has:attachment\", use it to identify the messages you should be getting when testing. Note this appears to give both messages with attached files (paperclip icon shown), as well as inline attached images (no paperclip shown).  There is no Gmail API, so IMAP or POP are your only real options. The JavaMail API may be of some assistance as well as this very terse article on downloading attachments from IMAP using Perl. Some previous questions here on SO may also help.  This PHP example may help too. Unfortunately from what I can see, there is no attachment information contained within the imap_header, so downloading the body is required to be able to see the X-Attachment-Id field. (someone please prove me wrong).     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  If any of you have updated to python 3.3 I took the 2.7 script from HERE and updated it to 3.3.  Also fixed some issues with the way gmail was returning the information.  # Something in lines of http://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail # Make sure you have IMAP enabled in your gmail settings. # Right now it won't download same file name twice even if their contents are different. # Gmail as of now returns in bytes but just in case they go back to string this line is left here.  import email import getpass, imaplib import os import sys import time  detach_dir = '.' if 'attachments' not in os.listdir(detach_dir):     os.mkdir('attachments')  userName = input('Enter your GMail username:\\n') passwd = getpass.getpass('Enter your password:\\n')   try:     imapSession = imaplib.IMAP4_SSL('imap.gmail.com',993)     typ, accountDetails = imapSession.login(userName, passwd)     if typ != 'OK':         print ('Not able to sign in!')         raise      imapSession.select('Inbox')     typ, data = imapSession.search(None, 'ALL')     if typ != 'OK':         print ('Error searching Inbox.')         raise      # Iterating over all emails     for msgId in data[0].split():         typ, messageParts = imapSession.fetch(msgId, '(RFC822)')          if typ != 'OK':             print ('Error fetching mail.')             raise           #print(type(emailBody))         emailBody = messageParts[0][1]         #mail = email.message_from_string(emailBody)         mail = email.message_from_bytes(emailBody)          for part in mail.walk():             #print (part)             if part.get_content_maintype() == 'multipart':                 # print part.as_string()                 continue             if part.get('Content-Disposition') is None:                 # print part.as_string()                 continue              fileName = part.get_filename()              if bool(fileName):                 filePath = os.path.join(detach_dir, 'attachments', fileName)                 if not os.path.isfile(filePath) :                     print (fileName)                     fp = open(filePath, 'wb')                     fp.write(part.get_payload(decode=True))                     fp.close()      imapSession.close()     imapSession.logout()  except :     print ('Not able to download all attachments.')     time.sleep(3)      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  The question is quite old and at that time Gmail API was not available.  But now Google provides Gmail API to access IMAP.  See Google's Gmail API here. Also see google-api-python-client on pypi.     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  /*based on http://www.codejava.net/java-ee/javamail/using-javamail-for-searching-e-mail-messages*/ package getMailsWithAtt;  import java.io.File; import java.io.IOException; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Properties;  import javax.mail.Address; import javax.mail.Folder; import javax.mail.Message; import javax.mail.MessagingException; import javax.mail.Multipart; import javax.mail.NoSuchProviderException; import javax.mail.Part; import javax.mail.Session; import javax.mail.Store; import javax.mail.internet.MimeBodyPart; import javax.mail.search.AndTerm; import javax.mail.search.SearchTerm; import javax.mail.search.ReceivedDateTerm; import javax.mail.search.ComparisonTerm;  public class EmailReader {     private String saveDirectory;      /**      * Sets the directory where attached files will be stored.      *       * @param dir      *            absolute path of the directory      */     public void setSaveDirectory(String dir) {         this.saveDirectory = dir;     }      /**      * Downloads new messages and saves attachments to disk if any.      *       * @param host      * @param port      * @param userName      * @param password      * @throws IOException      */     public void downloadEmailAttachments(String host, String port,             String userName, String password, Date startDate, Date endDate) {         Properties props = System.getProperties();         props.setProperty(\"mail.store.protocol\", \"imaps\");         try {             Session session = Session.getDefaultInstance(props, null);             Store store = session.getStore(\"imaps\");             store.connect(\"imap.gmail.com\", userName, password);             // ...             Folder inbox = store.getFolder(\"INBOX\");             inbox.open(Folder.READ_ONLY);             SearchTerm olderThan = new ReceivedDateTerm (ComparisonTerm.LT, startDate);             SearchTerm newerThan = new ReceivedDateTerm (ComparisonTerm.GT, endDate);             SearchTerm andTerm = new AndTerm(olderThan, newerThan);             //Message[] arrayMessages = inbox.getMessages(); <--get all messages             Message[] arrayMessages = inbox.search(andTerm);             for (int i = arrayMessages.length; i > 0; i--) { //from newer to older                 Message msg = arrayMessages[i-1];                 Address[] fromAddress = msg.getFrom();                 String from = fromAddress[0].toString();                 String subject = msg.getSubject();                 String sentDate = msg.getSentDate().toString();                 String receivedDate = msg.getReceivedDate().toString();                  String contentType = msg.getContentType();                 String messageContent = \"\";                  // store attachment file name, separated by comma                 String attachFiles = \"\";                  if (contentType.contains(\"multipart\")) {                     // content may contain attachments                     Multipart multiPart = (Multipart) msg.getContent();                     int numberOfParts = multiPart.getCount();                     for (int partCount = 0; partCount < numberOfParts; partCount++) {                         MimeBodyPart part = (MimeBodyPart) multiPart                                 .getBodyPart(partCount);                         if (Part.ATTACHMENT.equalsIgnoreCase(part                                 .getDisposition())) {                             // this part is attachment                             String fileName = part.getFileName();                             attachFiles += fileName + \", \";                             part.saveFile(saveDirectory + File.separator + fileName);                         } else {                             // this part may be the message content                             messageContent = part.getContent().toString();                         }                     }                     if (attachFiles.length() > 1) {                         attachFiles = attachFiles.substring(0,                                 attachFiles.length() - 2);                     }                 } else if (contentType.contains(\"text/plain\")                         || contentType.contains(\"text/html\")) {                     Object content = msg.getContent();                     if (content != null) {                         messageContent = content.toString();                     }                 }                  // print out details of each message                 System.out.println(\"Message #\" + (i + 1) + \":\");                 System.out.println(\"\\t From: \" + from);                 System.out.println(\"\\t Subject: \" + subject);                 System.out.println(\"\\t Received: \" + sentDate);                 System.out.println(\"\\t Message: \" + messageContent);                 System.out.println(\"\\t Attachments: \" + attachFiles);             }              // disconnect             inbox.close(false);             store.close();          } catch (NoSuchProviderException e) {             e.printStackTrace();             System.exit(1);         } catch (MessagingException e) {             e.printStackTrace();             System.exit(2);         } catch (IOException ex) {             ex.printStackTrace();         }     }      /**      * Runs this program with Gmail POP3 server      * @throws ParseException       */     public static void main(String[] args) throws ParseException {         String host = \"pop.gmail.com\";         String port = \"995\";         String userName = \"user@gmail.com\";         String password = \"pass\";         Date startDate = new SimpleDateFormat(\"yyyy-MM-dd\").parse(\"2014-06-30\");         Date endDate = new SimpleDateFormat(\"yyyy-MM-dd\").parse(\"2014-06-01\");         String saveDirectory = \"C:\\\\Temp\";          EmailReader receiver = new EmailReader();         receiver.setSaveDirectory(saveDirectory);         receiver.downloadEmailAttachments(host, port, userName, password,startDate,endDate);      } }   Maven Dependency:  <dependency>     <groupId>com.sun.mail</groupId>     <artifactId>javax.mail</artifactId>     <version>1.5.1</version> </dependency>      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Since Gmail supports the standard protocols POP and IMAP, any platform, tool, application, component, or API that provides the client side of either protocol should work.  I suggest doing a Google search for your favorite language/platform (e.g., \"python\"), plus \"pop\", plus \"imap\", plus perhaps \"open source\", plus perhaps \"download\" or \"review\", and see what you get for options.  There are numerous free applications and components, pick a few that seem worthy, check for reviews, then download and enjoy.     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  You should be aware of the fact that you need SSL to connect to GMail (both for POP3 and IMAP - this is of course true also for their SMTP-servers apart from port 25 but that's another story).     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Here's something I wrote to download my bank statements in Groovy (dynamic language for the Java Platform).  import javax.mail.* import java.util.Properties  String  gmailServer int gmailPort def user, password, LIMIT def inboxFolder, root, StartDate, EndDate   //    Downloads all attachments from a gmail mail box as per some criteria //    to a specific folder //    Based on code from //    http://agileice.blogspot.com/2008/10/using-groovy-to-connect-to-gmail.html //    http://stackoverflow.com/questions/155504/download-mail-attachment-with-java // //    Requires:  //        java mail jars in the class path (mail.jar and activation.jar) //        openssl, with gmail certificate added to java keystore (see agileice blog) //         //    further improvement: maybe findAll could be used to filter messages //    subject could be added as another criteria ////////////////////// <CONFIGURATION> ////////////////////// // Maximm number of emails to access in case parameter range is too high LIMIT = 10000  // gmail credentials gmailServer = \"imap.gmail.com\" gmailPort = 993  user = \"gmailuser@gmail.com\" password = \"gmailpassword\"  // gmail label, or \"INBOX\" for inbox inboxFolder = \"finance\"  // local file system where the attachment files need to be stored root = \"D:\\\\AttachmentStore\"   // date range dd-mm-yyyy StartDate= \"31-12-2009\" EndDate = \"1-6-2010\"  ////////////////////// </CONFIGURATION> //////////////////////  StartDate = Date.parse(\"dd-MM-yyyy\", StartDate) EndDate = Date.parse(\"dd-MM-yyyy\", EndDate)  Properties props = new Properties(); props.setProperty(\"mail.store.protocol\", \"imaps\"); props.setProperty(\"mail.imaps.host\", gmailServer); props.setProperty(\"mail.imaps.port\", gmailPort.toString()); props.setProperty(\"mail.imaps.partialfetch\", \"false\");  def session = javax.mail.Session.getDefaultInstance(props,null) def store = session.getStore(\"imaps\")  store.connect(gmailServer, user, password)  int i = 0; def folder = store.getFolder(inboxFolder)  folder.open(Folder.READ_ONLY)  for(def msg : folder.messages) {       //if (msg.subject?.contains(\"bank Statement\"))      println \"[$i] From: ${msg.from} Subject: ${msg.subject} -- Received: ${msg.receivedDate}\"       if (msg.receivedDate <  StartDate || msg.receivedDate > EndDate) {          println \"Ignoring due to date range\"          continue      }        if (msg.content instanceof Multipart) {          Multipart mp = (Multipart)msg.content;           for (int j=0; j < mp.count; j++) {               Part part = mp.getBodyPart(j);               println \" ---- ${part.fileName} ---- ${part.disposition}\"               if (part.disposition?.equalsIgnoreCase(Part.ATTACHMENT)) {                   if (part.content) {                       def name = msg.receivedDate.format(\"yyyy_MM_dd\") + \" \" + part.fileName                      println \"Saving file to $name\"                       def f = new File(root, name)                       //f << part.content                      try {                          if (!f.exists())                              f << part.content                      }                      catch (Exception e) {                          println \"*** Error *** $e\"                       }                  }                  else {                     println \"NO Content Found!!\"                  }              }          }      }       if (i++ > LIMIT)          break;  }      ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  Have you taken a look at the GMail 3rd party add-ons at wikipedia?  In particular, PhpGmailDrive is an open source add-on that you may be able to use as-is, or perhaps study for inspiration?     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"How can I download all emails with attachments from Gmail?","A_Content":"  For Java, you will find G4J of use. It's a set of APIs to communicate with Google Mail via Java (the screenshot on the homepage is a demonstration email client built around this)     ","Language":"Python","Tags":["java","python","perl","gmail"],"URL":"https://stackoverflow.com/questions/348630/how-can-i-download-all-emails-with-attachments-from-gmail","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  Reflection in python is a lot easier and far more flexible than it is in Java.  I recommend reading this tutorial  There's no direct function (that I know of) which takes a fully qualified class name and returns the class, however you have all the pieces needed to build that, and you can connect them together.  One bit of advice though: don't try to program in Java style when you're in python.  If you can explain what is it that you're trying to do, maybe we can help you find a more pythonic way of doing it.  Here's a function that does what you want:  def get_class( kls ):     parts = kls.split('.')     module = \".\".join(parts[:-1])     m = __import__( module )     for comp in parts[1:]:         m = getattr(m, comp)                 return m   You can use the return value of this function as if it were the class itself.  Here's a usage example:  >>> D = get_class(\"datetime.datetime\") >>> D <type 'datetime.datetime'> >>> D.now() datetime.datetime(2009, 1, 17, 2, 15, 58, 883000) >>> a = D( 2010, 4, 22 ) >>> a datetime.datetime(2010, 4, 22, 0, 0) >>>    How does that work?  We're using __import__ to import the module that holds the class, which required that we first extract the module name from the fully qualified name. Then we import the module:  m = __import__( module )   In this case, m will only refer to the top level module,   For example, if your class lives in foo.baz module, then m will be the module foo We can easily obtain a reference to foo.baz using getattr( m, 'baz' )  To get from the top level module to the class, have to recursively use gettatr on the parts of the class name  Say for example, if you class name is foo.baz.bar.Model then we do this:  m = __import__( \"foo.baz.bar\" ) #m is package foo m = getattr( m, \"baz\" ) #m is package baz m = getattr( m, \"bar\" ) #m is module bar m = getattr( m, \"Model\" ) #m is class Model   This is what's happening in this loop:  for comp in parts[1:]:     m = getattr(m, comp)       At the end of the loop, m will be a reference to the class. This means that m is actually the class itslef, you can do for instance:  a = m() #instantiate a new instance of the class     b = m( arg1, arg2 ) # pass arguments to the constructor      ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"148","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  Assuming the class is in your scope:  globals()['classname'](args, to, constructor)   Otherwise:  getattr(someModule, 'classname')(args, to, constructor)   Edit:  Note, you can't give a name like 'foo.bar' to getattr.  You'll need to split it by . and call getattr() on each piece left-to-right.  This will handle that:  module, rest = 'foo.bar.baz'.split('.', 1) fooBar = reduce(lambda a, b: getattr(a, b), rest.split('.'), globals()[module]) someVar = fooBar(args, to, constructor)      ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  def import_class_from_string(path):     from importlib import import_module     module_path, _, class_name = path.rpartition('.')     mod = import_module(module_path)     klass = getattr(mod, class_name)     return klass   Usage  In [59]: raise import_class_from_string('google.appengine.runtime.apiproxy_errors.DeadlineExceededError')() --------------------------------------------------------------------------- DeadlineExceededError                     Traceback (most recent call last) <ipython-input-59-b4e59d809b2f> in <module>() ----> 1 raise import_class_from_string('google.appengine.runtime.apiproxy_errors.DeadlineExceededError')()  DeadlineExceededError:       ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  Yet another implementation.  def import_class(class_string):     \"\"\"Returns class object specified by a string.      Args:         class_string: The string representing a class.      Raises:         ValueError if module part of the class is not specified.     \"\"\"     module_name, _, class_name = class_string.rpartition('.')     if module_name == '':         raise ValueError('Class name must contain module part.')     return getattr(         __import__(module_name, globals(), locals(), [class_name], -1),         class_name)      ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  It seems you're approaching this from the middle instead of the beginning. What are you really trying to do? Finding the class associated with a given string is a means to an end.  If you clarify your problem, which might require your own mental refactoring, a better solution may present itself.  For instance: Are you trying to load a saved object based on its type name and a set of parameters? Python spells this unpickling and you should look at the pickle module. And even though the unpickling process does exactly what you describe, you don't have to worry about how it works internally:  >>> class A(object): ...   def __init__(self, v): ...     self.v = v ...   def __reduce__(self): ...     return (self.__class__, (self.v,)) >>> a = A(\"example\") >>> import pickle >>> b = pickle.loads(pickle.dumps(a)) >>> a.v, b.v ('example', 'example') >>> a is b False      ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"Does python have an equivalent to Java Class.forName()?","A_Content":"  This is found in the python standard library, as unittest.TestLoader.loadTestsFromName. Unfortunately the method goes on to do additional test-related activities, but this first ha looks re-usable. I've edited it to remove the test-related functionality:  def get_object(name):     \"\"\"Retrieve a python object, given its dotted.name.\"\"\"     parts = name.split('.')     parts_copy = parts[:]     while parts_copy:         try:             module = __import__('.'.join(parts_copy))             break         except ImportError:             del parts_copy[-1]             if not parts_copy: raise     parts = parts[1:]      obj = module     for part in parts:         parent, obj = obj, getattr(obj, part)      return obj      ","Language":"Python","Tags":["java","python","class","instantiation"],"URL":"https://stackoverflow.com/questions/452969/does-python-have-an-equivalent-to-java-class-forname","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have the need to take a string argument and create an object of the class named in that string in Python.  In Java, I would use Class.forName().newInstance().  Is there an equivalent in Python?    Thanks for the responses.  To answer those who want to know what I'm doing: I want to use a command line argument as the class name, and instantiate it.  I'm actually programming in Jython and instantiating Java classes, hence the Java-ness of the question.  getattr() works great.  Thanks much.     ","Q_Votes":"82"},{"Q_Title":"How to construct a set out of list items in python?","A_Content":"  If you have a list of hashable objects (filenames would probably be strings, so they should count):  lst = ['foo.py', 'bar.py', 'baz.py', 'qux.py', Ellipsis]   you can construct the set directly:  s = set(lst)   In fact, set will work this way with any iterable object!  (Isn't duck typing great?)    If you want to do it iteratively:  s = set() for item in iterable:     s.add(item)   But there's rarely a need to do it this way.  I only mention it because the set.add method is quite useful.     ","Language":"Python","Tags":["python","list","set"],"URL":"https://stackoverflow.com/questions/15768757/how-to-construct-a-set-out-of-list-items-in-python","A_Votes":"176","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a list of filenames in python and I would want to construct a set out of all the filenames.  filelist=[] for filename in filelist:     set(filename)   This does not seem to work. How can do this?     ","Q_Votes":"82"},{"Q_Title":"How to construct a set out of list items in python?","A_Content":"  The most direct solution is this:   s = set(filelist)   The issue in your original code is that the values weren't being assigned to the set.  Here's the fixed-up version of your code:   s = set()  for filename in filelist:      s.add(filename)  print(s)      ","Language":"Python","Tags":["python","list","set"],"URL":"https://stackoverflow.com/questions/15768757/how-to-construct-a-set-out-of-list-items-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of filenames in python and I would want to construct a set out of all the filenames.  filelist=[] for filename in filelist:     set(filename)   This does not seem to work. How can do this?     ","Q_Votes":"82"},{"Q_Title":"How to construct a set out of list items in python?","A_Content":"  Here is another solution:  >>>list1=[\"C:\\\\\",\"D:\\\\\",\"E:\\\\\",\"C:\\\\\"] >>>set1=set(list1) >>>set1 set(['E:\\\\', 'D:\\\\', 'C:\\\\'])   In this code I have used the set method in order to turn it into a set and then it removed all duplicate values from the list     ","Language":"Python","Tags":["python","list","set"],"URL":"https://stackoverflow.com/questions/15768757/how-to-construct-a-set-out-of-list-items-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of filenames in python and I would want to construct a set out of all the filenames.  filelist=[] for filename in filelist:     set(filename)   This does not seem to work. How can do this?     ","Q_Votes":"82"},{"Q_Title":"How to construct a set out of list items in python?","A_Content":"  You can do  my_set = set(my_list)   or, for Python 3,  my_set = {*my_list}   to create a set from a list. Conversely, you can also do  my_list = list(my_set)   or, for Python 3,  my_list = [*my_set]   to create a list from a set.  Just note that the order of the elements in a list is generally lost when converting the list to a set since a set is inherently unordered. (One exception in CPython, though, seems to be if the list consists only of non-negative integers, but I assume this is a consequence of the implementation of sets in CPython and that this behavior can vary between different Python implementations.)     ","Language":"Python","Tags":["python","list","set"],"URL":"https://stackoverflow.com/questions/15768757/how-to-construct-a-set-out-of-list-items-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of filenames in python and I would want to construct a set out of all the filenames.  filelist=[] for filename in filelist:     set(filename)   This does not seem to work. How can do this?     ","Q_Votes":"82"},{"Q_Title":"Root mean square error in python","A_Content":"  sklearn.metrics has a mean_squared_error function. The RMSE is just the square root of whatever it returns.  from sklearn.metrics import mean_squared_error from math import sqrt  rms = sqrt(mean_squared_error(y_actual, y_predicted))      ","Language":"Python","Tags":["python","scipy"],"URL":"https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python","A_Votes":"114","_type":"dict","isAccepted":"No","Q_Content":"    I know I could implement a root mean squared error function like this:  def rmse(predictions, targets):     return np.sqrt(((predictions - targets) ** 2).mean())   What I'm looking for if this rmse function is implemented in a library somewhere, perhaps in scipy or scikit-learn?     ","Q_Votes":"82"},{"Q_Title":"Root mean square error in python","A_Content":"  What is RMSE?  Also known as MSE or RMS.  What problem does it solve?  If you understand RMSE: (Root mean squared error), MSE: (Mean Squared Error) and RMS: (Root Mean Squared), then asking for a library to calculate it for you is unnecessary over-engineering.  All these metrics are a single line of python code at most 2 inches long.  The three metrics rmse, mse and rms are all conceptually identical.  RMSE answers the question: \"How similar, on average, are the numbers in list1 to list2?\".  The two lists must be the same size.  I want to \"wash out the noise between any two given elements, wash out the size of the data collected, and get a single number feel for change over time\".   Intuition and ELI5 for RMSE:  Imagine you are learning to throw darts at a dart board.  Every day you practice for one hour.  You want to figure out if you are getting better or getting worse.  So every day you make 10 throws and measure the distance between the bullseye and where your dart hit.  You make a list of those numbers.  Use the root mean squared error between the distances at day 1 and a list containing all zeros.  Do the same on the 2nd and nth days.  What you will get is a single number that hopefully decreases over time.  When your RMSE number is zero, you hit bullseyes every time.  If the number goes up, you are getting worse.  Example in calculating root mean squared error in python:  import numpy as np d = [0.000, 0.166, 0.333] p = [0.000, 0.254, 0.998]  print(\"d is: \" + str([\"%.8f\" % elem for elem in d])) print(\"p is: \" + str([\"%.8f\" % elem for elem in p]))  def rmse(predictions, targets):     return np.sqrt(((predictions - targets) ** 2).mean())  rmse_val = rmse(np.array(d), np.array(p)) print(\"rms error is: \" + str(rmse_val))   Which prints:  d is: ['0.00000000', '0.16600000', '0.33300000'] p is: ['0.00000000', '0.25400000', '0.99800000'] rms error between lists d and p is: 0.387284994115   The mathematical notation:    The rmse done in small steps so it can be understood:  def rmse(predictions, targets):      differences = predictions - targets                       #the DIFFERENCEs.      differences_squared = differences ** 2                    #the SQUAREs of ^      mean_of_differences_squared = differences_squared.mean()  #the MEAN of ^      rmse_val = np.sqrt(mean_of_differences_squared)           #ROOT of ^      return rmse_val                                           #get the ^   How does every step of RMSE work:  Subtracting one number from another gives you the distance between them.  8 - 5 = 3         #distance between 8 and 5 is 3 -20 - 10 = -30    #distance between -20 and 10 is +30   If you multiply any number times itself, the result is always positive because negative times negative is positive:    3*3     = 9   = positive -30*-30 = 900 = positive   Add them all up, but wait, then an array with many elements would have a larger error than a small array, so average them by the number of elements.  But wait, we squared them all earlier to force them positive.  Undo the damage with a square root!    That leaves you with a single number that represents, on average, the distance between every value of list1 to it's corresponding element value of list2.  If the RMSE value goes down over time we are happy because variance is decreasing.  RMSE isn't the most accurate line fitting strategy, total least squares is:  Root mean squared error measures the vertical distance between the point and the line, so if your data is shaped like a banana, flat near the bottom and steep near the top, then the RMSE will report greater distances to points high, but short distances to points low when in fact the distances are equivalent. This causes a skew where the line prefers to be closer to points high than low.  If this is a problem the total least squares method fixes this: https://mubaris.com/2017-09-28/linear-regression-from-scratch  Gotchas that can break this RMSE function:  If there are nulls or infinity in either input list, then output rmse value is is going to not make sense.  There are three strategies to deal with nulls / missing values / infinities in either list: Ignore that component, zero it out or add a best guess or a uniform random noise to all timesteps.  Each remedy has its pros and cons depending on what your data means.  In general ignoring any component with a missing value is preferred, but this biases the RMSE toward zero making you think performance has improved when it really hasn't.  Adding random noise on a best guess could be preferred if there are lots of missing values.    In order to guarantee relative correctness of the RMSE output, you must eliminate all nulls/infinites from the input.  RMSE has zero tolerance for outlier data points which don't belong  Root mean squared error squares relies on all data being right and all are counted as equal.  That means one stray point that's way out in left field is going to totally ruin the whole calculation.  To handle outlier data points and dismiss their tremendous influence after a certain threshold, see Robust estimators that build in a threshold for dismissal of outliers.     ","Language":"Python","Tags":["python","scipy"],"URL":"https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python","A_Votes":"60","_type":"dict","isAccepted":"No","Q_Content":"    I know I could implement a root mean squared error function like this:  def rmse(predictions, targets):     return np.sqrt(((predictions - targets) ** 2).mean())   What I'm looking for if this rmse function is implemented in a library somewhere, perhaps in scipy or scikit-learn?     ","Q_Votes":"82"},{"Q_Title":"Root mean square error in python","A_Content":"  This is probably faster?:  n = len(predictions) rmse = np.linalg.norm(predictions - targets) / np.sqrt(n)      ","Language":"Python","Tags":["python","scipy"],"URL":"https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I know I could implement a root mean squared error function like this:  def rmse(predictions, targets):     return np.sqrt(((predictions - targets) ** 2).mean())   What I'm looking for if this rmse function is implemented in a library somewhere, perhaps in scipy or scikit-learn?     ","Q_Votes":"82"},{"Q_Title":"Root mean square error in python","A_Content":"  Actually, I did write a bunch of those as utility functions for statsmodels  http://statsmodels.sourceforge.net/devel/tools.html#measure-for-fit-performance-eval-measures  and  http://statsmodels.sourceforge.net/devel/generated/statsmodels.tools.eval_measures.rmse.html#statsmodels.tools.eval_measures.rmse  Mostly one or two liners and not much input checking, and mainly intended for easily getting some statistics when comparing arrays. But they have unit tests for the axis arguments, because that's where I sometimes make sloppy mistakes.     ","Language":"Python","Tags":["python","scipy"],"URL":"https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I know I could implement a root mean squared error function like this:  def rmse(predictions, targets):     return np.sqrt(((predictions - targets) ** 2).mean())   What I'm looking for if this rmse function is implemented in a library somewhere, perhaps in scipy or scikit-learn?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  str.split complements str.join, so  \"/\".join(['', 'segment', 'segment', ''])   gets you back the original string.  If the empty strings were not there, the first and last '/' would be missing after the join()     ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"127","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  There are two main points to consider here:   Expecting the result of '/segment/segment/'.split('/') to be equal to ['segment', 'segment'] is reasonable, but then this loses information.  If split() worked the way you wanted, if I tell you that a.split('/') == ['segment', 'segment'], you can't tell me what a was. What should be the result of 'a//b'.split() be? ['a', 'b']?, or ['a', '', 'b']? I.e., should split() merge adjacent delimiters?  If it should, then it will be very hard to parse data that's delimited by a character, and some of the fields can be empty.  I am fairly sure there are many people who do want the empty values in the result for the above case!   In the end, it boils down to two things:  Consistency: if I have n delimiters, in a, I get n+1 values back after the split().  It should be possible to do complex things, and easy to do simple things: if you want to ignore empty strings as a result of the split(), you can always do:  def mysplit(s, delim=None):     return [x for x in s.split(delim) if x]   but if one doesn't want to ignore the empty values, one should be able to.  The language has to pick one definition of split()there are too many different use cases to satisfy everyone's requirement as a default.  I think that Python's choice is a good one, and is the most logical.  (As an aside, one of the reasons I don't like C's strtok() is because it merges adjacent delimiters, making it extremely hard to do serious parsing/tokenization with it.)  There is one exception: a.split() without an argument squeezes consecutive white-space, but one can argue that this is the right thing to do in that case.  If you don't want the behavior, you can always to a.split(' ').     ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  More generally, to remove empty strings returned in split() results, you may want to look at the filter function.   Example:  filter(None, '/segment/segment/'.split('/'))   returns  ['segment', 'segment']      ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  Having x.split(y) always return a list of 1 + x.count(y) items is a precious regularity -- as @gnibbler's already pointed out it makes split and join exact inverses of each other (as they obviously should be), it also precisely maps the semantics of all kinds of delimiter-joined records (such as csv file lines [[net of quoting issues]], lines from /etc/group in Unix, and so on), it allows (as @Roman's answer mentioned) easy checks for (e.g.) absolute vs relative paths (in file paths and URLs), and so forth.  Another way to look at it is that you shouldn't wantonly toss information out of the window for no gain.  What would be gained in making x.split(y) equivalent to x.strip(y).split(y)?  Nothing, of course -- it's easy to use the second form when that's what you mean, but if the first form was arbitrarily deemed to mean the second one, you'd have lot of work to do when you do want the first one (which is far from rare, as the previous paragraph points out).  But really, thinking in terms of mathematical regularity is the simplest and most general way you can teach yourself to design passable APIs.  To take a different example, it's very important that for any valid x and y x == x[:y] + x[y:] -- which immediately indicates why one extreme of a slicing should be excluded.  The simpler the invariant assertion you can formulate, the likelier it is that the resulting semantics are what you need in real life uses -- part of the mystical fact that maths is very useful in dealing with the universe.    Try formulating the invariant for a split dialect in which leading and trailing delimiters are special-cased... counter-example: string methods such as isspace are not maximally simple -- x.isspace() is equivalent to x and all(c in string.whitespace for c in x) -- that silly leading x and is why you so often find yourself coding not x or x.isspace(), to get back to the simplicity which should have been designed into the is... string methods (whereby an empty string \"is\" anything you want -- contrary to man-in-the-street horse-sense, maybe [[empty sets, like zero &c, have always confused most people;-)]], but fully conforming to obvious well-refined mathematical common-sense!-).     ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  I'm not sure what kind of answer you're looking for?  You get three matches because you have three delimiters.  If you don't want that empty one, just use:  '/segment/segment/'.strip('/').split('/')      ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"Why are empty strings returned in split() results?","A_Content":"  Well, it lets you know there was a delimiter there. So, seeing 4 results lets you know you had 3 delimiters. This gives you the power to do whatever you want with this information, rather than having Python drop the empty elements, and then making you manually check for starting or ending delimiters if you need to know it.  Simple example: Say you want to check for absolute vs. relative filenames. This way you can do it all with the split, without also having to check what the first character of your filename is.     ","Language":"Python","Tags":["python","string","split"],"URL":"https://stackoverflow.com/questions/2197451/why-are-empty-strings-returned-in-split-results","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What is the point of '/segment/segment/'.split('/') returning ['', 'segment', 'segment', '']?  Notice the empty elements. If you're splitting on a delimiter that happens to be at position one and at the very end of a string, what extra value does it give you to have the empty string returned from each end?     ","Q_Votes":"82"},{"Q_Title":"deciding among subprocess, multiprocessing, and thread in Python?","A_Content":"  multiprocessing is a great Swiss-army knife type of module.  It is more general than threads, as you can even perform remote computations.  This is therefore the module I would suggest you use.  The subprocess module would also allow you to launch multiple processes, but I found it to be less convenient to use than the new multiprocessing module.  Threads are notoriously subtle, and, with CPython, you are often limited to one core, with them (even though, as noted in one of the comments, the Global Interpreter Lock (GIL) can be released in C code called from Python code).  I believe that most of the functions of the three modules you cite can be used in a platform-independent way.  On the portability side, note that multiprocessing only comes in standard since Python 2.6 (a version for some older versions of Python does exist, though).  But it's a great module!     ","Language":"Python","Tags":["python","multithreading","parallel-processing"],"URL":"https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    I'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.  Portability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.  Any thoughts on this?  I'd like the simplest solution that's portable.     ","Q_Votes":"82"},{"Q_Title":"deciding among subprocess, multiprocessing, and thread in Python?","A_Content":"  For me this is actually pretty simple:  The subprocess option:  subprocess is for running other executables --- it's basically a wrapper around os.fork() and os.execve() with some support for optional plumbing (setting up PIPEs to and from the subprocesses.  (Obviously other inter-process communications (IPC) mechanisms, such as sockets, SysV shared memory and message queues could be used --- but you're going to be limited to whatever interfaces and IPC channels are supported by the programs you're calling).  Commonly one uses subprocess synchronously --- simply calling some external utility and reading back its output or awaiting its completion (perhaps reading its results from a temporary file, or after it's posted them to some database).  However one can spawn hundreds of subprocesses and poll them.  My own personal favorite utility classh does exactly that.  The biggest disadvantage of the subprocess module is that its I/O support is generally blocking.  There is a draft PEP-3145 to fix that in some future version of Python 3.x and an alternative asyncproc (Warning that leads right to the download, not to any sort of documentation nor README).  I've also found that it's relatively easy to just import fcntl and manipulate your Popen PIPE file descriptors directly --- though I don't know if this is portable to non-UNIX platforms.  subprocess has almost no event handling support ... though you can use the signal module and plain old-school UNIX/Linux signals --- killing your processes softly, as it were.  The multiprocessing option:  multiprocessing is for running functions within your existing (Python) code with support for more flexible communications among this family of processes.  In particular it's best to build your multiprocessing IPC around the module's Queue objects where possible, but you can also use Event objects and various other features (some of which are, presumably, built around mmap support on the platforms where that support is sufficient).  Python's multiprocessing module is intended to provide interfaces and features which are very similar to threading while allowing CPython to scale your processing among multiple CPUs/cores despite the GIL (Global Interpreter Lock).  It leverages all the fine-grained SMP locking and coherency effort that was done by developers of your OS kernel.  The threading option:  threading is for a fairly narrow range of applications which are I/O bound (don't need to scale across multiple CPU cores) and which benefit from the extremely low latency and switching overhead of thread switching (with shared core memory) vs. process/context switching.  On Linux this is almost the empty set (Linux process switch times are extremely close to its thread-switches).  threading suffers from two major disadvantages in Python.  One, of course, is implementation specific --- mostly affecting CPython.  That's the GIL.  For the most part, most CPython programs will not benefit from the availability of more than two CPUs (cores) and often performance will suffer from the GIL locking contention.  The larger issue which is not implementation specific, is that threads share the same memory, signal handlers, file descriptors and certain other OS resources.  Thus the programmer must be extremely careful about object locking, exception handling and other aspects of their code which are both subtle and which can kill, stall, or deadlock the entire process (suite of threads).  By comparison the multiprocessing model gives each process its own memory, file descriptors, etc.  A crash or unhandled exception in any one of them will only kill that resource and robustly handling the disappearance of a child or sibling process can be considerably easier than debugging, isolating and fixing or working around similar issues in threads.   (Note: use of threading with major Python systems, such as NumPy, may suffer considerably less from GIL contention then most of your own Python code would.  That's because they've been specifically engineered to do so).   The twisted option:  It's also worth noting that Twisted offers yet another alternative which is both elegant and very challenging to understand.  Basically, at the risk of over simplifying to the point where fans of Twisted may storm my home with pitchforks and torches, Twisted provides and event-driven co-operative multi-tasking within any (single) process.  To understand how this is possible one should read about the features of select() (which can be built around the select() or poll() or similar OS system calls).  Basically it's all driven by the ability to make a request of the OS to sleep pending any activity on a list of file descriptors or some timeout.  Awakening from each of these calls to select() is an event --- either one involving input available (readable) on some number of sockets or file descriptors, or buffering space becoming available on some other (writable) descriptors or sockets, some exceptional conditions (TCP out-of-band PUSH'd packets, for example), or a TIMEOUT.  Thus the Twisted programming model is built around handling these events then looping on the resulting \"main\" handler, allowing it to dispatch the events to your handlers.  I personally think of the name, Twisted as evocative of the programming model ... since your approach to the problem must be, in some sense, \"twisted\" inside out.  Rather than conceiving of your program as a series of operations on input data and outputs or results, you're writing your program as a service or daemon and defining how it reacts to various events.  (In fact the core \"main loop\" of a Twisted program is (usually?  always?) a reactor().  The major challenges to using Twisted involve twisting your mind around the event driven model and also eschewing the use of any class libraries or toolkits which are not written to co-operate within the Twisted framework.  This is why Twisted supplies its own modules for SSH protocol handling, for curses, and its own subprocess/popen functions, and many other modules and protocol handlers which, at first blush, would seem to duplicate things in the Python standard libraries.  I think it's useful to understand Twisted on a conceptual level even if you never intend to use it.  It may give insights into performance, contention, and event handling in your threading, multiprocessing and even subprocess handling as well as any distributed processing you undertake.  (Note: Newer versions of Python 3.x are including asyncio (asynchronous I/O) features such as async def, the @async.coroutine decorator, and the await keyword, and yield from future support.  All of these are roughly similar to Twisted from a process (co-operative multitasking) perspective).  The distributed option:  Yet another realm of processing you haven't asked about, but which is worth considering, is that of distributed processing.  There are many Python tools and frameworks for distributed processing and parallel computation.  Personally I think the easiest to use is one which is least often considered to be in that space.  It is almost trivial to build distributed processing around Redis.  The entire key store can be used to store work units and results, Redis LISTs can be used as Queue() like object, and the PUB/SUB support can be used for Event-like handling. You can hash your keys and use values, replicated across a loose cluster of Redis instances, to store the topology and hash-token mappings to provide consistent hashing and fail-over for scaling beyond the capacity of any single instance for co-ordinating your workers and marshaling data (pickled, JSON, BSON, or YAML) among them.  Of course as you start to build a larger scale and more sophisticated solution around Redis you are re-implementing many of the features that have already been solved using, Celery, Apache Spark and Hadoop, Zookeeper, etcd, Cassandra and so on.  Those alll have modules for Python access to their services.  [Update: A couple of resources for consideration if you're considering Python for computationally intensive across distributed systems: IPython Parallel and PySpark.  While these are general purpose distributed computing systems, they are particularly accessible and popular subsystems data science and analytics].   Conclusion  There you have the gamut of processing alternatives for Python, from single threaded, with simple synchronous calls to sub-processes, pools of polled subprocesses, threaded and multiprocessing, event-driven co-operative multi-tasking, and out to distributed processing.     ","Language":"Python","Tags":["python","multithreading","parallel-processing"],"URL":"https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python","A_Votes":"136","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.  Portability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.  Any thoughts on this?  I'd like the simplest solution that's portable.     ","Q_Votes":"82"},{"Q_Title":"deciding among subprocess, multiprocessing, and thread in Python?","A_Content":"  To use multiple processors in CPython your only choice is the multiprocessing module. CPython keeps a lock on it's internals (the GIL) which prevents threads on other cpus to work in parallel. The multiprocessing module creates new processes ( like subprocess ) and manages communication between them.     ","Language":"Python","Tags":["python","multithreading","parallel-processing"],"URL":"https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.  Portability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.  Any thoughts on this?  I'd like the simplest solution that's portable.     ","Q_Votes":"82"},{"Q_Title":"deciding among subprocess, multiprocessing, and thread in Python?","A_Content":"  In a similar case I opted for separate processes and the little bit of necessary communication trough network socket. It is highly portable and quite simple to do using python, but probably not the simpler (in my case I had also another constraint: communication with other processes written in C++).  In your case I would probably go for multiprocess, as python threads, at least when using CPython, are not real threads. Well, they are native system threads but C modules called from Python may or may not release the GIL and allow other threads them to run when calling blocking code.     ","Language":"Python","Tags":["python","multithreading","parallel-processing"],"URL":"https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.  Portability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.  Any thoughts on this?  I'd like the simplest solution that's portable.     ","Q_Votes":"82"},{"Q_Title":"deciding among subprocess, multiprocessing, and thread in Python?","A_Content":"  Shell out and let the unix out to do your jobs:  use iterpipes to wrap subprocess and then:  From Ted Ziuba's site  INPUTS_FROM_YOU | xargs -n1 -0 -P NUM ./process  #NUM parallel processes  OR  Gnu Parallel will also serve  You hang out with GIL while you send the backroom boys out to do your multicore work.     ","Language":"Python","Tags":["python","multithreading","parallel-processing"],"URL":"https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.  Portability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.  Any thoughts on this?  I'd like the simplest solution that's portable.     ","Q_Votes":"82"},{"Q_Title":"split string in to 2 based on last occurrence of a separator","A_Content":"  Use rpartition(s). It does exactly that.  You can also use rsplit(s, 1).     ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/7351744/split-string-in-to-2-based-on-last-occurrence-of-a-separator","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to know if there is any built in function in python to break the string in to 2 parts, based on the last occurrence of a separator.  for eg: consider the string \"a b c,d,e,f\" , after the split over separator \",\", i want the output as  \"a b c,d,e\" and \"f\".   I know how to manipulate the string to get the desired output, but i want to know if there is any in built function in python.     ","Q_Votes":"82"},{"Q_Title":"split string in to 2 based on last occurrence of a separator","A_Content":"  >>> \"a b c,d,e,f\".rsplit(',',1) ['a b c,d,e', 'f']      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/7351744/split-string-in-to-2-based-on-last-occurrence-of-a-separator","A_Votes":"61","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is any built in function in python to break the string in to 2 parts, based on the last occurrence of a separator.  for eg: consider the string \"a b c,d,e,f\" , after the split over separator \",\", i want the output as  \"a b c,d,e\" and \"f\".   I know how to manipulate the string to get the desired output, but i want to know if there is any in built function in python.     ","Q_Votes":"82"},{"Q_Title":"split string in to 2 based on last occurrence of a separator","A_Content":"  You can split a string by the last occurrence of a separator with rsplit:     Returns a list of the words in the string, separated by the delimiter string (starting from right).   To split by the last comma:  >>> \"a b c,d,e,f\".rsplit(',', 1) ['a b c,d,e', 'f']      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/7351744/split-string-in-to-2-based-on-last-occurrence-of-a-separator","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is any built in function in python to break the string in to 2 parts, based on the last occurrence of a separator.  for eg: consider the string \"a b c,d,e,f\" , after the split over separator \",\", i want the output as  \"a b c,d,e\" and \"f\".   I know how to manipulate the string to get the desired output, but i want to know if there is any in built function in python.     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  [i for i, v in enumerate(L) if v[0] == 53]      ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  You can use a list comprehension:  >>> a = [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")] >>> [x[0] for x in a] [1, 22, 53, 44] >>> [x[0] for x in a].index(53) 2      ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  tl;dr  A generator expression is probably the most performant and simple solution to your problem:    l = [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]  result = next((i for i, v in enumerate(l) if v[0] == 53), None) # 2   Explanation  There are several answers that provide a simple solution to this question with list comprehensions. While these answers are perfectly correct, they are not optimal. Depending on your use case, there may be significant benefits to making a few simple modifications.  The main problem I see with using a list comprehension for this use case is that the entire list will be processed, although you only want to find 1 element.  Python provides a simple construct which is ideal here. It is called the generator expression. Here is an example:  # Our input list, same as before l = [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]  # Call next on our generator expression. next((i for i, v in enumerate(l) if v[0] == 53), None)   We can expect this method to perform basically the same as list comprehensions in our trivial example, but what if we're working with a larger data set? That's where the advantage of using the generator method comes into play. Rather than constructing a new list, we'll use your existing list as our iterable, and use next() to get the first item from our generator.  Lets look at how these methods perform differently on some larger data sets. These are large lists, made of 10000000 + 1 elements, with our target at the beginning (best) or end (worst). We can verify that both of these lists will perform equally using the following list comprehension:  List comprehensions  \"Worst case\"  worst_case = ([(False, 'F')] * 10000000) + [(True, 'T')] print [i for i, v in enumerate(worst_case) if v[0] is True]  # [10000000] #          2 function calls in 3.885 seconds # #    Ordered by: standard name # #    ncalls  tottime  percall  cumtime  percall filename:lineno(function) #         1    3.885    3.885    3.885    3.885 so_lc.py:1(<module>) #         1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}   \"Best case\"  best_case = [(True, 'T')] + ([(False, 'F')] * 10000000) print [i for i, v in enumerate(best_case) if v[0] is True]  # [0] #          2 function calls in 3.864 seconds # #    Ordered by: standard name # #    ncalls  tottime  percall  cumtime  percall filename:lineno(function) #         1    3.864    3.864    3.864    3.864 so_lc.py:1(<module>) #         1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}   Generator expressions  Here's my hypothesis for generators: we'll see that generators will significantly perform better in the best case, but similarly in the worst case. This performance gain is mostly due to the fact that the generator is evaluated lazily, meaning it will only compute what is required to yield a value.  Worst case  # 10000000 #          5 function calls in 1.733 seconds # #    Ordered by: standard name # #    ncalls  tottime  percall  cumtime  percall filename:lineno(function) #         2    1.455    0.727    1.455    0.727 so_lc.py:10(<genexpr>) #         1    0.278    0.278    1.733    1.733 so_lc.py:9(<module>) #         1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects} #         1    0.000    0.000    1.455    1.455 {next}   Best case  best_case  = [(True, 'T')] + ([(False, 'F')] * 10000000) print next((i for i, v in enumerate(best_case) if v[0] == True), None)  # 0 #          5 function calls in 0.316 seconds # #    Ordered by: standard name # #    ncalls  tottime  percall  cumtime  percall filename:lineno(function) #         1    0.316    0.316    0.316    0.316 so_lc.py:6(<module>) #         2    0.000    0.000    0.000    0.000 so_lc.py:7(<genexpr>) #         1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects} #         1    0.000    0.000    0.000    0.000 {next}   WHAT?! The best case blows away the list comprehensions, but I wasn't expecting the our worst case to outperform the list comprehensions to such an extent. How is that? Frankly, I could only speculate without further research.  Take all of this with a grain of salt, I have not run any robust profiling here, just some very basic testing. This should be sufficient to appreciate that a generator expression is more performant for this type of list searching.  Note that this is all basic, built-in python. We don't need to import anything or use any libraries.  I first saw this technique for searching in the Udacity cs212 course with Peter Norvig.     ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  Your tuples are basically key-value pairs--a python dict--so:  l = [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")] val = dict(l)[53]   Edit -- aha, you say you want the index value of (53, \"xuxa\"). If this is really what you want, you'll have to iterate through the original list, or perhaps make a more complicated dictionary:  d = dict((n,i) for (i,n) in enumerate(e[0] for e in l)) idx = d[53]      ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  Hmm... well, the simple way that comes to mind is to convert it to a dict  d = dict(thelist)   and access d[53].  EDIT: Oops, misread your question the first time. It sounds like you actually want to get the index where a given number is stored. In that case, try  dict((t[0], i) for i, t in enumerate(thelist))   instead of a plain old dict conversion. Then d[53] would be 2.     ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  If you want the simple approach, this should work.  You'll want to \".close()\" the file first so you know it's flushed to disk from Python.  import os os.system(\"scp FILE USER@SERVER:PATH\") #e.g. os.system(\"scp foo.bar joe@srvr.net:/path/to/foo.bar\")   You need to generate (on the source machine) and install (on the destination machine) an ssh key beforehand so that the scp automatically gets authenticated with your public ssh key (in other words, so your script doesn't ask for a password).    ssh-keygen example     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"36","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  Supposing the list may be long and the numbers may repeat, consider using the SortedList type from the Python sortedcontainers module. The SortedList type will automatically maintain the tuples in order by number and allow for fast searching.  For example:  from sortedcontainers import SortedList sl = SortedList([(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")])  # Get the index of 53:  index = sl.bisect((53,))  # With the index, get the tuple:  tup = sl[index]   This will work a lot faster than the list comprehension suggestion by doing a binary search. The dictionary suggestion will be faster still but won't work if there could be duplicate numbers with different strings.  If there are duplicate numbers with different strings then you need to take one more step:  end = sl.bisect((53 + 1,))  results = sl[index:end]   By bisecting for 54, we will find the end index for our slice. This will be significantly faster on long lists as compared with the accepted answer.     ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  Just another way.  zip(*a)[0].index(53)      ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to search a list of tuples in Python","A_Content":"  [k for k,v in l if v =='delicia']  here l is the list of tuples-[(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]  And instead of converting it to a dict, we are using llist comprehension.  *Key* in Key,Value in list, where value = **delicia**     ","Language":"Python","Tags":["python","search","list","tuples"],"URL":"https://stackoverflow.com/questions/2917372/how-to-search-a-list-of-tuples-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    So I have a list of tuples such as this:  [(1,\"juca\"),(22,\"james\"),(53,\"xuxa\"),(44,\"delicia\")]   I want this list for a tuple whose number value is equal to something.  So that if I do search(53) it will return the index value of 2  Is there an easy way to do this?     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  To do this in Python (i.e. not wrapping scp through subprocess.Popen or similar) with the Paramiko library, you would do something like this:  import os import paramiko  ssh = paramiko.SSHClient()  ssh.load_host_keys(os.path.expanduser(os.path.join(\"~\", \".ssh\", \"known_hosts\"))) ssh.connect(server, username=username, password=password) sftp = ssh.open_sftp() sftp.put(localpath, remotepath) sftp.close() ssh.close()   (You would probably want to deal with unknown hosts, errors, creating any directories necessary, and so on).     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"123","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  You'd probably use the subprocess module. Something like this:  import subprocess p = subprocess.Popen([\"scp\", myfile, destination]) sts = os.waitpid(p.pid, 0)   Where destination is probably of the form user@remotehost:remotepath. Thanks to @Charles Duffy for pointing out the weakness in my original answer, which used a single string argument to specify the scp operation shell=True - that wouldn't handle whitespace in paths.  The module documentation has examples of error checking that you may want to perform in conjunction with this operation.  Ensure that you've set up proper credentials so that you can perform an unattended, passwordless scp between the machines. There is a stackoverflow question for this already.     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  There are a couple of different ways to approach the problem:   Wrap command-line programs use a Python library that provides SSH capabilities (eg - Paramiko or Twisted Conch)   Each approach has its own quirks. You will need to setup SSH keys to enable password-less logins if you are wrapping system commands like \"ssh\", \"scp\" or \"rsync.\" You can embed a password in a script using Paramiko or some other library, but you might find the lack of documentation frustrating, especially if you are not familiar with the basics of the SSH connection (eg - key exchanges, agents, etc). It probably goes without saying that SSH keys are almost always a better idea than passwords for this sort of stuff.  NOTE: its hard to beat rsync if you plan on transferring files via SSH, especially if the alternative is plain old scp.  I've used Paramiko with an eye towards replacing system calls but found myself drawn back to the wrapped commands due to their ease of use and immediate familiarity. You might be different. I gave Conch the once-over some time ago but it didn't appeal to me.  If opting for the system-call path, Python offers an array of options such as os.system or the commands/subprocess modules. I'd go with the subprocess module if using version 2.4+.     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  Reached the same problem, but instead of \"hacking\" or emulating command line:  Found this answer here.  from paramiko import SSHClient from scp import SCPClient  ssh = SSHClient() ssh.load_system_host_keys() ssh.connect('example.com')  with SCPClient(ssh.get_transport()) as scp:     scp.put('test.txt', 'test2.txt')     scp.get('test2.txt')      ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  fabric could be used to upload files vis ssh:  #!/usr/bin/env python from fabric.api import execute, put from fabric.network import disconnect_all  if __name__==\"__main__\":     import sys     # specify hostname to connect to and the remote/local paths     srcdir, remote_dirname, hostname = sys.argv[1:]     try:         s = execute(put, srcdir, remote_dirname, host=hostname)         print(repr(s))     finally:         disconnect_all()      ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  Calling scp command via subprocess doesn't allow to receive the progress report inside the script. pexpect could be used to extract that info:  import pipes import re import pexpect # $ pip install pexpect  def progress(locals):     # extract percents     print(int(re.search(br'(\\d+)%$', locals['child'].after).group(1)))  command = \"scp %s %s\" % tuple(map(pipes.quote, [srcfile, destination])) pexpect.run(command, events={r'\\d+%': progress})   See python copy file in local network (linux -> linux)     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  from paramiko import SSHClient from scp import SCPClient import os  ssh = SSHClient()  ssh.load_host_keys(os.path.expanduser(os.path.join(\"~\", \".ssh\", \"known_hosts\"))) ssh.connect(server, username='username', password='password') with SCPClient(ssh.get_transport()) as scp:         scp.put('test.txt', 'test2.txt')      ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  a very simple approach is the following:   import os sshpass -p \"password\" scp user@host:/path/to/file ./   no python library are required (only os) and it works     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  I used sshfs to mount the remote directory via ssh, and shutil to copy the files:  $ mkdir ~/sshmount $ sshfs user@remotehost:/path/to/remote/dst ~/sshmount   Then in python:  import shutil shutil.copy('a.txt', '~/sshmount')   This method has the advantage that you can stream data over if you are generating data rather than caching locally and sending a single large file.     ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to copy a file to a remote server in Python using SCP or SSH?","A_Content":"  Kind of hacky, but the following should work :)  import os filePath = \"/foo/bar/baz.py\" serverPath = \"/blah/boo/boom.py\" os.system(\"scp \"+filePath+\" user@myserver.com:\"+serverPath)      ","Language":"Python","Tags":["python","ssh","automation","scp"],"URL":"https://stackoverflow.com/questions/68335/how-to-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file on my local machine that is generated by a daily Python script run in cron.   I would like to add a bit of code to have that file sent securely to my server over SSH.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  The webdriver will wait for a page to load by default via .get() method.  As you may be looking for some specific element as @user227215 said, you should use WebDriverWait to wait for an element located in your page:  from selenium import webdriver from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.common.by import By from selenium.common.exceptions import TimeoutException  browser = webdriver.Firefox() browser.get(\"url\") delay = 3 # seconds try:     myElem = WebDriverWait(browser, delay).until(EC.presence_of_element_located((By.ID, 'IdOfMyElement')))     print \"Page is ready!\" except TimeoutException:     print \"Loading took too much time!\"   I have used it for checking alerts. You can use any other type methods to find the locator.   EDIT 1:  I should mention that the webdriver will wait for a page to load by default. It does not wait for loading inside frames or for ajax requests. It means when you use .get('url'), your browser will wait until the page is completely loaded and then go to the next command in the code. But when you are posting an ajax request, webdriver does not wait and it's your responsibility to wait an appropriate amount of time for the page or a part of page to load; so there is a module named expected_conditions.     ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  Trying to pass find_element_by_id to the constructor for presence_of_element_located (as shown in the accepted answer) caused NoSuchElementException to be raised. I had to use the syntax in fragles' comment:  from selenium import webdriver from selenium.common.exceptions import TimeoutException from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.common.by import By  driver = webdriver.Firefox() driver.get('url') timeout = 5 try:     element_present = EC.presence_of_element_located((By.ID, 'element_id'))     WebDriverWait(driver, timeout).until(element_present) except TimeoutException:     print \"Timed out waiting for page to load\"   This matches the example in the documentation. Here is a link to the documentation for By.     ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"45","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  Find below 3 methods:  readyState  Checking page readyState (not reliable):  def page_has_loaded(self):     self.log.info(\"Checking if {} page is loaded.\".format(self.driver.current_url))     page_state = self.driver.execute_script('return document.readyState;')     return page_state == 'complete'      The wait_for helper function is good, but unfortunately click_through_to_new_page is open to the race condition where we manage to execute the script in the old page, before the browser has started processing the click, and page_has_loaded just returns true straight away.   id  Comparing new page ids with the old one:  def page_has_loaded_id(self):     self.log.info(\"Checking if {} page is loaded.\".format(self.driver.current_url))     try:         new_page = browser.find_element_by_tag_name('html')         return new_page.id != old_page.id     except NoSuchElementException:         return False      It's possible that comparing ids is not as effective as waiting for stale reference exceptions.   staleness_of  Using staleness_of method:  @contextlib.contextmanager def wait_for_page_load(self, timeout=10):     self.log.debug(\"Waiting for page to load at {}.\".format(self.driver.current_url))     old_page = self.find_element_by_tag_name('html')     yield     WebDriverWait(self, timeout).until(staleness_of(old_page))     For more details, check Harry's blog.     ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  As mentioned in the answer from David Cullen, I've seen always recommended using a line like the following one:  element_present = EC.presence_of_element_located((By.ID, 'element_id'))     WebDriverWait(driver, timeout).until(element_present)   It was difficult for me to find anywhere all possible locators that can be used with the By syntax, so I thought it would be useful to provide here the list. According to Web Scraping with Python by Ryan Mitchell:     ID      Used in the example; finds elements by their HTML id attribute      CLASS_NAME      Used to find elements by their HTML class attribute. Why is this   function CLASS_NAME not simply CLASS? Using the form object.CLASS   would create problems for Selenium's Java library, where .class is a   reserved method. In order to keep the Selenium syntax consistent   between different languages, CLASS_NAME was used instead.      CSS_SELECTOR      Find elements by their class, id, or tag name, using the #idName,   .className, tagName convention.      LINK_TEXT      Finds HTML  tags by the text they contain. For example, a link that   says \"Next\" can be selected using (By.LINK_TEXT, \"Next\").      PARTIAL_LINK_TEXT      Similar to LINK_TEXT, but matches on a partial string.      NAME      Finds HTML tags by their name attribute. This is handy for HTML forms.      TAG_NAME      Fins HTML tags by their tag name.      XPATH      Uses an XPath expression ... to select matching elements.      ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  From selenium/webdriver/support/wait.py  driver = ... from selenium.webdriver.support.wait import WebDriverWait element = WebDriverWait(driver, 10).until(     lambda x: x.find_element_by_id(\"someId\"))      ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  On a side note, instead of scrolling down 100 times, you can check if there are no more modifications to the DOM (we are in the case of the bottom of the page being AJAX lazy-loaded)  def scrollDown(driver, value):     driver.execute_script(\"window.scrollBy(0,\"+str(value)+\")\")  # Scroll down the page def scrollDownAllTheWay(driver):     old_page = driver.page_source     while True:         logging.debug(\"Scrolling loop\")         for i in range(2):             scrollDown(driver, 500)             time.sleep(2)         new_page = driver.page_source         if new_page != old_page:             old_page = new_page         else:             break     return True      ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  How about putting WebDriverWait in While loop and catching the exceptions.  from selenium import webdriver from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.common.exceptions import TimeoutException  browser = webdriver.Firefox() browser.get(\"url\") delay = 3 # seconds while True:     try:         WebDriverWait(browser, delay).until(EC.presence_of_element_located(browser.find_element_by_id('IdOfMyElement')))         print \"Page is ready!\"         break # it will break from the loop once the specific element will be present.      except TimeoutException:         print \"Loading took too much time!-Try again\"      ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"How to wait until the page is loaded with Selenium for Python?","A_Content":"  Have you tried driver.implicitly_wait. It is like a setting for the driver, so you only call it once in the session and it basically tells the driver to wait the given amount of time until each command can be executed.   driver = webdriver.Chrome() driver.implicitlyWait(10)   So if you set a wait time of 10 seconds it will execute the command as soon as possible, waiting 10 seconds before it gives up. I've used this in similar scroll-down scenarios so I don't see why it wouldn't work in your case. Hope this is helpful :)     ","Language":"Python","Tags":["python","selenium"],"URL":"https://stackoverflow.com/questions/26566799/how-to-wait-until-the-page-is-loaded-with-selenium-for-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to scrape all the data of a page implemented by a infinite scroll. The following python code works.  for i=1:100     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")     time.sleep(5)   This means every time I scroll down to the bottom, I need to wait 5 seconds, which is generally enough for the page to finish loading the newly generated contents. But, this may not be time efficient. The page may finish loading the new contents within 5 seconds. How can I detect whether the page finished loading the new contents every time I scroll down? If I can detect this, I can scroll down again to see more contents once I know the page finished loading. This is more time efficient.     ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  I finally figured it out working on another problem. The problem was that my test couldn't find an import.   It looks like you get the above error if your test fails to import. This makes sense because the test suite can't import a broken test. At least I think this is what is going on because I fixed the import within my test file and sure enough it started working.  To validate your test case just try import the test case file in python console.   Example:  from project.apps.app1.tests import *      ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"158","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  Use:  ./manage.py shell  followed by   import myapp.tests  to find the nature of the import error.     ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  For my case, I need to create an empty __init__.py in my app/tests folder     ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  Steve Bradshaw's example above works for import errors (thanks Steve).  Other type of errors (e.g. ValueError) may also cause   AttributeError: 'module' object has no attribute 'tests'   to see what these errors are  ./manage.py shell from myapp.tests import SomeTestCase t = SomeTestCase()      ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  I had the same error as Chris.  I had deleted an old model, then run tests.py, but another file (views.py) was still trying to import the deleted model.  When I took out the now-obsolete import statement, problem solved.     ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  According to django document When you run your tests, the default behavior of the test utility is to find all the test cases (that is, subclasses of unittest.TestCase) in any file whose name begins with test, automatically build a test suite out of those test cases, and run that suite.  so try this : python manage.py test tests.py     ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  Got the same error, but checked all the reasons list here, did not fix my problem.   Finally figure it out that, the reason is that the name of one method that imported but not used yet is not correct. Though it is a stupid error, it happens.     ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"AttributeError: 'module' object has no attribute 'tests'","A_Content":"  Make sure that all modules that you are using in your script are not broken. By this I mean check spelling in your import statements.   # invalid import from app.model.notification import Notification # valid import from app.models.notification import Notification   You can test yours modules by executing imports statements in djano's interactive console.  $root@13faefes8: python manage.py shell Type \"help\", \"copyright\", \"credits\" or \"license\" for more information (InteractiveConsole) >>> from app.model.notification import Notification Traceback (most recent call last):     File \"<console>\", line 1, in <module> ImportError: No module named model.notification      ","Language":"Python","Tags":["python","django","python-2.7","python-unittest"],"URL":"https://stackoverflow.com/questions/25575073/attributeerror-module-object-has-no-attribute-tests","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm running this command:  python manage.py test project.apps.app1.tests   and it causes this error:     AttributeError: 'module' object has no attribute 'tests'   Below is my directory structure. I've also added app1 to my installed apps config.  Traceback (most recent call last):     File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line     utility.execute()     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv     super(Command, self).run_from_argv(argv)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv     self.execute(*args, **options.__dict__)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute     super(Command, self).execute(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute     output = self.handle(*args, **options)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle     failures = test_runner.run_tests(test_labels)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests     suite = self.build_suite(test_labels, extra_tests)     File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite     tests = self.test_loader.loadTestsFromName(label)     File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName     parent, obj = obj, getattr(obj, part)     AttributeError: 'module' object has no attribute 'tests'   Directory structure:       ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  You haven't actually converted your strings to ints.  Or rather, you did, but then you didn't do anything with the results.  What you want is:  list1 = [\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] list1 = [int(x) for x in list1] list1.sort()   However, python makes it even easier for you: sort takes a named parameter, key, which is a function that is called on each element before it is compared (but without modifying the list)  list1 = [\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] # call int(x) on each element before comparing it list1.sort(key=int)      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"145","_type":"dict","isAccepted":"Yes","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  You could pass a function to the key parameter to the .sort method. With this, the system will sort by key(x) instead of x.  list1.sort(key=int)     BTW, to convert the list to integers permanently, use the map function  list1 = list(map(int, list1))   # you don't need to call list() in Python 2.x   or list comprehension  list1 = [int(x) for x in list1]      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"32","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  In case you want to use sorted() function: sorted(list1, key=int)  It returns a new sorted list.     ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  Python's sort isn't weird. It's just that this code:  for item in list1:    item=int(item)   isn't doing what you think it is - item is not replaced back into the list, it is simply thrown away.  Anyway, the correct solution is to use key=int as others have shown you.     ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  You can also use:     import re def sort_human(l):   convert = lambda text: float(text) if text.isdigit() else text   alphanum = lambda key: [ convert(c) for c in re.split('([-+]?[0-9]*\\.?[0-9]*)', key) ]   l.sort( key=alphanum )   return l    this is very similar for other stuff that you can find on the internet but also works for alphanumericals like [abc0.1, abc0.2..]      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  Seamus Campbell's answer doesnot work on python2.x. list1 = sorted(list1, key=lambda e: int(e)) using lambda function works well.      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  The most recent solution is right. You are reading solutions as a string, in which case the order is 1, then 100, then 104 followed by 2 then 21, then 2001001010, 3 and so forth.  You have to CAST your input as an int instead:  sorted strings:   stringList = (1, 10, 2, 21, 3)  sorted ints:   intList = (1, 2, 3, 10, 21)  To cast, just put the stringList inside int ( blahblah ).  Again:   stringList = (1, 10, 2, 21, 3)  newList = int (stringList)  print newList  => returns (1, 2, 3, 10, 21)       ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  I approached the same problem yesterday and found a module called natsort which solves the problems. Use:  from natsort import natsorted  # Example list of strings a = ['1', '10', '2', '3', '11']  [In]  sorted(a) [Out] ['1', '10', '11', '2', '3']  [In]  natsorted(a) [Out] ['1', '2', '3', '10', '11']      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  Simple way to sort a numerical list      numlists = [5,50,7,51,87,97,53]     numlists.sort(reverse=False)     print(numlists)      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"How to sort a list numerically?","A_Content":"  scores = ['91','89','87','86','85'] scores.sort() print (scores)   This worked for me using python version 3, though it didn't in version 2.      ","Language":"Python","Tags":["python","sorting"],"URL":"https://stackoverflow.com/questions/3426108/how-to-sort-a-list-numerically","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I know that this sounds trivial but I did not realize that the sort() function of Python was weird. I have a list of \"numbers\" that are actually in string form, so I first convert them to ints, then attempt a sort.  list1=[\"1\",\"10\",\"3\",\"22\",\"23\",\"4\",\"2\",\"200\"] for item in list1:     item=int(item)  list1.sort() print list1   Gives me:  ['1', '10', '2', '200', '22', '23', '3', '4']   What I want is   ['1','2','3','4','10','22','23','200']   I've looked around for some of the algorithms associated with sorting numeric sets, but the ones I found all involve sorting alphanumeric sets.   I know this is probably a no brainer problem but google and my textbook don't offer anything more or less useful than the .sort() function.     ","Q_Votes":"82"},{"Q_Title":"Getting today's date in YYYY-MM-DD in Python?","A_Content":"  You can use strftime:  datetime.datetime.today().strftime('%Y-%m-%d')      ","Language":"Python","Tags":["python","python-2.7","datetime","python-datetime"],"URL":"https://stackoverflow.com/questions/32490629/getting-todays-date-in-yyyy-mm-dd-in-python","A_Votes":"170","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm using:  str(datetime.datetime.today()).split()[0]   to return today's date in the form YYYY-MM-DD.  Is there a less crude way to achieve this?     ","Q_Votes":"82"},{"Q_Title":"Getting today's date in YYYY-MM-DD in Python?","A_Content":"  Datetime is just lovely if you like remembering funny codes. Wouldn't you prefer simplicity?  >>> import arrow >>> arrow.now().format('YYYY-MM-DD') '2017-02-17'   This module is clever enough to understand what you mean.   Just do pip install arrow.     ","Language":"Python","Tags":["python","python-2.7","datetime","python-datetime"],"URL":"https://stackoverflow.com/questions/32490629/getting-todays-date-in-yyyy-mm-dd-in-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I'm using:  str(datetime.datetime.today()).split()[0]   to return today's date in the form YYYY-MM-DD.  Is there a less crude way to achieve this?     ","Q_Votes":"82"},{"Q_Title":"Getting today's date in YYYY-MM-DD in Python?","A_Content":"  There's even simpler way than the accepted answer; valid both for Python 2 & 3.  from datetime import date today = str(date.today()) print(today)   # '2017-12-26'      ","Language":"Python","Tags":["python","python-2.7","datetime","python-datetime"],"URL":"https://stackoverflow.com/questions/32490629/getting-todays-date-in-yyyy-mm-dd-in-python","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I'm using:  str(datetime.datetime.today()).split()[0]   to return today's date in the form YYYY-MM-DD.  Is there a less crude way to achieve this?     ","Q_Votes":"82"},{"Q_Title":"Getting today's date in YYYY-MM-DD in Python?","A_Content":"  I prefer this. (because this is simple. but maybe somehow inefficient and buggy. You must check the exit code of shell command if you want very strongly error-proof program.)  os.system('date +%Y-%m-%d')      ","Language":"Python","Tags":["python","python-2.7","datetime","python-datetime"],"URL":"https://stackoverflow.com/questions/32490629/getting-todays-date-in-yyyy-mm-dd-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm using:  str(datetime.datetime.today()).split()[0]   to return today's date in the form YYYY-MM-DD.  Is there a less crude way to achieve this?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Here's a more verbose version of @Greg Hewgill's answer. It is the most conforming to the question requirements. It makes a distinction between creation and modification dates (at least on Windows).  #!/usr/bin/env python from stat import S_ISREG, ST_CTIME, ST_MODE import os, sys, time  # path to the directory (relative or absolute) dirpath = sys.argv[1] if len(sys.argv) == 2 else r'.'  # get all entries in the directory w/ stats entries = (os.path.join(dirpath, fn) for fn in os.listdir(dirpath)) entries = ((os.stat(path), path) for path in entries)  # leave only regular files, insert creation date entries = ((stat[ST_CTIME], path)            for stat, path in entries if S_ISREG(stat[ST_MODE])) #NOTE: on Windows `ST_CTIME` is a creation date  #  but on Unix it could be something else #NOTE: use `ST_MTIME` to sort by a modification date  for cdate, path in sorted(entries):     print time.ctime(cdate), os.path.basename(path)   Example:  $ python stat_creation_date.py Thu Feb 11 13:31:07 2009 stat_creation_date.py      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"49","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  I've done this in the past for a Python script to determine the last updated files in a directory:   import glob import os  search_dir = \"/mydir/\" # remove anything from the list that is not a file (directories, symlinks) # thanks to J.F. Sebastion for pointing out that the requirement was a list  # of files (presumably not including directories)   files = filter(os.path.isfile, glob.glob(search_dir + \"*\")) files.sort(key=lambda x: os.path.getmtime(x))   That should do what you're looking for based on file mtime.  EDIT: Note that you can also use os.listdir() in place of glob.glob() if desired - the reason I used glob in my original code was that I was wanting to use glob to only search for files with a particular set of file extensions, which glob() was better suited to. To use listdir here's what it would look like:   import os  search_dir = \"/mydir/\" os.chdir(search_dir) files = filter(os.path.isfile, os.listdir(search_dir)) files = [os.path.join(search_dir, f) for f in files] # add path to each file files.sort(key=lambda x: os.path.getmtime(x))      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"97","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Here's a one-liner:  import os import time from pprint import pprint  pprint([(x[0], time.ctime(x[1].st_ctime)) for x in sorted([(fn, os.stat(fn)) for fn in os.listdir(\".\")], key = lambda x: x[1].st_ctime)])   This calls os.listdir() to get a list of the filenames, then calls os.stat() for each one to get the creation time, then sorts against the creation time.  Note that this method only calls os.stat() once for each file, which will be more efficient than calling it for each comparison in a sort.     ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Here's my version:  def getfiles(dirpath):     a = [s for s in os.listdir(dirpath)          if os.path.isfile(os.path.join(dirpath, s))]     a.sort(key=lambda s: os.path.getmtime(os.path.join(dirpath, s)))     return a   First, we build a list of the file names. isfile() is used to skip directories; it can be omitted if directories should be included. Then, we sort the list in-place, using the modify date as the key.     ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  There is an os.path.getmtime function that gives the number of seconds since the epoch and should be faster than os.stat.  os.chdir(directory) sorted(filter(os.path.isfile, os.listdir('.')), key=os.path.getmtime)      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Without changing directory:  import os      path = '/path/to/files/' name_list = os.listdir(path) full_list = [os.path.join(path,i) for i in name_list] time_sorted_list = sorted(full_list, key=os.path.getmtime)  print time_sorted_list  # if you want just the filenames sorted, simply remove the dir from each sorted_filename_list = [ os.path.basename(i) for i in time_sorted_list] print sorted_filename_list      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Here's my answer using glob without filter if you want to read files with a certain extension in date order (Python 3).    dataset_path='/mydir/'    files = glob.glob(dataset_path+\"/morepath/*.extension\")    files.sort(key=os.path.getmtime)      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  sorted(filter(os.path.isfile, os.listdir('.')),      key=lambda p: os.stat(p).st_mtime)   You could use os.walk('.').next()[-1] instead of filtering with os.path.isfile, but that leaves dead symlinks in the list, and os.stat will fail on them.     ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  In python 3.5+  from pathlib import Path sorted(Path('.').iterdir(), key=lambda f: f.stat().st_mtime)      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  this is a basic step for learn:  import os, stat, sys import time  dirpath = sys.argv[1] if len(sys.argv) == 2 else r'.'  listdir = os.listdir(dirpath)  for i in listdir:     os.chdir(dirpath)     data_001 = os.path.realpath(i)     listdir_stat1 = os.stat(data_001)     listdir_stat2 = ((os.stat(data_001), data_001))     print time.ctime(listdir_stat1.st_ctime), data_001      ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How do you get a directory listing sorted by creation date in python?","A_Content":"  Alex Coventry's answer will produce an exception if the file is a symlink to an unexistent file, the following code corrects that answer:  import time import datetime sorted(filter(os.path.isfile, os.listdir('.')),      key=lambda p: os.path.exists(p) and os.stat(p).st_mtime or time.mktime(datetime.now().timetuple())   When the file doesn't exist, now() is used, and the symlink will go at the very end of the list.     ","Language":"Python","Tags":["python","windows","directory"],"URL":"https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?     ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  In Python2, print was a keyword which introduced a statement:  print \"Hi\"   In Python3, print is a function which may be invoked:  print (\"Hi\")   In both versions, % is an operator which requires a string on the left-hand side and a value or a tuple of values or a mapping object (like dict) on the right-hand side.  So, your line ought to look like this:  print(\"a=%d,b=%d\" % (f(x,n),g(x,n)))   Also, the recommendation for Python3 and newer is to use {}-style formatting instead of %-style formatting:  print('a={:d}, b={:d}'.format(f(x,n),g(x,n)))   Python 3.6 introduces yet another string-formatting paradigm: f-strings.  print(f'a={f(x,n):d}, b={g(x,n):d}')      ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"144","_type":"dict","isAccepted":"Yes","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  The most recommended way to do is to use format method. Read more about it here  a, b = 1, 2  print(\"a={0},b={1}\".format(a, b))      ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  Simple printf() function from O'Reilly's Python Cookbook.  import sys def printf(format, *args):     sys.stdout.write(format % args)   Example output:  i = 7 pi = 3.14159265359 printf(\"hi there, i=%d, pi=%.2f\\n\", i, pi) # hi there, i=7, pi=3.14      ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  Simple Example:   print(\"foo %d, bar %d\" % (1,2))         ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  Python 3.6 introduced f-strings for inline interpolation. What's even nicer is it extended the syntax to also allow format specifiers with interpolation. Something I've been working on while I googled this (and came across this old question!):  print(f'{account:40s} ({ratio:3.2f}) -> AUD {splitAmount}')   PEP 498 has the details. And... it sorted my pet peeve with format specifiers in other langs -- allows for specifiers that themselves can be expressions! Yay! See: Format Specifiers.     ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  A simpler one.  def printf(format, *values):     print(format % values )   Then:  printf(\"Hello, this is my name %s and my age %d\", \"Martin\", 20)      ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  Because your % is outside the print(...) parentheses, you're trying to insert your variables into the result of your print call. print(...) returns None, so this won't work, and there's also the small matter of you already having printed your template by this time and time travel being prohibited by the laws of the universe we inhabit.  The whole thing you want to print, including the % and its operand, needs to be inside your print(...) call, so that the string can be built before it is printed.  print( \"a=%d,b=%d\" % (f(x,n), g(x,n)) )   I have added a few extra spaces to make it clearer (though they are not necessary and generally not considered good style).     ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  Other words printf absent in python... I'm surprised! Best code is  def printf(format, *args):     sys.stdout.write(format % args)   Because of this form allows not to print \\n. All others no. That's why print is bad operator. And also you need write args in special form. There is no disadvantages in function above. It's a standard usual form of printf function.     ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"How to print like printf in Python3?","A_Content":"  print(\"Name={}, balance={}\".format(var-name, var-balance))      ","Language":"Python","Tags":["python","string","python-3.x"],"URL":"https://stackoverflow.com/questions/19457227/how-to-print-like-printf-in-python3","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    In Python 2 I used:  print \"a=%d,b=%d\" % (f(x,n),g(x,n))   I've tried:  print(\"a=%d,b=%d\") % (f(x,n),g(x,n))      ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  Obligatory Twisted example:  twistd -n ftp   And probably useful:  twistd ftp --help  Usage: twistd [options] ftp [options]. WARNING: This FTP server is probably INSECURE do not use it. Options:   -p, --port=           set the port number [default: 2121]   -r, --root=           define the root of the ftp-site. [default:                     /usr/local/ftp]   --userAnonymous=  Name of the anonymous user. [default: anonymous]   --password-file=  username:password-style credentials database   --version            --help            Display this help and exit.      ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"107","_type":"dict","isAccepted":"Yes","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  Check out pyftpdlib from Giampaolo Rodola.  It is one of the very best ftp servers out there for python.  It's used in google's chromium (their browser) and bazaar (a version control system).  It is the most complete implementation on Python for RFC-959 (aka: FTP server implementation spec).  From the commandline:  python -m pyftpdlib   Alternatively 'my_server.py':  #!/usr/bin/env python  from pyftpdlib import servers from pyftpdlib.handlers import FTPHandler address = (\"0.0.0.0\", 21)  # listen on every IP on my machine on port 21 server = servers.FTPServer(address, FTPHandler) server.serve_forever()   There's more examples on the website if you want something more complicated.  To get a list of command line options:  python -m pyftpdlib --help   Note, if you want to override or use a standard ftp port, you'll need admin privileges (e.g. sudo).     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  Why don't you instead use a one-line HTTP server?  python -m SimpleHTTPServer 8000   will serve the contents of the current working directory over HTTP on port 8000.  If you use Python 3, you should instead write  python3 -m http.server 8000   See the SimpleHTTPServer module docs for 2.x and the http.server docs for 3.x.  By the way, in both cases the port parameter is optional.     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  The answers above were all assuming your Python distribution would have some third-party libraries in order to achieve the \"one liner python ftpd\" goal, but that is not the case of what @zio was asking. Also, SimpleHTTPServer involves web broswer for downloading files, it's not quick enough.    Python can't do ftpd by itself, but you can use netcat, nc:    nc is basically a built-in tool from any UNIX-like systems (even embedded systems), so it's perfect for \"quick and temporary way to transfer files\".  Step 1, on the receiver side, run:    nc -l 12345 | tar -xf -    this will listen on port 12345, waiting for data.    Step 2, on the sender side:    tar -cf - ALL_FILES_YOU_WANT_TO_SEND ... | nc $RECEIVER_IP 12345    You can also put pv in the middle to monitor the progress of transferring:   tar -cf - ALL_FILES_YOU_WANT_TO_SEND ...| pv | nc $RECEIVER_IP 12345    After the transferring is finished, both sides of nc will quit automatically,  and job done.     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  For pyftpdlib users. I found this on the pyftpdlib website. This creates anonymous ftp with write access to your filesystem so please use with due care. More features are available under the hood for better security so just go look:  sudo pip install pyftpdlib  python -m pyftpdlib -w   Might be helpful for those that tried using the deprecated method above.   sudo python -m pyftpdlib.ftpserver     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  Install:  pip install twisted   Then the code:  from twisted.protocols.ftp import FTPFactory, FTPRealm from twisted.cred.portal import Portal from twisted.cred.checkers import AllowAnonymousAccess, FilePasswordDB from twisted.internet import reactor  reactor.listenTCP(21, FTPFactory(Portal(FTPRealm('./'), [AllowAnonymousAccess()]))) reactor.run()   Get deeper:  http://twistedmatrix.com/documents/current/core/examples/     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  The simpler solution will be to user pyftpd library. This library allows you to spin Python FTP server in one line. It doesnt come installed by default though, but we can install it using simple apt command   apt-get install python-pyftpdlib   now from the directory you want to serve just run the pythod module  python -m pyftpdlib -p 21       ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  I dont know about a one-line FTP server, but if you do  python -m SimpleHTTPServer   It'll run an HTTP server on 0.0.0.0:8000, serving files out of the current directory. If you're looking for a way to quickly get files off a linux box with a web browser, you cant beat it.     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"One line ftp server in python","A_Content":"  Good list of tools at  http://www.willdonnelly.net/blog/file-transfer/  I've used woof myself on a number of occasions. Very nice.     ","Language":"Python","Tags":["python","ftp","ftp-server"],"URL":"https://stackoverflow.com/questions/4994638/one-line-ftp-server-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have a one line command in python to do a simple ftp server? I'd like to be able to do this as quick and temporary way to transfer files to a linux box without having to install a ftp server. Preferably a way using built in python libraries so there's nothing extra to install.     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  Pyparsing can be used to parse mathematical expressions. In particular, fourFn.py shows how to parse basic arithmetic expressions. Below, I've rewrapped fourFn into a numeric parser class for easier reuse.   from __future__ import division from pyparsing import (Literal, CaselessLiteral, Word, Combine, Group, Optional,                        ZeroOrMore, Forward, nums, alphas, oneOf) import math import operator  __author__ = 'Paul McGuire' __version__ = '$Revision: 0.0 $' __date__ = '$Date: 2009-03-20 $' __source__ = '''http://pyparsing.wikispaces.com/file/view/fourFn.py http://pyparsing.wikispaces.com/message/view/home/15549426 ''' __note__ = ''' All I've done is rewrap Paul McGuire's fourFn.py as a class, so I can use it more easily in other places. '''   class NumericStringParser(object):     '''     Most of this code comes from the fourFn.py pyparsing example      '''      def pushFirst(self, strg, loc, toks):         self.exprStack.append(toks[0])      def pushUMinus(self, strg, loc, toks):         if toks and toks[0] == '-':             self.exprStack.append('unary -')      def __init__(self):         \"\"\"         expop   :: '^'         multop  :: '*' | '/'         addop   :: '+' | '-'         integer :: ['+' | '-'] '0'..'9'+         atom    :: PI | E | real | fn '(' expr ')' | '(' expr ')'         factor  :: atom [ expop factor ]*         term    :: factor [ multop factor ]*         expr    :: term [ addop term ]*         \"\"\"         point = Literal(\".\")         e = CaselessLiteral(\"E\")         fnumber = Combine(Word(\"+-\" + nums, nums) +                           Optional(point + Optional(Word(nums))) +                           Optional(e + Word(\"+-\" + nums, nums)))         ident = Word(alphas, alphas + nums + \"_$\")         plus = Literal(\"+\")         minus = Literal(\"-\")         mult = Literal(\"*\")         div = Literal(\"/\")         lpar = Literal(\"(\").suppress()         rpar = Literal(\")\").suppress()         addop = plus | minus         multop = mult | div         expop = Literal(\"^\")         pi = CaselessLiteral(\"PI\")         expr = Forward()         atom = ((Optional(oneOf(\"- +\")) +                  (ident + lpar + expr + rpar | pi | e | fnumber).setParseAction(self.pushFirst))                 | Optional(oneOf(\"- +\")) + Group(lpar + expr + rpar)                 ).setParseAction(self.pushUMinus)         # by defining exponentiation as \"atom [ ^ factor ]...\" instead of         # \"atom [ ^ atom ]...\", we get right-to-left exponents, instead of left-to-right         # that is, 2^3^2 = 2^(3^2), not (2^3)^2.         factor = Forward()         factor << atom + \\             ZeroOrMore((expop + factor).setParseAction(self.pushFirst))         term = factor + \\             ZeroOrMore((multop + factor).setParseAction(self.pushFirst))         expr << term + \\             ZeroOrMore((addop + term).setParseAction(self.pushFirst))         # addop_term = ( addop + term ).setParseAction( self.pushFirst )         # general_term = term + ZeroOrMore( addop_term ) | OneOrMore( addop_term)         # expr <<  general_term         self.bnf = expr         # map operator symbols to corresponding arithmetic operations         epsilon = 1e-12         self.opn = {\"+\": operator.add,                     \"-\": operator.sub,                     \"*\": operator.mul,                     \"/\": operator.truediv,                     \"^\": operator.pow}         self.fn = {\"sin\": math.sin,                    \"cos\": math.cos,                    \"tan\": math.tan,                    \"exp\": math.exp,                    \"abs\": abs,                    \"trunc\": lambda a: int(a),                    \"round\": round,                    \"sgn\": lambda a: abs(a) > epsilon and cmp(a, 0) or 0}      def evaluateStack(self, s):         op = s.pop()         if op == 'unary -':             return -self.evaluateStack(s)         if op in \"+-*/^\":             op2 = self.evaluateStack(s)             op1 = self.evaluateStack(s)             return self.opn[op](op1, op2)         elif op == \"PI\":             return math.pi  # 3.1415926535         elif op == \"E\":             return math.e  # 2.718281828         elif op in self.fn:             return self.fn[op](self.evaluateStack(s))         elif op[0].isalpha():             return 0         else:             return float(op)      def eval(self, num_string, parseAll=True):         self.exprStack = []         results = self.bnf.parseString(num_string, parseAll)         val = self.evaluateStack(self.exprStack[:])         return val   You can use it like this  nsp = NumericStringParser() result = nsp.eval('2^4') print(result) # 16.0  result = nsp.eval('exp(2^4)') print(result) # 8886110.520507872      ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  eval is evil  eval(\"__import__('os').remove('important file')\") # arbitrary commands eval(\"9**9**9**9**9**9**9**9\", {'__builtins__': None}) # CPU, memory   Note: even if you use set __builtins__ to None it still might be possible to break out using introspection:  eval('(1).__class__.__bases__[0].__subclasses__()', {'__builtins__': None})   Evaluate arithmetic expression using ast  import ast import operator as op  # supported operators operators = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul,              ast.Div: op.truediv, ast.Pow: op.pow, ast.BitXor: op.xor,              ast.USub: op.neg}  def eval_expr(expr):     \"\"\"     >>> eval_expr('2^6')     4     >>> eval_expr('2**6')     64     >>> eval_expr('1 + 2*3**(4^5) / (6 + -7)')     -5.0     \"\"\"     return eval_(ast.parse(expr, mode='eval').body)  def eval_(node):     if isinstance(node, ast.Num): # <number>         return node.n     elif isinstance(node, ast.BinOp): # <left> <operator> <right>         return operators[type(node.op)](eval_(node.left), eval_(node.right))     elif isinstance(node, ast.UnaryOp): # <operator> <operand> e.g., -1         return operators[type(node.op)](eval_(node.operand))     else:         raise TypeError(node)   You can easily limit allowed range for each operation or any intermediate result, e.g., to limit input arguments for a**b:  def power(a, b):     if any(abs(n) > 100 for n in [a, b]):         raise ValueError((a,b))     return op.pow(a, b) operators[ast.Pow] = power   Or to limit magnitude of intermediate results:  import functools  def limit(max_=None):     \"\"\"Return decorator that limits allowed returned values.\"\"\"     def decorator(func):         @functools.wraps(func)         def wrapper(*args, **kwargs):             ret = func(*args, **kwargs)             try:                 mag = abs(ret)             except TypeError:                 pass # not applicable             else:                 if mag > max_:                     raise ValueError(ret)             return ret         return wrapper     return decorator  eval_ = limit(max_=10**100)(eval_)   Example  >>> evil = \"__import__('os').remove('important file')\" >>> eval_expr(evil) #doctest:+IGNORE_EXCEPTION_DETAIL Traceback (most recent call last): ... TypeError: >>> eval_expr(\"9**9\") 387420489 >>> eval_expr(\"9**9**9**9**9**9**9**9\") #doctest:+IGNORE_EXCEPTION_DETAIL Traceback (most recent call last): ... ValueError:      ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"144","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  Some safer alternatives to eval() and sympy.sympify().evalf()*:   asteval  numexpr   *SymPy sympify is also unsafe according to the following warning from the documentation.     Warning: Note that this function uses eval, and thus shouldnt be used on unsanitized input.      ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  Okay, so the problem with eval is that it can escape its sandbox too easily, even if you get rid of __builtins__.  All the methods for escaping the sandbox come down to using getattr or object.__getattribute__ (via the . operator) to obtain a reference to some dangerous object via some allowed object (''.__class__.__bases__[0].__subclasses__ or similar).  getattr is eliminated by setting __builtins__ to None.  object.__getattribute__ is the difficult one, since it cannot simply be removed, both because object is immutable and because removing it would break everything.  However, __getattribute__ is only accessible via the . operator, so purging that from your input is sufficient to ensure eval cannot escape its sandbox. In processing formulas, the only valid use of a decimal is when it is preceded or followed by [0-9], so we just remove all other instances of ..  import re inp = re.sub(r\"\\.(?![0-9])\",\"\", inp) val = eval(inp, {'__builtins__':None})   Note that while python normally treats 1 + 1. as 1 + 1.0, this will remove the trailing . and leave you with 1 + 1.  You could add ),, and EOF to the list of things allowed to follow ., but why bother?     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  The reason eval and exec are so dangerous is that the default compile function will generate bytecode for any valid python expression, and the default eval or exec will execute any valid python bytecode.  All the answers to date have focused on restricting the bytecode that can be generated (by sanitizing input) or building your own domain-specific-language using the AST.    Instead, you can easily create a simple eval function that is incapable of doing anything nefarious and can easily have runtime checks on memory or time used.  Of course, if it is simple math, than there is a shortcut.  c = compile(stringExp, 'userinput', 'eval') if c.co_code[0]==b'd' and c.co_code[3]==b'S':     return c.co_consts[ord(c.co_code[1])+ord(c.co_code[2])*256]   The way this works is simple, any constant mathematic expression is safely evaluated during compilation and stored as a constant.  The code object returned by compile consists of d, which is the bytecode for LOAD_CONST, followed by the number of the constant to load (usually the last one in the list), followed by S, which is the bytecode for RETURN_VALUE.  If this shortcut doesn't work, it means that the user input isn't a constant expression (contains a variable or function call or similar).    This also opens the door to some more sophisticated input formats.  For example:  stringExp = \"1 + cos(2)\"   This requires actually evaluating the bytecode, which is still quite simple.  Python bytecode is a stack oriented language, so everything is a simple matter of TOS=stack.pop(); op(TOS); stack.put(TOS) or similar.  The key is to only implement the opcodes that are safe (loading/storing values, math operations, returning values) and not unsafe ones (attribute lookup).  If you want the user to be able to call functions (the whole reason not to use the shortcut above), simple make your implementation of CALL_FUNCTION only allow functions in a 'safe' list.  from dis import opmap from Queue import LifoQueue from math import sin,cos import operator  globs = {'sin':sin, 'cos':cos} safe = globs.values()  stack = LifoQueue()  class BINARY(object):     def __init__(self, operator):         self.op=operator     def __call__(self, context):         stack.put(self.op(stack.get(),stack.get()))  class UNARY(object):     def __init__(self, operator):         self.op=operator     def __call__(self, context):         stack.put(self.op(stack.get()))   def CALL_FUNCTION(context, arg):     argc = arg[0]+arg[1]*256     args = [stack.get() for i in range(argc)]     func = stack.get()     if func not in safe:         raise TypeError(\"Function %r now allowed\"%func)     stack.put(func(*args))  def LOAD_CONST(context, arg):     cons = arg[0]+arg[1]*256     stack.put(context['code'].co_consts[cons])  def LOAD_NAME(context, arg):     name_num = arg[0]+arg[1]*256     name = context['code'].co_names[name_num]     if name in context['locals']:         stack.put(context['locals'][name])     else:         stack.put(context['globals'][name])  def RETURN_VALUE(context):     return stack.get()  opfuncs = {     opmap['BINARY_ADD']: BINARY(operator.add),     opmap['UNARY_INVERT']: UNARY(operator.invert),     opmap['CALL_FUNCTION']: CALL_FUNCTION,     opmap['LOAD_CONST']: LOAD_CONST,     opmap['LOAD_NAME']: LOAD_NAME     opmap['RETURN_VALUE']: RETURN_VALUE, }  def VMeval(c):     context = dict(locals={}, globals=globs, code=c)     bci = iter(c.co_code)     for bytecode in bci:         func = opfuncs[ord(bytecode)]         if func.func_code.co_argcount==1:             ret = func(context)         else:             args = ord(bci.next()), ord(bci.next())             ret = func(context, args)         if ret:             return ret  def evaluate(expr):     return VMeval(compile(expr, 'userinput', 'eval'))   Obviously, the real version of this would be a bit longer (there are 119 opcodes, 24 of which are math related).  Adding STORE_FAST and a couple others would allow for input like 'x=5;return x+x or similar, trivially easily.  It can even be used to execute user-created functions, so long as the user created functions are themselves executed via VMeval (don't make them callable!!! or they could get used as a callback somewhere).  Handling loops requires support for the goto bytecodes, which means changing from a for iterator to while and maintaining a pointer to the current instruction, but isn't too hard.  For resistance to DOS, the main loop should check how much time has passed since the start of the calculation, and certain operators should deny input over some reasonable limit (BINARY_POWER being the most obvious).  While this approach is somewhat longer than a simple grammar parser for simple expressions (see above about just grabbing the compiled constant), it extends easily to more complicated input, and doesn't require dealing with grammar (compile take anything arbitrarily complicated and reduces it to a sequence of simple instructions).     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  You can use the ast module and write a NodeVisitor that verifies that the type of each node is part of a whitelist.  import ast, math  locals =  {key: value for (key,value) in vars(math).items() if key[0] != '_'} locals.update({\"abs\": abs, \"complex\": complex, \"min\": min, \"max\": max, \"pow\": pow, \"round\": round})  class Visitor(ast.NodeVisitor):     def visit(self, node):        if not isinstance(node, self.whitelist):            raise ValueError(node)        return super().visit(node)      whitelist = (ast.Module, ast.Expr, ast.Load, ast.Expression, ast.Add, ast.Sub, ast.UnaryOp, ast.Num, ast.BinOp,             ast.Mult, ast.Div, ast.Pow, ast.BitOr, ast.BitAnd, ast.BitXor, ast.USub, ast.UAdd, ast.FloorDiv, ast.Mod,             ast.LShift, ast.RShift, ast.Invert, ast.Call, ast.Name)  def evaluate(expr, locals = {}):     if any(elem in expr for elem in '\\n#') : raise ValueError(expr)     try:         node = ast.parse(expr.strip(), mode='eval')         Visitor().visit(node)         return eval(compile(node, \"<string>\", \"eval\"), {'__builtins__': None}, locals)     except Exception: raise ValueError(expr)   Because it works via a whitelist rather than a blacklist, it is safe. The only functions and variables it can access are those you explicitly give it access to. I populated a dict with math-related functions so you can easily provide access to those if you want, but you have to explicitly use it.  If the string attempts to call functions that haven't been provided, or invoke any methods, an exception will be raised, and it will not be executed.  Because this uses Python's built in parser and evaluator, it also inherits Python's precedence and promotion rules as well.  >>> evaluate(\"7 + 9 * (2 << 2)\") 79 >>> evaluate(\"6 // 2 + 0.0\") 3.0   The above code has only been tested on Python 3.  If desired, you can add a timeout decorator on this function.     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  I think I would use eval(), but would first check to make sure the string is a valid mathematical expression, as opposed to something malicious.  You could use a regex for the validation.  eval() also takes additional arguments which you can use to restrict the namespace it operates in for greater security.     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  This is a massively late reply, but I think useful for future reference. Rather than write your own math parser (although the pyparsing example above is great) you could use SymPy. I don't have a lot of experience with it, but it contains a much more powerful math engine than anyone is likely to write for a specific application and the basic expression evaluation is very easy:  >>> import sympy >>> x, y, z = sympy.symbols('x y z') >>> sympy.sympify(\"x**3 + sin(y)\").evalf(subs={x:1, y:-3}) 0.858879991940133   Very cool indeed! A from sympy import * brings in a lot more function support, such as trig functions, special functions, etc., but I've avoided that here to show what's coming from where.     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  [I know this is an old question, but it is worth pointing out new useful solutions as they pop up]  Since python3.6, this capability is now built into the language, coined \"f-strings\".  See: PEP 498 -- Literal String Interpolation  For example (note the f prefix):  f'{2**4}' => '16'      ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  If you don't want to use eval, then the only solution is to implement the appropriate grammar parser. Have a look at pyparsing.     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  Use eval in a clean namespace:  >>> ns = {'__builtins__': None} >>> eval('2 ** 4', ns) 16   The clean namespace should prevent injection. For instance:  >>> eval('__builtins__.__import__(\"os\").system(\"echo got through\")', ns) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<string>\", line 1, in <module> AttributeError: 'NoneType' object has no attribute '__import__'   Otherwise you would get:  >>> eval('__builtins__.__import__(\"os\").system(\"echo got through\")') got through 0   You might want to give access to the math module:  >>> import math >>> ns = vars(math).copy() >>> ns['__builtins__'] = None >>> eval('cos(pi/3)', ns) 0.50000000000000011      ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  If you are already using wolframalpha, they have a python api, which allows you to evaluate expressions. Might be a little slow, but at least very accurate.   https://pypi.python.org/pypi/wolframalpha     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Evaluating a mathematical expression in a string","A_Content":"  Python already has a function for safely evaluating strings containing literal expressions:  http://docs.python.org/2/library/ast.html#ast.literal_eval     ","Language":"Python","Tags":["python","math"],"URL":"https://stackoverflow.com/questions/2371436/evaluating-a-mathematical-expression-in-a-string","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    stringExp = \"2^4\" intVal = int(stringExp)      # Expected value: 16   This returns the following error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: invalid literal for int() with base 10: '2^4'   I know that eval can work around this, but isn't there a better and - more importantly - safer method to evaluate a mathematical expression that is being stored in a string?     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  If you're coming to Python from a language in the C/Java/etc. family, it may help you to stop thinking about a as a \"variable\", and start thinking of it as a \"name\".  a, b, and c aren't different variables with equal values; they're different names for the same identical value. Variables have types, identities, addresses, and all kinds of stuff like that.   Names don't have any of that. Values do, of course, and you can have lots of names for the same value.  If you give Notorious B.I.G. a hot dog,* Biggie Smalls and Chris Wallace have a hot dog. If you change the first element of a to 1, the first elements of b and c are 1.  If you want to know if two names are naming the same object, use the is operator:  >>> a=b=c=[0,3,5] >>> a is b True     You then ask:     what is different from this?   d=e=f=3 e=4 print('f:',f) print('e:',e)   Here, you're rebinding the name e to the value 4. That doesn't affect the names d and f in any way.  In your previous version, you were assigning to a[0], not to a. So, from the point of view of a[0], you're rebinding a[0], but from the point of view of a, you're changing it in-place.  You can use the id function, which gives you some unique number representing the identity of an object, to see exactly which object is which even when is can't help:  >>> a=b=c=[0,3,5] >>> id(a) 4473392520 >>> id(b) 4473392520 >>> id(a[0]) 4297261120 >>> id(b[0]) 4297261120  >>> a[0] = 1 >>> id(a) 4473392520 >>> id(b) 4473392520 >>> id(a[0]) 4297261216 >>> id(b[0]) 4297261216   Notice that a[0] has changed from 4297261120 to 4297261216it's now a name for a different value. And b[0] is also now a name for that same new value. That's because a and b are still naming the same object.    Under the covers, a[0]=1 is actually calling a method on the list object. (It's equivalent to a.__setitem__(0, 1).) So, it's not really rebinding anything at all. It's like calling my_object.set_something(1). Sure, likely the object is rebinding an instance attribute in order to implement this method, but that's not what's important; what's important is that you're not assigning anything, you're just mutating the object. And it's the same with a[0]=1.    user570826 asked:     What if we have, a = b = c =  10   That's exactly the same situation as a = b = c = [1, 2, 3]: you have three names for the same value.  But in this case, the value is an int, and ints are immutable. In either case, you can rebind a to a different value (e.g., a = \"Now I'm a string!\"), but the won't affect the original value, which b and c will still be names for. The difference is that with a list, you can change the value [1, 2, 3] into [1, 2, 3, 4] by doing, e.g., a.append(4); since that's actually changing the value that b and c are names for, b will now b [1, 2, 3, 4]. There's no way to change the value 10 into anything else. 10 is 10 forever, just like Claudia the vampire is 5 forever (at least until she's replaced by Kirsten Dunst).    * Warning: Do not give Notorious B.I.G. a hot dog. Gangsta rap zombies should never be fed after midnight.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"194","_type":"dict","isAccepted":"Yes","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  Cough cough  >>> a,b,c = (1,2,3) >>> a 1 >>> b 2 >>> c 3 >>> a,b,c = ({'test':'a'},{'test':'b'},{'test':'c'}) >>> a {'test': 'a'} >>> b {'test': 'b'} >>> c {'test': 'c'} >>>       ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  Yes, that's the expected behavior.  a, b and c are all set as labels for the same list.  If you want three different lists, you need to assign them individually.  You can either repeat the explicit list, or use one of the numerous ways to copy a list:  b = a[:] # this does a shallow copy, which is good enough for this case import copy c = copy.deepcopy(a) # this does a deep copy, which matters if the list contains mutable objects   Assignment statements in Python do not copy objects - they bind the the name to an object, and an object can have as many labels as you set.  In your first edit, changing a[0], you're updating one element of the single list that a, b, and c all refer to.  In your second, changing e, you're switching e to be a label for a different object (4 instead of 3).     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  In python, everything is an object, also \"simple\" variables types (int, float, etc..).  When you changes a variable value, you actually changes it's pointer, and if you compares between two variables it's compares their pointers. (To be clear, pointer is the address in physical computer memory where a variable is stored).  As a result, when you changes an inner variable value, you changes it's value in the memory and it's affects all the variables that point to this address.  For your example, when you do:  a = b =  5    This means that a and b points to the same address in memory that contains the value 5, but when you do:  a = 6   It's not affect b because  a is now points to another memory location that contains 6 and b still points to the memory address that contains 5.  But, when you do:  a = b = [1,2,3]   a and b, again, points to the same location but the difference is that if you change the one of the list values:  a[0] = 2   It's changes the value of the memory that a is points on, but a is still points to the same address as b, and as a result, b changes as well.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  You can use id(name) to check if two names represent the same object:  >>> a = b = c = [0, 3, 5] >>> print(id(a), id(b), id(c)) 46268488 46268488 46268488   Lists are mutable; it means you can change the value in place without creating a new object. However, it depends on how you change the value:  >>> a[0] = 1 >>> print(id(a), id(b), id(c)) 46268488 46268488 46268488 >>> print(a, b, c) [1, 3, 5] [1, 3, 5] [1, 3, 5]   If you assign a new list to a, then its id will change, so it won't affect b and c's values:  >>> a = [1, 8, 5] >>> print(id(a), id(b), id(c)) 139423880 46268488 46268488 >>> print(a, b, c) [1, 8, 5] [1, 3, 5] [1, 3, 5]   Integers are immutable, so you cannot change the value without creating a new object:  >>> x = y = z = 1 >>> print(id(x), id(y), id(z)) 507081216 507081216 507081216 >>> x = 2 >>> print(id(x), id(y), id(z)) 507081248 507081216 507081216 >>> print(x, y, z) 2 1 1      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  in your first example a = b = c = [1, 2, 3] you are really saying:   'a' is the same as 'b', is the same as 'c' and they are all [1, 2, 3]   If you want to set 'a' equal to 1, 'b' equal to '2' and 'c' equal to 3, try this:  a, b, c = [1, 2, 3]  print(a) --> 1 print(b) --> 2 print(c) --> 3   Hope this helps!     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  What you need is this:  a, b, c = [0,3,5] # Unpack the list, now a, b, and c are ints a = 1             # `a` did equal 0, not [0,3,5] print(a) print(b) print(c)      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  Simply put, in the first case, you are assigning multiple names to a list. Only one copy of list is created in memory and all names refer to that location. So changing the list using any of the names will actually modify the list in memory.  In the second case, multiple copies of same value are created in memory. So each copy is independent of one another.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"Python assigning multiple variables to same value? list behavior","A_Content":"  Thanks all for your clarifications.  the code that does what I need could be this:  #test aux=[[0 for n in range(3)] for i in range(4)] print('aux:',aux) #initialization a,b,c,d=[[0 for n in range(3)] for i in range(4)] #changing values a[0]=1 d[2]=5 print('a:',a) print('b:',b) print('c:',c) print('d:',d)   result:     ('aux:', [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])     ('a:', [1, 0, 0])     ('b:', [0, 0, 0])     ('c:', [0, 0, 0])     ('d:', [0, 0, 5])  Regards     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/16348815/python-assigning-multiple-variables-to-same-value-list-behavior","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I tried to use multiple assignment as show below to initialize variables, but I got confused by the behavior, I expect to reassign the values list separately, I mean  b[0] and c[0] equal 0 as before.  a=b=c=[0,3,5] a[0]=1 print(a) print(b) print(c)   Result is:     [1, 3, 5]     [1, 3, 5]     [1, 3, 5]  Is that correct? what should I use for multiple assignment? what is different from this?  d=e=f=3 e=4 print('f:',f) print('e:',e)   result:     ('f:', 3)     ('e:', 4)     ","Q_Votes":"82"},{"Q_Title":"What's the difference of ContentType and MimeType","A_Content":"     Why we use 2 different naming for   (almost the same) thing? Is   \"Content-Type\" just a name used in   browser requests, and with very little   use outside it?      What's the main difference between the   each one, and when is right to call   something mimetype as opposed to   content-type ? Am i being pitty and   grammar nazi?   The reason isn't only backward compatibility, and I'm afraid the usually excellent Django documentation is a bit hand-wavy about it. MIME (it's really worth reading at least the Wikipedia entry) has its origin in extending internet mail, and specifically SMTP. From there, the MIME and MIME-inspired extension design has found its way into a lot of other protocols (such as HTTP here), and is still being used when new kinds of metadata or data need to be transmitted in an existing protocol. There are dozens of RFCs that discuss MIME used for a plethora of purposes.  Specifically, Content-Type: is one among several MIME headers. \"Mimetype\" does indeed sound obsolete, but a reference to MIME itself isn't. Call that part backward-compatibility, if you will.  [BTW, this is purely a terminology problem which has nothing whatsoever to do with grammar. Filing every usage question under \"grammar\" is a pet peeve of mine. Grrrr.]     ","Language":"Python","Tags":["python","django","content-type","mime-types"],"URL":"https://stackoverflow.com/questions/3452381/whats-the-difference-of-contenttype-and-mimetype","A_Votes":"43","_type":"dict","isAccepted":"Yes","Q_Content":"    As far as I know, they are absolute equal. However, browsing some django docs, I've found this piece of code:  HttpResponse.__init__(content='', mimetype=None, status=200, content_type='text/html')  which surprise me the two getting along each other. The official docs was able to solve the issue in a pratical manner:     content_type is an alias for mimetype.   Historically, this parameter was only   called mimetype, but since this is   actually the value included in the   HTTP Content-Type header, it can also   include the character set encoding,   which makes it more than just a MIME   type specification. If mimetype is   specified (not None), that value is   used. Otherwise, content_type is used.   If neither is given, the   DEFAULT_CONTENT_TYPE setting is used.   However, I don't find it elucidating enough. Why we use 2 different naming for (almost the same) thing? Is \"Content-Type\" just a name used in browser requests, and with very little use outside it?  What's the main difference between the each one, and when is right to call something mimetype as opposed to content-type ? Am I being pitty and grammar nazi?     ","Q_Votes":"83"},{"Q_Title":"What's the difference of ContentType and MimeType","A_Content":"  I've always viewed contentType to be a superset of mimeType.  The only difference being the optional character set encoding.  If the contentType does not include an optional character set encoding then it is identical to a mimeType.  Otherwise, the mimeType is the data prior to the character set encoding sequence.  E.G. text/html; charset=UTF-8  text/html is the mimeType ; is the additional parameters indicator charset=UTF-8 is the character set encoding parameter  E.G. application/msword  application/msword is the mimeType It cannot have a character set encoding as it describes a well formed octet-stream not comprising characters directly.     ","Language":"Python","Tags":["python","django","content-type","mime-types"],"URL":"https://stackoverflow.com/questions/3452381/whats-the-difference-of-contenttype-and-mimetype","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know, they are absolute equal. However, browsing some django docs, I've found this piece of code:  HttpResponse.__init__(content='', mimetype=None, status=200, content_type='text/html')  which surprise me the two getting along each other. The official docs was able to solve the issue in a pratical manner:     content_type is an alias for mimetype.   Historically, this parameter was only   called mimetype, but since this is   actually the value included in the   HTTP Content-Type header, it can also   include the character set encoding,   which makes it more than just a MIME   type specification. If mimetype is   specified (not None), that value is   used. Otherwise, content_type is used.   If neither is given, the   DEFAULT_CONTENT_TYPE setting is used.   However, I don't find it elucidating enough. Why we use 2 different naming for (almost the same) thing? Is \"Content-Type\" just a name used in browser requests, and with very little use outside it?  What's the main difference between the each one, and when is right to call something mimetype as opposed to content-type ? Am I being pitty and grammar nazi?     ","Q_Votes":"83"},{"Q_Title":"What's the difference of ContentType and MimeType","A_Content":"  If you want to know the details see ticket 3526.  Quote:     Added content_type as an alias for   mimetype to the HttpResponse   constructor. It's a slightly more   accurate name. Based on a patch from   Simon Willison. Fully backwards   compatible.      ","Language":"Python","Tags":["python","django","content-type","mime-types"],"URL":"https://stackoverflow.com/questions/3452381/whats-the-difference-of-contenttype-and-mimetype","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know, they are absolute equal. However, browsing some django docs, I've found this piece of code:  HttpResponse.__init__(content='', mimetype=None, status=200, content_type='text/html')  which surprise me the two getting along each other. The official docs was able to solve the issue in a pratical manner:     content_type is an alias for mimetype.   Historically, this parameter was only   called mimetype, but since this is   actually the value included in the   HTTP Content-Type header, it can also   include the character set encoding,   which makes it more than just a MIME   type specification. If mimetype is   specified (not None), that value is   used. Otherwise, content_type is used.   If neither is given, the   DEFAULT_CONTENT_TYPE setting is used.   However, I don't find it elucidating enough. Why we use 2 different naming for (almost the same) thing? Is \"Content-Type\" just a name used in browser requests, and with very little use outside it?  What's the main difference between the each one, and when is right to call something mimetype as opposed to content-type ? Am I being pitty and grammar nazi?     ","Q_Votes":"83"},{"Q_Title":"What's the difference of ContentType and MimeType","A_Content":"     Why we use 2 different naming for (almost the same) thing?   Backwards compatibility, based on your quote from the documentation.     ","Language":"Python","Tags":["python","django","content-type","mime-types"],"URL":"https://stackoverflow.com/questions/3452381/whats-the-difference-of-contenttype-and-mimetype","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know, they are absolute equal. However, browsing some django docs, I've found this piece of code:  HttpResponse.__init__(content='', mimetype=None, status=200, content_type='text/html')  which surprise me the two getting along each other. The official docs was able to solve the issue in a pratical manner:     content_type is an alias for mimetype.   Historically, this parameter was only   called mimetype, but since this is   actually the value included in the   HTTP Content-Type header, it can also   include the character set encoding,   which makes it more than just a MIME   type specification. If mimetype is   specified (not None), that value is   used. Otherwise, content_type is used.   If neither is given, the   DEFAULT_CONTENT_TYPE setting is used.   However, I don't find it elucidating enough. Why we use 2 different naming for (almost the same) thing? Is \"Content-Type\" just a name used in browser requests, and with very little use outside it?  What's the main difference between the each one, and when is right to call something mimetype as opposed to content-type ? Am I being pitty and grammar nazi?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  From what i've read about bundler  pip without virtualenv should work just fine for you. You can think of it as something between regular gem command and bundler. Common things that you can do with pip:   Installing packages (gem install)  pip install mypackage  Dependencies and bulk-install (gemfile)  Probably the easiest way is to use pip's requirements.txt files. Basically it's just a plain list of required packages with possible version constraints. It might look something like:  nose==1.1.2 django<1.3 PIL   Later when you'd want to install those dependencies you would do:  $ pip install -r requirements.txt   A simple way to see all your current packages in requirements-file syntax is to do:  $ pip freeze   You can read more about it here. Execution (bundler exec)  All python packages that come with executable files are usually directly available after install (unless you have custom setup or it's a special package). For example:  $ pip install gunicorn $ gunicorn -h   Package gems for install from cache (bundler package)  There is pip bundle and pip zip/unzip. But i'm not sure if many people use it.   p.s. If you do care about environment isolation you can also use virtualenv together with pip (they are close friends and work perfectly together). By default pip installs packages system-wide which might require admin rights.      ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"71","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  You can use pipenv, which has similar interface with bundler.  $ pip install pipenv   Pipenv creates virtualenv automatically and installs dependencies from Pipfile or Pipfile.lock.  $ pipenv --three           # Create virtualenv with Python3 $ pipenv install           # Install dependencies from Pipfile $ pipenv install requests  # Install `requests` and update Pipfile $ pipenv lock              # Generate `Pipfile.lock` $ pipenv shell             # Run shell with virtualenv activated   You can run command with virtualenv scope like bundle exec.  $ pipenv run python3 -c \"print('hello!')\"      ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  There is a clone pbundler.   The version that is currently in pip simply reads the requirements.txt file you already have, but is much out of date. It's also not totally equivalent: it insists on making a virtualenv. Bundler, I notice, only installs what packages are missing, and gives you the option of giving your sudo password to install into your system dirs or of restarting, which doesn't seem to be a feature of pbundler.  However, the version on git is an almost complete rewrite to be much closer to Bundler's behaviour... including having a \"Cheesefile\" and now not supporting requirements.txt. This is unfortunate, since requirements.txt is the de facto standard in pythonland, and there's even Offical BDFL-stamped work to standardize it. When that comes into force, you can be sure that something like pbundler will become the de facto standard. Alas, nothing quite stable yet that I know of (but I would love to be proven wrong).     ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  No, no all the developers use virtualenv and/or pip, but many developers use/prefer these tools  And now, for package development tools and diferent environments that is your real question. Exist any other tools like Buildout (http://www.buildout.org/en/latest/) for the same purpose, isolate your environment Python build system for every project that you manage. For some time I use this, but not now.   Independent environments per project, in Python are a little different that the same situation in Ruby. In my case i use pyenv (https://github.com/yyuu/pyenv) that is something like rbenv but, for Python. diferent versions of python and virtualenvs per project, and, in this isolated environments, i can use pip or easy-install (if is needed).     ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  I wrote one  https://github.com/Deepwalker/pundler . On PIP its pundle, name was already taken.  It uses requirements(_\\w+)?.txt files as your desired dependencies and creates frozen(_\\w+)?.txt files with frozen versions.  About (_\\w+)? thing  this is envs. You can create requirements_test.txt and then use PUNDLEENV=test to use this deps in your run with requirements.txt ones alongside.  And about virtualenv  you need not one, its what pundle takes from bundler in first head.     ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"What are the Python equivalents to Ruby's bundler / Perl's carton?","A_Content":"  I'd say Shovel is worth a look. It was developed specifically to the the Pythonish version of Rake. There's not a ton of commit activity on the project, but seems stable and useful.     ","Language":"Python","Tags":["python","ruby","perl","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/8726207/what-are-the-python-equivalents-to-rubys-bundler-perls-carton","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I know about virtualenv and pip. But these are a bit different from bundler/carton.  For instance:   pip writes the absolute path to shebang or activate script pip doesn't have the exec sub command (bundle exec bar) virtualenv copies the Python interpreter to a local directory   Does every Python developer use virtualenv/pip? Are there other package management tools for Python?     ","Q_Votes":"83"},{"Q_Title":"How do I handle the window close event in Tkinter?","A_Content":"  Tkinter supports a mechanism called protocol handlers. Here, the term protocol refers to the interaction between the application and the window manager. The most commonly used protocol is called WM_DELETE_WINDOW, and is used to define what happens when the user explicitly closes a window using the window manager.  You can use the protocol method to install a handler for this protocol (the widget must be a Tk or Toplevel widget):  Here you have a concrete example:  import tkinter as tk from tkinter import messagebox  root = tk.Tk()  def on_closing():     if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):         root.destroy()  root.protocol(\"WM_DELETE_WINDOW\", on_closing) root.mainloop()      ","Language":"Python","Tags":["python","events","tkinter","window"],"URL":"https://stackoverflow.com/questions/111155/how-do-i-handle-the-window-close-event-in-tkinter","A_Votes":"108","_type":"dict","isAccepted":"No","Q_Content":"    How do I handle the window close event (user clicking the 'X' button) in a Python Tkinter program?     ","Q_Votes":"83"},{"Q_Title":"How do I handle the window close event in Tkinter?","A_Content":"  Matt has shown one classic modification of the close button. The other is to have the close button minimize the window. You can reproduced this behavior by having the iconify method be the protocol method's second argument.  Here's a working example, tested on Windows 7:  # Python 3 import tkinter import tkinter.scrolledtext as scrolledtext  class GUI(object):      def __init__(self):         root = self.root = tkinter.Tk()         root.title('Test')      # make the top right close button minimize (iconify) the main window         root.protocol(\"WM_DELETE_WINDOW\", root.iconify)      # make Esc exit the program         root.bind('<Escape>', lambda e: root.destroy())      # create a menu bar with an Exit command         menubar = tkinter.Menu(root)         filemenu = tkinter.Menu(menubar, tearoff=0)         filemenu.add_command(label=\"Exit\", command=root.destroy)         menubar.add_cascade(label=\"File\", menu=filemenu)         root.config(menu=menubar)      # create a Text widget with a Scrollbar attached         txt = scrolledtext.ScrolledText(root, undo=True)         txt['font'] = ('consolas', '12')         txt.pack(expand=True, fill='both')  gui = GUI() gui.root.mainloop()   In this example we give the user two new exit options: the classic file menu -> Exit, and also the Esc button.     ","Language":"Python","Tags":["python","events","tkinter","window"],"URL":"https://stackoverflow.com/questions/111155/how-do-i-handle-the-window-close-event-in-tkinter","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    How do I handle the window close event (user clicking the 'X' button) in a Python Tkinter program?     ","Q_Votes":"83"},{"Q_Title":"How do I handle the window close event in Tkinter?","A_Content":"  Depending on the Tkinter activity, end esp. when using Tkinter.after, stopping this activity with destroy() -- even by using protocol(), a button, etc. --  will disturb this activity (\"while executing\" error) rather than just terminate it. The best solution in almost every case is to use a flag. Here is a simple, silly example of how to use it (although I am certain that most of you don't need it! :)  from Tkinter import *  def close_window():   global running   running = False   print \"Window closed\"  root = Tk() root.protocol(\"WM_DELETE_WINDOW\", close_window) cv = Canvas(root, width=200, height=200); cv.pack()  running = True; # This is an endless loop stopped only by setting 'running' to 'False' while running:    for i in range(200):      if not running: break     cv.create_oval(i,i,i+1,i+1); root.update()    This terminates graphics activity nicely. You only need to check running at the right place(s).      ","Language":"Python","Tags":["python","events","tkinter","window"],"URL":"https://stackoverflow.com/questions/111155/how-do-i-handle-the-window-close-event-in-tkinter","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do I handle the window close event (user clicking the 'X' button) in a Python Tkinter program?     ","Q_Votes":"83"},{"Q_Title":"Why don't I get any syntax errors when I execute my Python script with Perl?","A_Content":"  From perlrun,     If the #! line does not contain the word \"perl\" nor the word \"indir\" the program named after the #! is executed instead of the Perl interpreter. This is slightly bizarre, but it helps people on machines that don't do #! , because they can tell a program that their SHELL is /usr/bin/perl, and Perl will then dispatch the program to the correct interpreter for them.   For example,  $ cat a #!/bin/cat meow  $ perl a #!/bin/cat meow      ","Language":"Python","Tags":["python","perl"],"URL":"https://stackoverflow.com/questions/29563832/why-dont-i-get-any-syntax-errors-when-i-execute-my-python-script-with-perl","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    I just wrote some testing python code into test.py, and I'm launching it as follows:  perl test.py   After a while I realized my mistake. I say \"after a while\", because the Python code gets actually correctly executed, as if in Python interpreter!  Why is my Perl interpreting my Python? test.py looks like this:  #!/usr/bin/python  ...Python code here...   Interestingly, if I do the opposite (i.e. call python something.pl) I get a good deal of syntax errors.     ","Q_Votes":"83"},{"Q_Title":"How to divide flask app into multiple py files?","A_Content":"  You can use the usual Python package structure to divide your App into multiple modules, see the Flask docs.  However,     Flask uses a concept of blueprints for making application components and supporting common patterns within an application or across applications.   You can create a sub-component of your app as a Blueprint in a separate file:  simple_page = Blueprint('simple_page', __name__, template_folder='templates') @simple_page.route('/<page>') def show(page):     # stuff   And then use it in the main part:  from yourapplication.simple_page import simple_page  app = Flask(__name__) app.register_blueprint(simple_page)   Blueprints can also bundle specific resources: templates or static files. Please refer to the Flask docs for all the details.     ","Language":"Python","Tags":["python","flask"],"URL":"https://stackoverflow.com/questions/11994325/how-to-divide-flask-app-into-multiple-py-files","A_Votes":"99","_type":"dict","isAccepted":"Yes","Q_Content":"    My flask application currently consists of a single test.py file with multiple routes and the main() route defined. Is there some way I could create a test2.py file that contains routes that were not handled in test.py?  @app.route('/somepath') def somehandler():     # Handler code here   I am concerned that there are too many routes in test.py and would like to make it such that I can run python test.py, which will also pick up the routes on test.py as if it were part of the same file. What changes to I have to make in test.py and/or include in test2.py to get this to work?     ","Q_Votes":"83"},{"Q_Title":"How to divide flask app into multiple py files?","A_Content":"  I would like to recommend flask-empty at GitHub.  It provides an easy way to understand Blueprints, multiple views and extensions.     ","Language":"Python","Tags":["python","flask"],"URL":"https://stackoverflow.com/questions/11994325/how-to-divide-flask-app-into-multiple-py-files","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    My flask application currently consists of a single test.py file with multiple routes and the main() route defined. Is there some way I could create a test2.py file that contains routes that were not handled in test.py?  @app.route('/somepath') def somehandler():     # Handler code here   I am concerned that there are too many routes in test.py and would like to make it such that I can run python test.py, which will also pick up the routes on test.py as if it were part of the same file. What changes to I have to make in test.py and/or include in test2.py to get this to work?     ","Q_Votes":"83"},{"Q_Title":"How to divide flask app into multiple py files?","A_Content":"  Dividing the app into blueprints is a great idea. However, if this isn't enough, and if you want to then divide the Blueprint itself into multiple py files, this is also possible using the regular Python module import system, and then looping through all the routes that get imported from the other files.  I created a Gist with the code for doing this:  https://gist.github.com/Jaza/61f879f577bc9d06029e  As far as I'm aware, this is the only feasible way to divide up a Blueprint at the moment. It's not possible to create \"sub-blueprints\" in Flask, although there's an issue open with a lot of discussion about this:  https://github.com/mitsuhiko/flask/issues/593  Also, even if it were possible (and it's probably do-able using some of the snippets from that issue thread), sub-blueprints may be too restrictive for your use case anyway - e.g. if you don't want all the routes in a sub-module to have the same URL sub-prefix.     ","Language":"Python","Tags":["python","flask"],"URL":"https://stackoverflow.com/questions/11994325/how-to-divide-flask-app-into-multiple-py-files","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    My flask application currently consists of a single test.py file with multiple routes and the main() route defined. Is there some way I could create a test2.py file that contains routes that were not handled in test.py?  @app.route('/somepath') def somehandler():     # Handler code here   I am concerned that there are too many routes in test.py and would like to make it such that I can run python test.py, which will also pick up the routes on test.py as if it were part of the same file. What changes to I have to make in test.py and/or include in test2.py to get this to work?     ","Q_Votes":"83"},{"Q_Title":"How can I profile Python code line-by-line?","A_Content":"  I believe that's what Robert Kern's line_profiler is intended for.  From the link:  File: pystone.py Function: Proc2 at line 149 Total time: 0.606656 s  Line #      Hits         Time  Per Hit   % Time  Line Contents ==============================================================    149                                           @profile    150                                           def Proc2(IntParIO):    151     50000        82003      1.6     13.5      IntLoc = IntParIO + 10    152     50000        63162      1.3     10.4      while 1:    153     50000        69065      1.4     11.4          if Char1Glob == 'A':    154     50000        66354      1.3     10.9              IntLoc = IntLoc - 1    155     50000        67263      1.3     11.1              IntParIO = IntLoc - IntGlob    156     50000        65494      1.3     10.8              EnumLoc = Ident1    157     50000        68001      1.4     11.2          if EnumLoc == Ident1:    158     50000        63739      1.3     10.5              break    159     50000        61575      1.2     10.1      return IntParIO   Hope that helps!     ","Language":"Python","Tags":["python","profiling","line-by-line"],"URL":"https://stackoverflow.com/questions/3927628/how-can-i-profile-python-code-line-by-line","A_Votes":"97","_type":"dict","isAccepted":"Yes","Q_Content":"    I've been using cProfile to profile my code, and it's been working great. I also use gprof2dot.py to visualize the results (makes it a little clearer).  However, cProfile (and most other Python profilers I've seen so far) seem to only profile at the function-call level. This causes confusion when certain functions are called from different places - I have no idea if call #1 or call #2 is taking up the majority of the time. This gets even worse when the function in question is six levels deep, called from seven other places.  How do I get a line-by-line profiling?  Instead of this:  function #12, total time: 2.0s   I'd like to see something like this:  function #12 (called from somefile.py:102) 0.5s function #12 (called from main.py:12) 1.5s   cProfile does show how much of the total time \"transfers\" to the parent, but again this connection is lost when you have a bunch of layers and interconnected calls.  Ideally, I'd love to have a GUI that would parse through the data, then show me my source file with a total time given to each line. Something like this:  main.py:  a = 1 # 0.0s result = func(a) # 0.4s c = 1000 # 0.0s result = func(c) # 5.0s   Then I'd be able to click on the second \"func(c)\" call to see what's taking up time in that call, separate from the \"func(a)\" call.  Does that make sense? Is there any profiling library that collects this type of information? Is there some awesome tool I've missed?     ","Q_Votes":"83"},{"Q_Title":"How can I profile Python code line-by-line?","A_Content":"  You could also use pprofile(pypi). If you want to profile the entire execution, it does not require source code modification.  You can also profile a subset of a larger program in two ways:   toggle profiling when reaching a specific point in the code, such as:  import pprofile profiler = pprofile.Profile() with profiler:     some_code # Process profile content: generate a cachegrind file and send it to user.  toggle profiling asynchronously from call stack (requires a way to trigger this code in considered application, for example a signal handler or an available worker thread) by using statistical profiling:  import pprofile profiler = pprofile.StatisticalProfile() statistical_profiler_thread = pprofile.StatisticalThread(     profiler=profiler, ) with statistical_profiler_thread:     sleep(n) # Likewise, process profile content    Code annotation output format is much like line profiler:  $ pprofile --threads 0 demo/threads.py Command line: ['demo/threads.py'] Total duration: 1.00573s File: demo/threads.py File duration: 1.00168s (99.60%) Line #|      Hits|         Time| Time per hit|      %|Source code ------+----------+-------------+-------------+-------+-----------      1|         2|  3.21865e-05|  1.60933e-05|  0.00%|import threading      2|         1|  5.96046e-06|  5.96046e-06|  0.00%|import time      3|         0|            0|            0|  0.00%|      4|         2|   1.5974e-05|  7.98702e-06|  0.00%|def func():      5|         1|      1.00111|      1.00111| 99.54%|  time.sleep(1)      6|         0|            0|            0|  0.00%|      7|         2|  2.00272e-05|  1.00136e-05|  0.00%|def func2():      8|         1|  1.69277e-05|  1.69277e-05|  0.00%|  pass      9|         0|            0|            0|  0.00%|     10|         1|  1.81198e-05|  1.81198e-05|  0.00%|t1 = threading.Thread(target=func) (call)|         1|  0.000610828|  0.000610828|  0.06%|# /usr/lib/python2.7/threading.py:436 __init__     11|         1|  1.52588e-05|  1.52588e-05|  0.00%|t2 = threading.Thread(target=func) (call)|         1|  0.000438929|  0.000438929|  0.04%|# /usr/lib/python2.7/threading.py:436 __init__     12|         1|  4.79221e-05|  4.79221e-05|  0.00%|t1.start() (call)|         1|  0.000843048|  0.000843048|  0.08%|# /usr/lib/python2.7/threading.py:485 start     13|         1|  6.48499e-05|  6.48499e-05|  0.01%|t2.start() (call)|         1|   0.00115609|   0.00115609|  0.11%|# /usr/lib/python2.7/threading.py:485 start     14|         1|  0.000205994|  0.000205994|  0.02%|(func(), func2()) (call)|         1|      1.00112|      1.00112| 99.54%|# demo/threads.py:4 func (call)|         1|  3.09944e-05|  3.09944e-05|  0.00%|# demo/threads.py:7 func2     15|         1|  7.62939e-05|  7.62939e-05|  0.01%|t1.join() (call)|         1|  0.000423908|  0.000423908|  0.04%|# /usr/lib/python2.7/threading.py:653 join     16|         1|  5.26905e-05|  5.26905e-05|  0.01%|t2.join() (call)|         1|  0.000320196|  0.000320196|  0.03%|# /usr/lib/python2.7/threading.py:653 join   Note that because pprofile does not rely on code modification it can profile top-level module statements, allowing to profile program startup time (how long it takes to import modules, initialise globals, ...).  It can generate cachegrind-formatted output, so you can use kcachegrind to browse large results easily.  Disclosure: I am pprofile author.     ","Language":"Python","Tags":["python","profiling","line-by-line"],"URL":"https://stackoverflow.com/questions/3927628/how-can-i-profile-python-code-line-by-line","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I've been using cProfile to profile my code, and it's been working great. I also use gprof2dot.py to visualize the results (makes it a little clearer).  However, cProfile (and most other Python profilers I've seen so far) seem to only profile at the function-call level. This causes confusion when certain functions are called from different places - I have no idea if call #1 or call #2 is taking up the majority of the time. This gets even worse when the function in question is six levels deep, called from seven other places.  How do I get a line-by-line profiling?  Instead of this:  function #12, total time: 2.0s   I'd like to see something like this:  function #12 (called from somefile.py:102) 0.5s function #12 (called from main.py:12) 1.5s   cProfile does show how much of the total time \"transfers\" to the parent, but again this connection is lost when you have a bunch of layers and interconnected calls.  Ideally, I'd love to have a GUI that would parse through the data, then show me my source file with a total time given to each line. Something like this:  main.py:  a = 1 # 0.0s result = func(a) # 0.4s c = 1000 # 0.0s result = func(c) # 5.0s   Then I'd be able to click on the second \"func(c)\" call to see what's taking up time in that call, separate from the \"func(a)\" call.  Does that make sense? Is there any profiling library that collects this type of information? Is there some awesome tool I've missed?     ","Q_Votes":"83"},{"Q_Title":"How can I profile Python code line-by-line?","A_Content":"  PyVmMonitor has a live-view which can help you there (you can connect to a running program and get statistics from it).  See: http://www.pyvmmonitor.com/     ","Language":"Python","Tags":["python","profiling","line-by-line"],"URL":"https://stackoverflow.com/questions/3927628/how-can-i-profile-python-code-line-by-line","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've been using cProfile to profile my code, and it's been working great. I also use gprof2dot.py to visualize the results (makes it a little clearer).  However, cProfile (and most other Python profilers I've seen so far) seem to only profile at the function-call level. This causes confusion when certain functions are called from different places - I have no idea if call #1 or call #2 is taking up the majority of the time. This gets even worse when the function in question is six levels deep, called from seven other places.  How do I get a line-by-line profiling?  Instead of this:  function #12, total time: 2.0s   I'd like to see something like this:  function #12 (called from somefile.py:102) 0.5s function #12 (called from main.py:12) 1.5s   cProfile does show how much of the total time \"transfers\" to the parent, but again this connection is lost when you have a bunch of layers and interconnected calls.  Ideally, I'd love to have a GUI that would parse through the data, then show me my source file with a total time given to each line. Something like this:  main.py:  a = 1 # 0.0s result = func(a) # 0.4s c = 1000 # 0.0s result = func(c) # 5.0s   Then I'd be able to click on the second \"func(c)\" call to see what's taking up time in that call, separate from the \"func(a)\" call.  Does that make sense? Is there any profiling library that collects this type of information? Is there some awesome tool I've missed?     ","Q_Votes":"83"},{"Q_Title":"Dynamically updating plot in matplotlib","A_Content":"     Is there a way in which I can update the plot just by adding more point[s] to it...   There are a number of ways of animating data in matplotlib, depending on the version you have. Have you seen the matplotlib cookbook examples? Also, check out the more modern animation examples in the matplotlib documentation. Finally, the animation API defines a function FuncAnimation which animates a function in time. This function could just be the function you use to acquire your data.  Each method basically sets the data property of the object being drawn, so doesn't require clearing the screen or figure. The data property can simply be extended, so you can keep the previous points and just keep adding to your line (or image or whatever you are drawing).  Given that you say that your data arrival time is uncertain your best bet is probably just to do something like:  import matplotlib.pyplot as plt import numpy  hl, = plt.plot([], [])  def update_line(hl, new_data):     hl.set_xdata(numpy.append(hl.get_xdata(), new_data))     hl.set_ydata(numpy.append(hl.get_ydata(), new_data))     plt.draw()   Then when you receive data from the serial port just call update_line.     ","Language":"Python","Tags":["python","matplotlib","tkinter"],"URL":"https://stackoverflow.com/questions/10944621/dynamically-updating-plot-in-matplotlib","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    I am making an application in Python which collects data from a serial port and plots a graph of the collected data against arrival time. The time of arrival for the data is uncertain. I want the plot to be updated when data is received. I searched on how to do this and found two methods:   Clear the plot and re-draw the plot with all the points again. Animate the plot by changing it after a particular interval.   I do not prefer the first one as the program runs and collects data for a long time (a day for example), and redrawing the plot will be pretty slow. The second one is also not preferable as time of arrival of data is uncertain and I want the plot to update only when the data is received.  Is there a way in which I can update the plot just by adding more points to it only when the data is received?     ","Q_Votes":"83"},{"Q_Title":"Dynamically updating plot in matplotlib","A_Content":"  In order to do this without FuncAnimation (eg you want to execute other parts of the code while the plot is been produced or you want to be updating several plots at the same time), calling draw alone does not produce the plot (at least with the qt backend).  The following works for me:  import matplotlib.pyplot as plt plt.ion() class DynamicUpdate():     #Suppose we know the x range     min_x = 0     max_x = 10      def on_launch(self):         #Set up plot         self.figure, self.ax = plt.subplots()         self.lines, = self.ax.plot([],[], 'o')         #Autoscale on unknown axis and known lims on the other         self.ax.set_autoscaley_on(True)         self.ax.set_xlim(self.min_x, self.max_x)         #Other stuff         self.ax.grid()         ...      def on_running(self, xdata, ydata):         #Update data (with the new _and_ the old points)         self.lines.set_xdata(xdata)         self.lines.set_ydata(ydata)         #Need both of these in order to rescale         self.ax.relim()         self.ax.autoscale_view()         #We need to draw *and* flush         self.figure.canvas.draw()         self.figure.canvas.flush_events()      #Example     def __call__(self):         import numpy as np         import time         self.on_launch()         xdata = []         ydata = []         for x in np.arange(0,10,0.5):             xdata.append(x)             ydata.append(np.exp(-x**2)+10*np.exp(-(x-7)**2))             self.on_running(xdata, ydata)             time.sleep(1)         return xdata, ydata  d = DynamicUpdate() d()      ","Language":"Python","Tags":["python","matplotlib","tkinter"],"URL":"https://stackoverflow.com/questions/10944621/dynamically-updating-plot-in-matplotlib","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I am making an application in Python which collects data from a serial port and plots a graph of the collected data against arrival time. The time of arrival for the data is uncertain. I want the plot to be updated when data is received. I searched on how to do this and found two methods:   Clear the plot and re-draw the plot with all the points again. Animate the plot by changing it after a particular interval.   I do not prefer the first one as the program runs and collects data for a long time (a day for example), and redrawing the plot will be pretty slow. The second one is also not preferable as time of arrival of data is uncertain and I want the plot to update only when the data is received.  Is there a way in which I can update the plot just by adding more points to it only when the data is received?     ","Q_Votes":"83"},{"Q_Title":"Dynamically updating plot in matplotlib","A_Content":"  I know I'm late to answer this question, but for your issue you could look into the \"joystick\" package. I designed it for plotting a stream of data from the serial port, but it works for any stream. It also allows for interactive text logging or image plotting (in addition to graph plotting). No need to do your own loops in a separate thread, the package takes care of it, just give the update frequency you wish. Plus the terminal remains available for monitoring commands while plotting. See http://www.github.com/ceyzeriat/joystick/ or https://pypi.python.org/pypi/joystick (use pip install joystick to install)  Just replace np.random.random() by your real data point read from the serial port in the code below:  import joystick as jk import numpy as np import time  class test(jk.Joystick):     # initialize the infinite loop decorator     _infinite_loop = jk.deco_infinite_loop()      def _init(self, *args, **kwargs):         \"\"\"         Function called at initialization, see the doc         \"\"\"         self._t0 = time.time()  # initialize time         self.xdata = np.array([self._t0])  # time x-axis         self.ydata = np.array([0.0])  # fake data y-axis         # create a graph frame         self.mygraph = self.add_frame(jk.Graph(name=\"test\", size=(500, 500), pos=(50, 50), fmt=\"go-\", xnpts=10000, xnptsmax=10000, xylim=(None, None, 0, 1)))      @_infinite_loop(wait_time=0.2)     def _generate_data(self):  # function looped every 0.2 second to read or produce data         \"\"\"         Loop starting with the simulation start, getting data and     pushing it to the graph every 0.2 seconds         \"\"\"         # concatenate data on the time x-axis         self.xdata = jk.core.add_datapoint(self.xdata, time.time(), xnptsmax=self.mygraph.xnptsmax)         # concatenate data on the fake data y-axis         self.ydata = jk.core.add_datapoint(self.ydata, np.random.random(), xnptsmax=self.mygraph.xnptsmax)         self.mygraph.set_xydata(t, self.ydata)  t = test() t.start() t.stop()      ","Language":"Python","Tags":["python","matplotlib","tkinter"],"URL":"https://stackoverflow.com/questions/10944621/dynamically-updating-plot-in-matplotlib","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am making an application in Python which collects data from a serial port and plots a graph of the collected data against arrival time. The time of arrival for the data is uncertain. I want the plot to be updated when data is received. I searched on how to do this and found two methods:   Clear the plot and re-draw the plot with all the points again. Animate the plot by changing it after a particular interval.   I do not prefer the first one as the program runs and collects data for a long time (a day for example), and redrawing the plot will be pretty slow. The second one is also not preferable as time of arrival of data is uncertain and I want the plot to update only when the data is received.  Is there a way in which I can update the plot just by adding more points to it only when the data is received?     ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  For arbitrary-length integers, bin(n).count(\"1\") is the fastest I could find in pure Python.  I tried adapting scar's and Adam's solutions to process the integer in 64-bit and 32-bit chunks, respectively. Both were at least ten times slower than bin(n).count(\"1\") (the 32-bit version took about half again as much time).  On the other hand, gmpy popcount() took about 1/20th of the time of bin(n).count(\"1\"). So if you can install gmpy, use that.     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"86","_type":"dict","isAccepted":"Yes","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  You can adapt the following algorithm:  def CountBits(n):   n = (n & 0x5555555555555555) + ((n & 0xAAAAAAAAAAAAAAAA) >> 1)   n = (n & 0x3333333333333333) + ((n & 0xCCCCCCCCCCCCCCCC) >> 2)   n = (n & 0x0F0F0F0F0F0F0F0F) + ((n & 0xF0F0F0F0F0F0F0F0) >> 4)   n = (n & 0x00FF00FF00FF00FF) + ((n & 0xFF00FF00FF00FF00) >> 8)   n = (n & 0x0000FFFF0000FFFF) + ((n & 0xFFFF0000FFFF0000) >> 16)   n = (n & 0x00000000FFFFFFFF) + ((n & 0xFFFFFFFF00000000) >> 32) # This last & isn't strictly necessary.   return n   This works for 64-bit positive numbers, but it's easily extendable and the number of operations growth with the logarithm of the argument (i.e. linearly with the bit-size of the argument).  In order to understand how this works imagine that you divide the entire 64-bit string into 64 1-bit buckets. Each bucket's value is equal to the number of bits set in the bucket (0 if no bits are set and 1 if one bit is set). The first transformation results in an analogous state, but with 32 buckets each 2-bit long. This is achieved by appropriately shifting the buckets and adding their values (one addition takes care of all buckets since no carry can occur across buckets - n-bit number is always long enough to encode number n). Further transformations lead to states with exponentially decreasing number of buckets of exponentially growing size until we arrive at one 64-bit long bucket. This gives the number of bits set in the original argument.     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  Here's a Python implementation of the population count algorithm, as explained in this post:  def numberOfSetBits(i):     i = i - ((i >> 1) & 0x55555555)     i = (i & 0x33333333) + ((i >> 2) & 0x33333333)     return (((i + (i >> 4) & 0xF0F0F0F) * 0x1010101) & 0xffffffff) >> 24   It will work for 0 <= i < 0x100000000.     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  According to this post, this seems to be one the fastest implementation of the Hamming weight (if you don't mind using about 64KB of memory).  #http://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetTable POPCOUNT_TABLE16 = [0] * 2**16 for index in range(len(POPCOUNT_TABLE16)):     POPCOUNT_TABLE16[index] = (index & 1) + POPCOUNT_TABLE16[index >> 1]  def popcount32_table16(v):     return (POPCOUNT_TABLE16[ v        & 0xffff] +             POPCOUNT_TABLE16[(v >> 16) & 0xffff])   On Python 2.x you should replace range with xrange.  Edit  If you need better performance (and your numbers are big integers), have a look at the GMP library. It contains hand-written assembly implementations for many different architectures.  gmpy is A C-coded Python extension module that wraps the GMP library.  >>> import gmpy >>> gmpy.popcount(2**1024-1) 1024      ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  You said Numpy was too slow. Were you using it to store individual bits? Why not extend the idea of using ints as bit arrays but use Numpy to store those?  Store n bits as an array of ceil(n/32.) 32-bit ints. You can then work with the numpy array the same (well, similar enough) way you use ints, including using them to index another array.  The algorithm is basically to compute, in parallel, the number of bits set in each cell, and them sum up the bitcount of each cell.  setup = \"\"\" import numpy as np #Using Paolo Moretti's answer http://stackoverflow.com/a/9829855/2963903 POPCOUNT_TABLE16 = np.zeros(2**16, dtype=int) #has to be an array  for index in range(len(POPCOUNT_TABLE16)):     POPCOUNT_TABLE16[index] = (index & 1) + POPCOUNT_TABLE16[index >> 1]  def popcount32_table16(v):     return (POPCOUNT_TABLE16[ v        & 0xffff] +             POPCOUNT_TABLE16[(v >> 16) & 0xffff])  def count1s(v):     return popcount32_table16(v).sum()  v1 = np.arange(1000)*1234567                       #numpy array v2 = sum(int(x)<<(32*i) for i, x in enumerate(v1)) #single int \"\"\" from timeit import timeit  timeit(\"count1s(v1)\", setup=setup)        #49.55184188873349 timeit(\"bin(v2).count('1')\", setup=setup) #225.1857464598633   Though I'm surprised no one suggested you write a C module.     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  You can use the algorithm to get the binary string [1] of an integer but instead of concatenating the string, counting the number of ones:  def count_ones(a):     s = 0     t = {'0':0, '1':1, '2':1, '3':2, '4':1, '5':2, '6':2, '7':3}     for c in oct(a)[1:]:         s += t[c]     return s   [1] https://wiki.python.org/moin/BitManipulation     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"Fast way of counting non-zero bits in positive integer","A_Content":"  It turns out your starting representation is a list of lists of ints which are either 1 or 0. Simply count them in that representation.    The number of bits in an integer is constant in python.  However, if you want to count the number of set bits, the fastest way is to create a list conforming to the following pseudocode: [numberofsetbits(n) for n in range(MAXINT)]  This will provide you a constant time lookup after you have generated the list. See @PaoloMoretti's answer for a good implementation of this. Of course, you don't have to keep this all in memory - you could use some sort of persistent key-value store, or even MySql. (Another option would be to implement your own simple disk-based storage).     ","Language":"Python","Tags":["python","binary","counting"],"URL":"https://stackoverflow.com/questions/9829578/fast-way-of-counting-non-zero-bits-in-positive-integer","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I need a fast way to count the number of bits in an integer in python. My current solutions is   bin(n).count(\"1\")   but I am wondering if there is any faster way of doing this?  PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.  Edit:  1. it has to be in python 2.7 or 2.6  and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places  for example this is a 2000 bit case:  12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L      ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  Answers so far have been templating the values into a plain SQL string. That's absolutely fine for integers, but if we wanted to do it for strings we get the escaping issue.  Here's a variant using a parameterised query that would work for both:  placeholder= '?' # For SQLite. See DBAPI paramstyle. placeholders= ', '.join(placeholder for unused in l) query= 'SELECT name FROM students WHERE id IN (%s)' % placeholders cursor.execute(query, l)      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  The SQL you want is  select name from studens where id in (1, 5, 8)   If you want to construct this from the python you could use  l = [1, 5, 8] sql_query = 'select name from studens where id in (' + ','.join(map(str, l)) + ')'   The map function will transform the list into a list of strings that can be glued together by commas using the str.join method.  Alternatively:  l = [1, 5, 8] sql_query = 'select name from studens where id in (' + ','.join((str(n) for n in l)) + ')'   if you prefer generator expressions to the map function.  UPDATE: S. Lott mentions in the comments that the Python SQLite bindings don't support sequences. In that case, you might want  select name from studens where id = 1 or id = 5 or id = 8   Generated by   sql_query = 'select name from studens where ' + ' or '.join(('id = ' + str(n) for n in l))      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  Dont complicate it, Solution for this is simple.  l = [1,5,8]  l = tuple(l)  params = {'l': l}  cursor.execute('SELECT * FROM table where id in %(l)s',params)     I hope this helped !!!     ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  string.join the list values separated by commas, and use the format operator to form a query string.  myquery = \"select name from studens where id in (%s)\" % \",\".join(map(str,mylist))   (Thanks, blair-conrad)     ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  I like bobince's answer:  placeholder= '?' # For SQLite. See DBAPI paramstyle. placeholders= ', '.join(placeholder for unused in l) query= 'SELECT name FROM students WHERE id IN (%s)' % placeholders cursor.execute(query, l)   But I noticed this:  placeholders= ', '.join(placeholder for unused in l)   Can be replaced with:  placeholders= ', '.join(placeholder*len(l))   I find this more direct if less clever and less general. Here l is required to have a length (i.e. refer to an object that defines a __len__ method), which shouldn't be a problem. But placeholder must also be a single character. To support a multi-character placeholder use:  placeholders= ', '.join([placeholder]*len(l))      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  Solution for @umounted answer, because that broke with a one-element tuple, since (1,) is not valid SQL.:  >>> random_ids = [1234,123,54,56,57,58,78,91] >>> cursor.execute(\"create table test (id)\") >>> for item in random_ids:     cursor.execute(\"insert into test values (%d)\" % item) >>> sublist = [56,57,58] >>> cursor.execute(\"select id from test where id in %s\" % str(tuple(sublist)).replace(',)',')')) >>> a = cursor.fetchall() >>> a [(56,), (57,), (58,)]   Other solution for sql string:  cursor.execute(\"select id from test where id in (%s)\" % ('\"'+'\", \"'.join(l)+'\"'))      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  For example, if you want the sql query:  select name from studens where id in (1, 5, 8)   What about:  my_list = [1, 5, 8] cur.execute(\"select name from studens where id in %s\" % repr(my_list).replace('[','(').replace(']',')') )      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  This uses parameter substitution and takes care of the single value list case:  l = [1,5,8]  get_operator = lambda x: '=' if len(x) == 1 else 'IN' get_value = lambda x: int(x[0]) if len(x) == 1 else x  query = 'SELECT * FROM table where id ' + get_operator(l) + ' %s'  cursor.execute(query, (get_value(l),))      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"python list in sql query as parameter","A_Content":"  Easiest way is to turn the list to tuple first  t = tuple(l) select name from studens where id IN\" + str(t)      ","Language":"Python","Tags":["python","sql"],"URL":"https://stackoverflow.com/questions/283645/python-list-in-sql-query-as-parameter","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have a python list, say l  l = [1,5,8]   I want to write a sql query to get the data for all the elements of the list, say  select name from students where id = |IN THE LIST l|   How do I accomplish this?     ","Q_Votes":"83"},{"Q_Title":"Re-raise exception with a different type and message, preserving existing information","A_Content":"  Python 3 introduced exception chaining (as described in PEP 3134). This allows, when raising an exception, to cite an existing exception as the cause:  try:     frobnicate() except KeyError as exc:     raise ValueError(\"Bad grape\") from exc   The caught exception thereby becomes part of (is the cause of) the new exception, and is available to whatever code catches the new exception.    In Python 2, it appears this use case has no good answer (as described by Ian Bicking and Ned Batchelder). Bummer.     ","Language":"Python","Tags":["python","exception-handling","polymorphism"],"URL":"https://stackoverflow.com/questions/696047/re-raise-exception-with-a-different-type-and-message-preserving-existing-inform","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm writing a module and want to have a unified exception hierarchy for the exceptions that it can raise (e.g. inheriting from a FooError abstract class for all the foo module's specific exceptions). This allows users of the module to catch those particular exceptions and handle them distinctly, if needed. But many of the exceptions raised from the module are raised because of some other exception; e.g. failing at some task because of an OSError on a file.  What I need is to wrap the exception caught such that it has a different type and message, so that information is available further up the propagation hierarchy by whatever catches the exception. But I don't want to lose the existing type, message, and stack trace; that's all useful information for someone trying to debug the problem. A top-level exception handler is no good, since I'm trying to decorate the exception before it makes its way further up the propagation stack, and the top-level handler is too late.  This is partly solved by deriving my module foo's specific exception types from the existing type (e.g. class FooPermissionError(OSError, FooError)), but that doesn't make it any easier to wrap the existing exception instance in a new type, nor modify the message.  Python's PEP 3134 Exception Chaining and Embedded Tracebacks discusses a change accepted in Python 3.0 for chaining exception objects, to indicate that a new exception was raised during the handling of an existing exception.  What I'm trying to do is related: I need it also working in earlier Python versions, and I need it not for chaining, but only for polymorphism. What is the right way to do this?     ","Q_Votes":"83"},{"Q_Title":"Re-raise exception with a different type and message, preserving existing information","A_Content":"  You can use sys.exc_info() to get the traceback, and raise your new exception with said traceback (as the PEP mentions). If you want to preserve the old type and message, you can do so on the exception, but that's only useful if whatever catches your exception looks for it.  For example  import sys  def failure():     try: 1/0     except ZeroDivisionError, e:         type, value, traceback = sys.exc_info()         raise ValueError, (\"You did something wrong!\", type, value), traceback   Of course, this is really not that useful. If it was, we wouldn't need that PEP. I'd not recommend doing it.     ","Language":"Python","Tags":["python","exception-handling","polymorphism"],"URL":"https://stackoverflow.com/questions/696047/re-raise-exception-with-a-different-type-and-message-preserving-existing-inform","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a module and want to have a unified exception hierarchy for the exceptions that it can raise (e.g. inheriting from a FooError abstract class for all the foo module's specific exceptions). This allows users of the module to catch those particular exceptions and handle them distinctly, if needed. But many of the exceptions raised from the module are raised because of some other exception; e.g. failing at some task because of an OSError on a file.  What I need is to wrap the exception caught such that it has a different type and message, so that information is available further up the propagation hierarchy by whatever catches the exception. But I don't want to lose the existing type, message, and stack trace; that's all useful information for someone trying to debug the problem. A top-level exception handler is no good, since I'm trying to decorate the exception before it makes its way further up the propagation stack, and the top-level handler is too late.  This is partly solved by deriving my module foo's specific exception types from the existing type (e.g. class FooPermissionError(OSError, FooError)), but that doesn't make it any easier to wrap the existing exception instance in a new type, nor modify the message.  Python's PEP 3134 Exception Chaining and Embedded Tracebacks discusses a change accepted in Python 3.0 for chaining exception objects, to indicate that a new exception was raised during the handling of an existing exception.  What I'm trying to do is related: I need it also working in earlier Python versions, and I need it not for chaining, but only for polymorphism. What is the right way to do this?     ","Q_Votes":"83"},{"Q_Title":"Re-raise exception with a different type and message, preserving existing information","A_Content":"  You could create your own exception type that extends whichever exception you've caught.  class NewException(CaughtException):     def __init__(self, caught):         self.caught = caught  try:     ... except CaughtException as e:     ...     raise NewException(e)   But most of the time, I think it would be simpler to catch the exception, handle it, and either raise the original exception (and preserve the traceback) or raise NewException().  If I were calling your code, and I received one of your custom exceptions, I'd expect that your code has already handled whatever exception you had to catch.  Thus I don't need to access it myself.  Edit: I found this analysis of ways to throw your own exception and keep the original exception.  No pretty solutions.     ","Language":"Python","Tags":["python","exception-handling","polymorphism"],"URL":"https://stackoverflow.com/questions/696047/re-raise-exception-with-a-different-type-and-message-preserving-existing-inform","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a module and want to have a unified exception hierarchy for the exceptions that it can raise (e.g. inheriting from a FooError abstract class for all the foo module's specific exceptions). This allows users of the module to catch those particular exceptions and handle them distinctly, if needed. But many of the exceptions raised from the module are raised because of some other exception; e.g. failing at some task because of an OSError on a file.  What I need is to wrap the exception caught such that it has a different type and message, so that information is available further up the propagation hierarchy by whatever catches the exception. But I don't want to lose the existing type, message, and stack trace; that's all useful information for someone trying to debug the problem. A top-level exception handler is no good, since I'm trying to decorate the exception before it makes its way further up the propagation stack, and the top-level handler is too late.  This is partly solved by deriving my module foo's specific exception types from the existing type (e.g. class FooPermissionError(OSError, FooError)), but that doesn't make it any easier to wrap the existing exception instance in a new type, nor modify the message.  Python's PEP 3134 Exception Chaining and Embedded Tracebacks discusses a change accepted in Python 3.0 for chaining exception objects, to indicate that a new exception was raised during the handling of an existing exception.  What I'm trying to do is related: I need it also working in earlier Python versions, and I need it not for chaining, but only for polymorphism. What is the right way to do this?     ","Q_Votes":"83"},{"Q_Title":"Re-raise exception with a different type and message, preserving existing information","A_Content":"  The most straighforward solution to your needs should be this:  try:      upload(file_id) except Exception as upload_error:      error_msg = \"Your upload failed! File: \" + file_id      raise RuntimeError(error_msg, upload_error)   In this way you can later print your message and the specific error throwed by the upload function     ","Language":"Python","Tags":["python","exception-handling","polymorphism"],"URL":"https://stackoverflow.com/questions/696047/re-raise-exception-with-a-different-type-and-message-preserving-existing-inform","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a module and want to have a unified exception hierarchy for the exceptions that it can raise (e.g. inheriting from a FooError abstract class for all the foo module's specific exceptions). This allows users of the module to catch those particular exceptions and handle them distinctly, if needed. But many of the exceptions raised from the module are raised because of some other exception; e.g. failing at some task because of an OSError on a file.  What I need is to wrap the exception caught such that it has a different type and message, so that information is available further up the propagation hierarchy by whatever catches the exception. But I don't want to lose the existing type, message, and stack trace; that's all useful information for someone trying to debug the problem. A top-level exception handler is no good, since I'm trying to decorate the exception before it makes its way further up the propagation stack, and the top-level handler is too late.  This is partly solved by deriving my module foo's specific exception types from the existing type (e.g. class FooPermissionError(OSError, FooError)), but that doesn't make it any easier to wrap the existing exception instance in a new type, nor modify the message.  Python's PEP 3134 Exception Chaining and Embedded Tracebacks discusses a change accepted in Python 3.0 for chaining exception objects, to indicate that a new exception was raised during the handling of an existing exception.  What I'm trying to do is related: I need it also working in earlier Python versions, and I need it not for chaining, but only for polymorphism. What is the right way to do this?     ","Q_Votes":"83"},{"Q_Title":"Purpose of Django setting SECRET_KEY","A_Content":"  It is used for making hashes.  Look:  >grep -Inr SECRET_KEY * conf/global_settings.py:255:SECRET_KEY = '' conf/project_template/settings.py:61:SECRET_KEY = '' contrib/auth/tokens.py:54:        hash = sha_constructor(settings.SECRET_KEY + unicode(user.id) + contrib/comments/forms.py:86:        info = (content_type, object_pk, timestamp, settings.SECRET_KEY) contrib/formtools/utils.py:15:    order, pickles the result with the SECRET_KEY setting, then takes an md5 contrib/formtools/utils.py:32:    data.append(settings.SECRET_KEY) contrib/messages/storage/cookie.py:112:        SECRET_KEY, modified to make it unique for the present purpose. contrib/messages/storage/cookie.py:114:        key = 'django.contrib.messages' + settings.SECRET_KEY contrib/sessions/backends/base.py:89:        pickled_md5 = md5_constructor(pickled + settings.SECRET_KEY).hexdigest() contrib/sessions/backends/base.py:95:        if md5_constructor(pickled + settings.SECRET_KEY).hexdigest() != tamper_check: contrib/sessions/backends/base.py:134:        # Use settings.SECRET_KEY as added salt. contrib/sessions/backends/base.py:143:                       settings.SECRET_KEY)).hexdigest() contrib/sessions/models.py:16:        pickled_md5 = md5_constructor(pickled + settings.SECRET_KEY).hexdigest() contrib/sessions/models.py:59:        if md5_constructor(pickled + settings.SECRET_KEY).hexdigest() != tamper_check: core/management/commands/startproject.py:32:        # Create a random SECRET_KEY hash, and put it in the main settings. core/management/commands/startproject.py:37:        settings_contents = re.sub(r\"(?<=SECRET_KEY = ')'\", secret_key + \"'\", settings_contents) middleware/csrf.py:38:                % (randrange(0, _MAX_CSRF_KEY), settings.SECRET_KEY)).hexdigest() middleware/csrf.py:41:    return md5_constructor(settings.SECRET_KEY + session_id).hexdigest()      ","Language":"Python","Tags":["python","django","security","encryption"],"URL":"https://stackoverflow.com/questions/7382149/purpose-of-django-setting-secret-key","A_Votes":"65","_type":"dict","isAccepted":"Yes","Q_Content":"    What exactly is the point of the SECRET_KEY in django? I did a few google searches and checked out the docs ( https://docs.djangoproject.com/en/dev/ref/settings/#secret-key ), but I was looking for a more in-depth explanation of this, and why it is required.   For example, what could happen if the key was compromised / others knew what it was? Thank you.     ","Q_Votes":"81"},{"Q_Title":"Purpose of Django setting SECRET_KEY","A_Content":"  The Django documentation for cryptographic signing covers the uses of the SECRET_KEY setting:     This value [the SECRET_KEY setting] is the key to securing signed data  it is vital you keep this secure, or attackers could use it to generate their own signed values.   (This section is also referenced from the Django documentation for the SECRET_KEY setting.)  The cryptographic signing API in Django is available to any app for cryptographically-secure signatures on values. Django itself makes use of this in various higher-level features:   Signing serialised data (e.g. JSON documents). Unique tokens for a user session, password reset request, messages, etc. Prevention of cross-site or replay attacks by adding (and then expecting) unique values for the request. Generating a unique salt for hash functions.   So, the general answer is: There are many things in a Django app which require a cryptographic signature, and the SECRET_KEY setting is the key used for those. It needs to have a cryptographically strong amount of entropy (hard for computers to guess) and unique between all Django instances.     ","Language":"Python","Tags":["python","django","security","encryption"],"URL":"https://stackoverflow.com/questions/7382149/purpose-of-django-setting-secret-key","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    What exactly is the point of the SECRET_KEY in django? I did a few google searches and checked out the docs ( https://docs.djangoproject.com/en/dev/ref/settings/#secret-key ), but I was looking for a more in-depth explanation of this, and why it is required.   For example, what could happen if the key was compromised / others knew what it was? Thank you.     ","Q_Votes":"81"},{"Q_Title":"Multiple Models in a single django ModelForm?","A_Content":"  You can just show both forms in the template inside of one <form> html element. Then just process the forms separately in the view. You'll still be able to use form.save() and not have to process db loading and saving yourself.  In this case you shouldn't need it, but if you're going to be using forms with the same field names, look into the prefix kwarg for django forms. (I answered a question about it here).     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/2770810/multiple-models-in-a-single-django-modelform","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this  class UserEditForm(ModelForm):      class Meta:         model = User         fields = (\"first_name\", \"last_name\")  class UserProfileForm(ModelForm):      class Meta:         model = UserProfile         fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")   Is there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?     ","Q_Votes":"81"},{"Q_Title":"Multiple Models in a single django ModelForm?","A_Content":"  You can try to use this pieces of code:  class CombinedFormBase(forms.Form):     form_classes = []      def __init__(self, *args, **kwargs):         super(CombinedFormBase, self).__init__(*args, **kwargs)         for f in self.form_classes:             name = f.__name__.lower()             setattr(self, name, f(*args, **kwargs))             form = getattr(self, name)             self.fields.update(form.fields)             self.initial.update(form.initial)      def is_valid(self):         isValid = True         for f in self.form_classes:             name = f.__name__.lower()             form = getattr(self, name)             if not form.is_valid():                 isValid = False         # is_valid will trigger clean method         # so it should be called after all other forms is_valid are called         # otherwise clean_data will be empty         if not super(CombinedFormBase, self).is_valid() :             isValid = False         for f in self.form_classes:             name = f.__name__.lower()             form = getattr(self, name)             self.errors.update(form.errors)         return isValid      def clean(self):         cleaned_data = super(CombinedFormBase, self).clean()         for f in self.form_classes:             name = f.__name__.lower()             form = getattr(self, name)             cleaned_data.update(form.cleaned_data)         return cleaned_data   Example Usage:  class ConsumerRegistrationForm(CombinedFormBase):     form_classes = [RegistrationForm, ConsumerProfileForm]  class RegisterView(FormView):     template_name = \"register.html\"     form_class = ConsumerRegistrationForm      def form_valid(self, form):         # some actions...         return redirect(self.get_success_url())      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/2770810/multiple-models-in-a-single-django-modelform","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this  class UserEditForm(ModelForm):      class Meta:         model = User         fields = (\"first_name\", \"last_name\")  class UserProfileForm(ModelForm):      class Meta:         model = UserProfile         fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")   Is there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?     ","Q_Votes":"81"},{"Q_Title":"Multiple Models in a single django ModelForm?","A_Content":"  You probably should take a look at Inline formsets. Inline formsets are used when your models are related by a foreign key.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/2770810/multiple-models-in-a-single-django-modelform","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this  class UserEditForm(ModelForm):      class Meta:         model = User         fields = (\"first_name\", \"last_name\")  class UserProfileForm(ModelForm):      class Meta:         model = UserProfile         fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")   Is there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?     ","Q_Votes":"81"},{"Q_Title":"Multiple Models in a single django ModelForm?","A_Content":"  You can check my answer here for a similar problem.  It talks about how to combine registration and user profile into one form, but it can be generalized to any ModelForm combination.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/2770810/multiple-models-in-a-single-django-modelform","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this  class UserEditForm(ModelForm):      class Meta:         model = User         fields = (\"first_name\", \"last_name\")  class UserProfileForm(ModelForm):      class Meta:         model = UserProfile         fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")   Is there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?     ","Q_Votes":"81"},{"Q_Title":"Multiple Models in a single django ModelForm?","A_Content":"  erikbwork and me both had the problem that one can only include one model into a generic Class Based View. I found a similar way of approaching it like Miao, but more modular.   I wrote a Mixin so you can use all generic Class Based Views. Define model, fields and now also child_model and child_field - and then you can wrap fields of both models in a  tag like Zach describes.  class ChildModelFormMixin:      ''' extends ModelFormMixin with the ability to include ChildModelForm '''     child_model = \"\"     child_fields = ()     child_form_class = None      def get_child_model(self):         return self.child_model      def get_child_fields(self):         return self.child_fields      def get_child_form(self):         if not self.child_form_class:             self.child_form_class = model_forms.modelform_factory(self.get_child_model(), fields=self.get_child_fields())         return self.child_form_class(**self.get_form_kwargs())      def get_context_data(self, **kwargs):         if 'child_form' not in kwargs:             kwargs['child_form'] = self.get_child_form()         return super().get_context_data(**kwargs)      def post(self, request, *args, **kwargs):         form = self.get_form()         child_form = self.get_child_form()          # check if both forms are valid         form_valid = form.is_valid()         child_form_valid = child_form.is_valid()          if form_valid and child_form_valid:             return self.form_valid(form, child_form)         else:             return self.form_invalid(form)      def form_valid(self, form, child_form):         self.object = form.save()         save_child_form = child_form.save(commit=False)         save_child_form.course_key = self.object         save_child_form.save()          return HttpResponseRedirect(self.get_success_url())   Example Usage:  class ConsumerRegistrationUpdateView(UpdateView):     model = Registration     fields = ('firstname', 'lastname',)     child_model = ConsumerProfile     child_fields = ('payment_token', 'cart',)   Or with ModelFormClass:  class ConsumerRegistrationUpdateView(UpdateView):     model = Registration     fields = ('firstname', 'lastname',)     child_model = ConsumerProfile     child_form_class = ConsumerProfileForm   Done. Hope that helps someone.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/2770810/multiple-models-in-a-single-django-modelform","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this  class UserEditForm(ModelForm):      class Meta:         model = User         fields = (\"first_name\", \"last_name\")  class UserProfileForm(ModelForm):      class Meta:         model = UserProfile         fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")   Is there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  It varies based on the options that you pass to install and the contents of the distutils configuration files on the system/in the package. I don't believe that any files are modified outside of directories specified in these ways.  Notably, distutils does not have an uninstall command at this time.   It's also noteworthy that deleting a package/egg can cause dependency issues -- utilities like easy_install attempt to alleviate such problems.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"39","_type":"dict","isAccepted":"Yes","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  The three things that get installed that you will need to delete are:   Packages/modules Scripts Data files   Now on my linux system these live in:   /usr/lib/python2.5/site-packages /usr/bin /usr/share   But on a windows system they are more likely to be entirely within the Python distribution directory. I have no idea about OSX except it is more likey to follow the linux pattern.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  Another time stamp based hack:   Create an anchor: touch /tmp/ts Reinstall the package to be removed: python setup.py install --prefix=<PREFIX> Remove files what are more recent than the anchor file: find <PREFIX> -cnewer /tmp/ts | xargs rm -r      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  Yes, it is safe to simply delete anything that distutils installed. That goes for installed folders or .egg files. Naturally anything that depends on that code will no longer work.   If you want to make it work again, simply re-install.   By the way, if you are using distutils also consider using the multi-version feature. It allows you to have multiple versions of any single package installed. That means you do not need to delete an old version of a package if you simply want to install a newer version.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  If this is for testing and/or development purposes, setuptools has a develop command that updates every time you make a change (so you don't have to uninstall and reinstall every time you make a change).  And you can uninstall the package using this command as well.  If you do use this, anything that you declare as a script will be left behind as a lingering file.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  In ubuntu 12.04, I have found that the only place you need to look by default is under  /usr/local/lib/python2.7/   And simply remove the associated folder and file, if there is one!     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  I just uninstalled a python package, and even though I'm not certain I did so perfectly, I'm reasonably confident.    I started by getting a list of all python-related files, ordered by date, on the assumption that all of the files in my package will have more or less the same timestamp, and no other files will.  Luckily, I've got python installed under /opt/Python-2.6.1; if I had been using the Python that comes with my Linux distro, I'd have had to scour all of /usr, which would have taken a long time.  Then I just examined that list, and noted with relief that all the stuff that I wanted to nuke consisted of one directory, /opt/Python-2.6.1/lib/python2.6/site-packages/module-name/, and one file, /opt/Python-2.6.1/lib/python2.6/site-packages/module-x.x.x_blah-py2.6.egg-info.  So I just deleted those.  Here's how I got the date-sorted list of files:  find \"$@\" -printf '%T@ ' -ls | sort -n | cut -d\\  -f 2-  (I think that's got to be GNU \"find\", by the way; the flavor you get on OS X doesn't know about \"-printf '%T@'\")  I use that all the time.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  For Windows 7,  Control Panel --> Programs --> Uninstall  , then   choose the python package to remove.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  install --record + xargs rm  sudo python setup.py install --record files.txt xargs sudo rm -rf < files.txt   removes all files and but leaves empty directories behind.  That is not ideal, it should be enough to avoid package conflicts.  And then you can finish the job manually if you want by reading files.txt, or be braver and automate empty directory removal as well.  A safe helper would be:  python-setup-uninstall() (   sudo rm -f files.txt   sudo python setup.py install --record files.txt && \\   xargs rm -rf < files.txt   sudo rm -f files.txt )   Tested in Python 2.7.6, Ubuntu 14.04.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  for Python in Windows:  python -m pip uninstall \"package_keyword\" uninstall **** (y/n)?      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"How do you uninstall a python package that was installed using distutils?","A_Content":"  On Mac OSX, manually delete these 2 directories under your pathToPython/site-packages/ will work:    {packageName} {packageName}-{version}-info   for example, to remove pyasn1, which is a distutils installed project:   rm -rf lib/python2.7/site-packages/pyasn1 rm -rf lib/python2.7/site-packages/pyasn1-0.1.9-py2.7.egg-info   To find out where is your site-packages:  python -m site      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/402359/how-do-you-uninstall-a-python-package-that-was-installed-using-distutils","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Can you simply delete the directory from your python installation, or are there any lingering files that you must delete?     ","Q_Votes":"81"},{"Q_Title":"Are list-comprehensions and functional functions faster than for loops?","A_Content":"  The following are rough guidelines and educated guesses based on experience. You should timeit or profile your concrete use case to get hard numbers, and those numbers may occasionally disagree with the below.  A list comprehension is usually a tiny bit faster than the precisely equivalent for loop (that actually builds a list), most likely because it doesn't have to look up the list and its append method on every iteration. However, a list comprehension still does a bytecode-level loop:  >>> dis.dis(<the code object for `[x for x in range(10)]`>)  1           0 BUILD_LIST               0              3 LOAD_FAST                0 (.0)        >>    6 FOR_ITER                12 (to 21)              9 STORE_FAST               1 (x)             12 LOAD_FAST                1 (x)             15 LIST_APPEND              2             18 JUMP_ABSOLUTE            6        >>   21 RETURN_VALUE   Using a list comprehension in place of a loop that doesn't build a list, nonsensically accumulating a list of meaningless values and then throwing the list away, is often slower because of the overhead of creating and extending the list. List comprehensions aren't magic that is inherently faster than a good old loop.  As for functional list processing functions: While these are written in C and probably outperform equivalent functions written in Python, they are not necessarily the fastest option. Some speed up is expected if the function is written in C too. But most cases using a lambda (or other Python function), the overhead of repeatedly setting up Python stack frames etc. eats up any savings. Simply doing the same work in-line, without function calls (e.g. a list comprehension instead of map or filter) is often slightly faster.     Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).   Chances are, if code like this isn't already fast enough when written in good non-\"optimized\" Python, no amount of Python level micro optimization is going to make it fast enough and you should start thinking about dropping to C. While extensive micro optimizations can often speed up Python code considerably, there is a low (in absolute terms) limit to this. Moreover, even before you hit that ceiling, it becomes simply more cost efficient (15% speedup vs. 300% speed up with the same effort) to bite the bullet and write some C.     ","Language":"Python","Tags":["python","performance","for-loop","list-comprehension","map-function"],"URL":"https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops","A_Votes":"86","_type":"dict","isAccepted":"Yes","Q_Content":"    In terms of performance in Python, is a list-comprehension, or functions like map(), filter() and reduce() faster than a for loop? Why, technically, they \"run in a C speed\", while \"the for loop runs in the python virtual machine speed\"?.  Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).     ","Q_Votes":"81"},{"Q_Title":"Are list-comprehensions and functional functions faster than for loops?","A_Content":"  If you check the info on python.org, you can see this summary:  Version Time (seconds) Basic loop 3.47 Eliminate dots 2.45 Local variable & no dots 1.79 Using map function 0.54   But you really should read the above article in details to understand the cause of the performance difference.  I also strongly suggest you should time your code by using timeit.  At the end of the day, there can be a situation where, for example, you may need to break out of for loop when a condition is met. It could potentially be faster than finding out the result by calling map.      ","Language":"Python","Tags":["python","performance","for-loop","list-comprehension","map-function"],"URL":"https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    In terms of performance in Python, is a list-comprehension, or functions like map(), filter() and reduce() faster than a for loop? Why, technically, they \"run in a C speed\", while \"the for loop runs in the python virtual machine speed\"?.  Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).     ","Q_Votes":"81"},{"Q_Title":"Are list-comprehensions and functional functions faster than for loops?","A_Content":"  You ask specifically about map(), filter() and reduce(), but I assume you want to know about functional programming in general. Having tested this myself on the problem of computing distances between all points within a set of points, functional programming (using the starmap function from the built-in itertools module) turned out to be slightly slower than for-loops (taking 1.25 times as long, in fact). Here is the sample code I used:  import itertools, time, math, random  class Point:     def __init__(self,x,y):         self.x, self.y = x, y  point_set = (Point(0, 0), Point(0, 1), Point(0, 2), Point(0, 3)) n_points = 100 pick_val = lambda : 10 * random.random() - 5 large_set = [Point(pick_val(), pick_val()) for _ in range(n_points)]     # the distance function f_dist = lambda x0, x1, y0, y1: math.sqrt((x0 - x1) ** 2 + (y0 - y1) ** 2)     # go through each point, get its distance from all remaining points  f_pos = lambda p1, p2: (p1.x, p2.x, p1.y, p2.y)  extract_dists = lambda x: itertools.starmap(f_dist,                            itertools.starmap(f_pos,                            itertools.combinations(x, 2)))  print('Distances:', list(extract_dists(point_set)))  t0_f = time.time() list(extract_dists(large_set)) dt_f = time.time() - t0_f   Is the functional version faster than the procedural version?  def extract_dists_procedural(pts):     n_pts = len(pts)     l = []         for k_p1 in range(n_pts - 1):         for k_p2 in range(k_p1, n_pts):             l.append((pts[k_p1].x - pts[k_p2].x) ** 2 +                      (pts[k_p1].y - pts[k_p2].y) ** 2)     return l  t0_p = time.time() list(extract_dists_procedural(large_set))      # using list() on the assumption that     # it eats up as much time as in the functional version  dt_p = time.time() - t0_p  f_vs_p = dt_p / dt_f if f_vs_p >= 1.0:     print('Time benefit of functional progamming:', f_vs_p,            'times as fast for', n_points, 'points') else:     print('Time penalty of functional programming:', 1 / f_vs_p,            'times as slow for', n_points, 'points')      ","Language":"Python","Tags":["python","performance","for-loop","list-comprehension","map-function"],"URL":"https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    In terms of performance in Python, is a list-comprehension, or functions like map(), filter() and reduce() faster than a for loop? Why, technically, they \"run in a C speed\", while \"the for loop runs in the python virtual machine speed\"?.  Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).     ","Q_Votes":"81"},{"Q_Title":"Are list-comprehensions and functional functions faster than for loops?","A_Content":"  I wrote a simple script that test the speed and this is what I found out. Actually for loop was fastest in my case. That really suprised me, check out bellow (was calculating sum of squares).  from functools import reduce import datetime   def time_it(func, numbers, *args):     start_t = datetime.datetime.now()     for i in range(numbers):         func(args[0])     print (datetime.datetime.now()-start_t)  def square_sum1(numbers):     return reduce(lambda sum, next: sum+next**2, numbers, 0)   def square_sum2(numbers):     a = 0     for i in numbers:         i = i**2         a += i     return a  def square_sum3(numbers):     sqrt = lambda x: x**2     return sum(map(sqrt, numbers))  def square_sum4(numbers):     return(sum([int(i)**2 for i in numbers]))   time_it(square_sum1, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum2, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum3, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum4, 100000, [1, 2, 5, 3, 1, 2, 5, 3])   0:00:00.302000 #Reduce 0:00:00.144000 #For loop 0:00:00.318000 #Map 0:00:00.390000 #List comprehension     ","Language":"Python","Tags":["python","performance","for-loop","list-comprehension","map-function"],"URL":"https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    In terms of performance in Python, is a list-comprehension, or functions like map(), filter() and reduce() faster than a for loop? Why, technically, they \"run in a C speed\", while \"the for loop runs in the python virtual machine speed\"?.  Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).     ","Q_Votes":"81"},{"Q_Title":"Are list-comprehensions and functional functions faster than for loops?","A_Content":"  Adding a twist to Alphii answer, actually the for loop would be second best and about 6 times slower than map  from functools import reduce import datetime   def time_it(func, numbers, *args):     start_t = datetime.datetime.now()     for i in range(numbers):         func(args[0])     print (datetime.datetime.now()-start_t)  def square_sum1(numbers):     return reduce(lambda sum, next: sum+next**2, numbers, 0)   def square_sum2(numbers):     a = 0     for i in numbers:         a += i**2     return a  def square_sum3(numbers):     a = 0     map(lambda x: a+x**2, numbers)     return a  def square_sum4(numbers):     a = 0     return [a+i**2 for i in numbers]  time_it(square_sum1, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum2, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum3, 100000, [1, 2, 5, 3, 1, 2, 5, 3]) time_it(square_sum4, 100000, [1, 2, 5, 3, 1, 2, 5, 3])   Main changes have been to eliminate the slow sum calls, as well as the probably unnecessary int() in the last case. Putting the for loop and map in the same terms makes it quite fact, actually. Remember that lambdas are functional concepts and theoretically shouldn't have side effects, but, well, they can have side effects like adding to a. Results in this case with Python 3.6.1, Ubuntu 14.04, Intel(R) Core(TM) i7-4770 CPU @ 3.40GHz  0:00:00.257703 0:00:00.184898 0:00:00.031718 0:00:00.212699      ","Language":"Python","Tags":["python","performance","for-loop","list-comprehension","map-function"],"URL":"https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    In terms of performance in Python, is a list-comprehension, or functions like map(), filter() and reduce() faster than a for loop? Why, technically, they \"run in a C speed\", while \"the for loop runs in the python virtual machine speed\"?.  Suppose that in a game that I'm developing I need to draw complex and huge maps using for loops. This question would be definitely relevant, for if a list-comprehension, for example, is indeed faster, it would be a much better option in order to avoid lags (Despite the visual complexity of the code).     ","Q_Votes":"81"},{"Q_Title":"Python method/function arguments starting with asterisk and dual asterisk [duplicate]","A_Content":"  The *args and **keywordargs forms are used for passing lists of arguments and dictionaries of arguments, respectively. So if I had a function like this:  def printlist(*args):     for x in args:         print(x)   I could call it like this:  printlist(1, 2, 3, 4, 5)  # or as many more arguments as I'd like   For this  def printdict(**kwargs):     print(repr(kwargs))  printdict(john=10, jill=12, david=15)   *args behaves like a list, and **keywordargs behaves like a dictionary, but you don't have to explicitly pass a list or a dict to the function.  See this for more examples.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/4306574/python-method-function-arguments-starting-with-asterisk-and-dual-asterisk","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          I am not able understand where does these type of functions are used and how differently these arguments work from the normal arguments. I have encountered them many time but never got chance to understand them properly.  Ex:  def method(self, *links, **locks):     #some foo     #some bar     return   I know i could have search the documentation but i have no idea what to search for.     ","Q_Votes":"81"},{"Q_Title":"Python pandas: fill a dataframe row by row","A_Content":"  df['y'] will set a column  since you want to set a row, use .loc  Note that .ix is equivalent here, yours failed because you tried to assign a dictionary to each element of the row y probably not what you want; converting to a Series tells pandas that you want to align the input (for example you then don't have to to specify all of the elements)  In [7]: df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z'])  In [8]: df.loc['y'] = pandas.Series({'a':1, 'b':5, 'c':2, 'd':3})  In [9]: df Out[9]:       a    b    c    d x  NaN  NaN  NaN  NaN y    1    5    2    3 z  NaN  NaN  NaN  NaN      ","Language":"Python","Tags":["python","dataframe","row","pandas"],"URL":"https://stackoverflow.com/questions/17091769/python-pandas-fill-a-dataframe-row-by-row","A_Votes":"62","_type":"dict","isAccepted":"Yes","Q_Content":"    The simple task of adding a row to a pandas.DataFrame object seems to be hard to accomplish. There are 3 stackoverflow questions relating to this, none of which give a working answer.  Here is what I'm trying to do. I have a DataFrame of which I already know the shape as well as the names of the rows and columns.  >>> df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z']) >>> df      a    b    c    d x  NaN  NaN  NaN  NaN y  NaN  NaN  NaN  NaN z  NaN  NaN  NaN  NaN   Now, I have a function to compute the values of the rows iteratively. How can I fill in one of the rows with either a dictionary or a pandas.Series ? Here are various attempts that have failed:  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df['y'] = y AssertionError: Length of values does not match length of index   Apparently it tried to add a column instead of a row.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.join(y) AttributeError: 'builtin_function_or_method' object has no attribute 'is_unique'   Very uninformative error message.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.set_value(index='y', value=y) TypeError: set_value() takes exactly 4 arguments (3 given)   Apparently that is only for setting individual values in the dataframe.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.append(y) Exception: Can only append a Series if ignore_index=True   Well, I don't want to ignore the index, otherwise here is the result:  >>> df.append(y, ignore_index=True)      a    b    c    d 0  NaN  NaN  NaN  NaN 1  NaN  NaN  NaN  NaN 2  NaN  NaN  NaN  NaN 3    1    5    2    3   It did align the column names with the values, but lost the row labels.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.ix['y'] = y >>> df                                   a                                 b  \\ x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN                                    c                                 d x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN   That also failed miserably.  So how do you do it ?     ","Q_Votes":"81"},{"Q_Title":"Python pandas: fill a dataframe row by row","A_Content":"  My approach was, but I can't guarantee that this is the fastest solution.  df = pd.DataFrame(columns=[\"firstname\", \"lastname\"]) df = df.append({      \"firstname\": \"John\",      \"lastname\":  \"Johny\"       }, ignore_index=True)      ","Language":"Python","Tags":["python","dataframe","row","pandas"],"URL":"https://stackoverflow.com/questions/17091769/python-pandas-fill-a-dataframe-row-by-row","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    The simple task of adding a row to a pandas.DataFrame object seems to be hard to accomplish. There are 3 stackoverflow questions relating to this, none of which give a working answer.  Here is what I'm trying to do. I have a DataFrame of which I already know the shape as well as the names of the rows and columns.  >>> df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z']) >>> df      a    b    c    d x  NaN  NaN  NaN  NaN y  NaN  NaN  NaN  NaN z  NaN  NaN  NaN  NaN   Now, I have a function to compute the values of the rows iteratively. How can I fill in one of the rows with either a dictionary or a pandas.Series ? Here are various attempts that have failed:  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df['y'] = y AssertionError: Length of values does not match length of index   Apparently it tried to add a column instead of a row.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.join(y) AttributeError: 'builtin_function_or_method' object has no attribute 'is_unique'   Very uninformative error message.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.set_value(index='y', value=y) TypeError: set_value() takes exactly 4 arguments (3 given)   Apparently that is only for setting individual values in the dataframe.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.append(y) Exception: Can only append a Series if ignore_index=True   Well, I don't want to ignore the index, otherwise here is the result:  >>> df.append(y, ignore_index=True)      a    b    c    d 0  NaN  NaN  NaN  NaN 1  NaN  NaN  NaN  NaN 2  NaN  NaN  NaN  NaN 3    1    5    2    3   It did align the column names with the values, but lost the row labels.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.ix['y'] = y >>> df                                   a                                 b  \\ x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN                                    c                                 d x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN   That also failed miserably.  So how do you do it ?     ","Q_Votes":"81"},{"Q_Title":"Python pandas: fill a dataframe row by row","A_Content":"  This is a simpler version  df = DataFrame(columns=('col1', 'col2', 'col3')) for i in range(5):    df.loc[i] = ['<some value for first>','<some value for second>','<some value for third>']`      ","Language":"Python","Tags":["python","dataframe","row","pandas"],"URL":"https://stackoverflow.com/questions/17091769/python-pandas-fill-a-dataframe-row-by-row","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    The simple task of adding a row to a pandas.DataFrame object seems to be hard to accomplish. There are 3 stackoverflow questions relating to this, none of which give a working answer.  Here is what I'm trying to do. I have a DataFrame of which I already know the shape as well as the names of the rows and columns.  >>> df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z']) >>> df      a    b    c    d x  NaN  NaN  NaN  NaN y  NaN  NaN  NaN  NaN z  NaN  NaN  NaN  NaN   Now, I have a function to compute the values of the rows iteratively. How can I fill in one of the rows with either a dictionary or a pandas.Series ? Here are various attempts that have failed:  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df['y'] = y AssertionError: Length of values does not match length of index   Apparently it tried to add a column instead of a row.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.join(y) AttributeError: 'builtin_function_or_method' object has no attribute 'is_unique'   Very uninformative error message.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.set_value(index='y', value=y) TypeError: set_value() takes exactly 4 arguments (3 given)   Apparently that is only for setting individual values in the dataframe.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.append(y) Exception: Can only append a Series if ignore_index=True   Well, I don't want to ignore the index, otherwise here is the result:  >>> df.append(y, ignore_index=True)      a    b    c    d 0  NaN  NaN  NaN  NaN 1  NaN  NaN  NaN  NaN 2  NaN  NaN  NaN  NaN 3    1    5    2    3   It did align the column names with the values, but lost the row labels.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.ix['y'] = y >>> df                                   a                                 b  \\ x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN                                    c                                 d x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN   That also failed miserably.  So how do you do it ?     ","Q_Votes":"81"},{"Q_Title":"Python pandas: fill a dataframe row by row","A_Content":"  If your input rows are lists rather than dictionaries, then the following is a simple solution:  import pandas as pd list_of_lists = [] list_of_lists.append([1,2,3]) list_of_lists.append([4,5,6])  pd.DataFrame(list_of_lists, columns=['A', 'B', 'C']) #    A  B  C # 0  1  2  3 # 1  4  5  6      ","Language":"Python","Tags":["python","dataframe","row","pandas"],"URL":"https://stackoverflow.com/questions/17091769/python-pandas-fill-a-dataframe-row-by-row","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    The simple task of adding a row to a pandas.DataFrame object seems to be hard to accomplish. There are 3 stackoverflow questions relating to this, none of which give a working answer.  Here is what I'm trying to do. I have a DataFrame of which I already know the shape as well as the names of the rows and columns.  >>> df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z']) >>> df      a    b    c    d x  NaN  NaN  NaN  NaN y  NaN  NaN  NaN  NaN z  NaN  NaN  NaN  NaN   Now, I have a function to compute the values of the rows iteratively. How can I fill in one of the rows with either a dictionary or a pandas.Series ? Here are various attempts that have failed:  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df['y'] = y AssertionError: Length of values does not match length of index   Apparently it tried to add a column instead of a row.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.join(y) AttributeError: 'builtin_function_or_method' object has no attribute 'is_unique'   Very uninformative error message.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.set_value(index='y', value=y) TypeError: set_value() takes exactly 4 arguments (3 given)   Apparently that is only for setting individual values in the dataframe.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.append(y) Exception: Can only append a Series if ignore_index=True   Well, I don't want to ignore the index, otherwise here is the result:  >>> df.append(y, ignore_index=True)      a    b    c    d 0  NaN  NaN  NaN  NaN 1  NaN  NaN  NaN  NaN 2  NaN  NaN  NaN  NaN 3    1    5    2    3   It did align the column names with the values, but lost the row labels.  >>> y = {'a':1, 'b':5, 'c':2, 'd':3}  >>> df.ix['y'] = y >>> df                                   a                                 b  \\ x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN                                    c                                 d x                               NaN                               NaN y  {'a': 1, 'c': 2, 'b': 5, 'd': 3}  {'a': 1, 'c': 2, 'b': 5, 'd': 3} z                               NaN                               NaN   That also failed miserably.  So how do you do it ?     ","Q_Votes":"81"},{"Q_Title":"How to convert an array of strings to an array of floats in numpy?","A_Content":"  Well, if you're reading the data in as a list, just do np.array(map(float, list_of_strings)) (or equivalently, use a list comprehension). (In Python 3, you'll need to call list on the map return value if you use map, since map returns an iterator now.)  However, if it's already a numpy array of strings, there's a better way.  Use astype().  import numpy as np x = np.array(['1.1', '2.2', '3.3']) y = x.astype(np.float)      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/3877209/how-to-convert-an-array-of-strings-to-an-array-of-floats-in-numpy","A_Votes":"120","_type":"dict","isAccepted":"Yes","Q_Content":"    How to convert  [\"1.1\", \"2.2\", \"3.2\"]   to  [1.1, 2.2, 3.2]   in NumPy?     ","Q_Votes":"81"},{"Q_Title":"How to convert an array of strings to an array of floats in numpy?","A_Content":"  You can use this as well   import numpy as np x=np.array(['1.1', '2.2', '3.3']) x=np.asfarray(x,float)      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/3877209/how-to-convert-an-array-of-strings-to-an-array-of-floats-in-numpy","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How to convert  [\"1.1\", \"2.2\", \"3.2\"]   to  [1.1, 2.2, 3.2]   in NumPy?     ","Q_Votes":"81"},{"Q_Title":"How to convert an array of strings to an array of floats in numpy?","A_Content":"  If you have (or create) a single string, you can use np.fromstring:  import numpy as np x = [\"1.1\", \"2.2\", \"3.2\"] x = ','.join(x) x = np.fromstring( x, dtype=np.float, sep=',' )   Note, x = ','.join(x) transforms the x array to string '1.1, 2.2, 3.2'. If you read a line from a txt file, each line will be already a string.     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/3877209/how-to-convert-an-array-of-strings-to-an-array-of-floats-in-numpy","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How to convert  [\"1.1\", \"2.2\", \"3.2\"]   to  [1.1, 2.2, 3.2]   in NumPy?     ","Q_Votes":"81"},{"Q_Title":"How to convert an array of strings to an array of floats in numpy?","A_Content":"  Another option might be numpy.asarray:  import numpy as np a = [\"1.1\", \"2.2\", \"3.2\"] b = np.asarray(a, dtype=np.float64, order='C')   For Python 2*:  print a, type(a), type(a[0]) print b, type(b), type(b[0])   resulting in:  ['1.1', '2.2', '3.2'] <type 'list'> <type 'str'> [1.1 2.2 3.2] <type 'numpy.ndarray'> <type 'numpy.float64'>      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/3877209/how-to-convert-an-array-of-strings-to-an-array-of-floats-in-numpy","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How to convert  [\"1.1\", \"2.2\", \"3.2\"]   to  [1.1, 2.2, 3.2]   in NumPy?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  The best-known library is PIL.  However if you are simply doing basic manipulation, you are probably better off with the Python bindings for ImageMagick, which will be a good deal more efficient than writing the transforms in Python.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"51","_type":"dict","isAccepted":"Yes","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  Depending on what you mean by \"image processing\", a better choice might be in the numpy based libraries: mahotas, scikits.image, or scipy.ndimage. All of these work based on numpy arrays, so you can mix and match functions from one library and another.  I started the website http://pythonvision.org which has more information on these.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"44","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  You also have an approach to image processing based on \"standard\" scientific modules: SciPy has a whole package dedicated to image processing: scipy.ndimage.  Scipy is in effect the standard general numerical calculations package; it is based on the de facto standard array-manipulation module NumPy: images can also be manipulated as array of numbers.  As for image display, Matplotlib (also part of the \"science trilogy\") makes displaying images quite simple.  SciPy is still actively maintained, so it's a good investment for the future.  Furthermore, SciPy currently runs with Python 3 too, while the Python Imaging Library (PIL) does not.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  To complete the list: opencv http://opencv.willowgarage.com/documentation/python/index.html     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  There's also pycairo, which might be more suitable depending on your needs.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  There is actually a wonderful Python Imaging Library (PIL).  It gives you the ability to alter existing images, including anti-aliasing capabilities, and create new images with text and such.  You can also find a decent introductory tutorial in the PIL handbook provided on the aforementioned site.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  If you are creating a custom image processing effect, you may find PythonPixels useful. http://halfhourhacks.blogspot.com/2008/03/pythonpixels.html It is intended for writing and experimenting with image processing.     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"Image Processing, In Python? [closed]","A_Content":"  VIPS should be fast and uses multiple CPUs: http://www.vips.ecs.soton.ac.uk/index.php?title=Speed_and_Memory_Use     ","Language":"Python","Tags":["python","image","image-processing","image-manipulation"],"URL":"https://stackoverflow.com/questions/94875/image-processing-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've recently come across a problem which requires at least a basic degree of image processing, can I do this in Python, and if so, with what?     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  You can also use the mimetypes module:  import mimetypes ... mime = mimetypes.guess_type(file)   It's fairly easy to compile a list of binary mime types. For example Apache distributes with a mime.types file that you could parse into a set of lists, binary and text and then check to see if the mime is in your text or binary list.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"36","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Yet another method based on file(1) behavior:  >>> textchars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7f}) >>> is_binary_string = lambda bytes: bool(bytes.translate(None, textchars))   Example:  >>> is_binary_string(open('/usr/bin/python', 'rb').read(1024)) True >>> is_binary_string(open('/usr/bin/dh_python3', 'rb').read(1024)) False      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"48","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Try this:  def is_binary(filename):     \"\"\"Return true if the given filename is binary.     @raise EnvironmentError: if the file does not exist or cannot be accessed.     @attention: found @ http://bytes.com/topic/python/answers/21222-determine-file-type-binary-text on 6/08/2010     @author: Trent Mick <TrentM@ActiveState.com>     @author: Jorge Orpinel <jorge@orpinel.com>\"\"\"     fin = open(filename, 'rb')     try:         CHUNKSIZE = 1024         while 1:             chunk = fin.read(CHUNKSIZE)             if '\\0' in chunk: # found null byte                 return True             if len(chunk) < CHUNKSIZE:                 break # done     # A-wooo! Mira, python no necesita el \"except:\". Achis... Que listo es.     finally:         fin.close()      return False      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  If it helps, many many binary types begin with a magic numbers. Here is a list of file signatures.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Here's a suggestion that uses the Unix file command:  import re import subprocess  def istext(path):     return (re.search(r':.* text',                       subprocess.Popen([\"file\", '-L', path],                                         stdout=subprocess.PIPE).stdout.read())             is not None)   Example usage:   >>> istext('/etc/motd')  True >>> istext('/vmlinuz')  False >>> open('/tmp/japanese').read() '\\xe3\\x81\\x93\\xe3\\x82\\x8c\\xe3\\x81\\xaf\\xe3\\x80\\x81\\xe3\\x81\\xbf\\xe3\\x81\\x9a\\xe3\\x81\\x8c\\xe3\\x82\\x81\\xe5\\xba\\xa7\\xe3\\x81\\xae\\xe6\\x99\\x82\\xe4\\xbb\\xa3\\xe3\\x81\\xae\\xe5\\xb9\\x95\\xe9\\x96\\x8b\\xe3\\x81\\x91\\xe3\\x80\\x82\\n' >>> istext('/tmp/japanese') # works on UTF-8 True   It has the downsides of not being portable to Windows (unless you have something like the file command there), and having to spawn an external process for each file, which might not be palatable.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Use binaryornot library (GitHub).  It is very simple and based on the code found in this stackoverflow question.  You can actually write this in 2 lines of code, however this package saves you from having to write and thoroughly test those 2 lines of code with all sorts of weird file types, cross-platform.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Usually you have to guess.  You can look at the extensions as one clue, if the files have them.  You can also recognise know binary formats, and ignore those.  Otherwise see what proportion of non-printable ASCII bytes you have and take a guess from that.  You can also try decoding from UTF-8 and see if that produces sensible output.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  If you're not on Windows, you can use Python Magic to determine the filetype. Then you can check if it is a text/ mime type.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  A shorter solution, with a UTF-16 warning:  def is_binary(filename):     \"\"\"      Return true if the given filename appears to be binary.     File is considered to be binary if it contains a NULL byte.     FIXME: This approach incorrectly reports UTF-16 as binary.     \"\"\"     with open(filename, 'rb') as f:         for block in f:             if b'\\0' in block:                 return True     return False      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  If you're using python3 with utf-8 it is straight forward, just open the file in text mode and stop processing if you get an UnicodeDecodeError. Python3 will use unicode when handling files in text mode (and bytearray in binary mode) - if your encoding can't decode arbitrary files it's quite likely that you will get UnicodeDecodeError.   Example:  try:     with open(filename, \"r\") as f:         for l in f:              process_line(l) except UnicodeDecodeError:     pass # Fond non-text data      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  I came here looking for exactly the same thing--a comprehensive solution provided by the standard library to detect binary or text. After reviewing the options people suggested, the nix file command looks to be the best choice (I'm only developing for linux boxen). Some others posted solutions using file but they are unnecessarily complicated in my opinion, so here's what I came up with:  def test_file_isbinary(filename):     cmd = shlex.split(\"file -b -e soft '{}'\".format(filename))     if subprocess.check_output(cmd)[:4] in {'ASCI', 'UTF-'}:         return False     return True   It should go without saying, but your code that calls this function should make sure you can read a file before testing it, otherwise this will be mistakenly detect the file as binary.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  I guess that the best solution is to use the guess_type function. It holds a list with several mimetypes and you can also include your own types. Here come the script that I did to solve my problem:  from mimetypes import guess_type from mimetypes import add_type  def __init__(self):         self.__addMimeTypes()  def __addMimeTypes(self):         add_type(\"text/plain\",\".properties\")  def __listDir(self,path):         try:             return listdir(path)         except IOError:             print (\"The directory {0} could not be accessed\".format(path))  def getTextFiles(self, path):         asciiFiles = []         for files in self.__listDir(path):             if guess_type(files)[0].split(\"/\")[0] == \"text\":                 asciiFiles.append(files)         try:             return asciiFiles         except NameError:             print (\"No text files in directory: {0}\".format(path))         finally:             del asciiFiles   It is inside of a Class, as you can see based on the ustructure of the code. But you can pretty much change the things you want to implement it inside your application. It`s quite simple to use. The method getTextFiles returns a list object with all the text files that resides on the directory you pass in path variable.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Here's a function that first checks if the file starts with a BOM and if not looks for a zero byte within the initial 8192 bytes:  import codecs   #: BOMs to indicate that a file is a text file even if it contains zero bytes. _TEXT_BOMS = (     codecs.BOM_UTF16_BE,     codecs.BOM_UTF16_LE,     codecs.BOM_UTF32_BE,     codecs.BOM_UTF32_LE,     codecs.BOM_UTF8, )   def is_binary_file(source_path):     with open(source_path, 'rb') as source_file:         initial_bytes = source_file.read(8192)     return not any(initial_bytes.startswith(bom) for bom in _TEXT_BOMS) \\            and b'\\0' in initial_bytes   Technically the check for the UTF-8 BOM is unnecessary because it should not contain zero bytes for all practical purpose. But as it is a very common encoding it's quicker to check for the BOM in the beginning instead of scanning all the 8192 bytes for 0.     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  are you in unix? if so, then try:  isBinary = os.system(\"file -b\" + name + \" | grep text > /dev/null\")   The shell return values are inverted (0 is ok, so if it finds \"text\" then it will return a 0, and in Python that is a False expression).     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Simpler way is to check if the file consist NULL character (\\x00) by using in operator, for instance:  b'\\x00' in open(\"foo.bar\", 'rb').read()   See below the complete example:  #!/usr/bin/env python3 import argparse if __name__ == '__main__':     parser = argparse.ArgumentParser()     parser.add_argument('file', nargs=1)     args = parser.parse_args()     with open(args.file[0], 'rb') as f:         if b'\\x00' in f.read():             print('The file is binary!')         else:             print('The file is not binary!')   Sample usage:  $ ./is_binary.py /etc/hosts The file is not binary! $ ./is_binary.py `which which` The file is binary!        ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  on *NIX:  If you have access to the file shell-command, shlex can help make the subprocess module more usable:  from os.path import realpath from subprocess import check_output from shlex import split  filepath = realpath('rel/or/abs/path/to/file') assert 'ascii' in check_output(split('file {}'.format(filepth).lower()))   Or, you could also stick that in a for-loop to get output for all files in the current dir using:  import os for afile in [x for x in os.listdir('.') if os.path.isfile(x)]:     assert 'ascii' in check_output(split('file {}'.format(afile).lower()))   or for all subdirs:  for curdir, filelist in zip(os.walk('.')[0], os.walk('.')[2]):      for afile in filelist:          assert 'ascii' in check_output(split('file {}'.format(afile).lower()))      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  Most of the programs consider the file to be binary (which is any file that is not \"line-oriented\") if it contains a NULL character.  Here is perl's version of pp_fttext() (pp_sys.c) implemented in Python:  import sys PY3 = sys.version_info[0] == 3  # A function that takes an integer in the 8-bit range and returns # a single-character byte object in py3 / a single-character string # in py2. # int2byte = (lambda x: bytes((x,))) if PY3 else chr  _text_characters = (         b''.join(int2byte(i) for i in range(32, 127)) +         b'\\n\\r\\t\\f\\b')  def istextfile(fileobj, blocksize=512):     \"\"\" Uses heuristics to guess whether the given file is text or binary,         by reading a single block of bytes from the file.         If more than 30% of the chars in the block are non-text, or there         are NUL ('\\x00') bytes in the block, assume this is a binary file.     \"\"\"     block = fileobj.read(blocksize)     if b'\\x00' in block:         # Files with null bytes are binary         return False     elif not block:         # An empty file is considered a valid text file         return True      # Use translate's 'deletechars' argument to efficiently remove all     # occurrences of _text_characters from the block     nontext = block.translate(None, _text_characters)     return float(len(nontext)) / len(block) <= 0.30      Note also that this code was written to run on both Python 2 and Python 3 without changes.   Source: Perl's \"guess if file is text or binary\" implemented in Python     ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I detect if a file is binary (non-text) in python?","A_Content":"  We can use python itself to check if a file is binary, because it fails if we try to open binary file in text mode  def is_binary(file_name):     try:         with open(file_name, 'tr') as check_file:  # try open file in text mode             check_file.read()             return False     except:  # if fail then file is non-text (binary)         return True      ","Language":"Python","Tags":["python","file","binary"],"URL":"https://stackoverflow.com/questions/898669/how-can-i-detect-if-a-file-is-binary-non-text-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.  I know I could use grep -I, but I am doing more with the data than what grep allows for.  In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  Consider using Django's json lib, which is included with GAE.  from django.utils import simplejson as json  # load the object from a string obj = json.loads( string )   The link above has examples of Django's serializer, and here's the link for simplejson's documentation.  If you're looking at storing Python class instances or objects (as opposed to compositions of lists, strings, numbers, and dictionaries), you probably want to look at pickle.  I hope that helps.  Incidentally, to get Django 1.0 (instead of Django 0.96) running on GAE, you can use the following call in your main.py, per this article:  from google.appengine.dist import use_library use_library('django', '1.0')     Edit: Native JSON support in Google App Engine 1.6.0 with Python 2.7  As of Google App Engine 1.6.0, you can use the Python 2.7 runtime by adding runtime: python27 in app.yaml, and then you can import the native JSON library with import json.     ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"114","_type":"dict","isAccepted":"Yes","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  Google App Engine now supports python 2.7. If using python 2.7, you can do the following:  import json structured_dictionary = json.loads(string_received)      ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  Include the simplejson library with your app?      ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  This is an old question, but I thought I'd give an updated, more detailed answer. For those landing here now, you are almost certainly using python 2.6 or greater, so you can use the built-in json module for Python 2 (or for Python 3, since Google recently added support for Python 3 on GAE). Importing is as easy as import json. Here are some examples of how to use the json module:  import json  # parse json_string into a dict json_string = '{\"key_one\": \"value_one\", \"key_two\": 1234}' json_dict = json.loads(json_string) # json_dict: {u'key_two': 1234, u'key_one': u'value_one'}  # generate json from a dict json_dict = {'key': 'value', 'key_two': 1234, 'key_three': True} json_string = json.dumps(json_dict) # json_string: '{\"key_two\": 1234, \"key\": \"value\", \"key_three\": true}'   If you are using an older version of python, stick to @Brian M. Hunt's answer.   Again, here is the doc page for the json module for Python 2, and here it is for Python 3.     ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  If you're using Python2.6 or greater, I've used with success the built-in json.load function. Otherwise, simplejson works on 2.4 without dependencies.      ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"How can I parse JSON in Google App Engine?","A_Content":"  Look at the python section of json.org. The standard library support for JSON started at python 2.6, which I believe is newer than what the app engine provides. Maybe one of the other options listed?     ","Language":"Python","Tags":["python","json","google-app-engine"],"URL":"https://stackoverflow.com/questions/1171584/how-can-i-parse-json-in-google-app-engine","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to parse a JSON string into an object under Google App Engine (python).  What do you recommend?  Something to encode/stringify would be nice too.  Is what you recommend built in, or a library that I have to include in my app?  Is it secure?  Thanks.     ","Q_Votes":"81"},{"Q_Title":"Full examples of using pySerial package [closed]","A_Content":"  Blog post Serial RS232 connections in Python  import time import serial  # configure the serial connections (the parameters differs on the device you are connecting to) ser = serial.Serial(     port='/dev/ttyUSB1',     baudrate=9600,     parity=serial.PARITY_ODD,     stopbits=serial.STOPBITS_TWO,     bytesize=serial.SEVENBITS )  ser.isOpen()  print 'Enter your commands below.\\r\\nInsert \"exit\" to leave the application.'  input=1 while 1 :     # get keyboard input     input = raw_input(\">> \")         # Python 3 users         # input = input(\">> \")     if input == 'exit':         ser.close()         exit()     else:         # send the character to the device         # (note that I happend a \\r\\n carriage return and line feed to the characters - this is requested by my device)         ser.write(input + '\\r\\n')         out = ''         # let's wait one second before reading output (let's give device time to answer)         time.sleep(1)         while ser.inWaiting() > 0:             out += ser.read(1)          if out != '':             print \">>\" + out      ","Language":"Python","Tags":["python","modem","pyserial"],"URL":"https://stackoverflow.com/questions/676172/full-examples-of-using-pyserial-package","A_Votes":"83","_type":"dict","isAccepted":"No","Q_Content":"    Can someone please show me a full python sample code that uses pyserial, i have the package and am wondering how to send the AT commands and read them back!     ","Q_Votes":"81"},{"Q_Title":"Full examples of using pySerial package [closed]","A_Content":"  import serial ser = serial.Serial(0)  # open first serial port print ser.portstr       # check which port was really used ser.write(\"hello\")      # write a string ser.close()             # close port   use https://pythonhosted.org/pyserial/ for more examples     ","Language":"Python","Tags":["python","modem","pyserial"],"URL":"https://stackoverflow.com/questions/676172/full-examples-of-using-pyserial-package","A_Votes":"44","_type":"dict","isAccepted":"No","Q_Content":"    Can someone please show me a full python sample code that uses pyserial, i have the package and am wondering how to send the AT commands and read them back!     ","Q_Votes":"81"},{"Q_Title":"Full examples of using pySerial package [closed]","A_Content":"  http://www.roman10.net/serial-port-communication-in-python/comment-page-1/#comment-1877  #!/usr/bin/python  import serial, time #initialization and open the port  #possible timeout values: #    1. None: wait forever, block call #    2. 0: non-blocking mode, return immediately #    3. x, x is bigger than 0, float allowed, timeout block call  ser = serial.Serial() #ser.port = \"/dev/ttyUSB0\" ser.port = \"/dev/ttyUSB7\" #ser.port = \"/dev/ttyS2\" ser.baudrate = 9600 ser.bytesize = serial.EIGHTBITS #number of bits per bytes ser.parity = serial.PARITY_NONE #set parity check: no parity ser.stopbits = serial.STOPBITS_ONE #number of stop bits #ser.timeout = None          #block read ser.timeout = 1            #non-block read #ser.timeout = 2              #timeout block read ser.xonxoff = False     #disable software flow control ser.rtscts = False     #disable hardware (RTS/CTS) flow control ser.dsrdtr = False       #disable hardware (DSR/DTR) flow control ser.writeTimeout = 2     #timeout for write  try:      ser.open() except Exception, e:     print \"error open serial port: \" + str(e)     exit()  if ser.isOpen():      try:         ser.flushInput() #flush input buffer, discarding all its contents         ser.flushOutput()#flush output buffer, aborting current output                   #and discard all that is in buffer          #write data         ser.write(\"AT+CSQ\")         print(\"write data: AT+CSQ\")         time.sleep(0.5)  #give the serial port sometime to receive the data         numOfLines = 0         while True:           response = ser.readline()           print(\"read data: \" + response)          numOfLines = numOfLines + 1          if (numOfLines >= 5):             break          ser.close()     except Exception, e1:         print \"error communicating...: \" + str(e1)  else:     print \"cannot open serial port \"      ","Language":"Python","Tags":["python","modem","pyserial"],"URL":"https://stackoverflow.com/questions/676172/full-examples-of-using-pyserial-package","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    Can someone please show me a full python sample code that uses pyserial, i have the package and am wondering how to send the AT commands and read them back!     ","Q_Votes":"81"},{"Q_Title":"Full examples of using pySerial package [closed]","A_Content":"  I have not used pyserial but based on the API documentation at https://pyserial.readthedocs.io/en/latest/shortintro.html it seems like a very nice interface.  It might be worth double-checking the specification for AT commands of the device/radio/whatever you are dealing with.  Specifically, some require some period of silence before and/or after the AT command for it to enter into command mode.  I have encountered some which do not like reads of the response without some delay first.     ","Language":"Python","Tags":["python","modem","pyserial"],"URL":"https://stackoverflow.com/questions/676172/full-examples-of-using-pyserial-package","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Can someone please show me a full python sample code that uses pyserial, i have the package and am wondering how to send the AT commands and read them back!     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  audio /= np.max(np.abs(audio),axis=0) image *= (255.0/image.max())   Using /= and *= allows you to eliminate an intermediate temporary array, thus saving some memory.  Multiplication is less expensive than division, so   image *= 255.0/image.max()    # Uses 1 division and image.size multiplications   is marginally faster than   image /= image.max()/255.0    # Uses 1+image.size divisions   Since we are using basic numpy methods here, I think this is about as efficient a solution in numpy as can be.     ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  You can also rescale using sklearn. The advantages are that you can adjust normalize the standard deviation, in addition to mean-centering the data, and that you can do this on either axis, by features, or by records.  from sklearn.preprocessing import scale X = scale( X, axis=0, with_mean=True, with_std=True, copy=True )   The keyword arguments axis, with_mean, with_std are self explanatory, and are shown in their default state. The argument copy performs the operation in-place if it is set to False. Documentation here.     ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  If the array contains both positive and negative data, I'd go with:  import numpy as np  a = np.random.rand(3,2)  # Normalised [0,1] b = (a - np.min(a))/np.ptp(a)  # Normalised [0,255] as integer c = (255*(a - np.min(a))/np.ptp(a)).astype(int)  # Normalised [-1,1] d = 2*(a - np.min(a))/np.ptp(a)-1   also, worth mentioning even if it's not OP's question, standardization:  e = (a - np.mean(a)) / np.std(a)      ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  You can use the \"i\" (as in idiv, imul..) version, and it doesn't look half bad:  image /= (image.max()/255.0)   For the other case you can write a function to normalize an n-dimensional array by colums:  def normalize_columns(arr):     rows, cols = arr.shape     for col in xrange(cols):         arr[:,col] /= abs(arr[:,col]).max()      ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  I tried following this, and got the error   TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''   The numpy array I was trying to normalize was an integer array. It seems they deprecated type casting in versions > 1.10, and you have to use numpy.true_divide() to resolve that.  arr = np.array(img) arr = np.true_divide(arr,[255.0],out=None)   img was an PIL.Image object.     ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How to normalize a NumPy array to within a certain range?","A_Content":"  A simple solution is using the scalers offered by the sklearn.preprocessing library.   scaler = sk.MinMaxScaler(feature_range=(0, 250)) scaler = scaler.fit(X) X_scaled = scaler.transform(X) # Checking reconstruction X_rec = scaler.inverse_transform(X_scaled)   The error X_rec-X will be zero. You can adjust the feature_range for your needs, or even use a standart scaler sk.StandardScaler()     ","Language":"Python","Tags":["python","arrays","numpy","scipy","convenience-methods"],"URL":"https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    After doing some processing on an audio or image array, it needs to be normalized within a range before it can be written back to a file.  This can be done like so:  # Normalize audio channels to between -1.0 and +1.0 audio[:,0] = audio[:,0]/abs(audio[:,0]).max() audio[:,1] = audio[:,1]/abs(audio[:,1]).max()  # Normalize image to between 0 and 255 image = image/(image.max()/255.0)   Is there a less verbose, convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related.     ","Q_Votes":"81"},{"Q_Title":"How can I rename a conda environment?","A_Content":"  You can't.  One workaround is to create clone environment, and then remove original one:  (remember about deactivating current environment with deactivate on Windows and source deactivate on macOS/Linux)  conda create --name new_name --clone old_name conda remove --name old_name --all # or its alias: `conda env remove --name old_name`   There are several drawbacks of this method:   it redownloads packages - you can use --offline flag to disable it, time consumed on copying environment's files, temporary double disk usage.   There is an open issue requesting this feature.     ","Language":"Python","Tags":["python","anaconda","conda"],"URL":"https://stackoverflow.com/questions/42231764/how-can-i-rename-a-conda-environment","A_Votes":"154","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a conda environment named old_name, how can I change its name to new_name without breaking references?     ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  list( myBigList[i] for i in [87, 342, 217, 998, 500] )     I compared the answers with python 2.5.2:   19.7 usec: [ myBigList[i] for i in [87, 342, 217, 998, 500] ] 20.6 usec: map(myBigList.__getitem__, (87, 342, 217, 998, 500)) 22.7 usec: itemgetter(87, 342, 217, 998, 500)(myBigList) 24.6 usec: list( myBigList[i] for i in [87, 342, 217, 998, 500] )   Note that in Python 3, the 1st was changed to be the same as the 4th.    Another option would be to start out with a numpy.array which allows indexing via a list or a numpy.array:  >>> import numpy >>> myBigList = numpy.array(range(1000)) >>> myBigList[(87, 342, 217, 998, 500)] Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> IndexError: invalid index >>> myBigList[[87, 342, 217, 998, 500]] array([ 87, 342, 217, 998, 500]) >>> myBigList[numpy.array([87, 342, 217, 998, 500])] array([ 87, 342, 217, 998, 500])   The tuple doesn't work the same way as those are slices.     ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  What about this:  from operator import itemgetter itemgetter(0,2,3)(myList) ('foo', 'baz', 'quux')      ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"32","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  It isn't built-in, but you can make a subclass of list that takes tuples as \"indexes\" if you'd like:  class MyList(list):      def __getitem__(self, index):         if isinstance(index, tuple):             return [self[i] for i in index]         return super(MyList, self).__getitem__(index)   seq = MyList(\"foo bar baaz quux mumble\".split()) print seq[0] print seq[2,4] print seq[1::2]   printing  foo ['baaz', 'mumble'] ['bar', 'quux']      ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  >>> map(myList.__getitem__, (2,2,1,3)) ('baz', 'baz', 'bar', 'quux')   You can also create your own List class which supports tuples as arguments to __getitem__ if you want to be able to do myList[(2,2,1,3)].     ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  Maybe a list comprehension is in order:  L = ['a', 'b', 'c', 'd', 'e', 'f'] print [ L[index] for index in [1,3,5] ]   Produces:  ['b', 'd', 'f']   Is that what you are looking for?     ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  I just want to point out, even syntax of itemgetter looks really neat, but it's kinda slow when perform on large list.  import timeit from operator import itemgetter start=timeit.default_timer() for i in range(1000000):     itemgetter(0,2,3)(myList) print (\"Itemgetter took \", (timeit.default_timer()-start))   Itemgetter took  1.065209062149279  start=timeit.default_timer() for i in range(1000000):     myList[0],myList[2],myList[3] print (\"Multiple slice took \", (timeit.default_timer()-start))   Multiple slice took  0.6225321444745759     ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  Another possible solution:  sek=[] L=[1,2,3,4,5,6,7,8,9,0] for i in [2, 4, 7, 0, 3]:    a=[L[i]]    sek=sek+a print (sek)      ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Explicitly select items from a Python list or tuple","A_Content":"  like often when you have a boolean numpy array like mask  [mylist[i] for i in np.arange(len(mask), dtype=int)[mask]]  A lambda that works for any sequence or np.array:  subseq = lambda myseq, mask : [myseq[i] for i in np.arange(len(mask), dtype=int)[mask]]  newseq = subseq(myseq, mask)     ","Language":"Python","Tags":["python","list","select","indexing","tuples"],"URL":"https://stackoverflow.com/questions/6632188/explicitly-select-items-from-a-python-list-or-tuple","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have the following Python list (can also be a tuple):  myList = ['foo', 'bar', 'baz', 'quux']   I can say  >>> myList[0:3] ['foo', 'bar', 'baz'] >>> myList[::2] ['foo', 'baz'] >>> myList[1::2] ['bar', 'quux']   How do I explicitly pick out items whose indices have no specific patterns? For example, I want to select [0,2,3]. Or from a very big list of 1000 items, I want to select [87, 342, 217, 998, 500]. Is there some Python syntax that does that? Something that looks like:  >>> myBigList[87, 342, 217, 998, 500]      ","Q_Votes":"81"},{"Q_Title":"Save a large file using the Python requests library [duplicate]","A_Content":"  Oddly enough, requests doesn't have anything simple for this. You'll have to iterate over the response and write those chunks to a file:  response = requests.get('http://www.example.com/image.jpg', stream=True)  # Throw an error for bad status codes response.raise_for_status()  with open('output.jpg', 'wb') as handle:     for block in response.iter_content(1024):         handle.write(block)   I usually just use urllib.urlretrieve(). It works, but if you need to use a session or some sort of authentication, the above code works as well.     ","Language":"Python","Tags":["python","file","http","download","request"],"URL":"https://stackoverflow.com/questions/14114729/save-a-large-file-using-the-python-requests-library","A_Votes":"152","_type":"dict","isAccepted":"Yes","Q_Content":"       Possible Duplicate:   How to download image using requests       I know that fetching a url is as simple as requests.get and I can get at the raw response body and save it to a file, but for large files, is there a way to stream directly to a file? Like if I'm downloading a movie with it or something?     ","Q_Votes":"81"},{"Q_Title":"How does numpy.newaxis work and when to use it?","A_Content":"  Simply put, the newaxis is used to increase the dimension of the existing array by one more dimension, when used once. Thus,   1D array will become 2D array 2D array will become 3D array 3D array will become 4D array   and so on.. Here is a visual illustration.      Scenario-1: np.newaxis might come in handy when you want to explicitly convert an 1D array to either a row vector or a column vector, as depicted in the above picture.  Example:  # 1D array In [7]: arr = np.arange(4) In [8]: arr.shape Out[8]: (4,)  # make it as row vector by inserting an axis along first dimension In [9]: row_vec = arr[np.newaxis, :] In [10]: row_vec.shape Out[10]: (1, 4)  # make it as column vector by inserting an axis along second dimension In [11]: col_vec = arr[:, np.newaxis] In [12]: col_vec.shape Out[12]: (4, 1)     Scenario-2: When we want to make use of numpy broadcasting as part of some operation, for instance while doing addition of some arrays.  Example:  Let's say you want to add the following two arrays:   x1 = np.array([1, 2, 3, 4, 5])  x2 = np.array([5, 4, 3])   If you try to add these just like that, NumPy will raise the following ValueError :  ValueError: operands could not be broadcast together with shapes (5,) (3,)   In this situation, you can use np.newaxis to increase the dimension of one of the arrays so that NumPy can broadcast.  In [2]: x1_new = x1[:, np.newaxis] # now, the shape of x1_new is (5, 1) # array([[1], #        [2], #        [3], #        [4], #        [5]])   Now, add:  In [3]: x1_new + x2 Out[3]: array([[ 6,  5,  4],        [ 7,  6,  5],        [ 8,  7,  6],        [ 9,  8,  7],        [10,  9,  8]])     Alternatively, you can also add new axis to the array x2:  In [6]: x2_new = x2[:, np.newaxis] In [7]: x2_new     # shape is (3, 1) Out[7]:  array([[5],        [4],        [3]])   Now, add:  In [8]: x1 + x2_new Out[8]:  array([[ 6,  7,  8,  9, 10],        [ 5,  6,  7,  8,  9],        [ 4,  5,  6,  7,  8]])   Note: Observe that we get the same result in both cases (but one being the transpose of the other).    Scenario-3: This is similar to scenario-1. But, you can use np.newaxis more than once to promote the array to higher dimensions.  Example:    In [124]: arr = np.arange(5*5).reshape(5,5)  In [125]: arr.shape Out[125]: (5, 5)  # promoting 2D array to a 5D array In [126]: arr_5D = arr[np.newaxis, ..., np.newaxis, np.newaxis]  In [127]: arr_5D.shape Out[127]: (1, 5, 5, 1, 1)     More background on np.newaxis vs np.reshape  newaxis is also called as a pseudo-index that allows the temporary addition of an axis into a multiarray.  np.newaxis uses the slicing operator to recreate the array while np.reshape reshapes the array to the desired layout (assuming that the dimensions match; And this is must for a reshape to happen).  Example  In [13]: A = np.ones((3,4,5,6)) In [14]: B = np.ones((4,6)) In [15]: (A + B[:, np.newaxis, :]).shape Out[15]: (3, 4, 5, 6)   In the above example, we inserted a temporary axis between the first and second axes of B (to use broadcasting). A missing axis is filled-in here using np.newaxis to make the broadcasting operation work.    General Tip: You can also use None in place of np.newaxis; These are in fact the same objects.  In [13]: np.newaxis is None Out[13]: True   P.S. Also see this great answer: newaxis vs reshape to add dimensions     ","Language":"Python","Tags":["python","numpy","multidimensional-array","numpy-broadcasting","numpy-ndarray"],"URL":"https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it","A_Votes":"135","_type":"dict","isAccepted":"No","Q_Content":"    When I try  numpy.newaxis   the result gives me a 2-d plot frame with x-axis from 0 to 1. However, when I try using numpy.newaxis to slice a vector,   vector[0:4,] [ 0.04965172  0.04979645  0.04994022  0.05008303] vector[:, np.newaxis][0:4,] [[ 0.04965172] [ 0.04979645] [ 0.04994022] [ 0.05008303]]   Is it the same thing except that it changes a row vector to a column vector?   Generally, what is the use of numpy.newaxis, and in which circumstances should we use it?     ","Q_Votes":"81"},{"Q_Title":"How does numpy.newaxis work and when to use it?","A_Content":"  You started with a one-dimensional list of numbers.  Once you used numpy.newaxis, you turned it into a two-dimensional matrix, consisting of four rows of one column each.  You could then use that matrix for matrix multiplication, or involve it in the construction of a larger 4 x n matrix.     ","Language":"Python","Tags":["python","numpy","multidimensional-array","numpy-broadcasting","numpy-ndarray"],"URL":"https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    When I try  numpy.newaxis   the result gives me a 2-d plot frame with x-axis from 0 to 1. However, when I try using numpy.newaxis to slice a vector,   vector[0:4,] [ 0.04965172  0.04979645  0.04994022  0.05008303] vector[:, np.newaxis][0:4,] [[ 0.04965172] [ 0.04979645] [ 0.04994022] [ 0.05008303]]   Is it the same thing except that it changes a row vector to a column vector?   Generally, what is the use of numpy.newaxis, and in which circumstances should we use it?     ","Q_Votes":"81"},{"Q_Title":"How does numpy.newaxis work and when to use it?","A_Content":"  What is np.newaxis?  The np.newaxis is just an alias for the Python constant None, which means that wherever you use np.newaxis you could also use None:  >>> np.newaxis is None True   It's just more descriptive if you read code that uses np.newaxis instead of None.  How to use np.newaxis?  The np.newaxis is generally used with slicing. It indicates that you want to add an additional dimension to the array. The position of the np.newaxis represents where I want to add dimensions.  >>> import numpy as np >>> a = np.arange(10) >>> a array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> a.shape (10,)   In the first example I use all elements from the first dimension and add a second dimension:  >>> a[:, np.newaxis] array([[0],        [1],        [2],        [3],        [4],        [5],        [6],        [7],        [8],        [9]]) >>> a[:, np.newaxis].shape (10, 1)   The second example adds a dimension as first dimension and then uses all elements from the first dimension of the original array as elements in the second dimension of the result array:  >>> a[np.newaxis, :]  # The output has 2 [] pairs! array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) >>> a[np.newaxis, :].shape (1, 10)   Similarly you can use multiple np.newaxis to add multiple dimensions:  >>> a[np.newaxis, :, np.newaxis]  # note the 3 [] pairs in the output array([[[0],         [1],         [2],         [3],         [4],         [5],         [6],         [7],         [8],         [9]]]) >>> a[np.newaxis, :, np.newaxis].shape (1, 10, 1)   Are there alternatives to np.newaxis?  There is another very similar functionality in NumPy: np.expand_dims, which can also be used to insert one dimension:  >>> np.expand_dims(a, 1)  # like a[:, np.newaxis] >>> np.expand_dims(a, 0)  # like a[np.newaxis, :]   But given that it just inserts 1s in the shape you could also reshape the array to add these dimensions:  >>> a.reshape(a.shape + (1,))  # like a[:, np.newaxis] >>> a.reshape((1,) + a.shape)  # like a[np.newaxis, :]   Most of the times np.newaxis is the easiest way to add dimensions, but it's good to know the alternatives.  When to use np.newaxis?  In several contexts is adding dimensions useful:   If the data should have a specified number of dimensions. For example if you want to use matplotlib.pyplot.imshow to display a 1D array. If you want NumPy to broadcast arrays. By adding a dimension you could for example get the difference between all elements of one array: a - a[:, np.newaxis]. This works because NumPy operations broadcast starting with the last dimension 1. To add a necessary dimension so that NumPy can broadcast arrays. This works because each length-1 dimension is simply broadcast to the length of the corresponding1 dimension of the other array.     1 If you want to read more about the broadcasting rules the NumPy documentation on that subject is very good. It also includes an example with np.newaxis:   >>> a = np.array([0.0, 10.0, 20.0, 30.0]) >>> b = np.array([1.0, 2.0, 3.0]) >>> a[:, np.newaxis] + b array([[  1.,   2.,   3.],        [ 11.,  12.,  13.],        [ 21.,  22.,  23.],        [ 31.,  32.,  33.]])       ","Language":"Python","Tags":["python","numpy","multidimensional-array","numpy-broadcasting","numpy-ndarray"],"URL":"https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    When I try  numpy.newaxis   the result gives me a 2-d plot frame with x-axis from 0 to 1. However, when I try using numpy.newaxis to slice a vector,   vector[0:4,] [ 0.04965172  0.04979645  0.04994022  0.05008303] vector[:, np.newaxis][0:4,] [[ 0.04965172] [ 0.04979645] [ 0.04994022] [ 0.05008303]]   Is it the same thing except that it changes a row vector to a column vector?   Generally, what is the use of numpy.newaxis, and in which circumstances should we use it?     ","Q_Votes":"81"},{"Q_Title":"How does numpy.newaxis work and when to use it?","A_Content":"  newaxis object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension.  It is not just conversion of row matrix to column matrix.  Consider the example below:  In [1]:x1 = np.arange(1,10).reshape(3,3)        print(x1) Out[1]: array([[1, 2, 3],                [4, 5, 6],                [7, 8, 9]])   Now lets add new dimension to our data,  In [2]:x1_new = x1[:,np.newaxis]        print(x1_new) Out[2]:array([[[1, 2, 3]],                [[4, 5, 6]],                [[7, 8, 9]]])   You can see that newaxis added the extra dimension here, x1 had dimension (3,3) and X1_new has dimension (3,1,3).  How our new dimension enables us to different operations:  In [3]:x2 = np.arange(11,20).reshape(3,3)        print(x2) Out[3]:array([[11, 12, 13],               [14, 15, 16],               [17, 18, 19]])    Adding x1_new and x2, we get:  In [4]:x1_new+x2 Out[4]:array([[[12, 14, 16],                [15, 17, 19],                [18, 20, 22]],                [[15, 17, 19],                [18, 20, 22],                [21, 23, 25]],                [[18, 20, 22],                [21, 23, 25],                [24, 26, 28]]])   Thus, newaxis is not just conversion of row to column matrix. It increases the dimension of matrix, thus enabling us to do more operations on it.     ","Language":"Python","Tags":["python","numpy","multidimensional-array","numpy-broadcasting","numpy-ndarray"],"URL":"https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    When I try  numpy.newaxis   the result gives me a 2-d plot frame with x-axis from 0 to 1. However, when I try using numpy.newaxis to slice a vector,   vector[0:4,] [ 0.04965172  0.04979645  0.04994022  0.05008303] vector[:, np.newaxis][0:4,] [[ 0.04965172] [ 0.04979645] [ 0.04994022] [ 0.05008303]]   Is it the same thing except that it changes a row vector to a column vector?   Generally, what is the use of numpy.newaxis, and in which circumstances should we use it?     ","Q_Votes":"81"},{"Q_Title":"Using .sort with PyMongo","A_Content":"  sort should be a list of key-direction pairs, that is  db.test.find({\"number\": {\"$gt\": 1}}).sort([(\"number\", 1), (\"date\", -1)])   The reason why this has to be a list is that the ordering of the arguments matters and dicts are not ordered in Python.     ","Language":"Python","Tags":["python","mongodb","pymongo"],"URL":"https://stackoverflow.com/questions/10242149/using-sort-with-pymongo","A_Votes":"155","_type":"dict","isAccepted":"Yes","Q_Content":"    With PyMongo, when I try to retrieve objects sorted by their 'number' and 'date' fields like this:  db.test.find({\"number\": {\"$gt\": 1}}).sort({\"number\": 1, \"date\": -1})   I get this error:  TypeError: if no direction is specified, key_or_list must be an instance of list   What's wrong with my sort query?     ","Q_Votes":"81"},{"Q_Title":"Latest 'pip' fails with requires setuptools >= 0.8 for dist-info","A_Content":"  This worked for me:  sudo pip install setuptools --no-use-wheel --upgrade   Note it's usage of sudo  UPDATE  On window you just need to execute pip install setuptools --no-use-wheel --upgrade as an administrator. In unix/linux, sudo command is for elevating permissions.  UPDATE  This appears to have been fixed in 1.5.1.     ","Language":"Python","Tags":["python","pip","setuptools","python-wheel"],"URL":"https://stackoverflow.com/questions/20905350/latest-pip-fails-with-requires-setuptools-0-8-for-dist-info","A_Votes":"147","_type":"dict","isAccepted":"Yes","Q_Content":"    Using the recent (1.5) version of pip, I get an error when attempting to update several packages. For example, sudo pip install -U pytz results in failure with:  Wheel installs require setuptools >= 0.8 for dist-info support. pip's wheel support requires setuptools >= 0.8 for dist-info support.   I don't understand this message (I have setuptools 2.1) or what to do about it.    Exception information from the log for this error:  Exception information: Traceback (most recent call last):   File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 230, in run     finder = self._build_package_finder(options, index_urls, session)   File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 185, in _build_package_finder     session=session,   File \"/Library/Python/2.7/site-packages/pip/index.py\", line 50, in __init__     self.use_wheel = use_wheel   File \"/Library/Python/2.7/site-packages/pip/index.py\", line 89, in use_wheel     raise InstallationError(\"pip's wheel support requires setuptools >= 0.8 for dist-info support.\") InstallationError: pip's wheel support requires setuptools >= 0.8 for dist-info support.      ","Q_Votes":"81"},{"Q_Title":"Latest 'pip' fails with requires setuptools >= 0.8 for dist-info","A_Content":"  First, you should never run 'sudo pip'.   If possible you should use your system package manager because it uses GPG signatures to ensure you're not running malicious code.   Otherwise, try upgrading setuptools:  easy_install -U setuptools   Alternatively, try:  pip install --user <somepackage>   This is of course for \"global\" packages. You should ideally be using virtualenvs.     ","Language":"Python","Tags":["python","pip","setuptools","python-wheel"],"URL":"https://stackoverflow.com/questions/20905350/latest-pip-fails-with-requires-setuptools-0-8-for-dist-info","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Using the recent (1.5) version of pip, I get an error when attempting to update several packages. For example, sudo pip install -U pytz results in failure with:  Wheel installs require setuptools >= 0.8 for dist-info support. pip's wheel support requires setuptools >= 0.8 for dist-info support.   I don't understand this message (I have setuptools 2.1) or what to do about it.    Exception information from the log for this error:  Exception information: Traceback (most recent call last):   File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 230, in run     finder = self._build_package_finder(options, index_urls, session)   File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 185, in _build_package_finder     session=session,   File \"/Library/Python/2.7/site-packages/pip/index.py\", line 50, in __init__     self.use_wheel = use_wheel   File \"/Library/Python/2.7/site-packages/pip/index.py\", line 89, in use_wheel     raise InstallationError(\"pip's wheel support requires setuptools >= 0.8 for dist-info support.\") InstallationError: pip's wheel support requires setuptools >= 0.8 for dist-info support.      ","Q_Votes":"81"},{"Q_Title":"Union of dict objects in Python [duplicate]","A_Content":"  This question provides an idiom. You use one of the dicts as keyword arguments to the dict() constructor:  dict(y, **x)   Duplicates are resolved in favor of the value in x; for example  dict({'a' : 'y[a]'}, **{'a', 'x[a]'}) == {'a' : 'x[a]'}      ","Language":"Python","Tags":["python","dictionary","associative-array","idioms","set-operations"],"URL":"https://stackoverflow.com/questions/9819602/union-of-dict-objects-in-python","A_Votes":"72","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              How to merge two dictionaries in a single expression?                                        49 answers                                          How do you calculate the union of two dict objects in Python, where a (key, value) pair is present in the result iff key is in either dict (unless there are duplicates)?  For example, the union of {'a' : 0, 'b' : 1} and {'c' : 2} is {'a' : 0, 'b' : 1, 'c' : 2}.  Preferably you can do this without modifying either input dict. Example of where this is useful: Get a dict of all variables currently in scope and their values     ","Q_Votes":"81"},{"Q_Title":"Union of dict objects in Python [duplicate]","A_Content":"  You can also use update method of dict like  a = {'a' : 0, 'b' : 1} b = {'c' : 2}  a.update(b) print a      ","Language":"Python","Tags":["python","dictionary","associative-array","idioms","set-operations"],"URL":"https://stackoverflow.com/questions/9819602/union-of-dict-objects-in-python","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to merge two dictionaries in a single expression?                                        49 answers                                          How do you calculate the union of two dict objects in Python, where a (key, value) pair is present in the result iff key is in either dict (unless there are duplicates)?  For example, the union of {'a' : 0, 'b' : 1} and {'c' : 2} is {'a' : 0, 'b' : 1, 'c' : 2}.  Preferably you can do this without modifying either input dict. Example of where this is useful: Get a dict of all variables currently in scope and their values     ","Q_Votes":"81"},{"Q_Title":"Union of dict objects in Python [duplicate]","A_Content":"  Two dictionaries  def union2(dict1, dict2):     return dict(list(dict1.items()) + list(dict2.items()))   n dictionaries  def union(*dicts):     return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))      ","Language":"Python","Tags":["python","dictionary","associative-array","idioms","set-operations"],"URL":"https://stackoverflow.com/questions/9819602/union-of-dict-objects-in-python","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to merge two dictionaries in a single expression?                                        49 answers                                          How do you calculate the union of two dict objects in Python, where a (key, value) pair is present in the result iff key is in either dict (unless there are duplicates)?  For example, the union of {'a' : 0, 'b' : 1} and {'c' : 2} is {'a' : 0, 'b' : 1, 'c' : 2}.  Preferably you can do this without modifying either input dict. Example of where this is useful: Get a dict of all variables currently in scope and their values     ","Q_Votes":"81"},{"Q_Title":"Union of dict objects in Python [duplicate]","A_Content":"  If you need both dicts to remain independent, and updatable, you can create a single object that queries both dictionaries in its __getitem__ method (and implement  get, __contains__ and other mapping method as you need them).  A minimalist example could be like this:  class UDict(object):    def __init__(self, d1, d2):        self.d1, self.d2 = d1, d2    def __getitem__(self, item):        if item in self.d1:            return self.d1[item]        return self.d2[item]   And it works:  >>> a = UDict({1:1}, {2:2}) >>> a[2] 2 >>> a[1] 1 >>> a[3] Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 7, in __getitem__ KeyError: 3 >>>       ","Language":"Python","Tags":["python","dictionary","associative-array","idioms","set-operations"],"URL":"https://stackoverflow.com/questions/9819602/union-of-dict-objects-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to merge two dictionaries in a single expression?                                        49 answers                                          How do you calculate the union of two dict objects in Python, where a (key, value) pair is present in the result iff key is in either dict (unless there are duplicates)?  For example, the union of {'a' : 0, 'b' : 1} and {'c' : 2} is {'a' : 0, 'b' : 1, 'c' : 2}.  Preferably you can do this without modifying either input dict. Example of where this is useful: Get a dict of all variables currently in scope and their values     ","Q_Votes":"81"},{"Q_Title":"models.py getting huge, what is the best way to break it up?","A_Content":"  Django is designed to let you build many small applications instead of one big application.  Inside every large application are many small applications struggling to be free.  If your models.py feels big, you're doing too much.  Stop.  Relax.  Decompose.  Find smaller, potentially reusable small application components, or pieces.  You don't have to actually reuse them.  Just think about them as potentially reusable.  Consider your upgrade paths and decompose applications that you might want to replace some day.  You don't have to actually replace them, but you can consider them as a stand-alone \"module\" of programming that might get replaced with something cooler in the future.  We have about a dozen applications, each model.py is no more than about 400 lines of code.  They're all pretty focused on less than about half-dozen discrete class definitions. (These aren't hard limits, they're observations about our code.)  We decompose early and often.       ","Language":"Python","Tags":["python","django","django-models","models"],"URL":"https://stackoverflow.com/questions/1160579/models-py-getting-huge-what-is-the-best-way-to-break-it-up","A_Votes":"61","_type":"dict","isAccepted":"Yes","Q_Content":"    Directions from my supervisor: \"I want to avoid putting any logic in the models.py.  From here on out, let's use that as only classes for accessing the database, and keep all logic in external classes that use the models classes, or wrap them.\"  I feel like this is the wrong way to go. I feel that keeping logic out of the models just to keep the file small is a bad idea. If the logic is best in the model, that's where it really should go regardless of file size.  So is there a simple way to just use includes? In PHP-speak, I'd like to propose to the supervisor that we just have models.py include() the model classes from other places. Conceptually, this would allow the models to have all the logic we want, yet keep file size down via increasing the number of files (which leads to less revision control problems like conflicts, etc.).  So, is there a simple way to remove model classes from the models.py file, but still have the models work with all of the Django tools? Or, is there a completely different yet elegant solution to the general problem of a \"large\" models.py file? Any input would be appreciated.     ","Q_Votes":"81"},{"Q_Title":"models.py getting huge, what is the best way to break it up?","A_Content":"  It's natural for model classes to contain methods to operate on the model.  If I have a Book model, with a method book.get_noun_count(), that's where it belongs--I don't want to have to write \"get_noun_count(book)\", unless the method actually intrinsically belongs with some other package.  (It might--for example, if I have a package for accessing Amazon's API with \"get_amazon_product_id(book)\".)  I cringed when Django's documentation suggested putting models in a single file, and I took a few minutes from the very beginning to figure out how to split it into a proper subpackage.  site/models/__init__.py site/models/book.py   __init__.py looks like:  from .book import Book   so I can still write \"from site.models import Book\".       The following is only required for versions prior to Django 1.7, see   https://code.djangoproject.com/ticket/3591   The only trick is that you need to explicitly set each model's application, due to a bug in Django: it assumes that the application name is the third-to-last entry in the model path.  \"site.models.Book\" results in \"site\", which is correct; \"site.models.book.Book\" makes it think the application name is \"models\".  This is a pretty nasty hack on Django's part; it should probably search the list of installed applications for a prefix match.  class Book(models.Model):     class Meta: app_label = \"site\"   You could probably use a base class or metaclass to generalize this, but I haven't bothered with that yet.     ","Language":"Python","Tags":["python","django","django-models","models"],"URL":"https://stackoverflow.com/questions/1160579/models-py-getting-huge-what-is-the-best-way-to-break-it-up","A_Votes":"96","_type":"dict","isAccepted":"No","Q_Content":"    Directions from my supervisor: \"I want to avoid putting any logic in the models.py.  From here on out, let's use that as only classes for accessing the database, and keep all logic in external classes that use the models classes, or wrap them.\"  I feel like this is the wrong way to go. I feel that keeping logic out of the models just to keep the file small is a bad idea. If the logic is best in the model, that's where it really should go regardless of file size.  So is there a simple way to just use includes? In PHP-speak, I'd like to propose to the supervisor that we just have models.py include() the model classes from other places. Conceptually, this would allow the models to have all the logic we want, yet keep file size down via increasing the number of files (which leads to less revision control problems like conflicts, etc.).  So, is there a simple way to remove model classes from the models.py file, but still have the models work with all of the Django tools? Or, is there a completely different yet elegant solution to the general problem of a \"large\" models.py file? Any input would be appreciated.     ","Q_Votes":"81"},{"Q_Title":"models.py getting huge, what is the best way to break it up?","A_Content":"  I can't quite get which of many possible problems you might have. Here are some possibilities with answers:   multiple models in the same file  Put them into separate files. If there are dependencies, use import to pull in the  additional models. extraneous logic / utility functions in models.py   Put the extra logic into separate files.  static methods for selecting some model instances from database  Create a new Manager in a separate file. methods obviously related to the model  save, __unicode__ and get_absolute_url are examples.      ","Language":"Python","Tags":["python","django","django-models","models"],"URL":"https://stackoverflow.com/questions/1160579/models-py-getting-huge-what-is-the-best-way-to-break-it-up","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Directions from my supervisor: \"I want to avoid putting any logic in the models.py.  From here on out, let's use that as only classes for accessing the database, and keep all logic in external classes that use the models classes, or wrap them.\"  I feel like this is the wrong way to go. I feel that keeping logic out of the models just to keep the file small is a bad idea. If the logic is best in the model, that's where it really should go regardless of file size.  So is there a simple way to just use includes? In PHP-speak, I'd like to propose to the supervisor that we just have models.py include() the model classes from other places. Conceptually, this would allow the models to have all the logic we want, yet keep file size down via increasing the number of files (which leads to less revision control problems like conflicts, etc.).  So, is there a simple way to remove model classes from the models.py file, but still have the models work with all of the Django tools? Or, is there a completely different yet elegant solution to the general problem of a \"large\" models.py file? Any input would be appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  Use {{ request.user.get_profile.whatever }}. Django's templating language automatically calls things that are callable - in this case, the .get_profile() method.     ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"129","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  Not sure why it's different for me, but I need to use {{user}} rather than {{request.user}}.     ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  Yes it is possible to access profile from template using     request.user.get_profile  However there is a small caveat: not all users will have profiles, which was in my case with admin users. So calling directly    {{ request.user.get_profile.whatever }} from the template will cause an error in such cases.  If you are sure all your users always have profiles it is safe to call from template, otherwise call get_profile() from within try-except block in your view and pass it to the template.     ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  If you are using Django > 1.5 you can no longer use get_profile.  If you have a legacy app, you should remove AUTH_PROFILE_MODULE = 'myapp.profile' from your settings.py.  If you use models.OneToOneField(User) in your Profile class, you can simply use   {{ request.user.profile.whatever }}   in your Django template     ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  If it helps anyone, I used the followings in my template:  Username: {{ user.username }}  User Full name: {{ user.get_full_name }}  User Group: {{ user.groups.all.0 }}  Email: {{ user.email }}  Session Started at: {{ user.last_login }}  A sample result is like this:     User: auditor ezio       User Group: auditGroup       Username: testUser03       Email: testuser03@auditor.com       Session Started at- April 16, 2018, 9:38 p.m.   Thanks :)     ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"How to access the user profile in a Django template?","A_Content":"  Working !  In your profile model provide related_name  user = models.OneToOneField(AUTH_USER_MODEL, related_name=\"user_profile\", on_delete=models.CASCADE)   Then in template use. Here company_name is field in profile table  {{ request.user.user_profile.company_name }}      ","Language":"Python","Tags":["python","django","django-templates"],"URL":"https://stackoverflow.com/questions/422140/how-to-access-the-user-profile-in-a-django-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.  We can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?  Is it really required to explicitly pass the profile into the template every time?     ","Q_Votes":"81"},{"Q_Title":"Python: Implementing slicing in __getitem__","A_Content":"  The __getitem__() method will receive a slice object when the object is sliced. Simply look at the start, stop, and step members of the slice object in order to get the components for the slice.  >>> class C(object): ...   def __getitem__(self, val): ...     print val ...  >>> c = C() >>> c[3] 3 >>> c[3:4] slice(3, 4, None) >>> c[3:4:-2] slice(3, 4, -2) >>> c[():1j:'a'] slice((), 1j, 'a')      ","Language":"Python","Tags":["python","slice","python-datamodel"],"URL":"https://stackoverflow.com/questions/2936863/python-implementing-slicing-in-getitem","A_Votes":"91","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to implement slice functionality for a class I am making that creates a vector representation.  I have this code so far, which I believe will properly implement the slice but whenever I do a call like v[4] where v is a vector python returns an error about not having enough parameters. So I am trying to figure out how to define the getitem special method in my class to handle both plain indexes and slicing.  def __getitem__(self, start, stop, step):     index = start     if stop == None:         end = start + 1     else:         end = stop     if step == None:         stride = 1     else:         stride = step     return self.__data[index:end:stride]      ","Q_Votes":"81"},{"Q_Title":"Python: Implementing slicing in __getitem__","A_Content":"  I have a \"synthetic\" list (one where the data is larger than you would want to create in memory) and my __getitem__ looks like this:  def __getitem__( self, key ) :     if isinstance( key, slice ) :         #Get the start, stop, and step from the slice         return [self[ii] for ii in xrange(*key.indices(len(self)))]     elif isinstance( key, int ) :         if key < 0 : #Handle negative indices             key += len( self )         if key < 0 or key >= len( self ) :             raise IndexError, \"The index (%d) is out of range.\"%key         return self.getData(key) #Get the data from elsewhere     else:         raise TypeError, \"Invalid argument type.\"   The slice doesn't return the same type, which is a no-no, but it works for me.     ","Language":"Python","Tags":["python","slice","python-datamodel"],"URL":"https://stackoverflow.com/questions/2936863/python-implementing-slicing-in-getitem","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to implement slice functionality for a class I am making that creates a vector representation.  I have this code so far, which I believe will properly implement the slice but whenever I do a call like v[4] where v is a vector python returns an error about not having enough parameters. So I am trying to figure out how to define the getitem special method in my class to handle both plain indexes and slicing.  def __getitem__(self, start, stop, step):     index = start     if stop == None:         end = start + 1     else:         end = stop     if step == None:         stride = 1     else:         stride = step     return self.__data[index:end:stride]      ","Q_Votes":"81"},{"Q_Title":"Python: Implementing slicing in __getitem__","A_Content":"     How to define the getitem class to handle both plain indexes and slicing?   Slice objects gets automatically created when you use a colon in the subscript notation - and that is what is passed to __getitem__. Use isinstance to check if you have a slice object:  from __future__ import print_function  class Sliceable(object):      def __getitem__(self, given):         if isinstance(given, slice):             # do your handling for a slice object:             print(given.start, given.stop, given.step)         else:             # Do your handling for a plain index             print(given)   Example usage:  >>> sliceme = Sliceable() >>> sliceme[1] 1 >>> sliceme[2] 2 >>> sliceme[:] None None None >>> sliceme[1:] 1 None None >>> sliceme[1:2] 1 2 None >>> sliceme[1:2:3] 1 2 3 >>> sliceme[:2:3] None 2 3 >>> sliceme[::3] None None 3 >>> sliceme[::] None None None >>> sliceme[:] None None None      ","Language":"Python","Tags":["python","slice","python-datamodel"],"URL":"https://stackoverflow.com/questions/2936863/python-implementing-slicing-in-getitem","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to implement slice functionality for a class I am making that creates a vector representation.  I have this code so far, which I believe will properly implement the slice but whenever I do a call like v[4] where v is a vector python returns an error about not having enough parameters. So I am trying to figure out how to define the getitem special method in my class to handle both plain indexes and slicing.  def __getitem__(self, start, stop, step):     index = start     if stop == None:         end = start + 1     else:         end = stop     if step == None:         stride = 1     else:         stride = step     return self.__data[index:end:stride]      ","Q_Votes":"81"},{"Q_Title":"Python: Implementing slicing in __getitem__","A_Content":"  The correct way to do this is to have __getitem__ take one parameter, which can either be a number, or a slice object.  See:  http://docs.python.org/library/functions.html#slice  http://docs.python.org/reference/datamodel.html#object.__getitem__     ","Language":"Python","Tags":["python","slice","python-datamodel"],"URL":"https://stackoverflow.com/questions/2936863/python-implementing-slicing-in-getitem","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to implement slice functionality for a class I am making that creates a vector representation.  I have this code so far, which I believe will properly implement the slice but whenever I do a call like v[4] where v is a vector python returns an error about not having enough parameters. So I am trying to figure out how to define the getitem special method in my class to handle both plain indexes and slicing.  def __getitem__(self, start, stop, step):     index = start     if stop == None:         end = start + 1     else:         end = stop     if step == None:         stride = 1     else:         stride = step     return self.__data[index:end:stride]      ","Q_Votes":"81"},{"Q_Title":"Python: Implementing slicing in __getitem__","A_Content":"  To extend Aaron's answer, for things like numpy, you can do multi-dimensional slicing by checking to see if given is a tuple:  class Sliceable(object):     def __getitem__(self, given):         if isinstance(given, slice):             # do your handling for a slice object:             print(\"slice\", given.start, given.stop, given.step)         elif isinstance(given, tuple):             print(\"multidim\", given)         else:             # Do your handling for a plain index             print(\"plain\", given)  sliceme = Sliceable() sliceme[1] sliceme[::] sliceme[1:, ::2]   ```  Output:  ('plain', 1) ('slice', None, None, None) ('multidim', (slice(1, None, None), slice(None, None, 2)))      ","Language":"Python","Tags":["python","slice","python-datamodel"],"URL":"https://stackoverflow.com/questions/2936863/python-implementing-slicing-in-getitem","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to implement slice functionality for a class I am making that creates a vector representation.  I have this code so far, which I believe will properly implement the slice but whenever I do a call like v[4] where v is a vector python returns an error about not having enough parameters. So I am trying to figure out how to define the getitem special method in my class to handle both plain indexes and slicing.  def __getitem__(self, start, stop, step):     index = start     if stop == None:         end = start + 1     else:         end = stop     if step == None:         stride = 1     else:         stride = step     return self.__data[index:end:stride]      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  In [1]: import numpy as np  In [2]: a = np.array([[1, 2, 3], [4, 5, 6]])  In [3]: b = np.array([[9, 8, 7], [6, 5, 4]])  In [4]: np.concatenate((a, b)) Out[4]:  array([[1, 2, 3],        [4, 5, 6],        [9, 8, 7],        [6, 5, 4]])   or this:  In [1]: a = np.array([1, 2, 3])  In [2]: b = np.array([4, 5, 6])  In [3]: np.vstack((a, b)) Out[3]:  array([[1, 2, 3],        [4, 5, 6]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"109","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  Well, the error message says it all:  NumPy arrays do not have an append() method.  There's a free function numpy.append() however:  numpy.append(M, a)   This will create a new array instead of mutating M in place.  Note that using numpy.append() involves copying both arrays.  You will get better performing code if you use fixed-sized NumPy arrays.     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  You may use numpy.append()...   import numpy  B = numpy.array([3]) A = numpy.array([1, 2, 2]) B = numpy.append( B , A )  print B  > [3 1 2 2]   This will not create two separate arrays but will append two arrays into a single dimensional array.     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  Sven said it all, just be very cautious because of automatic type adjustments when append is called.  In [2]: import numpy as np  In [3]: a = np.array([1,2,3])  In [4]: b = np.array([1.,2.,3.])  In [5]: c = np.array(['a','b','c'])  In [6]: np.append(a,b) Out[6]: array([ 1.,  2.,  3.,  1.,  2.,  3.])  In [7]: a.dtype Out[7]: dtype('int64')  In [8]: np.append(a,c) Out[8]:  array(['1', '2', '3', 'a', 'b', 'c'],        dtype='|S1')   As you see based on the contents the dtype went from int64 to float32, and then to S1     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  Actually one can always create an ordinary list of numpy arrays and convert it later.  In [1]: import numpy as np  In [2]: a = np.array([[1,2],[3,4]])  In [3]: b = np.array([[1,2],[3,4]])  In [4]: l = [a]  In [5]: l.append(b)  In [6]: l = np.array(l)  In [7]: l.shape Out[7]: (2, 2, 2)  In [8]: l Out[8]:  array([[[1, 2],         [3, 4]],         [[1, 2],         [3, 4]]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Append a NumPy array to a NumPy array","A_Content":"  If I understand your question, here's one way.  Say you have:  a = [4.1, 6.21, 1.0]   so here's some code...   def array_in_array(scalarlist):     return [(x,) for x in scalarlist]   Which leads to:   In [72]: a = [4.1, 6.21, 1.0]  In [73]: a Out[73]: [4.1, 6.21, 1.0]  In [74]: def array_in_array(scalarlist):    ....:     return [(x,) for x in scalarlist]    ....:   In [75]: b = array_in_array(a)  In [76]: b Out[76]: [(4.1,), (6.21,), (1.0,)]      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a numpy_array. Something like [ a b c ].  And then I want to append it into another NumPy array (just like we create a list of lists). How do we create an array of NumPy arrays containing NumPy arrays?  I tried to do the following without any luck  >>> M = np.array([]) >>> M array([], dtype=float64) >>> M.append(a,axis=0) Traceback (most recent call last):  File \"<stdin>\", line 1, in <module> AttributeError: 'numpy.ndarray' object has no attribute 'append' >>> a array([1, 2, 3])      ","Q_Votes":"81"},{"Q_Title":"Finding last occurrence of substring in string, replacing that","A_Content":"  This should do it  old_string = \"this is going to have a full stop. some written sstuff!\" k = old_string.rfind(\".\") new_string = old_string[:k] + \". - \" + old_string[k+1:]      ","Language":"Python","Tags":["python","string","parsing"],"URL":"https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that","A_Votes":"129","_type":"dict","isAccepted":"Yes","Q_Content":"    So I have a long list of strings in the same format, and I want to find the last \".\" character in each one, and replace it with \". - \". I've tried using rfind, but I can't seem to utilize it properly to do this.     ","Q_Votes":"81"},{"Q_Title":"Finding last occurrence of substring in string, replacing that","A_Content":"  To replace from the right:  def replace_right(source, target, replacement, replacements=None):     return replacement.join(source.rsplit(target, replacements))   In use:  >>> replace_right(\"asd.asd.asd.\", \".\", \". -\", 1) 'asd.asd.asd. -'      ","Language":"Python","Tags":["python","string","parsing"],"URL":"https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    So I have a long list of strings in the same format, and I want to find the last \".\" character in each one, and replace it with \". - \". I've tried using rfind, but I can't seem to utilize it properly to do this.     ","Q_Votes":"81"},{"Q_Title":"Finding last occurrence of substring in string, replacing that","A_Content":"  I would use a regex:  import re new_list = [re.sub(r\"\\.(?=[^.]*$)\", r\". - \", s) for s in old_list]      ","Language":"Python","Tags":["python","string","parsing"],"URL":"https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    So I have a long list of strings in the same format, and I want to find the last \".\" character in each one, and replace it with \". - \". I've tried using rfind, but I can't seem to utilize it properly to do this.     ","Q_Votes":"81"},{"Q_Title":"Finding last occurrence of substring in string, replacing that","A_Content":"  A one liner would be :    str=str[::-1].replace(\".\",\".-\",1)[::-1]     ","Language":"Python","Tags":["python","string","parsing"],"URL":"https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    So I have a long list of strings in the same format, and I want to find the last \".\" character in each one, and replace it with \". - \". I've tried using rfind, but I can't seem to utilize it properly to do this.     ","Q_Votes":"81"},{"Q_Title":"Finding last occurrence of substring in string, replacing that","A_Content":"  Nave approach:  a = \"A long string with a . in the middle ending with .\" fchar = '.' rchar = '. -' a[::-1].replace(fchar, rchar[::-1], 1)[::-1]  Out[2]: 'A long string with a . in the middle ending with . -'     Aditya Sihag's answer with a single rfind:  pos = a.rfind('.') a[:pos] + '. -' + a[pos+1:]      ","Language":"Python","Tags":["python","string","parsing"],"URL":"https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    So I have a long list of strings in the same format, and I want to find the last \".\" character in each one, and replace it with \". - \". I've tried using rfind, but I can't seem to utilize it properly to do this.     ","Q_Votes":"81"},{"Q_Title":"How can I add items to an empty set in python","A_Content":"  D = {}  is a dictionary not set.  >>> d = {} >>> type(d) <type 'dict'>   Use  D =  set():  >>> d = set() >>> type(d) <type 'set'> >>> d.update({1}) >>> d.add(2) >>> d.update([3,3,3]) >>> d set([1, 2, 3])      ","Language":"Python","Tags":["python","set"],"URL":"https://stackoverflow.com/questions/17511270/how-can-i-add-items-to-an-empty-set-in-python","A_Votes":"154","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following procedure:  def myProc(invIndex, keyWord):     D={}     for i in range(len(keyWord)):         if keyWord[i] in invIndex.keys():                     D.update(invIndex[query[i]])     return D   But I am getting the following error:  Traceback (most recent call last):   File \"<stdin>\", line 3, in <module> TypeError: cannot convert dictionary update sequence element #0 to a sequence   I do not get any error if D contains elements. But I need D to be empty at the beginning.     ","Q_Votes":"81"},{"Q_Title":"How can I add items to an empty set in python","A_Content":"  >>> d = {} >>> D = set() >>> type(d) <type 'dict'> >>> type(D) <type 'set'>   What you've made is a dictionary and not a Set.  The update method in dictionary is used to update the new dictionary from a previous one, like so,  >>> abc = {1: 2} >>> d.update(abc) >>> d {1: 2}   Whereas in sets, it is used to add elements to the set.  >>> D.update([1, 2]) >>> D set([1, 2])      ","Language":"Python","Tags":["python","set"],"URL":"https://stackoverflow.com/questions/17511270/how-can-i-add-items-to-an-empty-set-in-python","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have the following procedure:  def myProc(invIndex, keyWord):     D={}     for i in range(len(keyWord)):         if keyWord[i] in invIndex.keys():                     D.update(invIndex[query[i]])     return D   But I am getting the following error:  Traceback (most recent call last):   File \"<stdin>\", line 3, in <module> TypeError: cannot convert dictionary update sequence element #0 to a sequence   I do not get any error if D contains elements. But I need D to be empty at the beginning.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"   Shell scripting has simpler notations for I/O redirection. It is simpler to create pipelines out of existing programs in shell. Shell scripting reuses entire programs. Shell is universally available (on anything like Unix) - Python is not necessarily installed.   'Tis true that you can do everything in Python that you can do in shell; 'tis also true that there are things that are easy in Python that are hard in shell (just as there are things that are easy in shell but hard in Python).  Knowing both will be best in the long term.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"72","_type":"dict","isAccepted":"Yes","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  \"What are strengths of shell scripting that make it an indispensable tool as compared to Python?\"  The shell is not indispensable.  Why do you think there are so many?  bash, tcsh, csh, sh, etc., etc.,   Python is a shell.  Not the one you'd use for running all commands, but for scripting, it's ideal.  Python is a more-or-less standard part of all Linux distro's.  The more traditional shells do too many things.   They have a handy user interface for running commands.  This includes one-line commands where the shell searches your PATH, forks and execs the requested program.  It also includes pipelines, sequences and concurrent programs (using ;, | and &) as well as some redirection (using > and <). They have a crummy little programming-language-like capability for running scripts.  This language is rather hard to use and extremely inefficient.  Most statements in this language require forking one or more additional processes, wasting time and memory.   Running programs from the shell, redirecting stderr to a log file and that kind of thing is good.  Do that in the shell.  Almost everything else can be done more efficiently and more clearly as a Python script.  You need both.  However, you should never write a script with if-statements or loops in a traditional shell language.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"50","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  The shell makes common and simple actions really simple, at the expense of making more complex things much much more complex.  Typically, a small shell script will be shorter and simpler than the corresponding python program, but the python program will tend to gracefully accept modifications, whereas the shell script will tend to get less and less maintainable as code is added.  This has the consequence that for optimal day-to-day productivity you need shell-scripting, but you should use it mostly for throwaway scripts, and use python everywhere else.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  There's nothing you can do with shell scripts that you can't do with python.  The big advantage of shell scripts is that you use the same commands as you do when you use the shell, so if you're a heavy shell user, shell scripting will at some point become a very quick and easy way to automate your shell work.  I also find it easier to deal with pipes of data in shell scripts than in python, though it's absolutely doable from python.  And, finally, you don't have to fire up an additional interpeter to run the shell scripts,  giving you a very small, but sometimes maybe noticeable speed and memory usage advantage.  But then again, Python scripts are a lot more maintainable, I'm trying to migrate from big ugly shell scripts to Python scripts for that very reason. It's also easier to do exception handling and QA with Python.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  one doesn't have to learn shell scripting, as all the previous answers indicate; but learning is never a bad thing. it's really a question of personal priorities. it's very hard for someone else to tell you what is and isn't worth your time.  most programmers find that learning new languages gets incrementally easier each time. (the same is largely true of natural languages too.) and the earlier you start, the better.  plus: having learned a language enables you to extravagantly diss its limitations from a position of complete knowledge and familiarity. this probably won't get you laid, but might earn you a beer from your peers!     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  I agree with most of the previous answers. I consider shell commands most suited to do filesystem-oriented tasks (copy and move files, grep, etc). Shell is better, in my opinion, if you have to read and write to file, since a single >>file.txt redirection appends to file instantly, instead of needing, say, file=open('file.txt','a'); file.write(), etc.  Currently, for my personal use, I mix both, creating a python script and calling os.system('command') or os.popen('command') every time some action is easier in shell than in python.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  The shell is available everywhere. If you stick to a relatively basic set of portable functionality, your scripts can run on cell phones, wireless routers, DVRs, netbooks, workstations, big iron servers, and the like. Python is not necessarily included out of the box on lots of systems, and depending on the environment it may be hard to get it installed.  Learning some shell scripting can also help you learn some command line tricks, since the command line is, well, the shell. It's also good for taking some fairly long and complicated command line, and converting that into a more general script after you realize you'll need it some more.  The shell also has some pretty powerful features; pipelines are a really interesting control construct that is native only to the shell, as far as I know.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Strengths of Shell Scripting compared to Python [closed]","A_Content":"  Another thing to consider when choosing shell scripts of Python is the Python version that will be running on the target machines. RHEL5 (to name one) is going to be around for a long time. RHEL5 is stuck with Python 2.4. There are a lot of nice libraries that depend on functionality added to Python post-2.4.     ","Language":"Python","Tags":["python","shell"],"URL":"https://stackoverflow.com/questions/796319/strengths-of-shell-scripting-compared-to-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I tried to learn shell(bash) scripting few times but was driven away by the syntax. Then I found Python and was able to do most of the things a shell script can do in Python. I am now not sure whether I should invest my time in learning shell scripting anymore. So I want to ask:  What are strengths of shell scripting that make it an indispensable tool as compared to Python?  I am not a system administration by profession, but I am interested in setting up Linux systems for home users, hence I think learning shell scripting can become necessary.     ","Q_Votes":"81"},{"Q_Title":"Tool to convert Python code to be PEP8 compliant","A_Content":"  Unfortunately \"pep8 storming\" (the entire project) has several negative side-effects:   lots of merge-conflicts break git blame make code review difficult   As an alternative (and thanks to @y-p for the idea), I wrote a small package which autopep8s only those lines which you have been working on since the last commit/branch:  Basically leaving the project a little better than you found it:  pip install pep8radius   Suppose you've done your work off of master and are ready to commit:  # be somewhere in your project directory # see the diff with pep, see the changes you've made since master pep8radius master --diff #make those changes pep8radius master --diff --in-place   Or to clean the new lines you've commited since the last commit:  pep8radius --diff pep8radius --diff --in-place  # the lines which changed since a specific commit `git diff 98f51f` pep8radius 98f51f --diff   Basically pep8radius is applying autopep8 to lines in the output of git/hg diff (from the last shared commit).  This script currently works with git and hg, if your using something else and want this to work please post a comment/issue/PR!     ","Language":"Python","Tags":["python","coding-style","pep8"],"URL":"https://stackoverflow.com/questions/14328406/tool-to-convert-python-code-to-be-pep8-compliant","A_Votes":"27","_type":"dict","isAccepted":"Yes","Q_Content":"    I know there are tools which validate whether your Python code is compliant with PEP8,  for example there is both an online service and a python module.  However, I cannot find a service or module which can convert my Python file to a self-contained, PEP8 valid Python file. Does anyone know if there are any? I assume it's feasible since PEP8 is all about the appearance of the code, right?     ","Q_Votes":"81"},{"Q_Title":"Tool to convert Python code to be PEP8 compliant","A_Content":"  You can use autopep8! Whilst you make yourself a cup of coffee this tool happily removes all those pesky PEP8 violations which don't change the meaning of the code.  Install it via pip:  pip install autopep8   Apply this to a specific file:  autopep8 py_file --in-place   or to your project (recursively), the verbose option gives you some feedback of how it's going:  autopep8 project_dir --recursive --in-place --pep8-passes 2000 --verbose   Note: Sometimes the default of 100 passes isn't enough, I set it to 2000 as it's reasonably high and will catch all but the most troublesome files (it stops passing once it finds no resolvable pep8 infractions)...  At this point I suggest retesting and doing a commit!  If you want \"full\" PEP8 compliance: one tactic I've used is to run autopep8 as above, then run PEP8, which prints the remaining violations (file, line number, and what):  pep8 project_dir --ignore=E501   and manually change these individually (e.g. E712s - comparison with boolean).  Note: autopep8 offers an --aggressive argument (to ruthlessly \"fix\" these meaning-changing violations), but beware if you do use aggressive you may have to debug... (e.g. in numpy/pandas True == np.bool_(True) but not True is np.bool_(True)!)  You can check how many violations of each type (before and after):  pep8 --quiet --statistics .   Note: I consider E501s (line too long) are a special case as there will probably be a lot of these in your code and sometimes these are not corrected by autopep8.  As an example, I applied this technique to the pandas code base.     ","Language":"Python","Tags":["python","coding-style","pep8"],"URL":"https://stackoverflow.com/questions/14328406/tool-to-convert-python-code-to-be-pep8-compliant","A_Votes":"148","_type":"dict","isAccepted":"No","Q_Content":"    I know there are tools which validate whether your Python code is compliant with PEP8,  for example there is both an online service and a python module.  However, I cannot find a service or module which can convert my Python file to a self-contained, PEP8 valid Python file. Does anyone know if there are any? I assume it's feasible since PEP8 is all about the appearance of the code, right?     ","Q_Votes":"81"},{"Q_Title":"Tool to convert Python code to be PEP8 compliant","A_Content":"  @Andy Hayden gave good overview of autopep8. In addition to that there is one more package called pep8ify which also does the same thing.  However both packages can remove only lint errors but they cannot format code.  little = more[3:   5]   Above code remains same after pep8ifying also. But the code doesn't look good yet. You can use formatters like yapf, which will format the code even if the code is PEP8 compliant.  Above code will be formatted to   little = more[3:5]   Some times this even destroys Your manual formatting. For example   BAZ = {     [1, 2, 3, 4],     [5, 6, 7, 8],     [9, 10, 11, 12] }   will be converted to   BAZ = {[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]}   But You can tell it to ignore some parts.  BAZ = {    [1, 2, 3, 4],    [5, 6, 7, 8],    [9, 10, 11, 12] }  # yapf: disable   Taken from my  old blog post: Automatically PEP8 & Format Your Python Code!     ","Language":"Python","Tags":["python","coding-style","pep8"],"URL":"https://stackoverflow.com/questions/14328406/tool-to-convert-python-code-to-be-pep8-compliant","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I know there are tools which validate whether your Python code is compliant with PEP8,  for example there is both an online service and a python module.  However, I cannot find a service or module which can convert my Python file to a self-contained, PEP8 valid Python file. Does anyone know if there are any? I assume it's feasible since PEP8 is all about the appearance of the code, right?     ","Q_Votes":"81"},{"Q_Title":"Tool to convert Python code to be PEP8 compliant","A_Content":"  If you're using eclipse + PyDev you can simply activate autopep8 from PyDev's settings:  Windows -> Preferences -> type 'autopep8' in the search filter.  Check the 'use autopep8.py for code formatting?' -> OK  Now eclipse's CTRL-SHIFT-F code formatting should format your code using autopep8 :)       ","Language":"Python","Tags":["python","coding-style","pep8"],"URL":"https://stackoverflow.com/questions/14328406/tool-to-convert-python-code-to-be-pep8-compliant","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I know there are tools which validate whether your Python code is compliant with PEP8,  for example there is both an online service and a python module.  However, I cannot find a service or module which can convert my Python file to a self-contained, PEP8 valid Python file. Does anyone know if there are any? I assume it's feasible since PEP8 is all about the appearance of the code, right?     ","Q_Votes":"81"},{"Q_Title":"Tool to convert Python code to be PEP8 compliant","A_Content":"  There is many.  IDEs usually have some formatting capability built in. IntelliJ Idea / PyCharm does, same goes for Python plugin for Eclipse, and so on.  There are formatters/linters that can target multiple languages. https://coala.io is a good example of those.  Then there are the single purpose tools, of which many are mentioned in other answers.     ","Language":"Python","Tags":["python","coding-style","pep8"],"URL":"https://stackoverflow.com/questions/14328406/tool-to-convert-python-code-to-be-pep8-compliant","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I know there are tools which validate whether your Python code is compliant with PEP8,  for example there is both an online service and a python module.  However, I cannot find a service or module which can convert my Python file to a self-contained, PEP8 valid Python file. Does anyone know if there are any? I assume it's feasible since PEP8 is all about the appearance of the code, right?     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  In principle it shouldn't run out of memory, but there are currently memory problems with read_csv on large files caused by some complex Python internal issues (this is vague but it's been known for a long time: http://github.com/pydata/pandas/issues/407).   At the moment there isn't a perfect solution (here's a tedious one: you could transcribe the file row-by-row into a pre-allocated NumPy array or memory-mapped file--np.mmap), but it's one I'll be working on in the near future. Another solution is to read the file in smaller pieces (use iterator=True, chunksize=1000) then concatenate then with pd.concat. The problem comes in when you pull the entire text file into memory in one big slurp.     ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"71","_type":"dict","isAccepted":"Yes","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  Wes is of course right! I'm just chiming in to provide a little more complete example code. I had the same issue with a 129 Mb file, which was solved by:  from pandas import *  tp = read_csv('large_dataset.csv', iterator=True, chunksize=1000)  # gives TextFileReader, which is iterable with chunks of 1000 rows. df = concat(tp, ignore_index=True)  # df is DataFrame. If errors, do `list(tp)` instead of `tp`      ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"72","_type":"dict","isAccepted":"No","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  This is an older thread, but I just wanted to dump my workaround solution here. I initially tried the chunksize parameter (even with quite small values like 10000), but it didn't help much; had still technical issues with the memory size (my CSV was ~ 7.5 Gb).   Right now, I just read chunks of the CSV files in a for-loop approach and add them e.g., to an SQLite database step by step:  import pandas as pd import sqlite3 from pandas.io import sql import subprocess  # In and output file paths in_csv = '../data/my_large.csv' out_sqlite = '../data/my.sqlite'  table_name = 'my_table' # name for the SQLite database table chunksize = 100000 # number of lines to process at each iteration  # columns that should be read from the CSV file columns = ['molecule_id','charge','db','drugsnow','hba','hbd','loc','nrb','smiles']  # Get number of lines in the CSV file nlines = subprocess.check_output('wc -l %s' % in_csv, shell=True) nlines = int(nlines.split()[0])   # connect to database cnx = sqlite3.connect(out_sqlite)  # Iteratively read CSV and dump lines into the SQLite table for i in range(0, nlines, chunksize):      df = pd.read_csv(in_csv,               header=None,  # no header, define column header manually later             nrows=chunksize, # number of rows to read at each iteration             skiprows=i)   # skip rows that were already read      # columns to read             df.columns = columns      sql.to_sql(df,                  name=table_name,                  con=cnx,                  index=False, # don't use CSV file index                 index_label='molecule_id', # use a unique column from DataFrame as index                 if_exists='append')  cnx.close()          ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  If you want to load huge csv files, dask might be a good option. It mimics the pandas api, so it feels quite similar to pandas  link to dask on github     ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  Below is my working flow.   import sqlalchemy as sa import pandas as pd import psycopg2  count = 0 con = sa.create_engine('postgresql://postgres:pwd@localhost:00001/r') #con = sa.create_engine('sqlite:///XXXXX.db') SQLite chunks = pd.read_csv('..file', chunksize=10000, encoding=\"ISO-8859-1\",                      sep=',', error_bad_lines=False, index_col=False, dtype='unicode')   Base on your file size, you'd better optimized the chunksize.     for chunk in chunks:         chunk.to_sql(name='Table', if_exists='append', con=con)         count += 1         print(count)   After have all data in Database, You can query out those you need from database.      ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Large, persistent DataFrame in pandas","A_Content":"  You can use Pytable rather than pandas df. It is designed for large data sets and the file format is in hdf5. So the processing time is relatively fast.     ","Language":"Python","Tags":["python","pandas","sas"],"URL":"https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am exploring switching to python and pandas as a long-time SAS user.    However, when running some tests today, I was surprised that python ran out of memory when trying to pandas.read_csv() a 128mb csv file.  It had about 200,000 rows and 200 columns of mostly numeric data.  With SAS, I can import a csv file into a SAS dataset and it can be as large as my hard drive.   Is there something analogous in pandas?   I regularly work with large files and do not have access to a distributed computing network.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  AFAIK, Orange may be the best choice at the moment. PyML is good too. PyMC for Bayesian estimation. and, there is a Book \"Machine Learning: An Algorithmic Perspective\", There are lots of Python code examples in the book, maybe it is worth reading. and there is a blog post: Pragmatic Classification with Python. Just my two cents.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"44","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  There is also scikit-learn (BSD, with only dependencies on numpy & scipy). It includes various supervised learning algorithms such as:   SVM based on libsvm and linear with scipy.sparse bindings for wide features datasets bayesian methods HMMs L1 and L1+L2 regularized regression methods aka Lasso and Elastic Net models implemented with algorithms such as LARS and coordinate descent   It also features unsupervised clustering algorithms such as:   kmeans++ meanshift affinity propagation spectral clustering   And also other tools such as:   feature extractors for text content (token and char ngrams + hashing vectorizer) univariate feature selections a simple pipe line tool numerous implementations of cross validation strategies performance metrics evaluation and ploting (ROC curve, AUC, confusion matrix, ...) a grid search utility to perform hyper-parameters tuning using parallel cross validation integration with joblib for caching partial results when working in interactive environment (e.g. using ipython)   Each algorithm implementation comes with sample programs demonstrating its usage either on toy data or real life datasets.  Also, the official source repository is hosted on github so please feel free to contribute bugfixes and improvement using the regular pull request feature for interactive code review.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"99","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  A general user friendly package is Orange -- kind of like Weka or RapidMiner, if you're familiar with those.  Other than that, there's a variety of packages and toolkits for various tasks.  You should consult the Python packages listed on mloss as a starting point.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  You might want to look at:  http://www.shogun-toolbox.org/, which has interfaces for multiple languages, including python. There's also http://www.pybrain.org/, which is (I believe) a native implementation of ML algorithms. Hope that helps.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  For Support Vector Machines, take a look at LibSVM which among others, have Python interface.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  Deep Learning Tutorials describe how to develop and train deep neural networks. The used library even use Nvidia GPU if available.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  Probably related questions at Stack Overflow:  Artificial Inteligence library in python.  What is the best artificial-intelligence library for Python?     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  I gave Orange a try.  It's powerful, but if you go through the documentation, you would realize that the author has his own crazy style of writing Python. His code does get pretty cryptic if you are relatively new to Python so I wouldn't recommend Orange unless you are familiar with Python.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  http://www.pymvpa.org might work as well.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  I'm not sure you'd exactly call this machine learning, but the nltk package does Bayesian-style classification of text. You can use learning data and test data to see that it is inferring rules about the data.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  This is a great list done by SciPy, of many well-known Python packages, among others, machine learning related: Artificial intelligence & machine learning     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  If you are looking for neural network, python binding for fann is quite easy to use,and come with tools to train your networks     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  Take a look at the Modular toolkit for Data Processing (MDP). It implements a couple of algorithms from machine learning and statistics and it's mature and well documented.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Is there a recommended package for machine learning in Python? [closed]","A_Content":"  SVMlight is sometimes a handy alternative to LibSVM! LibSVM is also fantastic, though.     ","Language":"Python","Tags":["python","machine-learning"],"URL":"https://stackoverflow.com/questions/1289920/is-there-a-recommended-package-for-machine-learning-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a recommended package for machine learning in Python?  I have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.     ","Q_Votes":"81"},{"Q_Title":"Enable access control on simple HTTP server","A_Content":"  Unfortunately, the simple HTTP server is really that simple that it does not allow any customization, especially not for the headers it sends. You can however create a simple HTTP server yourself, using most of SimpleHTTPRequestHandler, and just add that desired header.  For that, simply create a file simple-cors-http-server.py (or whatever) and, depending on the Python version you are using, put one of the following codes inside.  Then you can do python simple-cors-http-server.py and it will launch your modified server which will set the CORS header for every response.  With the shebang at the top, make the file executable and put it into your PATH, and you can just run it using simple-cors-http-server.py too.  Python 3 solution  Python 3 uses SimpleHTTPRequestHandler and HTTPServer from the http.server module to run the server:  #!/usr/bin/env python3 from http.server import HTTPServer, SimpleHTTPRequestHandler, test import sys  class CORSRequestHandler (SimpleHTTPRequestHandler):     def end_headers (self):         self.send_header('Access-Control-Allow-Origin', '*')         SimpleHTTPRequestHandler.end_headers(self)  if __name__ == '__main__':     test(CORSRequestHandler, HTTPServer, port=int(sys.argv[1]) if len(sys.argv) > 1 else 8000)   Python 2 solution  Python 2 uses SimpleHTTPServer.SimpleHTTPRequestHandler and the BaseHTTPServer module to run the server.  #!/usr/bin/env python2 from SimpleHTTPServer import SimpleHTTPRequestHandler import BaseHTTPServer  class CORSRequestHandler (SimpleHTTPRequestHandler):     def end_headers (self):         self.send_header('Access-Control-Allow-Origin', '*')         SimpleHTTPRequestHandler.end_headers(self)  if __name__ == '__main__':     BaseHTTPServer.test(CORSRequestHandler, BaseHTTPServer.HTTPServer)   Python 2 & 3 solution  If you need compatibility for both Python 3 and Python 2, you could use this polyglot script that works in both versions. It first tries to import from the Python 3 locations, and otherwise falls back to Python 2:  #!/usr/bin/env python try:     # Python 3     from http.server import HTTPServer, SimpleHTTPRequestHandler, test as test_orig     import sys     def test (*args):         test_orig(*args, port=int(sys.argv[1]) if len(sys.argv) > 1 else 8000) except ImportError: # Python 2     from BaseHTTPServer import HTTPServer, test     from SimpleHTTPServer import SimpleHTTPRequestHandler  class CORSRequestHandler (SimpleHTTPRequestHandler):     def end_headers (self):         self.send_header('Access-Control-Allow-Origin', '*')         SimpleHTTPRequestHandler.end_headers(self)  if __name__ == '__main__':     test(CORSRequestHandler, HTTPServer)      ","Language":"Python","Tags":["python","cors","simplehttpserver"],"URL":"https://stackoverflow.com/questions/21956683/enable-access-control-on-simple-http-server","A_Votes":"129","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following shell script for a very simple HTTP server:  #!/bin/sh  echo \"Serving at http://localhost:3000\" python -m SimpleHTTPServer 3000   I was wondering how I can enable or add a CORS header like Access-Control-Allow-Origin: * to this server?     ","Q_Votes":"81"},{"Q_Title":"Enable access control on simple HTTP server","A_Content":"  Try an alternative like http-server  As SimpleHTTPServer is not really the kind of server you deploy to production, I'm assuming here that you don't care that much about which tool you use as long as it does the job of exposing your files at http://localhost:3000 with CORS headers in a simple command line  # install (it requires nodejs/npm) npm install http-server -g  #run http-server -p 3000 --cors     Some related tools you might find useful   ngrok: when running ngrok http 3000, it creates an url https://$random.ngrok.com that permits anyone to access your http://localhost:3000 server. It can expose to the world what runs locally on your computer (including local backends/apis) localtunnel: almost the same as ngrok now: when running now, it uploads your static assets online and deploy them to https://$random.now.sh. They remain online forever unless you decide otherwise. Deployment is fast (except the first one) thanks to diffing. Now is suitable for production frontend/SPA code deployment It can also deploy Docker and NodeJS apps. It is not really free, but they have a free plan.      ","Language":"Python","Tags":["python","cors","simplehttpserver"],"URL":"https://stackoverflow.com/questions/21956683/enable-access-control-on-simple-http-server","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"    I have the following shell script for a very simple HTTP server:  #!/bin/sh  echo \"Serving at http://localhost:3000\" python -m SimpleHTTPServer 3000   I was wondering how I can enable or add a CORS header like Access-Control-Allow-Origin: * to this server?     ","Q_Votes":"81"},{"Q_Title":"Enable access control on simple HTTP server","A_Content":"  You'll need to provide your own instances of do_GET() (and do_HEAD() if choose to support HEAD operations). something like this:  class MyHTTPServer(SimpleHTTPServer):      allowed_hosts = (('127.0.0.1', 80),)      def do_GET(self):         if self.client_address not in allowed_hosts:             self.send_response(401, 'request not allowed')         else:             super(MyHTTPServer, self).do_Get()      ","Language":"Python","Tags":["python","cors","simplehttpserver"],"URL":"https://stackoverflow.com/questions/21956683/enable-access-control-on-simple-http-server","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have the following shell script for a very simple HTTP server:  #!/bin/sh  echo \"Serving at http://localhost:3000\" python -m SimpleHTTPServer 3000   I was wondering how I can enable or add a CORS header like Access-Control-Allow-Origin: * to this server?     ","Q_Votes":"81"},{"Q_Title":"How do I create a Python function with optional arguments?","A_Content":"  Try calling it like: obj.some_function( '1', 2, '3', g=\"foo\", h=\"bar\" ). After the required positional arguments, you can specify specific optional arguments by name.     ","Language":"Python","Tags":["python","function","arguments","optional-arguments"],"URL":"https://stackoverflow.com/questions/9539921/how-do-i-create-a-python-function-with-optional-arguments","A_Votes":"84","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a Python function which takes several arguments. Some of these arguments could be omitted in some scenarios.  def some_function (self, a, b, c, d = None, e = None, f = None, g = None, h = None):     #code   The arguments d through h are strings which each have different meanings. It is important that I can choose which optional parameters to pass in any combination. For example, (a, b, C, d, e), or (a, b, C, g, h), or (a, b, C, d, e, f, or all of them (these are my choices).   It would be great if I could overload the function - but I read that Python does not support overloading. I tried to insert some of the required int arguments in the list - and got an argument mismatch error.  Right now I am sending empty strings in place of the first few missing arguments as placeholders. I would like to be able to call a function just using actual values.  Is there any way to do this? Could I pass a list instead of the argument list?  Right now the prototype using ctypes looks something like:  _fdll.some_function.argtypes = [c_void_p, c_char_p, c_int, c_char_p, c_char_p, c_char_p, c_char_p, c_char_p]      ","Q_Votes":"81"},{"Q_Title":"How do I create a Python function with optional arguments?","A_Content":"  Just use the *args parameter, which allows you to pass as many arguments as you want after your  a,b,c.  You would have to add some logic to map args->c,d,e,f but its a \"way\" of overloading.  def myfunc(a,b, *args, **kwargs):    for ar in args:       print ar myfunc(a,b,c,d,e,f)   And it will print c,d,e,f    Similarly you could use the kwargs argument and then you could name your parameters.  def myfunc(a,b, *args, **kwargs):       c = kwargs.get('c', None)       d = kwargs.get('d', None)       #etc myfunc(a,b, c='nick', d='dog', ...)   And then kwargs would have a dictionary of all the parameters that are key valued after a,b     ","Language":"Python","Tags":["python","function","arguments","optional-arguments"],"URL":"https://stackoverflow.com/questions/9539921/how-do-i-create-a-python-function-with-optional-arguments","A_Votes":"110","_type":"dict","isAccepted":"No","Q_Content":"    I have a Python function which takes several arguments. Some of these arguments could be omitted in some scenarios.  def some_function (self, a, b, c, d = None, e = None, f = None, g = None, h = None):     #code   The arguments d through h are strings which each have different meanings. It is important that I can choose which optional parameters to pass in any combination. For example, (a, b, C, d, e), or (a, b, C, g, h), or (a, b, C, d, e, f, or all of them (these are my choices).   It would be great if I could overload the function - but I read that Python does not support overloading. I tried to insert some of the required int arguments in the list - and got an argument mismatch error.  Right now I am sending empty strings in place of the first few missing arguments as placeholders. I would like to be able to call a function just using actual values.  Is there any way to do this? Could I pass a list instead of the argument list?  Right now the prototype using ctypes looks something like:  _fdll.some_function.argtypes = [c_void_p, c_char_p, c_int, c_char_p, c_char_p, c_char_p, c_char_p, c_char_p]      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  You can use {{ variable }} anywhere in your template, not just in the HTML part. So this should work:  <html> <head>   <script>     var someJavaScriptVar = '{{ geocode[1] }}';   </script> </head> <body>   <p>Hello World</p>   <button onclick=\"alert('Geocode: {{ geocode[0] }} ' + someJavaScriptVar)\" /> </body> </html>   Think of it as a two-stage process: First, Jinja (the template engine Flask uses) generates your text output. This gets sent to the user who executes the JavaScript he sees. If you want your Flask variable to be available in JavaScript as an array, you have to generate an array definition in your output:  <html>   <head>     <script>       var myGeocode = ['{{ geocode[0] }}', '{{ geocode[1] }}'];     </script>   </head>   <body>     <p>Hello World</p>     <button onclick=\"alert('Geocode: ' + myGeocode[0] + ' ' + myGeocode[1])\" />   </body> </html>   Jinja also offers more advanced constructs from Python, so you can shorten it to:  <html> <head>   <script>     var myGeocode = [{{ ', '.join(geocode) }}];   </script> </head> <body>   <p>Hello World</p>   <button onclick=\"alert('Geocode: ' + myGeocode[0] + ' ' + myGeocode[1])\" /> </body> </html>   You can also use for loops, if statements and many more, see the Jinja2 documentation for more.   Also have a look at ford's answer who points out the tojson filter which is an addition to Jinja2's standard set of filters.     ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  The ideal way to go about getting pretty much any Python object into a JavaScript object is to use JSON. JSON is great as a format for transfer between systems, but sometimes we forget that it stands for JavaScript Object Notation. This means that injecting JSON into the template is the same as injecting JavaScript code that describes the object.  Flask provides a Jinja filter for this: tojson dumps the structure to a JSON string and marks it safe so that Jinja does not autoescape it.  <html>   <head>     <script>       var myGeocode = {{ geocode|tojson }};     </script>   </head>   <body>     <p>Hello World</p>     <button onclick=\"alert('Geocode: ' + myGeocode[0] + ' ' + myGeocode[1])\" />   </body> </html>   This works for any Python structure that is JSON serializable:  python_data = {     'some_list': [4, 5, 6],     'nested_dict': {'foo': 7, 'bar': 'a string'} }   var data = {{ python_data|tojson }}; alert('Data: ' + data.some_list[1] + ' ' + data.nested_dict.foo +        ' ' + data.nested_dict.bar);      ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"77","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  Using a data attribute on an HTML element avoids having to use inline scripting, which in turn means you can use stricter CSP rules for increased security.  Specify a data attribute like so:  <div id=\"mydiv\" data-geocode=\"{{ geocode|tojson }}\">...</div>   Then access it in a static JavaScript file like so:  // Raw JavaScript var geocode = JSON.parse(document.getElementById(\"mydiv\").dataset.geocode);  // jQuery var geocode = JSON.parse($(\"#mydiv\").data(\"geocode\"));      ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  Alternatively you could add an endpoint to return your variable:  @app.route(\"/api/geocode\") def geo_code():     return jsonify(geocode)   Then do  an XHR to retrieve it:  fetch('/api/geocode')   .then((res)=>{ console.log(res) })      ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  Just another alternative solution for those who want to pass variables to a script which is sourced using flask, I only managed to get this working by defining the variables outside and then calling the script as follows:      <script>     var myfileuri = \"/static/my_csv.csv\"     var mytableid = 'mytable';     </script>     <script type=\"text/javascript\" src=\"/static/test123.js\"></script>   If I input jinja variables in test123.js it doesn't work and you will get an error.     ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  Working answers are already given but I want to add a check that acts as a fail-safe in case the flask variable is not available.  When you use:  var myVariable = {{ flaskvar | tojson }};   if there is an error that causes the variable to be non existent, resulting errors may produce unexpected results. To avoid this:  {% if flaskvar is defined and flaskvar %} var myVariable = {{ flaskvar | tojson }}; {% endif %}      ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"How can I pass data from Flask to JavaScript in a template?","A_Content":"  Some js files come from the web or library, they are not written by yourself. The code they get variable like this:  var queryString = document.location.search.substring(1); var params = PDFViewerApplication.parseQueryString(queryString); var file = 'file' in params ? params.file : DEFAULT_URL;   This method makes js files unchanged(keep independence), and pass variable correctly!     ","Language":"Python","Tags":["javascript","python","flask","jinja2"],"URL":"https://stackoverflow.com/questions/11178426/how-can-i-pass-data-from-flask-to-javascript-in-a-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    My app makes a call to an API that returns a  dictionary. I want to pass information from this dict to JavaScript in the view. I am using the Google Maps API in the JS, specifically, so I'd like to pass it a list of tuples with the long/lat information. I know that render_template will pass these variables to the view so they can be used in HTML, but how could I pass them to JavaScript in the template?   from flask import Flask from flask import render_template  app = Flask(__name__)  import foo_api  api = foo_api.API('API KEY')  @app.route('/') def get_data():     events = api.call(get_event, arg0, arg1)     geocode = event['latitude'], event['longitude']     return render_template('get_data.html', geocode=geocode)      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  If your own module is in the same path, you need mark the path as Sources Root. In the project explorer, right-click on the directory that you want import. Then select Mark Directory As and select Sources Root.  I hope this helps.      ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"182","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  What I tried is to source the location where my files are.  e.g. E:\\git_projects\\My_project\\__init__.py is my location.  I went to File -> Setting -> Project:My_project -> Project Structure and added the content root to about mention place E:\\git_projects\\My_project  it worked for me.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  my_module is a folder not a module and you can't import a folder, try moving my_mod.py to the same folder as the cool_script.py and then doimport my_mod as mm. This is because python only looks in the current directory and sys.path, and so wont find my_mod.py unless it's in the same directory  Or you can look here for an answer telling you how to import from other directories.  As to your other questions, I do not know as I do not use PyCharm.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  I was getting the error with \"Add source roots to PYTHONPATH\" as well. My problem was that I had two folders with the same name, like project/subproject1/thing/src and project/subproject2/thing/src and I had both of them marked as source root. When I renamed one of the \"thing\" folders to \"thing1\" (any unique name), it worked.  Maybe if PyCharm automatically adds selected source roots, it doesn't use the full path and hence mixes up folders with the same name.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  This can be caused when Python interpreter can't find your code. You have to mention explicitly to Python to find your code in this location.  To do so:   Go to your python console Add sys.path.extend(['your module location']) to Python console.   In your case:   Go to your python console, On the start, write the following code:  import sys sys.path.extend([my module URI location])  Once you have written this statement you can run following command:  from mymodule import functions       ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  The key confusing step that must be done is to recreate the run configuration for the source file that you're trying to execute, so that the IDE picks up the new paths.   The way that actually worked for me was to go to Run/Edit Configurations..., select the configuration for the file that you're trying to run on the left side, uncheck the \"Add source roots to PYTHONPATH\" box, save, and then go back and check the box and save.  THEN it would work.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  Content roots are folders holding your project code while source roots are defined as same too. The only difference i came to understand was that the code in source roots is built before the code in the content root.   Unchecking them wouldn't affect the runtime till the point you're not making separate modules in your package which are manually connected to Django. That means if any of your files do not hold the 'from django import...' or any of the function isn't called via django, unchecking these 2 options will result in a malfunction.  Update - the problem only arises when using Virtual Environmanet, and only when controlling the project via the provided terminal. Cause the terminal still works via the default system pyhtonpath and not the virtual env. while the python django control panel works fine.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  Pycharm 2017.1.1   Click on View->ToolBar & View->Tool Buttons On the left pane Project would be visible, right click on it and  press Autoscroll to source and then run your code.   This worked for me.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"PyCharm error: 'No Module' when trying to import own module (python script)","A_Content":"  PyCharm Professional 2018.2.1  I was having this problem just now and I was able to solve it in sort of a similar way that @Beatriz Fonseca and @Julie pointed out.   If you go to File -> Settings -> Project: YourProjectName -> Project Structure, you'll have a directory layout of the project you're currently working in. You'll have to go through your directories and label them as being either the Source directory for all your Source files, or as a Resource folder for files that are strictly for importing.   You'll also want to make sure that you place __init__.py files within your resource directories, or really anywhere that you want to import from, and it'll work perfectly fine.   I hope this answer helps someone, and hopefully JetBrains will fix this annoying bug.     ","Language":"Python","Tags":["python","module","pycharm"],"URL":"https://stackoverflow.com/questions/28705029/pycharm-error-no-module-when-trying-to-import-own-module-python-script","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have written a module (a file my_mod.py file residing in the folder my_module). Currently, I am working in the file cool_script.py that resides in the folder cur_proj. I have opened the folder in PyCharm using File -- open (and I assume, hence, it is a PyCharm project).  In ProjectView (CMD-7), I can see my project cur_proj (in red) and under \"External Libraries\" I do see my_module. In cool_script.py, I can write   from my_module import my_mod as mm   and PyCharm even makes suggestion for my_mod. So far so good.  However, when I try to run cool_script.py, PyCharm tells me  \"No module named my_module\"  This seems strange to me, because  A) in the terminal (OS 10.10.2), in python, I can import the module no problem -- there is a corresponding entry in the PYTHONPATH in .bashrc  B) in PyCharm -- Settings -- Project cur_proj -- Project Interpreter -- CogWheel next to python interpreter -- more -- show paths for selected interpreter icon, the paths from PYTHONPATH do appear (as I think they should)  Hence, why do I get the error when I try to run cool_script.py?  -- What am I missing?  Notes:   I am not declaring a different / special python version at the top of cool_script.py I made sure that the path to my_module is correct I put __init__.py files (empty files) both in my_module and in cur_proj I am not using virtualenv   Addendum 2015-Feb-25  When I go in PyCharm to Run -- Edit Configurations, for my current project, there are two options that are selected with a check mark: \"Add content roots to PYTHONPATH\" and \"Add source roots to PYTHONPATH\". When I have both unchecked, I can load my module.  So it works now -- but why?   Further questions emerged:   What are \"content roots\" and what are \"source roots\"? And why does adding something to the PYTHONPATH make it somehow break? should I uncheck both of those options all the time (so also in the defaults, not only the project specific configurations (left panel of the Run/Debug Configurations dialog)?      ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  from nltk.corpus import stopwords # ... filtered_words = [word for word in word_list if word not in stopwords.words('english')]      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"156","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  You could also do a set diff, for example:  list(set(nltk.regexp_tokenize(sentence, pattern, gaps=True)) - set(nltk.corpus.stopwords.words('english')))      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  I suppose you have a list of words (word_list) from which you want to remove stopwords. You could do something like this:  filtered_word_list = word_list[:] #make a copy of the word_list for word in word_list: # iterate over word_list   if word in stopwords.words('english'):      filtered_word_list.remove(word) # remove word from filtered_word_list if it is a stopword      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  To exclude all type of stop-words including nltk stop-words, you could do something like this:      from stop_words import get_stop_words from nltk.corpus import stopwords  stop_words = list(get_stop_words('en'))         #About 900 stopwords nltk_words = list(stopwords.words('english')) #About 150 stopwords stop_words.extend(nltk_words)  output = [w for w in word_list if not w in stop_words]      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  using filter:  from nltk.corpus import stopwords # ...   filtered_words = list(filter(lambda word: word not in stopwords.words('english'), word_list))      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"     import sys print (\"enter the string from which you want to remove list of stop words\") userstring = input().split(\" \") list =[\"a\",\"an\",\"the\",\"in\"] another_list = [] for x in userstring:     if x not in list:           # comparing from the list and removing it         another_list.append(x)  # it is also possible to use .remove for x in another_list:      print(x,end=' ')     # 2) if you want to use .remove more preferred code     import sys     print (\"enter the string from which you want to remove list of stop words\")     userstring = input().split(\" \")     list =[\"a\",\"an\",\"the\",\"in\"]     another_list = []     for x in userstring:         if x in list:                        userstring.remove(x)       for x in userstring:                    print(x,end = ' ')      #the code will be like this      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How to remove stop words using nltk or python","A_Content":"  you can use this function, you should notice that you need to lower all the words  from nltk.corpus import stopwords  def remove_stopwords(word_list):         processed_word_list = []         for word in word_list:             word = word.lower() # in case they arenet all lower cased             if word not in stopwords.words(\"english\"):                 processed_word_list.append(word)         return processed_word_list      ","Language":"Python","Tags":["python","nltk","stop-words"],"URL":"https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    So I have a dataset that I would like to remove stop words from using   stopwords.words('english')   I'm struggling how to use this within my code to just simply take out these words. I have a list of the words from this dataset already, the part i'm struggling with is comparing to this list and removing the stop words. Any help is appreciated.     ","Q_Votes":"81"},{"Q_Title":"How could I use requests in asyncio?","A_Content":"  To use requests (or any other blocking libraries) with asyncio, you can use BaseEventLoop.run_in_executor to run a function in another thread and yield from it to get the result. For example:  import asyncio import requests  @asyncio.coroutine def main():     loop = asyncio.get_event_loop()     future1 = loop.run_in_executor(None, requests.get, 'http://www.google.com')     future2 = loop.run_in_executor(None, requests.get, 'http://www.google.co.uk')     response1 = yield from future1     response2 = yield from future2     print(response1.text)     print(response2.text)  loop = asyncio.get_event_loop() loop.run_until_complete(main())   This will get both responses in parallel.  With python 3.5 you can use the new await/async syntax:  import asyncio import requests  async def main():     loop = asyncio.get_event_loop()     future1 = loop.run_in_executor(None, requests.get, 'http://www.google.com')     future2 = loop.run_in_executor(None, requests.get, 'http://www.google.co.uk')     response1 = await future1     response2 = await future2     print(response1.text)     print(response2.text)  loop = asyncio.get_event_loop() loop.run_until_complete(main())   See PEP0492 for more.     ","Language":"Python","Tags":["python","python-requests","python-3.4","aiohttp"],"URL":"https://stackoverflow.com/questions/22190403/how-could-i-use-requests-in-asyncio","A_Votes":"128","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to do parallel http request tasks in asyncio, but I find that python-requests would block the event loop of asyncio. I've found aiohttp but it couldn't provide the service of http request using a http proxy.  So I want to know if there's a way to do asynchronous http requests with the help of asyncio.     ","Q_Votes":"81"},{"Q_Title":"How could I use requests in asyncio?","A_Content":"  aiohttp can be used with HTTP proxy already:  import asyncio import aiohttp   @asyncio.coroutine def do_request():     proxy_url = 'http://localhost:8118'  # your proxy address     response = yield from aiohttp.request(         'GET', 'http://google.com',         proxy=proxy_url,     )     return response  loop = asyncio.get_event_loop() loop.run_until_complete(do_request())      ","Language":"Python","Tags":["python","python-requests","python-3.4","aiohttp"],"URL":"https://stackoverflow.com/questions/22190403/how-could-i-use-requests-in-asyncio","A_Votes":"55","_type":"dict","isAccepted":"No","Q_Content":"    I want to do parallel http request tasks in asyncio, but I find that python-requests would block the event loop of asyncio. I've found aiohttp but it couldn't provide the service of http request using a http proxy.  So I want to know if there's a way to do asynchronous http requests with the help of asyncio.     ","Q_Votes":"81"},{"Q_Title":"How could I use requests in asyncio?","A_Content":"  Requests does not currently support asyncio and there are no plans to provide such support. It's likely that you could implement a custom \"Transport Adapter\" (as discussed here) that knows how to use asyncio.  If I find myself with some time it's something I might actually look into, but I can't promise anything.     ","Language":"Python","Tags":["python","python-requests","python-3.4","aiohttp"],"URL":"https://stackoverflow.com/questions/22190403/how-could-i-use-requests-in-asyncio","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I want to do parallel http request tasks in asyncio, but I find that python-requests would block the event loop of asyncio. I've found aiohttp but it couldn't provide the service of http request using a http proxy.  So I want to know if there's a way to do asynchronous http requests with the help of asyncio.     ","Q_Votes":"81"},{"Q_Title":"How could I use requests in asyncio?","A_Content":"  There is a good case of async/await loops and threading in an article by Pimin Konstantin Kefaloukos Easy parallel HTTP requests with Python and asyncio:     To minimize the total completion time, we could increase the size of the thread pool to match the number of requests we have to make. Luckily, this is easy to do as we will see next. The code listing below is an example of how to make twenty asynchronous HTTP requests with a thread pool of twenty worker threads:   # Example 3: asynchronous requests with larger thread pool import asyncio import concurrent.futures import requests  async def main():      with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:          loop = asyncio.get_event_loop()         futures = [             loop.run_in_executor(                 executor,                  requests.get,                  'http://example.org/'             )             for i in range(20)         ]         for response in await asyncio.gather(*futures):             pass   loop = asyncio.get_event_loop() loop.run_until_complete(main())      ","Language":"Python","Tags":["python","python-requests","python-3.4","aiohttp"],"URL":"https://stackoverflow.com/questions/22190403/how-could-i-use-requests-in-asyncio","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to do parallel http request tasks in asyncio, but I find that python-requests would block the event loop of asyncio. I've found aiohttp but it couldn't provide the service of http request using a http proxy.  So I want to know if there's a way to do asynchronous http requests with the help of asyncio.     ","Q_Votes":"81"},{"Q_Title":"How could I use requests in asyncio?","A_Content":"  The answers above are still using the old Python 3.4 style coroutines. Here is what you would write if you got Python 3.5+.  aiohttp supports http proxy now  import aiohttp import asyncio  async def fetch(session, url):     async with session.get(url) as response:         return await response.text()  async def main():     urls = [             'http://python.org',             'https://google.com',             'http://yifei.me'         ]     tasks = []     async with aiohttp.ClientSession() as session:         for url in urls:             tasks.append(fetch(session, url))         htmls = await asyncio.gather(*tasks)         for html in htmls:             print(html[:100])  if __name__ == '__main__':     loop = asyncio.get_event_loop()     loop.run_until_complete(main())      ","Language":"Python","Tags":["python","python-requests","python-3.4","aiohttp"],"URL":"https://stackoverflow.com/questions/22190403/how-could-i-use-requests-in-asyncio","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to do parallel http request tasks in asyncio, but I find that python-requests would block the event loop of asyncio. I've found aiohttp but it couldn't provide the service of http request using a http proxy.  So I want to know if there's a way to do asynchronous http requests with the help of asyncio.     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  Try this:  [dict(t) for t in {tuple(d.items()) for d in l}]   The strategy is to convert the list of dictionaries to a list of tuples where the tuples contain the items of the dictionary. Since the tuples can be hashed, you can remove duplicates using set (using a set comprehension here, older python alternative would be set(tuple(d.items()) for d in l)) and, after that, re-create the dictionaries from tuples with dict.  where:   l is the original list d is one of the dictionaries in the list t is one of the tuples created from a dictionary   Edit: If you want to preserve ordering, the one-liner above won't work since set won't do that. However, with a few lines of code, you can also do that:  l = [{'a': 123, 'b': 1234},         {'a': 3222, 'b': 1234},         {'a': 123, 'b': 1234}]  seen = set() new_l = [] for d in l:     t = tuple(d.items())     if t not in seen:         seen.add(t)         new_l.append(d)  print new_l   Example output:  [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]   Note: As pointed out by @alexis it might happen that two dictionaries with the same keys and values, don't result in the same tuple. That could happen if they go through a different adding/removing keys history. If that's the case for your problem, then consider sorting d.items() as he suggests.     ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"143","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  Another one-liner based on list comprehensions:  >>> d = [{'a': 123}, {'b': 123}, {'a': 123}] >>> [i for n, i in enumerate(d) if i not in d[n + 1:]] [{'b': 123}, {'a': 123}]   Here since we can use dict comparison, we only keep the elements that are not in the rest of the initial list (this notion is only accessible through the index n, hence the use of enumerate).     ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  Sometimes old-style loops are still useful. This code is little longer than jcollado's, but very easy to read:  a = [{'a': 123}, {'b': 123}, {'a': 123}] b = [] for i in range(0, len(a)):     if a[i] not in a[i+1:]:         b.append(a[i])      ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  Other answers would not work if you're operating on nested dictionaries such as deserialized JSON objects. For this case you could use:  import json set_of_jsons = {json.dumps(d, sort_keys=True) for d in X} X = [json.loads(t) for t in set_of_jsons]      ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  If you want to preserve the Order, then you can do  from collections import OrderedDict print OrderedDict((frozenset(item.items()),item) for item in data).values() # [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]   If the order doesn't matter, then you can do  print {frozenset(item.items()):item for item in data}.values() # [{'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]      ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  You can use a set, but you need to turn the dicts into a hashable type.  seq = [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}] unique = set() for d in seq:     t = tuple(d.iteritems())     unique.add(t)   Unique now equals  set([(('a', 3222), ('b', 1234)), (('a', 123), ('b', 1234))])   To get dicts back:  [dict(x) for x in unique]      ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  Not a universal answer, but if your list happens to be sorted by some key, like this:  l=[{'a': {'b': 31}, 't': 1},    {'a': {'b': 31}, 't': 1},  {'a': {'b': 145}, 't': 2},  {'a': {'b': 25231}, 't': 2},  {'a': {'b': 25231}, 't': 2},   {'a': {'b': 25231}, 't': 2},   {'a': {'b': 112}, 't': 3}]   then the solution is as simple as:  import itertools result = [a[0] for a in itertools.groupby(l)]   Result:  [{'a': {'b': 31}, 't': 1}, {'a': {'b': 145}, 't': 2}, {'a': {'b': 25231}, 't': 2}, {'a': {'b': 112}, 't': 3}]   Works with nested dictionaries and (obviously) preserves order.     ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  If using a third-party package would be okay then you could use iteration_utilities.unique_everseen:  >>> from iteration_utilities import unique_everseen >>> l = [{'a': 123}, {'b': 123}, {'a': 123}] >>> list(unique_everseen(l)) [{'a': 123}, {'b': 123}]   It preserves the order of the original list and ut can also handle unhashable items like dictionaries by falling back on a slower algorithm (O(n*m) where n are the elements in the original list and m the unique elements in the original list instead of O(n)). In case both keys and values are hashable you can use the key argument of that function to create hashable items for the \"uniqueness-test\" (so that it works in O(n)).  In the case of a dictionary (which compares independent of order) you need to map it to another data-structure that compares like that, for example frozenset:  >>> list(unique_everseen(l, key=lambda item: frozenset(item.items()))) [{'a': 123}, {'b': 123}]   Note that you shouldn't use a simple tuple approach (without sorting) because equal dictionaries don't necessarily have the same order (even in Python 3.7 where insertion order - not absolute order - is guaranteed):  >>> d1 = {1: 1, 9: 9} >>> d2 = {9: 9, 1: 1} >>> d1 == d2 True >>> tuple(d1.items()) == tuple(d2.items()) False   And even sorting the tuple might not work if the keys aren't sortable:  >>> d3 = {1: 1, 'a': 'a'} >>> tuple(sorted(d3.items())) TypeError: '<' not supported between instances of 'str' and 'int'   Benchmark  I thought it might be useful to see how the performance of these approaches compares, so I did a small benchmark. The benchmark graphs are time vs. list-size based on a list containing no duplicates (that was chosen arbitrarily, the runtime doesn't change significantly if I add some or lots of duplicates). It's a log-log plot so the complete range is covered.  The absolute times:    The timings relative to the fastest approach:    The second approach from thefourtheye is fastest here. The unique_everseen approach with the key function is on the second place, however it's the fastest approach that preserves order. The other approaches from jcollado and thefourtheye are almost as fast. The approach using unique_everseen without key and the solutions from Emmanuel and Scorpil are very slow for longer lists and behave much worse O(n*n) instead of O(n). stpks approach with json isn't O(n*n) but it's much slower than the similar O(n) approaches.  The code to reproduce the benchmarks:  from simple_benchmark import benchmark import json from collections import OrderedDict from iteration_utilities import unique_everseen  def jcollado_1(l):     return [dict(t) for t in {tuple(d.items()) for d in l}]  def jcollado_2(l):     seen = set()     new_l = []     for d in l:         t = tuple(d.items())         if t not in seen:             seen.add(t)             new_l.append(d)     return new_l  def Emmanuel(d):     return [i for n, i in enumerate(d) if i not in d[n + 1:]]  def Scorpil(a):     b = []     for i in range(0, len(a)):         if a[i] not in a[i+1:]:             b.append(a[i])  def stpk(X):     set_of_jsons = {json.dumps(d, sort_keys=True) for d in X}     return [json.loads(t) for t in set_of_jsons]  def thefourtheye_1(data):     return OrderedDict((frozenset(item.items()),item) for item in data).values()  def thefourtheye_2(data):     return {frozenset(item.items()):item for item in data}.values()  def iu_1(l):     return list(unique_everseen(l))  def iu_2(l):     return list(unique_everseen(l, key=lambda inner_dict: frozenset(inner_dict.items())))  funcs = (jcollado_1, Emmanuel, stpk, Scorpil, thefourtheye_1, thefourtheye_2, iu_1, jcollado_2, iu_2) arguments = {2**i: [{'a': j} for j in range(2**i)] for i in range(2, 12)} b = benchmark(funcs, arguments, 'list size')  %matplotlib widget import matplotlib as mpl import matplotlib.pyplot as plt plt.style.use('ggplot') mpl.rcParams['figure.figsize'] = '8, 6'  b.plot(relative_to=thefourtheye_2)   For completeness here is the timing for a list containing only duplicates:  # this is the only change for the benchmark arguments = {2**i: [{'a': 1} for j in range(2**i)] for i in range(2, 12)}     The timings don't change significantly except for unique_everseen without key function, which in this case is the fastest solution. However that's just the best case (so not representative) for that function with unhashable values because it's runtime depends on the amount of unique values in the list: O(n*m) which in this case is just 1 and thus it runs in O(n).     Disclaimer: I'm the author of iteration_utilities.     ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"Remove duplicate dict in list in Python","A_Content":"  If you are using Pandas in your workflow, one option is to feed a list of dictionaries directly to the pd.DataFrame constructor. Then use drop_duplicates and to_dict methods for the required result.  import pandas as pd  d = [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  d_unique = pd.DataFrame(d).drop_duplicates().to_dict('records')  print(d_unique)  [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]      ","Language":"Python","Tags":["python","list","dictionary"],"URL":"https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of dicts, and I'd like to remove the dicts with identical key and value pairs.  For this list: [{'a': 123}, {'b': 123}, {'a': 123}]  I'd like to return this: [{'a': 123}, {'b': 123}]  Another example:  For this list: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}, {'a': 123, 'b': 1234}]  I'd like to return this: [{'a': 123, 'b': 1234}, {'a': 3222, 'b': 1234}]     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  I went ahead and answered my own question.  Here's the answer for future reference:  In Django form.py does some dark magic using the __new__ method to load your class variables ultimately into self.fields in the order defined in the class.  self.fields is a Django SortedDict instance (defined in datastructures.py).  So to override this, say in my example you wanted sender to come first but needed to add it in an init method, you would do:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     def __init__(self,*args,**kwargs):         forms.Form.__init__(self,*args,**kwargs)         #first argument, index is the position of the field you want it to come before         self.fields.insert(0,'sender',forms.EmailField(initial=str(time.time())))      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"38","_type":"dict","isAccepted":"Yes","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  [NOTE: this answer is now pretty completely outdated - please see the discussion below it, and more recent answers].  If f is a form, its fields are f.fields, which is a django.utils.datastructures.SortedDict  (it presents the items in the order they are added). After form construction f.fields has a keyOrder attribute, which is a list containing the field names in the order they should be presented. You can set this to the correct ordering (though you need to exercise care to ensure you don't omit items or add extras).  Here's an example I just created in my current project:  class PrivEdit(ModelForm):     def __init__(self, *args, **kw):         super(ModelForm, self).__init__(*args, **kw)         self.fields.keyOrder = [             'super_user',             'all_districts',             'multi_district',             'all_schools',             'manage_users',             'direct_login',             'student_detail',             'license']     class Meta:         model = Privilege      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"87","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  New to Django 1.9 is Form.field_order and Form.order_fields().  # example  class SignupForm(forms.Form):      password = ...     email = ...     username = ...      field_order = ['username', 'email', 'password']      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  Fields are listed in the order they are defined in ModelClass._meta.fields. But if you want to change order in Form, you can do by using keyOrder function. For example :   class ContestForm(ModelForm):   class Meta:     model = Contest     exclude=('create_date', 'company')    def __init__(self, *args, **kwargs):     super(ContestForm, self).__init__(*args, **kwargs)     self.fields.keyOrder = [         'name',         'description',         'image',         'video_link',         'category']      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  Form fields have an attribute for creation order, called creation_counter. .fields attribute is a dictionary, so simple adding to dictionary and changing creation_counter attributes in all fields to reflect new ordering should suffice (never tried this, though).     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  Use a counter in the Field class. Sort by that counter:  import operator import itertools  class Field(object):     _counter = itertools.count()     def __init__(self):         self.count = Field._counter.next()         self.name = ''     def __repr__(self):         return \"Field(%r)\" % self.name  class MyForm(object):     b = Field()     a = Field()     c = Field()      def __init__(self):         self.fields = []         for field_name in dir(self):             field = getattr(self, field_name)             if isinstance(field, Field):                 field.name = field_name                 self.fields.append(field)         self.fields.sort(key=operator.attrgetter('count'))  m = MyForm() print m.fields # in defined order   Output:  [Field('b'), Field('a'), Field('c')]        ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  With Django >= 1.7  your must modify ContactForm.base_fields as below:  from collections import OrderedDict  ...  class ContactForm(forms.Form):     ...  ContactForm.base_fields = OrderedDict(     (k, ContactForm.base_fields[k])     for k in ['your', 'field', 'in', 'order'] )   This trick is used in Django Admin PasswordChangeForm: Source on Github     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  As of Django 1.7 forms use OrderedDict which does not support the append operator.  So you have to rebuild the dictionary from scratch...  class ChecklistForm(forms.ModelForm):    class Meta:     model = Checklist     fields = ['name', 'email', 'website']    def __init__(self, guide, *args, **kwargs):     self.guide = guide     super(ChecklistForm, self).__init__(*args, **kwargs)      new_fields = OrderedDict()     for tier, tasks in guide.tiers().items():       questions = [(t['task'], t['question']) for t in tasks if 'question' in t]       new_fields[tier.lower()] = forms.MultipleChoiceField(         label=tier,         widget=forms.CheckboxSelectMultiple(),         choices=questions,         help_text='desired set of site features'       )      new_fields['name'] = self.fields['name']     new_fields['email'] = self.fields['email']     new_fields['website'] = self.fields['website']     self.fields = new_fields       ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  For future reference: things have changed a bit since newforms. This is one way of reordering fields from base formclasses you have no control over:  def move_field_before(form, field, before_field):     content = form.base_fields[field]     del(form.base_fields[field])     insert_at = list(form.base_fields).index(before_field)     form.base_fields.insert(insert_at, field, content)     return form   Also, there's a little bit of documentation about the SortedDict that base_fields uses here: http://code.djangoproject.com/wiki/SortedDict     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  If either fields = '__all__':  class AuthorForm(ModelForm):     class Meta:         model = Author         fields = '__all__'   or exclude are used:  class PartialAuthorForm(ModelForm):     class Meta:         model = Author         exclude = ['title']   Then Django references the order of fields as defined in the model. This just caught me out, so I thought I'd mention it. It's referenced in the ModelForm docs:     If either of these are used, the order the fields appear in the form will be the order the fields are defined in the model, with ManyToManyField instances appearing last.      ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  It has to do with the meta class that is used in defining the form class.  I think it keeps an internal list of the fields and if you insert into the middle of the list it might work.  It has been a while since I looked at that code.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  Using fields in inner Meta class is what worked for me on Django==1.6.5:  #!/usr/bin/env python # -*- coding: utf-8 -*-  \"\"\" Example form declaration with custom field order. \"\"\"  from django import forms  from app.models import AppModel   class ExampleModelForm(forms.ModelForm):     \"\"\"     An example model form for ``AppModel``.     \"\"\"     field1 = forms.CharField()     field2 = forms.CharField()      class Meta:         model = AppModel         fields = ['field2', 'field1']   As simple as that.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  I've used this to move fields about:  def move_field_before(frm, field_name, before_name):     fld = frm.fields.pop(field_name)     pos = frm.fields.keys().index(before_name)     frm.fields.insert(pos, field_name, fld)   This works in 1.5 and I'm reasonably sure it still works in more recent versions.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"How does Django Know the Order to Render Form Fields?","A_Content":"  The easiest way to order fields in django 1.9 forms is to use field_order in your form Form.field_order  Here is a small example  class ContactForm(forms.Form):      subject = forms.CharField(max_length=100)      message = forms.CharField()      sender = forms.EmailField()      field_order = ['sender','message','subject']   This will show everything in the order you specified in field_order dict.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/350799/how-does-django-know-the-order-to-render-form-fields","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If I have a Django form such as:  class ContactForm(forms.Form):     subject = forms.CharField(max_length=100)     message = forms.CharField()     sender = forms.EmailField()   And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.  My question is how does Django know the order that class variables where defined?    (Also how do I override this order, for example when I want to add a field from the classe's init method?)     ","Q_Votes":"81"},{"Q_Title":"View onto a numpy array?","A_Content":"  Sure, just index it as you normally would.  E.g. y = x[:k, :]  This will return a view into the original array. No data will be copied, and any updates made to y will be reflected in x and vice versa.    Edit:   I commonly work with >10GB 3D arrays of uint8's, so I worry about this a lot... Numpy can be very efficient at memory management if you keep a few things in mind. Here are a few tips on avoiding making copies of arrays in memory:   Use +=, -=, *=, etc to avoid making a copy of the array. E.g. x += 10 will modify the array in place, while x = x + 10 will make a copy and modify it.  (also, have a look at numexpr)    If you do want to make a copy with x = x + 10, be aware that x = x + 10.0 will cause x to automatically be up-casted to a floating point array, if it wasn't already.  However, x += 10.0, where x is an integer array, will cause the 10.0 to be down-casted to an int of the same precision as the array, instead.    Additionally, many numpy functions take an out parameter, so you can do things like np.abs(x, x) to take the absolute value of x in-place.    As a second edit, here's few more tips on views vs. copies with numpy arrays:  Unlike python lists, y = x[:] does not return a copy, it returns a view. If you do want a copy (which will, of course, double the amount of memory you're using) use y = x.copy()  You'll often hear about \"fancy indexing\" of numpy arrays. Using a list (or integer array) as an index is \"fancy indexing\". It can be very useful, but copies the data.    As an example of this: y = x[[0, 1, 2], :] returns a copy, while y = x[:3,:] would return a view.    Even really crazy indexing like x[4:100:5, :-10:-1, None] is \"normal\" indexing and will return a view, though, so don't be afraid to use all kinds of slicing tricks on large arrays.  x.astype(<dtype>) will return a copy of the data as the new type, whilex.view(<dtype>) will return a view.    Be careful with this, however... It's extremely powerful and useful, but you need to understand how the underlying data is stored in memory.  If you have an array of floats, and view them as ints, (or vice versa) numpy will interpret the underlying bits of the array as ints.   For example, this means that 1.0 as a 64bit float on a little-endian system will be 4607182418800017408 when viewed as a 64bit int, and an array of [  0,   0,   0,   0,   0,   0, 240,  63] if viewed as a uint8.  This is really nice when you need to do bit-twiddling of some sort on large arrays, though... You have low level control over how the memory buffer is interpreted.     ","Language":"Python","Tags":["python","numpy","scikits"],"URL":"https://stackoverflow.com/questions/4370745/view-onto-a-numpy-array","A_Votes":"204","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a 2D numpy array. Is there a way to create a view onto it that would include the first k rows and all columns?  The point is to avoid copying the underlying data (the array is so large that making partial copies is not feasible.)     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  Your path only lists Visual Studio 11 and 12, it wants 14, which is Visual Studio 2015. If you install that, and remember to tick the box for Languages->C++ then it should work.   On my Python 3.5 install, the error message was a little more useful, and included the URL to get it from   error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools   Edit: New working link  Edit: As suggested by Lightfire228, you may also need to upgrade setuptools package for the error to disappear:  pip install --upgrade setuptools      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"53","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  As the other responses pointed out, one solution is to install Visual Studio 2015. However, it takes a few GBs of disk space. One way around is to install precompiled binaries. The webpage http://www.lfd.uci.edu/~gohlke/pythonlibs  (mirror)  contains precompiled binaries for many Python packages. After downloading the package of interest to you, you can install it using pip install, e.g. pip install mysqlclient1.3.10cp35cp35mwin_amd64.whl.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  To solve any of the following errors:   Failed building wheel for misaka Failed to build misaka Microsoft Visual C++ 14.0 is required Unable to find vcvarsall.bat   The Solution is:   Go to Build Tools for Visual Studio 2017 Select free download under Visual Studio Community 2017. This will download the installer. Run the installer. Select what you need under workload tab:  a. Under Windows, there are 3 choices. Only check Desktop development with C++  b. Under Web & Cloud, there are 7 choices. Only check Python development (I believe this is optional But I have done it). In cmd, type pip3 install misaka    Note if you already installed Visual Studio then when you run the installer, you can modify yours (click modify button under Visual Studio Community 2017) and do steps 3 and 4    Final Note : If you don't want to install all modules, having the 3 ones below (or a newer version of the  VC++ 2017) would be sufficient. (you can also install the Visual Studio Build Tools with only these options so you dont need to install Visual Studio Community Edition itself) => This minimal install is already a 4.5GB, so saving off anything is helpful      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"     I had the exact issue while trying to install Scrapy web scraping Python framework on my Windows 10 machine. I figured out the solution this way:    Download the latest (the last one) wheel file from this link \uD83D\uDC49 wheel file for twisted package  I'd recommend saving that wheel file in the directory where you've installed Python i.e somewhere in Local Disk C Then visit the folder where the wheel file exists and run pip install <*wheel file's name*> Finally run the command pip install Scrapy again and you're good to use Scrapy or any other tool which required you to download massive Windows C++ Package/SDK.      Disclaimer: This solution worked for me while trying to install Scrapy, but I can't guarantee the same happening while installing other softwares/packages/etc.      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  Binary install it the simple way!  I can't believe no one has suggested this already - use the binary-only option for pip. For example, for mysqlclient:  pip install --only-binary :all: mysqlclient   Many packages don't create a build for every single release which forces your pip to build from source. If you're happy to use the latest pre-compiled binary version, use --only-binary :all: to allow pip to use an older binary version.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  I had the same problem when installing spaCy module. And I checked control panel I have several visual C++ redistributables installed already.  What I did was select \"Microsoft Visual Studio Community 2015\" which is already installed on my PC --> \"Modify\" -->check \"Common Tools for Visual C++ 2015\". Then it will take some time and download more than 1 GB to install it.  This fixed my issue. Now I have spaCy installed.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  I had this same problem. A solution for updating setuptools  pip install -U setuptools   or  pip install setuptools --upgrade      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  I had the same issue. Downloading the Build Tools for Visual Studio 2017 worked for me. Find it here     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"     To expand on the answers by ocean800, davidsheldon and user3661384:   You should now no longer use Visual Studio Tools 2015 since a newer version is available.  As indicated by the Python documentation you should be using Visual Studio Tools 2017 instead.     Visual C++ Build Tools 2015 was upgraded by Microsoft to Build Tools for Visual Studio 2017.   Download it from here  You will require also need setuptools,  if you don't have setup tools run:  pip install setuptools   Or if you already have it, be sure to upgrade it.  pip install setuptools --upgrade   For the Python documentation link above you will see that setuptools version must be at least 34.4.0. for VS Tools to work     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  I had the same problem. I needed a 64-bit version of Python so I installed 3.5.0 (the most recent as of writing this). After switching to 3.4.3 all of my module installations worked.  Python Releases for Windows     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  Just had the same issue while using the latest Python 3.6. With Windows OS 10 Home Edition and 64 Bit Operation System  Steps to solve this issue :   Uninstall any versions of Visual studio you have had, through Control Panel Install Visual Studio 2015 and chose the default option that will install  Visual C++ 14.0 on its own You can use Pycharm for installing scrapy ->Project->Project Interpreter->+ (install scrapy) check scrapy in REPL and pycharm by import , you should not see any errors      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  had a similar situation installing pymssql  pip was trying to build the package because there were no official wheels for python 3.6 & windows.  solved it by downloading an unoffical wheel from here: http://www.lfd.uci.edu/~gohlke/pythonlibs/  specifically for your case ->  http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  Oops! Looks like they don't have Windows wheels on PyPI.  In the meantime, installing from source probably works or try downloading MSVC++ 14 as suggested in the error message and by others on this page.  Christoph's site also has unofficial Windows Binaries for Python Extension Packages (.whl files).  Follow steps mentioned in following links to install binaries :   Directly in base python In virtual environments / Pycharm   Also check :  Which binary to download??     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"  I was facing the same problem. The following worked for me: Download the unoffical binaries file from Christoph Gohlke installers site as per the python version installed on your system. Navigate to the folder where you have installed the file and run  pip install filename   For me python_ldap3.0.0cp35cp35mwin_amd64.whl worked as my machine is 64 bit and python version is 3.5. This successfully installed python-ldap on my windows machine. You can try the same for mysql-python     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)","A_Content":"     I was not able to comment on @Sushant Chaudhary's answer so thought to add the answer here.      I was facing the exact issue when tried to install scrapy. I was following the instructions from the above answer of @Sushant Chaudhary.   in my case, I got another error regarding lxml as below  copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\readme.txt -> build\\lib.win-amd64-3.7\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1 running build_ext building 'lxml.etree' extension error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools   I had to install lxml4.2.3cp37cp37mwin_amd64.whl same way as in the answer of @Sushant Chaudhary to successfully complete installation of Scrapy.   Download lxml4.2.3cp37cp37mwin_amd64.whl from https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml put it in folder when python is installed install it using pip install <file-name>   now you can run pip install scrapy     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've installed Python 3.5 and while running   pip install mysql-python   it gives me the following error   error: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)   I have added the following lines to my Path  C:\\Program Files\\Python 3.5\\Scripts\\; C:\\Program Files\\Python 3.5\\;  C:\\Windows\\System32; C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC; C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC   I have a 64bit win 7 setup in my PC.  What could be the solution for mitigating this error and installing the modules correctly via pip.     ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  Use a version of pip installed against the Python instance you want to install new packages to.  In many distributions, there may be separate python2.6-pip and python2.7-pip packages, invoked with binary names such as pip-2.6 and pip-2.7. If pip is not packaged in your distribution for the desired target, you might look for a setuptools or easyinstall package, or use virtualenv (which will always include pip in a generated environment).  pip's website includes installation instructions, if you can't find anything within your distribution.     ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"37","_type":"dict","isAccepted":"Yes","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  Alternatively, since pip itself is written in python, you can just call it with the python version you want to install the package for:  python2.7 /usr/bin/pip install foo   Edit: Or, as per llopis' remark:  python2.7 -m pip install foo      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"84","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  You can execute pip module for a specific python version using the corresponding python:  Python 2.6:  python2.6 -m pip install beautifulsoup4   Python 2.7  python2.7 -m pip install beautifulsoup4      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  You can use this syntax  python_version -m pip install your_package   For example. If you're running python3.5, you named it as \"python3\", and want to install numpy package  python3 -m pip install numpy      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  In Windows, you can execute the pip module by mentioning the python version ( You need to ensure that the launcher is on your path )  py -2 -m pip install pyfora      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  Alternatively, if you want to install specific version of the package with the specific version of python, this is the way   sudo python2.7 -m pip install pyudev=0.16   if the \"=\" doesnt work, use ==  x@ubuntuserv:~$ sudo python2.7 -m pip install pyudev=0.16  Invalid requirement: 'pyudev=0.16' = is not a valid operator. Did you mean == ?  x@ubuntuserv:~$ sudo python2.7 -m pip install pyudev==0.16  works fine     ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  Python 2    sudo pip2 install johnbonjovi     Python 3    sudo pip3 install johnbonjovi      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  If you have both 2.7 and 3.x versions of python installed, then just rename the python exe file of python 3.x version to something like - \"python.exe\" to \"python3.exe\". Now you can use pip for both versions individually. If you normally type \"pip install \" it will consider the 2.7 version by default. If you want to install it on the 3.x version you need to call the command as \"python3 -m pip install \".     ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  For Python 3  sudo apt-get install python3-pip sudo pip3 install beautifulsoup4   For Python 2  sudo apt-get install python2-pip sudo pip2 install beautifulsoup4      On Debian/Ubuntu,  pip is the command to use when installing packages   for Python 2, while pip3 is the command to use when installing   packages for Python 3.      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  I had Python 2.7 installed via chocolatey on Windows and found pip2.7.exe in C:\\tools\\python2\\Scripts.  Using this executable instead of the pip command installed the correct module for me (requests for Python 2.7).     ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  I faced a similar problem with another package called Twisted. I wanted to install it for Python 2.7, but it only got installed for Python 2.6 (system's default version).  Making a simple change worked for me.   When adding Python 2.7's path to your $PATH variable, append it to the front like this: PATH=/usr/local/bin:$PATH, so that the system uses that version.   If you face more problems, you can follow this blog post which helped me - https://github.com/h2oai/h2o-2/wiki/installing-python-2.7-on-centos-6.3.-follow-this-sequence-exactly-for-centos-machine-only     ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"Install a module using pip for specific python version","A_Content":"  As with any other python script, you may specify the python installation you'd like to run it with. You may put this in your shell profile to save the alias. The $1 refers to the first argument you pass to the script.  # PYTHON3 PIP INSTALL V2 alias pip_install3=\"python3 -m $(which pip) install $1\"      ","Language":"Python","Tags":["python","pip"],"URL":"https://stackoverflow.com/questions/10919569/install-a-module-using-pip-for-specific-python-version","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    On Ubuntu 10.04 by default Python 2.6 is installed, then I have installed Python 2.7. How can I use pip install to install packages for Python 2.7.  For example:  pip install beautifulsoup4   by default installs BeautifulSoup for Python 2.6  When I do:  import bs4   in Python 2.6 it works, but in Python 2.7 it says:  No module named bs4      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  I'm a big fan of hdf5 for storing large numpy arrays. There are two options for dealing with hdf5 in python:  http://www.pytables.org/  http://www.h5py.org/  Both are designed to work with numpy arrays efficiently.     ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"40","_type":"dict","isAccepted":"Yes","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  I've compared performance (space and time) for a number of ways to store numpy arrays. Few of them support multiple arrays per file, but perhaps it's useful anyway.    Npy and binary files are both really fast and small for dense data. If the data is sparse or very structured, you might want to use npz with compression, which'll save a lot of space but cost some load time.  If portability is an issue, binary is better than npy. If human readability is important, then you'll have to sacrifice a lot of performance, but it can be achieved fairly well using csv (which is also very portable of course).  More details and the code are available at the github repo.     ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"110","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  There is now a HDF5 based clone of pickle called hickle!  https://github.com/telegraphic/hickle  import hickle as hkl   data = { 'name' : 'test', 'data_arr' : [1, 2, 3, 4] }  # Dump data to file hkl.dump( data, 'new_data_file.hkl' )  # Load data from file data2 = hkl.load( 'new_data_file.hkl' )  print( data == data2 )     EDIT:  There also is the possibility to \"pickle\" directly into a compressed archive by doing:  import pickle, gzip, lzma, bz2  pickle.dump( data, gzip.open( 'data.pkl.gz',   'wb' ) ) pickle.dump( data, lzma.open( 'data.pkl.lzma', 'wb' ) ) pickle.dump( data,  bz2.open( 'data.pkl.bz2',  'wb' ) )       Appendix  import numpy as np import matplotlib.pyplot as plt import pickle, os, time import gzip, lzma, bz2, h5py  compressions = [ 'pickle', 'h5py', 'gzip', 'lzma', 'bz2' ] labels = [ 'pickle', 'h5py', 'pickle+gzip', 'pickle+lzma', 'pickle+bz2' ] size = 1000  data = {}  # Random data data['random'] = np.random.random((size, size))  # Not that random data data['semi-random'] = np.zeros((size, size)) for i in range(size):     for j in range(size):         data['semi-random'][i,j] = np.sum(data['random'][i,:]) + np.sum(data['random'][:,j])  # Not random data data['not-random'] = np.arange( size*size, dtype=np.float64 ).reshape( (size, size) )  sizes = {}  for key in data:      sizes[key] = {}      for compression in compressions:          if compression == 'pickle':             time_start = time.time()             pickle.dump( data[key], open( 'data.pkl', 'wb' ) )             time_tot = time.time() - time_start             sizes[key]['pickle'] = ( os.path.getsize( 'data.pkl' ) * 10**(-6), time_tot )             os.remove( 'data.pkl' )          elif compression == 'h5py':             time_start = time.time()             with h5py.File( 'data.pkl.{}'.format(compression), 'w' ) as h5f:                 h5f.create_dataset('data', data=data[key])             time_tot = time.time() - time_start             sizes[key][compression] = ( os.path.getsize( 'data.pkl.{}'.format(compression) ) * 10**(-6), time_tot)             os.remove( 'data.pkl.{}'.format(compression) )          else:             time_start = time.time()             pickle.dump( data[key], eval(compression).open( 'data.pkl.{}'.format(compression), 'wb' ) )             time_tot = time.time() - time_start             sizes[key][ labels[ compressions.index(compression) ] ] = ( os.path.getsize( 'data.pkl.{}'.format(compression) ) * 10**(-6), time_tot )             os.remove( 'data.pkl.{}'.format(compression) )   f, ax_size = plt.subplots() ax_time = ax_size.twinx()  x_ticks = labels x = np.arange( len(x_ticks) )  y_size = {} y_time = {} for key in data:     y_size[key] = [ sizes[key][ x_ticks[i] ][0] for i in x ]     y_time[key] = [ sizes[key][ x_ticks[i] ][1] for i in x ]  width = .2 viridis = plt.cm.viridis  p1 = ax_size.bar( x-width, y_size['random']       , width, color = viridis(0)  ) p2 = ax_size.bar( x      , y_size['semi-random']  , width, color = viridis(.45)) p3 = ax_size.bar( x+width, y_size['not-random']   , width, color = viridis(.9) )  p4 = ax_time.bar( x-width, y_time['random']  , .02, color = 'red') ax_time.bar( x      , y_time['semi-random']  , .02, color = 'red') ax_time.bar( x+width, y_time['not-random']   , .02, color = 'red')  ax_size.legend( (p1, p2, p3, p4), ('random', 'semi-random', 'not-random', 'saving time'), loc='upper center',bbox_to_anchor=(.5, -.1), ncol=4 ) ax_size.set_xticks( x ) ax_size.set_xticklabels( x_ticks )  f.suptitle( 'Pickle Compression Comparison' ) ax_size.set_ylabel( 'Size [MB]' ) ax_time.set_ylabel( 'Time [s]' )  f.savefig( 'sizes.pdf', bbox_inches='tight' )      ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"33","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  savez() save data in a zip file, It may take some time to zip & unzip the file. You can use save() & load() function:  f = file(\"tmp.bin\",\"wb\") np.save(f,a) np.save(f,b) np.save(f,c) f.close()  f = file(\"tmp.bin\",\"rb\") aa = np.load(f) bb = np.load(f) cc = np.load(f) f.close()   To save multiple arrays in one file, you just need to open the file first, and then save or load the arrays in sequence.     ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  Another possibility to store numpy arrays efficiently is Bloscpack:  #!/usr/bin/python import numpy as np import bloscpack as bp import time  n = 10000000  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5 tsizeMB = sum(i.size*i.itemsize for i in (a,b,c)) / 2**20.  blosc_args = bp.DEFAULT_BLOSC_ARGS blosc_args['clevel'] = 6 t = time.time() bp.pack_ndarray_file(a, 'a.blp', blosc_args=blosc_args) bp.pack_ndarray_file(b, 'b.blp', blosc_args=blosc_args) bp.pack_ndarray_file(c, 'c.blp', blosc_args=blosc_args) t1 = time.time() - t print \"store time = %.2f (%.2f MB/s)\" % (t1, tsizeMB / t1)  t = time.time() a1 = bp.unpack_ndarray_file('a.blp') b1 = bp.unpack_ndarray_file('b.blp') c1 = bp.unpack_ndarray_file('c.blp') t1 = time.time() - t print \"loading time = %.2f (%.2f MB/s)\" % (t1, tsizeMB / t1)   and the output for my laptop (a relatively old MacBook Air with a Core2 processor):  $ python store-blpk.py store time = 0.19 (1216.45 MB/s) loading time = 0.25 (898.08 MB/s)   that means that it can store really fast, i.e. the bottleneck is typically the disk.  However, as the compression ratios are pretty good here, the effective speed is multiplied by the compression ratios.  Here are the sizes for these 76 MB arrays:  $ ll -h *.blp -rw-r--r--  1 faltet  staff   921K Mar  6 13:50 a.blp -rw-r--r--  1 faltet  staff   2.2M Mar  6 13:50 b.blp -rw-r--r--  1 faltet  staff   1.4M Mar  6 13:50 c.blp   Please note that the use of the Blosc compressor is fundamental for achieving this.  The same script but using 'clevel' = 0 (i.e. disabling compression):  $ python bench/store-blpk.py store time = 3.36 (68.04 MB/s) loading time = 2.61 (87.80 MB/s)   is clearly bottlenecked by the disk performance.     ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"best way to preserve numpy arrays on disk","A_Content":"  The lookup time is slow because when you use mmap to does not load content of array to memory when you invoke load method. Data is lazy loaded when particular data is needed.  And this happens in lookup in your case. But second lookup won`t be so slow.  This is nice feature of mmap when you have a big array you do not have to load whole data into memory.  To solve your can use joblib you can dump any object you want using joblib.dump even two or more numpy arrays, see the example  firstArray = np.arange(100) secondArray = np.arange(50) # I will put two arrays in dictionary and save to one file my_dict = {'first' : firstArray, 'second' : secondArray} joblib.dump(my_dict, 'file_name.dat')      ","Language":"Python","Tags":["python","numpy","pickle","binary-data","preserve"],"URL":"https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a fast way to preserve large numpy arrays. I want to save them to the disk in a binary format, then read them back into memory relatively fastly. cPickle is not fast enough, unfortunately.   I found numpy.savez and numpy.load. But the weird thing is, numpy.load loads a npy file into \"memory-map\". That means regular manipulating of arrays really slow. For example, something like this would be really slow:   #!/usr/bin/python import numpy as np; import time;  from tempfile import TemporaryFile  n = 10000000;  a = np.arange(n) b = np.arange(n) * 10 c = np.arange(n) * -0.5  file = TemporaryFile() np.savez(file,a = a, b = b, c = c);  file.seek(0) t = time.time() z = np.load(file) print \"loading time = \", time.time() - t  t = time.time() aa = z['a'] bb = z['b'] cc = z['c'] print \"assigning time = \", time.time() - t;   more precisely, the first line will be really fast, but the remaining lines that assign the arrays to obj are ridiculously slow:  loading time =  0.000220775604248 assining time =  2.72940087318   Is there any better way of preserving numpy arrays? Ideally, I want to be able to store multiple arrays in one file.      ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  You can use the python sorting functions' key parameter to sort the index array instead.  >>> s = [2, 3, 1, 4, 5] >>> sorted(range(len(s)), key=lambda k: s[k]) [2, 0, 1, 3, 4] >>>       ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"149","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  You can do this with numpy's argsort method if you have numpy available:  >>> import numpy >>> vals = numpy.array([2,3,1,4,5]) >>> vals array([2, 3, 1, 4, 5]) >>> sort_index = numpy.argsort(vals) >>> sort_index array([2, 0, 1, 3, 4])   If not available, taken from this question, this is the fastest method:  >>> vals = [2,3,1,4,5] >>> sorted(range(len(vals)), key=vals.__getitem__) [2, 0, 1, 3, 4]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"54","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  If you need both the sorted list and the list of indices, you could do:  >>> L = [2,3,1,4,5] >>> from operator import itemgetter >>> indices, L_sorted = zip(*sorted(enumerate(L), key=itemgetter(1))) >>> list(L_sorted) [1, 2, 3, 4, 5] >>> list(indices) [2, 0, 1, 3, 4]   Or, for Python <2.4 (no itemgetter or sorted):  >>> temp = [(v,i) for i,v in enumerate(L)] >>> temp.sort >>> indices, L_sorted = zip(*temp)   p.s. The zip(*iterable) idiom reverses the zip process (unzip).    Update:  To deal with your specific requirements:     \"my specific need to sort a list of objects based on a property of the objects. i then need to re-order a corresponding list to match the order of the newly sorted list.\"    That's a long-winded way of doing it. You can achieve that with a single sort by zipping both lists together then sort using the object property as your sort key (and unzipping after).  zipped = zip(obj_list, secondary_list) zipped_sorted = sorted(combined, key=lambda x: x[0].some_obj_attribute) obj_list, secondary_list = map(list, zip(*zipped_sorted))   Here's a simple example, using strings to represent your object. Here we use the length of the string as the key for sorting.:  >>> str_list = [\"banana\", \"apple\", \"nom\", \"Eeeeeeeeeeek\"] >>> sec_list = [0.123423, 9.231, 23, 10.11001] >>> temp = sorted(zip(str_list, sec_list), key=lambda x: len(x[0])) >>> str_list, sec_list = map(list, zip(*temp)) >>> str_list ['nom', 'apple', 'banana', 'Eeeeeeeeeeek'] >>> sec_list [23, 9.231, 0.123423, 10.11001]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  How about  l1 = [2,3,1,4,5] l2 = [l1.index(x) for x in sorted(l1)]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  you can use numpy.argsort  or you can do:  test =  [2,3,1,4,5] idxs = zip(*sorted([(val, i) for i, val in enumerate(test)]))[1]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  What I would do, looking at your specific need:  Say you have list a with some values, and your keys are in the attribute x of the objects stored in list b  keys = {i:j.x for i,j in zip(a, b)} a.sort(key=keys.__get_item__)   With this method you get your list ordered without having to construct the intermediate permutation list you were asking for.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"how to return index of a sorted list? [duplicate]","A_Content":"  Straight out of the documentation for collections.OrderedDict:  >>> # dictionary sorted by value >>> OrderedDict(sorted(d.items(), key=lambda t: t[1])) OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])   Adapted to the example in the original post:  >>> l=[2,3,1,4,5] >>> OrderedDict(sorted(enumerate(l), key=lambda x: x[1])).keys() [2, 0, 1, 3, 4]   See http://docs.python.org/library/collections.html#collections.OrderedDict for details.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-list","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Equivalent of Numpy.argsort() in basic python? [duplicate]                                        4 answers                                          I need  to sort a list and then return a list with the index of the sorted items in the list. For example, if the list I want to sort is [2,3,1,4,5], I need [2,0,1,3,4] to be returned.   This question was posted on bytes, but I thought I would repost it here. http://bytes.com/topic/python/answers/44513-sorting-list-then-return-index-sorted-item  My specific need to sort a list of objects based on a property of the objects. I then need to re-order a corresponding list to match the order of the newly sorted list.   Is there a good way to do this?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  SQLAlchemy's ORM is meant to be used together with the SQL layer, not hide it. But you do have to keep one or two things in mind when using the ORM and plain SQL in the same transaction. Basically, from one side, ORM data modifications will only hit the database when you flush the changes from your session. From the other side, SQL data manipulation statements don't affect the objects that are in your session.  So if you say  for c in session.query(Stuff).all():     c.foo = c.foo+1 session.commit()   it will do what it says, go fetch all the objects from the database, modify all the objects and then when it's time to flush the changes to the database, update the rows one by one.  Instead you should do this:  session.execute(update(stuff_table, values={stuff_table.c.foo: stuff_table.c.foo + 1})) session.commit()   This will execute as one query as you would expect, and because atleast the default session configuration expires all data in the session on commit you don't have any stale data issues.  In the almost-released 0.5 series you could also use this method for updating:  session.query(Stuff).update({Stuff.foo: Stuff.foo + 1}) session.commit()   That will basically run the same SQL statement as the previous snippet, but also select the changed rows and expire any stale data in the session. If you know you aren't using any session data after the update you could also add synchronize_session=False to the update statement and get rid of that select.     ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"138","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  session.query(Clients).filter(Clients.id == client_id_list).update({'status': status}) session.commit()   Try this =)     ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"67","_type":"dict","isAccepted":"No","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  There are several ways to UPDATE using sqlalchemy  1) for c in session.query(Stuff).all():        c.foo += 1    session.commit()  2) session.query().\\        update({\"foo\": (Stuff.foo + 1)})    session.commit()  3) conn = engine.connect()    stmt = Stuff.update().\\        values(Stuff.foo = (Stuff.foo + 1))    conn.execute(stmt)      ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  Here's an example of how to solve the same problem without having to map the fields manually:  from sqlalchemy import Column, ForeignKey, Integer, String, Date, DateTime, text, create_engine from sqlalchemy.exc import IntegrityError from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker from sqlalchemy.orm.attributes import InstrumentedAttribute  engine = create_engine('postgres://postgres@localhost:5432/database') session = sessionmaker() session.configure(bind=engine)  Base = declarative_base()   class Media(Base):   __tablename__ = 'media'   id = Column(Integer, primary_key=True)   title = Column(String, nullable=False)   slug = Column(String, nullable=False)   type = Column(String, nullable=False)    def update(self):     s = session()     mapped_values = {}     for item in Media.__dict__.iteritems():       field_name = item[0]       field_type = item[1]       is_column = isinstance(field_type, InstrumentedAttribute)       if is_column:         mapped_values[field_name] = getattr(self, field_name)      s.query(Media).filter(Media.id == self.id).update(mapped_values)     s.commit()   So to update a Media instance, you can do something like this:  media = Media(id=123, title=\"Titular Line\", slug=\"titular-line\", type=\"movie\") media.update()      ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  Withough testing, I'd try:  for c in session.query(Stuff).all():      c.foo = c.foo+1 session.commit()   (IIRC, commit() works without flush()).  I've found that at times doing a large query and then iterating in python can be up to 2 orders of magnitude faster than lots of queries.  I assume that iterating over the query object is less efficient than iterating over a list generated by the all() method of the query object.  [Please note comment below - this did not speed things up at all].     ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"Efficiently updating database using SQLAlchemy ORM","A_Content":"  If it is because of the overhead in terms of creating objects, then it probably can't be sped up at all with SA.  If it is because it is loading up related objects, then you might be able to do something with lazy loading.  Are there lots of objects being created due to references?  (IE, getting a Company object also gets all of the related People objects).     ","Language":"Python","Tags":["python","orm","sqlalchemy"],"URL":"https://stackoverflow.com/questions/270879/efficiently-updating-database-using-sqlalchemy-orm","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm starting a new application and looking at using an ORM -- in particular, SQLAlchemy.  Say I've got a column 'foo' in my database and I want to increment it.  In straight sqlite, this is easy:  db = sqlite3.connect('mydata.sqlitedb') cur = db.cursor() cur.execute('update table stuff set foo = foo + 1')   I figured out the SQLAlchemy SQL-builder equivalent:  engine = sqlalchemy.create_engine('sqlite:///mydata.sqlitedb') md = sqlalchemy.MetaData(engine) table = sqlalchemy.Table('stuff', md, autoload=True) upd = table.update(values={table.c.foo:table.c.foo+1}) engine.execute(upd)   This is slightly slower, but there's not much in it.  Here's my best guess for a SQLAlchemy ORM approach:  # snip definition of Stuff class made using declarative_base # snip creation of session object for c in session.query(Stuff):     c.foo = c.foo + 1 session.flush() session.commit()   This does the right thing, but it takes just under fifty times as long as the other two approaches.  I presume that's because it has to bring all the data into memory before it can work with it.  Is there any way to generate the efficient SQL using SQLAlchemy's ORM?  Or using any other python ORM?  Or should I just go back to writing the SQL by hand?     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  One option is a list comprehension:  [add(x, 2) for x in [1, 2, 3]]   More options:  a = [1, 2, 3]  import functools map(functools.partial(add, y=2), a)  import itertools map(add, a, itertools.repeat(2, len(a)))      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"124","_type":"dict","isAccepted":"Yes","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  Use a list comprehension.  [x + 2 for x in [1, 2, 3]]   If you really, really, really want to use map, give it an anonymous function as the first argument:  map(lambda x: x + 2, [1,2,3])      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  The docs explicitly suggest this is the main use for itertools.repeat:     Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for invariant parameters to the called function. Also used with zip() to create an invariant part of a tuple record.    And there's no reason for pass len([1,2,3]) as the times argument; map stops as soon as the first iterable is consumed, so an infinite iterable is perfectly fine:  >>> from operator import add >>> from itertools import repeat >>> list(map(add, [1,2,3], repeat(4))) [5, 6, 7]   In fact, this is equivalent to the example for repeat in the docs:  >>> list(map(pow, range(10), repeat(2))) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]   This makes for a nice lazy-functional-language-y solution that's also perfectly readable in Python-iterator terms.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  If you have it available, I would consider using numpy. It's very fast for these types of operations:  >>> import numpy >>> numpy.array([1,2,3]) + 2 array([3, 4, 5])   This is assuming your real application is doing mathematical operations (that can be vectorized).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  If you really really need to use map function (like my class assignment here...), you could use a wrapper function with 1 argument, passing the rest to the original one in its body; i.e. :  extraArguments = value def myFunc(arg):     # call the target function     return Func(arg, extraArguments)   map(myFunc, itterable)   Dirty & ugly, still does the trick     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  Sometimes I resolved similar situations (such as using pandas.apply method) using closures  In order to use them, you define a function which dynamically defines and returns a wrapper for your function, effectively making one of the parameters a constant.  Something like this:  def add(x, y):    return x + y  def add_constant(y):     def f(x):         return add(x, y)     return f   Then, add_constant(y) returns a function which can be used to add y to any given value:  >>> add_constant(2)(3) 5   Which allows you to use it in any situation where parameters are given one at a time:  >>> map(add_constant(2), [1,2,3]) [3, 4, 5]   edit  If you do not want to have to write the closure function somewhere else, you always have the possibility to build it on the fly using a lambda function:  >>> map(lambda x: add(x, 2), [1, 2, 3]) [3, 4, 5]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  The correct answer is simpler than you think. Simply do:  map(add, [(x, 2) for x in [1,2,3]])   And change the implementation of add to take a tuple i.e  def add(t):    x, y = t    return x+y   This can handle any complicated use case where both add parameters are dynamic.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  Map can contain multiple arguments, the standard way is   map(add, a, b)   In your question, it should be   map(add, a, [2]*len(a))      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  To pass multiple arguments to a map function.  def q(x,y):     return x*y  print map (q,range(0,10),range(10,20))   Here q is function with multiple argument that map() calls. Make sure, the length of both the ranges i.e.  len (range(a,a')) and len (range(b,b')) are equal.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  Another option is:  results = [] for x in [1,2,3]:     z = add(x,2)     ...     results += [f(z,x,y)]   This format is very useful when calling multiple functions.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"  In :nums = [1, 2, 3]  In :map(add, nums, [2]*len(nums))  Out:[3, 4, 5]     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"How to do multiple arguments to map function where one remains the same in python?","A_Content":"   def func(a, b, c, d):  return a + b * c % d  map(lambda x: func(*x), [[1,2,3,4], [5,6,7,8]])   By wrapping the function call with a lambda and using the star unpack, u can do map with arbitrary number of arguments.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Lets say we have a function add as follows  def add(x, y):     return x + y   we want to apply map function for an array   map(add, [1, 2, 3], 2)   The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.  Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.     ","Q_Votes":"81"},{"Q_Title":"Counterintuitive behaviour of int() in python","A_Content":"  There is no special reason. Python is simply applying its general principle of not performing implicit conversions, which are well-known causes of problems, particularly for newcomers, in languages such as Perl and Javascript.  int(some_string) is an explicit request to convert a string to integer format; the rules for this conversion specify that the string must contain a valid integer literal representation. int(float) is an explicit request to convert a float to an integer; the rules for this conversion specify that the float's fractional portion will be truncated.  In order for int(\"3.1459\") to return 3 the interpreter would have to implicitly convert the string to a float. Since Python doesn't support implicit conversions, it chooses to raise an exception instead.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/36085185/counterintuitive-behaviour-of-int-in-python","A_Votes":"124","_type":"dict","isAccepted":"Yes","Q_Content":"    It's clearly stated in the docs that int(number) is a flooring type conversion:  int(1.23) 1   and int(string) returns an int if and only if the string is an integer literal.  int('1.23') ValueError  int('1') 1   Is there any special reason for that? I find it counterintuitive that the function floors in one case, but not the other.     ","Q_Votes":"81"},{"Q_Title":"Counterintuitive behaviour of int() in python","A_Content":"  This is almost certainly a case of applying three of the principles from the Zen of Python:      Explicit is better implicit.       [...] practicality beats purity      Errors should never pass silently    Some percentage of the time, someone doing int('1.23') is calling the wrong conversion for their use case, and wants something like float or decimal.Decimal instead. In these cases, it's clearly better for them to get an immediate error that they can fix, rather than silently giving the wrong value.   In the case that you do want to truncate that to an int, it is trivial to explicitly do so by passing it through float first, and then calling one of int, round, trunc, floor or ceil as appropriate. This also makes your code more self-documenting, guarding against a later modification \"correcting\" a hypothetical silently-truncating int call to float by making it clear that the rounded value is what you want.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/36085185/counterintuitive-behaviour-of-int-in-python","A_Votes":"76","_type":"dict","isAccepted":"No","Q_Content":"    It's clearly stated in the docs that int(number) is a flooring type conversion:  int(1.23) 1   and int(string) returns an int if and only if the string is an integer literal.  int('1.23') ValueError  int('1') 1   Is there any special reason for that? I find it counterintuitive that the function floors in one case, but not the other.     ","Q_Votes":"81"},{"Q_Title":"Counterintuitive behaviour of int() in python","A_Content":"  Sometimes a thought experiment can be useful.   Behavior A: int('1.23') fails with an error.  This is the existing behavior. Behavior B: int('1.23') produces 1 without error.  This is what you're proposing.   With behavior A, it's straightforward and trivial to get the effect of behavior B: use int(float('1.23')) instead.  On the other hand, with behavior B, getting the effect of behavior A is significantly more complicated:  def parse_pure_int(s):     if \".\" in s:         raise ValueError(\"invalid literal for integer with base 10: \" + s)     return int(s)   (and even with the code above, I don't have complete confidence that there isn't some corner case that it mishandles.)  Behavior A therefore is more expressive than behavior B.  Another thing to consider: '1.23' is a string representation of a floating-point value.  Converting '1.23' to an integer conceptually involves two conversions (string to float to integer), but int(1.23) and int('1') each involve only one conversion.    Edit:  And indeed, there are corner cases that the above code would not handle: 1e-2 and 1E-2 are both floating point values too.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/36085185/counterintuitive-behaviour-of-int-in-python","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    It's clearly stated in the docs that int(number) is a flooring type conversion:  int(1.23) 1   and int(string) returns an int if and only if the string is an integer literal.  int('1.23') ValueError  int('1') 1   Is there any special reason for that? I find it counterintuitive that the function floors in one case, but not the other.     ","Q_Votes":"81"},{"Q_Title":"Counterintuitive behaviour of int() in python","A_Content":"  In simple words - they're not the same function.    int( decimal ) behaves as 'floor i.e. knock off the decimal portion and return as int'  int( string ) behaves as 'this text describes an integer, convert it and return as int'.   They are 2 different functions with the same name that return an integer but they are different functions.  'int' is short and easy to remember and its meaning applied to each type is intuitive to most programmers which is why they chose it.   There's no implication they are providing the same or combined functionality, they simply have the same name and return the same type. They could as easily be called 'floorDecimalAsInt' and 'convertStringToInt', but they went for 'int' because it's easy to remember, (99%) intuitive and confusion would rarely occur.  Parsing text as an Integer for text which included a decimal point such as \"4.5\" would throw an error in majority of computer languages and be expected to throw an error by majority of programmers, since the text-value does not represent an integer and implies they are providing erroneous data     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/36085185/counterintuitive-behaviour-of-int-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    It's clearly stated in the docs that int(number) is a flooring type conversion:  int(1.23) 1   and int(string) returns an int if and only if the string is an integer literal.  int('1.23') ValueError  int('1') 1   Is there any special reason for that? I find it counterintuitive that the function floors in one case, but not the other.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  The first one create a single lambda function and calls it ten times.  The second one doesn't call the function. It creates 10 different lambda functions. It puts all of those in a list. To make it equivalent to the first you need:  [(lambda x: x*x)(x) for x in range(10)]   Or better yet:  [x*x for x in range(10)]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"156","_type":"dict","isAccepted":"Yes","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  This question touches a very stinking part of the \"famous\" and \"obvious\" Python syntax - what takes precedence, the lambda, or the for of list comprehension.  I don't think the purpose of the OP was to generate a list of squares from 0 to 9. If that was the case, we could give even more solutions:  squares = [] for x in range(10): squares.append(x*x)    this is the good ol' way of imperative syntax.   But it's not the point. The point is W(hy)TF is this ambiguous expression so counter-intuitive? And I have an idiotic case for you at the end, so don't dismiss my answer too early (I had it on a job interview).  So, the OP's comprehension returned a list of lambdas:  [(lambda x: x*x) for x in range(10)]   This is of course just 10 different copies of the squaring function, see:  >>> [lambda x: x*x for _ in range(3)] [<function <lambda> at 0x00000000023AD438>, <function <lambda> at 0x00000000023AD4A8>, <function <lambda> at 0x00000000023AD3C8>]   Note the memory addresses of the lambdas - they are all different!  You could of course have a more \"optimal\" (haha) version of this expression:  >>> [lambda x: x*x] * 3 [<function <lambda> at 0x00000000023AD2E8>, <function <lambda> at 0x00000000023AD2E8>, <function <lambda> at 0x00000000023AD2E8>]   See? 3 time the same lambda.  Please note, that I used _ as the for variable. It has nothing to do with the x in the lambda (it is overshadowed lexically!). Get it?  I'm leaving out the discussion, why the syntax precedence is not so, that it all meant:  [lambda x: (x*x for x in range(10))]   which could be: [[0, 1, 4, ..., 81]], or [(0, 1, 4, ..., 81)], or which I find most logical, this would be a list of 1 element - a generator returning the values. It is just not the case, the language doesn't work this way.  BUT What, If...  What if you DON'T overshadow the for variable, AND use it in your lambdas???  Well, then crap happens. Look at this:  [lambda x: x * i for i in range(4)]   this means of course:  [(lambda x: x * i) for i in range(4)]   BUT it DOESN'T mean:  [(lambda x: x * 0), (lambda x: x * 1), ... (lambda x: x * 3)]   This is just crazy!  The lambdas in the list comprehension are a closure over the scope of this comprehension. A lexical closure, so they refer to the i via reference, and not its value when they were evaluated!  So, this expression:  [(lambda x: x * i) for i in range(4)]   IS roughly EQUIVALENT to:  [(lambda x: x * 3), (lambda x: x * 3), ... (lambda x: x * 3)]   I'm sure we could see more here using a python decompiler (by which I mean e.g. the dis module), but for Python-VM-agnostic discussion this is enough. So much for the job interview question.  Now, how to make a list of multiplier lambdas, which really multiply by consecutive integers? Well, similarly to the accepted answer, we need to break the direct tie to i by wrapping it in another lambda, which is getting called inside the list comprehension expression:  Before:  >>> a = [(lambda x: x * i) for i in (1, 2)] >>> a[1](1) 2 >>> a[0](1) 2   After:  >>> a = [(lambda y: (lambda x: y * x))(i) for i in (1, 2)] >>> a[1](1) 2 >>> a[0](1) 1   (I had the outer lambda variable also = i, but I decided this is the clearer solution - I introduced y so that we can all see which witch is which).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"49","_type":"dict","isAccepted":"No","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  The big difference is that the first example actually invokes the lambda f(x), while the second example doesn't.  Your first example is equivalent to [(lambda x: x*x)(x) for x in range(10)] while your second example is equivalent to [f for x in range(10)].     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  The first one   f = lambda x: x*x [f(x) for x in range(10)]   runs f() for each value in the range so it does f(x) for each value  the second one   [lambda x: x*x for x in range(10)]   runs the lambda for each value in the list, so it generates all of those functions.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  People gave good answers but forgot to mention the most important part in my opinion: In the second example the X of the list comprehension is NOT the same as the X of the lambda function, they are totally unrelated. So the second example is actually the same as:  [Lambda X: X*X for I in range(10)]   The internal iterations on range(10) are only responsible for creating 10 similar lambda functions in a list (10 separate functions but totally similar - returning the power 2 of each input).  On the other hand, the first example works totally different, because the X of the iterations DO interact with the results, for each iteration the value is X*X so the result would be [0,1,4,9,16,25, 36, 49, 64 ,81]     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Python: Lambda function in List Comprehensions","A_Content":"  The other answers are correct, but if you are trying to make a list of functions, each with a different parameter, that can be executed later, the following code will do that:  import functools a = [functools.partial(lambda x: x*x, x) for x in range(10)]  b = [] for i in a:     b.append(i())  In [26]: b Out[26]: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]   While the example is contrived, I found it useful when I wanted a list of functions that each print something different, i.e.  import functools a = [functools.partial(lambda x: print(x), x) for x in range(10)]  for i in a:     i()      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6076270/python-lambda-function-in-list-comprehensions","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Why is the output of the following two list comprehensions different, even though f and the lambda function are the same ?  f = lambda x: x*x [f(x) for x in range(10)]   and  [lambda x: x*x for x in range(10)]   Mind you, both type(f) and type(lambda x: x*x) return the same type.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  Use a single underscore prefix:  class _Internal:     ...   This is the official Python convention for 'internal' symbols; \"from module import *\" does not import underscore-prefixed objects.  Edit: Reference to the single underscore convention      ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"133","_type":"dict","isAccepted":"Yes","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  In short:   You cannot enforce privacy. There are no private classes/methods/functions in Python. At least, not strict privacy as in other languages, such as Java.  You can only indicate/suggest privacy. This follows a convention. The python convention for marking a class/function/method as private is to preface it with an _ (underscore). For example, def _myfunc() or class _MyClass:. You can also create pseudo-privacy by prefacing the method with two underscores (eg: __foo). You cannot access the method directly, but you can still call it through a special prefix using the classname (eg: _classname__foo). So the best you can do is indicate/suggest privacy, not enforce it.   Python is like perl in this respect. To paraphrase a famous line about privacy from the Perl book, the philosophy is that you should stay out of the living room because you weren't invited, not because it is defended with a shotgun.  For more information:   Private variables Python Documentation Private functions Dive into Python, by Mark Pilgrim Why are Pythons private methods not actually private? StackOverflow question 70528      ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"53","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  Define __all__, a list of names that you want to be exported (see documentation).  __all__ = ['public_class'] # don't add here the 'implementation_class'      ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  A pattern that I sometimes use is this:  Define a class:  class x(object):     def doThis(self):         ...     def doThat(self):         ...   Create an instance of the class, overwriting the class name:  x = x()   Define symbols that expose the functionality:  doThis = x.doThis doThat = x.doThat   Delete the instance itself:  del x   Now you have a module that only exposes your public functions.     ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  The convention is prepend \"_\" to internal classes, functions, and variables.     ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  To address the issue of design conventions, and as Christopher said, there's really no such thing as \"private\" in Python. This may sound twisted for someone coming from C/C++ background (like me a while back), but eventually, you'll probably realize following conventions is plenty enough.   Seeing something having an underscore in front should be a good enough hint not to use it directly. If you're concerned with cluttering help(MyClass) output (which is what everyone looks at when searching on how to use a class), the underscored attributes/classes are not included there, so you'll end up just having your \"public\" interface described.  Plus, having everything public has its own awesome perks, like for instance, you can unit test pretty much anything from outside (which you can't really do with C/C++ private constructs).     ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Private (implementation) class in Python","A_Content":"  Use two underscores to prefix names of \"private\" identifiers. For classes in a module, use a single leading underscore and they will not be imported using \"from module import *\".  class _MyInternalClass:     def __my_private_method:         pass   (There is no such thing as true \"private\" in Python. For example, Python just automatically mangles the names of class members with double underscores to be __clssname_mymember. So really, if you know the mangled name you can use the \"private\" entity anyway. See here. And of course you can choose to manually import \"internal\" classes if you wanted to).     ","Language":"Python","Tags":["python","design","access-modifiers"],"URL":"https://stackoverflow.com/questions/551038/private-implementation-class-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am coding a small Python module composed of two parts:   some functions defining a public interface, an implementation class used by the above functions, but which is not meaningful outside the module.   At first, I decided to \"hide\" this implementation class by defining it inside the function using it, but this hampers readability and cannot be used if multiple functions reuse the same class.  So, in addition to comments and docstrings, is there a mechanism to mark a class as \"private\" or \"internal\"? I am aware of the underscore mechanism, but as I understand it it only applies to variables, function and methods name.     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  Easiest way: math.factorial(x) (available in 2.6 and above).  If you want/have to write it yourself, use something like  def factorial(n):return reduce(lambda x,y:x*y,[1]+range(1,n+1))   or something more readable:  def factorial(n):     if n == 0:         return 1     else:         return n * factorial(n-1)   As always, Google is your friend ;)     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"125","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  On Python 2.6 and up, try:  import math math.factorial(n)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"72","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  Not really necessary since this is such an old thread. But I did here is another way to compute the factorial of an integer using a while loop.   def factorial(n):     num = 1     while n >= 1:         num = num * n         n = n - 1     return num      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  Existing solution  The shortest and probably the fastest solution is:  from math import factorial print factorial(1000)   Building your own  You can also build your own solution. Generally you have two approaches. The one that suits me best is:  from itertools import imap def factorial(x):     return reduce(long.__mul__, imap(long, xrange(1, x + 1)))  print factorial(1000)   (it works also for bigger numbers, when the result becomes long)  The second way of achieving the same is:  def factorial(x):     result = 1     for i in xrange(2, x + 1):         result *= i     return result  print factorial(1000)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  If you are using Python2.5 or older try  from operator import mul def factorial(n):     return reduce(mul, range(1,n+1))   for newer Python, there is factorial in the math module as given in other answers here     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  def factorial(n):     if n < 2:         return 1     return n * factorial(n - 1)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  Just another method for computing the factorial using a for-loop -   def factorial(n):     base = 1     for i in range(n,0,-1):         base = base * i     print base      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  You mean:  def fact(n):   f = 1   for i in range(1, n +1):    f *= i   return f     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  http://www.google.com/search?aq=0&oq=factorial+py&sourceid=chrome&ie=UTF-8&q=factorial+python  import math math.factorial( yourInt )      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"      For performance reasons, please do not use recursion. It would be disastrous.  def fact(n, total=1):     while True:         if n == 1:             return total         n, total = n - 1, total * n       Check running results  cProfile.run('fact(126000)')     4 function calls in 5.164 seconds   Using the stack is convenient(like recursive call), but it comes at a cost: storing detailed information can take up a lot of memory.  If the stack is high, it means that the computer stores a lot of information about function calls.  The method only takes up constant memory(like iteration).      Or Using for loop  def fact(n):     result = 1     for i in range(2, n + 1):         result *= i     return result       Check running results  cProfile.run('fact(126000)')     4 function calls in 4.708 seconds         Or Using builtin function math  def fact(n):     return math.factorial(n)       Check running results  cProfile.run('fact(126000)')     5 function calls in 0.272 seconds      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  def factorial(n):     result = 1     i = n * (n -1)     while n >= 1:         result = result * n         n = n - 1     return result  print (factorial(10)) #prints 3628800      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  A lot of these methods are very good but I would say your best bet is always to use the built in function. However there are some very easily creatable ones by yourself if you want to see what is going on. A quick one I came up with is much the same as many of them here.  def factorial(n):     x = 1     li = list(range(1, n + 1))     for each in li:         x = x * each     print(x)   This is a rather efficient code, the advantage being that a list is created if you wan't to manipulate some data from the list although im not to sure why you would really.     Edit: Only just saw that I posted this on an old thing. Sorry.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"Function for Factorial in Python","A_Content":"  Loops and recursion (also a form of a loop) are slow. So though probably not considered best practices, consider trying this one out:  # Factorials are really just a range of numbers  # multiplied by each other.  #  # So this one liners: # 1) onverts a range (1,2,3...) to a string,  # 2) removes the leading & closing brackets, and  # 3) then multiplies the results together using eval.  factorial = eval(str(range(1,n+1)).replace(', ','*')[1:-1:])   All in just good fun.  Thanks and Best!     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/5136447/function-for-factorial-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    How do I go about computing a factorial of an integer in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  You could use an import and single line code like this:  import ctypes  # An included library with Python install.    ctypes.windll.user32.MessageBoxW(0, \"Your text\", \"Your title\", 1)   Or define a function (Mbox) like so:  import ctypes  # An included library with Python install. def Mbox(title, text, style):     return ctypes.windll.user32.MessageBoxW(0, text, title, style) Mbox('Your title', 'Your text', 1)   Note the styles are as follows:  ##  Styles: ##  0 : OK ##  1 : OK | Cancel ##  2 : Abort | Retry | Ignore ##  3 : Yes | No | Cancel ##  4 : Yes | No ##  5 : Retry | No  ##  6 : Cancel | Try Again | Continue   Have fun!  Note: edited to use MessageBoxW instead of MessageBoxA     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"174","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  Have you looked at easygui?  import easygui  easygui.msgbox(\"This is a message!\", title=\"simple gui\")      ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  Also you can position the other window before withdrawing it so that you position your message  #!/usr/bin/env python  from Tkinter import * import tkMessageBox  window = Tk() window.wm_withdraw()  #message at x:200,y:200 window.geometry(\"1x1+200+200\")#remember its .geometry(\"WidthxHeight(+or-)X(+or-)Y\") tkMessageBox.showerror(title=\"error\",message=\"Error Message\",parent=window)  #centre screen message window.geometry(\"1x1+\"+str(window.winfo_screenwidth()/2)+\"+\"+str(window.winfo_screenheight()/2)) tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")      ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  The code you presented is fine! You just need to explicitly create the \"other window in the background\" and hide it, with this code:  import Tkinter window = Tkinter.Tk() window.wm_withdraw()   Right before your messagebox.     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  On Mac, the python standard library has a module called EasyDialogs. There is also a (ctypes based) windows version at http://www.averdevelopment.com/python/EasyDialogs.html  If it matters to you: it uses native dialogs and doesn't depend on Tkinter like the already mentioned easygui, but it might not have as much features.     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  In Windows, you can use ctypes with user32 library:  from ctypes import c_int, WINFUNCTYPE, windll from ctypes.wintypes import HWND, LPCSTR, UINT prototype = WINFUNCTYPE(c_int, HWND, LPCSTR, LPCSTR, UINT) paramflags = (1, \"hwnd\", 0), (1, \"text\", \"Hi\"), (1, \"caption\", None), (1, \"flags\", 0) MessageBox = prototype((\"MessageBoxA\", windll.user32), paramflags)  MessageBox() MessageBox(text=\"Spam, spam, spam\") MessageBox(flags=2, text=\"foo bar\")      ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  The PyMsgBox module does exactly this. It has message box functions that follow the naming conventions of JavaScript: alert(), confirm(), prompt() and password() (which is prompt() but uses * when you type). These function calls block until the user clicks an OK/Cancel button. It's a cross-platform, pure Python module with no dependencies.  Install with: pip install PyMsgBox  Sample usage:  >>> import pymsgbox >>> pymsgbox.alert('This is an alert!', 'Title') >>> response = pymsgbox.prompt('What is your name?')   Full documentation at http://pymsgbox.readthedocs.org/en/latest/     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  import ctypes ctypes.windll.user32.MessageBoxW(0, \"Your text\", \"Your title\", 1)   The last number (here 1) can be change to change window style (not only buttons!):    ## Button styles: # 0 : OK # 1 : OK | Cancel # 2 : Abort | Retry | Ignore # 3 : Yes | No | Cancel # 4 : Yes | No # 5 : Retry | No  # 6 : Cancel | Try Again | Continue  ## To also change icon, add these values to previous number # 16 Stop-sign icon # 32 Question-mark icon # 48 Exclamation-point icon # 64 Information-sign icon consisting of an 'i' in a circle   For example,  ctypes.windll.user32.MessageBoxW(0, \"That's an error\", \"Warning!\", 16)   will give this.     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  Use  from tkinter.messagebox import * Message([master], title=\"[title]\", message=\"[message]\")   The master window has to be created before. This is for Python 3. This is not fot wxPython, but for tkinter.     ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  import sys from tkinter import * def mhello():     pass     return  mGui = Tk() ment = StringVar()  mGui.geometry('450x450+500+300') mGui.title('My youtube Tkinter')  mlabel = Label(mGui,text ='my label').pack()  mbutton = Button(mGui,text ='ok',command = mhello,fg = 'red',bg='blue').pack()  mEntry = entry().pack       ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  Not the best, here is my basic Message box using only tkinter.  #Python 3.4 from    tkinter import  messagebox  as  msg; import  tkinter as      tk;  def MsgBox(title, text, style):     box = [         msg.showinfo,       msg.showwarning,    msg.showerror,         msg.askquestion,    msg.askyesno,       msg.askokcancel,        msg.askretrycancel, ];  tk.Tk().withdraw(); #Hide Main Window.  if style in range(7):     return box[style](title, text);  if __name__ == '__main__':  Return = MsgBox(#Use Like This.     'Basic Error Exemple',      ''.join( [         'The Basic Error Exemple a problem with test',                      '\\n',         'and is unable to continue. The application must close.',           '\\n\\n',         'Error code Test',                                                  '\\n',         'Would you like visit http://wwww.basic-error-exemple.com/ for',    '\\n',         'help?',     ] ),      2, );  print( Return );  \"\"\" Style   |   Type        |   Button      |   Return ------------------------------------------------------ 0           Info            Ok              'ok' 1           Warning         Ok              'ok' 2           Error           Ok              'ok' 3           Question        Yes/No          'yes'/'no' 4           YesNo           Yes/No          True/False 5           OkCancel        Ok/Cancel       True/False 6           RetryCancal     Retry/Cancel    True/False \"\"\"      ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How can I create a simple message box in Python?","A_Content":"  check out my python module: pip install quickgui  (Requires wxPython, but requires no knowledge of wxPython) https://pypi.python.org/pypi/quickgui  Can create any numbers of inputs,(ratio, checkbox, inputbox), auto arrange them on a single gui.      ","Language":"Python","Tags":["python","wxpython","tkinter"],"URL":"https://stackoverflow.com/questions/2963263/how-can-i-create-a-simple-message-box-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for the same effect as alert() in JavaScript.  I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).  I've tried tkMessageBox:  import tkMessageBox tkMessageBox.showinfo(title=\"Greetings\", message=\"Hello World!\")   but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?     ","Q_Votes":"81"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  This is a great module that someone created. I've used it several times.  http://code.activestate.com/recipes/410469-xml-as-dictionary/  Here is the code from the website just in case the link goes bad.   import cElementTree as ElementTree  class XmlListConfig(list):     def __init__(self, aList):         for element in aList:             if element:                 # treat like dict                 if len(element) == 1 or element[0].tag != element[1].tag:                     self.append(XmlDictConfig(element))                 # treat like list                 elif element[0].tag == element[1].tag:                     self.append(XmlListConfig(element))             elif element.text:                 text = element.text.strip()                 if text:                     self.append(text)   class XmlDictConfig(dict):     '''     Example usage:      >>> tree = ElementTree.parse('your_file.xml')     >>> root = tree.getroot()     >>> xmldict = XmlDictConfig(root)      Or, if you want to use an XML string:      >>> root = ElementTree.XML(xml_string)     >>> xmldict = XmlDictConfig(root)      And then use xmldict for what it is... a dict.     '''     def __init__(self, parent_element):         if parent_element.items():             self.update(dict(parent_element.items()))         for element in parent_element:             if element:                 # treat like dict - we assume that if the first two tags                 # in a series are different, then they are all different.                 if len(element) == 1 or element[0].tag != element[1].tag:                     aDict = XmlDictConfig(element)                 # treat like list - we assume that if the first two tags                 # in a series are the same, then the rest are the same.                 else:                     # here, we put the list in dictionary; the key is the                     # tag name the list elements all share in common, and                     # the value is the list itself                      aDict = {element[0].tag: XmlListConfig(element)}                 # if the tag has attributes, add those to the dict                 if element.items():                     aDict.update(dict(element.items()))                 self.update({element.tag: aDict})             # this assumes that if you've got an attribute in a tag,             # you won't be having any text. This may or may not be a              # good idea -- time will tell. It works for the way we are             # currently doing XML configuration files...             elif element.items():                 self.update({element.tag: dict(element.items())})             # finally, if there are no child tags and no attributes, extract             # the text             else:                 self.update({element.tag: element.text})   Example usage:  tree = ElementTree.parse('your_file.xml') root = tree.getroot() xmldict = XmlDictConfig(root)   //Or, if you want to use an XML string:  root = ElementTree.XML(xml_string) xmldict = XmlDictConfig(root)      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"38","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  xmltodict (full disclosure: I wrote it) does exactly that:  xmltodict.parse(\"\"\" <?xml version=\"1.0\" ?> <person>   <name>john</name>   <age>20</age> </person>\"\"\") # {u'person': {u'age': u'20', u'name': u'john'}}      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"201","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  The following XML-to-Python-dict snippet parses entities as well as attributes following this XML-to-JSON \"specification\". It is the most general solution handling all cases of XML.  from collections import defaultdict  def etree_to_dict(t):     d = {t.tag: {} if t.attrib else None}     children = list(t)     if children:         dd = defaultdict(list)         for dc in map(etree_to_dict, children):             for k, v in dc.items():                 dd[k].append(v)         d = {t.tag: {k:v[0] if len(v) == 1 else v for k, v in dd.items()}}     if t.attrib:         d[t.tag].update(('@' + k, v) for k, v in t.attrib.items())     if t.text:         text = t.text.strip()         if children or t.attrib:             if text:               d[t.tag]['#text'] = text         else:             d[t.tag] = text     return d   It is used:  from xml.etree import cElementTree as ET e = ET.XML(''' <root>   <e />   <e>text</e>   <e name=\"value\" />   <e name=\"value\">text</e>   <e> <a>text</a> <b>text</b> </e>   <e> <a>text</a> <a>text</a> </e>   <e> text <a>text</a> </e> </root> ''')  from pprint import pprint pprint(etree_to_dict(e))   The output of this example (as per above-linked \"specification\") should be:  {'root': {'e': [None,                 'text',                 {'@name': 'value'},                 {'#text': 'text', '@name': 'value'},                 {'a': 'text', 'b': 'text'},                 {'a': ['text', 'text']},                 {'#text': 'text', 'a': 'text'}]}}   Not necessarily pretty, but it is unambiguous, and simpler XML inputs result in simpler JSON. :)    Update  If you want to do the reverse, emit an XML string from a JSON/dict, you can use:  try:   basestring except NameError:  # python3   basestring = str  def dict_to_etree(d):     def _to_etree(d, root):         if not d:             pass         elif isinstance(d, basestring):             root.text = d         elif isinstance(d, dict):             for k,v in d.items():                 assert isinstance(k, basestring)                 if k.startswith('#'):                     assert k == '#text' and isinstance(v, basestring)                     root.text = v                 elif k.startswith('@'):                     assert isinstance(v, basestring)                     root.set(k[1:], v)                 elif isinstance(v, list):                     for e in v:                         _to_etree(e, ET.SubElement(root, k))                 else:                     _to_etree(v, ET.SubElement(root, k))         else:             raise TypeError('invalid type: ' + str(type(d)))     assert isinstance(d, dict) and len(d) == 1     tag, body = next(iter(d.items()))     node = ET.Element(tag)     _to_etree(body, node)     return ET.tostring(node)  pprint(dict_to_etree(d))      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  This lightweight version, while not configurable, is pretty easy to tailor as needed, and works in old pythons.  Also it is rigid - meaning the results are the same regardless of the existence of attributes.  import xml.etree.ElementTree as ET  from copy import copy  def dictify(r,root=True):     if root:         return {r.tag : dictify(r, False)}     d=copy(r.attrib)     if r.text:         d[\"_text\"]=r.text     for x in r.findall(\"./*\"):         if x.tag not in d:             d[x.tag]=[]         d[x.tag].append(dictify(x,False))     return d   So:  root = ET.fromstring(\"<erik><a x='1'>v</a><a y='2'>w</a></erik>\")  dictify(root)   Results in:  {'erik': {'a': [{'x': '1', '_text': 'v'}, {'y': '2', '_text': 'w'}]}}      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  The most recent versions of the PicklingTools libraries (1.3.0 and 1.3.1) support tools for converting from XML to a Python dict.  The download is available here:  PicklingTools 1.3.1  There is quite a bit of documentation for the converters here: the documentation describes in detail all of the decisions and issues that will arise when converting between XML and Python dictionaries (there are a number of edge cases: attributes, lists, anonymous lists, anonymous dicts, eval, etc. that most converters don't handle).  In general, though, the converters are easy to use.  If an 'example.xml' contains:  <top>   <a>1</a>   <b>2.2</b>   <c>three</c> </top>   Then to convert it to a dictionary:  >>> from xmlloader import * >>> example = file('example.xml', 'r')   # A document containing XML >>> xl = StreamXMLLoader(example, 0)     # 0 = all defaults on operation >>> result = xl.expect XML() >>> print result {'top': {'a': '1', 'c': 'three', 'b': '2.2'}}   There are tools for converting in both C++ and Python: the C++ and Python do indentical conversion, but the C++ is about 60x faster     ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  You can do this quite easily with lxml. First install it:  [sudo] pip install lxml   Here is a recursive function I wrote that does the heavy lifting for you:  from lxml import objectify as xml_objectify   def xml_to_dict(xml_str):     \"\"\" Convert xml to dict, using lxml v3.4.2 xml processing library \"\"\"     def xml_to_dict_recursion(xml_object):         dict_object = xml_object.__dict__         if not dict_object:             return xml_object         for key, value in dict_object.items():             dict_object[key] = xml_to_dict_recursion(value)         return dict_object     return xml_to_dict_recursion(xml_objectify.fromstring(xml_str))  xml_string = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><Response><NewOrderResp> <IndustryType>Test</IndustryType><SomeData><SomeNestedData1>1234</SomeNestedData1> <SomeNestedData2>3455</SomeNestedData2></SomeData></NewOrderResp></Response>\"\"\"  print xml_to_dict(xml_string)   The below variant preserves the parent key / element:  def xml_to_dict(xml_str):     \"\"\" Convert xml to dict, using lxml v3.4.2 xml processing library, see http://lxml.de/ \"\"\"     def xml_to_dict_recursion(xml_object):         dict_object = xml_object.__dict__         if not dict_object:  # if empty dict returned             return xml_object         for key, value in dict_object.items():             dict_object[key] = xml_to_dict_recursion(value)         return dict_object     xml_obj = objectify.fromstring(xml_str)     return {xml_obj.tag: xml_to_dict_recursion(xml_obj)}   If you want to only return a subtree and convert it to dict, you can use Element.find() to get the subtree and then convert it:   xml_obj.find('.//')  # lxml.objectify.ObjectifiedElement instance   See the lxml docs here. I hope this helps!     ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  The easiest to use XML parser for Python is ElementTree (as of 2.5x and above it is in the standard library xml.etree.ElementTree). I don't think there is anything that does exactly what you want out of the box. It would be pretty trivial to write something to do what you want using ElementTree, but why convert to a dictionary, and why not just use ElementTree directly.     ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  def xml_to_dict(node):     u'''      @param node:lxml_node     @return: dict      '''      return {'tag': node.tag, 'text': node.text, 'attrib': node.attrib, 'children': {child.tag: xml_to_dict(child) for child in node}}      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  The code from http://code.activestate.com/recipes/410469-xml-as-dictionary/ works well, but if there are multiple elements that are the same at a given place in the hierarchy it just overrides them.  I added a shim between that looks to see if the element already exists before self.update().  If so, pops the existing entry and creates a lists out of the existing and the new.  Any subsequent duplicates are added to the list.  Not sure if this can be handled more gracefully, but it works:  import xml.etree.ElementTree as ElementTree  class XmlDictConfig(dict):     def __init__(self, parent_element):         if parent_element.items():             self.updateShim(dict(parent_element.items()))         for element in parent_element:             if len(element):                 aDict = XmlDictConfig(element)                 if element.items():                     aDict.updateShim(dict(element.items()))                 self.updateShim({element.tag: aDict})             elif element.items():                 self.updateShim({element.tag: dict(element.items())})             else:                 self.updateShim({element.tag: element.text.strip()})      def updateShim (self, aDict ):         for key in aDict.keys():             if key in self:                 value = self.pop(key)                 if type(value) is not list:                     listOfDicts = []                     listOfDicts.append(value)                     listOfDicts.append(aDict[key])                     self.update({key: listOfDicts})                  else:                     value.append(aDict[key])                     self.update({key: value})             else:                 self.update(aDict)      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  Disclaimer: This modified XML parser was inspired by Adam Clark  The original XML parser works for most of simple cases. However, it didn't work for some complicated XML files. I debugged the code line by line and finally fixed some issues. If you find some bugs, please let me know. I am glad to fix it.  class XmlDictConfig(dict):       '''        Note: need to add a root into if no exising         Example usage:     >>> tree = ElementTree.parse('your_file.xml')     >>> root = tree.getroot()     >>> xmldict = XmlDictConfig(root)     Or, if you want to use an XML string:     >>> root = ElementTree.XML(xml_string)     >>> xmldict = XmlDictConfig(root)     And then use xmldict for what it is... a dict.     '''     def __init__(self, parent_element):         if parent_element.items():             self.updateShim( dict(parent_element.items()) )         for element in parent_element:             if len(element):                 aDict = XmlDictConfig(element)             #   if element.items():             #   aDict.updateShim(dict(element.items()))                 self.updateShim({element.tag: aDict})             elif element.items():    # items() is specialy for attribtes                 elementattrib= element.items()                 if element.text:                                elementattrib.append((element.tag,element.text ))     # add tag:text if there exist                 self.updateShim({element.tag: dict(elementattrib)})             else:                 self.updateShim({element.tag: element.text})      def updateShim (self, aDict ):         for key in aDict.keys():   # keys() includes tag and attributes             if key in self:                 value = self.pop(key)                 if type(value) is not list:                     listOfDicts = []                     listOfDicts.append(value)                     listOfDicts.append(aDict[key])                     self.update({key: listOfDicts})                 else:                     value.append(aDict[key])                     self.update({key: value})             else:                 self.update({key:aDict[key]})  # it was self.update(aDict)          ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  Here's a link to an ActiveState solution - and the code in case it disappears again.  ================================================== xmlreader.py: ================================================== from xml.dom.minidom import parse   class NotTextNodeError:     pass   def getTextFromNode(node):     \"\"\"     scans through all children of node and gathers the     text. if node has non-text child-nodes, then     NotTextNodeError is raised.     \"\"\"     t = \"\"     for n in node.childNodes:     if n.nodeType == n.TEXT_NODE:         t += n.nodeValue     else:         raise NotTextNodeError     return t   def nodeToDic(node):     \"\"\"     nodeToDic() scans through the children of node and makes a     dictionary from the content.     three cases are differentiated:     - if the node contains no other nodes, it is a text-node     and {nodeName:text} is merged into the dictionary.     - if the node has the attribute \"method\" set to \"true\",     then it's children will be appended to a list and this     list is merged to the dictionary in the form: {nodeName:list}.     - else, nodeToDic() will call itself recursively on     the nodes children (merging {nodeName:nodeToDic()} to     the dictionary).     \"\"\"     dic = {}      for n in node.childNodes:     if n.nodeType != n.ELEMENT_NODE:         continue     if n.getAttribute(\"multiple\") == \"true\":         # node with multiple children:         # put them in a list         l = []         for c in n.childNodes:             if c.nodeType != n.ELEMENT_NODE:             continue         l.append(nodeToDic(c))             dic.update({n.nodeName:l})         continue      try:         text = getTextFromNode(n)     except NotTextNodeError:             # 'normal' node             dic.update({n.nodeName:nodeToDic(n)})             continue          # text node         dic.update({n.nodeName:text})     continue     return dic   def readConfig(filename):     dom = parse(filename)     return nodeToDic(dom)      def test():     dic = readConfig(\"sample.xml\")      print dic[\"Config\"][\"Name\"]     print     for item in dic[\"Config\"][\"Items\"]:     print \"Item's Name:\", item[\"Name\"]     print \"Item's Value:\", item[\"Value\"]  test()    ================================================== sample.xml: ================================================== <?xml version=\"1.0\" encoding=\"UTF-8\"?>  <Config>     <Name>My Config File</Name>      <Items multiple=\"true\">     <Item>         <Name>First Item</Name>         <Value>Value 1</Value>     </Item>     <Item>         <Name>Second Item</Name>         <Value>Value 2</Value>     </Item>     </Items>  </Config>    ================================================== output: ================================================== My Config File  Item's Name: First Item Item's Value: Value 1 Item's Name: Second Item Item's Value: Value 2      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  From @K3---rnc response (the best for me) I've added a small modifications to get an OrderedDict from an XML text (some times order matters):  def etree_to_ordereddict(t): d = OrderedDict() d[t.tag] = OrderedDict() if t.attrib else None children = list(t) if children:     dd = OrderedDict()     for dc in map(etree_to_ordereddict, children):         for k, v in dc.iteritems():             if k not in dd:                 dd[k] = list()             dd[k].append(v)     d = OrderedDict()     d[t.tag] = OrderedDict()     for k, v in dd.iteritems():         if len(v) == 1:             d[t.tag][k] = v[0]         else:             d[t.tag][k] = v if t.attrib:     d[t.tag].update(('@' + k, v) for k, v in t.attrib.iteritems()) if t.text:     text = t.text.strip()     if children or t.attrib:         if text:             d[t.tag]['#text'] = text     else:         d[t.tag] = text return d   Following @K3---rnc example, you can use it:  from xml.etree import cElementTree as ET e = ET.XML(''' <root>   <e />   <e>text</e>   <e name=\"value\" />   <e name=\"value\">text</e>   <e> <a>text</a> <b>text</b> </e>   <e> <a>text</a> <a>text</a> </e>   <e> text <a>text</a> </e> </root> ''')  from pprint import pprint pprint(etree_to_ordereddict(e))   Hope it helps ;)     ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  At one point I had to parse and write XML that only consisted of elements without attributes so a 1:1 mapping from XML to dict was possible easily. This is what I came up with in case someone else also doesnt need attributes:  def xmltodict(element):     if not isinstance(element, ElementTree.Element):         raise ValueError(\"must pass xml.etree.ElementTree.Element object\")      def xmltodict_handler(parent_element):         result = dict()         for element in parent_element:             if len(element):                 obj = xmltodict_handler(element)             else:                 obj = element.text              if result.get(element.tag):                 if hasattr(result[element.tag], \"append\"):                     result[element.tag].append(obj)                 else:                     result[element.tag] = [result[element.tag], obj]             else:                 result[element.tag] = obj         return result      return {element.tag: xmltodict_handler(element)}   def dicttoxml(element):     if not isinstance(element, dict):         raise ValueError(\"must pass dict type\")     if len(element) != 1:         raise ValueError(\"dict must have exactly one root key\")      def dicttoxml_handler(result, key, value):         if isinstance(value, list):             for e in value:                 dicttoxml_handler(result, key, e)         elif isinstance(value, basestring):             elem = ElementTree.Element(key)             elem.text = value             result.append(elem)         elif isinstance(value, int) or isinstance(value, float):             elem = ElementTree.Element(key)             elem.text = str(value)             result.append(elem)         elif value is None:             result.append(ElementTree.Element(key))         else:             res = ElementTree.Element(key)             for k, v in value.items():                 dicttoxml_handler(res, k, v)             result.append(res)      result = ElementTree.Element(element.keys()[0])     for key, value in element[element.keys()[0]].items():         dicttoxml_handler(result, key, value)     return result  def xmlfiletodict(filename):     return xmltodict(ElementTree.parse(filename).getroot())  def dicttoxmlfile(element, filename):     ElementTree.ElementTree(dicttoxml(element)).write(filename)  def xmlstringtodict(xmlstring):     return xmltodict(ElementTree.fromstring(xmlstring).getroot())  def dicttoxmlstring(element):     return ElementTree.tostring(dicttoxml(element))      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  @dibrovsd: Solution will not work if the xml have more than one tag with same name  On your line of thought, I have modified the code a bit and written it for general node instead of root:  from collections import defaultdict def xml2dict(node):     d, count = defaultdict(list), 1     for i in node:         d[i.tag + \"_\" + str(count)]['text'] = i.findtext('.')[0]         d[i.tag + \"_\" + str(count)]['attrib'] = i.attrib # attrib gives the list         d[i.tag + \"_\" + str(count)]['children'] = xml2dict(i) # it gives dict      return d      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"How to convert an xml string to a dictionary in Python?","A_Content":"  I have a recursive method to get a dictionary from a lxml element      def recursive_dict(element):         return (element.tag.split('}')[1],                 dict(map(recursive_dict, element.getchildren()),                      **element.attrib))      ","Language":"Python","Tags":["python","xml","json","dictionary","xml-deserialization"],"URL":"https://stackoverflow.com/questions/2148119/how-to-convert-an-xml-string-to-a-dictionary-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.  Take as an example:  str =\"<?xml version=\"1.0\" ?><person><name>john</name><age>20</age></person\" dic_xml = convert_to_dic(str)   Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }     ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I had the same problem (though on Linux). The solution was quite simple - add:  libraries: - name: pycrypto   version: \"2.6\"   to my app.yaml file. Since this worked correctly in the past, I assume this is a new requirement.     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"43","_type":"dict","isAccepted":"Yes","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I had the same problem on my Mac when installing with pip. I then removed pycrypto and installed it again with easy_install, like this:  pip uninstall pycrypto easy_install pycrypto   also as Luke commented: If you have trouble running these commands, be sure to run them as admin (sudo)   Hope this helps!     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"160","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I ran into this on Mac as well, and it seems to be related to having an unfortunately similarly named \"crypto\" module (not sure what that is for) installed alongside of pycrypto via pip.  The fix seems to be removing both crypto and pycrypto with pip:  sudo pip uninstall crypto sudo pip uninstall pycrypto   and reinstalling pycrypto:  sudo pip install pycrypto   Now it works as expected when I do something like:  from Crypto.Cipher import AES      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"69","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  On the mac... if you run into this.. try to see if you can import crypto instead?  If so.. the package name is the issue C vs c.  To get around this.. just add these lines to the top of your script.  import crypto import sys sys.modules['Crypto'] = crypto   You know should be able to import paramiko successfully.     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  type command:  sudo pip install pycrypto      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I found the solution. Issue is probably in case sensitivity (on Windows).  Just change the name of the folder:    C:\\Python27\\Lib\\site-packages\\crypto to: C:\\Python27\\Lib\\site-packages\\Crypto   This is how folder was named after installation of pycrypto:   I've changed it to:   And now the following code works fine:      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I've had the same problem 'ImportError: No module named Crypto.Cipher', since using GoogleAppEngineLauncher (version > 1.8.X) with GAE Boilerplate on OSX 10.8.5 (Mountain Lion). In Google App Engine SDK with python 2.7 runtime, pyCrypto 2.6 is the suggested version.  The solution that worked for me was...  1) Download pycrypto2.6 source extract it somewhere(~/Downloads/pycrypto26)  e.g., git clone https://github.com/dlitz/pycrypto.git  2) cd (cd ~/Downloads/pycrypto26)  then   3) Execute the following terminal command inside the previous folder in order to install pyCrypto 2.6 manually in GAE folder.    sudo python setup.py install --install-lib /Applications/GoogleAppEngineLauncher.app/Contents/Resources/GoogleAppEngine-default.bundle/Contents/Resources/google_appengine      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  if you are using redhat,fedora, centos :  sudo yum  install pycrypto  for my case I coouldnot install it using pip     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  Uninstalling crypto and pycrypto works on me. Then install only pycrypto. pip uninstall crypto  pip uninstall pycrypto  pip install pycrypto     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  Try with pip3:  sudo pip3 install pycrypto      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  It could be a problem of loading python modules installed via pip. Refer to this answer Can't load Python modules installed via pip from site-packages directory and try something like  python -m pip install pycrypto      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  For Windows 7:  I got through this error \"Module error Crypo.Cipher import AES\"  To install Pycrypto in Windows,  Try this in Command Prompt,  Set path=C:\\Python27\\Scripts  (i.e path where easy_install is located)  Then execute the following,  easy_install pycrypto  For Ubuntu:  Try this,  Download Pycrypto from \"https://pypi.python.org/pypi/pycrypto\"  Then change your current path to downloaded path using your terminal:  Eg: root@xyz-virtual-machine:~/pycrypto-2.6.1#  Then execute the following using the terminal:   python setup.py install  It's worked for me. Hope works for all..     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  I solve this problem by change the first letter case to upper. Make sure ''from Crypto.Cipher import AES'' not ''from crypto.Cipher import AES''.     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  This problem can be fixed by installing the C++ compiler (python27 or python26). Download it from Microsoft https://www.microsoft.com/en-us/download/details.aspx?id=44266 and re-run the command : pip install pycrypto to run the gui web access when you kill the process of easy_install.exe.     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  For CentOS 7.4 I first installed pip and then pycrypto using pip:  > sudo yum -y install python-pip  > sudo python -m pip install pycrypto      ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  Worked for me (Ubuntu 17.10)  Removing venv and creating it again with python v3.6  pip3 install PyJWT sudo apt-get install build-essential libgmp3-dev python3-dev pip3 install cryptography pip3 install pycryptodome pip3 install pycryptodomex   Pycrypto is deprecated, had problems with it, used Pycryptodome     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named Crypto.Cipher","A_Content":"  To date, I'm having same issue when importing from Crypto.Cipher import AES even i've installed/reinstalled pycrypto few times. End up it's because pip defaulted to python3.    ~ pip --version pip 18.0 from /usr/local/lib/python3.7/site-packages/pip (python 3.7)   installing pycrypo with pip2 should solve this issue.     ","Language":"Python","Tags":["python","virtualenv","pip","easy-install","pycrypto"],"URL":"https://stackoverflow.com/questions/19623267/importerror-no-module-named-crypto-cipher","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    When I try to run app.py (Python 3.3, PyCrypto 2.6) my virtualenv keeps returning the error listed above. My import statement is just from Crypto.Cipher import AES. I looked for duplicates and you might say that there are some, but I tried the solutions (although most are not even solutions) and nothing worked.  You can see what the files are like for PyCrypto below:       ","Q_Votes":"79"},{"Q_Title":"How to set adaptive learning rate for GradientDescentOptimizer?","A_Content":"  First of all, tf.train.GradientDescentOptimizer is designed to use a constant learning rate for all variables in all steps. TensorFlow also provides out-of-the-box adaptive optimizers including the tf.train.AdagradOptimizer and the tf.train.AdamOptimizer, and these can be used as drop-in replacements.  However, if you want to control the learning rate with otherwise-vanilla gradient descent, you can take advantage of the fact that the learning_rate argument to the tf.train.GradientDescentOptimizer constructor can be a Tensor object. This allows you to compute a different value for the learning rate in each step, for example:  learning_rate = tf.placeholder(tf.float32, shape=[]) # ... train_step = tf.train.GradientDescentOptimizer(     learning_rate=learning_rate).minimize(mse)  sess = tf.Session()  # Feed different values for learning rate to each training step. sess.run(train_step, feed_dict={learning_rate: 0.1}) sess.run(train_step, feed_dict={learning_rate: 0.1}) sess.run(train_step, feed_dict={learning_rate: 0.01}) sess.run(train_step, feed_dict={learning_rate: 0.01})   Alternatively, you could create a scalar tf.Variable that holds the learning rate, and assign it each time you want to change the learning rate.     ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer","A_Votes":"163","_type":"dict","isAccepted":"Yes","Q_Content":"    I am using TensorFlow to train a neural network. This is how I am initializing the GradientDescentOptimizer:  init = tf.initialize_all_variables() sess = tf.Session() sess.run(init)  mse        = tf.reduce_mean(tf.square(out - out_)) train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)   The thing here is that I don't know how to set an update rule for the learning rate or a decay value for that.   How can I use an adaptive learning rate here?     ","Q_Votes":"79"},{"Q_Title":"How to set adaptive learning rate for GradientDescentOptimizer?","A_Content":"  Tensorflow provides an op to automatically apply an exponential decay to a learning rate tensor: tf.train.exponential_decay.  For an example of it in use, see this line in the MNIST convolutional model example.  Then use @mrry's suggestion above to supply this variable as the learning_rate parameter to your optimizer of choice.  The key excerpt to look at is:  # Optimizer: set up a variable that's incremented once per batch and # controls the learning rate decay. batch = tf.Variable(0)  learning_rate = tf.train.exponential_decay(   0.01,                # Base learning rate.   batch * BATCH_SIZE,  # Current index into the dataset.   train_size,          # Decay step.   0.95,                # Decay rate.   staircase=True) # Use simple momentum for the optimization. optimizer = tf.train.MomentumOptimizer(learning_rate,                                      0.9).minimize(loss,                                                    global_step=batch)   Note the global_step=batch parameter to minimize.  That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.     ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer","A_Votes":"79","_type":"dict","isAccepted":"No","Q_Content":"    I am using TensorFlow to train a neural network. This is how I am initializing the GradientDescentOptimizer:  init = tf.initialize_all_variables() sess = tf.Session() sess.run(init)  mse        = tf.reduce_mean(tf.square(out - out_)) train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)   The thing here is that I don't know how to set an update rule for the learning rate or a decay value for that.   How can I use an adaptive learning rate here?     ","Q_Votes":"79"},{"Q_Title":"How to set adaptive learning rate for GradientDescentOptimizer?","A_Content":"  Gradient descent algorithm uses the constant learning rate which you can provide in during the initialization. You can pass various learning rates in a way showed by Mrry.  But instead of it you can also use more advanced optimizers which have faster convergence rate and adapts to the situation.  Here is a brief explanation based on my understanding:   momentum helps SGD to navigate along the relevant directions and softens the oscillations in the irrelevant. It simply adds a fraction of the direction of the previous step to a current step. This achieves amplification of speed in the correct dirrection and softens oscillation in wrong directions. This fraction is usually in the (0, 1) range. It also makes sense to use adaptive momentum. In the beginning of learning a big momentum will only hinder your progress, so it makse sense to use something like 0.01 and once all the high gradients disappeared you can use a bigger momentom. There is one problem with momentum: when we are very close to the goal, our momentum in most of the cases is very high and it does not know that it should slow down. This can cause it to miss or oscillate around the minima nesterov accelerated gradient overcomes this problem by starting to slow down early. In momentum we first compute gradient and then make a jump in that direction amplified by whatever momentum we had previously. NAG does the same thing but in another order: at first we make a big jump based on our stored information, and then we calculate the gradient and make a small correction. This seemingly irrelevant change gives significant practical speedups. AdaGrad or adaptive gradient allows the learning rate to adapt based on parameters. It performs larger updates for infrequent parameters and smaller updates for frequent one. Because of this it is well suited for sparse data (NLP or image recognition). Another advantage is that it basically illiminates the need to tune the learning rate. Each parameter has its own learning rate and due to the peculiarities of the algorithm the learning rate is monotonically decreasing. This causes the biggest problem: at some point of time the learning rate is so small that the system stops learning AdaDelta resolves the problem of monotonically decreasing learning rate in AdaGrad. In AdaGrad the learning rate was calculated approximately as one divided by the sum of square roots. At each stage you add another square root to the sum, which causes denominator to constantly decrease. In AdaDelta instead of summing all past square roots it uses sliding window which allows the sum to decrease. RMSprop is very similar to AdaDelta Adam or adaptive momentum is an algorithm similar to AdaDelta. But in addition to storing learning rates for each of the parameters it also stores momentum changes for each of them separately  A few visualizations:        ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"    I am using TensorFlow to train a neural network. This is how I am initializing the GradientDescentOptimizer:  init = tf.initialize_all_variables() sess = tf.Session() sess.run(init)  mse        = tf.reduce_mean(tf.square(out - out_)) train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)   The thing here is that I don't know how to set an update rule for the learning rate or a decay value for that.   How can I use an adaptive learning rate here?     ","Q_Votes":"79"},{"Q_Title":"How to set adaptive learning rate for GradientDescentOptimizer?","A_Content":"  From tensorflow official docs  global_step = tf.Variable(0, trainable=False) starter_learning_rate = 0.1 learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,                                        100000, 0.96, staircase=True)  # Passing global_step to minimize() will increment it at each step. learning_step = ( tf.train.GradientDescentOptimizer(learning_rate) .minimize(...my loss..., global_step=global_step))      ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am using TensorFlow to train a neural network. This is how I am initializing the GradientDescentOptimizer:  init = tf.initialize_all_variables() sess = tf.Session() sess.run(init)  mse        = tf.reduce_mean(tf.square(out - out_)) train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)   The thing here is that I don't know how to set an update rule for the learning rate or a decay value for that.   How can I use an adaptive learning rate here?     ","Q_Votes":"79"},{"Q_Title":"What's the purpose of tf.app.flags in TensorFlow?","A_Content":"  The tf.app.flags module is presently a thin wrapper around python-gflags, so the documentation for that project is the best resource for how to use it argparse, which implements a subset of the functionality in python-gflags.  Note that this module is currently packaged as a convenience for writing demo apps, and is not technically part of the public API, so it may change in future.  We recommend that you implement your own flag parsing using argparse or whatever library you prefer.  EDIT: The tf.app.flags module is not in fact implemented using python-gflags, but it uses a similar API.      ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33932901/whats-the-purpose-of-tf-app-flags-in-tensorflow","A_Votes":"89","_type":"dict","isAccepted":"No","Q_Content":"    I am reading some example codes in Tensorflow, I found following code   flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.') flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.') flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.') flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.') flags.DEFINE_integer('batch_size', 100, 'Batch size.  '                  'Must divide evenly into the dataset sizes.') flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.') flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '                  'for unit testing.')   in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py  But I can't find any docs about this usage of tf.app.flags.   And I found the implementation of this flags is in the  tensorflow/tensorflow/python/platform/default/_flags.py  Obviously, this tf.app.flags is somehow used to configure a network, so why  is it not in the API docs? Can anyone explain what is going on here?      ","Q_Votes":"80"},{"Q_Title":"What's the purpose of tf.app.flags in TensorFlow?","A_Content":"  When you use tf.app.run(), you can transfer the variable very conveniently between threads using tf.app.flags. See this for further usage of tf.app.flags.     ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33932901/whats-the-purpose-of-tf-app-flags-in-tensorflow","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am reading some example codes in Tensorflow, I found following code   flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.') flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.') flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.') flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.') flags.DEFINE_integer('batch_size', 100, 'Batch size.  '                  'Must divide evenly into the dataset sizes.') flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.') flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '                  'for unit testing.')   in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py  But I can't find any docs about this usage of tf.app.flags.   And I found the implementation of this flags is in the  tensorflow/tensorflow/python/platform/default/_flags.py  Obviously, this tf.app.flags is somehow used to configure a network, so why  is it not in the API docs? Can anyone explain what is going on here?      ","Q_Votes":"80"},{"Q_Title":"What's the purpose of tf.app.flags in TensorFlow?","A_Content":"  After trying many times I found this to print all FLAGS key as well as actual value -  for key in tf.app.flags.FLAGS.flag_values_dict():    print(key, FLAGS[i].value)      ","Language":"Python","Tags":["python","tensorflow"],"URL":"https://stackoverflow.com/questions/33932901/whats-the-purpose-of-tf-app-flags-in-tensorflow","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I am reading some example codes in Tensorflow, I found following code   flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.') flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.') flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.') flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.') flags.DEFINE_integer('batch_size', 100, 'Batch size.  '                  'Must divide evenly into the dataset sizes.') flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.') flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '                  'for unit testing.')   in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py  But I can't find any docs about this usage of tf.app.flags.   And I found the implementation of this flags is in the  tensorflow/tensorflow/python/platform/default/_flags.py  Obviously, this tf.app.flags is somehow used to configure a network, so why  is it not in the API docs? Can anyone explain what is going on here?      ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  Perhaps take a look at SymPy.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"31","_type":"dict","isAccepted":"Yes","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  Shapely is a nice python wrapper around the popular GEOS library.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  I found pyeuclid to be a great simple general purpose euclidean math package. Though the library may not contain exactly the problems that you mentioned, its infrastructure is good enough to make it easy to write these on your own.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  CGAL has Python bindings too.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  geometry-simple has classes Point Line Plane Movement in ~ 300 lines, using only numpy; take a look.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  I really want a good answer to this question, and the ones above left me dissatisfied. However, I just came across pythonocc which looks great, apart from lacking good docs and still having some trouble with installation (not yet pypi compatible). The last update was 4 days ago (June 19th, 2011). It wraps OpenCascade which has a ton of geometry and modeling functionality. From the pythonocc website:     pythonOCC is a 3D CAD/CAE/PLM development framework for the Python programming language. It provides features such as advanced topological and geometrical operations, data exchange (STEP, IGES, STL import/export), 2D and 3D meshing, rigid body simulation, parametric modeling.   [EDIT: I've now downloaded pythonocc and began working through some of the examples]  I believe it can perform all of the tasks mentioned, but I found it to be unintuitive to use. It is created almost entirely from SWIG wrappers, and as a result, introspection of the commands becomes difficult.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  You may be interested in Python module SpaceFuncs from OpenOpt project, http://openopt.org  SpaceFuncs is tool for 2D, 3D, N-dimensional geometric modeling with possibilities of parametrized calculations, numerical optimization and solving systems of geometrical equations      ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Good geometry library in python? [closed]","A_Content":"  Python Wild Magic is another SWIG wrapped code. It is however a gaming library, but you could manipulate the SWIG library file to exclude any undesired graphics stuff from the Python API.     ","Language":"Python","Tags":["python","geometry"],"URL":"https://stackoverflow.com/questions/1076778/good-geometry-library-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am looking for a good and well developed library for geometrical manipulations and evaluations in python, like:   evaluate the intersection between two lines in 2D and 3D (if present) evaluate the point of intersection between a plane and a line, or the line of intersection between two planes evaluate the minimum distance between a line and a point find the orthonormal to a plane passing through a point rotate, translate, mirror a set of points find the dihedral angle defined by four points   I have a compendium book for all these operations, and I could implement it but unfortunately I have no time, so I would enjoy a library that does it. Most operations are useful for gaming purposes, so I am sure that some of these functionalities can be found in gaming libraries, but I would prefer not to include functionalities (such as graphics) I don't need.  Any suggestions ? Thanks     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  For anyone else wanting to do this, I'd recommend taking a look at django-email-as-username which is a pretty comprehensive solution, that includes patching up the admin and the createsuperuser management commands, amongst other bits and pieces.  Edit: As of Django 1.5 onwards you should consider using a custom user model instead of django-email-as-username.     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Here's what we do. It isn't a \"complete\" solution, but it does much of what you're looking for.  from django import forms from django.contrib import admin from django.contrib.auth.admin import UserAdmin from django.contrib.auth.models import User  class UserForm(forms.ModelForm):     class Meta:         model = User         exclude = ('email',)     username = forms.EmailField(max_length=64,                                 help_text=\"The person's email address.\")     def clean_email(self):         email = self.cleaned_data['username']         return email  class UserAdmin(UserAdmin):     form = UserForm     list_display = ('email', 'first_name', 'last_name', 'is_staff')     list_filter = ('is_staff',)     search_fields = ('email',)  admin.site.unregister(User) admin.site.register(User, UserAdmin)      ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Here is one way to do it so that both username and email are accepted:  from django.contrib.auth.forms import AuthenticationForm from django.contrib.auth.models import User from django.core.exceptions import ObjectDoesNotExist from django.forms import ValidationError  class EmailAuthenticationForm(AuthenticationForm):     def clean_username(self):         username = self.data['username']         if '@' in username:             try:                 username = User.objects.get(email=username).username             except ObjectDoesNotExist:                 raise ValidationError(                     self.error_messages['invalid_login'],                     code='invalid_login',                     params={'username':self.username_field.verbose_name},                 )         return username   Don't know if there is some setting to set the default Authentication form but you can also override the url in urls.py  url(r'^accounts/login/$', 'django.contrib.auth.views.login', { 'authentication_form': EmailAuthenticationForm }, name='login'),   Raising the ValidationError will prevent 500 errors when an invalid email is submitted. Using the super's definition for \"invalid_login\" keeps the error message ambiguous (vs a specific \"no user by that email found\") which would be required to prevent leaking whether an email address is signed up for an account on your service. If that information is not secure in your architecture it might be friendlier to have a more informative error message.     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Django now provides a full example of an extended authentication system with admin and form: https://docs.djangoproject.com/en/stable/topics/auth/customizing/#a-full-example  You can basically copy/paste it and adapt (I didn't need the date_of_birth in my case).  It is actually available since Django 1.5 and is still available as of now (django 1.7).     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  If you're going to extend user model, you will have to implement custom user model anyway.   Here is an example for Django 1.8. Django 1.7 would require a little bit more work, mostly changing default forms (just take a look  at UserChangeForm & UserCreationForm in django.contrib.auth.forms - that's what you need in 1.7).  user_manager.py:  from django.contrib.auth.models import BaseUserManager from django.utils import timezone  class SiteUserManager(BaseUserManager):     def create_user(self, email, password=None, **extra_fields):         today = timezone.now()          if not email:             raise ValueError('The given email address must be set')          email = SiteUserManager.normalize_email(email)         user  = self.model(email=email,                           is_staff=False, is_active=True, **extra_fields)          user.set_password(password)         user.save(using=self._db)         return user      def create_superuser(self, email, password, **extra_fields):         u = self.create_user(email, password, **extra_fields)         u.is_staff = True         u.is_active = True         u.is_superuser = True         u.save(using=self._db)         return u   models.py:  from mainsite.user_manager import SiteUserManager  from django.contrib.auth.models import AbstractBaseUser from django.contrib.auth.models import PermissionsMixin  class SiteUser(AbstractBaseUser, PermissionsMixin):     email    = models.EmailField(unique=True, blank=False)      is_active   = models.BooleanField(default=True)     is_admin    = models.BooleanField(default=False)     is_staff    = models.BooleanField(default=False)      USERNAME_FIELD = 'email'      objects = SiteUserManager()      def get_full_name(self):         return self.email      def get_short_name(self):         return self.email   forms.py:  from django.contrib import admin from django.contrib.auth.admin import UserAdmin from django.contrib.auth.forms import UserChangeForm, UserCreationForm from mainsite.models import SiteUser  class MyUserCreationForm(UserCreationForm):     class Meta(UserCreationForm.Meta):         model = SiteUser         fields = (\"email\",)   class MyUserChangeForm(UserChangeForm):     class Meta(UserChangeForm.Meta):         model = SiteUser   class MyUserAdmin(UserAdmin):     form = MyUserChangeForm     add_form = MyUserCreationForm      fieldsets = (         (None,              {'fields': ('email', 'password',)}),         ('Permissions',     {'fields': ('is_active', 'is_staff', 'is_superuser',)}),           ('Groups',          {'fields': ('groups', 'user_permissions',)}),     )      add_fieldsets = (         (None, {             'classes': ('wide',),             'fields': ('email', 'password1', 'password2')}         ),     )      list_display = ('email', )            list_filter = ('is_active', )         search_fields = ('email',)            ordering = ('email',)   admin.site.register(SiteUser, MyUserAdmin)   settings.py:  AUTH_USER_MODEL = 'mainsite.SiteUser'      ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Other alternatives look too complex for me, so I wrote a snippet that allows to authenticate using username, email, or both, and also enable or disable case sensitive. I uploaded it to pip as django-dual-authentication.  from django.contrib.auth.backends import ModelBackend from django.contrib.auth import get_user_model from django.conf import settings  ################################### \"\"\"  DEFAULT SETTINGS + ALIAS   \"\"\" ###################################   try:     am = settings.AUTHENTICATION_METHOD except:     am = 'both' try:     cs = settings.AUTHENTICATION_CASE_SENSITIVE except:     cs = 'both'  ##################### \"\"\"   EXCEPTIONS  \"\"\" #####################   VALID_AM = ['username', 'email', 'both'] VALID_CS = ['username', 'email', 'both', 'none']  if (am not in VALID_AM):     raise Exception(\"Invalid value for AUTHENTICATION_METHOD in project \"                     \"settings. Use 'username','email', or 'both'.\")  if (cs not in VALID_CS):     raise Exception(\"Invalid value for AUTHENTICATION_CASE_SENSITIVE in project \"                     \"settings. Use 'username','email', 'both' or 'none'.\")  ############################ \"\"\"  OVERRIDDEN METHODS  \"\"\" ############################   class DualAuthentication(ModelBackend):     \"\"\"     This is a ModelBacked that allows authentication     with either a username or an email address.     \"\"\"      def authenticate(self, username=None, password=None):         UserModel = get_user_model()         try:             if ((am == 'email') or (am == 'both')):                 if ((cs == 'email') or cs == 'both'):                     kwargs = {'email': username}                 else:                     kwargs = {'email__iexact': username}                  user = UserModel.objects.get(**kwargs)             else:                 raise         except:             if ((am == 'username') or (am == 'both')):                 if ((cs == 'username') or cs == 'both'):                     kwargs = {'username': username}                 else:                 kwargs = {'username__iexact': username}                  user = UserModel.objects.get(**kwargs)         finally:             try:                 if user.check_password(password):                     return user             except:                 # Run the default password hasher once to reduce the timing                 # difference between an existing and a non-existing user.                 UserModel().set_password(password)                 return None      def get_user(self, username):         UserModel = get_user_model()         try:             return UserModel.objects.get(pk=username)         except UserModel.DoesNotExist:             return None      ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Latest version of django-registration allows some nice customisation and might do the job - docs here https://bitbucket.org/ubernostrum/django-registration/src/fad7080fe769/docs/backend-api.rst     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"       if user_form.is_valid():         # Save the user's form data to a user object without committing.         user = user_form.save(commit=False)         user.set_password(user.password)         #Set username of user as the email         user.username = user.email         #commit         user.save()   working perfectly... for django 1.11.4     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  you can also find an interesting discussion on this topic at the below link :  http://groups.google.com/group/django-users/browse_thread/thread/c943ede66e6807c/2fbf2afeade397eb#2fbf2afeade397eb     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  The easiest way is to lookup the username based on the email in the login view. That way you can leave everything else alone:  from django.contrib.auth import authenticate, login as auth_login  def _is_valid_email(email):     from django.core.validators import validate_email     from django.core.exceptions import ValidationError     try:         validate_email(email)         return True     except ValidationError:         return False  def login(request):      next = request.GET.get('next', '/')      if request.method == 'POST':         username = request.POST['username'].lower()  # case insensitivity         password = request.POST['password']      if _is_valid_email(username):         try:             username = User.objects.filter(email=username).values_list('username', flat=True)         except User.DoesNotExist:             username = None     kwargs = {'username': username, 'password': password}     user = authenticate(**kwargs)          if user is not None:             if user.is_active:                 auth_login(request, user)                 return redirect(next or '/')             else:                 messages.info(request, \"<stvrong>Error</strong> User account has not been activated..\")         else:             messages.info(request, \"<strong>Error</strong> Username or password was incorrect.\")      return render_to_response('accounts/login.html', {}, context_instance=RequestContext(request))   In your template set the next variable accordingly, i.e.   <form method=\"post\" class=\"form-login\" action=\"{% url 'login' %}?next={{ request.GET.next }}\" accept-charset=\"UTF-8\">   And give your username / password inputs the right names, i.e. username, password.  UPDATE:   Alternatively, the if _is_valid_email(email): call can be replaced with  if '@' in username. That way you can drop the _is_valid_email function. This really depends on how you define your username. It will not work if you allow the '@' character in your usernames.     ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  I think the most quickly way is to create a form inherit from UserCreateForm, and then override the username field with forms.EmailField. Then for every new registration user, they need to signon with their email address.  For example:  urls.py  ... urlpatterns += url(r'^signon/$', SignonView.as_view(), name=\"signon\")   views.py  from django.contrib.auth.models import User from django.contrib.auth.forms import UserCreationForm from django import forms  class UserSignonForm(UserCreationForm):     username = forms.EmailField()   class SignonView(CreateView):     template_name = \"registration/signon.html\"     model = User     form_class = UserSignonForm   signon.html  ... <form action=\"#\" method=\"post\">     ...     <input type=\"email\" name=\"username\" />     ... </form> ...      ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Accepting email address as username in Django","A_Content":"  Not sure if people are trying to accomplish this, but I found nice (and clean) way to only ask for the email and then set the username as the email in the view before saving.  My UserForm only requires the email and password:  class UserForm(forms.ModelForm):     password = forms.CharField(widget=forms.PasswordInput())      class Meta:         model = User         fields = ('email', 'password')   Then in my view I add the following logic:  if user_form.is_valid():             # Save the user's form data to a user object without committing.             user = user_form.save(commit=False)              user.set_password(user.password)             #Set username of user as the email             user.username = user.email             #commit             user.save()      ","Language":"Python","Tags":["python","django","authentication"],"URL":"https://stackoverflow.com/questions/778382/accepting-email-address-as-username-in-django","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a good way to do this in django without rolling my own authentication system?  I want the username to be the user's email address instead of them creating a username.  Please advise, thank you.     ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"  They always give the same result.  In fact, not 'ham' in 'spam and eggs' appears to be special cased to perform a single \"not in\" operation, rather than an \"in\" operation and then negating the result:  >>> import dis  >>> def notin():     'ham' not in 'spam and eggs' >>> dis.dis(notin)   2           0 LOAD_CONST               1 ('ham')               3 LOAD_CONST               2 ('spam and eggs')               6 COMPARE_OP               7 (not in)               9 POP_TOP                           10 LOAD_CONST               0 (None)              13 RETURN_VALUE      >>> def not_in():     not 'ham' in 'spam and eggs' >>> dis.dis(not_in)   2           0 LOAD_CONST               1 ('ham')               3 LOAD_CONST               2 ('spam and eggs')               6 COMPARE_OP               7 (not in)               9 POP_TOP                           10 LOAD_CONST               0 (None)              13 RETURN_VALUE      >>> def not__in():     not ('ham' in 'spam and eggs') >>> dis.dis(not__in)   2           0 LOAD_CONST               1 ('ham')               3 LOAD_CONST               2 ('spam and eggs')               6 COMPARE_OP               7 (not in)               9 POP_TOP                           10 LOAD_CONST               0 (None)              13 RETURN_VALUE          >>> def noteq():     not 'ham' == 'spam and eggs' >>> dis.dis(noteq)   2           0 LOAD_CONST               1 ('ham')               3 LOAD_CONST               2 ('spam and eggs')               6 COMPARE_OP               2 (==)               9 UNARY_NOT                         10 POP_TOP                           11 LOAD_CONST               0 (None)              14 RETURN_VALUE         I had thought at first that they always gave the same result, but that not on its own was simply a low precedence logical negation operator, which could be applied to a in b just as easily as any other boolean expression, whereas not in was a separate operator for convenience and clarity.  The disassembly above was revealing! It seems that while not obviously is a logical negation operator, the form not a in b is special cased so that it's not actually using the general operator. This makes not a in b literally the same expression as a not in b, rather than merely an expression that results in the same value.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"   No, there is no difference.     The operator not in is defined to have the inverse true value of in.      Python documentation   I would assume not in is preferred because it is more obvious and they added a special case for it.         ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"  Others have already made it very clear that the two statements are, down to a quite low level, equivalent.  However, I don't think that anyone yet has stressed enough that since this leaves the choice up to you, you should  choose the form that makes your code as readable as possible.  And not necessarily as readable as possible to anyone, even if that's of course a nice thing to aim for. No, make sure the code is as readable as possible to you, since you are the one who is the most likely to come back to this code later and try to read it.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"  They are identical in meaning, but the pep8 Python style guide checker prefers the not in operator in rule E713:     E713:     test for membership should be not in    See also \"Python if x is not None or if not x is None?\" for a very similar choice of style.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"  In Python, there is no difference. And there is no preference.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"Order of syntax for using 'not' and 'in' keywords","A_Content":"  Syntactically they're the same statement.  I would be quick to state that 'ham' not in 'spam and eggs' conveys clearer intent, but I've seen code and scenarios in which not 'ham' in 'spam and eggs' conveys a clearer meaning than the other.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/8738388/order-of-syntax-for-using-not-and-in-keywords","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    When testing for membership, we can use:  x not in y   Or alternatively:  not y in x   There can be many possible contexts for this expression depending on x and y.  It could be for a substring check, list membership, dict key existence, for example.   Are the two forms always equivalent?   Is there a preferred syntax?      ","Q_Votes":"80"},{"Q_Title":"adding directory to sys.path /PYTHONPATH","A_Content":"  This is working as documented.  Any paths specified in PYTHONPATH are documented as normally coming after the working directory but before the standard interpreter-supplied paths.  sys.path.append() appends to the existing path.  See here and here.  If you want a particular directory to come first, simply insert it at the head of sys.path:  import sys sys.path.insert(0,'/path/to/mod_directory')   That said, there are usually better ways to manage imports than either using PYTHONPATH or manipulating sys.path directly.  See, for example, the answers to this question.     ","Language":"Python","Tags":["python","mechanize","python-import","pythonpath"],"URL":"https://stackoverflow.com/questions/16114391/adding-directory-to-sys-path-pythonpath","A_Votes":"109","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to import a module from a particular directory.   The problem is that if I use sys.path.append(mod_directory) to append the path and then open the python interpreter, the directory mod_directory gets added to the end of the list sys.path. If I export the PYTHONPATH variable before opening the python interpreter, the  directory gets added to the start of the list. In the latter case I can import the module but in the former, I cannot.  Can somebody explain why this is happening and give me a solution to add the mod_directory to the start, inside a python script ?     ","Q_Votes":"80"},{"Q_Title":"adding directory to sys.path /PYTHONPATH","A_Content":"  You could use:  import os path = 'the path you want' os.environ['PATH'] += ':'+path      ","Language":"Python","Tags":["python","mechanize","python-import","pythonpath"],"URL":"https://stackoverflow.com/questions/16114391/adding-directory-to-sys-path-pythonpath","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to import a module from a particular directory.   The problem is that if I use sys.path.append(mod_directory) to append the path and then open the python interpreter, the directory mod_directory gets added to the end of the list sys.path. If I export the PYTHONPATH variable before opening the python interpreter, the  directory gets added to the start of the list. In the latter case I can import the module but in the former, I cannot.  Can somebody explain why this is happening and give me a solution to add the mod_directory to the start, inside a python script ?     ","Q_Votes":"80"},{"Q_Title":"adding directory to sys.path /PYTHONPATH","A_Content":"  Temporarily changing dirs works well for importing:  cwd = os.getcwd() os.chdir(<module_path>) import <module> os.chdir(cwd)      ","Language":"Python","Tags":["python","mechanize","python-import","pythonpath"],"URL":"https://stackoverflow.com/questions/16114391/adding-directory-to-sys-path-pythonpath","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to import a module from a particular directory.   The problem is that if I use sys.path.append(mod_directory) to append the path and then open the python interpreter, the directory mod_directory gets added to the end of the list sys.path. If I export the PYTHONPATH variable before opening the python interpreter, the  directory gets added to the start of the list. In the latter case I can import the module but in the former, I cannot.  Can somebody explain why this is happening and give me a solution to add the mod_directory to the start, inside a python script ?     ","Q_Votes":"80"},{"Q_Title":"adding directory to sys.path /PYTHONPATH","A_Content":"  As to me, i need to caffe to my python path. I can add it's path to the file   /home/xy/.bashrc by add   export PYTHONPATH=/home/xy/caffe-master/python:$PYTHONPATH.  to my /home/xy/.bashrc file.  But when I use pycharm, the path is still not in.  So I can add path to PYTHONPATH variable, by run -> edit Configuration.       ","Language":"Python","Tags":["python","mechanize","python-import","pythonpath"],"URL":"https://stackoverflow.com/questions/16114391/adding-directory-to-sys-path-pythonpath","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to import a module from a particular directory.   The problem is that if I use sys.path.append(mod_directory) to append the path and then open the python interpreter, the directory mod_directory gets added to the end of the list sys.path. If I export the PYTHONPATH variable before opening the python interpreter, the  directory gets added to the start of the list. In the latter case I can import the module but in the former, I cannot.  Can somebody explain why this is happening and give me a solution to add the mod_directory to the start, inside a python script ?     ","Q_Votes":"80"},{"Q_Title":"adding directory to sys.path /PYTHONPATH","A_Content":"  When running a Python script from Powershell under Windows, this should work:  $pathToSourceRoot = \"C:/Users/Steve/YourCode\" $env:PYTHONPATH = \"$($pathToSourceRoot);$($pathToSourceRoot)/subdirs_if_required\"  # Now run the actual script python your_script.py      ","Language":"Python","Tags":["python","mechanize","python-import","pythonpath"],"URL":"https://stackoverflow.com/questions/16114391/adding-directory-to-sys-path-pythonpath","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to import a module from a particular directory.   The problem is that if I use sys.path.append(mod_directory) to append the path and then open the python interpreter, the directory mod_directory gets added to the end of the list sys.path. If I export the PYTHONPATH variable before opening the python interpreter, the  directory gets added to the start of the list. In the latter case I can import the module but in the former, I cannot.  Can somebody explain why this is happening and give me a solution to add the mod_directory to the start, inside a python script ?     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  There isn't currently a better way to do it than Ctrl+C in the terminal.  We're thinking about how to have an explicit shutdown, but there's some tension between the notebook as a single-user application, where the user is free to stop it, and as a multi-user server, where only an admin should be able to stop it. We haven't quite worked out how to handle the differences yet.  (For future readers, this is the situation with 0.12 released and 0.13 in development.)  Update December 2017  The IPython Notebook has become the Jupyter Notebook. A recent version has added a jupyter notebook stop shell command which will shut down a server running on that system. You can pass the port number at the command line if it's not the default port 8888.  You can also use nbmanager, a desktop application which can show running servers and shut them down.  Finally, we are working on adding:   A config option to automatically shut down the server if you don't use it for a specified time. A button in the user interface to shut the server down. (We know it's a bit crazy that it has taken this long. Changing UI is controversial.)      ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"79","_type":"dict","isAccepted":"Yes","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  If you run jupyter in the background like me:  jupyter notebook &> /dev/null &   Then to exit jupyter completely, instead of Ctl-C, make an alias command:  echo 'alias quitjupyter=\"kill $(pgrep jupyter)\"' >> ~/.bashrc   Restart your terminal. Kill all jupyter instances:  quitjupyter   Note: use double quotes inside of single quotes as shown above.  The other way around will evaluate the expression before writing it to your .bashrc (you want to write the command itself not 'kill 1430' or whatever process number may be associated with a current jupyter instance).  Of course you can use any alias you wish.  I actually use 'qjup':  echo 'alias qjup=\"kill $(pgrep jupyter)\"' >> ~/.bashrc   Restart your terminal. Kill all jupyter instances:  qjup      ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  I think accepted answer outdated and is not valid anymore.  You can terminate jupyter notebook from web interface on file men item.    When you move Mouse cursor on \"close and halt\", you will see following explanation.     And when you click \"close and halt\", you will see following message on terminal screen.       ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  Try killing the pythonw process from the Task Manager (if Windows) if nothing else works.     ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  Linux (Ubuntu 14.04)   As mentioned, try to kill ipython notebook processes properly by first going to the \"running\" tab in your ipynb/jupyter browser session, and then check open terminals on your console and shut down with ctrl-c. The latter should be avoided if possible.  If you run an ipython notebook list and continue to see running ipython servers at different ports, make note of which ports the existing notebooks are being served to. Then shut down your TCP ports:   fuser -k 'port#'/tcp    I'm not sure if there are other risks involved with doing this. If so, let me know.      ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  Environment    My OS is Ubuntu 16.04 and jupyter is 4.3.0.  Method    First, i logged out jupyter at its homepage on browser(the logout button is at top-right)  Second, type in Ctrl + C in your terminal and it shows:     [I 15:59:48.407 NotebookApp]interrupted Serving notebooks from local   directory: /home/Username 0 active kernels       The Jupyter Notebook is running at:   http://localhost:8888/?token=a572c743dfb73eee28538f9a181bf4d9ad412b19fbb96c82      Shutdown this notebook server (y/[n])?   Last step, type in y within 5 sec, and if it shows:     [C 15:59:50.407 NotebookApp] Shutdown confirmed   [I 15:59:50.408   NotebookApp] Shutting down kernels   Congrats! You close your jupyter successfully.     ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  Actually, I believe there's a cleaner way than killing the process(es) using kill or task manager.  In the Jupyter Notebook Dashboard (the browser interface you see when you first launch 'jupyter notebook'), browse to the location of notebook files you have closed in the browser, but whose kernels may still be running.  iPython Notebook files appear with a book icon, shown in green if it has a running kernel, or gray if the kernel is not running.  Just select the tick box next to the running file, then click on the Shutdown button that appears above it.  This will properly shut down the kernel associated with that specific notebook.     ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  In the browser session you can also go to Kernel and then click Restart and Clear Output.      ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  I am copy pasting from the Jupyter/IPython Notebook Quick Start Guide Documentation, released on Feb 13, 2018. http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/execute.html  1.3.3 Close a notebook: kernel shut down When a notebook is opened, its computational engine (called the kernel) is automatically started. Closing the notebook browser tab, will not shut down the kernel, instead the kernel will keep running until is explicitly shut down. To shut down a kernel, go to the associated notebook and click on menu File -> Close and Halt. Alternatively, the Notebook Dashboard has a tab named Running that shows all the running notebooks (i.e. kernels) and allows shutting them down (by clicking on a Shutdown button).  Summary: First close and halt the notebooks running.  1.3.2 Shut down the Jupyter Notebook App Closing the browser (or the tab) will not close the Jupyter Notebook App. To completely shut it down you need to close the associated terminal. In more detail, the Jupyter Notebook App is a server that appears in your browser at a default address (http://localhost:8888). Closing the browser will not shut down the server. You can reopen the previous address and the Jupyter Notebook App will be redisplayed. You can run many copies of the Jupyter Notebook App and they will show up at a similar address (only the number after :, which is the port, will increment for each new copy). Since with a single Jupyter Notebook App you can already open many notebooks, we do not recommend running multiple copies of Jupyter  Notebook App.  Summary: Second, quit the terminal from which you fired Jupyter.     ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"How to close IPython Notebook properly?","A_Content":"  You can use this simple command:   $ jupyter notebook stop  Shutting down server on port 8888 ...   Which also takes the port number as argument and you can shut down the jupyter notebook gracefully.   For eg:   jupyter notebook stop 8889  Shutting down server on port 8889 ...   Additionally to know your current juypter instance running, check below command:   shell> juypter notebook list  Currently running servers: http://localhost:8888/?token=ef12021898c435f865ec706d7c9af8607a7ba58bbee98632 :: /Users/username/jupyter-notebooks [/code]      ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/10162707/how-to-close-ipython-notebook-properly","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How to close IPython Notebook properly?  Currently, I just close the browser tabs and then use Ctrl+C in the terminal. Unfortunately, neither exit() nor ticking Kill kernel upon exit does help (they do kill the kernel they but don't exit the iPython).     ","Q_Votes":"80"},{"Q_Title":"Is __init__.py not required for packages in Python 3?","A_Content":"  Python 3.3+ has Implicit Namespace Packages that allow to create a packages without an __init__.py file.     Allowing implicit namespace packages means that the requirement to provide an __init__.py file can be dropped completely, and affected ... .    The old way with __init__.py files still works as in Python 2.     ","Language":"Python","Tags":["python","python-3.x","package"],"URL":"https://stackoverflow.com/questions/37139786/is-init-py-not-required-for-packages-in-python-3","A_Votes":"88","_type":"dict","isAccepted":"Yes","Q_Content":"    I am using Python 3.5.1. I read the document and the package section here: https://docs.python.org/3/tutorial/modules.html#packages  Now, I have the following structure:  /home/wujek/Playground/a/b/module.py   module.py:  class Foo:     def __init__(self):         print('initializing Foo')   Now, while in /home/wujek/Playground:  ~/Playground $ python3 >>> import a.b.module >>> a.b.module.Foo() initializing Foo <a.b.module.Foo object at 0x100a8f0b8>   Similarly, now in home, superfolder of Playground:  ~ $ PYTHONPATH=Playground python3 >>> import a.b.module >>> a.b.module.Foo() initializing Foo <a.b.module.Foo object at 0x10a5fee10>   Actually, I can do all kinds of stuff:  ~ $ PYTHONPATH=Playground python3 >>> import a >>> import a.b >>> import Playground.a.b   Why does this work? I though there needed to be __init__.py files (empty ones would work) in both a and b for module.py to be importable when the Python path points to the Playground folder?  This seems to have changed from Python 2.7:  ~ $ PYTHONPATH=Playground python >>> import a ImportError: No module named a >>> import a.b ImportError: No module named a.b >>> import a.b.module ImportError: No module named a.b.module   With __init__.py in both ~/Playground/a and ~/Playground/a/b it works fine.     ","Q_Votes":"80"},{"Q_Title":"Is __init__.py not required for packages in Python 3?","A_Content":"  @Mike's answer is correct but too imprecise. It is true that Python 3.3+ supports Implicit Namespace Packages that allows to create a package without an __init__.py file.  This however, ONLY applies to EMPTY __init__.py files. So EMPTY __init__.py files are no longer necessary and can be omitted. If you want to import modules into a package you still require an __init__.py file listing all the imports.  Directory Structure Example:    parent_package/      __init__.py            <- EMPTY, NOT NECESSARY in Python 3.3+      child_package/           __init__.py       <- STILL REQUIRED to import all child modules           child1.py           child2.py           child3.py   __init__ file in child_package:  import child1 import child2 import child3      ","Language":"Python","Tags":["python","python-3.x","package"],"URL":"https://stackoverflow.com/questions/37139786/is-init-py-not-required-for-packages-in-python-3","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 3.5.1. I read the document and the package section here: https://docs.python.org/3/tutorial/modules.html#packages  Now, I have the following structure:  /home/wujek/Playground/a/b/module.py   module.py:  class Foo:     def __init__(self):         print('initializing Foo')   Now, while in /home/wujek/Playground:  ~/Playground $ python3 >>> import a.b.module >>> a.b.module.Foo() initializing Foo <a.b.module.Foo object at 0x100a8f0b8>   Similarly, now in home, superfolder of Playground:  ~ $ PYTHONPATH=Playground python3 >>> import a.b.module >>> a.b.module.Foo() initializing Foo <a.b.module.Foo object at 0x10a5fee10>   Actually, I can do all kinds of stuff:  ~ $ PYTHONPATH=Playground python3 >>> import a >>> import a.b >>> import Playground.a.b   Why does this work? I though there needed to be __init__.py files (empty ones would work) in both a and b for module.py to be importable when the Python path points to the Playground folder?  This seems to have changed from Python 2.7:  ~ $ PYTHONPATH=Playground python >>> import a ImportError: No module named a >>> import a.b ImportError: No module named a.b >>> import a.b.module ImportError: No module named a.b.module   With __init__.py in both ~/Playground/a and ~/Playground/a/b it works fine.     ","Q_Votes":"80"},{"Q_Title":"Convert numpy array to tuple","A_Content":"  >>> arr = numpy.array(((2,2),(2,-2))) >>> tuple(map(tuple, arr)) ((2, 2), (2, -2))      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/10016352/convert-numpy-array-to-tuple","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    Note: This is asking for the reverse of the usual tuple-to-array conversion.  I have to pass an argument to a (wrapped c++) function as a nested tuple.  For example, the following works  X = MyFunction( ((2,2),(2,-2)) )   whereas the following do not  X = MyFunction( numpy.array(((2,2),(2,-2))) ) X = MyFunction( [[2,2],[2,-2]] )   Unfortunately, the argument I would like to use comes to me as a numpy array.  That array always has dimensions 2xN for some N, which may be quite large.  Is there an easy way to convert that to a tuple?  I know that I could just loop through, creating a new tuple, but would prefer if there's some nice access the numpy array provides.  If it's not possible to do this as nicely as I hope, what's the prettiest way to do it by looping, or whatever?     ","Q_Votes":"80"},{"Q_Title":"Convert numpy array to tuple","A_Content":"  Here's a function that'll do it:  def totuple(a):     try:         return tuple(totuple(i) for i in a)     except TypeError:         return a   And an example:  >>> array = numpy.array(((2,2),(2,-2))) >>> totuple(array) ((2, 2), (2, -2))      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/10016352/convert-numpy-array-to-tuple","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    Note: This is asking for the reverse of the usual tuple-to-array conversion.  I have to pass an argument to a (wrapped c++) function as a nested tuple.  For example, the following works  X = MyFunction( ((2,2),(2,-2)) )   whereas the following do not  X = MyFunction( numpy.array(((2,2),(2,-2))) ) X = MyFunction( [[2,2],[2,-2]] )   Unfortunately, the argument I would like to use comes to me as a numpy array.  That array always has dimensions 2xN for some N, which may be quite large.  Is there an easy way to convert that to a tuple?  I know that I could just loop through, creating a new tuple, but would prefer if there's some nice access the numpy array provides.  If it's not possible to do this as nicely as I hope, what's the prettiest way to do it by looping, or whatever?     ","Q_Votes":"80"},{"Q_Title":"Convert numpy array to tuple","A_Content":"  I was not satisfied, so I finally used this:  >>> a=numpy.array([[1,2,3],[4,5,6]]) >>> a array([[1, 2, 3],        [4, 5, 6]])  >>> tuple(a.reshape(1, -1)[0]) (1, 2, 3, 4, 5, 6)   I don't know if it's quicker, but it looks more effective ;)     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/10016352/convert-numpy-array-to-tuple","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Note: This is asking for the reverse of the usual tuple-to-array conversion.  I have to pass an argument to a (wrapped c++) function as a nested tuple.  For example, the following works  X = MyFunction( ((2,2),(2,-2)) )   whereas the following do not  X = MyFunction( numpy.array(((2,2),(2,-2))) ) X = MyFunction( [[2,2],[2,-2]] )   Unfortunately, the argument I would like to use comes to me as a numpy array.  That array always has dimensions 2xN for some N, which may be quite large.  Is there an easy way to convert that to a tuple?  I know that I could just loop through, creating a new tuple, but would prefer if there's some nice access the numpy array provides.  If it's not possible to do this as nicely as I hope, what's the prettiest way to do it by looping, or whatever?     ","Q_Votes":"80"},{"Q_Title":"Convert numpy array to tuple","A_Content":"  Another option  tuple([tuple(row) for row in myarray])   If you are passing NumPy arrays to C++ functions, you may also wish to look at using Cython or SWIG.      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/10016352/convert-numpy-array-to-tuple","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Note: This is asking for the reverse of the usual tuple-to-array conversion.  I have to pass an argument to a (wrapped c++) function as a nested tuple.  For example, the following works  X = MyFunction( ((2,2),(2,-2)) )   whereas the following do not  X = MyFunction( numpy.array(((2,2),(2,-2))) ) X = MyFunction( [[2,2],[2,-2]] )   Unfortunately, the argument I would like to use comes to me as a numpy array.  That array always has dimensions 2xN for some N, which may be quite large.  Is there an easy way to convert that to a tuple?  I know that I could just loop through, creating a new tuple, but would prefer if there's some nice access the numpy array provides.  If it's not possible to do this as nicely as I hope, what's the prettiest way to do it by looping, or whatever?     ","Q_Votes":"80"},{"Q_Title":"Where is Python's best ASCII for this Unicode database?","A_Content":"  Unidecode looks like a complete solution. It converts fancy quotes to ascii quotes, accented latin characters to unaccented and even attempts transliteration to deal with characters that don't have ASCII equivalents. That way your users don't have to see a bunch of ? when you had to pass their text through a legacy 7-bit ascii system.  >>> from unidecode import unidecode >>> print unidecode(u\"\\u5317\\u4EB0\") Bei Jing    http://www.tablix.org/~avian/blog/archives/2009/01/unicode_transliteration_in_python/     ","Language":"Python","Tags":["python","unicode","ascii"],"URL":"https://stackoverflow.com/questions/816285/where-is-pythons-best-ascii-for-this-unicode-database","A_Votes":"85","_type":"dict","isAccepted":"Yes","Q_Content":"    I have some text that uses Unicode punctuation, like left double quote, right single quote for apostrophe, and so on, and I need it in ASCII. Does Python have a database of these characters with obvious ASCII substitutes so I can do better than turning them all into \"?\" ?     ","Q_Votes":"80"},{"Q_Title":"Where is Python's best ASCII for this Unicode database?","A_Content":"  In my original answer, I also suggested unicodedata.normalize. However, I decided to test it out and it turns out it doesn't work with Unicode quotation marks. It does a good job translating accented Unicode characters, so I'm guessing unicodedata.normalize is implemented using the unicode.decomposition function, which leads me to believe it probably can only handle Unicode characters that are combinations of a letter and a diacritical mark, but I'm not really an expert on the Unicode specification, so I could just be full of hot air...   In any event, you can use unicode.translate to deal with punctuation characters instead. The translate method takes a dictionary of Unicode ordinals to Unicode ordinals, thus you can create a mapping that translates Unicode-only punctuation to ASCII-compatible punctuation:  'Maps left and right single and double quotation marks' 'into ASCII single and double quotation marks' >>> punctuation = { 0x2018:0x27, 0x2019:0x27, 0x201C:0x22, 0x201D:0x22 } >>> teststring = u'\\u201Chello, world!\\u201D' >>> teststring.translate(punctuation).encode('ascii', 'ignore') '\"hello, world!\"'   You can add more punctuation mappings if needed, but I don't think you necessarily need to worry about handling every single Unicode punctuation character. If you do need to handle accents and other diacritical marks, you can still use unicodedata.normalize to deal with those characters.     ","Language":"Python","Tags":["python","unicode","ascii"],"URL":"https://stackoverflow.com/questions/816285/where-is-pythons-best-ascii-for-this-unicode-database","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I have some text that uses Unicode punctuation, like left double quote, right single quote for apostrophe, and so on, and I need it in ASCII. Does Python have a database of these characters with obvious ASCII substitutes so I can do better than turning them all into \"?\" ?     ","Q_Votes":"80"},{"Q_Title":"Where is Python's best ASCII for this Unicode database?","A_Content":"  Interesting question.   Google helped me find this page which descibes using the unicodedata module as the following:  import unicodedata unicodedata.normalize('NFKD', title).encode('ascii','ignore')      ","Language":"Python","Tags":["python","unicode","ascii"],"URL":"https://stackoverflow.com/questions/816285/where-is-pythons-best-ascii-for-this-unicode-database","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have some text that uses Unicode punctuation, like left double quote, right single quote for apostrophe, and so on, and I need it in ASCII. Does Python have a database of these characters with obvious ASCII substitutes so I can do better than turning them all into \"?\" ?     ","Q_Votes":"80"},{"Q_Title":"Where is Python's best ASCII for this Unicode database?","A_Content":"  There's additional discussion about this at http://code.activestate.com/recipes/251871/ which has the NFKD solution and some ways of doing a conversion table, for things like  => +/- and other non-letter characters.     ","Language":"Python","Tags":["python","unicode","ascii"],"URL":"https://stackoverflow.com/questions/816285/where-is-pythons-best-ascii-for-this-unicode-database","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have some text that uses Unicode punctuation, like left double quote, right single quote for apostrophe, and so on, and I need it in ASCII. Does Python have a database of these characters with obvious ASCII substitutes so I can do better than turning them all into \"?\" ?     ","Q_Votes":"80"},{"Q_Title":"Combine --user with --prefix error with setup.py install","A_Content":"  One time workaround:  pip install --user --install-option=\"--prefix=\" <package_name>   or  python setup.py install --user --prefix=   Note that there is no text (not even whitespace) after the =.  Do not forget the --user flag.  Installing multiple packages:  Create ~/.pydistutils.cfg (or equivalent for your OS/platform) with the following contents:  [install] prefix=   Note that there is no text (not even whitespace) after the =.  Then run the necessary pip install --user or python setup.py install --user commands. Do not forget the --user flag.  Finally, remove or rename this file. Leaving this file present will cause issues when installing Python packages system-wide (i.e., without --user) as this user with this ~/.pydistutils.cfg.  The cause of this issue  This appears to be an issue with both OpenSUSE and RedHat, which has lead to a bug in virtualenv on these platforms.  The error stems from a system-level distutils configuration file (in my case /usr/lib64/python2.6/distutils/distutils.cfg) where there was this  [install] prefix=/usr/local   Basically, this is equivalent to always running the install command as install --prefix=/usr/local. You have to override this specification using one of the techniques above.     ","Language":"Python","Tags":["python","installation","distutils"],"URL":"https://stackoverflow.com/questions/4495120/combine-user-with-prefix-error-with-setup-py-install","A_Votes":"127","_type":"dict","isAccepted":"Yes","Q_Content":"    I was trying to install Python packages a system I recently gained access to. I was trying to take advantage of Python's relatively new per user site-packages directory, and the new option --user. (The option is currently undocumented, however it exists for Python 2.6+; you can see the help by running python setup.py install --help.)  When I tried running  python setup.py install --user   on any package I downloaded, I always got the following error:  error: can't combine user with with prefix/exec_prefix/home or install_(plat)base   The error was extremely perplexing because, as you can see, I wasn't providing the --prefix, --exec-prefix, --install-base, or --install-platbase flags as command line options. I wasted a lot of time trying to figure out what the problem was. I document my answer below, in hopes to spare some other poor soul a few hours of yak shaving.     ","Q_Votes":"80"},{"Q_Title":"Combine --user with --prefix error with setup.py install","A_Content":"  As has been noted in the comments, the accepted answer (by @gotgenes, who, presumably, has genes) can lead to unexpected consequences.  @rogeleaderr says, \"Note that keeping this file like this will make Python think that / is your root python library directory, leading to confusing issues if you try to install other new packages.\"  Rather than write a new config file, as @gotgenes recommends, a better option is to add --prefix=  (with no text to the right of the equals sign) as an option on the command line, as in  $ python setup.py install --user --prefix=      ","Language":"Python","Tags":["python","installation","distutils"],"URL":"https://stackoverflow.com/questions/4495120/combine-user-with-prefix-error-with-setup-py-install","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I was trying to install Python packages a system I recently gained access to. I was trying to take advantage of Python's relatively new per user site-packages directory, and the new option --user. (The option is currently undocumented, however it exists for Python 2.6+; you can see the help by running python setup.py install --help.)  When I tried running  python setup.py install --user   on any package I downloaded, I always got the following error:  error: can't combine user with with prefix/exec_prefix/home or install_(plat)base   The error was extremely perplexing because, as you can see, I wasn't providing the --prefix, --exec-prefix, --install-base, or --install-platbase flags as command line options. I wasted a lot of time trying to figure out what the problem was. I document my answer below, in hopes to spare some other poor soul a few hours of yak shaving.     ","Q_Votes":"80"},{"Q_Title":"Combine --user with --prefix error with setup.py install","A_Content":"  Posting to save others time, as no available answers worked for me...  In some environments, using the --target (-t) switch will still hit the same error. In my testing on two flavors of linux, I encountered the same issue when using the --prefix= parameter.  Code:  PYTHONUSERBASE=/tmp/ pip install --user --force-reinstall $PACKAGE   Explanation: My workaround, which seems to work across many environments (MacOS, Amazon Linux, Debian) is to set the PYTHONUSERBASE environment variable to a temp location.  --force-reinstall is used to trigger the local installation even when the package is already installed.  This will result in the module being compiled/installed (depending on the OS and Python version) to: /tmp/lib/python2.7/site-packages/*     ","Language":"Python","Tags":["python","installation","distutils"],"URL":"https://stackoverflow.com/questions/4495120/combine-user-with-prefix-error-with-setup-py-install","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I was trying to install Python packages a system I recently gained access to. I was trying to take advantage of Python's relatively new per user site-packages directory, and the new option --user. (The option is currently undocumented, however it exists for Python 2.6+; you can see the help by running python setup.py install --help.)  When I tried running  python setup.py install --user   on any package I downloaded, I always got the following error:  error: can't combine user with with prefix/exec_prefix/home or install_(plat)base   The error was extremely perplexing because, as you can see, I wasn't providing the --prefix, --exec-prefix, --install-base, or --install-platbase flags as command line options. I wasted a lot of time trying to figure out what the problem was. I document my answer below, in hopes to spare some other poor soul a few hours of yak shaving.     ","Q_Votes":"80"},{"Q_Title":"How can I create a Set of Sets in Python?","A_Content":"  Python's complaining because the inner set objects are mutable and thus not hashable. The solution is to use frozenset for the inner sets, to indicate that you have no intention of modifying them.     ","Language":"Python","Tags":["python","class","set"],"URL":"https://stackoverflow.com/questions/5931291/how-can-i-create-a-set-of-sets-in-python","A_Votes":"81","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a set of sets in Python.  I can't figure out how to do it.  Starting with the empty set xx:  xx = set([]) # Now we have some other set, for example elements = set([2,3,4]) xx.add(elements)   but I get  TypeError: unhashable type: 'list'   or   TypeError: unhashable type: 'set'   Is it possible to have a set of sets in Python?  I am dealing with a large collection of sets and I want to be able to not have to deal duplicate sets (a set B of sets A1, A2, ...., An would \"cancel\" two sets if Ai = Aj)     ","Q_Votes":"80"},{"Q_Title":"How can I create a Set of Sets in Python?","A_Content":"  People already mentioned that you can do this with a frozenset(), so I will just add a code how to achieve this:  For example you want to create a set of sets from the following list of lists:  t = [[], [1, 2], [5], [1, 2, 5], [1, 2, 3, 4], [1, 2, 3, 6]]   you can create your set in the following way:  t1 = set(frozenset(i) for i in t)      ","Language":"Python","Tags":["python","class","set"],"URL":"https://stackoverflow.com/questions/5931291/how-can-i-create-a-set-of-sets-in-python","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a set of sets in Python.  I can't figure out how to do it.  Starting with the empty set xx:  xx = set([]) # Now we have some other set, for example elements = set([2,3,4]) xx.add(elements)   but I get  TypeError: unhashable type: 'list'   or   TypeError: unhashable type: 'set'   Is it possible to have a set of sets in Python?  I am dealing with a large collection of sets and I want to be able to not have to deal duplicate sets (a set B of sets A1, A2, ...., An would \"cancel\" two sets if Ai = Aj)     ","Q_Votes":"80"},{"Q_Title":"How can I create a Set of Sets in Python?","A_Content":"  Use frozenset inside.     ","Language":"Python","Tags":["python","class","set"],"URL":"https://stackoverflow.com/questions/5931291/how-can-i-create-a-set-of-sets-in-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a set of sets in Python.  I can't figure out how to do it.  Starting with the empty set xx:  xx = set([]) # Now we have some other set, for example elements = set([2,3,4]) xx.add(elements)   but I get  TypeError: unhashable type: 'list'   or   TypeError: unhashable type: 'set'   Is it possible to have a set of sets in Python?  I am dealing with a large collection of sets and I want to be able to not have to deal duplicate sets (a set B of sets A1, A2, ...., An would \"cancel\" two sets if Ai = Aj)     ","Q_Votes":"80"},{"Q_Title":"How can I create a Set of Sets in Python?","A_Content":"  So I had the exact same problem. I wanted to make a data structure that works as a set of sets. The problem is that the sets must contain immutable objects. So, what you can do is simply make it as a set of tuples. That worked fine for me!  A = set() A.add( (2,3,4) )##adds the element A.add( (2,3,4) )##does not add the same element A.add( (2,3,5) )##adds the element, because it is different!      ","Language":"Python","Tags":["python","class","set"],"URL":"https://stackoverflow.com/questions/5931291/how-can-i-create-a-set-of-sets-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a set of sets in Python.  I can't figure out how to do it.  Starting with the empty set xx:  xx = set([]) # Now we have some other set, for example elements = set([2,3,4]) xx.add(elements)   but I get  TypeError: unhashable type: 'list'   or   TypeError: unhashable type: 'set'   Is it possible to have a set of sets in Python?  I am dealing with a large collection of sets and I want to be able to not have to deal duplicate sets (a set B of sets A1, A2, ...., An would \"cancel\" two sets if Ai = Aj)     ","Q_Votes":"80"},{"Q_Title":"Django vs web2py for a beginner developer [closed]","A_Content":"  (disclaimer: I am the project leader for web2py)  Django has been around 5 years longer than web2py therefore it has more users and more applications to show off. Django has what they call \"admin\" which is not the same as web2py's \"admin\" but more like web2py's \"appadmin\". Django's \"admin\" is better and more customizable than web2py's \"appadmin\". Django does not have the equivalent of web2py's \"admin\". (sorry for the name confusion).  web2py is more compact and has more functionality out of the box (more supported databases, web based IDE, ticketing system, runs on GAE without patches, multiple login methods, role based access control, web based translation interface, support for multiple database connections, distributed transactions, and more).  For me the most important functionality of web2py is automatic migrations. Django does not provide them out of the box.  For web2py long term backward compatibility is a primary goal, together with security. Django is comparable to web2py in terms of security (except that web2py had CSRF prevention and default escaping in templates before they did) but Django broke backward compatibility when 1.0 was released. web2py never did since Oct 2007.  To me the web2py syntax is more natural:   db(db.tablename.fieldname <= value).select() # web2py  Tablename.objects.filter(fieldname__lt=value) # Django   I am not aware of any functionality of web2py that is not present in Django. I have asked that question many times because, if there is, we want to add it to web2py, but I have not yet received a satisfactory answer.  Of course there are things that we both do but differently. Django follows \"explicit is better than implicit\". web2py does not and instead follows \"everything should have a default behavior\". I believe this makes web2py code and configuration more compact.  Anyway, whatever you choose, they are both good solid web frameworks and there are fewer similarities than differences. Django's developers are very smart people.  The web2py community is very friendly. As an experiment, try asking a question on the web2py google group and on the Django group.     ","Language":"Python","Tags":["python","django","web2py"],"URL":"https://stackoverflow.com/questions/4352428/django-vs-web2py-for-a-beginner-developer","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    Which of these two frameworks is better suited to a developer with 11 months experience. I have decided to learn python for my server side coding and wanted to know which of these would be better suited for someone at my skill level. I have just spent a few days playing around with web2py and really like it and i am wondering if Django offers something more that i am missing out on?  PS. UPDATE: Thank you all for the wonderful input, after buying three django books and going through a few small projects/tutorials for both django and web2py, i have settled on web2py. This is a wonderful framework, which makes web development really fun for a newbe. I would recommend all newbies to learn this framework as it will be mainstream in the future. Django is also a wonderful framework but web2py is just better in my limited experience opinion.     ","Q_Votes":"80"},{"Q_Title":"Django vs web2py for a beginner developer [closed]","A_Content":"  Both Django and web2py are excellent 'full stack' web frameworks with similar features and capabilities - you won't be 'missing out' on much as a beginner with either framework.  It's hard to answer your question without knowing more about what you want to do with your learning.  Some would say that there is a danger of learning the framework and not the language so it might be best to get a deeper understanding of the Python language and lighter weight frameworks (e.g. Flask or wekzeug) first.  Having said that, web2py has a lower initial learning curve than Django as it was specifically designed as a learning tool. So I'd say you've made a good choice.  No learning is ever wasted and if you decided you need something else in the future the good techniques you will have learnt using web2py will not go to waste.  Although there are more learning resources for Django, as it has been around longer and has more users, learning web2py is also fast because of the excellent book and almost instant responses to questions on the user group.  If you're looking to get a job, there are more Django jobs so that might be a factor.  Having said that, the web2py community has recently set up experts4solutions where you could promote your skills and availability in the future.  Have fun!     ","Language":"Python","Tags":["python","django","web2py"],"URL":"https://stackoverflow.com/questions/4352428/django-vs-web2py-for-a-beginner-developer","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Which of these two frameworks is better suited to a developer with 11 months experience. I have decided to learn python for my server side coding and wanted to know which of these would be better suited for someone at my skill level. I have just spent a few days playing around with web2py and really like it and i am wondering if Django offers something more that i am missing out on?  PS. UPDATE: Thank you all for the wonderful input, after buying three django books and going through a few small projects/tutorials for both django and web2py, i have settled on web2py. This is a wonderful framework, which makes web development really fun for a newbe. I would recommend all newbies to learn this framework as it will be mainstream in the future. Django is also a wonderful framework but web2py is just better in my limited experience opinion.     ","Q_Votes":"80"},{"Q_Title":"Django vs web2py for a beginner developer [closed]","A_Content":"  I'm a complete noob with both Web2py and DJango, but  I wanted a web framework that was pythonic to play with,learn and create a front end for a simple database. I looked at web2py but couldn't find any decent tutorials,targeted at complete newbies, when i did get web2py installed, which was very easy, i didn't know what to do next, there seemed to be no tutorials that guided me on how to build a simple web app,(not just hello world). On the other hand DJango did Writing your first DJango App Part 1. This has been really good, giving a newbie an introduction on how to setup & use the framework by writing a simple web app. Until Web2Py offers this, my vote goes to DJango.     ","Language":"Python","Tags":["python","django","web2py"],"URL":"https://stackoverflow.com/questions/4352428/django-vs-web2py-for-a-beginner-developer","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Which of these two frameworks is better suited to a developer with 11 months experience. I have decided to learn python for my server side coding and wanted to know which of these would be better suited for someone at my skill level. I have just spent a few days playing around with web2py and really like it and i am wondering if Django offers something more that i am missing out on?  PS. UPDATE: Thank you all for the wonderful input, after buying three django books and going through a few small projects/tutorials for both django and web2py, i have settled on web2py. This is a wonderful framework, which makes web development really fun for a newbe. I would recommend all newbies to learn this framework as it will be mainstream in the future. Django is also a wonderful framework but web2py is just better in my limited experience opinion.     ","Q_Votes":"80"},{"Q_Title":"Django vs web2py for a beginner developer [closed]","A_Content":"  In many words: (as I understood)  Web2py is definitely easier and makes the code simpler and cleaner. But Django gives you a better understanding on whats going on, and also more power to modify the design/process.  Web2py has more focus on \"simple is better than complex\", but Django has more focus on \"explicit is better than implicit\". Two parts of The Zen of Python, so its very hard to say which framework is more Pythonic.     ","Language":"Python","Tags":["python","django","web2py"],"URL":"https://stackoverflow.com/questions/4352428/django-vs-web2py-for-a-beginner-developer","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Which of these two frameworks is better suited to a developer with 11 months experience. I have decided to learn python for my server side coding and wanted to know which of these would be better suited for someone at my skill level. I have just spent a few days playing around with web2py and really like it and i am wondering if Django offers something more that i am missing out on?  PS. UPDATE: Thank you all for the wonderful input, after buying three django books and going through a few small projects/tutorials for both django and web2py, i have settled on web2py. This is a wonderful framework, which makes web development really fun for a newbe. I would recommend all newbies to learn this framework as it will be mainstream in the future. Django is also a wonderful framework but web2py is just better in my limited experience opinion.     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  Since the return statement terminates the execution of the current function, the two forms are equivalent (although the second one is arguably more readable than the first).  The efficiency of both forms is comparable, the underlying machine code has to perform a jump if the if condition is false anyway.  Note that Python supports a syntax that allows you to use only one return statement in your case:  return A+1 if A > B else A-1      ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  From Chromium's style guide:  Don't use else after return:  # Bad if (foo)   return 1 else   return 2  # Good if (foo)   return 1 return 2  return 1 if foo else 2      ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  With any sensible compiler, you should observe no difference; they should be compiled to identical machine code as they're equivalent.     ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  Regarding coding style:  Most coding standards no matter language ban multiple return statements from a single function as bad practice.   (Although personally I would say there are several cases where multiple return statements do make sense: text/data protocol parsers, functions with extensive error handling etc)  The consensus from all those industry coding standards is that the expression should be written as:  int result;  if(A > B) {   result = A+1; } else {   result = A-1; } return result;     Regarding efficiency:  The above example and the two examples in the question are all completely equivalent in terms of efficiency. The machine code in all these cases have to compare A > B, then branch to either the A+1 or the A-1 calculation, then store the result of that in a CPU register or on the stack.  EDIT :  Sources:   MISRA-C:2004 rule 14.7, which in turn cites...: IEC 61508-3. Part 3, table B.9. IEC 61508-7. C.2.9.      ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  Version A is simpler and that's why I would use it.  And if you turn on all compiler warnings in Java you will get a warning on the second Version because it is unnecesarry and turns up code complexity.     ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  I would always use:  return A+1 if (A > B) else A-1   As it obeys both the good convention of having a single return statement as the last statement in the function (as already mentioned) and the good functional programming paradigm of avoiding imperative style intermediate results. For more complex functions I revert to using a imperative style variable called rval.  I never use multiple return statements, preferring to break the function into multiple sub-functions to avoid this if necessary.  I do not consider the question of efficiency at all, as its the efficiency of coding (i.e. writing error free code) that matters to me.      ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"It is more efficient to use if-return-return or if-else-return?","A_Content":"  I know the question is tagged python, but it mentions dynamic languages so thought I should mention that in ruby the if statement actually has a return type so you can do something like  def foo   rv = if (A > B)          A+1        else          A-1        end   return rv  end   Or because it also has implicit return simply   def foo    if (A>B)     A+1   else      A-1   end end   which gets around the style issue of not having multiple returns quite nicely.     ","Language":"Python","Tags":["python","c","performance","compiler-construction"],"URL":"https://stackoverflow.com/questions/9191388/it-is-more-efficient-to-use-if-return-return-or-if-else-return","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have an if statement with a return. From the efficiency perspective, should I use  if(A > B):     return A+1 return A-1   or  if(A > B):     return A+1 else:     return A-1   Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  To include Unicode characters in your Python source code, you can use Unicode escape characters in the form \\u0123 in your string, and prefix the string literal with 'u'.  Here's an example running in the Python interactive console:  >>> print u'\\u0420\\u043e\\u0441\\u0441\\u0438\\u044f'    Strings declared like this are Unicode-type variables, as described in the Python Unicode documentation.  If running the above command doesn't display the text correctly for you, perhaps your terminal isn't capable of displaying Unicode characters.  For information about reading Unicode data from a file, see this answer:  Character reading from file in Python     ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"75","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  Print a unicode character in Python:  Print a unicode character directly from python interpreter:  el@apollo:~$ python Python 2.7.3 >>> print u'\\u2713'    Unicode character u'\\u2713' is a checkmark.  The interpreter prints the checkmark on the screen.  Print a unicode character from a python script:  Put this in test.py:  #!/usr/bin/python print(\"here is your checkmark: \" + u'\\u2713');   Run it like this:  el@apollo:~$ python test.py here is your checkmark:    If it doesn't show a checkmark for you, then the problem could be elsewhere, like the terminal settings or something you are doing with stream redirection.  Store unicode characters in a file:  Save this to file: foo.py:  #!/usr/bin/python -tt # -*- coding: utf-8 -*- import codecs import sys  UTF8Writer = codecs.getwriter('utf8') sys.stdout = UTF8Writer(sys.stdout) print(u'e with obfuscation: ')   Run it and pipe output to file:  python foo.py > tmp.txt   Open tmp.txt and look inside, you see this:  el@apollo:~$ cat tmp.txt  e with obfuscation:    Thus you have saved unicode e with a obfuscation mark on it to a file.     ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  In Python 2, you declare unicode strings with a u, as in u\"\" and use decode() and encode() to translate to and from unicode, respectively.  It's quite a bit easier in Python 3. A very good overview can be found here.  That presentation clarified a lot of things for me.     ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  If you're trying to print() Unicode, and getting ascii codec errors, check out this page, the TLDR of which is do export PYTHONIOENCODING=UTF-8 before firing up python (this variable controls what sequence of bytes the console tries to encode your string data as).  Internally, Python3 uses UTF-8 by default (see the Unicode HOWTO) so that's not the problem; you can just put Unicode in strings, as seen in the other answers and comments.  It's when you try and get this data out to your console that the problem happens.  Python thinks your console can only handle ascii.  Some of the other answers say, \"Write it to a file, first\" but note they specify the encoding (UTF-8) for doing so (so, Python doesn't change anything in writing), and then use a method for reading the file that just spits out the bytes without any regard for encoding, which is why that works.     ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  I use Portable winpython in Windows, it includes IPython QT console, I could achieve the following.  >>>print (\"\")   >>>print (\"\")   >>>str = \"\"   >>>print (str)    your console interpreter should support unicode in order to show unicode characters.     ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"How to print Unicode character in Python?","A_Content":"  Just one more thing that hasn't been added yet  In Python 2, if you want to print a variable that has unicode and use .format(), then do this (make the base string that is being formatted a unicode string with u'':  >>> text = \"Universit de Montral\" >>> print(u\"This is unicode: {}\".format(text)) >>> This is unicode: Universit de Montral      ","Language":"Python","Tags":["python","python-unicode"],"URL":"https://stackoverflow.com/questions/10569438/how-to-print-unicode-character-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to make a dictionary where English words point to Russian and French translations.   How do I print out unicode characters in Python?  Also, how do you store unicode chars in a variable?     ","Q_Votes":"80"},{"Q_Title":"Filters in Python3 [duplicate]","A_Content":"  It looks like you're using python 3.x.  In python3, filter, map, zip, etc return an object which is iterable, but not a list.  In other words,  filter(func,data) #python 2.x   is equivalent to:  list(filter(func,data)) #python 3.x   I think it was changed because you (often) want to do the filtering in a lazy sense -- You don't need to consume all of the memory to create a list up front, as long as the iterator returns the same thing a list would during iteration.    If you're familiar with list comprehensions and generator expressions, the above filter is now (almost) equivalent to the following in python3.x:  ( x for x in data if func(x) )    As opposed to:  [ x for x in data if func(x) ]   in python 2.x     ","Language":"Python","Tags":["python","list","python-3.x","filter"],"URL":"https://stackoverflow.com/questions/12319025/filters-in-python3","A_Votes":"130","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              How to use filter, map, and reduce in Python 3                                        4 answers                                          I am learning the concept of filters in Python. I am running a simple code like this.  >>> def f(x): return x % 2 != 0 and x % 3 != 0 >>> filter(f, range(2, 25))   But instead of getting a list, I am getting some message like this.  <filter object at 0x00FDC550>   What does this mean? Does it means that my filtered object i.e list to come out is stored at that memory location? How do I get the list which I need?     ","Q_Votes":"80"},{"Q_Title":"Filters in Python3 [duplicate]","A_Content":"  It's an iterator returned by the filter function.  If you want a list, just do  list(filter(f, range(2, 25)))   Nonetheless, you can just iterate over this object with a for loop.  for e in filter(f, range(2, 25)):     do_stuff(e)      ","Language":"Python","Tags":["python","list","python-3.x","filter"],"URL":"https://stackoverflow.com/questions/12319025/filters-in-python3","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to use filter, map, and reduce in Python 3                                        4 answers                                          I am learning the concept of filters in Python. I am running a simple code like this.  >>> def f(x): return x % 2 != 0 and x % 3 != 0 >>> filter(f, range(2, 25))   But instead of getting a list, I am getting some message like this.  <filter object at 0x00FDC550>   What does this mean? Does it means that my filtered object i.e list to come out is stored at that memory location? How do I get the list which I need?     ","Q_Votes":"80"},{"Q_Title":"How many concurrent requests does a single Flask process receive?","A_Content":"  When running the development server you get running app.run(), you get a single synchronous process, which means at most 1 requests being processed at a time.  By sticking Gunicorn in front of it in its default configuration and simply increasing the number of --workers, what you get is essentially a number of processes (managed by Gunicorn) that each behave like the app.run() development server. 4 workers == 4 concurrent requests. This is because Gunicorn uses its included sync worker type by default.   It is important to note that Gunicorn also includes asynchronous workers, namely eventlet and gevent (and also tornado, but that's best used with the Tornado framework, it seems). By specifying one of these async workers with the --worker-class flag, what you get is Gunicorn managing a number of async processes, each of which managing its own concurrency. These processes don't use threads, but instead coroutines. Basically, within each process, still only 1 thing can be happening at a time (1 thread), but objects can be 'paused' when they are waiting on external processes to finish (think database queries or waiting on network I/O).   This means, if you're using one of Gunicorn's async workers, each worker can handle many more than a single request at a time. Just how many workers is best depends on the nature of your app, its environment, the hardware it runs on, etc. More details can be found on Gunicorn's design page and notes on how gevent works on its intro page.      ","Language":"Python","Tags":["python","flask","wsgi","gunicorn"],"URL":"https://stackoverflow.com/questions/10938360/how-many-concurrent-requests-does-a-single-flask-process-receive","A_Votes":"122","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm building an app with Flask, but I don't know much about WSGI and it's HTTP base, Werkzeug. When I start serving a Flask application with gunicorn and 4 worker processes, does this mean that I can handle 4 concurrent requests?  I do mean concurrent requests, and not requests per second or anything else.  Thanks!     ","Q_Votes":"80"},{"Q_Title":"How many concurrent requests does a single Flask process receive?","A_Content":"  Flask will process one request per thread at the same time. If you have 2 processes with 4 threads each, that's 8 concurrent requests.   Flask doesn't spawn or manage threads or processes. That's the responsability of the WSGI gateway (eg. gunicorn).     ","Language":"Python","Tags":["python","flask","wsgi","gunicorn"],"URL":"https://stackoverflow.com/questions/10938360/how-many-concurrent-requests-does-a-single-flask-process-receive","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I'm building an app with Flask, but I don't know much about WSGI and it's HTTP base, Werkzeug. When I start serving a Flask application with gunicorn and 4 worker processes, does this mean that I can handle 4 concurrent requests?  I do mean concurrent requests, and not requests per second or anything else.  Thanks!     ","Q_Votes":"80"},{"Q_Title":"How many concurrent requests does a single Flask process receive?","A_Content":"  No- you can definitely handle more than that.  Its important to remember that deep deep down, assuming you are running a single core machine, the CPU really only runs one instruction* at a time.    Namely, the CPU can only execute a very limited set of instructions, and it can't execute more than one instruction per clock tick (many instructions even take more than 1 tick).  Therefore, most concurrency we talk about in computer science is software concurrency. In other words, there are layers of software implementation that abstract the bottom level CPU from us and make us think we are running code concurrently.  These \"things\" can be processes, which are units of code that get run concurrently in the sense that each process thinks its running in its own world with its own, non-shared memory.  Another example is threads, which are units of code inside processes that allow concurrency as well.   The reason your 4 worker processes will be able to handle more than 4 requests is that they will fire off threads to handle more and more requests.   The actual request limit depends on HTTP server chosen, I/O, OS, hardware, network connection etc.  Good luck!  *instructions are the very basic commands the CPU can run. examples - add two numbers, jump from one instruction to another     ","Language":"Python","Tags":["python","flask","wsgi","gunicorn"],"URL":"https://stackoverflow.com/questions/10938360/how-many-concurrent-requests-does-a-single-flask-process-receive","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm building an app with Flask, but I don't know much about WSGI and it's HTTP base, Werkzeug. When I start serving a Flask application with gunicorn and 4 worker processes, does this mean that I can handle 4 concurrent requests?  I do mean concurrent requests, and not requests per second or anything else.  Thanks!     ","Q_Votes":"80"},{"Q_Title":"How many concurrent requests does a single Flask process receive?","A_Content":"  Currently there is a far simpler solution than the ones already provided. When running your application you just have to pass along the threaded=True parameter to the app.run() call, like:  app.run(host=\"your.host\", port=4321, threaded=True)   Another option as per what we can see in the werkzeug docs, is to use the procesess parameter, which receives a number > 1 indicating the maximum number of concurrent processes to handle:        threaded  should the process handle each request in a separate thread?   processes  if greater than 1 then handle each request in a new process up to this maximum number of concurrent processes.      Something like:  app.run(host=\"your.host\", port=4321, processes=3) #up to 3 processes   More info on the run() method here, and the blog post that led me to find the solution and api references.     ","Language":"Python","Tags":["python","flask","wsgi","gunicorn"],"URL":"https://stackoverflow.com/questions/10938360/how-many-concurrent-requests-does-a-single-flask-process-receive","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm building an app with Flask, but I don't know much about WSGI and it's HTTP base, Werkzeug. When I start serving a Flask application with gunicorn and 4 worker processes, does this mean that I can handle 4 concurrent requests?  I do mean concurrent requests, and not requests per second or anything else.  Thanks!     ","Q_Votes":"80"},{"Q_Title":"Connecting to a host listed in ~/.ssh/config when using Fabric","A_Content":"  Since version 1.4.0, Fabric uses your ssh config (partly). However, you need to explicitly enable it, with  env.use_ssh_config = True   somewhere near the top of your fabfile. Once you do this, Fabric should read your ssh config (from ~/.ssh/config by default, or from env.ssh_config_path).  One warning: if you use a version older than 1.5.4, an abort will occur if env.use_ssh_config is set but there is no config file present. In that case, you can use a workaround like:  if env.ssh_config_path and os.path.isfile(os.path.expanduser(env.ssh_config_path)):     env.use_ssh_config = True      ","Language":"Python","Tags":["python","ssh","fabric"],"URL":"https://stackoverflow.com/questions/3077281/connecting-to-a-host-listed-in-ssh-config-when-using-fabric","A_Votes":"138","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm having trouble with Fabric not recognizing hosts that I have in ~/.ssh/config.  My fabfile.py is as follows:  from fabric.api import run, env  env.hosts = ['lulu']  def whoami():     run('whoami')   Running $ fab whoami gives:     [lulu] run: whoami      Fatal error: Name lookup failed for   lulu   The name lulu is in my ~/.ssh/config, like this:  Host lulu      hostname 192.168.100.100      port 2100      IdentityFile ~/.ssh/lulu-key   My first thought to solving this is adding something like lulu.lulu to /etc/hosts (I'm on a Mac), but then I have to also pass in the identity file to Fabric - and I'd rather keep my authentication (i.e. ~/.ssh/config) separate from my deployment (i.e. fabfile.py).  As well, incidentally, if you try to connect to a host in the hosts file, fabric.contrib.projects.rsync_project doesn't seem to acknowledge 'ports' in the hosts.env (i.e. if you use hosts.env = [lulu:2100] a call to rsync_project seems to try connecting to lulu:21).  Is there a reason Fabric doesn't recognize this lulu name?     ","Q_Votes":"80"},{"Q_Title":"Connecting to a host listed in ~/.ssh/config when using Fabric","A_Content":"  Note that this also happens when the name is not in /etc/hosts. I had the same problem and had to add the host name to both that file and ~/.ssh/config.     ","Language":"Python","Tags":["python","ssh","fabric"],"URL":"https://stackoverflow.com/questions/3077281/connecting-to-a-host-listed-in-ssh-config-when-using-fabric","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm having trouble with Fabric not recognizing hosts that I have in ~/.ssh/config.  My fabfile.py is as follows:  from fabric.api import run, env  env.hosts = ['lulu']  def whoami():     run('whoami')   Running $ fab whoami gives:     [lulu] run: whoami      Fatal error: Name lookup failed for   lulu   The name lulu is in my ~/.ssh/config, like this:  Host lulu      hostname 192.168.100.100      port 2100      IdentityFile ~/.ssh/lulu-key   My first thought to solving this is adding something like lulu.lulu to /etc/hosts (I'm on a Mac), but then I have to also pass in the identity file to Fabric - and I'd rather keep my authentication (i.e. ~/.ssh/config) separate from my deployment (i.e. fabfile.py).  As well, incidentally, if you try to connect to a host in the hosts file, fabric.contrib.projects.rsync_project doesn't seem to acknowledge 'ports' in the hosts.env (i.e. if you use hosts.env = [lulu:2100] a call to rsync_project seems to try connecting to lulu:21).  Is there a reason Fabric doesn't recognize this lulu name?     ","Q_Votes":"80"},{"Q_Title":"Connecting to a host listed in ~/.ssh/config when using Fabric","A_Content":"  update: This Answer is now outdated.    Fabric doesn't have support currently for the .ssh/config file. You can set these up in a function to then call on the cli, eg: fab production task; where production sets the username, hostname, port, and ssh identity.   As for rsync project, that should now have port setting ability, if not, you can always run local(\"rsync ...\") as that is essentially what that contributed function does.     ","Language":"Python","Tags":["python","ssh","fabric"],"URL":"https://stackoverflow.com/questions/3077281/connecting-to-a-host-listed-in-ssh-config-when-using-fabric","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm having trouble with Fabric not recognizing hosts that I have in ~/.ssh/config.  My fabfile.py is as follows:  from fabric.api import run, env  env.hosts = ['lulu']  def whoami():     run('whoami')   Running $ fab whoami gives:     [lulu] run: whoami      Fatal error: Name lookup failed for   lulu   The name lulu is in my ~/.ssh/config, like this:  Host lulu      hostname 192.168.100.100      port 2100      IdentityFile ~/.ssh/lulu-key   My first thought to solving this is adding something like lulu.lulu to /etc/hosts (I'm on a Mac), but then I have to also pass in the identity file to Fabric - and I'd rather keep my authentication (i.e. ~/.ssh/config) separate from my deployment (i.e. fabfile.py).  As well, incidentally, if you try to connect to a host in the hosts file, fabric.contrib.projects.rsync_project doesn't seem to acknowledge 'ports' in the hosts.env (i.e. if you use hosts.env = [lulu:2100] a call to rsync_project seems to try connecting to lulu:21).  Is there a reason Fabric doesn't recognize this lulu name?     ","Q_Votes":"80"},{"Q_Title":"Connecting to a host listed in ~/.ssh/config when using Fabric","A_Content":"  One can use following code to read the config (original code taken from: http://markpasc.typepad.com/blog/2010/04/loading-ssh-config-settings-for-fabric.html):  from fabric.api import * env.hosts = ['servername']  def _annotate_hosts_with_ssh_config_info():     from os.path import expanduser     from paramiko.config import SSHConfig      def hostinfo(host, config):         hive = config.lookup(host)         if 'hostname' in hive:             host = hive['hostname']         if 'user' in hive:             host = '%s@%s' % (hive['user'], host)         if 'port' in hive:             host = '%s:%s' % (host, hive['port'])         return host      try:         config_file = file(expanduser('~/.ssh/config'))     except IOError:         pass     else:         config = SSHConfig()         config.parse(config_file)         keys = [config.lookup(host).get('identityfile', None)             for host in env.hosts]         env.key_filename = [expanduser(key) for key in keys if key is not None]         env.hosts = [hostinfo(host, config) for host in env.hosts]          for role, rolehosts in env.roledefs.items():             env.roledefs[role] = [hostinfo(host, config) for host in rolehosts]  _annotate_hosts_with_ssh_config_info()      ","Language":"Python","Tags":["python","ssh","fabric"],"URL":"https://stackoverflow.com/questions/3077281/connecting-to-a-host-listed-in-ssh-config-when-using-fabric","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm having trouble with Fabric not recognizing hosts that I have in ~/.ssh/config.  My fabfile.py is as follows:  from fabric.api import run, env  env.hosts = ['lulu']  def whoami():     run('whoami')   Running $ fab whoami gives:     [lulu] run: whoami      Fatal error: Name lookup failed for   lulu   The name lulu is in my ~/.ssh/config, like this:  Host lulu      hostname 192.168.100.100      port 2100      IdentityFile ~/.ssh/lulu-key   My first thought to solving this is adding something like lulu.lulu to /etc/hosts (I'm on a Mac), but then I have to also pass in the identity file to Fabric - and I'd rather keep my authentication (i.e. ~/.ssh/config) separate from my deployment (i.e. fabfile.py).  As well, incidentally, if you try to connect to a host in the hosts file, fabric.contrib.projects.rsync_project doesn't seem to acknowledge 'ports' in the hosts.env (i.e. if you use hosts.env = [lulu:2100] a call to rsync_project seems to try connecting to lulu:21).  Is there a reason Fabric doesn't recognize this lulu name?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  To explain \"why\":  The + operation adds the array elements to the original array. The array.append operation inserts the array (or any object) into the end of the original array, which results in a reference to self in that spot (hence the infinite recursion).  The difference here is that the + operation acts specific when you add an array (it's overloaded like others, see this chapter on sequences) by concatenating the element. The append-method however does literally what you ask: append the object on the right-hand side that you give it (the array or any other object), instead of taking its elements.  An alternative  Use extend() if you want to use a function that acts similar to the + operator (as others have shown here as well). It's not wise to do the opposite: to try to mimic append with the + operator for lists (see my earlier link on why).  Little history  For fun, a little history: the birth of the array module in Python in February 1993. it might surprise you, but arrays were added way after sequences and lists came into existence.     ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"114","_type":"dict","isAccepted":"Yes","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  append is appending an element to a list. if you want to extend the list with the new list you need to use extend.  >>> c = [1, 2, 3] >>> c.extend(c) >>> c [1, 2, 3, 1, 2, 3]      ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  The concatenation operator + is a binary infix operator which, when applied to lists, returns a new list containing all the elements of each of its two operands. The list.append() method is a mutator on list which appends its single object argument (in your specific example the list c) to the subject list. In your example this results in c appending a reference to itself (hence the infinite recursion).  An alternative to '+' concatenation  The list.extend() method is also a mutator method which concatenates its sequence argument with the subject list. Specifically, it appends each of the elements of sequence in iteration order.  An aside  Being an operator, + returns the result of the expression as a new value. Being a non-chaining mutator method, list.extend() modifies the subject list in-place and returns nothing.  Arrays  I've added this due to the potential confusion which the Abel's answer above may cause by mixing the discussion of lists, sequences and arrays. Arrays were added to Python after sequences and lists, as a more efficient way of storing arrays of integral data types. Do not confuse arrays with lists. They are not the same.   From the array docs:   Arrays are sequence types and behave very much like lists, except that the type of objects stored in them is constrained. The type is specified at object creation time by using a type code, which is a single character.     ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  Python lists are heterogeneous that is the elements in the same list can be any type of object. The expression: c.append(c) appends the object c what ever it may be to the list. In the case it makes the list itself a member of the list.  The expression c += c adds two lists together and assigns the result to the variable c. The overloaded + operator is defined on lists to create a new list whose contents are the elements in the first list and the elements in the second list.  So these are really just different expressions used to do different things by design.     ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  The method you're looking for is extend(). From the Python documentation:  list.append(x)     Add an item to the end of the list; equivalent to a[len(a):] = [x].  list.extend(L)     Extend the list by appending all the items in the given list; equivalent to a[len(a):] = L.  list.insert(i, x)     Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).      ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  you should use extend()  >>> c=[1,2,3] >>> c.extend(c) >>> c [1, 2, 3, 1, 2, 3]   other info: append vs. extend     ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python append() vs. + operator on lists, why do these give different results?","A_Content":"  See the documentation:     list.append(x)         Add an item to the end of the list; equivalent to a[len(a):] = [x].         list.extend(L)    - Extend the list by appending all the items in the given list;   equivalent to a[len(a):] = L.   c.append(c) \"appends\" c to itself as an element. Since a list is a reference type, this creates a recursive data structure.  c += c is equivalent to extend(c), which appends the elements of c to c.     ","Language":"Python","Tags":["python","list","append","nested-lists"],"URL":"https://stackoverflow.com/questions/2022031/python-append-vs-operator-on-lists-why-do-these-give-different-results","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Why do these two operations (append() resp. +) give different results?  >>> c = [1, 2, 3] >>> c [1, 2, 3] >>> c += c >>> c [1, 2, 3, 1, 2, 3] >>> c = [1, 2, 3] >>> c.append(c) >>> c [1, 2, 3, [...]] >>>    In the last case there's actually an infinite recursion. c[-1] and c are the same. Why is it different with the + operation?     ","Q_Votes":"80"},{"Q_Title":"Python: How can I increment a char?","A_Content":"  In Python 2.x, just use the ord and chr functions:  >>> ord('c') 99 >>> ord('c') + 1 100 >>> chr(ord('c') + 1) 'd' >>>    Python 3.x makes this more organized and interesting, due to its clear distinction between bytes and unicode. By default, a \"string\" is unicode, so the above works (ord receives Unicode chars and chr produces them).  But if you're interested in bytes (such as for processing some binary data stream), things are even simpler:  >>> bstr = b'abc' >>> bstr[0] 97 >>> bytes([97, 98, 99]) b'abc' >>> bytes([bstr[0] + 1, 98, 99]) b'bbc'      ","Language":"Python","Tags":["python","char","increment"],"URL":"https://stackoverflow.com/questions/2156892/python-how-can-i-increment-a-char","A_Votes":"147","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm new to Python, coming from Java and C. How can I increment a char? In Java or C, chars and ints are practically interchangeable, and in certain loops, it's very useful to me to be able to do increment chars, and index arrays by chars.   How can I do this in Python? It's bad enough not having a traditional for(;;) looper - is there any way I can achieve what I want to achieve without having to rethink my entire strategy?  Any help appreciated.     ","Q_Votes":"80"},{"Q_Title":"Python: How can I increment a char?","A_Content":"  \"bad enough not having a traditional for(;;) looper\"??  What?    Are you trying to do   import string for c in string.lowercase:     ...do something with c...   Or perhaps you're using string.uppercase or string.letters?  Python doesn't have for(;;) because there are often better ways to do it.  It also doesn't have character math because it's not necessary, either.     ","Language":"Python","Tags":["python","char","increment"],"URL":"https://stackoverflow.com/questions/2156892/python-how-can-i-increment-a-char","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm new to Python, coming from Java and C. How can I increment a char? In Java or C, chars and ints are practically interchangeable, and in certain loops, it's very useful to me to be able to do increment chars, and index arrays by chars.   How can I do this in Python? It's bad enough not having a traditional for(;;) looper - is there any way I can achieve what I want to achieve without having to rethink my entire strategy?  Any help appreciated.     ","Q_Votes":"80"},{"Q_Title":"Python: How can I increment a char?","A_Content":"  I came from PHP, where you can increment char (A to B, Z to AA, AA to AB etc.) using ++ operator. I made a simple function which does the same in Python. You can also change list of chars to whatever (lowercase, uppercase, etc.) is your need.  # Increment char (a -> b, az -> ba) def inc_char(text, chlist = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'):     # Unique and sort     chlist = ''.join(sorted(set(str(chlist))))     chlen = len(chlist)     if not chlen:         return ''     text = str(text)     # Replace all chars but chlist     text = re.sub('[^' + chlist + ']', '', text)     if not len(text):         return chlist[0]     # Increment     inc = ''     over = False     for i in range(1, len(text)+1):         lchar = text[-i]         pos = chlist.find(lchar) + 1         if pos < chlen:             inc = chlist[pos] + inc             over = False             break         else:             inc = chlist[0] + inc             over = True     if over:         inc += chlist[0]     result = text[0:-len(inc)] + inc     return result      ","Language":"Python","Tags":["python","char","increment"],"URL":"https://stackoverflow.com/questions/2156892/python-how-can-i-increment-a-char","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm new to Python, coming from Java and C. How can I increment a char? In Java or C, chars and ints are practically interchangeable, and in certain loops, it's very useful to me to be able to do increment chars, and index arrays by chars.   How can I do this in Python? It's bad enough not having a traditional for(;;) looper - is there any way I can achieve what I want to achieve without having to rethink my entire strategy?  Any help appreciated.     ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  As @S.Lott says, you should be opening your files in 'rb' mode, not 'rU' mode. However that may NOT be causing your current problem. As far as I know, using 'rU' mode would mess you up if there are embedded \\r in the data, but not cause any other dramas. I also note that you have several files (all opened with 'rU' ??) but only one causing a problem.  If the csv module says that you have a \"NULL\" (silly message, should be \"NUL\") byte in your file, then you need to check out what is in your file. I would suggest that you do this even if using 'rb' makes the problem go away.  repr() is (or wants to be) your debugging friend. It will show unambiguously what you've got, in a platform independant fashion (which is helpful to helpers who are unaware what od is or does). Do this:  print repr(open('my.csv', 'rb').read(200)) # dump 1st 200 bytes of file   and carefully copy/paste (don't retype) the result into an edit of your question (not into a comment).  Also note that if the file is really dodgy e.g. no \\r or \\n within reasonable distance from the start of the file, the line number reported by reader.line_num will be (unhelpfully) 1. Find where the first \\x00 is (if any) by doing  data = open('my.csv', 'rb').read() print data.find('\\x00')   and make sure that you dump at least that many bytes with repr or od.  What does data.count('\\x00') tell you? If there are many, you may want to do something like  for i, c in enumerate(data):     if c == '\\x00':         print i, repr(data[i-30:i]) + ' *NUL* ' + repr(data[i+1:i+31])   so that you can see the NUL bytes in context.  If you can see \\x00 in the output (or \\0 in your od -c output), then you definitely have NUL byte(s) in the file, and you will need to do something like this:  fi = open('my.csv', 'rb') data = fi.read() fi.close() fo = open('mynew.csv', 'wb') fo.write(data.replace('\\x00', '')) fo.close()   By the way, have you looked at the file (including the last few lines) with a text editor? Does it actually look like a reasonable CSV file like the other (no \"NULL byte\" exception) files?     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"96","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  Reading it as UTF-16 was also my problem.  Here's my code that ended up working:  f=codecs.open(location,\"rb\",\"utf-16\") csvread=csv.reader(f,delimiter='\\t') csvread.next() for row in csvread:     print row   Where location is the directory of your csv file.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  data_initial = open(\"staff.csv\", \"rb\") data = csv.reader((line.replace('\\0','') for line in data_initial), delimiter=\",\")   This works for me.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  I bumped into this problem as well.  Using the Python csv module, I was trying to read an XLS file created in MS Excel and running into the NULL byte error you were getting.  I looked around and found the xlrd Python module for reading and formatting data from MS Excel spreadsheet files.  With the xlrd module, I am not only able to read the file properly, but I can also access many different parts of the file in a way I couldn't before.  I thought it might help you.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  Converting the encoding of the source file from UTF-16 to UTF-8 solve my problem.  How to convert a file to utf-8 in Python?  import codecs BLOCKSIZE = 1048576 # or some other, desired size in bytes with codecs.open(sourceFileName, \"r\", \"utf-16\") as sourceFile:     with codecs.open(targetFileName, \"w\", \"utf-8\") as targetFile:         while True:             contents = sourceFile.read(BLOCKSIZE)             if not contents:                 break             targetFile.write(contents)      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  You could just inline a generator to filter out the null values if you want to pretend they don't exist.  Of course this is assuming the null bytes are not really part of the encoding and really are some kind of erroneous artifact or bug.  with open(filepath, \"rb\") as f:     reader = csv.reader( (line.replace('\\0','') for line in f) )      try:         for row in reader:             print 'Row read successfully!', row     except csv.Error, e:         sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  Why are you doing this?   reader = csv.reader(open(filepath, \"rU\"))   The docs are pretty clear that you must do this:  with open(filepath, \"rb\") as src:     reader= csv.reader( src )   The mode must be \"rb\" to read.  http://docs.python.org/library/csv.html#csv.reader     If csvfile is a file object, it must be opened with the b flag on platforms where that makes a difference.       ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  appparently it's a XLS file and not a CSV file as http://www.garykessler.net/library/file_sigs.html confirm     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  Instead of csv reader I use read file and split function for string:  lines = open(input_file,'rb')   for line_all in lines:      line=line_all.replace('\\x00', '').split(\";\")      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  I got the same error. Saved the file in UTF-8 and it worked.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  This happened to me when I created a CSV file with OpenOffice Calc. It didn't happen when I created the CSV file in my text editor, even if I later edited it with Calc.  I solved my problem by copy-pasting in my text editor the data  from my Calc-created file to a new editor-created file.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  I had the same problem opening a CSV produced from a webservice which inserted NULL bytes in empty headers. I did the following to clean the file:  with codecs.open ('my.csv', 'rb', 'utf-8') as myfile:     data = myfile.read()     # clean file first if dirty     if data.count( '\\x00' ):         print 'Cleaning...'         with codecs.open('my.csv.tmp', 'w', 'utf-8') as of:             for line in data:                 of.write(line.replace('\\x00', ''))          shutil.move( 'my.csv.tmp', 'my.csv' )  with codecs.open ('my.csv', 'rb', 'utf-8') as myfile:     myreader = csv.reader(myfile, delimiter=',')     # Continue with your business logic here...   Disclaimer: Be aware that this overwrites your original data. Make sure you have a backup copy of it. You have been warned!     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  For all those 'rU' filemode haters: I just tried opening a CSV file from a Windows machine on a Mac with the 'rb' filemode and I got this error from the csv module:  Error: new-line character seen in unquoted field - do you need to  open the file in universal-newline mode?   Opening the file in 'rU' mode works fine. I love universal-newline mode -- it saves me so much hassle.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  I encountered this when using scrapy and fetching a zipped csvfile without having a correct middleware to unzip the response body before handing it to the csvreader. Hence the file was not really a csv file and threw the line contains NULL byte error accordingly.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  Have you tried using gzip.open?  with gzip.open('my.csv', 'rb') as data_file:   I was trying to open a file that had been compressed but had the extension '.csv' instead of 'csv.gz'. This error kept showing up until I used gzip.open     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python CSV error: line contains NULL byte","A_Content":"  One case is that - If the CSV file contains empty rows this error may show up. Check for row is necessary before we proceed to write or read.  for row in csvreader:         if (row):                    do something   I solved my issue by adding this check in the code.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm working with some CSV files, with the following code:  reader = csv.reader(open(filepath, \"rU\")) try:     for row in reader:         print 'Row read successfully!', row except csv.Error, e:     sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))   And one file is throwing this error:   file my.csv, line 1: line contains NULL byte   What can I do? Google seems to suggest that it may be an Excel file that's been saved as a .csv improperly. Is there any way I can get round this problem in Python?  == UPDATE ==  Following @JohnMachin's comment below, I tried adding these lines to my script:   print repr(open(filepath, 'rb').read(200)) # dump 1st 200 bytes of file data = open(filepath, 'rb').read() print data.find('\\x00') print data.count('\\x00')   And this is the output I got:   '\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ .... <snip> 8 13834   So the file does indeed contain NUL bytes.      ","Q_Votes":"80"},{"Q_Title":"Python class method decorator with self arguments?","A_Content":"  Yes. Instead of passing in the instance attribute at class definition time, check it at runtime:  def check_authorization(f):     def wrapper(*args):         print args[0].url         return f(*args)     return wrapper  class Client(object):     def __init__(self, url):         self.url = url      @check_authorization     def get(self):         print 'get'  >>> Client('http://www.google.com').get() http://www.google.com get   The decorator intercepts the method arguments; the first argument is the instance, so it reads the attribute off of that. You can pass in the attribute name as a string to the decorator and use getattr if you don't want to hardcode the attribute name:  def check_authorization(attribute):     def _check_authorization(f):         def wrapper(self, *args):             print getattr(self, attribute)             return f(self, *args)         return wrapper     return _check_authorization      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11731136/python-class-method-decorator-with-self-arguments","A_Votes":"120","_type":"dict","isAccepted":"Yes","Q_Content":"    How do I pass a class field to a decorator on a class method as an argument?  What I want to do is something like:  class Client(object):     def __init__(self, url):         self.url = url      @check_authorization(\"some_attr\", self.url)     def get(self):         do_work()   It complains that self doesn't exist for passing self.url to the decorator.  Is there a way around this?     ","Q_Votes":"80"},{"Q_Title":"Python class method decorator with self arguments?","A_Content":"  from re import search from functools import wraps  def is_match(_lambda, pattern):     def wrapper(f):         @wraps(f)         def wrapped(self, *f_args, **f_kwargs):             if callable(_lambda) and search(pattern, (_lambda(self) or '')):                  f(self, *f_args, **f_kwargs)         return wrapped     return wrapper  class MyTest(object):      def __init__(self):         self.name = 'foo'         self.surname = 'bar'      @is_match(lambda x: x.name, 'foo')     @is_match(lambda x: x.surname, 'foo')     def my_rule(self):         print 'my_rule : ok'      @is_match(lambda x: x.name, 'foo')     @is_match(lambda x: x.surname, 'bar')     def my_rule2(self):         print 'my_rule2 : ok'    test = MyTest() test.my_rule() test.my_rule2()      ouput:   my_rule2 : ok      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11731136/python-class-method-decorator-with-self-arguments","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    How do I pass a class field to a decorator on a class method as an argument?  What I want to do is something like:  class Client(object):     def __init__(self, url):         self.url = url      @check_authorization(\"some_attr\", self.url)     def get(self):         do_work()   It complains that self doesn't exist for passing self.url to the decorator.  Is there a way around this?     ","Q_Votes":"80"},{"Q_Title":"Python class method decorator with self arguments?","A_Content":"  A more concise example might be as follows:  #/usr/bin/env python3 from functools import wraps  def wrapper(method):     @wraps(method)     def _impl(self, *method_args, **method_kwargs):         return method(self, *method_args, **method_kwargs) + \"!\"     return _impl  class Foo:     @wrapper     def bar(self, word):         return word  f = Foo() result = f.bar(\"kitty\") print(result)   Which will print:  kitty!      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11731136/python-class-method-decorator-with-self-arguments","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    How do I pass a class field to a decorator on a class method as an argument?  What I want to do is something like:  class Client(object):     def __init__(self, url):         self.url = url      @check_authorization(\"some_attr\", self.url)     def get(self):         do_work()   It complains that self doesn't exist for passing self.url to the decorator.  Is there a way around this?     ","Q_Votes":"80"},{"Q_Title":"Python class method decorator with self arguments?","A_Content":"  You can't. There's no self in the class body, because no instance exists. You'd need to pass it, say, a str containing the attribute name to lookup on the instance, which the returned function can then do, or use a different method entirely.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11731136/python-class-method-decorator-with-self-arguments","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How do I pass a class field to a decorator on a class method as an argument?  What I want to do is something like:  class Client(object):     def __init__(self, url):         self.url = url      @check_authorization(\"some_attr\", self.url)     def get(self):         do_work()   It complains that self doesn't exist for passing self.url to the decorator.  Is there a way around this?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  The typical approach is to use select() to wait until data is available or until the timeout occurs.  Only call recv() when data is actually available.  To be safe, we also set the socket to non-blocking mode to guarantee that recv() will never block indefinitely.  select() can also be used to wait on more than one socket at a time.  import select  mysocket.setblocking(0)  ready = select.select([mysocket], [], [], timeout_in_seconds) if ready[0]:     data = mysocket.recv(4096)   If you have a lot of open file descriptors, poll() is a more efficient alternative to select().  Another option is to set a timeout for all operations on the socket using socket.settimeout(), but I see that you've explicitly rejected that solution in another answer.     ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"90","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  there's socket.settimeout()     ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"43","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  As mentioned both select.select() and socket.settimeout() will work.  Note you might need to call settimeout twice for your needs, e.g.  sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # accept can throw socket.timeout sock.settimeout(5.0) conn, addr = sock.accept()  # recv can throw socket.timeout conn.settimeout(5.0) conn.recv(1024)      ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  You could set timeout before receiving the response and after having received the response set it back to None:  sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  sock.settimeout(5.0) data = sock.recv(1024) sock.settimeout(None)      ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  The timeout that you are looking for is the connection socket's timeout not the primary socket's, if you implement the server side. In other words, there is another timeout for the connection socket object, which is the output of socket.accept() method. Therefore:  sock.listen(1) connection, client_address = sock.accept() connection.settimeout(5)    # This is the one that affects recv() method. connection.gettimeout()     # This should result 5 sock.gettimeout()           # This outputs None when not set previously, if I remember correctly.   If you implement the client side, it would be simple.  sock.connect(server_address) sock.settimeout(3)      ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"How to set timeout on python's socket recv method?","A_Content":"  try this it uses the underlying C.  timeval = struct.pack('ll', 2, 100)  s.setsockopt(socket.SOL_SOCKET,SO_RCVTIMEO, timeval)      ","Language":"Python","Tags":["python","sockets","timeout"],"URL":"https://stackoverflow.com/questions/2719017/how-to-set-timeout-on-pythons-socket-recv-method","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to set timeout on python's socket recv method. How to do it?     ","Q_Votes":"80"},{"Q_Title":"python Named tuple to dictionary","A_Content":"  TL;DR: there's a method _asdict provided for this.  Here is a demonstration of the usage:  >>> fields = ['name', 'population', 'coordinates', 'capital', 'state_bird'] >>> Town = collections.namedtuple('Town', fields) >>> funkytown = Town('funky', 300, 'somewhere', 'lipps', 'chicken') >>> funkytown._asdict() OrderedDict([('name', 'funky'),              ('population', 300),              ('coordinates', 'somewhere'),              ('capital', 'lipps'),              ('state_bird', 'chicken')])   This is a documented method of namedtuples, i.e. unlike the usual convention in python the leading underscore on the method name isn't there to discourage use.  Along with the other methods added to namedtuples, _make, _replace, _source, _fields, it has the underscore only to try and prevent conflicts with possible field names.    Note:  For some 2.7.5 < python version < 3.5.0 code out in the wild, you might see this version:  >>> vars(funkytown) OrderedDict([('name', 'funky'),              ('population', 300),              ('coordinates', 'somewhere'),              ('capital', 'lipps'),              ('state_bird', 'chicken')])   For a while the documentation had mentioned that _asdict was obsolete (see here), and suggested to use the built-in method vars.  That advice is now outdated; in order to fix a bug related to subclassing, the __dict__ property which was present on namedtuples has again been removed by this commit.       ","Language":"Python","Tags":["python","dictionary","tuples","namedtuple"],"URL":"https://stackoverflow.com/questions/26180528/python-named-tuple-to-dictionary","A_Votes":"149","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a named tuple class in python   class Town(collections.namedtuple('Town', [     'name',      'population',     'coordinates',     'population',      'capital',      'state_bird'])):     # ...   What I'd like to do is turn this into a dictionary. I'll admit python is not one of my stronger languages. The key is that I dont want it to be rigidly tied to the name or numbers of the fields I have.   Is there a way to write it such that I could add more fields, or pass an entirely different named tuple in and get a dictionary.  Edit: I cant not alter the original class definition as its in someone elses code. So I need to take an instance of a Town and convert it to a dictionary.     ","Q_Votes":"80"},{"Q_Title":"python Named tuple to dictionary","A_Content":"  There's a built in method on namedtuple instances for this, _asdict.  As discussed in the comments, on some versions vars() will also do it, but it's apparently highly dependent on build details, whereas _asdict should be reliable. In some versions _asdict was marked as deprecated, but comments indicate that this is no longer the case as of 3.4.     ","Language":"Python","Tags":["python","dictionary","tuples","namedtuple"],"URL":"https://stackoverflow.com/questions/26180528/python-named-tuple-to-dictionary","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have a named tuple class in python   class Town(collections.namedtuple('Town', [     'name',      'population',     'coordinates',     'population',      'capital',      'state_bird'])):     # ...   What I'd like to do is turn this into a dictionary. I'll admit python is not one of my stronger languages. The key is that I dont want it to be rigidly tied to the name or numbers of the fields I have.   Is there a way to write it such that I could add more fields, or pass an entirely different named tuple in and get a dictionary.  Edit: I cant not alter the original class definition as its in someone elses code. So I need to take an instance of a Town and convert it to a dictionary.     ","Q_Votes":"80"},{"Q_Title":"python Named tuple to dictionary","A_Content":"  On Ubuntu 14.04 LTS versions of python2.7 and python3.4 the __dict__ property worked as expected. The _asdict method also worked, but I'm inclined to use the standards-defined, uniform, property api instead of the localized non-uniform api.  $ python2.7  # Works on: # Python 2.7.6 (default, Jun 22 2015, 17:58:13)  [GCC 4.8.2] on linux2 # Python 3.4.3 (default, Oct 14 2015, 20:28:29)  [GCC 4.8.4] on linux  import collections  Color = collections.namedtuple('Color', ['r', 'g', 'b']) red = Color(r=256, g=0, b=0)  # Access the namedtuple as a dict print(red.__dict__['r'])  # 256  # Drop the namedtuple only keeping the dict red = red.__dict__ print(red['r'])  #256   Seeing as dict is the semantic way to get a dictionary representing soemthing, (at least to the best of my knowledge).    It would be nice to accumulate a table of major python versions and platforms and their support for __dict__, currently I only have one platform version and two python versions as posted above.  | Platform         | PyVer     | __dict__ | _asdict | | -------------    | --------- | -------- | ------- | | Ubuntu 14.04 LTS | Python2.7 | yes      | yes     | | Ubuntu 14.04 LTS | Python3.4 | yes      | yes     |      ","Language":"Python","Tags":["python","dictionary","tuples","namedtuple"],"URL":"https://stackoverflow.com/questions/26180528/python-named-tuple-to-dictionary","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a named tuple class in python   class Town(collections.namedtuple('Town', [     'name',      'population',     'coordinates',     'population',      'capital',      'state_bird'])):     # ...   What I'd like to do is turn this into a dictionary. I'll admit python is not one of my stronger languages. The key is that I dont want it to be rigidly tied to the name or numbers of the fields I have.   Is there a way to write it such that I could add more fields, or pass an entirely different named tuple in and get a dictionary.  Edit: I cant not alter the original class definition as its in someone elses code. So I need to take an instance of a Town and convert it to a dictionary.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  Long integers:  There is no explicitly defined limit. The amount of available address space forms a practical limit. (Taken from this site). See the docs on Numeric Types where you'll see that Long integers have unlimited precision. In Python 2, Integers will automatically switch to longs when they grow beyond their limit:  >>> import sys >>> type(sys.maxsize) <type 'int'> >>> type(sys.maxsize+1) <type 'long'>    for integers we have  maxint and maxsize:  The maximum value of an int can be found in Python 2.x with sys.maxint. It was removed in Python 3, but sys.maxsize can often be used instead. From the changelog:     The sys.maxint constant was removed, since there is no longer a limit   to the value of integers. However, sys.maxsize can be used as an   integer larger than any practical list or string index. It conforms to   the implementations natural integer size and is typically the same   as sys.maxint in previous releases on the same platform (assuming the   same build options).   and, for anyone interested in the difference (Python 2.x):     sys.maxint The largest positive integer supported by Pythons regular   integer type. This is at least 2**31-1. The largest negative integer   is -maxint-1  the asymmetry results from the use of 2s complement   binary arithmetic.      sys.maxsize The largest positive integer supported by the platforms   Py_ssize_t type, and thus the maximum size lists, strings, dicts, and   many other containers can have.   and for completeness, here's the Python 3 version:     sys.maxsize    An integer giving the maximum value a variable of type Py_ssize_t can take. Its usually 2^31 - 1 on a 32-bit platform and   2^63 - 1 on a 64-bit platform.   floats:  There's float(\"inf\") and float(\"-inf\"). These can be compared to other numeric types:  >>> import sys >>> float(\"inf\") > sys.maxsize True      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"104","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  Python long can be arbitrarily large. If you need a value that's greater than any other value, you can use float('inf'), since Python has no trouble comparing numeric values of different types. Similarly, for a value lesser than any other value, you can use float('-inf').     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"33","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  Direct answer to title question:  Integers are unlimited in size and have no maximum value in Python.  Answer which addresses stated underlying use case:  According to your comment of what you're trying to do, you are currently thinking something along the lines of  minval = MAXINT; for (i = 1; i < num_elems; i++)     if a[i] < a[i-1]         minval = a[i];   That's not how to think in Python. A better translation to Python (but still not the best) would be  minval = a[0]  # Just use the first value for i in range(1, len(a)):     minval = min(a[i], a[i - 1])   Note that the above doesn't use MAXINT at all. That part of the solution applies to any programming language: You don't need to know the highest possible value just to find the smallest value in a collection.  But anyway, what you really do in Python is just  minval = min(a)   That is, you don't write a loop at all. The built-in min() function gets the minimum of the whole collection.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  Unlike C/C++ Long  in Python have unlimited precision. Refer the section Numeric Types  in python for more information.To determine the max value of integer you can just refer sys.maxint. You can get more details from the documentation of sys.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  long type in Python 2.x uses arbitrary precision arithmetic and has no such thing as maximum possible value. It is limited by the available memory. Python 3.x has no special type for values that cannot be represented by the native machine integer  everything is int and conversion is handled behind the scenes.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  You can use: max value of float is    float('inf')   for negative  float('-inf')      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Maximum value for long integer","A_Content":"  In python3, you can send the float value into the int function the get that number 1.7976931348623157e+308 in integer representation.  import sys     int(sys.float_info.max)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/9860588/maximum-value-for-long-integer","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I assign the maximum value for a long integer to a variable, similar, for example, to C++'s LONG_MAX.     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  The .encode method gets applied to a Unicode string to make a byte-string; but you're calling it on a byte-string instead... the wrong way 'round!  Look at the codecs module in the standard library and codecs.open in particular for better general solutions for reading UTF-8 encoded text files. However, for the csv module in particular, you need to pass in utf-8 data, and that's what you're already getting, so your code can be much simpler:  import csv  def unicode_csv_reader(utf8_data, dialect=csv.excel, **kwargs):     csv_reader = csv.reader(utf8_data, dialect=dialect, **kwargs)     for row in csv_reader:         yield [unicode(cell, 'utf-8') for cell in row]  filename = 'da.csv' reader = unicode_csv_reader(open(filename)) for field1, field2, field3 in reader:   print field1, field2, field3    PS: if it turns out that your input data is NOT in utf-8, but e.g. in ISO-8859-1, then you do need a \"transcoding\" (if you're keen on using utf-8 at the csv module level), of the form line.decode('whateverweirdcodec').encode('utf-8') -- but probably you can just use the name of your existing encoding in the yield line in my code above, instead of 'utf-8', as csv is actually going to be just fine with ISO-8859-* encoded bytestrings.     ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"104","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  Python 2.X  There is a unicode-csv library which should solve your problems, with added benefit of not naving to write any new csv-related code.  Here is a example from their readme:  >>> import unicodecsv >>> from cStringIO import StringIO >>> f = StringIO() >>> w = unicodecsv.writer(f, encoding='utf-8') >>> w.writerow((u'', u'')) >>> f.seek(0) >>> r = unicodecsv.reader(f, encoding='utf-8') >>> row = r.next() >>> print row[0], row[1]     Python 3.X  In python 3 this is supported out of the box by the build-in csv module. See this example:   import csv with open('some.csv', newline='', encoding='utf-8') as f:     reader = csv.reader(f)     for row in reader:         print(row)      ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  Also checkout the answer in this post: https://stackoverflow.com/a/9347871/1338557  It suggests use of library called ucsv.py. Short and simple replacement for CSV written to address the encoding problem(utf-8) for Python 2.7. Also provides support for csv.DictReader  Edit: Adding sample code that I used:  import ucsv as csv  #Read CSV file containing the right tags to produce fileObj = open('awol_title_strings.csv', 'rb') dictReader = csv.DictReader(fileObj, fieldnames = ['titles', 'tags'], delimiter = ',', quotechar = '\"') #Build a dictionary from the CSV file-> {<string>:<tags to produce>} titleStringsDict = dict() for row in dictReader:     titleStringsDict.update({unicode(row['titles']):unicode(row['tags'])})      ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  Using codecs.open as Alex Martelli suggested proved to be useful to me.  import codecs  delimiter = ';' reader = codecs.open(\"your_filename.csv\", 'r', encoding='utf-8') for line in reader:     row = line.split(delimiter)     # do something with your row ...      ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  The link to the help page is the same for python 2.6 and as far as I know there was no change in the csv module since 2.5 (besides bug fixes). Here is the code that just works without any encoding/decoding (file da.csv contains the same data as the variable data). I assume that your file should be read correctly without any conversions.  test.py:  ## -*- coding: utf-8 -*- # # NOTE: this first line is important for the version b) read from a string(unicode) variable #  import csv  data = \\ \"\"\"0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert\"\"\"  # a) read from a file print 'reading from a file:' for (f1, f2, f3) in csv.reader(open('da.csv'), dialect=csv.excel):     print (f1, f2, f3)  # b) read from a string(unicode) variable print 'reading from a list of strings:' reader = csv.reader(data.split('\\n'), dialect=csv.excel) for (f1, f2, f3) in reader:     print (f1, f2, f3)   da.csv:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert      ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  Looking at the Latin-1 unicode table, I see the character code 00E9 \"LATIN SMALL LETTER E WITH ACUTE\". This is the accented character in your sample data. A simple test in Python shows that UTF-8 encoding for this character is different from the unicode (almost UTF-16) encoding.  >>> u'\\u00e9' u'\\xe9' >>> u'\\u00e9'.encode('utf-8') '\\xc3\\xa9' >>>    I suggest you try to encode(\"UTF-8\") the unicode data before calling the special unicode_csv_reader(). Simply reading the data from a file might hide the encoding, so check the actual character values.     ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Reading a UTF8 CSV file with Python","A_Content":"  If you want to read a CSV File with encoding utf-8, a minimalistic approach that I recommend you is to use something like this:          with open(file_name, encoding=\"utf8\") as csv_file:   With that statement, you can use later a CSV reader to work with.     ","Language":"Python","Tags":["python","utf-8","csv","character-encoding"],"URL":"https://stackoverflow.com/questions/904041/reading-a-utf8-csv-file-with-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read a CSV file with accented characters with Python (only French and/or Spanish characters). Based on the Python 2.5 documentation for the csvreader (http://docs.python.org/library/csv.html), I came up with the following code to read the CSV file since the csvreader supports only ASCII.  def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):     # csv.py doesn't do Unicode; encode temporarily as UTF-8:     csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),                             dialect=dialect, **kwargs)     for row in csv_reader:         # decode UTF-8 back to Unicode, cell by cell:         yield [unicode(cell, 'utf-8') for cell in row]  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  filename = 'output.csv' reader = unicode_csv_reader(open(filename)) try:     products = []     for field1, field2, field3 in reader:         ...   Below is an extract of the CSV file I am trying to read:  0665000FS10120684,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Bleu 0665000FS10120689,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Gris 0665000FS10120687,SD1200IS,Appareil photo numrique PowerShot de 10 Mpx de Canon avec trpied (SD1200IS) - Vert ...   Even though I try to encode/decode to UTF-8, I am still getting the following exception:  Traceback (most recent call last):   File \".\\Test.py\", line 53, in <module>     for field1, field2, field3 in reader:   File \".\\Test.py\", line 40, in unicode_csv_reader     for row in csv_reader:   File \".\\Test.py\", line 46, in utf_8_encoder     yield line.encode('utf-8', 'ignore') UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 68: ordinal not in range(128)   How do I fix this?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  This looks like what you actually want. It applies the same approach of this answer to your specific case:  import matplotlib.pyplot as plt  fig, ax = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(6, 6))  fig.text(0.5, 0.04, 'common X', ha='center') fig.text(0.04, 0.5, 'common Y', va='center', rotation='vertical')        ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  Without sharex=True, sharey=True you get:    With it you should get it nicer:  fig, axes2d = plt.subplots(nrows=3, ncols=3,                            sharex=True, sharey=True,                            figsize=(6,6))  for i, row in enumerate(axes2d):     for j, cell in enumerate(row):         cell.imshow(np.random.rand(32,32))  plt.tight_layout()     But if you want to add additional labels, you should add them only to the edge plots:  fig, axes2d = plt.subplots(nrows=3, ncols=3,                            sharex=True, sharey=True,                            figsize=(6,6))  for i, row in enumerate(axes2d):     for j, cell in enumerate(row):         cell.imshow(np.random.rand(32,32))         if i == len(axes2d) - 1:             cell.set_xlabel(\"noise column: {0:d}\".format(j + 1))         if j == 0:             cell.set_ylabel(\"noise row: {0:d}\".format(i + 1))  plt.tight_layout()     Adding label for each plot would spoil it (maybe there is a way to automatically detect repeated labels, but I am not aware of one).     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  Since the command:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   you used returns a tuple consisting of the figure and a list of the axes instances, it is already sufficient to do something like (mind that I've changed fig,axto fig,axes):  fig,axes = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)  for ax in axes:     ax.set_xlabel('Common x-label')     ax.set_ylabel('Common y-label')   If you happen to want to change some details on a specific subplot, you can access it via axes[i] where i iterates over your subplots.  It might also be very helpful to include a  fig.tight_layout()   at the end of the file, before the plt.show(), in order to avoid overlapping labels.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  I ran into a similar problem while plotting a grid of graphs. The graphs consisted of two parts (top and bottom). The y-label was supposed to be centered over both parts.  I did not want to use a solution that depends on knowing the position in the outer figure (like fig.text()), so I manipulated the y-position of the set_ylabel() function. It is usually 0.5, the middle of the plot it is added to. As the padding between the parts (hspace) in my code was zero, I could calculate the middle of the two parts relative to the upper part.  import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec  # Create outer and inner grid outerGrid = gridspec.GridSpec(2, 3, width_ratios=[1,1,1], height_ratios=[1,1]) somePlot = gridspec.GridSpecFromSubplotSpec(2, 1,                subplot_spec=outerGrid[3], height_ratios=[1,3], hspace = 0)  # Add two partial plots partA = plt.subplot(somePlot[0]) partB = plt.subplot(somePlot[1])  # No x-ticks for the upper plot plt.setp(partA.get_xticklabels(), visible=False)  # The center is (height(top)-height(bottom))/(2*height(top)) # Simplified to 0.5 - height(bottom)/(2*height(top)) mid = 0.5-somePlot.get_height_ratios()[1]/(2.*somePlot.get_height_ratios()[0]) # Place the y-label partA.set_ylabel('shared label', y = mid)  plt.show()   picture  Downsides:   The horizontal distance to the plot is based on the top part, the bottom ticks might extend into the label. The formula does not take space between the parts into account. Throws an exception when the height of the top part is 0.   There is probably a general solution that takes padding between figures into account.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  I discovered a more robust method:  If you know the bottom and top kwargs that went into a GridSpec initialization, or you otherwise know the edges positions of your axes in Figure coordinates, you can also specify the ylabel position in Figure coordinates with some fancy \"transform\" magic. For example:  import matplotlib.transforms as mtransforms bottom, top = .1, .9 f, a = plt.subplots(nrows=2, ncols=1, bottom=bottom, top=top) avepos = (bottom+top)/2 a[0].yaxis.label.set_transform(mtransforms.blended_transform_factory(        mtransforms.IdentityTransform(), f.transFigure # specify x, y transform        )) # changed from default blend (IdentityTransform(), a[0].transAxes) a[0].yaxis.label.set_position((0, avepos)) a[0].set_ylabel('Hello, world!')   ...and you should see that the label still appropriately adjusts left-right to keep from overlapping with ticklabels, just like normal -- but now it will adjust to be always exactly between the desired subplots.  Furthermore, if you don't even use set_position, the ylabel will show up by default exactly halfway up the figure. I'm guessing this is because when the label is finally drawn, matplotlib uses 0.5 for the y-coordinate without checking whether the underlying coordinate transform has changed.      ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"Common xlabel/ylabel for matplotlib subplots","A_Content":"  It will look better if you reserve space for the common labels by making invisible labels for the subplot in the bottom left corner. It is also good to pass in the fontsize from rcParams. This way, the common labels will change size with your rc setup, and the axes will also be adjusted to leave space for the common labels.  fig_size = [8, 6] fig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=fig_size) # Reserve space for axis labels ax[-1, 0].set_xlabel('.', color=(0, 0, 0, 0)) ax[-1, 0].set_ylabel('.', color=(0, 0, 0, 0)) # Make common axis labels fig.text(0.5, 0.04, 'common X', va='center', ha='center', fontsize=rcParams['axes.labelsize']) fig.text(0.04, 0.5, 'common Y', va='center', ha='center', rotation='vertical', fontsize=rcParams['axes.labelsize'])         ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have the following plot:  fig,ax = plt.subplots(5,2,sharex=True,sharey=True,figsize=fig_size)   and now I would like to give this plot common x-axis labels and y-axis labels. With \"common\", I mean that there should be one big x-axis label below the whole grid of subplots, and one big y-axis label to the right. I can't find anything about this in the documentation for plt.subplots, and my googlings suggest that I need to make a big plt.subplot(111) to start with - but how do I then put my 5*2 subplots into that using plt.subplots?     ","Q_Votes":"80"},{"Q_Title":"python: urllib2 how to send cookie with urlopen request","A_Content":"  Cookie is just another HTTP header.  import urllib2 opener = urllib2.build_opener() opener.addheaders.append(('Cookie', 'cookiename=cookievalue')) f = opener.open(\"http://example.com/\")   See urllib2 examples for other ways how to add HTTP headers to your request.  There are more ways how to handle cookies. Some modules like cookielib try to behave like web browser - remember what cookies did you get previously and automatically send them again in following requests.     ","Language":"Python","Tags":["python","urllib2"],"URL":"https://stackoverflow.com/questions/3334809/python-urllib2-how-to-send-cookie-with-urlopen-request","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to use  urllib2 to open url and to send specific cookie text to the server. E.g. I want to open site Solve chess problems, with a specific cookie, e.g. search=1. How do I do it?  I am trying to do the following:  import urllib2 (need to add cookie to the request somehow) urllib2.urlopen(\"http://chess-problems.prg\")   Thanks in advance     ","Q_Votes":"80"},{"Q_Title":"python: urllib2 how to send cookie with urlopen request","A_Content":"  Maybe using cookielib.CookieJar can help you. For instance when posting to a page containing a form:  import urllib2 import urllib from cookielib import CookieJar  cj = CookieJar() opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj)) # input-type values from the html form formdata = { \"username\" : username, \"password\": password, \"form-id\" : \"1234\" } data_encoded = urllib.urlencode(formdata) response = opener.open(\"https://page.com/login.php\", data_encoded) content = response.read()   EDIT:  After Piotr's comment I'll elaborate a bit. From the docs:     The CookieJar class stores HTTP cookies. It extracts cookies from HTTP   requests, and returns them in HTTP responses. CookieJar instances   automatically expire contained cookies when necessary. Subclasses are   also responsible for storing and retrieving cookies from a file or   database.   So whatever requests you make with your CookieJar instance, all cookies will be handled automagically. Kinda like your browser does :)  I can only speak from my own experience and my 99% use-case for cookies is to receive a cookie and then need to send it with all subsequent requests in that session. The code above handles just that, and it does so transparently.     ","Language":"Python","Tags":["python","urllib2"],"URL":"https://stackoverflow.com/questions/3334809/python-urllib2-how-to-send-cookie-with-urlopen-request","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to use  urllib2 to open url and to send specific cookie text to the server. E.g. I want to open site Solve chess problems, with a specific cookie, e.g. search=1. How do I do it?  I am trying to do the following:  import urllib2 (need to add cookie to the request somehow) urllib2.urlopen(\"http://chess-problems.prg\")   Thanks in advance     ","Q_Votes":"80"},{"Q_Title":"python: urllib2 how to send cookie with urlopen request","A_Content":"  You might want to take a look at the excellent HTTP Python library called Requests. It makes every task involving HTTP a bit easier than urllib2. From Cookies section of quickstart guide:     To send your own cookies to the server, you can use the cookies parameter:   >>> cookies = dict(cookies_are='working')  >>> r = requests.get('http://httpbin.org/cookies', cookies=cookies) >>> r.text '{\"cookies\": {\"cookies_are\": \"working\"}}'      ","Language":"Python","Tags":["python","urllib2"],"URL":"https://stackoverflow.com/questions/3334809/python-urllib2-how-to-send-cookie-with-urlopen-request","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to use  urllib2 to open url and to send specific cookie text to the server. E.g. I want to open site Solve chess problems, with a specific cookie, e.g. search=1. How do I do it?  I am trying to do the following:  import urllib2 (need to add cookie to the request somehow) urllib2.urlopen(\"http://chess-problems.prg\")   Thanks in advance     ","Q_Votes":"80"},{"Q_Title":"python: urllib2 how to send cookie with urlopen request","A_Content":"  Use cookielib. The linked doc page provides examples at the end. You'll also find a tutorial here.     ","Language":"Python","Tags":["python","urllib2"],"URL":"https://stackoverflow.com/questions/3334809/python-urllib2-how-to-send-cookie-with-urlopen-request","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to use  urllib2 to open url and to send specific cookie text to the server. E.g. I want to open site Solve chess problems, with a specific cookie, e.g. search=1. How do I do it?  I am trying to do the following:  import urllib2 (need to add cookie to the request somehow) urllib2.urlopen(\"http://chess-problems.prg\")   Thanks in advance     ","Q_Votes":"80"},{"Q_Title":"How do I validate a date string format in python?","A_Content":"  >>> import datetime >>> def validate(date_text):     try:         datetime.datetime.strptime(date_text, '%Y-%m-%d')     except ValueError:         raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")   >>> validate('2003-12-23') >>> validate('2003-12-32')  Traceback (most recent call last):   File \"<pyshell#20>\", line 1, in <module>     validate('2003-12-32')   File \"<pyshell#18>\", line 5, in validate     raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\") ValueError: Incorrect data format, should be YYYY-MM-DD      ","Language":"Python","Tags":["python","date"],"URL":"https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python","A_Votes":"126","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a python method which accepts a date input as a string.  How do I add a validation to make sure the date string being passed to the method is in the ffg. format:  'YYYY-MM-DD'   if it's not, method should raise some sort of error     ","Q_Votes":"80"},{"Q_Title":"How do I validate a date string format in python?","A_Content":"  The Python dateutil library is designed for this (and more). It will automatically convert this to a datetime object for you and raise a ValueError if it can't.  As an example:  >>> from dateutil.parser import parse >>> parse(\"2003-09-25\") datetime.datetime(2003, 9, 25, 0, 0)   This raises a ValueError if the date is not formatted correctly:  >>> parse(\"2003-09-251\") Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/Users/jacinda/envs/dod-backend-dev/lib/python2.7/site-packages/dateutil/parser.py\", line 720, in parse     return DEFAULTPARSER.parse(timestr, **kwargs)   File \"/Users/jacinda/envs/dod-backend-dev/lib/python2.7/site-packages/dateutil/parser.py\", line 317, in parse     ret = default.replace(**repl) ValueError: day is out of range for month   dateutil is also extremely useful if you start needing to parse other formats in the future, as it can handle most known formats intelligently and allows you to modify your specification: dateutil parsing examples.    It also handles timezones if you need that.  Update based on comments: parse also accepts the keyword argument dayfirst which controls whether the day or month is expected to come first if a date is ambiguous. This defaults to False. E.g.  >>> parse('11/12/2001') >>> datetime.datetime(2001, 11, 12, 0, 0) # Nov 12 >>> parse('11/12/2001', dayfirst=True) >>> datetime.datetime(2001, 12, 11, 0, 0) # Dec 11      ","Language":"Python","Tags":["python","date"],"URL":"https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I have a python method which accepts a date input as a string.  How do I add a validation to make sure the date string being passed to the method is in the ffg. format:  'YYYY-MM-DD'   if it's not, method should raise some sort of error     ","Q_Votes":"80"},{"Q_Title":"How do I validate a date string format in python?","A_Content":"  from datetime import datetime  datetime.strptime(date_string, \"%Y-%m-%d\")   ..this raises a ValueError if it receives an incompatible format.  ..if you're dealing with dates and times a lot (in the sense of datetime objects, as opposed to unix timestamp floats), it's a good idea to look into the pytz module, and for storage/db, store everything in UTC.     ","Language":"Python","Tags":["python","date"],"URL":"https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I have a python method which accepts a date input as a string.  How do I add a validation to make sure the date string being passed to the method is in the ffg. format:  'YYYY-MM-DD'   if it's not, method should raise some sort of error     ","Q_Votes":"80"},{"Q_Title":"How do I validate a date string format in python?","A_Content":"  I think the full validate function should look like this:  from datetime import datetime  def validate(date_text):     try:         if date_text != datetime.strptime(date_text, \"%Y-%m-%d\").strftime('%Y-%m-%d'):             raise ValueError         return True     except ValueError:         return False   Executing just   datetime.strptime(date_text, \"%Y-%m-%d\")    is not enough because strptime method doesn't check that month and day of the month are zero-padded decimal numbers. For example  datetime.strptime(\"2016-5-3\", '%Y-%m-%d')   will be executed without errors.     ","Language":"Python","Tags":["python","date"],"URL":"https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have a python method which accepts a date input as a string.  How do I add a validation to make sure the date string being passed to the method is in the ffg. format:  'YYYY-MM-DD'   if it's not, method should raise some sort of error     ","Q_Votes":"80"},{"Q_Title":"How do I validate a date string format in python?","A_Content":"  This is the easiest way:  date = datetime.now() date = date.strftime('%Y-%m-%d_%H-%M-%S.jpg')      ","Language":"Python","Tags":["python","date"],"URL":"https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I have a python method which accepts a date input as a string.  How do I add a validation to make sure the date string being passed to the method is in the ffg. format:  'YYYY-MM-DD'   if it's not, method should raise some sort of error     ","Q_Votes":"80"},{"Q_Title":"Redefining the Index in a Pandas DataFrame object","A_Content":"  Why don't you simply use set_index method?  In : col = ['a','b','c']  In : data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)  In : data Out:     a   b   c 0   1   2   3 1  10  11  12 2  20  21  22  In : data2 = data.set_index('a')  In : data2 Out:      b   c a 1    2   3 10  11  12 20  21  22      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/10457584/redefining-the-index-in-a-pandas-dataframe-object","A_Votes":"184","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to re-index a pandas DataFrame object, like so,  From:             a   b   c         0   1   2   3         1  10  11  12         2  20  21  22  To :            b   c        1   2   3       10  11  12       20  21  22   I am going about this as shown below and am getting the wrong answer. Any clues on how to do this?  >>> col = ['a','b','c'] >>> data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col) >>> data     a   b   c 0   1   2   3 1  10  11  12 2  20  21  22 >>> idx2 = data.a.values >>> idx2 array([ 1, 10, 20], dtype=int64) >>> data2 = DataFrame(data,index=idx2,columns=col[1:]) >>> data2      b   c 1   11  12 10 NaN NaN 20 NaN NaN   Any idea why this is happening?     ","Q_Votes":"80"},{"Q_Title":"Redefining the Index in a Pandas DataFrame object","A_Content":"  If you don't want 'a' in the index  In :   col = ['a','b','c']  data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)  data   Out:      a   b   c 0   1   2   3 1  10  11  12 2  20  21  22   In :   data2 = data.set_index('a')   Out:       b   c a 1    2   3 10  11  12 20  21  22   In :   data2.index.name = None   Out:       b   c  1   2   3 10  11  12 20  21  22      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/10457584/redefining-the-index-in-a-pandas-dataframe-object","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to re-index a pandas DataFrame object, like so,  From:             a   b   c         0   1   2   3         1  10  11  12         2  20  21  22  To :            b   c        1   2   3       10  11  12       20  21  22   I am going about this as shown below and am getting the wrong answer. Any clues on how to do this?  >>> col = ['a','b','c'] >>> data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col) >>> data     a   b   c 0   1   2   3 1  10  11  12 2  20  21  22 >>> idx2 = data.a.values >>> idx2 array([ 1, 10, 20], dtype=int64) >>> data2 = DataFrame(data,index=idx2,columns=col[1:]) >>> data2      b   c 1   11  12 10 NaN NaN 20 NaN NaN   Any idea why this is happening?     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  Take a look at the other tokenizing options that nltk provides here. For example, you can define a tokenizer that picks out sequences of alphanumeric characters as tokens and drops everything else:  from nltk.tokenize import RegexpTokenizer  tokenizer = RegexpTokenizer(r'\\w+') tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')   Output:  ['Eighty', 'seven', 'miles', 'to', 'go', 'yet', 'Onward']      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"117","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  You do not really need NLTK to remove punctuation. You can remove it with simple python. For strings:  import string s = '... some string with punctuation ...' s = s.translate(None, string.punctuation)   Or for unicode:  import string translate_table = dict((ord(char), None) for char in string.punctuation)    s.translate(translate_table)   and then use this string in your tokenizer.  P.S. string module have some other sets of elements that can be removed (like digits).     ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  As noticed in comments start with sent_tokenize(), because word_tokenize() works only on a single sentence. You can filter out punctuation with filter(). And if you have an unicode strings make sure that is a unicode object (not a 'str' encoded with some encoding like 'utf-8').   from nltk.tokenize import word_tokenize, sent_tokenize  text = '''It is a blue, small, and extraordinary ball. Like no other''' tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)] print filter(lambda word: word not in ',-', tokens)      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  Below code will remove all punctuation marks as well as non alphabetic characters. Copied from their book.  http://www.nltk.org/book/ch01.html   import nltk  s = \"I can't do this now, because I'm so tired.  Please give me some time. @ sd  4 232\"  words = nltk.word_tokenize(s)  words=[word.lower() for word in words if word.isalpha()]  print(words)   output  ['i', 'ca', 'do', 'this', 'now', 'because', 'i', 'so', 'tired', 'please', 'give', 'me', 'some', 'time', 'sd']      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  I just used the following code, which removed all the punctuation:  tokens = nltk.wordpunct_tokenize(raw)  type(tokens)  text = nltk.Text(tokens)  type(text)    words = [w.lower() for w in text if w.isalpha()]      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  I use this code to remove punctuation:  import nltk def getTerms(sentences):     tokens = nltk.word_tokenize(sentences)     words = [w.lower() for w in tokens if w.isalnum()]     print tokens     print words  getTerms(\"hh, hh3h. wo shi 2 4 A . fdffdf. A&&B \")   And If you want to check whether a token is a valid English word or not, you may need PyEnchant  Tutorial:   import enchant  d = enchant.Dict(\"en_US\")  d.check(\"Hello\")  d.check(\"Helo\")  d.suggest(\"Helo\")      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  I think you need some sort of regular expression matching (the following code is in Python 3):  import string import re import nltk  s = \"I can't do this now, because I'm so tired.  Please give me some time.\" l = nltk.word_tokenize(s) ll = [x for x in l if not re.fullmatch('[' + string.punctuation + ']+', x)] print(l) print(ll)   Output:  ['I', 'ca', \"n't\", 'do', 'this', 'now', ',', 'because', 'I', \"'m\", 'so', 'tired', '.', 'Please', 'give', 'me', 'some', 'time', '.'] ['I', 'ca', \"n't\", 'do', 'this', 'now', 'because', 'I', \"'m\", 'so', 'tired', 'Please', 'give', 'me', 'some', 'time']   Should work well in most cases since it removes punctuation while preserving tokens like \"n't\", which can't be obtained from regex tokenizers such as wordpunct_tokenize.     ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to get rid of punctuation using NLTK tokenizer?","A_Content":"  Remove punctuaion(It will remove . as well as part of punctuation handling using below code)          tbl = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))         text_string = text_string.translate(tbl) #text_string don't have punctuation         w = word_tokenize(text_string)  #now tokenize the string    Sample Input/Output:  direct flat in oberoi esquire. 3 bhk 2195 saleable 1330 carpet. rate of 14500 final plus 1% floor rise. tax approx 9% only. flat cost with parking 3.89 cr plus taxes plus possession charger. middle floor. north door. arey and oberoi woods facing. 53% paymemt due. 1% transfer charge with buyer. total cost around 4.20 cr approx plus possession charges. rahul soni   ['direct', 'flat', 'oberoi', 'esquire', '3', 'bhk', '2195', 'saleable', '1330', 'carpet', 'rate', '14500', 'final', 'plus', '1', 'floor', 'rise', 'tax', 'approx', '9', 'flat', 'cost', 'parking', '389', 'cr', 'plus', 'taxes', 'plus', 'possession', 'charger', 'middle', 'floor', 'north', 'door', 'arey', 'oberoi', 'woods', 'facing', '53', 'paymemt', 'due', '1', 'transfer', 'charge', 'buyer', 'total', 'cost', 'around', '420', 'cr', 'approx', 'plus', 'possession', 'charges', 'rahul', 'soni']      ","Language":"Python","Tags":["python","nlp","tokenize","nltk"],"URL":"https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm just starting to use NLTK and I don't quite understand how to get a list of words from text. If I use nltk.word_tokenize(), I get a list of words and punctuation. I need only the words instead. How can I get rid of punctuation? Also word_tokenize doesn't work with multiple sentences: dots are added to the last word.     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  This is actually a pretty challenging problem that you are asking. Computing sentence similarity requires building a grammatical model of the sentence, understanding equivalent structures (e.g. \"he walked to the store yesterday\" and \"yesterday, he walked to the store\"), finding similarity not just in the pronouns and verbs but also in the proper nouns, finding statistical co-occurences / relationships in lots of real textual examples, etc.  The simplest thing you could try -- though I don't know how well this would perform and it would certainly not give you the optimal results -- would be to first remove all \"stop\" words (words like \"the\", \"an\", etc. that don't add much meaning to the sentence) and then run word2vec on the words in both sentences, sum up the vectors in the one sentence, sum up the vectors in the other sentence, and then find the difference between the sums. By summing them up instead of doing a word-wise difference, you'll at least not be subject to word order. That being said, this will fail in lots of ways and isn't a good solution by any means (though good solutions to this problem almost always involve some amount of NLP, machine learning, and other cleverness).  So, short answer is, no, there's no easy way to do this (at least not to do it well).     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"59","_type":"dict","isAccepted":"Yes","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  Since you're using gensim, you should probably use it's doc2vec implementation. doc2vec is an extension of word2vec to the phrase-, sentence-, and document-level. It's a pretty simple extension, described here  http://cs.stanford.edu/~quocle/paragraph_vector.pdf  Gensim is nice because it's intuitive, fast, and flexible. What's great is that you can grab the pretrained word embeddings from the official word2vec page and the syn0 layer of gensim's Doc2Vec model is exposed so that you can seed the word embeddings with these high quality vectors!  GoogleNews-vectors-negative300.bin.gz  I think gensim is definitely the easiest (and so far for me, the best) tool for embedding a sentence in a vector space.  There exist other sentence-to-vector techniques than the one proposed in Le & Mikolov's paper above. Socher and Manning from Stanford are certainly two of the most famous researchers working in this area. Their work has been based on the principle of compositionally - semantics of the sentence come from:  1. semantics of the words  2. rules for how these words interact and combine into phrases   They've proposed a few such models (getting increasingly more complex) for how to use compositionality to build sentence-level representations.  2011 - unfolding recursive autoencoder (very comparatively simple. start here if interested)  2012 - matrix-vector neural network  2013(?) - neural tensor network  2015 - Tree LSTM  his papers are all available at socher.org. Some of these models are available, but I'd still recommend gensim's doc2vec. For one, the 2011 URAE isn't particularly powerful. In addition, it comes pretrained with weights suited for paraphrasing news-y data. The code he provides does not allow you to retrain the network. You also can't swap in different word vectors, so you're stuck with 2011's pre-word2vec embeddings from Turian. These vectors are certainly not on the level of word2vec's or GloVe's.  Haven't worked with the Tree LSTM yet, but it seems very promising!  tl;dr Yeah, use gensim's doc2vec. But other methods do exist!     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  If you are using word2vec, you need to calculate the average vector for all words in every sentence/document and use cosine similarity between vectors:  import numpy as np from scipy import spatial  index2word_set = set(model.wv.index2word)  def avg_feature_vector(sentence, model, num_features, index2word_set):     words = sentence.split()     feature_vec = np.zeros((num_features, ), dtype='float32')     n_words = 0     for word in words:         if word in index2word_set:             n_words += 1             feature_vec = np.add(feature_vec, model[word])     if (n_words > 0):         feature_vec = np.divide(feature_vec, n_words)     return feature_vec   Calculate similarity:  s1_afv = avg_feature_vector('this is a sentence', model=model, num_features=300, index2word_set=index2word_set) s2_afv = avg_feature_vector('this is also sentence', model=model, num_features=300, index2word_set=index2word_set) sim = 1 - spatial.distance.cosine(s1_afv, s2_afv) print(sim)  > 0.915479828613      ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  Once you compute the sum of the two sets of word vectors, you should take the cosine between the vectors, not the diff. The cosine can be computed by taking the dot product of the two vectors normalized. Thus, the word count is not a factor.      ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  you can use Word Mover's Distance algorithm. here is an easy description about WMD.  #load word2vec model, here GoogleNews is used model = gensim.models.KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True) #two sample sentences  s1 = 'the first sentence' s2 = 'the second text'  #calculate distance between two sentences using WMD algorithm distance = model.wmdistance(s1, s2)  print ('distance = %.3f' % distance)   P.s.: if you face an error about import pyemd library, you can install it using following command:  pip install pyemd      ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  I am using the following method and it works well. You first need to run a POSTagger and then filter your sentence to get rid of the stop words (determinants, conjunctions, ...). I recommend TextBlob APTagger. Then you build a word2vec by taking the mean of each word vector in the sentence. The n_similarity method in Gemsim word2vec does exactly that by allowing to pass two sets of words to compare.     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  There are extensions of Word2Vec intended to solve the problem of comparing longer pieces of text like phrases or sentences. One of them is paragraph2vec or doc2vec.  \"Distributed Representations of Sentences and Documents\" http://cs.stanford.edu/~quocle/paragraph_vector.pdf  http://rare-technologies.com/doc2vec-tutorial/     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  I would like to update the existing solution to help the people who are going to calculate the semantic similarity of sentences.  Step 1:  Load the suitable model using gensim and calculate the word vectors for words in the sentence and store them as a word list  Step 2 : Computing the sentence vector  The calculation of semantic similarity between sentences was difficult before but recently a paper named \"A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS\" was proposed which suggests a simple approach by computing the weighted average of word vectors in the sentence and then remove the projections of the average vectors on their first principal component.Here the weight of a word w is a/(a + p(w)) with a being a parameter and p(w) the (estimated) word frequency called smooth inverse frequency.this method performing significantly better.  A simple code to calculate the sentence vector using SIF(smooth inverse frequency) the method proposed in the paper has been given here  Step 3: using sklearn cosine_similarity load two vectors for the sentences and compute the similarity.  This is the most simple and efficient method to compute the sentence similarity.     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  I have tried the methods provided by the previous answers. It works, but the main drawback of it is that the longer the sentences the larger similarity will be(to calculate the similarity I use the cosine score of the two mean embeddings of any two sentences) since the more the words the more positive semantic effects will be added to the sentence.   I thought I should change my mind and use the sentence embedding instead as studied in this paper and this.      ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  There is a function from the documentation taking a list of words and comparing their similarities.  s1 = 'This room is dirty' s3 = 'dirty and disgusting room'  distance = model.wv.n_similarity(s1.lower().split(), s2.lower().split())      ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"How to calculate the sentence similarity using word2vec model of gensim with python","A_Content":"  Facebook Research group released a new solution called InferSent  Results and code are published on Github, check their repo. It is pretty awesome. I am planning to use it.  https://github.com/facebookresearch/InferSent   their paper https://arxiv.org/abs/1705.02364  Abstract:  Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.     ","Language":"Python","Tags":["python","gensim","word2vec"],"URL":"https://stackoverflow.com/questions/22129943/how-to-calculate-the-sentence-similarity-using-word2vec-model-of-gensim-with-pyt","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    According to the Gensim Word2Vec, I can use the word2vec model in gensim package to calculate the similarity between 2 words.  e.g.  trained_model.similarity('woman', 'man')  0.73723527   However, the word2vec model fails to predict the sentence similarity. I find out the LSI model with sentence similarity in gensim, but, which doesn't seem that can be combined with word2vec model. The length of corpus of each sentence I have is not very long (shorter than 10 words).  So, are there any simple ways to achieve the goal?     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  I advocate an object oriented approach. This is the template that I start out with:  # Use Tkinter for python 2, tkinter for python 3 import tkinter as tk  class MainApplication(tk.Frame):     def __init__(self, parent, *args, **kwargs):         tk.Frame.__init__(self, parent, *args, **kwargs)         self.parent = parent          <create the rest of your GUI here>  if __name__ == \"__main__\":     root = tk.Tk()     MainApplication(root).pack(side=\"top\", fill=\"both\", expand=True)     root.mainloop()   The important things to notice are:   I don't use a wildcard import. I import the package as \"tk\", which requires that I prefix all commands with tk.. This prevents global namespace pollution, plus it makes the code completely obvious when you are using Tkinter classes, ttk classes, or some of your own.  The main application is a class. This gives you a private namespace for all of your callbacks and private functions, and just generally makes it easier to organize your code. In a procedural style you have to code top-down, defining functions before using them, etc. With this method you don't since you don't actually create the main window until the very last step. I prefer inheriting from tk.Frame just because I typically start by creating a frame, but it is by no means necessary.    If your app has additional toplevel windows, I recommend making each of those a separate class, inheriting from tk.Toplevel. This gives you all of the same advantages mentioned above -- the windows are atomic, they have their own namespace, and the code is well organized. Plus, it makes it easy to put each into its own module once the code starts to get large.   Finally, you might want to consider using classes for every major portion of your interface. For example, if you're creating an app with a toolbar, a navigation pane, a statusbar, and a main area, you could make each one of those classes. This makes your main code quite small and easy to understand:  class Navbar(tk.Frame): ... class Toolbar(tk.Frame): ... class Statusbar(tk.Frame): ... class Main(tk.Frame): ...  class MainApplication(tk.Frame):     def __init__(self, parent, *args, **kwargs):         tk.Frame.__init__(self, parent, *args, **kwargs)         self.statusbar = Statusbar(self, ...)         self.toolbar = Toolbar(self, ...)         self.navbar = Navbar(self, ...)         self.main = Main(self, ...)          self.statusbar.pack(side=\"bottom\", fill=\"x\")         self.toolbar.pack(side=\"top\", fill=\"x\")         self.navbar.pack(side=\"left\", fill=\"y\")         self.main.pack(side=\"right\", fill=\"both\", expand=True)   Since all of those instances share a common parent, the parent effectively becomes the \"controller\" part of a model-view-controller architecture. So, for example, the main window could place something on the statusbar by calling self.parent.statusbar.set(\"Hello, world\"). This allows you to define a simple interface between the components, helping to keep coupling to a minimun.      ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"159","_type":"dict","isAccepted":"Yes","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  Putting each of your top-level windows into it's own separate class gives you code re-use and better code organization. Any buttons and relevant methods that are present in the window should be defined inside this class. Here's an example (taken from here):  import tkinter as tk  class Demo1:     def __init__(self, master):         self.master = master         self.frame = tk.Frame(self.master)         self.button1 = tk.Button(self.frame, text = 'New Window', width = 25, command = self.new_window)         self.button1.pack()         self.frame.pack()     def new_window(self):         self.newWindow = tk.Toplevel(self.master)         self.app = Demo2(self.newWindow)  class Demo2:     def __init__(self, master):         self.master = master         self.frame = tk.Frame(self.master)         self.quitButton = tk.Button(self.frame, text = 'Quit', width = 25, command = self.close_windows)         self.quitButton.pack()         self.frame.pack()     def close_windows(self):         self.master.destroy()  def main():      root = tk.Tk()     app = Demo1(root)     root.mainloop()  if __name__ == '__main__':     main()   Also see:   simple hello world from tkinter docs Tkinter example code for multiple windows, why won't buttons load correctly? Tkinter: How to Show / Hide a Window   Hope that helps.     ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  Here is an excellent tutorial on tkinter GUI design, with a couple examples -- http://python-textbok.readthedocs.org/en/latest/Introduction_to_GUI_Programming.html  Here is another example with an MVC design pattern -- https://sukhbinder.wordpress.com/2014/12/25/an-example-of-model-view-controller-design-pattern-with-tkinter-python/     ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  This isn't a bad structure; it will work just fine. However, you do have to have functions in a function to do commands when someone clicks on a button or something  So what you could do is write classes for these then have methods in the class that handle commands for the button clicks and such.  Here's an example:  import tkinter as tk  class Window1:     def __init__(self, master):         pass         # Create labels, entries,buttons     def button_click(self):         pass         # If button is clicked, run this method and open window 2   class Window2:     def __init__(self, master):         #create buttons,entries,etc      def button_method(self):         #run this when button click to close window         self.master.destroy()  def main(): #run mianloop      root = tk.Tk()     app = Demo1(root)     root.mainloop()  if __name__ == '__main__':     main()   Usually tk programs with multiple windows are multiple big classes and in the __init__ all the entries, labels etc are created and then each method is to handle button click events  There isn't really a right way to do it, whatever works for you and gets the job done as long as its readable and you can easily explain it because if you cant easily explain your program, there probably is a better way to do it.  Take a look at Thinking in Tkinter.     ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  OOP should be the approach and frame should be a class variable instead of instance variable.  from Tkinter import * class App:   def __init__(self, master):     frame = Frame(master)     frame.pack()     self.button = Button(frame,                           text=\"QUIT\", fg=\"red\",                          command=frame.quit)     self.button.pack(side=LEFT)     self.slogan = Button(frame,                          text=\"Hello\",                          command=self.write_slogan)     self.slogan.pack(side=LEFT)   def write_slogan(self):     print \"Tkinter is easy to use!\"  root = Tk() app = App(root) root.mainloop()     Reference: http://www.python-course.eu/tkinter_buttons.php     ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Best way to structure a tkinter application [closed]","A_Content":"  Probably the best way to learn how to structure your program is by reading other people's code, especially if it's a large program to which many people have contributed. After looking at the code of many projects, you should get an idea of what the consensus style should be.   Python, as a language, is special in that there are some strong guidelines as to how you should format your code. The first is the so-called \"Zen of Python\":        Beautiful is better than ugly.   Explicit is better than implicit.   Simple is better than complex.   Complex is better than complicated.   Flat is better than nested.   Sparse is better than dense.   Readability counts.   Special cases aren't special enough to break the rules.   Although practicality beats purity.   Errors should never pass silently.   Unless explicitly silenced.   In the face of ambiguity, refuse the temptation to guess.   There should be one-- and preferably only one --obvious way to do it.   Although that way may not be obvious at first unless you're Dutch.   Now is better than never.   Although never is often better than right now.   If the implementation is hard to explain, it's a bad idea.   If the implementation is easy to explain, it may be a good idea.   Namespaces are one honking great idea -- let's do more of those!      On a more practical level, there is PEP8, the style guide for Python.  With those in mind, I would say that your code style doesn't really fit, particularly the nested functions. Find a way to flatten those out, either by using classes or moving them into separate modules. This will make the structure of your program much easier to understand.     ","Language":"Python","Tags":["python","tkinter"],"URL":"https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    The following is the overall structure of my typical python tkinter program.  def funA():     def funA1():         def funA12():             # stuff      def funA2():         # stuff  def funB():     def funB1():         # stuff      def funB2():         # stuff  def funC():     def funC1():         # stuff      def funC2():         # stuff   root = tk.Tk()  button1 = tk.Button(root, command=funA) button1.pack() button2 = tk.Button(root, command=funB) button2.pack() button3 = tk.Button(root, command=funC) button3.pack()   funA funB and funC will bring up another Toplevel windows with widgets when user click on button 1, 2, 3.    I am wondering if this is the right way to write a python tkinter program? Sure, it will work even if I write this way, but is it the best way? It sounds stupid but when I see the codes other people written, their code is not messed up with bunch of functions and mostly they have classes.  Is there any specific structure that we should follow as good practice? How should I plan before start writing a python program?  I know there is no such thing as best practice in programming and I am not asking for it either. I just want some advice and explanations to keep me on the right direction as I am learning Python by myself.     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  Assuming you are using Python 3.x:  print(*myList, sep='\\n')   You can get the same behavior on Python 2.x using from __future__ import print_function, as noted by mgilson in comments.  With the print statement on Python 2.x you will need iteration of some kind, regarding your question about print(p) for p in myList not working, you can just use the following which does the same thing and is still one line:  for p in myList: print p   For a solution that uses '\\n'.join(), I prefer list comprehensions and generators over map() so I would probably use the following:  print '\\n'.join(str(p) for p in myList)       ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"163","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  I use this all the time :   #!/usr/bin/python  l = [1,2,3,7]  print \"\".join([str(x) for x in l] )      ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  [print(a) for a in list] will give a bunch of None types at the end though it prints out all the items     ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  For Python 2.*:  If you overload the function __str__() for your Person class, you can omit the part with map(str, ...). Another way for this is creating a function, just like you wrote:  def write_list(lst):     for item in lst:         print str(item)   ...  write_list(MyList)   There is in Python 3.* the argument sep for the print() function. Take a look at documentation.     ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  Expanding @lucasg's answer (inspired by the comment it received):  To get a formatted list output, you can do something along these lines:  l = [1,2,5] print \", \".join('%02d'%x for x in l)  01, 02, 05   Now the \", \" provides the separator (only between items, not at the end) and the formatting string '02d'combined with %x gives a formatted string for each item x - in this case, formatted as an integer with two digits, left-filled with zeros.     ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  To display each content, I use:  mylist = ['foo', 'bar'] indexval = 0 for i in range(len(mylist)):          print(mylist[indexval])     indexval += 1   Example of using in a function:  def showAll(listname, startat):    indexval = startat    try:       for i in range(len(mylist)):          print(mylist[indexval])          indexval = indexval + 1    except IndexError:       print('That index value you gave is out of range.')   Hope I helped.     ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"Pythonic way to print list items","A_Content":"  I think this is the most convenient if you just want to see the content in the list:  myList = ['foo', 'bar'] print('myList is %s' % str(myList))   Simple, easy to read and can be used together with format string.     ","Language":"Python","Tags":["python","list","printing","list-comprehension"],"URL":"https://stackoverflow.com/questions/15769246/pythonic-way-to-print-list-items","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I would like to know if there is a better way to print all objects in a Python list than this :  myList = [Person(\"Foo\"), Person(\"Bar\")] print(\"\\n\".join(map(str, myList))) Foo Bar   I read this way is not really good :  myList = [Person(\"Foo\"), Person(\"Bar\")] for p in myList:     print(p)   Isn't there something like :  print(p) for p in myList   If not, my question is... why ? If we can do this kind of stuff with comprehensive lists, why not as a simple statement outside a list ?     ","Q_Votes":"80"},{"Q_Title":"What is the easiest way to get current GMT time in Unix timestamp format?","A_Content":"  I would use time.time() to get a timestamp in seconds since the epoch.  import time  time.time()   Output:  1369550494.884832   For the standard CPython implementation on most platforms this will return a UTC value.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format","A_Votes":"133","_type":"dict","isAccepted":"No","Q_Content":"    Python provides different packages (datetime, time, calendar) as can be seen here in order to deal with time. I made a big mistake by using the following to get current GMT time time.mktime(datetime.datetime.utcnow().timetuple())  What is a simple way to get current GMT time in Unix timestamp?     ","Q_Votes":"80"},{"Q_Title":"What is the easiest way to get current GMT time in Unix timestamp format?","A_Content":"  Does this help?  from datetime import datetime import calendar  d = datetime.utcnow() unixtime = calendar.timegm(d.utctimetuple()) print unixtime   How to convert Python UTC datetime object to UNIX timestamp     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format","A_Votes":"37","_type":"dict","isAccepted":"No","Q_Content":"    Python provides different packages (datetime, time, calendar) as can be seen here in order to deal with time. I made a big mistake by using the following to get current GMT time time.mktime(datetime.datetime.utcnow().timetuple())  What is a simple way to get current GMT time in Unix timestamp?     ","Q_Votes":"80"},{"Q_Title":"What is the easiest way to get current GMT time in Unix timestamp format?","A_Content":"  import time  int(time.time())    Output:  1521462189      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    Python provides different packages (datetime, time, calendar) as can be seen here in order to deal with time. I made a big mistake by using the following to get current GMT time time.mktime(datetime.datetime.utcnow().timetuple())  What is a simple way to get current GMT time in Unix timestamp?     ","Q_Votes":"80"},{"Q_Title":"What is the easiest way to get current GMT time in Unix timestamp format?","A_Content":"  Or just simply using the datetime standard module  In [2]: from datetime import timezone, datetime    ...: int(datetime.now(tz=timezone.utc).timestamp() * 1000)    ...:  Out[2]: 1514901741720   You can truncate or multiply depending on the resolution you want     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Python provides different packages (datetime, time, calendar) as can be seen here in order to deal with time. I made a big mistake by using the following to get current GMT time time.mktime(datetime.datetime.utcnow().timetuple())  What is a simple way to get current GMT time in Unix timestamp?     ","Q_Votes":"80"},{"Q_Title":"What is the easiest way to get current GMT time in Unix timestamp format?","A_Content":"  I like this method:  import datetime, time  dts = datetime.datetime.utcnow() epochtime = round(time.mktime(dts.timetuple()) + dts.microsecond/1e6)   The other methods posted here are either not guaranteed to give you UTC on all platforms or only report whole seconds. If you want full resolution, this works, to the micro-second.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python provides different packages (datetime, time, calendar) as can be seen here in order to deal with time. I made a big mistake by using the following to get current GMT time time.mktime(datetime.datetime.utcnow().timetuple())  What is a simple way to get current GMT time in Unix timestamp?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  1)While installing cygwin, make sure you install the  python/python-setuptools from the list. This will install \"easy_install\" package.  2) Type the following command:   easy_install-a.b pip      You must replace a.b with your python version which can be 2.7 or 3.4 or whatever else.     ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  If you have more than one python installation, then you need to install pip (and probably also setuptools) for each installation separately. To do so, you can first download ez_setup.py and run it with python3:  /usr/bin/python3 ez_setup.py   That should install setuptools, and also create an easy_install script for your python version, e.g. /usr/bin/easy_install-3.2, which you can use to install pip:  /usr/bin/easy_install-3.2 pip   This will install pip into your python3 site packages directory, and again create a script /usr/bin/pip-3.2, which you can use to install packages for this python version.  Alternatively you can follow the install instructions from here and here.     ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"43","_type":"dict","isAccepted":"No","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  I think the alternative install instructions linked by mata are simplest:     To install pip, securely download get-pip.py.      Then run the following (which may require administrator access):  python get-pip.py       ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  Since OP specifically talks about Python3, I think we need to specify that just in case the user already have Python2 installed, which is very likely.   # If you don't have Python3 already, use apt-cyg: apt-cyg install python3  # First update pip, pip2  pip2 install --upgrade pip   # Install pip3: python3 -m ensurepip  # Finally update pip3: pip3 install --upgrade pip  $ pip3 -V pip 9.0.1 from /usr/lib/python3.4/site-packages (python 3.4)   PS. There are several forks of apt-cyg, you'll love it.      ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  On windows, you can use pip to install packages. If you have multiple python installations under cygwin, give the full python path e.g.  Python 2  /usr/bin/python2.7 -m pip install pyyaml   Python 3  /usr/bin/python3.6 -m pip install pyyaml   In case you dont have pip installed install it using below command  /usr/bin/python2.7 -m ensurepip    or  /usr/bin/python3.6 -m ensurepip      ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Installing Pip-3.2 on Cygwin","A_Content":"  I just learned, inspired from https://www.scivision.co/install-pip-in-cygwin/ and the answer before, that instead of using pip, you just have to use pip2 for python2 or pip3 for python 3 in cygwin on windows. Wondered about this the whole day...     ","Language":"Python","Tags":["python","python-3.x","cygwin","pip"],"URL":"https://stackoverflow.com/questions/18641438/installing-pip-3-2-on-cygwin","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via pip. Is there a way to do this?     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  I believe the syntax you were looking for is as follows:  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:         writer = csv.writer(outfile)         mydict = {rows[0]:rows[1] for rows in reader}   Alternately, for python <= 2.7.1, you want:  mydict = dict((rows[0],rows[1]) for rows in reader)      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  import csv reader = csv.reader(open('filename.csv', 'r')) d = {} for row in reader:    k, v = row    d[k] = v      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  Open the file by calling open and then csv.DictReader.  input_file = csv.DictReader(open(\"coors.csv\"))   You may iterate over the rows of the csv file dict reader object by iterating over input_file.   for row in input_file:     print row   OR      To access first line only  dictobj = csv.DictReader(open('coors.csv')).next()       ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  You have to just convert csv.reader to dict:  ~ >> cat > 1.csv key1, value1 key2, value2 key2, value22 key3, value3  ~ >> cat > d.py import csv with open('1.csv') as f:     d = dict(filter(None, csv.reader(f)))  print(d)  ~ >> python d.py {'key3': ' value3', 'key2': ' value22', 'key1': ' value1'}      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  You can also use numpy for this.  from numpy import loadtxt key_value = loadtxt(\"filename.csv\", delimiter=\",\") mydict = { k:v for k,v in key_value }      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  This isn't elegant but a one line solution using pandas.  import pandas as pd pd.read_csv('coors.csv', header=None, index_col=0, squeeze=True).to_dict()   If you want to specify dtype for your index (it can't be specified in read_csv if you use the index_col argument because of a bug):  import pandas as pd pd.read_csv('coors.csv', header=None, dtype={0: str}).set_index(0).squeeze().to_dict()      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  I'd suggest adding if rows in case there is an empty line at the end of the file  import csv with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:         writer = csv.writer(outfile)         mydict = dict(row[:2] for row in reader if row)      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  If you are OK with using the numpy package, then you can do something like the following:  import numpy as np  lines = np.genfromtxt(\"coors.csv\", delimiter=\",\", dtype=None) my_dict = dict() for i in range(len(lines)):    my_dict[lines[i][0]] = lines[i][1]      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  You can use this, it is pretty cool:  import dataconverters.commas as commas filename = 'test.csv' with open(filename) as f:       records, metadata = commas.parse(f)       for row in records:             print 'this is row in dictionary:'+rowenter code here      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Creating a dictionary from a csv file?","A_Content":"  One-liner solution  import pandas as pd  dict = {row[0] : row[1] for _, row in pd.read_csv(\"file.csv\").iterrows()}      ","Language":"Python","Tags":["python","csv","dictionary","list-comprehension"],"URL":"https://stackoverflow.com/questions/6740918/creating-a-dictionary-from-a-csv-file","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to create a dictionary from a csv file. The first column of the csv file contains unique keys and the second column contains values. Each row of the csv file represents a unique key, value pair within the dictionary. I tried to use the csv.DictReader and csv.DictWriter classes, but I could only figure out how to generate a new dictionary for each row. I want one dictionary. Here is the code I am trying to use:  import csv  with open('coors.csv', mode='r') as infile:     reader = csv.reader(infile)     with open('coors_new.csv', mode='w') as outfile:     writer = csv.writer(outfile)     for rows in reader:         k = rows[0]         v = rows[1]         mydict = {k:v for k, v in rows}     print(mydict)   When I run the above code I get a ValueError: too many values to unpack (expected 2). How do I create one dictionary from a csv file? Thanks.     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  On Windows  import winsound duration = 1000  # millisecond freq = 440  # Hz winsound.Beep(freq, duration)   Where freq is the frequency in Hz and the duration is in milliseconds.  On Linux (and Mac)  import os duration = 1  # second freq = 440  # Hz os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))   In order to use this example, you must install sox.  On Debian/Ubuntu/LinuxMint you need to run in your terminal:  sudo apt install sox   Here is the macports way of doing that...run this is your terminal:  sudo port install sox   Speech on Mac  And something really cool if you're using a mac in terminal, maybe can do the same in windows, but I only know for sure for mac, this will tell you it's done:  import os os.system('say \"your program has finished\"')   Speech on Linux  import os os.system('spd-say \"your program has finished\"')   You need to install the speech-dispatcher package in Ubuntu (or the corresponding package on other distributions):  sudo apt install speech-dispatcher      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"132","_type":"dict","isAccepted":"Yes","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  This one seems to work on both Windows and Linux* (from this question):  def beep():     print \"\\a\" beep()   In Windows, can put at the end:  import winsound winsound.Beep(500,1000)  where 500 is the frequency in Herz       1000 is the duration in miliseconds   *: to work on Linux, you may need to do the following (from QO's comment):   in a terminal, type 'cd /etc/modprobe.d' then 'gksudo gedit blacklist.conf' comment the line that says 'blacklist pcspkr', then reboot check also that the terminal preferences has the 'Terminal Bell' checked.      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"   print('\\007')   plays the bell sound     ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  ubuntu speech dispatcher can be used:  import subprocess subprocess.call(['speech-dispatcher'])        #start speech dispatcher subprocess.call(['spd-say', '\"your process has finished\"'])      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  Kuchi's answer didn't work for me on OS X Yosemite (10.10.1). I did find a command that works, which you can just call from Python. This works regardless of whether the Terminal audible bell is enabled and without a third-party library.  os.system('afplay /System/Library/Sounds/Sosumi.aiff')      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  See: Python Sound (\"Bell\") This helped me when i wanted to do the same. All credits go to gbc  Quote:  Have you tried :  import sys sys.stdout.write('\\a') sys.stdout.flush()   That works for me here on Mac OS 10.5  Actually, I think your original attempt works also with a little modification:  print('\\a')   (You just need the single quotes around the character sequence).     ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  It can be done by code as follows:  import time time.sleep(10)   #Set the time for x in range(60):       time.sleep(1)     print('\\a')      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  import subprocess  subprocess.call(['D:\\greensoft\\TTPlayer\\TTPlayer.exe', \"E:\\stridevampaclip.mp3\"])      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  Why use python at all?  You might forget to remove it and check it into a repository.  Just run your python command with && and another command to run to do the alerting.  python myscript.py &&      notify-send 'Alert' 'Your task is complete' &&      paplay /usr/share/sounds/freedesktop/stereo/suspend-error.oga   or drop a function into your .bashrc. I use apython here but you could override 'python'  function apython() {     /usr/bin/python $*     notify-send 'Alert' \"python $* is complete\"     paplay /usr/share/sounds/freedesktop/stereo/suspend-error.oga }      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"Sound alarm when code finishes","A_Content":"  I'm assuming you want the standard system bell, and don't want to concern yourself with frequencies and durations etc., you just want the standard windows bell.  import winsound winsound.MessageBeep()      ","Language":"Python","Tags":["python","alarm","audio"],"URL":"https://stackoverflow.com/questions/16573051/sound-alarm-when-code-finishes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am in a situation where my code takes extremely long to run and I don't want to be staring at it all the time but want to know when it is done.  How can I make the (Python) code sort of sound an \"alarm\" when it is done? I was contemplating making it play a .wav file when it reaches the end of the code...   Is this even a feasible idea?  If so, how could I do it?     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  checker = None # not necessary  if some_decision:     checker = True  if checker:     # some stuff   [Edit]  For more information: http://docs.python.org/library/functions.html#bool  Your code works too, since 1 is converted to True when necessary. Actually Python didn't have a boolean type for a long time (as in old C), and some programmers sill use integers instead of booleans.     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"106","_type":"dict","isAccepted":"Yes","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  The boolean builtins are capitalized: True and False.  Note also that you can do checker = bool(some_decision) as a bit of shorthand -- bool will only ever return True or False.  It's good to know for future reference that classes defining __nonzero__ or __len__ will be True or False depending on the result of those functions, but virtually every other object's boolean result will be True (except for the None object, empty sequences, and numeric zeros).     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"85","_type":"dict","isAccepted":"No","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  True ... and False obviously.  Otherwise, None evaluates to False, as does the integer 0 and also the float 0.0 (although I wouldn't use floats like that). Also, empty lists [], empty tuplets (), and empty strings '' or \"\" evaluate to False.  Try it yourself with the function bool():  bool([]) bool(['a value']) bool('') bool('A string') bool(True)  # ;-) bool(False) bool(0) bool(None) bool(0.0) bool(1)   etc..     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  Boolean types are defined in documentation: http://docs.python.org/library/stdtypes.html#boolean-values  Quoted from doc:     Boolean values are the two constant objects False and True. They are used to represent truth values (although other values can also be considered false or true). In numeric contexts (for example when used as the argument to an arithmetic operator), they behave like the integers 0 and 1, respectively. The built-in function bool() can be used to cast any value to a Boolean, if the value can be interpreted as a truth value (see section Truth Value Testing above).      They are written as False and True, respectively.   So in java code remove braces, change true to True and you will be ok :)     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  Yes, there is a bool data type (which inherits from int and has only two values: True and False).  But also Python has the boolean-able concept for every object, which is used when function bool([x]) is called.  See more: object.nonzero and boolean-value-of-objects-in-python.     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"How do I use a Boolean in Python?","A_Content":"  Unlike Java where you would declare boolean flag = True, in Python you can just declare myFlag = True  Python would interpret this as a boolean variable     ","Language":"Python","Tags":["python","boolean"],"URL":"https://stackoverflow.com/questions/1748641/how-do-i-use-a-boolean-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Does Python actually contain a Boolean value? I know that you can do:  checker = 1 if checker:     #dostuff   But I'm quite pedantic and enjoy seeing booleans in Java. For instance:  Boolean checker; if (someDecision) {     checker = true; } if(checker) {     //some stuff }   Is there such a thing as a Boolean in Python? I can't seem to find anything like it in the documentation.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  If the URL is returning valid JSON-encoded data, use the json library to decode that:  import urllib2 import json  response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') data = json.load(response)    print data      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"170","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  import json import urllib  url = 'http://example.com/file.json' r = urllib.request.urlopen(url) data = json.loads(r.read().decode(r.info().get_param('charset') or 'utf-8')) print data   urllib, for Python 3.4 HTTPMessage, returned by r.info()     ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"33","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  Be careful about the validation and etc, but the straight solution is this:  import json the_dict = json.load(response)      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  \"\"\" Return JSON to webpage Adding to wonderful answer by @Sanal For Django 3.4 Adding a working url that returns a json (Source: http://www.jsontest.com/#echo) \"\"\"  import json import urllib  url = 'http://echo.jsontest.com/insert-key-here/insert-value-here/key/value' respons = urllib.request.urlopen(url) data = json.loads(respons.read().decode(respons.info().get_param('charset') or 'utf-8')) return HttpResponse(json.dumps(data), content_type=\"application/json\")      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  resource_url = 'http://localhost:8080/service/' response = json.loads(urllib2.urlopen(resource_url).read())      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  None of the provided examples on here worked for me. They were either for Python 2 (uurllib2) or those for Python 3 return the error \"ImportError: No module named request\". I google the error message and it apparently requires me to install a the module - which is obviously unacceptable for such a simple task.   This code worked for me:   import json,urllib data = urllib.urlopen(\"https://api.github.com/users?since=0\").read() d = json.loads(data) print (d)      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"Python urllib2: Receive JSON response from url","A_Content":"  Though I guess it has already answered I would like to add my little bit in this  import json import urllib2 class Website(object):     def __init__(self,name):         self.name = name      def dump(self):      self.data= urllib2.urlopen(self.name)      return self.data      def convJSON(self):          data=  json.load(self.dump())      print data  domain = Website(\"https://example.com\") domain.convJSON()   Note : object passed to json.load() should support .read() , therefore urllib2.urlopen(self.name).read() would not work . Doamin passed should be provided with protocol in this case http      ","Language":"Python","Tags":["python","json","urllib2"],"URL":"https://stackoverflow.com/questions/13921910/python-urllib2-receive-json-response-from-url","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to GET a URL using Python and the response is JSON. However, when I run  import urllib2 response = urllib2.urlopen('https://api.instagram.com/v1/tags/pizza/media/XXXXXX') html=response.read() print html   The html is of type str and I am expecting a JSON. Is there any way I can capture the response as JSON or a python dictionary instead of a str.     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  In terms of speed, it's no competition for empty lists/dicts:  >>> from timeit import timeit >>> timeit(\"[]\") 0.040084982867934334 >>> timeit(\"list()\") 0.17704233359267718 >>> timeit(\"{}\") 0.033620194745424214 >>> timeit(\"dict()\") 0.1821558326547077   and for non-empty:  >>> timeit(\"[1,2,3]\") 0.24316302770330367 >>> timeit(\"list((1,2,3))\") 0.44744206316727286 >>> timeit(\"list(foo)\", setup=\"foo=(1,2,3)\") 0.446036018543964 >>> timeit(\"{'a':1, 'b':2, 'c':3}\") 0.20868602015059423 >>> timeit(\"dict(a=1, b=2, c=3)\") 0.47635635255323905 >>> timeit(\"dict(bar)\", setup=\"bar=[('a', 1), ('b', 2), ('c', 3)]\") 0.9028228448029267   Also, using the bracket notation let's you use list and dictionary comprehensions, which may be reason enough.     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"146","_type":"dict","isAccepted":"Yes","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  In my opinion [] and {} are the most pythonic and readable ways to create empty lists/dicts.  Be wary of set()'s though, for example:  this_set = {5} some_other_set = {}   Can be confusing. The first creates a set with one element, the second creates an empty dict and not a set.     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  [] and {} are better  list() is inherently slower than [] and dict() is inherently slower than {} ,   Because   There is symbol lookup (no way for python to know in advance if you did not just redefine list to be something else!), There is function invocation, Then it has to check if there was iterable argument passed (so it can create list with elements from it)    In most cases the speed difference won't make any practical difference though.  (source)     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  The dict literal might be a tiny bit faster as its bytecode is shorter:  In [1]: import dis In [2]: a = lambda: {} In [3]: b = lambda: dict()  In [4]: dis.dis(a)   1           0 BUILD_MAP                0               3 RETURN_VALUE  In [5]: dis.dis(b)   1           0 LOAD_GLOBAL              0 (dict)               3 CALL_FUNCTION            0               6 RETURN_VALUE   Same applies to the list vs []     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  As it is not mentioned in the Python Style Guide you can use whatever style you want, it's a matter of personal taste.     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  IMHO, using list() and dict() makes your Python look like C.  Ugh.     ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  In the case of difference between [] and list(), there is a pitfall that I haven't seen anyone else point out.  If you use a dictionary as a member of the list, the two will give entirely different results:  In [1]: foo_dict = {\"1\":\"foo\", \"2\":\"bar\"}  In [2]: [foo_dict] Out [2]: [{'1': 'foo', '2': 'bar'}]  In [3]: list(foo_dict) Out [3]: ['1', '2']       ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  timeit doesn't seem to give accurate time. As per the timeit benchmark mentioned above for dict(), it seems to take ~200ms which is way slower than normal http calls. Try running in shell , dict() and then timeit(\"dict()\"), you would see visible difference in execution; timeit(\"dict()\") takes longer. Copy paste following piece of code and run in shell, you would not see much difference in both {} & dict().      from datetime import datetime     then = datetime.now()     a = dict()     now = datetime.now()     print then     print now      then = datetime.now()     b = {}     now = datetime.now()     print then     print now      ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"[] and {} vs list() and dict(), which is better?","A_Content":"  there is one difference in behavior between [] and list() as example below shows. we need to use list() if we want to have the list of numbers returned, otherwise we get a map object! No sure how to explain it though.  sth = [(1,2), (3,4),(5,6)] sth2 = map(lambda x: x[1], sth)  print(sth2) # print returns object <map object at 0x000001AB34C1D9B0>  sth2 = [map(lambda x: x[1], sth)] print(sth2) # print returns object <map object at 0x000001AB34C1D9B0> type(sth2) # list  type(sth2[0]) # map  sth2 = list(map(lambda x: x[1], sth)) print(sth2) #[2, 4, 6] type(sth2) # list type(sth2[0]) # int      ","Language":"Python","Tags":["python","performance","list","dictionary"],"URL":"https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I understand that they are both essentially the same thing, but in terms of style, which is the better (more Pythonic) one to use to create an empty list or dict?     ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  Use hashlib as hash() was designed to be used to:     quickly compare dictionary keys during a dictionary lookup   and therefore does not guarantee that it will be the same across Python implementations.     ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"54","_type":"dict","isAccepted":"Yes","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  As stated in the documentation, built-in hash() function is not designed for storing resulting hashes somewhere externally. It is used to provide object's hash value, to store them in dictionaries and so on. It's also implementation-specific (GAE uses a modified version of Python). Check out:  >>> class Foo: ...     pass ...  >>> a = Foo() >>> b = Foo() >>> hash(a), hash(b) (-1210747828, -1210747892)   As you can see, they are different, as hash() uses object's __hash__ method instead of 'normal' hashing algorithms, such as SHA.  Given the above, the rational choice is to use the hashlib module.     ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"88","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  The response is absolutely no surprise: in fact   In [1]: -5768830964305142685L & 0xffffffff Out[1]: 1934711907L   so if you want to get reliable responses on ASCII strings, just get the lower 32 bits as uint. The hash function for strings is 32-bit-safe and almost portable.  On the other side, you can't rely at all on getting the hash() of any object over which you haven't explicitly defined the __hash__ method to be invariant.   Over ASCII strings it works just because the hash is calculated on the single characters forming the string, like the following:  class string:     def __hash__(self):         if not self:             return 0 # empty         value = ord(self[0]) << 7         for char in self:             value = c_mul(1000003, value) ^ ord(char)         value = value ^ len(self)         if value == -1:             value = -2         return value   where the c_mul function is the \"cyclic\" multiplication (without overflow) as in C.     ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"32","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  Most answers suggest this is because of different platforms, but there is more to it. From the documentation of object.__hash__(self):     By default, the __hash__() values of str, bytes and   datetime objects are salted with an unpredictable random value.   Although they remain constant within an individual Python process,   they are not predictable between repeated invocations of Python.      This is intended to provide protection against a denial-of-service   caused by carefully-chosen inputs that exploit the worst case   performance of a dict insertion, O(n) complexity. See   http://www.ocert.org/advisories/ocert-2011-003.html for details.      Changing hash values affects the iteration order of dicts, sets   and other mappings. Python has never made guarantees about this   ordering (and it typically varies between 32-bit and 64-bit builds).   Even running on the same machine will yield varying results across invocations:  $ python -c \"print(hash('http://stackoverflow.com'))\" -3455286212422042986 $ python -c \"print(hash('http://stackoverflow.com'))\" -6940441840934557333   While:  $ python -c \"print(hash((1,2,3)))\" 2528502973977326415 $ python -c \"print(hash((1,2,3)))\" 2528502973977326415     See also the environment variable PYTHONHASHSEED:     If this variable is not set or set to random, a random value is used   to seed the hashes of str, bytes and datetime objects.      If PYTHONHASHSEED is set to an integer value, it is used as a fixed   seed for generating the hash() of the types covered by the hash   randomization.      Its purpose is to allow repeatable hashing, such as for selftests for   the interpreter itself, or to allow a cluster of python processes to   share hash values.      The integer must be a decimal number in the range [0, 4294967295].   Specifying the value 0 will disable hash randomization.   For example:  $ export PYTHONHASHSEED=0                             $ python -c \"print(hash('http://stackoverflow.com'))\" -5843046192888932305 $ python -c \"print(hash('http://stackoverflow.com'))\" -5843046192888932305      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  Hash results varies between 32bit and 64bit platforms  If a calculated hash shall be the same on both platforms consider using  def hash32(value):     return hash(value) & 0xffffffff      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  At a guess, AppEngine is using a 64-bit implementation of Python (-5768830964305142685 won't fit in 32 bits) and your implementation of Python is 32 bits. You can't rely on object hashes being meaningfully comparable between different implementations.     ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  This is the hash function that Google uses in production for python 2.5:  def c_mul(a, b):   return eval(hex((long(a) * b) & (2**64 - 1))[:-1])  def py25hash(self):   if not self:     return 0 # empty   value = ord(self[0]) << 7   for char in self:     value = c_mul(1000003, value) ^ ord(char)   value = value ^ len(self)   if value == -1:     value = -2   if value >= 2**63:     value -= 2**64   return value      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  What about sign bit?  For example:  Hex value 0xADFE74A5 represents unsigned 2919134373 and signed -1375832923. Currect value must be signed (sign bit = 1) but python converts it as unsigned and we have an incorrect hash value after translation from 64 to 32 bit.  Be careful using:  def hash32(value):     return hash(value) & 0xffffffff      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  Polynomial hash for strings. 1000000009 and 239 are arbitrary prime numbers. Unlikely to have collisions by accident. Modular arithmetic is not very fast, but for preventing collisions this is more reliable than taking it modulo a power of 2. Of course, it is easy to find a collision on purpose.  mod=1000000009 def hash(s):     result=0     for c in s:         result = (result * 239 + ord(c)) % mod     return result % mod      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Built in python hash() function","A_Content":"  The value of PYTHONHASHSEED might be used to initialize the hash values.  Try:  PYTHONHASHSEED python -c 'print(hash('http://stackoverflow.com'))'      ","Language":"Python","Tags":["python","google-app-engine","hash"],"URL":"https://stackoverflow.com/questions/793761/built-in-python-hash-function","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Windows XP, Python 2.5:  hash('http://stackoverflow.com') Result: 1934711907   Google App Engine (http://shell.appspot.com/):  hash('http://stackoverflow.com') Result: -5768830964305142685   Why is that? How can I have a hash function which will give me same results across different platforms (Windows, Linux, Mac)?      ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  Sure, try the following in Python:  import os from nltk.parse import stanford os.environ['STANFORD_PARSER'] = '/path/to/standford/jars' os.environ['STANFORD_MODELS'] = '/path/to/standford/jars'  parser = stanford.StanfordParser(model_path=\"/location/of/the/englishPCFG.ser.gz\") sentences = parser.raw_parse_sents((\"Hello, My name is Melroy.\", \"What is your name?\")) print sentences  # GUI for line in sentences:     for sentence in line:         sentence.draw()   Output:     [Tree('ROOT', [Tree('S', [Tree('INTJ', [Tree('UH', ['Hello'])]),   Tree(',', [',']), Tree('NP', [Tree('PRP$', ['My']), Tree('NN',   ['name'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('ADJP', [Tree('JJ',   ['Melroy'])])]), Tree('.', ['.'])])]), Tree('ROOT', [Tree('SBARQ',   [Tree('WHNP', [Tree('WP', ['What'])]), Tree('SQ', [Tree('VBZ',   ['is']), Tree('NP', [Tree('PRP$', ['your']), Tree('NN', ['name'])])]),   Tree('.', ['?'])])])]   Note 1: In this example both the parser & model jars are in the same folder.  Note 2:   File name of stanford parser is: stanford-parser.jar  File name of stanford models is: stanford-parser-x.x.x-models.jar   Note 3: The englishPCFG.ser.gz file can be found inside the models.jar file (/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz). Please use come archive manager to 'unzip' the models.jar file.  Note 4: Be sure you are using Java JRE (Runtime Environment) 1.8 also known as Oracle JDK 8. Otherwise you will get: Unsupported major.minor version 52.0.  Installation   Download NLTK v3 from: https://github.com/nltk/nltk. And install NLTK:  sudo python setup.py install You can use the NLTK downloader to get Stanford Parser, using Python:  import nltk nltk.download()  Try my example! (don't forget the change the jar paths and change the model path to the ser.gz location)   OR:   Download and install NLTK v3, same as above. Download the latest version from (current version filename is stanford-parser-full-2015-01-29.zip): http://nlp.stanford.edu/software/lex-parser.shtml#Download Extract the standford-parser-full-20xx-xx-xx.zip.  Create a new folder ('jars' in my example). Place the extracted files into this jar folder:  stanford-parser-3.x.x-models.jar and stanford-parser.jar.  As shown above you can use the environment variables (STANFORD_PARSER & STANFORD_MODELS) to point to this 'jars' folder. I'm using Linux, so if you use Windows please use something like: C://folder//jars. Open the stanford-parser-3.x.x-models.jar using an Archive manager (7zip). Browse inside the jar file; edu/stanford/nlp/models/lexparser. Again, extract the file called 'englishPCFG.ser.gz'. Remember the location where you extract this ser.gz file. When creating a StanfordParser instance, you can provide the model path as parameter. This is the complete path to the model, in our case /location/of/englishPCFG.ser.gz. Try my example! (don't forget the change the jar paths and change the model path to the ser.gz location)      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"73","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Deprecated Answer  The answer below is deprecated, please use the solution on https://stackoverflow.com/a/51981566/610569 for NLTK v3.3 and above.    EDITED  Note: The following answer will only work on:   NLTK version >=3.2.4 Stanford Tools compiled since 2015-04-20 Python 2.7, 3.4 and 3.5 (Python 3.6 is not yet officially supported)   As both tools changes rather quickly and the API might look very different 3-6 months later. Please treat the following answer as temporal and not an eternal fix.  Always refer to https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software for the latest instruction on how to interface Stanford NLP tools using NLTK!!     TL;DR  cd $HOME  # Update / Install NLTK pip install -U nltk  # Download the Stanford NLP tools wget http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip wget http://nlp.stanford.edu/software/stanford-postagger-full-2015-04-20.zip wget http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip # Extract the zip file. unzip stanford-ner-2015-04-20.zip  unzip stanford-parser-full-2015-04-20.zip  unzip stanford-postagger-full-2015-04-20.zip   export STANFORDTOOLSDIR=$HOME  export CLASSPATH=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/stanford-postagger.jar:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/stanford-ner.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar  export STANFORD_MODELS=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/models:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/classifiers   Then:  >>> from nltk.tag.stanford import StanfordPOSTagger >>> st = StanfordPOSTagger('english-bidirectional-distsim.tagger') >>> st.tag('What is the airspeed of an unladen swallow ?'.split()) [(u'What', u'WP'), (u'is', u'VBZ'), (u'the', u'DT'), (u'airspeed', u'NN'), (u'of', u'IN'), (u'an', u'DT'), (u'unladen', u'JJ'), (u'swallow', u'VB'), (u'?', u'.')]  >>> from nltk.tag import StanfordNERTagger >>> st = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')  >>> st.tag('Rami Eid is studying at Stony Brook University in NY'.split()) [(u'Rami', u'PERSON'), (u'Eid', u'PERSON'), (u'is', u'O'), (u'studying', u'O'), (u'at', u'O'), (u'Stony', u'ORGANIZATION'), (u'Brook', u'ORGANIZATION'), (u'University', u'ORGANIZATION'), (u'in', u'O'), (u'NY', u'O')]   >>> from nltk.parse.stanford import StanfordParser >>> parser=StanfordParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\") >>> list(parser.raw_parse(\"the quick brown fox jumps over the lazy dog\")) [Tree('ROOT', [Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('JJ', ['quick']), Tree('JJ', ['brown']), Tree('NN', ['fox'])]), Tree('NP', [Tree('NP', [Tree('NNS', ['jumps'])]), Tree('PP', [Tree('IN', ['over']), Tree('NP', [Tree('DT', ['the']), Tree('JJ', ['lazy']), Tree('NN', ['dog'])])])])])])]  >>> from nltk.parse.stanford import StanfordDependencyParser >>> dep_parser=StanfordDependencyParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\") >>> print [parse.tree() for parse in dep_parser.raw_parse(\"The quick brown fox jumps over the lazy dog.\")] [Tree('jumps', [Tree('fox', ['The', 'quick', 'brown']), Tree('dog', ['over', 'the', 'lazy'])])]     In Long:    Firstly, one must note that the Stanford NLP tools are written in Java and NLTK is written in Python. The way NLTK is interfacing the tool is through the call the Java tool through the command line interface.   Secondly, the NLTK API to the Stanford NLP tools have changed quite a lot since the version 3.1. So it is advisable to update your NLTK package to v3.1.  Thirdly, the NLTK API to Stanford NLP Tools wraps around the individual NLP tools, e.g. Stanford POS tagger, Stanford NER Tagger, Stanford Parser.   For the POS and NER tagger, it DOES NOT wrap around the Stanford Core NLP package.   For the Stanford Parser, it's a special case where it wraps around both the Stanford Parser and the Stanford Core NLP (personally, I have not used the latter using NLTK, i would rather follow @dimazest's demonstration on http://www.eecs.qmul.ac.uk/~dm303/stanford-dependency-parser-nltk-and-anaconda.html )  Note that as of NLTK v3.1, the STANFORD_JAR and STANFORD_PARSER variables is deprecated and NO LONGER used    In Longer:    STEP 1  Assuming that you have installed Java appropriately on your OS.  Now, install/update your NLTK version (see http://www.nltk.org/install.html):   Using pip: sudo pip install -U nltk Debian distro (using apt-get): sudo apt-get install python-nltk   For Windows (Use the 32-bit binary installation):   Install Python 3.4: http://www.python.org/downloads/ (avoid the 64-bit versions) Install Numpy (optional): http://sourceforge.net/projects/numpy/files/NumPy/ (the version that specifies pythnon3.4) Install NLTK: http://pypi.python.org/pypi/nltk Test installation: Start>Python34, then type import nltk   (Why not 64 bit? See https://github.com/nltk/nltk/issues/1079)    Then out of paranoia, recheck your nltk version inside python:  from __future__ import print_function import nltk print(nltk.__version__)   Or on the command line:  python3 -c \"import nltk; print(nltk.__version__)\"   Make sure that you see 3.1 as the output.  For even more paranoia, check that all your favorite Stanford NLP tools API are available:  from nltk.parse.stanford import StanfordParser from nltk.parse.stanford import StanfordDependencyParser from nltk.parse.stanford import StanfordNeuralDependencyParser from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger from nltk.tokenize.stanford import StanfordTokenizer   (Note: The imports above will ONLY ensure that you are using a correct NLTK version that contains these APIs. Not seeing errors in the import doesn't mean that you have successfully configured the NLTK API to use the Stanford Tools)    STEP 2  Now that you have checked that you have the correct version of NLTK that contains the necessary Stanford NLP tools interface. You need to download and extract all the necessary Stanford NLP tools.  TL;DR, in Unix:  cd $HOME  # Download the Stanford NLP tools wget http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip wget http://nlp.stanford.edu/software/stanford-postagger-full-2015-04-20.zip wget http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip # Extract the zip file. unzip stanford-ner-2015-04-20.zip  unzip stanford-parser-full-2015-04-20.zip  unzip stanford-postagger-full-2015-04-20.zip   In Windows / Mac:   Download and unzip the parser from http://nlp.stanford.edu/software/lex-parser.shtml#Download Download and unizp the FULL VERSION tagger from http://nlp.stanford.edu/software/tagger.shtml#Download Download and unizp the NER tagger from http://nlp.stanford.edu/software/CRF-NER.shtml#Download     STEP 3  Setup the environment variables such that NLTK can find the relevant file path automatically. You have to set the following variables:   Add the appropriate Stanford NLP .jar file to the  CLASSPATH environment variable.   e.g. for the NER, it will be stanford-ner-2015-04-20/stanford-ner.jar e.g. for the POS, it will be stanford-postagger-full-2015-04-20/stanford-postagger.jar e.g. for the parser, it will be stanford-parser-full-2015-04-20/stanford-parser.jar and the parser model jar file, stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar  Add the appropriate model directory to the STANFORD_MODELS variable (i.e. the directory where you can find where the pre-trained models are saved)   e.g. for the NER, it will be in stanford-ner-2015-04-20/classifiers/ e.g. for the POS, it will be in stanford-postagger-full-2015-04-20/models/ e.g. for the Parser, there won't be a model directory.    In the code, see that it searches for the STANFORD_MODELS directory before appending the model name. Also see that, the API also automatically tries to search the OS environments for the `CLASSPATH)  Note that as of NLTK v3.1, the STANFORD_JAR variables is deprecated and NO LONGER used. Code snippets found in the following Stackoverflow questions might not work:   Stanford Dependency Parser Setup and NLTK nltk interface to stanford parser trouble importing stanford pos tagger into nltk Stanford Entity Recognizer (caseless) in Python Nltk How to improve speed with Stanford NLP Tagger and NLTK How can I get the stanford NLTK python module? Stanford Parser and NLTK windows Stanford Named Entity Recognizer (NER) functionality with NLTK Stanford parser with NLTK produces empty output Extract list of Persons and Organizations using Stanford NER Tagger in NLTK Error using Stanford POS Tagger in NLTK Python   TL;DR for STEP 3 on Ubuntu  export STANFORDTOOLSDIR=/home/path/to/stanford/tools/  export CLASSPATH=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/stanford-postagger.jar:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/stanford-ner.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar  export STANFORD_MODELS=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/models:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/classifiers   (For Windows: See https://stackoverflow.com/a/17176423/610569 for instructions for setting environment variables)  You MUST set the variables as above before starting python, then:  >>> from nltk.tag.stanford import StanfordPOSTagger >>> st = StanfordPOSTagger('english-bidirectional-distsim.tagger') >>> st.tag('What is the airspeed of an unladen swallow ?'.split()) [(u'What', u'WP'), (u'is', u'VBZ'), (u'the', u'DT'), (u'airspeed', u'NN'), (u'of', u'IN'), (u'an', u'DT'), (u'unladen', u'JJ'), (u'swallow', u'VB'), (u'?', u'.')]  >>> from nltk.tag import StanfordNERTagger >>> st = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')  >>> st.tag('Rami Eid is studying at Stony Brook University in NY'.split()) [(u'Rami', u'PERSON'), (u'Eid', u'PERSON'), (u'is', u'O'), (u'studying', u'O'), (u'at', u'O'), (u'Stony', u'ORGANIZATION'), (u'Brook', u'ORGANIZATION'), (u'University', u'ORGANIZATION'), (u'in', u'O'), (u'NY', u'O')]   >>> from nltk.parse.stanford import StanfordParser >>> parser=StanfordParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\") >>> list(parser.raw_parse(\"the quick brown fox jumps over the lazy dog\")) [Tree('ROOT', [Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('JJ', ['quick']), Tree('JJ', ['brown']), Tree('NN', ['fox'])]), Tree('NP', [Tree('NP', [Tree('NNS', ['jumps'])]), Tree('PP', [Tree('IN', ['over']), Tree('NP', [Tree('DT', ['the']), Tree('JJ', ['lazy']), Tree('NN', ['dog'])])])])])])]     Alternatively, you could try add the environment variables inside python, as the previous answers have suggested but you can also directly tell the parser/tagger to initialize to the direct path where you kept the .jar file and your models.   There is NO need to set the environment variables if you use the following method BUT when the API changes its parameter names, you will need to change accordingly. That is why it is MORE advisable to set the environment variables than to modify your python code to suit the NLTK version.  For example (without setting any environment variables):  # POS tagging:  from nltk.tag import StanfordPOSTagger  stanford_pos_dir = '/home/alvas/stanford-postagger-full-2015-04-20/' eng_model_filename= stanford_pos_dir + 'models/english-left3words-distsim.tagger' my_path_to_jar= stanford_pos_dir + 'stanford-postagger.jar'  st = StanfordPOSTagger(model_filename=eng_model_filename, path_to_jar=my_path_to_jar)  st.tag('What is the airspeed of an unladen swallow ?'.split())   # NER Tagging: from nltk.tag import StanfordNERTagger  stanford_ner_dir = '/home/alvas/stanford-ner/' eng_model_filename= stanford_ner_dir + 'classifiers/english.all.3class.distsim.crf.ser.gz' my_path_to_jar= stanford_ner_dir + 'stanford-ner.jar'  st = StanfordNERTagger(model_filename=eng_model_filename, path_to_jar=my_path_to_jar)  st.tag('Rami Eid is studying at Stony Brook University in NY'.split())  # Parsing: from nltk.parse.stanford import StanfordParser  stanford_parser_dir = '/home/alvas/stanford-parser/' eng_model_path = stanford_parser_dir  + \"edu/stanford/nlp/models/lexparser/englishRNN.ser.gz\" my_path_to_models_jar = stanford_parser_dir  + \"stanford-parser-3.5.2-models.jar\" my_path_to_jar = stanford_parser_dir  + \"stanford-parser.jar\"  parser=StanfordParser(model_path=eng_model_path, path_to_models_jar=my_path_to_models_jar, path_to_jar=my_path_to_jar)      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Deprecated Answer  The answer below is deprecated, please use the solution on https://stackoverflow.com/a/51981566/610569 for NLTK v3.3 and above.    Edited  As of the current Stanford parser (2015-04-20), the default output for the lexparser.sh has changed so the script below will not work.  But this answer is kept for legacy sake, it will still work with http://nlp.stanford.edu/software/stanford-parser-2012-11-12.zip though.    Original Answer  I suggest you don't mess with Jython, JPype. Let python do python stuff and let java do java stuff, get the Stanford Parser output through the console.  After you've installed the Stanford Parser in your home directory ~/, just use this python recipe to get the flat bracketed parse:  import os sentence = \"this is a foo bar i want to parse.\"  os.popen(\"echo '\"+sentence+\"' > ~/stanfordtemp.txt\") parser_out = os.popen(\"~/stanford-parser-2012-11-12/lexparser.sh ~/stanfordtemp.txt\").readlines()  bracketed_parse = \" \".join( [i.strip() for i in parser_out if i.strip()[0] == \"(\"] ) print bracketed_parse      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  There is python interface for stanford parser  http://projects.csail.mit.edu/spatial/Stanford_Parser     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  The Stanford Core NLP software page has a list of python wrappers:  http://nlp.stanford.edu/software/corenlp.shtml#Extensions     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  If I remember well, the Stanford parser is a java library, therefore you must have a Java interpreter running on your server/computer.  I used it once a server, combined with a php script. The script used php's exec() function to make a command-line call to the parser like so:  <?php  exec( \"java -cp /pathTo/stanford-parser.jar -mx100m edu.stanford.nlp.process.DocumentPreprocessor /pathTo/fileToParse > /pathTo/resultFile 2>/dev/null\" );  ?>   I don't remember all the details of this command, it basically opened the fileToParse, parsed it, and wrote the output in the resultFile. PHP would then open the result file for further use.  The end of the command directs the parser's verbose to NULL, to prevent unnecessary command line information from disturbing the script.  I don't know much about Python, but there might be a way to make command line calls.  It might not be the exact route you were hoping for, but hopefully it'll give you some inspiration. Best of luck.     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  Here is an adaptation of danger98's code that works with nltk3.0.0 on windoze, and presumably the other platforms as well, adjust directory names as appropriate for your setup:  import os from nltk.parse import stanford os.environ['STANFORD_PARSER'] = 'd:/stanford-parser' os.environ['STANFORD_MODELS'] = 'd:/stanford-parser' os.environ['JAVAHOME'] = 'c:/Program Files/java/jre7/bin'  parser = stanford.StanfordParser(model_path=\"d:/stanford-grammars/englishPCFG.ser.gz\") sentences = parser.raw_parse_sents((\"Hello, My name is Melroy.\", \"What is your name?\")) print sentences   Note that the parsing command has changed (see the source code at www.nltk.org/_modules/nltk/parse/stanford.html), and that you need to define the JAVAHOME variable.  I tried to get it to read the grammar file in situ in the jar, but have so far failed to do that.     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  You can use the Stanford Parsers output to create a Tree in nltk (nltk.tree.Tree).  Assuming the stanford parser gives you a file in which there is exactly one parse tree for every sentence. Then this example works, though it might not look very pythonic:  f = open(sys.argv[1]+\".output\"+\".30\"+\".stp\", \"r\") parse_trees_text=[] tree = \"\" for line in f:   if line.isspace():     parse_trees_text.append(tree) tree = \"\"   elif \"(. ...))\" in line: #print \"YES\" tree = tree+')' parse_trees_text.append(tree) tree = \"\"   else: tree = tree + line  parse_trees=[] for t in parse_trees_text:   tree = nltk.Tree(t)   tree.__delitem__(len(tree)-1) #delete \"(. .))\" from tree (you don't need that)   s = traverse(tree)   parse_trees.append(tree)      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  I am on a windows machine and you can simply run the parser normally as you do from the command like but as in a different directory so you don't need to edit the lexparser.bat file. Just put in the full path.   cmd = r'java -cp \\Documents\\stanford_nlp\\stanford-parser-full-2015-01-30 edu.stanford.nlp.parser.lexparser.LexicalizedParser -outputFormat \"typedDependencies\" \\Documents\\stanford_nlp\\stanford-parser-full-2015-01-30\\stanford-parser-3.5.1-models\\edu\\stanford\\nlp\\models\\lexparser\\englishFactored.ser.gz stanfordtemp.txt' parse_out = os.popen(cmd).readlines()   The tricky part for me was realizing how to run a java program from a different path. There must be a better way but this works.     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  A slight update (or simply alternative) on danger89's comprehensive answer on using Stanford Parser in NLTK and Python  With stanford-parser-full-2015-04-20, JRE 1.8 and nltk 3.0.4 (python 2.7.6), it appears that you no longer need to extract the englishPCFG.ser.gz from stanford-parser-x.x.x-models.jar or setting up any os.environ  from nltk.parse.stanford import StanfordParser  english_parser = StanfordParser('path/stanford-parser.jar', 'path/stanford-parser-3.5.2-models.jar')  s = \"The real voyage of discovery consists not in seeking new landscapes, but in having new eyes.\"  sentences = english_parser.raw_parse_sents((s,)) print sentences #only print <listiterator object> for this version  #draw the tree for line in sentences:     for sentence in line:         sentence.draw()      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  Here is the windows version of alvas's answer  sentences = ('. '.join(['this is sentence one without a period','this is another foo bar sentence '])+'.').encode('ascii',errors = 'ignore') catpath =r\"YOUR CURRENT FILE PATH\"  f = open('stanfordtemp.txt','w') f.write(sentences) f.close()  parse_out = os.popen(catpath+r\"\\nlp_tools\\stanford-parser-2010-08-20\\lexparser.bat \"+catpath+r\"\\stanfordtemp.txt\").readlines()  bracketed_parse = \" \".join( [i.strip() for i in parse_out if i.strip() if i.strip()[0] == \"(\"] ) bracketed_parse = \"\\n(ROOT\".join(bracketed_parse.split(\" (ROOT\")).split('\\n') aa = map(lambda x :ParentedTree.fromstring(x),bracketed_parse)   NOTES:   In lexparser.bat  you need to change all the paths into absolute path to avoid java errors such as \"class not found\" I strongly recommend you to apply this method under windows since I Tried several answers on the page and   all the methods communicates python with Java fails. wish to hear from you if you succeed on windows and wish you can tell me how you overcome all these problems. search python wrapper for stanford coreNLP to get the python version        ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  Since nobody really mentioned and it's somehow troubled me a lot, here is an alternative way to use Stanford parser in python:  stanford_parser_jar = '../lib/stanford-parser-full-2015-04-20/stanford-parser.jar' stanford_model_jar = '../lib/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar'     parser = StanfordParser(path_to_jar=stanford_parser_jar,                          path_to_models_jar=stanford_model_jar)   in this way, you don't need to worry about the path thing anymore.  For those who cannot use it properly on Ubuntu or run the code in Eclipse.     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  As of NLTK v3.3, users should avoid the Stanford NER or POS taggers from nltk.tag, and avoid Stanford tokenizer/segmenter from nltk.tokenize.  Instead use the new nltk.parse.corenlp.CoreNLPParser API.   Please see https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK    (Avoiding link only answer, I've pasted the docs from NLTK github wiki below)  First, update your NLTK  pip3 install -U nltk # Make sure is >=3.3   Then download the necessary CoreNLP packages:  cd ~ wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip unzip stanford-corenlp-full-2018-02-27.zip cd stanford-corenlp-full-2018-02-27  # Get the Chinese model  wget http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-02-27-models.jar wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/StanfordCoreNLP-chinese.properties   # Get the Arabic model wget http://nlp.stanford.edu/software/stanford-arabic-corenlp-2018-02-27-models.jar wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/StanfordCoreNLP-arabic.properties   # Get the French model wget http://nlp.stanford.edu/software/stanford-french-corenlp-2018-02-27-models.jar wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/StanfordCoreNLP-french.properties   # Get the German model wget http://nlp.stanford.edu/software/stanford-german-corenlp-2018-02-27-models.jar wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/StanfordCoreNLP-german.properties    # Get the Spanish model wget http://nlp.stanford.edu/software/stanford-spanish-corenlp-2018-02-27-models.jar wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/StanfordCoreNLP-spanish.properties    English  Still in the stanford-corenlp-full-2018-02-27 directory, start the server:  java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -preload tokenize,ssplit,pos,lemma,ner,parse,depparse \\ -status_port 9000 -port 9000 -timeout 15000 &    Then in Python:  >>> from nltk.parse import CoreNLPParser  # Lexical Parser >>> parser = CoreNLPParser(url='http://localhost:9000')  # Parse tokenized text. >>> list(parser.parse('What is the airspeed of an unladen swallow ?'.split())) [Tree('ROOT', [Tree('SBARQ', [Tree('WHNP', [Tree('WP', ['What'])]), Tree('SQ', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['airspeed'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['an']), Tree('JJ', ['unladen'])])]), Tree('S', [Tree('VP', [Tree('VB', ['swallow'])])])])]), Tree('.', ['?'])])])]  # Parse raw string. >>> list(parser.raw_parse('What is the airspeed of an unladen swallow ?')) [Tree('ROOT', [Tree('SBARQ', [Tree('WHNP', [Tree('WP', ['What'])]), Tree('SQ', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['airspeed'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['an']), Tree('JJ', ['unladen'])])]), Tree('S', [Tree('VP', [Tree('VB', ['swallow'])])])])]), Tree('.', ['?'])])])]  # Neural Dependency Parser >>> from nltk.parse.corenlp import CoreNLPDependencyParser >>> dep_parser = CoreNLPDependencyParser(url='http://localhost:9000') >>> parses = dep_parser.parse('What is the airspeed of an unladen swallow ?'.split()) >>> [[(governor, dep, dependent) for governor, dep, dependent in parse.triples()] for parse in parses] [[(('What', 'WP'), 'cop', ('is', 'VBZ')), (('What', 'WP'), 'nsubj', ('airspeed', 'NN')), (('airspeed', 'NN'), 'det', ('the', 'DT')), (('airspeed', 'NN'), 'nmod', ('swallow', 'VB')), (('swallow', 'VB'), 'case', ('of', 'IN')), (('swallow', 'VB'), 'det', ('an', 'DT')), (('swallow', 'VB'), 'amod', ('unladen', 'JJ')), (('What', 'WP'), 'punct', ('?', '.'))]]   # Tokenizer >>> parser = CoreNLPParser(url='http://localhost:9000') >>> list(parser.tokenize('What is the airspeed of an unladen swallow?')) ['What', 'is', 'the', 'airspeed', 'of', 'an', 'unladen', 'swallow', '?']  # POS Tagger >>> pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos') >>> list(pos_tagger.tag('What is the airspeed of an unladen swallow ?'.split())) [('What', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('airspeed', 'NN'), ('of', 'IN'), ('an', 'DT'), ('unladen', 'JJ'), ('swallow', 'VB'), ('?', '.')]  # NER Tagger >>> ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner') >>> list(ner_tagger.tag(('Rami Eid is studying at Stony Brook University in NY'.split()))) [('Rami', 'PERSON'), ('Eid', 'PERSON'), ('is', 'O'), ('studying', 'O'), ('at', 'O'), ('Stony', 'ORGANIZATION'), ('Brook', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('in', 'O'), ('NY', 'STATE_OR_PROVINCE')]   Chinese  Start the server a little differently, still from the `stanford-corenlp-full-2018-02-27 directory:  java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -serverProperties StanfordCoreNLP-chinese.properties \\ -preload tokenize,ssplit,pos,lemma,ner,parse \\ -status_port 9001  -port 9001 -timeout 15000   In Python:  >>> parser = CoreNLPParser('http://localhost:9001') >>> list(parser.tokenize(u'')) ['', '', '', '']  >>> list(parser.parse(parser.tokenize(u''))) [Tree('ROOT', [Tree('IP', [Tree('IP', [Tree('NP', [Tree('NN', [''])]), Tree('VP', [Tree('VE', ['']), Tree('NP', [Tree('NN', [''])])])]), Tree('PU', [''])])])]   Arabic  Start the server:  java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -serverProperties StanfordCoreNLP-arabic.properties \\ -preload tokenize,ssplit,pos,parse \\ -status_port 9005  -port 9005 -timeout 15000   In Python:  >>> from nltk.parse import CoreNLPParser >>> parser = CoreNLPParser('http://localhost:9005') >>> text = u' '  # Parser. >>> parser.parse(text) <list_iterator object at 0x7fb5e5d27550> >>> list(parser.parse(text)) [Tree('ROOT', [Tree('S', [Tree('NP', [Tree('PRP', [''])]), Tree('SBAR', [Tree('IN', ['']), Tree('S', [Tree('VP', [Tree('PRP', ['']), Tree('NP', [Tree('NN', ['']), Tree('SBAR', [Tree('IN', ['']), Tree('S', [Tree('VP', [Tree('NN', ['']), Tree('PP', [Tree('IN', [''])])])])])])])])])])])]  # Tokenizer / Segmenter. >>> list(parser.tokenize(text)) ['', '']  # POS tagg >>> pos_tagger = CoreNLPParser('http://localhost:9005', tagtype='pos') >>> list(pos_tagger.tag(parser.tokenize(text))) [('', 'PRP'), ('', 'NN')]   # NER tag >>> ner_tagger = CoreNLPParser('http://localhost:9005', tagtype='ner') >>> list(ner_tagger.tag(parser.tokenize(text))) [('', 'O'), ('', 'O')]   French  Start the server:  java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -serverProperties StanfordCoreNLP-french.properties \\ -preload tokenize,ssplit,pos,parse \\ -status_port 9004  -port 9004 -timeout 15000   In Python:  >>> parser = CoreNLPParser('http://localhost:9004') >>> list(parser.parse('Je suis enceinte'.split())) [Tree('ROOT', [Tree('SENT', [Tree('NP', [Tree('PRON', ['Je']), Tree('VERB', ['suis']), Tree('AP', [Tree('ADJ', ['enceinte'])])])])])] >>> pos_tagger = CoreNLPParser('http://localhost:9004', tagtype='pos') >>> pos_tagger.tag('Je suis enceinte'.split()) [('Je', 'PRON'), ('suis', 'VERB'), ('enceinte', 'ADJ')]   German  Start the server:  java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -serverProperties StanfordCoreNLP-german.properties \\ -preload tokenize,ssplit,pos,ner,parse \\ -status_port 9002  -port 9002 -timeout 15000   In Python:  >>> parser = CoreNLPParser('http://localhost:9002') >>> list(parser.raw_parse('Ich bin schwanger')) [Tree('ROOT', [Tree('NUR', [Tree('S', [Tree('PPER', ['Ich']), Tree('VAFIN', ['bin']), Tree('AP', [Tree('ADJD', ['schwanger'])])])])])] >>> list(parser.parse('Ich bin schwanger'.split())) [Tree('ROOT', [Tree('NUR', [Tree('S', [Tree('PPER', ['Ich']), Tree('VAFIN', ['bin']), Tree('AP', [Tree('ADJD', ['schwanger'])])])])])]   >>> pos_tagger = CoreNLPParser('http://localhost:9002', tagtype='pos') >>> pos_tagger.tag('Ich bin schwanger'.split()) [('Ich', 'PPER'), ('bin', 'VAFIN'), ('schwanger', 'ADJD')]  >>> pos_tagger = CoreNLPParser('http://localhost:9002', tagtype='pos') >>> pos_tagger.tag('Ich bin schwanger'.split()) [('Ich', 'PPER'), ('bin', 'VAFIN'), ('schwanger', 'ADJD')]  >>> ner_tagger = CoreNLPParser('http://localhost:9002', tagtype='ner') >>> ner_tagger.tag('Donald Trump besuchte Angela Merkel in Berlin.'.split()) [('Donald', 'PERSON'), ('Trump', 'PERSON'), ('besuchte', 'O'), ('Angela', 'PERSON'), ('Merkel', 'PERSON'), ('in', 'O'), ('Berlin', 'LOCATION'), ('.', 'O')]   Spanish  Start the server:  java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -serverProperties StanfordCoreNLP-spanish.properties \\ -preload tokenize,ssplit,pos,ner,parse \\ -status_port 9003  -port 9003 -timeout 15000   In Python:  >>> pos_tagger = CoreNLPParser('http://localhost:9003', tagtype='pos') >>> pos_tagger.tag(u'Barack Obama sali con Michael Jackson .'.split()) [('Barack', 'PROPN'), ('Obama', 'PROPN'), ('sali', 'VERB'), ('con', 'ADP'), ('Michael', 'PROPN'), ('Jackson', 'PROPN'), ('.', 'PUNCT')] >>> ner_tagger = CoreNLPParser('http://localhost:9003', tagtype='ner') >>> ner_tagger.tag(u'Barack Obama sali con Michael Jackson .'.split()) [('Barack', 'PERSON'), ('Obama', 'PERSON'), ('sali', 'O'), ('con', 'O'), ('Michael', 'PERSON'), ('Jackson', 'PERSON'), ('.', 'O')]      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  I took many hours and finally found a simple solution for Windows users. Basically its summarized version of an existing answer by alvas, but made easy to follow(hopefully) for those who are new to stanford NLP and are Window users.  1) Download the module you want to use, such as NER, POS etc. In my case i wanted to use NER, so i downloaded the module from http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip  2) Unzip the file.  3) Set the environment variables(classpath and stanford_modules) from the unzipped folder.  import os os.environ['CLASSPATH'] = \"C:/Users/Downloads/stanford-ner-2015-04-20/stanford-ner.jar\" os.environ['STANFORD_MODELS'] = \"C:/Users/Downloads/stanford-ner-2015-04-20/classifiers/\"   4) set the environment variables for JAVA, as in where you have JAVA installed. for me it was below  os.environ['JAVAHOME'] = \"C:/Program Files/Java/jdk1.8.0_102/bin/java.exe\"   5) import the module you want  from nltk.tag import StanfordNERTagger   6) call the pretrained model which is present in classifier folder in the unzipped folder. add \".gz\" in the end for file extension. for me the model i wanted to use was english.all.3class.distsim.crf.ser  st = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')   7) Now execute the parser!! and we are done!!  st.tag('Rami Eid is studying at Stony Brook University in NY'.split())      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Deprecated Answer  The answer below is deprecated, please use the solution on https://stackoverflow.com/a/51981566/610569 for NLTK v3.3 and above.    EDITED  Note: The following answer will only work on:   NLTK version ==3.2.5 Stanford Tools compiled since 2016-10-31 Python 2.7, 3.5 and 3.6   As both tools changes rather quickly and the API might look very different 3-6 months later. Please treat the following answer as temporal and not an eternal fix.  Always refer to https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software for the latest instruction on how to interface Stanford NLP tools using NLTK!!  TL;DR  The follow code comes from https://github.com/nltk/nltk/pull/1735#issuecomment-306091826  In terminal:  wget http://nlp.stanford.edu/software/stanford-corenlp-full-2016-10-31.zip unzip stanford-corenlp-full-2016-10-31.zip && cd stanford-corenlp-full-2016-10-31  java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -preload tokenize,ssplit,pos,lemma,parse,depparse \\ -status_port 9000 -port 9000 -timeout 15000   In Python:  >>> from nltk.tag.stanford import CoreNLPPOSTagger, CoreNLPNERTagger >>> from nltk.parse.corenlp import CoreNLPParser  >>> stpos, stner = CoreNLPPOSTagger(), CoreNLPNERTagger()  >>> stpos.tag('What is the airspeed of an unladen swallow ?'.split()) [(u'What', u'WP'), (u'is', u'VBZ'), (u'the', u'DT'), (u'airspeed', u'NN'), (u'of', u'IN'), (u'an', u'DT'), (u'unladen', u'JJ'), (u'swallow', u'VB'), (u'?', u'.')]  >>> stner.tag('Rami Eid is studying at Stony Brook University in NY'.split()) [(u'Rami', u'PERSON'), (u'Eid', u'PERSON'), (u'is', u'O'), (u'studying', u'O'), (u'at', u'O'), (u'Stony', u'ORGANIZATION'), (u'Brook', u'ORGANIZATION'), (u'University', u'ORGANIZATION'), (u'in', u'O'), (u'NY', u'O')]   >>> parser = CoreNLPParser(url='http://localhost:9000')  >>> next( ...     parser.raw_parse('The quick brown fox jumps over the lazy dog.') ... ).pretty_print()  # doctest: +NORMALIZE_WHITESPACE                      ROOT                       |                       S        _______________|__________________________       |                         VP               |       |                _________|___             |       |               |             PP           |       |               |     ________|___         |       NP              |    |            NP       |   ____|__________     |    |     _______|____    |  DT   JJ    JJ   NN  VBZ   IN   DT      JJ   NN  .  |    |     |    |    |    |    |       |    |   | The quick brown fox jumps over the     lazy dog  .  >>> (parse_fox, ), (parse_wolf, ) = parser.raw_parse_sents( ...     [ ...         'The quick brown fox jumps over the lazy dog.', ...         'The quick grey wolf jumps over the lazy fox.', ...     ] ... )  >>> parse_fox.pretty_print()  # doctest: +NORMALIZE_WHITESPACE                      ROOT                       |                       S        _______________|__________________________       |                         VP               |       |                _________|___             |       |               |             PP           |       |               |     ________|___         |       NP              |    |            NP       |   ____|__________     |    |     _______|____    |  DT   JJ    JJ   NN  VBZ   IN   DT      JJ   NN  .  |    |     |    |    |    |    |       |    |   | The quick brown fox jumps over the     lazy dog  .  >>> parse_wolf.pretty_print()  # doctest: +NORMALIZE_WHITESPACE                      ROOT                       |                       S        _______________|__________________________       |                         VP               |       |                _________|___             |       |               |             PP           |       |               |     ________|___         |       NP              |    |            NP       |   ____|_________      |    |     _______|____    |  DT   JJ   JJ   NN   VBZ   IN   DT      JJ   NN  .  |    |    |    |     |    |    |       |    |   | The quick grey wolf jumps over the     lazy fox  .  >>> (parse_dog, ), (parse_friends, ) = parser.parse_sents( ...     [ ...         \"I 'm a dog\".split(), ...         \"This is my friends ' cat ( the tabby )\".split(), ...     ] ... )  >>> parse_dog.pretty_print()  # doctest: +NORMALIZE_WHITESPACE         ROOT          |          S   _______|____  |            VP  |    ________|___  NP  |            NP  |   |         ___|___ PRP VBP       DT      NN  |   |        |       |  I   'm       a      dog   Please take a look at http://www.nltk.org/_modules/nltk/parse/corenlp.html  for more information on of the Stanford API. Take a look at the docstrings!     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  Note that this answer applies to NLTK v 3.0, and not to more recent versions.  I cannot leave this as a comment because of reputation, but since I spent (wasted?) some time solving this I would rather share my problem/solution to get this parser to work in NLTK.  In the excellent answer from alvas, it is mentioned that:     e.g. for the Parser, there won't be a model directory.   This led me wrongly to:   not be careful to the value I put to STANFORD_MODELS  (and only care about my CLASSPATH) leave ../path/tostanford-parser-full-2015-2012-09/models directory * virtually empty* (or with a jar file whose name did not match nltk regex)!   If the OP, like me, just wanted to use the parser, it may be confusing that when not downloading anything else (no POStagger, no NER,...) and following all these instructions, we still get an error.  Eventually, for any CLASSPATH given (following examples and explanations in answers from this thread) I would still get the error:     NLTK was unable to find stanford-parser-(\\d+)(.(\\d+))+-models.jar!   Set the CLASSPATH environment variable. For more information, on   stanford-parser-(\\d+)(.(\\d+))+-models.jar,   see:     http://nlp.stanford.edu/software/lex-parser.shtml  OR:     NLTK was unable to find stanford-parser.jar! Set the CLASSPATH   environment variable. For more information, on stanford-parser.jar,   see: http://nlp.stanford.edu/software/lex-parser.shtml   Though, importantly, I could correctly load and use the parser if I called the function with all arguments and path fully specified, as in:  stanford_parser_jar = '../lib/stanford-parser-full-2015-04-20/stanford-parser.jar' stanford_model_jar = '../lib/stanford-parser-full-2015-04-20/stanfor-parser-3.5.2-models.jar'     parser = StanfordParser(path_to_jar=stanford_parser_jar,                      path_to_models_jar=stanford_model_jar)   Solution for Parser alone:  Therefore the error came from NLTK and how it is looking for jars using the supplied STANFORD_MODELS and CLASSPATH environment variables. To solve this, the *-models.jar, with the correct formatting (to match the regex in NLTK code, so no -corenlp-....jar) must be located in the folder designated by STANFORD_MODELS.  Namely, I first created:  mkdir stanford-parser-full-2015-12-09/models   Then added in .bashrc:  export STANFORD_MODELS=/path/to/stanford-parser-full-2015-12-09/models   And finally, by copying stanford-parser-3.6.0-models.jar (or corresponding version), into:  path/to/stanford-parser-full-2015-12-09/models/   I could get StanfordParser to load smoothly in python with the classic CLASSPATH that points to stanford-parser.jar. Actually, as such, you can call StanfordParser with no parameters, the default will just work.     ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Stanford Parser and NLTK","A_Content":"  I am using nltk version 3.2.4. And following code worked for me.  from nltk.internals import find_jars_within_path from nltk.tag import StanfordPOSTagger from nltk import word_tokenize  # Alternatively to setting the CLASSPATH add the jar and model via their  path: jar = '/home/ubuntu/stanford-postagger-full-2017-06-09/stanford-postagger.jar' model = '/home/ubuntu/stanford-postagger-full-2017-06-09/models/english-left3words-distsim.tagger'  pos_tagger = StanfordPOSTagger(model, jar)  # Add other jars from Stanford directory stanford_dir = pos_tagger._stanford_jar.rpartition('/')[0] stanford_jars = find_jars_within_path(stanford_dir) pos_tagger._stanford_jar = ':'.join(stanford_jars)  text = pos_tagger.tag(word_tokenize(\"Open app and play movie\")) print(text)   Output:  [('Open', 'VB'), ('app', 'NN'), ('and', 'CC'), ('play', 'VB'), ('movie', 'NN')]      ","Language":"Python","Tags":["python","parsing","nlp","nltk","stanford-nlp"],"URL":"https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to use Stanford Parser in NLTK? (I am not talking about Stanford POS.)     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  You can use the BytesIO class to get a wrapper around strings that behaves like a file. The BytesIO object provides the same interface as a file, but saves the contents just in memory:  import io  with io.BytesIO() as output:     image.save(output)     contents = output.getvalue()   This might lead to a KeyError if PIL tries to automatically detect the output format. To avoid this problem you can specify the format manually:  image.save(output, format=\"GIF\")   In old Python 2 versions before introduction of the io module you would have used the StringIO module instead.     ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"158","_type":"dict","isAccepted":"Yes","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  For Python3 it is required to use BytesIO:   from io import BytesIO from PIL import Image, ImageDraw  image = Image.new(\"RGB\", (300, 50)) draw = ImageDraw.Draw(image) draw.text((0, 0), \"This text is drawn on image\")  byte_io = BytesIO()  image.save(byte_io, 'PNG')   Read more: http://fadeit.dk/blog/post/python3-flask-pil-in-memory-image     ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  sth's solution didn't work for me because in ...     Imaging/PIL/Image.pyc line 1423 ->   raise KeyError(ext) # unknown   extension   It was trying to detect the format from the extension in the filename , which doesn't exist in StringIO case    You can bypass the format detection by setting the format yourself in a parameter    import StringIO output = StringIO.StringIO() format = 'PNG' # or 'JPEG' or whatever you want image.save(output, format) contents = output.getvalue() output.close()      ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  save() can take a file-like object as well as a path, so you can use an in-memory buffer like a StringIO:  buf= StringIO.StringIO() im.save(buf, format= 'JPEG') jpeg= buf.getvalue()      ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  When you say \"I'd like to have number of such images stored in dictionary\", it's not clear if this is an in-memory structure or not.  You don't need to do any of this to meek an image in memory.  Just keep the image object in your dictionary.  If you're going to write your dictionary to a file, you might want to look at  im.tostring() method and the Image.fromstring() function  http://effbot.org/imagingbook/image.htm     im.tostring() => string      Returns a string containing pixel   data, using the standard \"raw\"   encoder.      Image.fromstring(mode, size, data) =>   image      Creates an image memory from pixel   data in a string, using the standard   \"raw\" decoder.   The \"format\" (.jpeg, .png, etc.) only matters on disk when you are exchanging the files.  If you're not exchanging files, format doesn't matter.     ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Python PIL: how to write PNG image to string","A_Content":"  With modern (as of mid-2017 Python 3.5 and Pillow 4.0):  StringIO no longer seems to work as it used to. The BytesIO class is the proper way to handle this. Pillow's save function expects a string as the first argument, and surprisingly doesn't see StringIO as such. The following is similar to older StringIO solutions, but with BytesIO in its place.  from io import BytesIO from PIL import Image  image = Image.open(\"a_file.png\") faux_file = BytesIO() image_data = faux_file.getvalue() image.save(faux_file, 'png')      ","Language":"Python","Tags":["python","python-imaging-library"],"URL":"https://stackoverflow.com/questions/646286/python-pil-how-to-write-png-image-to-string","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have generated an image using PIL. How can I save it to a string in memory? The Image.save() method requires a file.  I'd like to have several such images stored in dictionary.     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Python 2.X  dict((k, v) for k, v in metadata.iteritems() if v)     Python 3.X  {k: v for k, v in metadata.items() if v is not None}   Note that all of your keys have values.  It's just that some of those values are the empty string.  There's no such thing as a key in a dict without a value; if it didn't have a value, it wouldn't be in the dict.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"134","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  It can get even shorter than BrenBarn's solution (and more readable I think)  {k: v for k, v in metadata.items() if v}   Tested with Python 2.7.3.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"66","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  If you really need to modify the original dictionary:  empty_keys = [k for k,v in metadata.iteritems() if not v] for k in empty_keys:     del metadata[k]   Note that we have to make a list of the empty keys because we can't modify a dictionary while iterating through it (as you may have noticed). This is less expensive (memory-wise) than creating a brand-new dictionary, though, unless there are a lot of entries with empty values.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  If you want a full-featured, yet succinct approach to handling real-world data structures which are often nested, and can even contain cycles, I recommend looking at the remap utility from the boltons utility package.   After pip install boltons or copying iterutils.py into your project, just do:    from boltons.iterutils import remap  drop_falsey = lambda path, key, value: bool(value) clean = remap(metadata, visit=drop_falsey)   This page has many more examples, including ones working with much larger objects from Github's API.  It's pure-Python, so it works everywhere, and is fully tested in Python 2.7 and 3.3+. Best of all, I wrote it for exactly cases like this, so if you find a case it doesn't handle, you can bug me to fix it right here.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  BrenBarn's solution is ideal (and pythonic, I might add). Here is another (fp) solution, however:  from operator import itemgetter dict(filter(itemgetter(1), metadata.items()))      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Based on Ryan's solution, if you also have lists and nested dictionaries:  For Python 2:  def remove_empty_from_dict(d):     if type(d) is dict:         return dict((k, remove_empty_from_dict(v)) for k, v in d.iteritems() if v and remove_empty_from_dict(v))     elif type(d) is list:         return [remove_empty_from_dict(v) for v in d if v and remove_empty_from_dict(v)]     else:         return d   For Python 3:  def remove_empty_from_dict(d):     if type(d) is dict:         return dict((k, remove_empty_from_dict(v)) for k, v in d.items() if v and remove_empty_from_dict(v))     elif type(d) is list:         return [remove_empty_from_dict(v) for v in d if v and remove_empty_from_dict(v)]     else:         return d      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  If you have a nested dictionary, and you want this to work even for empty sub-elements, you can use a recursive variant of BrenBarn's suggestion:  def scrub_dict(d):     if type(d) is dict:         return dict((k, scrub_dict(v)) for k, v in d.iteritems() if v and scrub_dict(v))     else:         return d      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Quick Answer (TL;DR)  Example01  ### example01 -------------------  mydict  =   { \"alpha\":0,               \"bravo\":\"0\",               \"charlie\":\"three\",               \"delta\":[],               \"echo\":False,               \"foxy\":\"False\",               \"golf\":\"\",               \"hotel\":\"   \",                                     } newdict =   dict([(vkey, vdata) for vkey, vdata in mydict.iteritems() if(vdata) ]) print newdict  ### result01 ------------------- result01 =''' {'foxy': 'False', 'charlie': 'three', 'bravo': '0'} '''   Detailed Answer  Problem   Context:  Python 2.x Scenario: Developer wishes modify a dictionary to exclude blank values   aka remove empty values from a dictionary aka delete keys with blank values aka filter dictionary for non-blank values over each key-value pair    Solution   example01 use python list-comprehension syntax with simple conditional to remove \"empty\" values   Pitfalls   example01 only operates on a copy of the original dictionary (does not modify in place) example01 may produce unexpected results depending on what developer means by \"empty\"   Does developer mean to keep values that are falsy? If the values in the dictionary are not gauranteed to be strings, developer may have unexpected data loss. result01 shows that only three key-value pairs were preserved from the original set    Alternate example   example02 helps deal with potential pitfalls The approach is to use a more precise definition of \"empty\" by changing the conditional. Here we only want to filter out values that evaluate to blank strings. Here we also use .strip() to filter out values that consist of only whitespace.         Example02  ### example02 -------------------  mydict  =   { \"alpha\":0,               \"bravo\":\"0\",               \"charlie\":\"three\",               \"delta\":[],               \"echo\":False,               \"foxy\":\"False\",               \"golf\":\"\",               \"hotel\":\"   \",             } newdict =   dict([(vkey, vdata) for vkey, vdata in mydict.iteritems() if(str(vdata).strip()) ]) print newdict  ### result02 ------------------- result02 =''' {'charlie': 'three', 'echo': False,   'foxy': 'False', 'delta': [],   'bravo': '0', 'alpha': 0   } '''   See also   list-comprehension falsy checking for empty string modifying original dictionary in place dictionary comprehensions pitfalls of checking for empty string      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Building on the answers from patriciasz and nneonneo, and accounting for the possibility that you might want to delete keys that have only certain falsy things (e.g. '') but not others (e.g. 0), or perhaps you even want to include some truthy things (e.g. 'SPAM'), then you could make a highly specific hitlist:  unwanted = ['', u'', None, False, [], 'SPAM']   Unfortunately, this doesn't quite work, because for example 0 in unwanted evaluates to True. We need to discriminate between 0 and other falsy things, so we have to use is:  any([0 is i for i in unwanted])   ...evaluates to False.  Now use it to del the unwanted things:  unwanted_keys = [k for k, v in metadata.items() if any([v is i for i in unwanted])] for k in unwanted_keys: del metadata[k]   If you want a new dictionary, instead of modifying metadata in place:  newdict = {k: v for k, v in metadata.items() if not any([v is i for i in unwanted])}      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  For python 3  dict((k, v) for k, v in metadata.items() if v)      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  An alternative way you can do this, is using dictionary comprehension. This should be compatible with 2.7+  result = {     key: value for key, value in     {\"foo\": \"bar\", \"lorem\": None}.items()     if value }      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  I read all replies in this thread and some referred also to this thread: Remove empty dicts in nested dictionary with recursive function  I originally used solution here and it worked great:  Attempt 1: Too Hot (not performant or future-proof):  def scrub_dict(d):     if type(d) is dict:         return dict((k, scrub_dict(v)) for k, v in d.iteritems() if v and scrub_dict(v))     else:         return d   But some performance and compatibility concerns were raised in Python 2.7 world:   use isinstance instead of type unroll the list comp into for loop for efficiency use python3 safe items instead of iteritems   Attempt 2: Too Cold (Lacks Memoization):  def scrub_dict(d):     new_dict = {}     for k, v in d.items():         if isinstance(v,dict):             v = scrub_dict(v)         if not v in (u'', None, {}):             new_dict[k] = v     return new_dict   DOH! This is not recursive and not at all memoizant.  Attempt 3: Just Right (so far):  def scrub_dict(d):     new_dict = {}     for k, v in d.items():         if isinstance(v,dict):             v = scrub_dict(v)         if not v in (u'', None, {}):             new_dict[k] = v     return new_dict      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Here is an option if you are using pandas:  import pandas as pd  d = dict.fromkeys(['a', 'b', 'c', 'd']) d['b'] = 'not null' d['c'] = ''  # empty string  print(d)  # convert `dict` to `Series` and replace any blank strings with `None`; # use the `.dropna()` method and # then convert back to a `dict` d_ = pd.Series(d).replace('', None).dropna().to_dict()  print(d_)      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Efficient way to remove keys with empty strings from a dict","A_Content":"  Some benchmarking:  1. List comprehension recreate dict  In [7]: %%timeit dic = {str(i):i for i in xrange(10)}; dic['10'] = None; dic['5'] = None    ...: dic = {k: v for k, v in dic.items() if v is not None}     1000000 loops, best of 7: 375 ns per loop   2. List comprehension recreate dict using dict()  In [8]: %%timeit dic = {str(i):i for i in xrange(10)}; dic['10'] = None; dic['5'] = None    ...: dic = dict((k, v) for k, v in dic.items() if v is not None) 1000000 loops, best of 7: 681 ns per loop   3. Loop and delete key if v is None  In [10]: %%timeit dic = {str(i):i for i in xrange(10)}; dic['10'] = None; dic['5'] = None     ...: for k, v in dic.items():     ...:   if v is None:     ...:     del dic[k]     ...:  10000000 loops, best of 7: 160 ns per loop   so loop and delete is the fastest at 160ns, list comprehension is half as slow at ~375ns and with a call to dict() is half as slow again ~680ns.  Wrapping 3 into a function brings it back down again to about 275ns. Also for me PyPy was about twice as fast as neet python.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-strings-from-a-dict","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I have a dict and would like to remove all the keys for which there are empty value strings.  metadata = {u'Composite:PreviewImage': u'(Binary data 101973 bytes)',             u'EXIF:CFAPattern2': u''}   What is the best way to do this?     ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  Your code is almost right!  You are right, you are just missing one step.  When you read in the file, you are reading it as a string; but you want to turn the string back into a dictionary.  The error message you saw was because self.whip was a string, not a dictionary.  I first wrote that you could just feed the string into dict() but that doesn't work!  You need to do something else.  Example  Here is the simplest way: feed the string into eval().  Like so:  def reading(self):     s = open('deed.txt', 'r').read()     self.whip = eval(s)   You can do it in one line, but I think it looks messy this way:  def reading(self):     self.whip = eval(open('deed.txt', 'r').read())   But eval() is sometimes not recommended.  The problem is that eval() will evaluate any string, and if someone tricked you into running a really tricky string, something bad might happen.  In this case, you are just running eval() on your own file, so it should be okay.  But because eval() is useful, someone made an alternative to it that is safer.  This is called literal_eval and you get it from a Python module called ast.  import ast  def reading(self):     s = open('deed.txt', 'r').read()     self.whip = ast.literal_eval(s)   ast.literal_eval() will only evaluate strings that turn into the basic Python types, so there is no way that a tricky string can do something bad on your computer.  EDIT  Actually, best practice in Python is to use a with statement to make sure the file gets properly closed.  Rewriting the above to use a with statement:  import ast  def reading(self):     with open('deed.txt', 'r') as f:         s = f.read()         self.whip = ast.literal_eval(s)   In the most popular Python, known as \"CPython\", you usually don't need the with statement as the built-in \"garbage collection\" features will figure out that you are done with the file and will close it for you.  But other Python implementations, like \"Jython\" (Python for the Java VM) or \"PyPy\" (a really cool experimental system with just-in-time code optimization) might not figure out to close the file for you.  It's good to get in the habit of using with, and I think it makes the code pretty easy to understand.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"60","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  Have you tried the json module? JSON format is very similar to python dictionary. And it's human readable/writable:  >>> import json >>> d = {\"one\":1, \"two\":2} >>> json.dump(d, open(\"text.txt\",'w'))   This code dumps to a text file  $ cat text.txt  {\"two\": 2, \"one\": 1}   Also you can load from a JSON file:  >>> d2 = json.load(open(\"text.txt\")) >>> print d2 {u'two': 2, u'one': 1}      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"135","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  To store Python objects in files, use the pickle module:  import pickle  a = {   'a': 1,   'b': 2 }  with open('file.txt', 'wb') as handle:   pickle.dump(a, handle)  with open('file.txt', 'rb') as handle:   b = pickle.loads(handle.read())  print a == b # True   Notice that I never set b = a, but instead pickled a to a file and then unpickled it into b.  As for your error:  self.whip = open('deed.txt', 'r').read()   self.whip was a dictionary object. deed.txt contains text, so when you load the contents of deed.txt into self.whip, self.whip becomes the string representation of itself.  You'd probably want to evaluate the string back into a Python object:  self.whip = eval(open('deed.txt', 'r').read())   Notice how eval sounds like evil. That's intentional. Use the pickle module instead.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  I created my own functions which work really nicely:  def writeDict(dict, filename, sep):     with open(filename, \"a\") as f:         for i in dict.keys():                         f.write(i + \" \" + sep.join([str(x) for x in dict[i]]) + \"\\n\")   It will store the keyname first, followed by all values. Note that in this case my dict contains integers so that's why it converts to int. This is most likely the part you need to change for your situation.  def readDict(filename, sep):     with open(filename, \"r\") as f:         dict = {}         for line in f:             values = line.split(sep)             dict[values[0]] = {int(x) for x in values[1:len(values)]}         return(dict)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  You can iterate through the key-value pair and write it into file  pair = {'name': name,'location': location} with open('F:\\\\twitter.json', 'a') as f:      f.writelines('{}:{}'.format(k,v) for k, v in pair.items())      f.write('\\n')      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"Writing a dict to txt file and reading it back?","A_Content":"  Hi there is a way to write and read the dictionary to file you can turn your dictionary to JSON format and read and write quickly just do this :  to write your date:   import json   your_dictionary = {\"some_date\" : \"date\"}  f = open('destFile.txt', 'w+')  f.write(json.dumps(yout_dictionary))   and to read your data:   import json   f = open('destFile.txt', 'r')  your_dictionary = json.loads(f.read())      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/11026959/writing-a-dict-to-txt-file-and-reading-it-back","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to write a dictionary to a txt file. Then read the dict values by typing the keys with raw_input. I feel like I am just missing one step but I have been looking for a while now.  I get this error  File \"name.py\", line 24, in reading     print whip[name] TypeError: string indices must be integers, not str   My code:  #!/usr/bin/env python from sys import exit  class Person(object):     def __init__(self):         self.name = \"\"         self.address = \"\"         self.phone = \"\"         self.age = \"\"         self.whip = {}      def writing(self):         self.whip[p.name] = p.age, p.address, p.phone         target = open('deed.txt', 'a')         target.write(str(self.whip))         print self.whip      def reading(self):         self.whip = open('deed.txt', 'r').read()         name = raw_input(\"> \")         if name in self.whip:             print self.whip[name]  p = Person()  while True:     print \"Type:\\n\\t*read to read data base\\n\\t*write to write to data base\\n\\t*exit to exit\"     action = raw_input(\"\\n> \")     if \"write\" in action:         p.name = raw_input(\"Name?\\n> \")         p.phone = raw_input(\"Phone Number?\\n> \")         p.age = raw_input(\"Age?\\n> \")         p.address = raw_input(\"Address?\\n>\")         p.writing()     elif \"read\" in action:         p.reading()     elif \"exit\" in action:         exit(0)      ","Q_Votes":"80"},{"Q_Title":"How do I send a POST request as a JSON?","A_Content":"  If your server is expecting the POST request to be json, then you would need to add a header, and also serialize the data for your request...  Python 2.x  import json import urllib2  data = {         'ids': [12, 3, 4, 5, 6] }  req = urllib2.Request('http://example.com/api/posts/create') req.add_header('Content-Type', 'application/json')  response = urllib2.urlopen(req, json.dumps(data))   Python 3.x  https://stackoverflow.com/a/26876308/496445    If you don't specify the header, it will be the default application/x-www-form-urlencoded type.     ","Language":"Python","Tags":["python","json","http","url","post"],"URL":"https://stackoverflow.com/questions/9746303/how-do-i-send-a-post-request-as-a-json","A_Votes":"130","_type":"dict","isAccepted":"Yes","Q_Content":"    data = {         'ids': [12, 3, 4, 5, 6 , ...]     }     urllib2.urlopen(\"http://abc.com/api/posts/create\",urllib.urlencode(data))   I want to send a POST request, but one of the fields should be a list of numbers. How can I do that ? (JSON?)     ","Q_Votes":"80"},{"Q_Title":"How do I send a POST request as a JSON?","A_Content":"  I recommend using the incredible requests module.  http://docs.python-requests.org/en/v0.10.7/user/quickstart/#custom-headers  url = 'https://api.github.com/some/endpoint' payload = {'some': 'data'} headers = {'content-type': 'application/json'}  response = requests.post(url, data=json.dumps(payload), headers=headers)      ","Language":"Python","Tags":["python","json","http","url","post"],"URL":"https://stackoverflow.com/questions/9746303/how-do-i-send-a-post-request-as-a-json","A_Votes":"93","_type":"dict","isAccepted":"No","Q_Content":"    data = {         'ids': [12, 3, 4, 5, 6 , ...]     }     urllib2.urlopen(\"http://abc.com/api/posts/create\",urllib.urlencode(data))   I want to send a POST request, but one of the fields should be a list of numbers. How can I do that ? (JSON?)     ","Q_Votes":"80"},{"Q_Title":"How do I send a POST request as a JSON?","A_Content":"  for python 3.4.2 I found the following will work:  import urllib.request import json        body = {'ids': [12, 14, 50]}    myurl = \"http://www.testmycode.com\" req = urllib.request.Request(myurl) req.add_header('Content-Type', 'application/json; charset=utf-8') jsondata = json.dumps(body) jsondataasbytes = jsondata.encode('utf-8')   # needs to be bytes req.add_header('Content-Length', len(jsondataasbytes)) print (jsondataasbytes) response = urllib.request.urlopen(req, jsondataasbytes)      ","Language":"Python","Tags":["python","json","http","url","post"],"URL":"https://stackoverflow.com/questions/9746303/how-do-i-send-a-post-request-as-a-json","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    data = {         'ids': [12, 3, 4, 5, 6 , ...]     }     urllib2.urlopen(\"http://abc.com/api/posts/create\",urllib.urlencode(data))   I want to send a POST request, but one of the fields should be a list of numbers. How can I do that ? (JSON?)     ","Q_Votes":"80"},{"Q_Title":"How do I send a POST request as a JSON?","A_Content":"  You have to add header,or you will get http 400 error. The code works well on python2.6,centos5.4  code:      import urllib2,json      url = 'http://www.google.com/someservice'     postdata = {'key':'value'}      req = urllib2.Request(url)     req.add_header('Content-Type','application/json')     data = json.dumps(postdata)      response = urllib2.urlopen(req,data)      ","Language":"Python","Tags":["python","json","http","url","post"],"URL":"https://stackoverflow.com/questions/9746303/how-do-i-send-a-post-request-as-a-json","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    data = {         'ids': [12, 3, 4, 5, 6 , ...]     }     urllib2.urlopen(\"http://abc.com/api/posts/create\",urllib.urlencode(data))   I want to send a POST request, but one of the fields should be a list of numbers. How can I do that ? (JSON?)     ","Q_Votes":"80"},{"Q_Title":"How do I send a POST request as a JSON?","A_Content":"  This works perfect for Python 3.5, if the URL contains Query String / Parameter value,  Request URL = https://bah2.com/ws/rest/v1/concept/ Parameter value = 21f6bb43-98a1-419d-8f0c-8133669e40ca  import requests  url = 'https://bahbah2.com/ws/rest/v1/concept/21f6bb43-98a1-419d-8f0c-8133669e40ca' data = {\"name\": \"Value\"} r = requests.post(url, auth=('username', 'password'), verify=False, json=data) print(r.status_code)      ","Language":"Python","Tags":["python","json","http","url","post"],"URL":"https://stackoverflow.com/questions/9746303/how-do-i-send-a-post-request-as-a-json","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    data = {         'ids': [12, 3, 4, 5, 6 , ...]     }     urllib2.urlopen(\"http://abc.com/api/posts/create\",urllib.urlencode(data))   I want to send a POST request, but one of the fields should be a list of numbers. How can I do that ? (JSON?)     ","Q_Votes":"80"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  Sending signal 0 to a pid will raise an OSError exception if the pid is not running, and do nothing otherwise.  import os  def check_pid(pid):             \"\"\" Check For the existence of a unix pid. \"\"\"     try:         os.kill(pid, 0)     except OSError:         return False     else:         return True      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"126","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  mluebke code is not 100% correct; kill() can also raise EPERM (access denied) in which case that obviously means a process exists. This is supposed to work:  (edited as per Jason R. Coombs comments)  import errno import os import sys  def pid_exists(pid):     \"\"\"Check whether pid exists in the current process table.     UNIX only.     \"\"\"     if pid < 0:         return False     if pid == 0:         # According to \"man 2 kill\" PID 0 refers to every process         # in the process group of the calling process.         # On certain systems 0 is a valid PID but we have no way         # to know that in a portable fashion.         raise ValueError('invalid PID 0')     try:         os.kill(pid, 0)     except OSError as err:         if err.errno == errno.ESRCH:             # ESRCH == No such process             return False         elif err.errno == errno.EPERM:             # EPERM clearly means there's a process to deny access to             return True         else:             # According to \"man 2 kill\" possible error values are             # (EINVAL, EPERM, ESRCH)             raise     else:         return True   You can't do this on Windows unless you use pywin32, ctypes or a C extension module. If you're OK with depending from an external lib you can use psutil:  >>> import psutil >>> psutil.pid_exists(2353) True      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"51","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  Have a look at the psutil module:      psutil (python system and process utilities) is a cross-platform library for retrieving information on running processes and system utilization (CPU, memory, disks, network) in Python. [...] It currently supports Linux, Windows, OSX, FreeBSD and Sun Solaris, both 32-bit and 64-bit architectures, with Python versions from 2.6 to 3.4 (users of Python 2.4 and 2.5 may use 2.1.3 version). PyPy is also known to work.   It has a function called pid_exists() that you can use to check whether a process with the given pid exists.  Here's an example:  import psutil pid = 12345 if psutil.pid_exists(pid):     print \"a process with pid %d exists\" % pid else:     print \"a process with pid %d does not exist\" % pid   For reference:   https://pypi.python.org/pypi/psutil https://github.com/giampaolo/psutil http://pythonhosted.org/psutil/#psutil.pid_exists      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"46","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  The answers involving sending 'signal 0' to the process will work only if the process in question is owned by the user running the test. Otherwise you will get an OSError due to permissions, even if the pid exists in the system.  In order to bypass this limitation you can check if /proc/<pid> exists:  import os  def is_running(pid):     if os.path.isdir('/proc/{}'.format(pid)):         return True     return False      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  Look here for windows-specific way of getting full list of running processes with their IDs.  It would be something like  from win32com.client import GetObject def get_proclist():     WMI = GetObject('winmgmts:')     processes = WMI.InstancesOf('Win32_Process')     return [process.Properties_('ProcessID').Value for process in processes]   You can then verify pid you get against this list.  I have no idea about performance cost, so you'd better check this if you're going to do pid verification often.  For *NIx, just use mluebke's solution.     ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  In Python 3.3+, you could use exception names instead of errno constants. Posix version:  import os  def pid_exists(pid):      if pid < 0: return False #NOTE: pid == 0 returns True     try:         os.kill(pid, 0)      except ProcessLookupError: # errno.ESRCH         return False # No such process     except PermissionError: # errno.EPERM         return True # Operation not permitted (i.e., process exists)     else:         return True # no error, we can send a signal to the process      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  Building upon ntrrgc's I've beefed up the windows version so it checks the process exit code and checks for permissions:  def pid_exists(pid):     \"\"\"Check whether pid exists in the current process table.\"\"\"     if os.name == 'posix':         import errno         if pid < 0:             return False         try:             os.kill(pid, 0)         except OSError as e:             return e.errno == errno.EPERM         else:             return True     else:         import ctypes         kernel32 = ctypes.windll.kernel32         HANDLE = ctypes.c_void_p         DWORD = ctypes.c_ulong         LPDWORD = ctypes.POINTER(DWORD)         class ExitCodeProcess(ctypes.Structure):             _fields_ = [ ('hProcess', HANDLE),                 ('lpExitCode', LPDWORD)]          SYNCHRONIZE = 0x100000         process = kernel32.OpenProcess(SYNCHRONIZE, 0, pid)         if not process:             return False          ec = ExitCodeProcess()         out = kernel32.GetExitCodeProcess(process, ctypes.byref(ec))         if not out:             err = kernel32.GetLastError()             if kernel32.GetLastError() == 5:                 # Access is denied.                 logging.warning(\"Access is denied to get pid info.\")             kernel32.CloseHandle(process)             return False         elif bool(ec.lpExitCode):             # print ec.lpExitCode.contents             # There is an exist code, it quit             kernel32.CloseHandle(process)             return False         # No exit code, it's running.         kernel32.CloseHandle(process)         return True      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  Combining Giampaolo Rodol's answer for POSIX and mine for Windows I got this:  import os if os.name == 'posix':     def pid_exists(pid):         \"\"\"Check whether pid exists in the current process table.\"\"\"         import errno         if pid < 0:             return False         try:             os.kill(pid, 0)         except OSError as e:             return e.errno == errno.EPERM         else:             return True else:     def pid_exists(pid):         import ctypes         kernel32 = ctypes.windll.kernel32         SYNCHRONIZE = 0x100000          process = kernel32.OpenProcess(SYNCHRONIZE, 0, pid)         if process != 0:             kernel32.CloseHandle(process)             return True         else:             return False      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  In Windows, you can do it in this way:  import ctypes PROCESS_QUERY_INFROMATION = 0x1000 def checkPid(pid):     processHandle = ctypes.windll.kernel32.OpenProcess(PROCESS_QUERY_INFROMATION, 0,pid)     if processHandle == 0:         return False     else:         ctypes.windll.kernel32.CloseHandle(processHandle)     return True   First of all, in this code you try to get a handle for process with pid given. If the handle is valid, then close the handle for process and return True; otherwise, you return False. Documentation for OpenProcess: https://msdn.microsoft.com/en-us/library/windows/desktop/ms684320%28v=vs.85%29.aspx     ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  This will work for Linux, for example if you want to check if banshee is running... (banshee is a music player)  import subprocess  def running_process(process):     \"check if process is running. < process > is the name of the process.\"      proc = subprocess.Popen([\"if pgrep \" + process + \" >/dev/null 2>&1; then echo 'True'; else echo 'False'; fi\"], stdout=subprocess.PIPE, shell=True)      (Process_Existance, err) = proc.communicate()     return Process_Existance  # use the function print running_process(\"banshee\")      ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to check if there exists a process with a given pid in Python?","A_Content":"  I'd say use the PID for whatever purpose you're obtaining it and handle the errors gracefully. Otherwise, it's a classic race (the PID may be valid when you check it's valid, but go away an instant later)     ","Language":"Python","Tags":["python","process","pid"],"URL":"https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine.   I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  @Eric S.  Eric S.'s answer is excellent, but I learned by experimentation that this will always cause messages logged at the new debug level to be printed -- regardless of what the log level is set to. So if you make a new level number of 9, if you call setLevel(50), the lower level messages will erroneously be printed. To prevent that from happening, you need another line inside the \"debugv\" function to check if the logging level in question is actually enabled.  Fixed example that checks if the logging level is enabled:  import logging DEBUG_LEVELV_NUM = 9  logging.addLevelName(DEBUG_LEVELV_NUM, \"DEBUGV\") def debugv(self, message, *args, **kws):     # Yes, logger takes its '*args' as 'args'.     if self.isEnabledFor(DEBUG_LEVELV_NUM):         self._log(DEBUG_LEVELV_NUM, message, args, **kws)  logging.Logger.debugv = debugv   If you look at the code for class Logger in logging.__init__.py for Python 2.7, this is what all the standard log functions do (.critical, .debug, etc.).  I apparently can't post replies to others' answers for lack of reputation... hopefully Eric will update his post if he sees this. =)     ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"126","_type":"dict","isAccepted":"Yes","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  I took the \"avoid seeing lambda\" answer and had to modify where the log_at_my_log_level was being added.  I too saw the problem that Paul did \"I don't think this works. Don't you need logger as the first arg in log_at_my_log_level?\"  This worked for me  import logging DEBUG_LEVELV_NUM = 9  logging.addLevelName(DEBUG_LEVELV_NUM, \"DEBUGV\") def debugv(self, message, *args, **kws):     # Yes, logger takes its '*args' as 'args'.     self._log(DEBUG_LEVELV_NUM, message, args, **kws)  logging.Logger.debugv = debugv      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  This question is rather old, but I just dealt with the same topic and found a way similiar to those already mentioned which appears a little cleaner to me. This was tested on 3.4, so I'm not sure whether the methods used exist in older versions:  from logging import getLoggerClass, addLevelName, setLoggerClass, NOTSET  VERBOSE = 5  class MyLogger(getLoggerClass()):     def __init__(self, name, level=NOTSET):         super().__init__(name, level)          addLevelName(VERBOSE, \"VERBOSE\")      def verbose(self, msg, *args, **kwargs):         if self.isEnabledFor(VERBOSE):             self._log(VERBOSE, msg, args, **kwargs)  setLoggerClass(MyLogger)      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  Combining all of the existing answers with a bunch of usage experience, I think that I have come up with a list of all the things that need to be done to ensure completely seamless usage of the new level. The steps below assume that you are adding a new level TRACE with value logging.DEBUG - 5 == 5:   logging.addLevelName(logging.DEBUG - 5, 'TRACE') needs to be invoked to get the new level registered internally so that it can be referenced by name. The new level needs to be added as an attribute to logging itself for consistency: logging.TRACE = logging.DEBUG - 5. A method called trace needs to be added to the logging module. It should behave just like debug, info, etc. A method called trace needs to be added to the currently configured logger class. Since this is not 100% guaranteed to be logging.Logger, use logging.getLoggerClass() instead.   All the steps are illustrated in the method below:  def addLoggingLevel(levelName, levelNum, methodName=None):     \"\"\"     Comprehensively adds a new logging level to the `logging` module and the     currently configured logging class.      `levelName` becomes an attribute of the `logging` module with the value     `levelNum`. `methodName` becomes a convenience method for both `logging`     itself and the class returned by `logging.getLoggerClass()` (usually just     `logging.Logger`). If `methodName` is not specified, `levelName.lower()` is     used.      To avoid accidental clobberings of existing attributes, this method will     raise an `AttributeError` if the level name is already an attribute of the     `logging` module or if the method name is already present       Example     -------     >>> addLoggingLevel('TRACE', logging.DEBUG - 5)     >>> logging.getLogger(__name__).setLevel(\"TRACE\")     >>> logging.getLogger(__name__).trace('that worked')     >>> logging.trace('so did this')     >>> logging.TRACE     5      \"\"\"     if not methodName:         methodName = levelName.lower()      if hasattr(logging, levelName):        raise AttributeError('{} already defined in logging module'.format(levelName))     if hasattr(logging, methodName):        raise AttributeError('{} already defined in logging module'.format(methodName))     if hasattr(logging.getLoggerClass(), methodName):        raise AttributeError('{} already defined in logger class'.format(methodName))      # This method was inspired by the answers to Stack Overflow post     # http://stackoverflow.com/q/2183233/2988730, especially     # http://stackoverflow.com/a/13638084/2988730     def logForLevel(self, message, *args, **kwargs):         if self.isEnabledFor(levelNum):             self._log(levelNum, message, args, **kwargs)     def logToRoot(message, *args, **kwargs):         logging.log(levelNum, message, *args, **kwargs)      logging.addLevelName(levelNum, levelName)     setattr(logging, levelName, levelNum)     setattr(logging.getLoggerClass(), methodName, logForLevel)     setattr(logging, methodName, logToRoot)      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  Who started the bad practice of using internal methods (self._log) and why is each answer based on that?! The pythonic solution would be to use self.log instead so you don't have to mess with any internal stuff:  import logging  SUBDEBUG = 5 logging.addLevelName(SUBDEBUG, 'SUBDEBUG')  def subdebug(self, message, *args, **kws):     self.log(SUBDEBUG, message, *args, **kws)  logging.Logger.subdebug = subdebug  logging.basicConfig() l = logging.getLogger() l.setLevel(SUBDEBUG) l.subdebug('test') l.setLevel(logging.DEBUG) l.subdebug('test')      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  I find it easier to create a new attribute for the logger object that passes the log() function. I think the logger module provides the addLevelName() and the log() for this very reason. Thus no subclasses or new method needed.   import logging  @property def log(obj):     logging.addLevelName(5, 'TRACE')     myLogger = logging.getLogger(obj.__class__.__name__)     setattr(myLogger, 'trace', lambda *args: myLogger.log(5, *args))     return myLogger   now  mylogger.trace('This is a trace message')   should work as expected.     ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  I think you'll have to subclass the Logger class and add a method called trace which basically calls Logger.log with a level lower than DEBUG. I haven't tried this but this is what the docs indicate.      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  Tips for creating a custom logger:   Do not use _log, use log (you don't have to check isEnabledFor) the logging module should be the one creating instance of the custom logger since it does some magic in getLogger, so you will need to set the class via setLoggerClass You do not need to define __init__ for the logger, class if you are not storing anything   # Lower than debug which is 10 TRACE = 5 class MyLogger(logging.Logger):     def trace(self, msg, *args, **kwargs):         self.log(TRACE, msg, *args, **kwargs)     When calling this logger use setLoggerClass(MyLogger) to make this the default logger from getLogger    logging.setLoggerClass(MyLogger) log = logging.getLogger(__name__) # ... log.trace(\"something specific\")   You will need to setFormatter, setHandler, and setLevel(TRACE) on the handler and on the log itself to actually se this low level trace     ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  In my experience, this is the full solution the the op's problem... to avoid seeing \"lambda\" as the function in which the message is emitted, go deeper:  MY_LEVEL_NUM = 25 logging.addLevelName(MY_LEVEL_NUM, \"MY_LEVEL_NAME\") def log_at_my_log_level(self, message, *args, **kws):     # Yes, logger takes its '*args' as 'args'.     self._log(MY_LEVEL_NUM, message, args, **kws) logger.log_at_my_log_level = log_at_my_log_level   I've never tried working with a standalone logger class, but I think the basic idea is the same (use _log).     ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  This worked for me:  import logging logging.basicConfig(     format='  %(levelname)-8.8s %(funcName)s: %(message)s', ) logging.NOTE = 32  # positive yet important logging.addLevelName(logging.NOTE, 'NOTE')      # new level logging.addLevelName(logging.CRITICAL, 'FATAL') # rename existing  log = logging.getLogger(__name__) log.note = lambda msg, *args: log._log(logging.NOTE, msg, args) log.note('school\\'s out for summer! %s', 'dude') log.fatal('file not found.')   The lambda/funcName issue is fixed with logger._log as @marqueed pointed out.  I think using lambda looks a bit cleaner, but the drawback is that it can't take keyword arguments.  I've never used that myself, so no biggie.     NOTE     setup: school's out for summer! dude   FATAL    setup: file not found.      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  Addition to Mad Physicists example to get file name and line number correct:  def logToRoot(message, *args, **kwargs):     if logging.root.isEnabledFor(levelNum):         logging.root._log(levelNum, message, args, **kwargs)      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  As alternative to adding an extra method to the Logger class I would recommend using the Logger.log(level, msg) method.  import logging  TRACE = 5 logging.addLevelName(TRACE, 'TRACE') FORMAT = '%(levelname)s:%(name)s:%(lineno)d:%(message)s'   logging.basicConfig(format=FORMAT) l = logging.getLogger() l.setLevel(TRACE) l.log(TRACE, 'trace message') l.setLevel(logging.DEBUG) l.log(TRACE, 'disabled trace message')      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  I'm confused; with python 3.5, at least, it just works:  import logging   TRACE = 5 \"\"\"more detail than debug\"\"\"  logging.basicConfig() logging.addLevelName(TRACE,\"TRACE\") logger = logging.getLogger('') logger.debug(\"n\") logger.setLevel(logging.DEBUG) logger.debug(\"y1\") logger.log(TRACE,\"n\") logger.setLevel(TRACE) logger.log(TRACE,\"y2\")   output:     DEBUG:root:y1       TRACE:root:y2      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"How to add a custom loglevel to Python's logging facility","A_Content":"  In case anyone wants an automated way to add a new logging level to the logging module (or a copy of it) dynamically, I have created this function, expanding @pfa's answer:  def add_level(log_name,custom_log_module=None,log_num=None,                 log_call=None,                    lower_than=None, higher_than=None, same_as=None,               verbose=True):     '''     Function to dynamically add a new log level to a given custom logging module.     <custom_log_module>: the logging module. If not provided, then a copy of         <logging> module is used     <log_name>: the logging level name     <log_num>: the logging level num. If not provided, then function checks         <lower_than>,<higher_than> and <same_as>, at the order mentioned.         One of those three parameters must hold a string of an already existent         logging level name.     In case a level is overwritten and <verbose> is True, then a message in WARNING         level of the custom logging module is established.     '''     if custom_log_module is None:         import imp         custom_log_module = imp.load_module('custom_log_module',                                             *imp.find_module('logging'))     log_name = log_name.upper()     def cust_log(par, message, *args, **kws):         # Yes, logger takes its '*args' as 'args'.         if par.isEnabledFor(log_num):             par._log(log_num, message, args, **kws)     available_level_nums = [key for key in custom_log_module._levelNames                             if isinstance(key,int)]      available_levels = {key:custom_log_module._levelNames[key]                              for key in custom_log_module._levelNames                             if isinstance(key,str)}     if log_num is None:         try:             if lower_than is not None:                 log_num = available_levels[lower_than]-1             elif higher_than is not None:                 log_num = available_levels[higher_than]+1             elif same_as is not None:                 log_num = available_levels[higher_than]             else:                 raise Exception('Infomation about the '+                                 'log_num should be provided')         except KeyError:             raise Exception('Non existent logging level name')     if log_num in available_level_nums and verbose:         custom_log_module.warn('Changing ' +                                   custom_log_module._levelNames[log_num] +                                   ' to '+log_name)     custom_log_module.addLevelName(log_num, log_name)      if log_call is None:         log_call = log_name.lower()     exec('custom_log_module.Logger.'+eval('log_call')+' = cust_log', None, locals())     return custom_log_module      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?  I've a mylogger.py with the following content:  import logging  @property def log(obj):     myLogger = logging.getLogger(obj.__class__.__name__)     return myLogger   In my code I use it in the following way:  class ExampleClass(object):     from mylogger import log      def __init__(self):         '''The constructor with the logger'''         self.log.debug(\"Init runs\")   Now I'd like to call self.log.trace(\"foo bar\")  Thanks in advance for your help.  Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  Instead of symlinking to a specific version of freetype2, do this:  ln -s /usr/local/include/freetype2 /usr/local/include/freetype   This saves you the trouble of recreating the symlink whenever you upgrade freetype2.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"210","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  With macports, the solution that worked for me:  sudo port install freetype sudo ln -s /opt/local/include/freetype2 /opt/local/include/freetype   And then re-run the PIL build process.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  I've solved this problem with this symlink:  ln -s /usr/local/Cellar/freetype/2.5.1/include/freetype2 /usr/local/include/freetype   I have freetype already installed via homebrew too.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  This is caused by a change in the headers of freetype >= 2.1.5. PIL is not using the correct documented way to include the freetype headers, which causes the build to fail now that freetype finally removed the long-deprecated way of including the headers. This problem is documented right at the top of http://freetype.sourceforge.net/freetype2/docs/tutorial/step1.html:     NOTE: Starting with FreeType 2.1.6, the old header file inclusion scheme is no longer supported. This means that you now get an error if you do something like the following:      #include <freetype/freetype.h>   #include <freetype/ftglyph.h>   Please take this problem upstream to the developers of PIL and advise them to use the documented way of including freetype headers:  #include <ft2build.h> #include FT_ERRORS_H     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  After many attempts, I solved this problem compiling the PIL without freetype support. To do that, I simply unlinked from my $PATH using brew unlink freetype and then, pip install PIL==1.1.7.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  I just solved this using the steps described in this Stackoverflow answer. Seems this is Xcode's fault for installing freetype in strange locations.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  Use Pillow where this issue is fixed \"for real\":   https://github.com/python-pillow/Pillow/commit/c6040f618d8f2706a7b46d1cdf37d1a587f9701f   And where you can report issues and see them addressed in a timely fashion:   https://github.com/python-pillow/Pillow/issues      ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  In my OSx, I found the .h file in /opt/local/include/freetype2 direcoty. So, I type  sudo ln -s /opt/local/include/freetype2/ /usr/local/include/freetype   it works  Maybe the best way is to add /opt/local/include to your clang's include path.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  osx yosemite, this worked for me:   (virtualenv)  $ ln -s /opt/local/include/freetype2/ /usr/local/include/freetype2 $ pip install pil==1.1.7 --allow-external pil --allow-unverified pil      ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  I'm using Arch Linux and had this issue.  In my case had to manually download and unpack the zip file from https://pypi.python.org/pypi/Pillow/2.2.1#downloads .  I then edited the file _imagingft.c to change the include path from freetype/fterrors.h to fterrors.h as there was no freetype subdirectory of /usr/include/freetype2 where fterrors.h was located.  Finally python setup.py install worked fine.  Edit:  I should mention this was the solution for installing Pillow, not PIL, but Pillow is just a fork of PIL and it may still be applicable to others with this issue.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"Error installing Python Image Library using pip on Mac OS X 10.9","A_Content":"  If you're still looking for answers like I was after reading this and other googling, you may be interested to see this:  Warning  Pillow >= 2.1.0 no longer supports import _imaging. Please use from PIL.Image import core as _imaging instead.  from here  By the time you read this, the page will probably have changed, but the text will be still here at least.     ","Language":"Python","Tags":["python","macos","pip"],"URL":"https://stackoverflow.com/questions/20325473/error-installing-python-image-library-using-pip-on-mac-os-x-10-9","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to install PIL on Mavericks using pip but get this error.  _imagingft.c:73:10: fatal error: 'freetype/fterrors.h' file not found #include <freetype/fterrors.h>          ^ 1 error generated. error: command 'cc' failed with exit status 1   My Command Line Tools are installed and up to date and every hint I found didn't help. How can I get this to compile?  EDIT: I just checked, freetype is also already installed via homebrew     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  Have you tried with sudo?  sudo pip install -r requirements.txt   (Edited regarding comments)  or safer options:  a) Create a virtualenv, activate it and install :  virtualenv env source env/bin/activate pip install -r requirements.tx   b) Install user-wise  pip install --user -r requirements.txt   My recommendation use safe (a) option.     ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"34","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  We should really stop advising the use of sudo with pip install. It's better to first try pip install --user. If this fails then take a look at the top post here.  The reason you shouldn't use sudo is as follows:  When you run pip with sudo, you are running arbitrary Python code from the Internet as a root user, which is quite a big security risk. If someone puts up a malicious project on PyPI and you install it, you give an attacker root access to your machine.     ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"266","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  You are trying to install a package on the system-wide path without having the permission to do so.   In general, you can use sudo to temporarily obtain superuser  permissions at your responsibility in order to install the package on the system-wide path:  sudo pip install -r requirements.txt   Find more about sudo here. If you don't want to make system-wide changes, you can install the package on your per-user path using the --user flag.  All it takes is:  pip install --user runloop requirements.txt  Finally, for even finer grained control, you can also use a virtualenv, which might be the superior solution for a development environment, especially if you are working on multiple projects and want to keep track of each one's dependencies.  After activating your virtualenv with  $ my-virtualenv/bin/activate  the following command will install the package inside the virtualenv (and not on the system-wide path):  pip install -r requirements.txt      ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  Just clarifying what worked for me after much pain in linux (ubuntu based) on permission denied errors, and leveraging from Bert's answer above, I now use ...  $ pip install --user <package-name>   or if running pip on a requirements file ...  $ pip install --user -r requirements.txt   and these work reliably for every pip install including creating virtual environments.  However, the cleanest solution in my further experience has been to install python-virtualenv and virtualenvwrapper with sudo apt-get install at the system level.   Then, inside virtual environments, use pip install without the --user flag AND without sudo. Much cleaner, safer, and easier overall.     ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  User doesn't have write permission for some Python installation paths. You can give the permission by:  sudo chown -R $USER /absolute/path/to/directory   So you should give permission, then try to install it again, if you have new paths you should also give permission:  sudo chown -R $USER /usr/local/lib/python2.7/      ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  In my case I found .local directory with path to pip in parallel to pip3 in /usr/lcoal/bin. After deleting the .local directory all was set fine.     ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"pip install -r: OSError: [Errno 13] Permission denied","A_Content":"  Only this command worked for me in case someone needs:  sudo -H /usr/local/bin/pip install --upgrade boto3      ","Language":"Python","Tags":["python","django","pip"],"URL":"https://stackoverflow.com/questions/31512422/pip-install-r-oserror-errno-13-permission-denied","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to setup Django.   When I run pip install -r requirements.txt, I get the following exception:  Installing collected packages: amqp, anyjson, arrow, beautifulsoup4, billiard, boto, braintree, celery, cffi, cryptography, Django, django-bower, django-braces, django-celery, django-crispy-forms, django-debug-toolbar, django-disqus, django-embed-video, django-filter, django-merchant, django-pagination, django-payments, django-storages, django-vote, django-wysiwyg-redactor, easy-thumbnails, enum34, gnureadline, idna, ipaddress, ipython, kombu, mock, names, ndg-httpsclient, Pillow, pyasn1, pycparser, pycrypto, PyJWT, pyOpenSSL, python-dateutil, pytz, requests, six, sqlparse, stripe, suds-jurko Cleaning up... Exception: Traceback (most recent call last):   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main     status = self.run(options, args)   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 283, in run     requirement_set.install(install_options, global_options, root=options.root_path)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1436, in install     requirement.install(install_options, global_options, *args, **kwargs)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 672, in install     self.move_wheel_files(self.source_dir, root=root)   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 902, in move_wheel_files     pycompile=self.pycompile,   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 206, in move_wheel_files     clobber(source, lib_dir, True)   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 193, in clobber     os.makedirs(destsubdir)   File \"/usr/lib/python2.7/os.py\", line 157, in makedirs     mkdir(name, mode) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/amqp-1.4.6.dist-info'   What's wrong and how do I fix this?     ","Q_Votes":"78"},{"Q_Title":"Python PDF library [closed]","A_Content":"  The two that come to mind are:   pyPdf2 PDFMiner      ","Language":"Python","Tags":["python","pdf","pdf-generation"],"URL":"https://stackoverflow.com/questions/6413441/python-pdf-library","A_Votes":"30","_type":"dict","isAccepted":"Yes","Q_Content":"    What Python PDF libraries are there?  I need to make some PDF with many grids, and I'm looking for a library that allows to manage pages (multi-page). The library should calculate when the page is ended and then create the next page.     ","Q_Votes":"79"},{"Q_Title":"Python PDF library [closed]","A_Content":"  Reportlab. There is an open source version, and a paid version which adds the Report Markup Language (an alternative method of defining your document).     ","Language":"Python","Tags":["python","pdf","pdf-generation"],"URL":"https://stackoverflow.com/questions/6413441/python-pdf-library","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    What Python PDF libraries are there?  I need to make some PDF with many grids, and I'm looking for a library that allows to manage pages (multi-page). The library should calculate when the page is ended and then create the next page.     ","Q_Votes":"79"},{"Q_Title":"Python PDF library [closed]","A_Content":"  I already have used Reportlab in one project.     ","Language":"Python","Tags":["python","pdf","pdf-generation"],"URL":"https://stackoverflow.com/questions/6413441/python-pdf-library","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What Python PDF libraries are there?  I need to make some PDF with many grids, and I'm looking for a library that allows to manage pages (multi-page). The library should calculate when the page is ended and then create the next page.     ","Q_Votes":"79"},{"Q_Title":"Python PDF library [closed]","A_Content":"  There is also http://appyframework.org/pod.html which takes a LibreOffice or OpenOffice document as template and can generate pdf, rtf, odt ... To generate pdf it requires a headless OOo on some server. Documentation is concise but relatively complete.  http://appyframework.org/podWritingTemplates.html If you need advice, the author is rather helpful.     ","Language":"Python","Tags":["python","pdf","pdf-generation"],"URL":"https://stackoverflow.com/questions/6413441/python-pdf-library","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    What Python PDF libraries are there?  I need to make some PDF with many grids, and I'm looking for a library that allows to manage pages (multi-page). The library should calculate when the page is ended and then create the next page.     ","Q_Votes":"79"},{"Q_Title":"Django model manager objects.create where is the documentation?","A_Content":"  It's in the page \"QuerySet API reference\", linked from the documentation index.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/9940674/django-model-manager-objects-create-where-is-the-documentation","A_Votes":"33","_type":"dict","isAccepted":"Yes","Q_Content":"    I always read that I should use  model = Model(a=5, b=6) model.save()   But I just saw there is a manager function create, because I saw an opensource django app using it.  model = Model.objects.create(a=5, b=6) print model.pk 1   So is it suggested to use it? Or is it still preferred to use the .save method. I'm guessing that objects.create will try to create it no matter what, whereas save may save an existing object if the pk is specified.  These are the docs that I found: https://docs.djangoproject.com/en/dev/topics/db/queries/#creating-objects     ","Q_Votes":"79"},{"Q_Title":"Django model manager objects.create where is the documentation?","A_Content":"  p = Person.objects.create(first_name=\"Bruce\", last_name=\"Springsteen\")   equivalent to:  p = Person(first_name=\"Bruce\", last_name=\"Springsteen\")  p.save(force_insert=True)      The force_insert means that a new object will always be created.   Normally you wont need to worry about this. However, if your model   contains a manual primary key value that you set and if that value   already exists in the database, a call to create() will fail with an   IntegrityError since primary keys must be unique. Be prepared to   handle the exception if you are using manual primary keys.      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/9940674/django-model-manager-objects-create-where-is-the-documentation","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    I always read that I should use  model = Model(a=5, b=6) model.save()   But I just saw there is a manager function create, because I saw an opensource django app using it.  model = Model.objects.create(a=5, b=6) print model.pk 1   So is it suggested to use it? Or is it still preferred to use the .save method. I'm guessing that objects.create will try to create it no matter what, whereas save may save an existing object if the pk is specified.  These are the docs that I found: https://docs.djangoproject.com/en/dev/topics/db/queries/#creating-objects     ","Q_Votes":"79"},{"Q_Title":"Django model manager objects.create where is the documentation?","A_Content":"  Basically, these two methods are equivalent. The usage of Model.objects.create could be preferred since it is more suited to the style of Django.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/9940674/django-model-manager-objects-create-where-is-the-documentation","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I always read that I should use  model = Model(a=5, b=6) model.save()   But I just saw there is a manager function create, because I saw an opensource django app using it.  model = Model.objects.create(a=5, b=6) print model.pk 1   So is it suggested to use it? Or is it still preferred to use the .save method. I'm guessing that objects.create will try to create it no matter what, whereas save may save an existing object if the pk is specified.  These are the docs that I found: https://docs.djangoproject.com/en/dev/topics/db/queries/#creating-objects     ","Q_Votes":"79"},{"Q_Title":"Django model manager objects.create where is the documentation?","A_Content":"  create essentially does the same. below is the source code for create.  def create(self, **kwargs):     \"\"\"     Creates a new object with the given kwargs, saving it to the database     and returning the created object.     \"\"\"     obj = self.model(**kwargs)     self._for_write = True     obj.save(force_insert=True, using=self.db)     return obj   it creates an instance and then saves it.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/9940674/django-model-manager-objects-create-where-is-the-documentation","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I always read that I should use  model = Model(a=5, b=6) model.save()   But I just saw there is a manager function create, because I saw an opensource django app using it.  model = Model.objects.create(a=5, b=6) print model.pk 1   So is it suggested to use it? Or is it still preferred to use the .save method. I'm guessing that objects.create will try to create it no matter what, whereas save may save an existing object if the pk is specified.  These are the docs that I found: https://docs.djangoproject.com/en/dev/topics/db/queries/#creating-objects     ","Q_Votes":"79"},{"Q_Title":"Pandas timeseries plot setting x-axis major and minor ticks and labels","A_Content":"  Both pandas and matplotlib.dates use matplotlib.units for locating the ticks.   But while matplotlib.dates has convenient ways to set the ticks manually, pandas seems to have the focus on auto formatting so far (you can have a look at the code for date conversion and formatting in pandas).  So for the moment it seems more reasonable to use matplotlib.dates (as mentioned by @BrenBarn in his comment).  import numpy as np import pandas as pd import matplotlib.pyplot as plt  import matplotlib.dates as dates  idx = pd.date_range('2011-05-01', '2011-07-01') s = pd.Series(np.random.randn(len(idx)), index=idx)  fig, ax = plt.subplots() ax.plot_date(idx.to_pydatetime(), s, 'v-') ax.xaxis.set_minor_locator(dates.WeekdayLocator(byweekday=(1),                                                 interval=1)) ax.xaxis.set_minor_formatter(dates.DateFormatter('%d\\n%a')) ax.xaxis.grid(True, which=\"minor\") ax.yaxis.grid() ax.xaxis.set_major_locator(dates.MonthLocator()) ax.xaxis.set_major_formatter(dates.DateFormatter('\\n\\n\\n%b\\n%Y')) plt.tight_layout() plt.show()     (my locale is German, so that Tuesday [Tue] becomes Dienstag [Di])       ","Language":"Python","Tags":["python","matplotlib","pandas"],"URL":"https://stackoverflow.com/questions/12945971/pandas-timeseries-plot-setting-x-axis-major-and-minor-ticks-and-labels","A_Votes":"76","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to be able to set the major and minor xticks and their labels for a time series graph plotted from a Pandas time series object.    The Pandas 0.9 \"what's new\" page says:      \"you can either use to_pydatetime or register a converter for the   Timestamp type\"   but I can't work out how to do that so that I can use the matplotlib ax.xaxis.set_major_locator and ax.xaxis.set_major_formatter (and minor) commands.  If I use them without converting the pandas times, the x-axis ticks and labels end up wrong.  By using the 'xticks' parameter I can pass the major ticks to pandas.plot, and then set the major tick labels. I can't work out how to do the minor ticks using this approach. (I can set the labels on the default minor ticks set by pandas.plot)  Here is my test code:  import pandas print 'pandas.__version__ is ', pandas.__version__ print 'matplotlib.__version__ is ', matplotlib.__version__      dStart = datetime.datetime(2011,5,1) # 1 May dEnd = datetime.datetime(2011,7,1) # 1 July      dateIndex = pandas.date_range(start=dStart, end=dEnd, freq='D') print \"1 May to 1 July 2011\", dateIndex        testSeries = pandas.Series(data=np.random.randn(len(dateIndex)),                            index=dateIndex)      ax = plt.figure(figsize=(7,4), dpi=300).add_subplot(111) testSeries.plot(ax=ax, style='v-', label='first line')      # using MatPlotLib date time locators and formatters doesn't work with new # pandas datetime index ax.xaxis.set_minor_locator(matplotlib.dates.WeekdayLocator(byweekday=(1),                                                            interval=1)) ax.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%d\\n%a')) ax.xaxis.grid(True, which=\"minor\") ax.xaxis.grid(False, which=\"major\") ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('\\n\\n\\n%b%Y')) plt.show()      # set the major xticks and labels through pandas ax2 = plt.figure(figsize=(7,4), dpi=300).add_subplot(111) xticks = pandas.date_range(start=dStart, end=dEnd, freq='W-Tue') print \"xticks: \", xticks testSeries.plot(ax=ax2, style='-v', label='second line',                 xticks=xticks.to_pydatetime()) ax2.set_xticklabels([x.strftime('%a\\n%d\\n%h\\n%Y') for x in xticks]); # set the text of the first few minor ticks created by pandas.plot #    ax2.set_xticklabels(['a','b','c','d','e'], minor=True) # remove the minor xtick labels set by pandas.plot  ax2.set_xticklabels([], minor=True) # turn the minor ticks created by pandas.plot off  # plt.minorticks_off() plt.show() print testSeries['6/4/2011':'6/7/2011']   and its output:  pandas.__version__ is  0.9.1.dev-3de54ae matplotlib.__version__ is  1.1.1 1 May to 1 July 2011 <class 'pandas.tseries.index.DatetimeIndex'> [2011-05-01 00:00:00, ..., 2011-07-01 00:00:00] Length: 62, Freq: D, Timezone: None     xticks:  <class 'pandas.tseries.index.DatetimeIndex'> [2011-05-03 00:00:00, ..., 2011-06-28 00:00:00] Length: 9, Freq: W-TUE, Timezone: None     2011-06-04   -0.199393 2011-06-05   -0.043118 2011-06-06    0.477771 2011-06-07   -0.033207 Freq: D   Update: I've been able to get closer to the layout I wanted by using a loop to build the major xtick labels:  # only show month for first label in month month = dStart.month - 1 xticklabels = [] for x in xticks:     if  month != x.month :         xticklabels.append(x.strftime('%d\\n%a\\n%h'))         month = x.month     else:         xticklabels.append(x.strftime('%d\\n%a'))   However, this is a bit like doing the x-axis using ax.annotate: possible but not ideal.     ","Q_Votes":"79"},{"Q_Title":"Pandas join issue: columns overlap but no suffix specified","A_Content":"  Your error on the snippet of data you posted is a little cryptic, in that because there are no common values, the join operation fails because the values don't overlap it requires you to supply a suffix for the left and right hand side:  In [173]:  df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right') Out[173]:        mukey_left  DI  PI  mukey_right  niccdcd index                                           0          100000  35  14          NaN      NaN 1         1000005  44  14          NaN      NaN 2         1000006  44  14          NaN      NaN 3         1000007  43  13          NaN      NaN 4         1000008  43  13          NaN      NaN   merge works because it doesn't have this restriction:  In [176]:  df_a.merge(df_b, on='mukey', how='left') Out[176]:      mukey  DI  PI  niccdcd 0   100000  35  14      NaN 1  1000005  44  14      NaN 2  1000006  44  14      NaN 3  1000007  43  13      NaN 4  1000008  43  13      NaN      ","Language":"Python","Tags":["python","join","pandas"],"URL":"https://stackoverflow.com/questions/26645515/pandas-join-issue-columns-overlap-but-no-suffix-specified","A_Votes":"83","_type":"dict","isAccepted":"Yes","Q_Content":"    I have following 2 data frames:  df_a =       mukey  DI  PI 0   100000  35  14 1  1000005  44  14 2  1000006  44  14 3  1000007  43  13 4  1000008  43  13  df_b =      mukey  niccdcd 0  190236        4 1  190237        6 2  190238        7 3  190239        4 4  190240        7   When I try to join these 2 dataframes:  join_df = df_a.join(df_b,on='mukey',how='left')   I get the error:  *** ValueError: columns overlap but no suffix specified: Index([u'mukey'], dtype='object')   Why is this so? The dataframes do have common 'mukey' values.     ","Q_Votes":"79"},{"Q_Title":"Pandas join issue: columns overlap but no suffix specified","A_Content":"  The .join() function is using the index of the passed as argument dataset, so you should use set_index or use .merge function instead.  Please find the two examples that should work in your case:  join_df = LS_sgo.join(MSU_pi.set_index('mukey'), on='mukey', how='left')  or  join_df = df_a.merge(df_b, on='mukey', how='left')     ","Language":"Python","Tags":["python","join","pandas"],"URL":"https://stackoverflow.com/questions/26645515/pandas-join-issue-columns-overlap-but-no-suffix-specified","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I have following 2 data frames:  df_a =       mukey  DI  PI 0   100000  35  14 1  1000005  44  14 2  1000006  44  14 3  1000007  43  13 4  1000008  43  13  df_b =      mukey  niccdcd 0  190236        4 1  190237        6 2  190238        7 3  190239        4 4  190240        7   When I try to join these 2 dataframes:  join_df = df_a.join(df_b,on='mukey',how='left')   I get the error:  *** ValueError: columns overlap but no suffix specified: Index([u'mukey'], dtype='object')   Why is this so? The dataframes do have common 'mukey' values.     ","Q_Votes":"79"},{"Q_Title":"Pandas join issue: columns overlap but no suffix specified","A_Content":"  This error indicates that the two tables have the 1 or more column names that have the same column name. The error message translates to: \"I can see the same column in both tables but you haven't told me to rename either before bringing one of them in\"  You either want to delete one of the columns before bringing it in from the other on using del df['column name'], or use lsuffix to re-write the original column, or rsuffix to rename the one that is being brought it.  df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')      ","Language":"Python","Tags":["python","join","pandas"],"URL":"https://stackoverflow.com/questions/26645515/pandas-join-issue-columns-overlap-but-no-suffix-specified","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have following 2 data frames:  df_a =       mukey  DI  PI 0   100000  35  14 1  1000005  44  14 2  1000006  44  14 3  1000007  43  13 4  1000008  43  13  df_b =      mukey  niccdcd 0  190236        4 1  190237        6 2  190238        7 3  190239        4 4  190240        7   When I try to join these 2 dataframes:  join_df = df_a.join(df_b,on='mukey',how='left')   I get the error:  *** ValueError: columns overlap but no suffix specified: Index([u'mukey'], dtype='object')   Why is this so? The dataframes do have common 'mukey' values.     ","Q_Votes":"79"},{"Q_Title":"Python: why are * and ** faster than / and sqrt()?","A_Content":"  The (somewhat unexpected) reason for your results is that Python seems to fold constant expressions involving floating-point multiplication and exponentiation, but not division. math.sqrt() is a different beast altogether since there's no bytecode for it and it involves a function call.  On Python 2.6.5, the following code:  x1 = 1234567890.0 / 4.0 x2 = 1234567890.0 * 0.25 x3 = 1234567890.0 ** 0.5 x4 = math.sqrt(1234567890.0)   compiles to the following bytecodes:    # x1 = 1234567890.0 / 4.0   4           0 LOAD_CONST               1 (1234567890.0)               3 LOAD_CONST               2 (4.0)               6 BINARY_DIVIDE                      7 STORE_FAST               0 (x1)    # x2 = 1234567890.0 * 0.25   5          10 LOAD_CONST               5 (308641972.5)              13 STORE_FAST               1 (x2)    # x3 = 1234567890.0 ** 0.5   6          16 LOAD_CONST               6 (35136.418286444619)              19 STORE_FAST               2 (x3)    # x4 = math.sqrt(1234567890.0)   7          22 LOAD_GLOBAL              0 (math)              25 LOAD_ATTR                1 (sqrt)              28 LOAD_CONST               1 (1234567890.0)              31 CALL_FUNCTION            1              34 STORE_FAST               3 (x4)   As you can see, multiplication and exponentiation take no time at all since they're done when the code is compiled. Division takes longer since it happens at runtime. Square root is not only the most computationally expensive operation of the four, it also incurs various  overheads that the others do not (attribute lookup, function call etc).  If you eliminate the effect of constant folding, there's little to separate multiplication and division:  In [16]: x = 1234567890.0  In [17]: %timeit x / 4.0 10000000 loops, best of 3: 87.8 ns per loop  In [18]: %timeit x * 0.25 10000000 loops, best of 3: 91.6 ns per loop   math.sqrt(x) is actually a little bit faster than x ** 0.5, presumably because it's a special case of the latter and can therefore be done more efficiently, in spite of the overheads:  In [19]: %timeit x ** 0.5 1000000 loops, best of 3: 211 ns per loop  In [20]: %timeit math.sqrt(x) 10000000 loops, best of 3: 181 ns per loop   edit 2011-11-16: Constant expression folding is done by Python's peephole optimizer. The source code (peephole.c) contains the following comment that explains why constant division isn't folded:      case BINARY_DIVIDE:         /* Cannot fold this operation statically since            the result can depend on the run-time presence            of the -Qnew flag */         return 0;   The -Qnew flag enables \"true division\" defined in PEP 238.     ","Language":"Python","Tags":["python","c","performance","python-2.7","python-internals"],"URL":"https://stackoverflow.com/questions/8068019/python-why-are-and-faster-than-and-sqrt","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    While optimising my code I realised the following:  >>> from timeit import Timer as T >>> T(lambda : 1234567890 / 4.0).repeat() [0.22256922721862793, 0.20560789108276367, 0.20530295372009277] >>> from __future__ import division >>> T(lambda : 1234567890 / 4).repeat() [0.14969301223754883, 0.14155197143554688, 0.14141488075256348] >>> T(lambda : 1234567890 * 0.25).repeat() [0.13619112968444824, 0.1281130313873291, 0.12830305099487305]   and also:  >>> from math import sqrt >>> T(lambda : sqrt(1234567890)).repeat() [0.2597470283508301, 0.2498021125793457, 0.24994492530822754] >>> T(lambda : 1234567890 ** 0.5).repeat() [0.15409398078918457, 0.14059877395629883, 0.14049601554870605]   I assume it has to do with the way python is implemented in C, but I wonder if anybody would care to explain why is so?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  I'd do it like this so changing its type in foo() won't require also changing it in bar().  def foo():     try:         raise IOError('Stuff')     except:         raise  def bar(arg1):     try:         foo()     except Exception as e:         raise type(e)(e.message + ' happens at %s' % arg1)  bar('arg1')   Traceback (most recent call last):   File \"test.py\", line 13, in <module>     bar('arg1')   File \"test.py\", line 11, in bar     raise type(e)(e.message + ' happens at %s' % arg1) IOError: Stuff happens at arg1   Update 1  Here's a slight modification that preserves the original traceback:  ... def bar(arg1):     try:         foo()     except Exception as e:         import sys         raise type(e), type(e)(e.message +                                ' happens at %s' % arg1), sys.exc_info()[2]  bar('arg1')   Traceback (most recent call last):   File \"test.py\", line 16, in <module>     bar('arg1')   File \"test.py\", line 11, in bar     foo()   File \"test.py\", line 5, in foo     raise IOError('Stuff') IOError: Stuff happens at arg1   Update 2  For Python 3.x, the code in my first update is syntactically incorrect plus the idea of having a message attribute on BaseException was retracted in a change to PEP 352 on 2012-05-16 (my first update was posted on 2012-03-12). So currently, in Python 3.5.2 anyway, you'd need to do something along these lines to preserve the traceback and not hardcode the type of exception in function bar(). Also note that there will be the line:  During handling of the above exception, another exception occurred:   in the traceback messages displayed.  # for Python 3.x ... def bar(arg1):     try:         foo()     except Exception as e:         import sys         raise type(e)(str(e) +                       ' happens at %s' % arg1).with_traceback(sys.exc_info()[2])  bar('arg1')   Update 3  A commenter asked if there was a way that would work in both Python 2 and 3. Although the answer might seem to be \"No\" due to the syntax differences, there is a way around that by using a helper function like reraise() in the six add-on module. So, if you'd rather not use the library for some reason, below is a simplified standalone version.  Note too, that since the exception is reraised within the reraise() function, that will appear in whatever traceback is raised, but the final result is what you want.  import sys  if sys.version_info.major < 3:  # Python 2?     # Using exec avoids a SyntaxError in Python 3.     exec(\"\"\"def reraise(exc_type, exc_value, exc_traceback=None):                 raise exc_type, exc_value, exc_traceback\"\"\") else:     def reraise(exc_type, exc_value, exc_traceback=None):         if exc_value is None:             exc_value = exc_type()         if exc_value.__traceback__ is not exc_traceback:             raise exc_value.with_traceback(exc_traceback)         raise exc_value  def foo():     try:         raise IOError('Stuff')     except:         raise  def bar(arg1):     try:        foo()     except Exception as e:         reraise(type(e), type(e)(str(e) +                                  ' happens at %s' % arg1), sys.exc_info()[2])  bar('arg1')      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"80","_type":"dict","isAccepted":"Yes","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  In case you came here searching for a solution for Python3 the manual  says:     When raising a new exception (rather than using a bare raise to re-raise the exception currently being handled), the implicit exception context can be supplemented with an explicit cause by using from with raise:   raise new_exc from original_exc     Example:      try:         return [permission() for permission in self.permission_classes]     except TypeError as e:         raise TypeError(\"Make sure your view's 'permission_classes' are iterable. \"                         +\"If you use '()' to generate a set with a single element \"                         +\"make sure that there is a comma behind the one (element,).\") from e   Which looks like this in the end:      2017-09-06 16:50:14,797 [ERROR] django.request: Internal Server Error: /v1/sendEmail/     Traceback (most recent call last):     File \"venv/lib/python3.4/site-packages/rest_framework/views.py\", line 275, in get_permissions         return [permission() for permission in self.permission_classes]     TypeError: 'type' object is not iterable       The above exception was the direct cause of the following exception:      Traceback (most recent call last):         # Traceback removed...     TypeError: Make sure your view's Permission_classes are iterable. If           you use parens () to generate a set with a single element make           sure that there is a (comma,) behind the one element.   Turning a totally nondescript TypeError into a nice message with hints towards a solution without messing up the original Exception.     ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  Assuming you don't want to or can't modify foo(), you can try this:  try:     raise IOError('stuff') except Exception as e:     e.args = (e.args[0] + ' happens',)     raise      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  One handy approach that I used is to use class attribute as storage for details, as class attribute is accessible both from class object and class instance:   class CustomError(Exception):     details = None   Then in your code:  exc = CustomError('Some message') exc.details('Details -- add whatever you want') raise exc   And when catching an error:  except CustomError, e:     # Do whatever you want with the exception instance     print e     print e.details      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  You can define your own exception that inherits from another and create it's own constructor to set value.  For example:  class MyError(Exception):    def __init__(self, value):      self.value = value      Exception.__init__(self)     def __str__(self):      return repr(self.value)      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  Unlike previous answers, this works in the face of exceptions with really bad __str__. It does modify the type however, in order to factor out unhelpful __str__ implementations.  I'd still like to find an additional improvement that doesn't modify the type.  from contextlib import contextmanager @contextmanager def helpful_info():     try:         yield     except Exception as e:         class CloneException(Exception): pass         CloneException.__name__ = type(e).__name__         CloneException.__module___ = type(e).__module__         helpful_message = '%s\\n\\nhelpful info!' % e         import sys         raise CloneException, helpful_message, sys.exc_traceback   class BadException(Exception):     def __str__(self):         return 'wat.'  with helpful_info():     raise BadException('fooooo')   The original traceback and type (name) are preserved.  Traceback (most recent call last):   File \"re_raise.py\", line 20, in <module>     raise BadException('fooooo')   File \"/usr/lib64/python2.6/contextlib.py\", line 34, in __exit__     self.gen.throw(type, value, traceback)   File \"re_raise.py\", line 5, in helpful_info     yield   File \"re_raise.py\", line 20, in <module>     raise BadException('fooooo') __main__.BadException: wat.  helpful info!      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"Adding information to an exception?","A_Content":"  I will provide a snippet of code that I use often whenever I want to add extra info to an exception.  I works both in Python 2.7 and 3.6.    import sys import traceback  try:     a = 1     b = 1j      # The line below raises an exception because     # we cannot compare int to complex.     m = max(a, b)    except Exception as ex:     # I create my  informational message for debugging:     msg = \"a=%r, b=%r\" % (a, b)      # Gather the information from the original exception:     exc_type, exc_value, exc_traceback = sys.exc_info()      # Format the original exception for a nice printout:     traceback_string = ''.join(traceback.format_exception(         exc_type, exc_value, exc_traceback))      # Re-raise a new exception of the same class as the original one,      # using my custom message and the original traceback:     raise type(ex)(\"%s\\n\\nORIGINAL TRACEBACK:\\n\\n%s\\n\" % (msg, traceback_string))   The code above results in the following output:   --------------------------------------------------------------------------- TypeError                                 Traceback (most recent call last) <ipython-input-6-09b74752c60d> in <module>()      14     raise type(ex)(      15         \"%s\\n\\nORIGINAL TRACEBACK:\\n\\n%s\\n\" % ---> 16         (msg, traceback_string))  TypeError: a=1, b=1j  ORIGINAL TRACEBACK:  Traceback (most recent call last):   File \"<ipython-input-6-09b74752c60d>\", line 7, in <module>     m = max(a, b)  # Cannot compare int to complex TypeError: no ordering relation is defined for complex numbers      I know this deviates a little from the example provided in the question, but nevertheless I hope someone finds it useful.      ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/6062576/adding-information-to-an-exception","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    EDIT: I am running python 2.6  I want to achieve something like this:  def foo():    try:        raise IOError('Stuff ')    except:        raise  def bar(arg1):     try:        foo()     except Exception as e:        e.message = e.message + 'happens at %s' % arg1        raise  bar('arg1')   Traceback...   IOError('Stuff Happens at arg1')   But what I get is:  Traceback..   IOError('Stuff')   Any clues as to how to achieve this?     ","Q_Votes":"79"},{"Q_Title":"About Python's built in sort() method","A_Content":"  Sure!  The code's here, starting with function islt and proceeding for QUITE a while;-). As Chris's comment suggests, it's C code.  You'll also want to read this text file for a textual explanation, results, etc etc.  If you prefer reading Java code than C code, you could look at Joshua Bloch's implementation of timsort in and for Java (Joshua's also the guy who implemented, in 1997, the modified mergesort that's still used in Java, and one can hope that Java will eventually switch to his recent port of timsort).  Some explanation of the Java port of timsort is here, the diff is here (with pointers to all needed files), the key file is here -- FWIW, while I'm a better C programmer than Java programmer, in this case I find Joshua's Java code more readable overall than Tim's C code;-).     ","Language":"Python","Tags":["python","algorithm","sorting","python-internals"],"URL":"https://stackoverflow.com/questions/1517347/about-pythons-built-in-sort-method","A_Votes":"90","_type":"dict","isAccepted":"Yes","Q_Content":"    What algorithm is the built in sort() method in Python using? Is it possible to have a look at the code for that method?     ","Q_Votes":"79"},{"Q_Title":"About Python's built in sort() method","A_Content":"  I just wanted to supply a very helpful link that I missed in Alex's otherwise comprehensive answer: A high-level explanation of Python's timsort (with graph visualizations!).  (Yes, the algorithm is basically known as Timsort now)     ","Language":"Python","Tags":["python","algorithm","sorting","python-internals"],"URL":"https://stackoverflow.com/questions/1517347/about-pythons-built-in-sort-method","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    What algorithm is the built in sort() method in Python using? Is it possible to have a look at the code for that method?     ","Q_Votes":"79"},{"Q_Title":"About Python's built in sort() method","A_Content":"  In early python-versions, the sort function implemented a modified version of quicksort. However, it was deemed unstable and as of 2.3 they switched to using an adaptive mergesort algorithm.     ","Language":"Python","Tags":["python","algorithm","sorting","python-internals"],"URL":"https://stackoverflow.com/questions/1517347/about-pythons-built-in-sort-method","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    What algorithm is the built in sort() method in Python using? Is it possible to have a look at the code for that method?     ","Q_Votes":"79"},{"Q_Title":"Determine if 2 lists have the same elements, regardless of order? [duplicate]","A_Content":"  You can simply check whether the multisets with the elements of x and y are equal:  import collections collections.Counter(x) == collections.Counter(y)   This requires the elements to be hashable; runtime will be in O(n), where n is the size of the lists.  If the elements are also unique, you can also convert to sets (same asymptotic runtime, may be a little bit faster in practice):  set(x) == set(y)   If the elements are not hashable, but sortable, another alternative (runtime in O(n log n)) is  sorted(x) == sorted(y)   If the elements are neither hashable nor sortable you can use the following helper function. Note that it will be quite slow (O(n)) and should generally not be used outside of the esoteric case of unhashable and unsortable elements.  def equal_ignore_order(a, b):     \"\"\" Use only when elements are neither hashable nor sortable! \"\"\"     unmatched = list(b)     for element in a:         try:             unmatched.remove(element)         except ValueError:             return False     return not unmatched      ","Language":"Python","Tags":["python","list","equality","python-2.x"],"URL":"https://stackoverflow.com/questions/8866652/determine-if-2-lists-have-the-same-elements-regardless-of-order","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              How to efficiently compare two unordered lists (not sets) in Python?                                        9 answers                                          Sorry for the simple question, but I'm having a hard time finding the answer.  When I compare 2 lists, I want to know if they are \"equal\" in that they have the same contents, but in different order.  Ex:  x = ['a', 'b'] y = ['b', 'a']   I want x == y to evaluate to True.     ","Q_Votes":"79"},{"Q_Title":"Determine if 2 lists have the same elements, regardless of order? [duplicate]","A_Content":"     Determine if 2 lists have the same elements, regardless of order?   Inferring from your example:  x = ['a', 'b'] y = ['b', 'a']   that the elements of the lists won't be repeated (they are unique) as well as hashable (which strings and other certain immutable python objects are), the most direct and computationally efficient answer uses Python's builtin sets, (which are semantically like mathematical sets you may have learned about in school).   set(x) == set(y) # prefer this if elements are hashable   In the case that the elements are hashable, but non-unique, the collections.Counter also works semantically as a multiset, but it is far slower:  from collections import Counter Counter(x) == Counter(y)   Prefer to use sorted:  sorted(x) == sorted(y)    if the elements are orderable. This would account for non-unique or non-hashable circumstances, but this could be much slower than using sets.  Empirical Experiment  An empirical experiment concludes that one should prefer set, then sorted. Only opt for Counter if you need other things like counts or further usage as a multiset.  First setup:  import timeit import random from collections import Counter  data = [str(random.randint(0, 100000)) for i in xrange(100)] data2 = data[:]     # copy the list into a new one  def sets_equal():      return set(data) == set(data2)  def counters_equal():      return Counter(data) == Counter(data2)  def sorted_lists_equal():      return sorted(data) == sorted(data2)   And testing:  >>> min(timeit.repeat(sets_equal)) 13.976069927215576 >>> min(timeit.repeat(counters_equal)) 73.17287588119507 >>> min(timeit.repeat(sorted_lists_equal)) 36.177085876464844   So we see that comparing sets is the fastest solution, and comparing sorted lists is second fastest.     ","Language":"Python","Tags":["python","list","equality","python-2.x"],"URL":"https://stackoverflow.com/questions/8866652/determine-if-2-lists-have-the-same-elements-regardless-of-order","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to efficiently compare two unordered lists (not sets) in Python?                                        9 answers                                          Sorry for the simple question, but I'm having a hard time finding the answer.  When I compare 2 lists, I want to know if they are \"equal\" in that they have the same contents, but in different order.  Ex:  x = ['a', 'b'] y = ['b', 'a']   I want x == y to evaluate to True.     ","Q_Votes":"79"},{"Q_Title":"Determine if 2 lists have the same elements, regardless of order? [duplicate]","A_Content":"  This seems to work, though possibly cumbersome for large lists.  >>> A = [0, 1] >>> B = [1, 0] >>> C = [0, 2] >>> not sum([not i in A for i in B]) True >>> not sum([not i in A for i in C]) False >>>    However, if each list must contain all the elements of other then the above code is problematic.   >>> A = [0, 1, 2] >>> not sum([not i in A for i in B]) True   The problem arises when len(A) != len(B) and, in this example, len(A) > len(B). To avoid this, you can add one more statement.  >>> not sum([not i in A for i in B]) if len(A) == len(B) else False False   One more thing, I benchmarked my solution with timeit.repeat, under the same conditions used by Aaron Hall in his post. As suspected, the results are disappointing. My method is the last one. set(x) == set(y) it is.  >>> def foocomprehend(): return not sum([not i in data for i in data2]) >>> min(timeit.repeat('fooset()', 'from __main__ import fooset, foocount, foocomprehend')) 25.2893661496 >>> min(timeit.repeat('foosort()', 'from __main__ import fooset, foocount, foocomprehend')) 94.3974742993 >>> min(timeit.repeat('foocomprehend()', 'from __main__ import fooset, foocount, foocomprehend')) 187.224562545      ","Language":"Python","Tags":["python","list","equality","python-2.x"],"URL":"https://stackoverflow.com/questions/8866652/determine-if-2-lists-have-the-same-elements-regardless-of-order","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to efficiently compare two unordered lists (not sets) in Python?                                        9 answers                                          Sorry for the simple question, but I'm having a hard time finding the answer.  When I compare 2 lists, I want to know if they are \"equal\" in that they have the same contents, but in different order.  Ex:  x = ['a', 'b'] y = ['b', 'a']   I want x == y to evaluate to True.     ","Q_Votes":"79"},{"Q_Title":"Determine if 2 lists have the same elements, regardless of order? [duplicate]","A_Content":"  As mentioned in comments above, the general case is a pain. It is fairly easy if all items are hashable or all items are sortable. However I have recently had to try solve the general case. Here is my solution. I realised after posting that this is a duplicate to a solution above that I missed on the first pass. Anyway, if you use slices rather than list.remove() you can compare immutable sequences.  def sequences_contain_same_items(a, b):     for item in a:         try:             i = b.index(item)         except ValueError:             return False         b = b[:i] + b[i+1:]     return not b      ","Language":"Python","Tags":["python","list","equality","python-2.x"],"URL":"https://stackoverflow.com/questions/8866652/determine-if-2-lists-have-the-same-elements-regardless-of-order","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to efficiently compare two unordered lists (not sets) in Python?                                        9 answers                                          Sorry for the simple question, but I'm having a hard time finding the answer.  When I compare 2 lists, I want to know if they are \"equal\" in that they have the same contents, but in different order.  Ex:  x = ['a', 'b'] y = ['b', 'a']   I want x == y to evaluate to True.     ","Q_Votes":"79"},{"Q_Title":"Pythons many ways of string formatting  are the older ones (going to be) deprecated?","A_Content":"  The new .format() method is meant to replace the old % formatting syntax. The latter has been de-emphasised, (but not officially deprecated yet). The method documentation states as much:     This method of string formatting is the new standard in Python 3, and should be preferred to the % formatting described in String Formatting Operations in new code.   (Emphasis mine).  To maintain backwards compatibility and to make transition easier, the old format has been left in place for now. From the original PEP 3101 proposal:     Backwards Compatibility      Backwards compatibility can be maintained by leaving the existing   mechanisms in place.  The new system does not collide with any of   the method names of the existing string formatting techniques, so   both systems can co-exist until it comes time to deprecate the   older system.   Note the until it comes time to deprecate the older system; it hasn't been deprecated, but the new system is to be used whenever you write new code.  The new system has as an advantage that you can combine the tuple and dictionary approach of the old % formatter:  \"{greeting}, {0}\".format(world, greeting='Hello')   and is extensible through the object.__format__() hook used to handle formatting of individual values.  Note that the old system had % and the Template class, where the latter allows you to create subclasses that add or alter its behaviour. The new-style system has the Formatter class to fill the same niche.  Python 3 has further stepped away from deprecation, instead giving you warning in the printf-style String Formatting section:     Note: The formatting operations described here exhibit a variety of quirks that lead to a number of common errors (such as failing to display tuples and dictionaries correctly). Using the newer formatted string literals or the str.format() interface helps avoid these errors. These alternatives also provide more powerful, flexible and extensible approaches to formatting text.    Python 3.6 also added formatted string literals, which in-line the expressions into the string format spits. These are the fastest method of creating strings with interpolated values, and should be used instead of str.format() wherever you can use a literal.      ","Language":"Python","Tags":["python","printf","string-formatting","deprecated","backwards-compatibility"],"URL":"https://stackoverflow.com/questions/13451989/pythons-many-ways-of-string-formatting-are-the-older-ones-going-to-be-deprec","A_Votes":"49","_type":"dict","isAccepted":"Yes","Q_Content":"    Python has at least six ways of formatting a string:  In [1]: world = \"Earth\"  # method 1a In [2]: \"Hello, %s\" % world Out[2]: 'Hello, Earth'  # method 1b In [3]: \"Hello, %(planet)s\" % {\"planet\": world} Out[3]: 'Hello, Earth'  # method 2a In [4]: \"Hello, {0}\".format(world) Out[4]: 'Hello, Earth'  # method 2b In [5]: \"Hello, {planet}\".format(planet=world) Out[5]: 'Hello, Earth'  # method 2c In [6]: f\"Hello, {world}\" Out[6]: 'Hello, Earth'  In [7]: from string import Template  # method 3 In [8]: Template(\"Hello, $planet\").substitute(planet=world) Out[8]: 'Hello, Earth'   A brief history of the different methods:   printf-style formatting has been around since Pythons infancy The Template class was introduced in Python 2.4 The format method was introduced in Python 2.6  f-strings were introduced in Python 3.6   My questions are:   Is printf-style formatting deprecated or going to be deprecated? In the Template class, is the substitute method deprecated or going to be deprecated? (I'm not talking about safe_substitute, which as I understand it offers unique capabilities)   Similar questions and why I think they're not duplicates:   Python string formatting: % vs. .format  treats only methods 1 and 2, and asks which one is better; my question is explicitly about deprecation in the light of the Zen of Python String formatting options: pros and cons  treats only methods 1a and 1b in the question, 1 and 2 in the answer, and also nothing about deprecation advanced string formatting vs template strings  mostly about methods 1 and 3, and doesn't address deprecation String formatting expressions (Python)  answer mentions that the original '%' approach is planned to be deprecated. But what's the difference between planned to be deprecated, pending deprecation and actual deprecation? And the printf-style method doesn't raise even a PendingDeprecationWarning, so is this really going to be deprecated? This post is also quite old, so the information may be outdated.   See also PEP 502: String Interpolation - Extended Discussion     ","Q_Votes":"79"},{"Q_Title":"Pythons many ways of string formatting  are the older ones (going to be) deprecated?","A_Content":"  The % operator for string formatting is not deprecated, and is not going to be removed - despite the other answers. Every time the subject is raised on Python development list, there is strong controversy on which is better, but no controversy on whether to remove the classic way - it will stay. Despite being denoted on PEP 3101, Python 3.1 had come and gone, and % formatting is still around.  The statements for the keeping classic style are clear: it is simple, it is fast, it is quick to do for short things. Using the .format method is not always more readable - and barely anyone - even among the core developers, can use the full syntax provided by .format without having to look at the reference  Even back in 2009, one had messages like this: http://mail.python.org/pipermail/python-dev/2009-October/092529.html  - the subject had barely showed up in the lists since.  2016 update  In current Python development version (which will become Python 3.6) there is a third method of string interpolation, described on PEP-0498. It defines a new quote prefix f\"\" (besides the current u\"\", b\"\" and r\"\").  Prefixing a string by f will call a method on the string object at runtime, which will automatically interpolate variables from the current scope into the string:  >>> value = 80 >>> f'The value is {value}.' 'The value is 80.'      ","Language":"Python","Tags":["python","printf","string-formatting","deprecated","backwards-compatibility"],"URL":"https://stackoverflow.com/questions/13451989/pythons-many-ways-of-string-formatting-are-the-older-ones-going-to-be-deprec","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    Python has at least six ways of formatting a string:  In [1]: world = \"Earth\"  # method 1a In [2]: \"Hello, %s\" % world Out[2]: 'Hello, Earth'  # method 1b In [3]: \"Hello, %(planet)s\" % {\"planet\": world} Out[3]: 'Hello, Earth'  # method 2a In [4]: \"Hello, {0}\".format(world) Out[4]: 'Hello, Earth'  # method 2b In [5]: \"Hello, {planet}\".format(planet=world) Out[5]: 'Hello, Earth'  # method 2c In [6]: f\"Hello, {world}\" Out[6]: 'Hello, Earth'  In [7]: from string import Template  # method 3 In [8]: Template(\"Hello, $planet\").substitute(planet=world) Out[8]: 'Hello, Earth'   A brief history of the different methods:   printf-style formatting has been around since Pythons infancy The Template class was introduced in Python 2.4 The format method was introduced in Python 2.6  f-strings were introduced in Python 3.6   My questions are:   Is printf-style formatting deprecated or going to be deprecated? In the Template class, is the substitute method deprecated or going to be deprecated? (I'm not talking about safe_substitute, which as I understand it offers unique capabilities)   Similar questions and why I think they're not duplicates:   Python string formatting: % vs. .format  treats only methods 1 and 2, and asks which one is better; my question is explicitly about deprecation in the light of the Zen of Python String formatting options: pros and cons  treats only methods 1a and 1b in the question, 1 and 2 in the answer, and also nothing about deprecation advanced string formatting vs template strings  mostly about methods 1 and 3, and doesn't address deprecation String formatting expressions (Python)  answer mentions that the original '%' approach is planned to be deprecated. But what's the difference between planned to be deprecated, pending deprecation and actual deprecation? And the printf-style method doesn't raise even a PendingDeprecationWarning, so is this really going to be deprecated? This post is also quite old, so the information may be outdated.   See also PEP 502: String Interpolation - Extended Discussion     ","Q_Votes":"79"},{"Q_Title":"Pythons many ways of string formatting  are the older ones (going to be) deprecated?","A_Content":"  Looking at the older Python docs and PEP 3101 there was a statement that the % operator will be deprecated and removed from the language in the future. The following statement was in the Python docs for Python 3.0, 3.1, and 3.2:     Since str.format() is quite new, a lot of Python code still uses the %   operator. However, because this old style of formatting will   eventually be removed from the language, str.format() should generally   be used.   If you go to the same section in Python 3.3 and 3.4 docs, you will see that statement has been removed. I also cannot find any other statement anywhere else in the documentation indicating that the operator will be depreciated or removed from the language. It's also important to note that PEP3101 has not been modified in over two and a half years (Fri, 30 Sep 2011).  Update  PEP461 Adding % formatting to bytes and bytearray is accepted and should be part of Python 3.5 or 3.6. It's another sign that the % operator is alive and kicking.     ","Language":"Python","Tags":["python","printf","string-formatting","deprecated","backwards-compatibility"],"URL":"https://stackoverflow.com/questions/13451989/pythons-many-ways-of-string-formatting-are-the-older-ones-going-to-be-deprec","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    Python has at least six ways of formatting a string:  In [1]: world = \"Earth\"  # method 1a In [2]: \"Hello, %s\" % world Out[2]: 'Hello, Earth'  # method 1b In [3]: \"Hello, %(planet)s\" % {\"planet\": world} Out[3]: 'Hello, Earth'  # method 2a In [4]: \"Hello, {0}\".format(world) Out[4]: 'Hello, Earth'  # method 2b In [5]: \"Hello, {planet}\".format(planet=world) Out[5]: 'Hello, Earth'  # method 2c In [6]: f\"Hello, {world}\" Out[6]: 'Hello, Earth'  In [7]: from string import Template  # method 3 In [8]: Template(\"Hello, $planet\").substitute(planet=world) Out[8]: 'Hello, Earth'   A brief history of the different methods:   printf-style formatting has been around since Pythons infancy The Template class was introduced in Python 2.4 The format method was introduced in Python 2.6  f-strings were introduced in Python 3.6   My questions are:   Is printf-style formatting deprecated or going to be deprecated? In the Template class, is the substitute method deprecated or going to be deprecated? (I'm not talking about safe_substitute, which as I understand it offers unique capabilities)   Similar questions and why I think they're not duplicates:   Python string formatting: % vs. .format  treats only methods 1 and 2, and asks which one is better; my question is explicitly about deprecation in the light of the Zen of Python String formatting options: pros and cons  treats only methods 1a and 1b in the question, 1 and 2 in the answer, and also nothing about deprecation advanced string formatting vs template strings  mostly about methods 1 and 3, and doesn't address deprecation String formatting expressions (Python)  answer mentions that the original '%' approach is planned to be deprecated. But what's the difference between planned to be deprecated, pending deprecation and actual deprecation? And the printf-style method doesn't raise even a PendingDeprecationWarning, so is this really going to be deprecated? This post is also quite old, so the information may be outdated.   See also PEP 502: String Interpolation - Extended Discussion     ","Q_Votes":"79"},{"Q_Title":"Pythons many ways of string formatting  are the older ones (going to be) deprecated?","A_Content":"  Guido's latest position on this seems to be indicated here:  Whats New In Python 3.0     PEP 3101: A New Approach To String Formatting      A new system for built-in string formatting operations replaces    the % string formatting operator. (However, the % operator is still   supported; it will be deprecated in Python 3.1 and removed from the   language at some later time.) Read PEP 3101 for the full scoop.   And the PEP3101 itself, which has the last modified dating back to (Fri, 30 Sep 2011), so no progress as of late on that one, I suppose.     ","Language":"Python","Tags":["python","printf","string-formatting","deprecated","backwards-compatibility"],"URL":"https://stackoverflow.com/questions/13451989/pythons-many-ways-of-string-formatting-are-the-older-ones-going-to-be-deprec","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Python has at least six ways of formatting a string:  In [1]: world = \"Earth\"  # method 1a In [2]: \"Hello, %s\" % world Out[2]: 'Hello, Earth'  # method 1b In [3]: \"Hello, %(planet)s\" % {\"planet\": world} Out[3]: 'Hello, Earth'  # method 2a In [4]: \"Hello, {0}\".format(world) Out[4]: 'Hello, Earth'  # method 2b In [5]: \"Hello, {planet}\".format(planet=world) Out[5]: 'Hello, Earth'  # method 2c In [6]: f\"Hello, {world}\" Out[6]: 'Hello, Earth'  In [7]: from string import Template  # method 3 In [8]: Template(\"Hello, $planet\").substitute(planet=world) Out[8]: 'Hello, Earth'   A brief history of the different methods:   printf-style formatting has been around since Pythons infancy The Template class was introduced in Python 2.4 The format method was introduced in Python 2.6  f-strings were introduced in Python 3.6   My questions are:   Is printf-style formatting deprecated or going to be deprecated? In the Template class, is the substitute method deprecated or going to be deprecated? (I'm not talking about safe_substitute, which as I understand it offers unique capabilities)   Similar questions and why I think they're not duplicates:   Python string formatting: % vs. .format  treats only methods 1 and 2, and asks which one is better; my question is explicitly about deprecation in the light of the Zen of Python String formatting options: pros and cons  treats only methods 1a and 1b in the question, 1 and 2 in the answer, and also nothing about deprecation advanced string formatting vs template strings  mostly about methods 1 and 3, and doesn't address deprecation String formatting expressions (Python)  answer mentions that the original '%' approach is planned to be deprecated. But what's the difference between planned to be deprecated, pending deprecation and actual deprecation? And the printf-style method doesn't raise even a PendingDeprecationWarning, so is this really going to be deprecated? This post is also quite old, so the information may be outdated.   See also PEP 502: String Interpolation - Extended Discussion     ","Q_Votes":"79"},{"Q_Title":"What are the differences between Conda and Anaconda","A_Content":"  conda is the package manager. Anaconda is a set of about a hundred packages including conda, numpy, scipy, ipython notebook, and so on.   You installed Miniconda, which is a smaller alternative to Anaconda that is just conda and its dependencies, not those listed above.   Once you have Miniconda, you can easily install Anaconda into it with conda install anaconda.     ","Language":"Python","Tags":["python","anaconda","conda"],"URL":"https://stackoverflow.com/questions/30034840/what-are-the-differences-between-conda-and-anaconda","A_Votes":"131","_type":"dict","isAccepted":"Yes","Q_Content":"    Post-question update:  See Introduction to Conda for more details.    The problem:  I first installed Anaconda on my ubuntu at ~/anaconda, when I was trying to update my anaconda, according to the documentation from Continuum Analytics, I should use the following commands:  conda update conda conda update anaconda   Then I realized that I did not have conda installed, so I installed it using the documentation from here.  After conda is installed, when I run conda update anaconda, I got the following error:     Error: package 'anaconda' is not installed in /home/xiang/miniconda   It appears conda is assuming my anaconda is installed under /home/xiang/miniconda which is NOT true.  The questions:   What is the differences between conda and anaconda? How can I tell conda where my anaconda is installed?      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  Sure you can do this. You just have to take to raw_decode directly. This implementation loads the whole file into memory and operates on that string (much as json.load does); if you have large files you can modify it to only read from the file as necessary without much difficulty.  import json from json.decoder import WHITESPACE  def iterload(string_or_fp, cls=json.JSONDecoder, **kwargs):     if isinstance(string_or_fp, file):         string = string_or_fp.read()     else:         string = str(string_or_fp)      decoder = cls(**kwargs)     idx = WHITESPACE.match(string, 0).end()     while idx < len(string):         obj, end = decoder.raw_decode(string, idx)         yield obj         idx = WHITESPACE.match(string, end).end()   Usage: just as you requested, it's a generator.     ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"24","_type":"dict","isAccepted":"Yes","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  JSON generally isn't very good for this sort of incremental use; there's no standard way to serialise multiple objects so that they can easily be loaded one at a time, without parsing the whole lot.  The object per line solution that you're using is seen elsewhere too. Scrapy calls it 'JSON lines':   http://doc.scrapy.org/topics/exporters.html#jsonlinesitemexporter http://www.enricozini.org/2011/tips/python-stream-json/   You can do it slightly more Pythonically:  for jsonline in f:     yield json.loads(jsonline)   # or do the processing in this loop   I think this is about the best way - it doesn't rely on any third party libraries, and it's easy to understand what's going on. I've used it in some of my own code as well.     ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  This is a pretty nasty problem actually because you have to stream in lines, but pattern match across multiple lines against braces, but also pattern match json. It's a sort of json-preparse followed by a json parse. Json is, in comparison to other formats, easy to parse so it's not always necessary to go for a parsing library, nevertheless, how to should we solve these conflicting issues?  Generators to the rescue!  The beauty of generators for a problem like this is you can stack them on top of each other gradually abstracting away the difficulty of the problem whilst maintaining laziness. I also considered using the mechanism for passing back values into a generator (send()) but fortunately found I didn't need to use that.  To solve the first of the problems you need some sort of streamingfinditer, as a streaming version of re.finditer. My attempt at this below pulls in lines as needed (uncomment the debug statement to see) whilst still returning matches. I actually then modified it slightly to yield non-matched lines as well as matches (marked as 0 or 1 in the first part of the yielded tuple).  import re  def streamingfinditer(pat,stream):   for s in stream: #    print \"Read next line: \" + s     while 1:       m = re.search(pat,s)       if not m:         yield (0,s)         break       yield (1,m.group())       s = re.split(pat,s,1)[1]   With that, it's then possible to match up until braces, account each time for whether the braces are balanced, and then return either simple or compound objects as appropriate.  braces='{}[]' whitespaceesc=' \\t' bracesesc='\\\\'+'\\\\'.join(braces) balancemap=dict(zip(braces,[1,-1,1,-1])) bracespat='['+bracesesc+']' nobracespat='[^'+bracesesc+']*' untilbracespat=nobracespat+bracespat  def simpleorcompoundobjects(stream):   obj = \"\"   unbalanced = 0   for (c,m) in streamingfinditer(re.compile(untilbracespat),stream):     if (c == 0): # remainder of line returned, nothing interesting       if (unbalanced == 0):         yield (0,m)       else:         obj += m     if (c == 1): # match returned       if (unbalanced == 0):         yield (0,m[:-1])         obj += m[-1]       else:         obj += m       unbalanced += balancemap[m[-1]]       if (unbalanced == 0):         yield (1,obj)         obj=\"\"    This returns tuples as follows:  (0,\"String of simple non-braced objects easy to parse\") (1,\"{ 'Compound' : 'objects' }\")   Basically that's the nasty part done. We now just have to do the final level of parsing as we see fit. For example we can use Jeremy Roman's iterload function (Thanks!) to do parsing for a single line:  def streamingiterload(stream):   for c,o in simpleorcompoundobjects(stream):     for x in iterload(o):       yield x    Test it:  of = open(\"test.json\",\"w\")  of.write(\"\"\"[ \"hello\" ] { \"goodbye\" : 1 } 1 2 { } 2 9 78  4 5 { \"animals\" : [ \"dog\" , \"lots of mice\" ,  \"cat\" ] } \"\"\") of.close() // open & stream the json f = open(\"test.json\",\"r\") for o in streamingiterload(f.readlines()):   print o f.close()   I get these results (and if you turn on that debug line, you'll see it pulls in the lines as needed):  [u'hello'] {u'goodbye': 1} 1 2 {} 2 9 78 4 5 {u'animals': [u'dog', u'lots of mice', u'cat']}   This won't work for all situations. Due to the implementation of the json library, it is impossible to work entirely correctly without reimplementing the parser yourself.     ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  A little late maybe, but I had this exact problem (well, more or less). My standard solution for these problems is usually to just do a regex split on some well-known root object, but in my case it was impossible. The only feasible way to do this generically is to implement a proper tokenizer.  After not finding a generic-enough and reasonably well-performing solution, I ended doing this myself, writing the splitstream module. It is a pre-tokenizer that understands JSON and XML and splits a continuous stream into multiple chunks for parsing (it leaves the actual parsing up to you though). To get some kind of performance out of it, it is written as a C module.  Example:  from splitstream import splitfile  for jsonstr in splitfile(sys.stdin, format=\"json\")):     yield json.loads(jsonstr)      ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  Here's a much, much simpler solution.  The secret is to try, fail, and use the information in the exception to parse correctly.  The only limitation is the file must be seekable.  def stream_read_json(fn):     import json     start_pos = 0     with open(fn, 'r') as f:         while True:             try:                 obj = json.load(f)                 yield obj                 return             except json.JSONDecodeError as e:                 f.seek(start_pos)                 json_str = f.read(e.pos)                 obj = json.loads(json_str)                 start_pos += e.pos                 yield obj   Edit:  just noticed that this will only work for Python >=3.5.  For earlier, failures return a ValueError, and you have to parse out the position from the string, e.g.  def stream_read_json(fn):     import json     import re     start_pos = 0     with open(fn, 'r') as f:         while True:             try:                 obj = json.load(f)                 yield obj                 return             except ValueError as e:                 f.seek(start_pos)                 end_pos = int(re.match('Extra data: line \\d+ column \\d+ .*\\(char (\\d+).*\\)',                                     e.args[0]).groups()[0])                 json_str = f.read(end_pos)                 obj = json.loads(json_str)                 start_pos += end_pos                 yield obj      ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  I'd like to provide a solution. The key thought is to \"try\" to decode: if it fails, give it more feed, otherwise use the offset information to prepare next decoding.  However the current json module can't tolerate SPACE in head of string to be decoded, so I have to strip them off.  import sys import json  def iterload(file):     buffer = \"\"     dec = json.JSONDecoder()     for line in file:                  buffer = buffer.strip(\" \\n\\r\\t\") + line.strip(\" \\n\\r\\t\")         while(True):             try:                 r = dec.raw_decode(buffer)             except:                 break             yield r[0]             buffer = buffer[r[1]:].strip(\" \\n\\r\\t\")   for o in iterload(sys.stdin):     print(\"Working on a\", type(o),  o)   ========================= I have tested for several txt files, and it works fine. (in1.txt)  {\"foo\": [\"bar\", \"baz\"] }  1 2 [   ]  4 {\"foo1\": [\"bar1\", {\"foo2\":{\"A\":1, \"B\":3}, \"DDD\":4}] }  5   6   (in2.txt)  {\"foo\" : [\"bar\",   \"baz\"]   }  1 2 [ ] 4 5 6   (in.txt, your initial)  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   (output for Benedict's testcase)  python test.py < in.txt ('Working on a', <type 'list'>, [u'hello']) ('Working on a', <type 'dict'>, {u'goodbye': 1}) ('Working on a', <type 'int'>, 1) ('Working on a', <type 'int'>, 2) ('Working on a', <type 'dict'>, {}) ('Working on a', <type 'int'>, 2) ('Working on a', <type 'int'>, 9) ('Working on a', <type 'int'>, 78) ('Working on a', <type 'int'>, 4) ('Working on a', <type 'int'>, 5) ('Working on a', <type 'dict'>, {u'animals': [u'dog', u'lots of mice', u'cat']})      ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  I used @wuilang's elegant solution. The simple approach -- read a byte, try to decode, read a byte, try to decode, ... -- worked, but unfortunately it was very slow.  In my case, I was trying to read \"pretty-printed\" JSON objects of the same object type from a file. This allowed me to optimize the approach; I could read the file line-by-line, only decoding when I found a line that contained exactly \"}\":  def iterload(stream):     buf = \"\"     dec = json.JSONDecoder()     for line in stream:         line = line.rstrip()         buf = buf + line         if line == \"}\":             yield dec.raw_decode(buf)             buf = \"\"   If you happen to be working with one-per-line compact JSON that escapes newlines in string literals, then you can safely simplify this approach even more:  def iterload(stream):     dec = json.JSONDecoder()     for line in stream:         yield dec.raw_decode(line)   Obviously, these simple approaches only work for very specific kinds of JSON. However, if these assumptions hold, these solutions work correctly and quickly.     ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  Here's mine:  import simplejson as json from simplejson import JSONDecodeError class StreamJsonListLoader():     \"\"\"     When you have a big JSON file containint a list, such as      [{         ...     },     {         ...     },     {         ...     },     ...     ]      And it's too big to be practically loaded into memory and parsed by json.load,     This class comes to the rescue. It lets you lazy-load the large json list.     \"\"\"      def __init__(self, filename_or_stream):         if type(filename_or_stream) == str:             self.stream = open(filename_or_stream)         else:             self.stream = filename_or_stream          if not self.stream.read(1) == '[':             raise NotImplementedError('Only JSON-streams of lists (that start with a [) are supported.')      def __iter__(self):         return self      def next(self):         read_buffer = self.stream.read(1)         while True:             try:                 json_obj = json.loads(read_buffer)                  if not self.stream.read(1) in [',',']']:                     raise Exception('JSON seems to be malformed: object is not followed by comma (,) or end of list (]).')                 return json_obj             except JSONDecodeError:                 next_char = self.stream.read(1)                 read_buffer += next_char                 while next_char != '}':                     next_char = self.stream.read(1)                     if next_char == '':                         raise StopIteration                     read_buffer += next_char      ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  I believe a better way of doing it would be to use a state machine. Below is a sample code that I worked out by converting a NodeJS code on below link to Python 3 (used nonlocal keyword only available in Python 3, code won't work on Python 2)  Edit-1: Updated and made code compatible with Python 2  Edit-2: Updated and added a Python3 only version as well  https://gist.github.com/creationix/5992451  Python 3 only version  # A streaming byte oriented JSON parser.  Feed it a single byte at a time and # it will emit complete objects as it comes across them.  Whitespace within and # between objects is ignored.  This means it can parse newline delimited JSON. import math   def json_machine(emit, next_func=None):     def _value(byte_data):         if not byte_data:             return          if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _value  # Ignore whitespace          if byte_data == 0x22:  # \"             return string_machine(on_value)          if byte_data == 0x2d or (0x30 <= byte_data < 0x40):  # - or 0-9             return number_machine(byte_data, on_number)          if byte_data == 0x7b:  #:             return object_machine(on_value)          if byte_data == 0x5b:  # [             return array_machine(on_value)          if byte_data == 0x74:  # t             return constant_machine(TRUE, True, on_value)          if byte_data == 0x66:  # f             return constant_machine(FALSE, False, on_value)          if byte_data == 0x6e:  # n             return constant_machine(NULL, None, on_value)          if next_func == _value:             raise Exception(\"Unexpected 0x\" + str(byte_data))          return next_func(byte_data)      def on_value(value):         emit(value)         return next_func      def on_number(number, byte):         emit(number)         return _value(byte)      next_func = next_func or _value     return _value   TRUE = [0x72, 0x75, 0x65] FALSE = [0x61, 0x6c, 0x73, 0x65] NULL = [0x75, 0x6c, 0x6c]   def constant_machine(bytes_data, value, emit):     i = 0     length = len(bytes_data)      def _constant(byte_data):         nonlocal i         if byte_data != bytes_data[i]:             i += 1             raise Exception(\"Unexpected 0x\" + str(byte_data))          i += 1         if i < length:             return _constant         return emit(value)      return _constant   def string_machine(emit):     string = \"\"      def _string(byte_data):         nonlocal string          if byte_data == 0x22:  # \"             return emit(string)          if byte_data == 0x5c:  # \\             return _escaped_string          if byte_data & 0x80:  # UTF-8 handling             return utf8_machine(byte_data, on_char_code)          if byte_data < 0x20:  # ASCII control character             raise Exception(\"Unexpected control character: 0x\" + str(byte_data))          string += chr(byte_data)         return _string      def _escaped_string(byte_data):         nonlocal string          if byte_data == 0x22 or byte_data == 0x5c or byte_data == 0x2f:  # \" \\ /             string += chr(byte_data)             return _string          if byte_data == 0x62:  # b             string += \"\\b\"             return _string          if byte_data == 0x66:  # f             string += \"\\f\"             return _string          if byte_data == 0x6e:  # n             string += \"\\n\"             return _string          if byte_data == 0x72:  # r             string += \"\\r\"             return _string          if byte_data == 0x74:  # t             string += \"\\t\"             return _string          if byte_data == 0x75:  # u             return hex_machine(on_char_code)      def on_char_code(char_code):         nonlocal string         string += chr(char_code)         return _string      return _string   # Nestable state machine for UTF-8 Decoding. def utf8_machine(byte_data, emit):     left = 0     num = 0      def _utf8(byte_data):         nonlocal num, left         if (byte_data & 0xc0) != 0x80:             raise Exception(\"Invalid byte in UTF-8 character: 0x\" + byte_data.toString(16))          left = left - 1          num |= (byte_data & 0x3f) << (left * 6)         if left:             return _utf8         return emit(num)      if 0xc0 <= byte_data < 0xe0:  # 2-byte UTF-8 Character         left = 1         num = (byte_data & 0x1f) << 6         return _utf8      if 0xe0 <= byte_data < 0xf0:  # 3-byte UTF-8 Character         left = 2         num = (byte_data & 0xf) << 12         return _utf8      if 0xf0 <= byte_data < 0xf8:  # 4-byte UTF-8 Character         left = 3         num = (byte_data & 0x07) << 18         return _utf8      raise Exception(\"Invalid byte in UTF-8 string: 0x\" + str(byte_data))   # Nestable state machine for hex escaped characters def hex_machine(emit):     left = 4     num = 0      def _hex(byte_data):         nonlocal num, left          if 0x30 <= byte_data < 0x40:             i = byte_data - 0x30         elif 0x61 <= byte_data <= 0x66:             i = byte_data - 0x57         elif 0x41 <= byte_data <= 0x46:             i = byte_data - 0x37         else:             raise Exception(\"Expected hex char in string hex escape\")          left -= 1         num |= i << (left * 4)          if left:             return _hex         return emit(num)      return _hex   def number_machine(byte_data, emit):     sign = 1     number = 0     decimal = 0     esign = 1     exponent = 0      def _mid(byte_data):         if byte_data == 0x2e:  # .             return _decimal          return _later(byte_data)      def _number(byte_data):         nonlocal number         if 0x30 <= byte_data < 0x40:             number = number * 10 + (byte_data - 0x30)             return _number          return _mid(byte_data)      def _start(byte_data):         if byte_data == 0x30:             return _mid          if 0x30 < byte_data < 0x40:             return _number(byte_data)          raise Exception(\"Invalid number: 0x\" + str(byte_data))      if byte_data == 0x2d:  # -         sign = -1         return _start      def _decimal(byte_data):         nonlocal decimal         if 0x30 <= byte_data < 0x40:             decimal = (decimal + byte_data - 0x30) / 10             return _decimal          return _later(byte_data)      def _later(byte_data):         if byte_data == 0x45 or byte_data == 0x65:  # E e             return _esign          return _done(byte_data)      def _esign(byte_data):         nonlocal esign         if byte_data == 0x2b:  # +             return _exponent          if byte_data == 0x2d:  # -             esign = -1             return _exponent          return _exponent(byte_data)      def _exponent(byte_data):         nonlocal exponent         if 0x30 <= byte_data < 0x40:             exponent = exponent * 10 + (byte_data - 0x30)             return _exponent          return _done(byte_data)      def _done(byte_data):         value = sign * (number + decimal)         if exponent:             value *= math.pow(10, esign * exponent)          return emit(value, byte_data)      return _start(byte_data)   def array_machine(emit):     array_data = []      def _array(byte_data):         if byte_data == 0x5d:  # ]             return emit(array_data)          return json_machine(on_value, _comma)(byte_data)      def on_value(value):         array_data.append(value)      def _comma(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _comma  # Ignore whitespace          if byte_data == 0x2c:  # ,             return json_machine(on_value, _comma)          if byte_data == 0x5d:  # ]             return emit(array_data)          raise Exception(\"Unexpected byte: 0x\" + str(byte_data) + \" in array body\")      return _array   def object_machine(emit):     object_data = {}     key = None      def _object(byte_data):         if byte_data == 0x7d:  #             return emit(object_data)          return _key(byte_data)      def _key(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _object  # Ignore whitespace          if byte_data == 0x22:             return string_machine(on_key)          raise Exception(\"Unexpected byte: 0x\" + str(byte_data))      def on_key(result):         nonlocal key         key = result         return _colon      def _colon(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _colon  # Ignore whitespace          if byte_data == 0x3a:  # :             return json_machine(on_value, _comma)          raise Exception(\"Unexpected byte: 0x\" + str(byte_data))      def on_value(value):         object_data[key] = value      def _comma(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _comma  # Ignore whitespace          if byte_data == 0x2c:  # ,             return _key          if byte_data == 0x7d:  #             return emit(object_data)          raise Exception(\"Unexpected byte: 0x\" + str(byte_data))      return _object   Python 2 compatible version  # A streaming byte oriented JSON parser.  Feed it a single byte at a time and # it will emit complete objects as it comes across them.  Whitespace within and # between objects is ignored.  This means it can parse newline delimited JSON. import math   def json_machine(emit, next_func=None):     def _value(byte_data):         if not byte_data:             return          if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _value  # Ignore whitespace          if byte_data == 0x22:  # \"             return string_machine(on_value)          if byte_data == 0x2d or (0x30 <= byte_data < 0x40):  # - or 0-9             return number_machine(byte_data, on_number)          if byte_data == 0x7b:  #:             return object_machine(on_value)          if byte_data == 0x5b:  # [             return array_machine(on_value)          if byte_data == 0x74:  # t             return constant_machine(TRUE, True, on_value)          if byte_data == 0x66:  # f             return constant_machine(FALSE, False, on_value)          if byte_data == 0x6e:  # n             return constant_machine(NULL, None, on_value)          if next_func == _value:             raise Exception(\"Unexpected 0x\" + str(byte_data))          return next_func(byte_data)      def on_value(value):         emit(value)         return next_func      def on_number(number, byte):         emit(number)         return _value(byte)      next_func = next_func or _value     return _value   TRUE = [0x72, 0x75, 0x65] FALSE = [0x61, 0x6c, 0x73, 0x65] NULL = [0x75, 0x6c, 0x6c]   def constant_machine(bytes_data, value, emit):     local_data = {\"i\": 0, \"length\": len(bytes_data)}      def _constant(byte_data):         # nonlocal i, length         if byte_data != bytes_data[local_data[\"i\"]]:             local_data[\"i\"] += 1             raise Exception(\"Unexpected 0x\" + byte_data.toString(16))          local_data[\"i\"] += 1          if local_data[\"i\"] < local_data[\"length\"]:             return _constant         return emit(value)      return _constant   def string_machine(emit):     local_data = {\"string\": \"\"}      def _string(byte_data):         # nonlocal string          if byte_data == 0x22:  # \"             return emit(local_data[\"string\"])          if byte_data == 0x5c:  # \\             return _escaped_string          if byte_data & 0x80:  # UTF-8 handling             return utf8_machine(byte_data, on_char_code)          if byte_data < 0x20:  # ASCII control character             raise Exception(\"Unexpected control character: 0x\" + byte_data.toString(16))          local_data[\"string\"] += chr(byte_data)         return _string      def _escaped_string(byte_data):         # nonlocal string          if byte_data == 0x22 or byte_data == 0x5c or byte_data == 0x2f:  # \" \\ /             local_data[\"string\"] += chr(byte_data)             return _string          if byte_data == 0x62:  # b             local_data[\"string\"] += \"\\b\"             return _string          if byte_data == 0x66:  # f             local_data[\"string\"] += \"\\f\"             return _string          if byte_data == 0x6e:  # n             local_data[\"string\"] += \"\\n\"             return _string          if byte_data == 0x72:  # r             local_data[\"string\"] += \"\\r\"             return _string          if byte_data == 0x74:  # t             local_data[\"string\"] += \"\\t\"             return _string          if byte_data == 0x75:  # u             return hex_machine(on_char_code)      def on_char_code(char_code):         # nonlocal string         local_data[\"string\"] += chr(char_code)         return _string      return _string   # Nestable state machine for UTF-8 Decoding. def utf8_machine(byte_data, emit):     local_data = {\"left\": 0, \"num\": 0}      def _utf8(byte_data):         # nonlocal num, left         if (byte_data & 0xc0) != 0x80:             raise Exception(\"Invalid byte in UTF-8 character: 0x\" + byte_data.toString(16))          local_data[\"left\"] -= 1          local_data[\"num\"] |= (byte_data & 0x3f) << (local_data[\"left\"] * 6)         if local_data[\"left\"]:             return _utf8         return emit(local_data[\"num\"])      if 0xc0 <= byte_data < 0xe0:  # 2-byte UTF-8 Character         local_data[\"left\"] = 1         local_data[\"num\"] = (byte_data & 0x1f) << 6         return _utf8      if 0xe0 <= byte_data < 0xf0:  # 3-byte UTF-8 Character         local_data[\"left\"] = 2         local_data[\"num\"] = (byte_data & 0xf) << 12         return _utf8      if 0xf0 <= byte_data < 0xf8:  # 4-byte UTF-8 Character         local_data[\"left\"] = 3         local_data[\"num\"] = (byte_data & 0x07) << 18         return _utf8      raise Exception(\"Invalid byte in UTF-8 string: 0x\" + str(byte_data))   # Nestable state machine for hex escaped characters def hex_machine(emit):     local_data = {\"left\": 4, \"num\": 0}      def _hex(byte_data):         # nonlocal num, left         i = 0  # Parse the hex byte         if 0x30 <= byte_data < 0x40:             i = byte_data - 0x30         elif 0x61 <= byte_data <= 0x66:             i = byte_data - 0x57         elif 0x41 <= byte_data <= 0x46:             i = byte_data - 0x37         else:             raise Exception(\"Expected hex char in string hex escape\")          local_data[\"left\"] -= 1         local_data[\"num\"] |= i << (local_data[\"left\"] * 4)          if local_data[\"left\"]:             return _hex         return emit(local_data[\"num\"])      return _hex   def number_machine(byte_data, emit):     local_data = {\"sign\": 1, \"number\": 0, \"decimal\": 0, \"esign\": 1, \"exponent\": 0}      def _mid(byte_data):         if byte_data == 0x2e:  # .             return _decimal          return _later(byte_data)      def _number(byte_data):         # nonlocal number         if 0x30 <= byte_data < 0x40:             local_data[\"number\"] = local_data[\"number\"] * 10 + (byte_data - 0x30)             return _number          return _mid(byte_data)      def _start(byte_data):         if byte_data == 0x30:             return _mid          if 0x30 < byte_data < 0x40:             return _number(byte_data)          raise Exception(\"Invalid number: 0x\" + byte_data.toString(16))      if byte_data == 0x2d:  # -         local_data[\"sign\"] = -1         return _start      def _decimal(byte_data):         # nonlocal decimal         if 0x30 <= byte_data < 0x40:             local_data[\"decimal\"] = (local_data[\"decimal\"] + byte_data - 0x30) / 10             return _decimal          return _later(byte_data)      def _later(byte_data):         if byte_data == 0x45 or byte_data == 0x65:  # E e             return _esign          return _done(byte_data)      def _esign(byte_data):         # nonlocal esign         if byte_data == 0x2b:  # +             return _exponent          if byte_data == 0x2d:  # -             local_data[\"esign\"] = -1             return _exponent          return _exponent(byte_data)      def _exponent(byte_data):         # nonlocal exponent         if 0x30 <= byte_data < 0x40:             local_data[\"exponent\"] = local_data[\"exponent\"] * 10 + (byte_data - 0x30)             return _exponent          return _done(byte_data)      def _done(byte_data):         value = local_data[\"sign\"] * (local_data[\"number\"] + local_data[\"decimal\"])         if local_data[\"exponent\"]:             value *= math.pow(10, local_data[\"esign\"] * local_data[\"exponent\"])          return emit(value, byte_data)      return _start(byte_data)   def array_machine(emit):     local_data = {\"array_data\": []}      def _array(byte_data):         if byte_data == 0x5d:  # ]             return emit(local_data[\"array_data\"])          return json_machine(on_value, _comma)(byte_data)      def on_value(value):         # nonlocal array_data         local_data[\"array_data\"].append(value)      def _comma(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _comma  # Ignore whitespace          if byte_data == 0x2c:  # ,             return json_machine(on_value, _comma)          if byte_data == 0x5d:  # ]             return emit(local_data[\"array_data\"])          raise Exception(\"Unexpected byte: 0x\" + str(byte_data) + \" in array body\")      return _array   def object_machine(emit):     local_data = {\"object_data\": {}, \"key\": \"\"}      def _object(byte_data):         # nonlocal object_data, key         if byte_data == 0x7d:  #             return emit(local_data[\"object_data\"])          return _key(byte_data)      def _key(byte_data):         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _object  # Ignore whitespace          if byte_data == 0x22:             return string_machine(on_key)          raise Exception(\"Unexpected byte: 0x\" + byte_data.toString(16))      def on_key(result):         # nonlocal object_data, key         local_data[\"key\"] = result         return _colon      def _colon(byte_data):         # nonlocal object_data, key         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _colon  # Ignore whitespace          if byte_data == 0x3a:  # :             return json_machine(on_value, _comma)          raise Exception(\"Unexpected byte: 0x\" + str(byte_data))      def on_value(value):         # nonlocal object_data, key         local_data[\"object_data\"][local_data[\"key\"]] = value      def _comma(byte_data):         # nonlocal object_data         if byte_data == 0x09 or byte_data == 0x0a or byte_data == 0x0d or byte_data == 0x20:             return _comma  # Ignore whitespace          if byte_data == 0x2c:  # ,             return _key          if byte_data == 0x7d:  #             return emit(local_data[\"object_data\"])          raise Exception(\"Unexpected byte: 0x\" + str(byte_data))      return _object   Testing it  if __name__ == \"__main__\":     test_json = \"\"\"[1,2,\"3\"] {\"name\":      \"tarun\"} 1 2      3 [{\"name\":\"a\",      \"data\": [1,     null,2]}] \"\"\"     def found_json(data):         print(data)      state = json_machine(found_json)      for char in test_json:         state = state(ord(char))   The output of the same is  [1, 2, '3'] {'name': 'tarun'} 1 2 3 [{'name': 'a', 'data': [1, None, 2]}]      ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"How I can I lazily read multiple JSON values from a file/stream in Python?","A_Content":"  If you use a json.JSONDecoder instance you can use raw_decode member function. It returns a tuple of python representation of the JSON value and an index to where the parsing stopped. This makes it easy to slice (or seek in a stream object) the remaining JSON values. I'm not so happy about the extra while loop to skip over the white space between the different JSON values in the input but it gets the job done in my opinion.  import json  def yield_multiple_value(f):     '''     parses multiple JSON values from a file.     '''     vals_str = f.read()     decoder = json.JSONDecoder()     try:         nread = 0         while nread < len(vals_str):             val, n = decoder.raw_decode(vals_str[nread:])             nread += n             # Skip over whitespace because of bug, below.             while nread < len(vals_str) and vals_str[nread].isspace():                 nread += 1             yield val     except json.JSONDecodeError as e:         pass     return   The next version is much shorter and eats the part of the string that is already parsed. It seems that for some reason a second call json.JSONDecoder.raw_decode() seems to fail when the first character in the string is a whitespace, that is also the reason why I skip over the whitespace in the whileloop above ...  def yield_multiple_value(f):     '''     parses multiple JSON values from a file.     '''     vals_str = f.read()     decoder = json.JSONDecoder()     while vals_str:         val, n = decoder.raw_decode(vals_str)         #remove the read characters from the start.         vals_str = vals_str[n:]         # remove leading white space because a second call to decoder.raw_decode()         # fails when the string starts with whitespace, and         # I don't understand why...         vals_str = vals_str.lstrip()         yield val     return   In the documentation about the json.JSONDecoder class the method raw_decode https://docs.python.org/3/library/json.html#encoders-and-decoders contains the following:     This can be used to decode a JSON document from a string that may have   extraneous data at the end.   And this extraneous data can easily be another JSON value. In other words the method might be written with this purpose in mind.  With the input.txt using the upper function I obtain the example output as presented in the original question.     ","Language":"Python","Tags":["python","json","serialization"],"URL":"https://stackoverflow.com/questions/6886283/how-i-can-i-lazily-read-multiple-json-values-from-a-file-stream-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to read multiple JSON objects from a file/stream in Python, one at a time. Unfortunately json.load() just .read()s until end-of-file; there doesn't seem to be any way to use it to read a single object or to lazily iterate over the objects.  Is there any way to do this? Using the standard library would be ideal, but if there's a third-party library I'd use that instead.  At the moment I'm putting each object on a separate line and using json.loads(f.readline()), but I would really prefer not to need to do this.  Example Use  example.py  import my_json as json import sys  for o in json.iterload(sys.stdin):     print(\"Working on a\", type(o))   in.txt  {\"foo\": [\"bar\", \"baz\"]} 1 2 [] 4 5 6   example session  $ python3.2 example.py < in.txt Working on a dict Working on a int Working on a int Working on a list Working on a int Working on a int Working on a int      ","Q_Votes":"79"},{"Q_Title":"Why does CSV file contain a blank line in between each data line when outputting with Dictwriter in Python [duplicate]","A_Content":"  By default, the classes in the csv module use Windows-style line terminators (\\r\\n) rather than Unix-style (\\n). Could this be whats causing the apparent double line breaks?  If so, you can override it in the DictWriter constructor:  output = csv.DictWriter(open('file3.csv','w'), delimiter=',', lineterminator='\\n', fieldnames=headers)      ","Language":"Python","Tags":["python","csv","dictionary"],"URL":"https://stackoverflow.com/questions/8746908/why-does-csv-file-contain-a-blank-line-in-between-each-data-line-when-outputting","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              CSV file written with Python has blank lines between each row                                        6 answers                                          I am using DictWriter to output data in a dictionary to a csv file.  Why does the CSV file have a blank line in between each data line?  It's not a huge deal, but my dataset is big and doesn't fit into one csv file because it has too many lines since the \"double-spacing\" doubles the number of lines in the file.  My code for writing to the dictionary is:  headers=['id', 'year', 'activity', 'lineitem', 'datum'] output = csv.DictWriter(open('file3.csv','w'), delimiter=',', fieldnames=headers) output.writerow(dict((fn,fn) for fn in headers)) for row in rows:     output.writerow(row)      ","Q_Votes":"79"},{"Q_Title":"Why does CSV file contain a blank line in between each data line when outputting with Dictwriter in Python [duplicate]","A_Content":"  From http://docs.python.org/library/csv.html#csv.writer:     If csvfile is a file object, it must be opened with the b flag on   platforms where that makes a difference.   In other words, when opening the file you pass 'wb' as opposed to 'w'. You can also use a with statement to close the file when you're done writing to it. Tested example below:  from __future__ import with_statement # not necessary in newer versions import csv headers=['id', 'year', 'activity', 'lineitem', 'datum'] with open('file3.csv','wb') as fou: # note: 'wb' instead of 'w'     output = csv.DictWriter(fou,delimiter=',',fieldnames=headers)     output.writerow(dict((fn,fn) for fn in headers))     output.writerows(rows)      ","Language":"Python","Tags":["python","csv","dictionary"],"URL":"https://stackoverflow.com/questions/8746908/why-does-csv-file-contain-a-blank-line-in-between-each-data-line-when-outputting","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              CSV file written with Python has blank lines between each row                                        6 answers                                          I am using DictWriter to output data in a dictionary to a csv file.  Why does the CSV file have a blank line in between each data line?  It's not a huge deal, but my dataset is big and doesn't fit into one csv file because it has too many lines since the \"double-spacing\" doubles the number of lines in the file.  My code for writing to the dictionary is:  headers=['id', 'year', 'activity', 'lineitem', 'datum'] output = csv.DictWriter(open('file3.csv','w'), delimiter=',', fieldnames=headers) output.writerow(dict((fn,fn) for fn in headers)) for row in rows:     output.writerow(row)      ","Q_Votes":"79"},{"Q_Title":"Why does CSV file contain a blank line in between each data line when outputting with Dictwriter in Python [duplicate]","A_Content":"  Changing the 'w' (write) in this line:  output = csv.DictWriter(open('file3.csv','w'), delimiter=',', fieldnames=headers)   To 'wb' (write binary) fixed this problem for me:  output = csv.DictWriter(open('file3.csv','wb'), delimiter=',', fieldnames=headers)   Python v2.75: Open()  Credit to @dandrejvv for the solution in the comment on the original post above.     ","Language":"Python","Tags":["python","csv","dictionary"],"URL":"https://stackoverflow.com/questions/8746908/why-does-csv-file-contain-a-blank-line-in-between-each-data-line-when-outputting","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              CSV file written with Python has blank lines between each row                                        6 answers                                          I am using DictWriter to output data in a dictionary to a csv file.  Why does the CSV file have a blank line in between each data line?  It's not a huge deal, but my dataset is big and doesn't fit into one csv file because it has too many lines since the \"double-spacing\" doubles the number of lines in the file.  My code for writing to the dictionary is:  headers=['id', 'year', 'activity', 'lineitem', 'datum'] output = csv.DictWriter(open('file3.csv','w'), delimiter=',', fieldnames=headers) output.writerow(dict((fn,fn) for fn in headers)) for row in rows:     output.writerow(row)      ","Q_Votes":"79"},{"Q_Title":"Why does CSV file contain a blank line in between each data line when outputting with Dictwriter in Python [duplicate]","A_Content":"  I just tested your snippet, and their is no double spacing line here. The end-of-line are \\r\\n, so what i would check in your case is:   your editor is reading correctly DOS file no \\n exist in values of your rows dict.   (Note that even by putting a value with \\n, DictWriter automaticly quote the value.)     ","Language":"Python","Tags":["python","csv","dictionary"],"URL":"https://stackoverflow.com/questions/8746908/why-does-csv-file-contain-a-blank-line-in-between-each-data-line-when-outputting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              CSV file written with Python has blank lines between each row                                        6 answers                                          I am using DictWriter to output data in a dictionary to a csv file.  Why does the CSV file have a blank line in between each data line?  It's not a huge deal, but my dataset is big and doesn't fit into one csv file because it has too many lines since the \"double-spacing\" doubles the number of lines in the file.  My code for writing to the dictionary is:  headers=['id', 'year', 'activity', 'lineitem', 'datum'] output = csv.DictWriter(open('file3.csv','w'), delimiter=',', fieldnames=headers) output.writerow(dict((fn,fn) for fn in headers)) for row in rows:     output.writerow(row)      ","Q_Votes":"79"},{"Q_Title":"Return HTTP status code 201 in flask","A_Content":"  You can read about it here.  return render_template('page.html'), 201      ","Language":"Python","Tags":["python","flask","httpresponse"],"URL":"https://stackoverflow.com/questions/7824101/return-http-status-code-201-in-flask","A_Votes":"96","_type":"dict","isAccepted":"Yes","Q_Content":"    We're using Flask for one of our API's and I was just wondering if anyone knew how to return a HTTP response 201?  For errors such as 404 we can call:  from flask import abort abort(404)   But for 201 I get     LookupError: no exception for 201   Do I need to create my own exception like this in the docs?     ","Q_Votes":"79"},{"Q_Title":"Return HTTP status code 201 in flask","A_Content":"  You can use Response to return any http status code.  > from flask import Response > return Response(\"{'a':'b'}\", status=201, mimetype='application/json')      ","Language":"Python","Tags":["python","flask","httpresponse"],"URL":"https://stackoverflow.com/questions/7824101/return-http-status-code-201-in-flask","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    We're using Flask for one of our API's and I was just wondering if anyone knew how to return a HTTP response 201?  For errors such as 404 we can call:  from flask import abort abort(404)   But for 201 I get     LookupError: no exception for 201   Do I need to create my own exception like this in the docs?     ","Q_Votes":"79"},{"Q_Title":"Return HTTP status code 201 in flask","A_Content":"  As lacks suggested send status code in return statement and if you are storing it in some variable like   notfound = 404 invalid = 403 ok = 200   and using  return xyz, notfound   than time make sure its type is int not str. as I faced this small issue also here is list of status code followed globally  http://www.w3.org/Protocols/HTTP/HTRESP.html  Hope it helps.     ","Language":"Python","Tags":["python","flask","httpresponse"],"URL":"https://stackoverflow.com/questions/7824101/return-http-status-code-201-in-flask","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    We're using Flask for one of our API's and I was just wondering if anyone knew how to return a HTTP response 201?  For errors such as 404 we can call:  from flask import abort abort(404)   But for 201 I get     LookupError: no exception for 201   Do I need to create my own exception like this in the docs?     ","Q_Votes":"79"},{"Q_Title":"Return HTTP status code 201 in flask","A_Content":"  In your flask code, you should ideally specify the MIME type as often as possible, as well:  return html_page_str, 200, {'ContentType':'text/html'}  return json.dumps({'success':True}), 200, {'ContentType':'application/json'}  ...etc     ","Language":"Python","Tags":["python","flask","httpresponse"],"URL":"https://stackoverflow.com/questions/7824101/return-http-status-code-201-in-flask","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    We're using Flask for one of our API's and I was just wondering if anyone knew how to return a HTTP response 201?  For errors such as 404 we can call:  from flask import abort abort(404)   But for 201 I get     LookupError: no exception for 201   Do I need to create my own exception like this in the docs?     ","Q_Votes":"79"},{"Q_Title":"MongoDB ORM for Python? [closed]","A_Content":"  Another option is MongoEngine. The ORM for MongoEngine is very similar to the ORM used by Django.  Example (from the tutorial):  class Post(Document):     title = StringField(max_length=120, required=True)     author = ReferenceField(User)  class TextPost(Post):     content = StringField()  class ImagePost(Post):     image_path = StringField()  class LinkPost(Post):     link_url = StringField()      ","Language":"Python","Tags":["python","mongodb"],"URL":"https://stackoverflow.com/questions/2781682/mongodb-orm-for-python","A_Votes":"64","_type":"dict","isAccepted":"Yes","Q_Content":"    im trying to convert from sqlalchemy (sqlite) to using mongodb.  i would like schema vertification.  im looking at mongokit, but i want something with similar to mappers, so that it would save from the object's property, and not a dict.  i would like a mapper so that i can use existing objects without modifying them.     ","Q_Votes":"79"},{"Q_Title":"MongoDB ORM for Python? [closed]","A_Content":"  Not being satisfied with either MongoKit or MongoEngine, I decided to write my own object-oriented interface for Python.  I delegated all queries directly to pymongo, so the query syntax there is the same.  Mostly, it's just an object-wrapper around the results, with some other helpers like database connection pooling, DBRef support, and other convenience methods to make your life easier.   It's called Minimongo and it's available from github.  Happy hacking!  Example:  from minimongo import Model, MongoCollection   class MyObject(Model):      model = MongoCollection(database='test', collection='my_collection')  m = MyObject() m.x = 1 m.field = 'value' m.other = {'list': True} m.save()  x = MyObject({'x': 1, 'y': 2}).save()  objs = MyObject.find({'x': 1}) for o in objs:      print o      ","Language":"Python","Tags":["python","mongodb"],"URL":"https://stackoverflow.com/questions/2781682/mongodb-orm-for-python","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    im trying to convert from sqlalchemy (sqlite) to using mongodb.  i would like schema vertification.  im looking at mongokit, but i want something with similar to mappers, so that it would save from the object's property, and not a dict.  i would like a mapper so that i can use existing objects without modifying them.     ","Q_Votes":"79"},{"Q_Title":"MongoDB ORM for Python? [closed]","A_Content":"  You want MongoKit. It is one layer of abstraction higher than PyMongo. Not sure if you're using Django, but there's also django-mongokit integration.  Example from this blog post. Note that instances of Computer can then reference make/model directly once the structure is defined ( e.g. atari.make, c64.model, ... ). No need for dictionaries:  import datetime  from mongokit import Document  class Computer(Document):      structure = {        'make': unicode,        'model': unicode,        'purchase_date': datetime.datetime,        'cpu_ghz': float,      }      validators = {        'cpu_ghz': lambda x: x > 0,        'make': lambda x: x.strip(),      }      default_values = {        'purchase_date': datetime.datetime.utcnow,      }      use_dot_notation = True      indexes = [        {'fields': ['make']},      ]      ","Language":"Python","Tags":["python","mongodb"],"URL":"https://stackoverflow.com/questions/2781682/mongodb-orm-for-python","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    im trying to convert from sqlalchemy (sqlite) to using mongodb.  i would like schema vertification.  im looking at mongokit, but i want something with similar to mappers, so that it would save from the object's property, and not a dict.  i would like a mapper so that i can use existing objects without modifying them.     ","Q_Votes":"79"},{"Q_Title":"MongoDB ORM for Python? [closed]","A_Content":"  I know I'm really late to this question, but I'm the author of Ming http://merciless.sourceforge.net, a SQLAlchemy-inspired MongoDB validation and ORM engine. It's what we use at SourceForge, and there's a reasonable presentation available at http://www.slideshare.net/rick446/rapid-and-scalable-development-with-mongodb-pymongo-and-ming as well as a case study on migrating from SQLAlchemy to Ming http://www.slideshare.net/__amol__/from-sqlalchemy-to-ming-with-turbogears2. Here's an example of the ORM layer in Ming (from the tutorial):    class WikiPage(MappedClass):      class __mongometa__:         session = session         name = 'wiki_page'      _id = FieldProperty(schema.ObjectId)     title = FieldProperty(str)     text = FieldProperty(str)     comments=RelationProperty('WikiComment')   Queries use the standard MongoDB query syntax (not Django ORM's magic keyword arguments):  WikiComment.query.find(dict(page_id=wp._id))      ","Language":"Python","Tags":["python","mongodb"],"URL":"https://stackoverflow.com/questions/2781682/mongodb-orm-for-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    im trying to convert from sqlalchemy (sqlite) to using mongodb.  i would like schema vertification.  im looking at mongokit, but i want something with similar to mappers, so that it would save from the object's property, and not a dict.  i would like a mapper so that i can use existing objects without modifying them.     ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  You could use d3py a python module that generate xml pages embedding d3.js script. For example :  import d3py import networkx as nx  import logging logging.basicConfig(level=logging.DEBUG)  G = nx.Graph() G.add_edge(1,2) G.add_edge(1,3) G.add_edge(3,2) G.add_edge(3,4) G.add_edge(4,2)  # use 'with' if you are writing a script and want to serve this up forever with d3py.NetworkXFigure(G, width=500, height=500) as p:     p += d3py.ForceLayout()     p.show()      ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"54","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Plotly supports interactive 2D and 3D graphing. Graphs are rendered with D3.js and can be created with a Python API, matplotlib, ggplot for Python, Seaborn, prettyplotlib, and pandas. You can zoom, pan, toggle traces on and off, and see data on the hover. Plots can be embedded in HTML, apps, dashboards, and IPython Notebooks. Below is a temperature graph showing interactivity. See the gallery of IPython Notebooks tutorials for more examples.            The docs provides examples of supported plot types and code snippets.       Specifically to your question, you can also make interactive plots from NetworkX.       For 3D plotting with Python, you can make 3D scatter, line, and surface plots that are similarly interactive. Plots are rendered with WebGL. For example, see a 3D graph of UK Swap rates.       Disclosure: I'm on the Plotly team.     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Have you looked at vincent?  Vincent takes Python data objects and converts them to Vega visualization grammar.  Vega is a higher-level visualization tool built on top of D3.  As compared to D3py, the vincent repo has been updated more recently.  Though the examples are all static D3.  more info:   https://github.com/wrobstory/vincent https://pypi.python.org/pypi/vincent/0.1.6     The graphs can be viewed in Ipython, just add this code  vincent.core.initialize_notebook()   Or output to JSON where you can view the JSON output graph in the Vega online editor (http://trifacta.github.io/vega/editor/) or view them on your Python server locally.  More info on viewing can be found in the pypi link above.  Not sure when, but the Pandas package should have D3 integration at some point.  http://pandas.pydata.org/developers.html  Bokeh is a Python visualization library that supports interactive visualization. Its primary output backend is HTML5 Canvas and uses client/server model.  examples: http://continuumio.github.io/bokehjs/     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  One recipe that I have used (described here: Co-Director Network Data Files in GEXF and JSON from OpenCorporates Data via Scraperwiki and networkx ) runs as follows:   generate a network representation using networkx export the network as a JSON file import that JSON into to d3.js. (networkx can export both the tree and graph/network representations that d3.js can import).   The networkx JSON exporter takes the form:  from networkx.readwrite import json_graph import json print json.dumps(json_graph.node_link_data(G))   Alternatively you can export the network as a GEXF XML file and then import this representation into the sigma.js Javascript visualisation library.  from xml.etree.cElementTree import tostring writer=gf.GEXFWriter(encoding='utf-8',prettyprint=True,version='1.1draft') writer.add_graph(G) print tostring(writer.xml)      ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Another option is bokeh which just went to version 0.3.     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Check out python-nvd3. It is a python wrapper for nvd3. Looks cooler than d3.py and also has more chart options.      ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  For those who recommended pyd3, it is no longer under active development and points you to vincent. vincent is also no longer under active development and recommends using altair.  So if you want a pythonic d3, use altair.     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  I would suggest using mpld3 which combines D3js javascript visualizations with matplotlib of python.  The installation and usage is really simple and it has some cool plugins and interactive stuffs.  http://mpld3.github.io/     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Plotly can do some cool stuffs for you   https://plot.ly/  Produces highly interactive graphs that can be easily embedded withing the HTML pages for your private server or website using its off line API.   Update: I am note sure about its 3D plotting capabilities, for 2D graphs is awesome Thanks       ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  There is an interesting port of NetworkX to Javascript that might do what you want.  See http://felix-kling.de/JSNetworkX/     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  See:  Is there a good interactive 3D graph library out there?  The accepted answer suggests the following program, which apparently has python bindings: http://ubietylab.net/ubigraph/  Edit  I'm not sure about the interactivity of NetworkX, but you can definitely make 3D graphs. There is at least one example in the gallery:  http://networkx.lanl.gov/examples/drawing/edge_colormap.html  And another example in the 'examples'. This one, however, requires that you have Mayavi.  http://networkx.lanl.gov/examples/3d_drawing/mayavi2_spring.html     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  You can also choose to serialize your data and then visualize it in D3.js, as done here: Use Python & Pandas to Create a D3 Force Directed Network Diagram (It comes with a jupyter notebook as well!)  Here is the gist. You serialize your graph data in this format:  import json json_data = {   \"nodes\":[     {\"name\":\"Myriel\",\"group\":1},     {\"name\":\"Napoleon\",\"group\":1},     {\"name\":\"Mlle.Baptistine\",\"group\":1},     {\"name\":\"Mme.Magloire\",\"group\":1},     {\"name\":\"CountessdeLo\",\"group\":1},   ],   \"links\":[     {\"source\":1,\"target\":0,\"value\":1},     {\"source\":2,\"target\":0,\"value\":8},     {\"source\":3,\"target\":0,\"value\":10},     {\"source\":3,\"target\":2,\"value\":6},     {\"source\":4,\"target\":0,\"value\":1},     {\"source\":5,\"target\":0,\"value\":1},   ] } filename_out = 'graph_data.json' json_out = open(filename_out,'w') json_out.write(json_data) json_out.close()   Then you load the data in with d3.js:  d3.json(\"pcap_export.json\", drawGraph);   For the routine drawGraph I refer you to the link, however.     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  I've got a good example of automatically generating D3.js network diagrams using Python here: http://brandonrose.org/ner2sna  The cool thing is that you end up with auto-generated HTML and JS and can embed the interactive D3 chart in a notebook with an IFrame     ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"Python equivalent of D3.js","A_Content":"  Try https://altair-viz.github.io/ - the successor of d3py and vincent. See also    https://altair-viz.github.io/gallery/index.html  https://speakerdeck.com/jakevdp/bespoke-visualizations-with-a-declarative-twist      ","Language":"Python","Tags":["python","graph","d3.js","graph-tool"],"URL":"https://stackoverflow.com/questions/12977517/python-equivalent-of-d3-js","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Can anyone recommend a Python library that can do interactive graph visualization?  I specifically want something like d3.js but for python and ideally it would be 3D as well.   I have looked at:   NetworkX - it only does Matplotlib plots and those seem to be 2D. I didn't see any sort of interactiveness, like one that d3.js gives, such as pulling nodes around. graph-tool - it does only 2D plots and has very slow interactive graphs.      ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  Quoted from http://www.geekinterview.com/question_details/64739:     Advantages of inner class:         Logical grouping of classes: If a class is useful to only one other class then it is logical to embed it in that class and keep the two together. Nesting such \"helper classes\" makes their package more streamlined.   Increased encapsulation: Consider two top-level classes A and B where B needs access to members of A that would otherwise be declared private. By hiding class B within class A A's members can be declared private and B can access them. In addition B itself can be hidden from the outside world.   More readable, maintainable code: Nesting small classes within top-level classes places the code closer to where it is used.      The main advantage is organization. Anything that can be accomplished with inner classes can be accomplished without them.     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"69","_type":"dict","isAccepted":"Yes","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"     Is there something that can't be accomplished without them?   No. They are absolutely equivalent to defining the class normally at top level, and then copying a reference to it into the outer class.  I don't think there's any special reason nested classes are allowed, other than it makes no particular sense to explicitly disallow them either.  If you're looking for a class that exists within the lifecycle of the outer/owner object, and always has a reference to an instance of the outer classinner classes as Java does itthen Python's nested classes are not that thing. But you can hack up something like that thing:  import weakref, new  class innerclass(object):     \"\"\"Descriptor for making inner classes.      Adds a property 'owner' to the inner class, pointing to the outer     owner instance.     \"\"\"      # Use a weakref dict to memoise previous results so that     # instance.Inner() always returns the same inner classobj.     #     def __init__(self, inner):         self.inner= inner         self.instances= weakref.WeakKeyDictionary()      # Not thread-safe - consider adding a lock.     #     def __get__(self, instance, _):         if instance is None:             return self.inner         if instance not in self.instances:             self.instances[instance]= new.classobj(                 self.inner.__name__, (self.inner,), {'owner': instance}             )         return self.instances[instance]   # Using an inner class # class Outer(object):     @innerclass     class Inner(object):         def __repr__(self):             return '<%s.%s inner object of %r>' % (                 self.owner.__class__.__name__,                 self.__class__.__name__,                 self.owner             )  >>> o1= Outer() >>> o2= Outer() >>> i1= o1.Inner() >>> i1 <Outer.Inner inner object of <__main__.Outer object at 0x7fb2cd62de90>> >>> isinstance(i1, Outer.Inner) True >>> isinstance(i1, o1.Inner) True >>> isinstance(i1, o2.Inner) False   (This uses class decorators, which are new in Python 2.6 and 3.0. Otherwise you'd have to say Inner= innerclass(Inner) after the class definition.)     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"46","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  There's something you need to wrap your head around to be able to understand this.  In most languages, class definitions are directives to the compiler.  That is, the class is created before the program is ever run.  In python, all statements are executable.  That means that this statement:  class foo(object):     pass   is a statement that is executed at runtime just like this one:  x = y + z   This means that not only can you create classes within other classes, you can create classes anywhere you want to.  Consider this code:  def foo():     class bar(object):         ...     z = bar()   Thus, the idea of an \"inner class\" isn't really a language construct; it's a programmer construct.  Guido has a very good summary of how this came about here.  But essentially, the basic idea is this simplifies the language's grammar.     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  Nesting classes within classes:   Nested classes bloat the class definition making it harder to see whats going on. Nested classes can create coupling that would make testing more difficult. In Python you can put more than one class in a file/module, unlike Java, so the class still remains close to top level class and could even have the class name prefixed with an \"_\" to help signify that others shouldn't be using it.   The place where nested classes can prove useful is within functions  def some_func(a, b, c):    class SomeClass(a):       def some_method(self):          return b    SomeClass.__doc__ = c    return SomeClass   The class captures the values from the function allowing you to dynamically create a class like template metaprogramming in C++     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  I understand the arguments against nested classes, but there is a case for using them in some occasions. Imagine I'm creating a doubly-linked list class, and I need to create a node class for maintaing the nodes. I have two choices, create Node class inside the DoublyLinkedList class, or create the Node class outside the DoublyLinkedList class. I prefer the first choice in this case, because the Node class is only meaningful inside the DoublyLinkedList class. While there's no hiding/encapsulation benefit, there is a grouping benefit of being able to say the Node class is part of the DoublyLinkedList class.     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  I have used Python's inner classes to create deliberately buggy subclasses within unittest functions (i.e. inside def test_something():) in order to get closer to 100% test coverage (e.g. testing very rarely triggered logging statements by overriding some methods).  In retrospect it's similar to Ed's answer https://stackoverflow.com/a/722036/1101109  Such inner classes should go out of scope and be ready for garbage collection once all references to them have been removed. For instance, take the following inner.py file:  class A(object):     pass  def scope():     class Buggy(A):         \"\"\"Do tests or something\"\"\"     assert isinstance(Buggy(), A)   I get the following curious results under OSX Python 2.7.6:  >>> from inner import A, scope >>> A.__subclasses__() [] >>> scope() >>> A.__subclasses__() [<class 'inner.Buggy'>] >>> del A, scope >>> from inner import A >>> A.__subclasses__() [<class 'inner.Buggy'>] >>> del A >>> import gc >>> gc.collect() 0 >>> gc.collect()  # Yes I needed to call the gc twice, seems reproducible 3 >>> from inner import A >>> A.__subclasses__() []   Hint - Don't go on and try doing this with Django models, which seemed to keep other (cached?) references to my buggy classes.  So in general, I wouldn't recommend using inner classes for this kind of purpose unless you really do value that 100% test coverage and can't use other methods. Though I think it's nice to be aware that if you use the __subclasses__(), that it can sometimes get polluted by inner classes. Either way if you followed this far, I think we're pretty deep into Python at this point, private dunderscores and all.     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"What is the purpose of python's inner classes?","A_Content":"  The main use case I use this for is the prevent proliferation of small modules and to prevent namespace pollution when separate modules are not needed. If I am extending an existing class, but that existing class must reference another subclass that should always be coupled to it. For example, I may have a utils.py module that has many helper classes in it, that aren't necessarily coupled together, but I want to reinforce coupling for some of those helper classes. For example, when I implement https://stackoverflow.com/a/8274307/2718295  :utils.py:  import json, decimal  class Helper1(object):     pass  class Helper2(object):     pass  # Here is the notorious JSONEncoder extension to serialize Decimals to JSON floats class DecimalJSONEncoder(json.JSONEncoder):      class _repr_decimal(float): # Because float.__repr__ cannot be monkey patched         def __init__(self, obj):             self._obj = obj         def __repr__(self):             return '{:f}'.format(self._obj)      def default(self, obj): # override JSONEncoder.default         if isinstance(obj, decimal.Decimal):             return self._repr_decimal(obj)         # else         super(self.__class__, self).default(obj)         # could also have inherited from object and used return json.JSONEncoder.default(self, obj)    Then we can:  >>> from utils import DecimalJSONEncoder >>> import json, decimal >>> json.dumps({'key1': decimal.Decimal('1.12345678901234'),  ... 'key2':'strKey2Value'}, cls=DecimalJSONEncoder) {\"key2\": \"key2_value\", \"key_1\": 1.12345678901234}   Of course, we could have eschewed inheriting json.JSONEnocder altogether and just override default():  :  import decimal, json  class Helper1(object):     pass  def json_encoder_decimal(obj):     class _repr_decimal(float):         ...      if isinstance(obj, decimal.Decimal):         return _repr_decimal(obj)      return json.JSONEncoder(obj)   >>> json.dumps({'key1': decimal.Decimal('1.12345678901234')}, default=json_decimal_encoder) '{\"key1\": 1.12345678901234}'   But sometimes just for convention, you want utils to be composed of classes for extensibility.  Here's another use-case: I want a factory for mutables in my OuterClass without having to invoke copy:  class OuterClass(object):      class DTemplate(dict):         def __init__(self):             self.update({'key1': [1,2,3],                 'key2': {'subkey': [4,5,6]})       def __init__(self):         self.outerclass_dict = {             'outerkey1': self.DTemplate(),             'outerkey2': self.DTemplate()}    obj = OuterClass() obj.outerclass_dict['outerkey1']['key2']['subkey'].append(4) assert obj.outerclass_dict['outerkey2']['key2']['subkey'] == [4,5,6]   I prefer this pattern over the @staticmethod decorator you would otherwise use for a factory function.     ","Language":"Python","Tags":["python","class","oop","language-features"],"URL":"https://stackoverflow.com/questions/719705/what-is-the-purpose-of-pythons-inner-classes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python's inner/nested classes confuse me. Is there something that can't be accomplished without them? If so, what is that thing?     ","Q_Votes":"79"},{"Q_Title":"Python constructor and default value [duplicate]","A_Content":"  Mutable default arguments don't generally do what you want. Instead, try this:  class Node:      def __init__(self, wordList=None, adjacencyList=None):         if wordList is None:             self.wordList = []         else:              self.wordList = wordList          if adjacencyList is None:             self.adjacencyList = []         else:              self.adjacencyList = adjacencyList       ","Language":"Python","Tags":["python","constructor","default-value"],"URL":"https://stackoverflow.com/questions/4841782/python-constructor-and-default-value","A_Votes":"103","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Least Astonishment and the Mutable Default Argument                                        30 answers                                          Somehow, in the Node class below, the wordList and adjacencyList variable is shared between all instances of Node.  >>> class Node: ...     def __init__(self, wordList = [], adjacencyList = []): ...         self.wordList = wordList ...         self.adjacencyList = adjacencyList ...  >>> a = Node() >>> b = Node() >>> a.wordList.append(\"hahaha\") >>> b.wordList ['hahaha'] >>> b.adjacencyList.append(\"hoho\") >>> a.adjacencyList ['hoho']   Is there any way I can keep using the default value (empty list in this case) for the constructor parameters but to get both a and b to have their own wordList and adjacencyList variables?  I am using python 3.1.2.     ","Q_Votes":"79"},{"Q_Title":"Python constructor and default value [duplicate]","A_Content":"  Let's illustrate what's happening here:  Python 3.1.2 (r312:79147, Sep 27 2010, 09:45:41)  [GCC 4.4.3] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> class Foo: ...     def __init__(self, x=[]): ...         x.append(1) ...  >>> Foo.__init__.__defaults__ ([],) >>> f = Foo() >>> Foo.__init__.__defaults__ ([1],) >>> f2 = Foo() >>> Foo.__init__.__defaults__ ([1, 1],)   You can see that the default arguments are stored in a tuple which is an attribute of the function in question. This actually has nothing to do with the class in question and goes for any function. In python 2, the attribute will be func.func_defaults.   As other posters have pointed out, you probably want to use None as a sentinel value and give each instance it's own list.      ","Language":"Python","Tags":["python","constructor","default-value"],"URL":"https://stackoverflow.com/questions/4841782/python-constructor-and-default-value","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Least Astonishment and the Mutable Default Argument                                        30 answers                                          Somehow, in the Node class below, the wordList and adjacencyList variable is shared between all instances of Node.  >>> class Node: ...     def __init__(self, wordList = [], adjacencyList = []): ...         self.wordList = wordList ...         self.adjacencyList = adjacencyList ...  >>> a = Node() >>> b = Node() >>> a.wordList.append(\"hahaha\") >>> b.wordList ['hahaha'] >>> b.adjacencyList.append(\"hoho\") >>> a.adjacencyList ['hoho']   Is there any way I can keep using the default value (empty list in this case) for the constructor parameters but to get both a and b to have their own wordList and adjacencyList variables?  I am using python 3.1.2.     ","Q_Votes":"79"},{"Q_Title":"Python constructor and default value [duplicate]","A_Content":"  I would try:  self.wordList = list(wordList)   to force it to make a copy instead of referencing the same object.     ","Language":"Python","Tags":["python","constructor","default-value"],"URL":"https://stackoverflow.com/questions/4841782/python-constructor-and-default-value","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Least Astonishment and the Mutable Default Argument                                        30 answers                                          Somehow, in the Node class below, the wordList and adjacencyList variable is shared between all instances of Node.  >>> class Node: ...     def __init__(self, wordList = [], adjacencyList = []): ...         self.wordList = wordList ...         self.adjacencyList = adjacencyList ...  >>> a = Node() >>> b = Node() >>> a.wordList.append(\"hahaha\") >>> b.wordList ['hahaha'] >>> b.adjacencyList.append(\"hoho\") >>> a.adjacencyList ['hoho']   Is there any way I can keep using the default value (empty list in this case) for the constructor parameters but to get both a and b to have their own wordList and adjacencyList variables?  I am using python 3.1.2.     ","Q_Votes":"79"},{"Q_Title":"Python constructor and default value [duplicate]","A_Content":"  class Node:     def __init__(self, wordList=None adjacencyList=None):         self.wordList = wordList or []         self.adjacencyList = adjacencyList or []      ","Language":"Python","Tags":["python","constructor","default-value"],"URL":"https://stackoverflow.com/questions/4841782/python-constructor-and-default-value","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Least Astonishment and the Mutable Default Argument                                        30 answers                                          Somehow, in the Node class below, the wordList and adjacencyList variable is shared between all instances of Node.  >>> class Node: ...     def __init__(self, wordList = [], adjacencyList = []): ...         self.wordList = wordList ...         self.adjacencyList = adjacencyList ...  >>> a = Node() >>> b = Node() >>> a.wordList.append(\"hahaha\") >>> b.wordList ['hahaha'] >>> b.adjacencyList.append(\"hoho\") >>> a.adjacencyList ['hoho']   Is there any way I can keep using the default value (empty list in this case) for the constructor parameters but to get both a and b to have their own wordList and adjacencyList variables?  I am using python 3.1.2.     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  [UPDATE] TL;DR pkg_resources is provided by either Distribute or setuptools.   [UPDATE 2] As announced at PyCon 2013, the Distribute and setuptools projects have re-merged.  Distribute is now deprecated and you should just use the new current setuptools.   Try this:  curl -O https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py python ez_setup.py   Or, better, use a current pip as the high level interface and which will use setuptools under the covers.  [Longer answer for OP's specific problem]:  You don't say in your question but I'm assuming you upgraded from the Apple-supplied Python (2.5 on 10.5 or 2.6.1 on 10.6) or that you upgraded from a python.org Python 2.5.  In any of those cases, the important point is that each Python instance has its own library, including its own site-packages library, which is where additional packages are installed. (And none of them use /usr/local/lib by default, by the way.) That means you'll need to install those additional packages you need for your new python 2.6.  The easiest way to do this is to first ensure that the new python2.6 appears first on your search $PATH (that is, typing python2.6 invokes it as expected); the python2.6 installer should have modified your .bash_profile to put its framework bin directory at the front of $PATH.  Then install easy_install using setuptools following the instructions there.  The pkg_resources module is also automatically installed by this step.  Then use the newly-installed version of easy_install (or pip) to install ipython.  easy_install ipython   or  pip install ipython   It should automatically get installed to the correct site-packages location for that python instance and you should be good to go.     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"73","_type":"dict","isAccepted":"Yes","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  I encountered the same ImportError. Somehow the setuptools package had been deleted in my Python environment.  To fix the issue, run the setup script for setuptools:  curl https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py | python   If you have any version of distribute, or any setuptools below 0.6, you will have to uninstall it first.*  See Installation Instructions for further details.    * If you already have a working distribute, upgrading it to the \"compatibility wrapper\" that switches you over to setuptools is easier. But if things are already broken, don't try that.     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"76","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  In case of upgrading your python on mac os 10.7 and pkg_resources doesn't work, the simplest way to fix this is just reinstall setuptools as Ned mentioned above.  sudo pip install setuptools --upgrade or sudo easy_install install setuptools --upgrade      ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  On my system (OSX 10.6) that package is at   /System/Library/Frameworks/Python.framework/Versions/2.6/Extras/lib/python/pkg_resources.py   I hope that helps you figure out if it's missing or just not on your path.     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  The reason might be because the IPython module is not in your PYTHONPATH.  If you donwload IPython and then do   python setup.py install   The setup doesn't add the module IPython to your python path.  You might want to add it to your PYTHONPATH manually. It should work after you do :  export PYTHONPATH=/pathtoIPython:$PYTHONPATH  Add this line in your .bashrc or .profile to make it permanent.     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  I realize this is not related to OSX, but on an embedded system (Beagle Bone Angstrom) I had the exact same error message. Installing the following ipk packages solved it.  opkg install python-setuptools opkg install python-pip      ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  I got this error on Ubuntu, and the following worked for me:  Removed the dropbox binaries and download them again, by running:  sudo rm -rf /var/lib/dropbox/.dropbox-dist dropbox start -i      ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  I encountered with the same problem when i am working on autobahn related project.   1)    So I download the setuptools.-0.9.8.tar.gz form https://pypi.python.org/packages/source/s/setuptools/ and extract it.   2    )Then i get the pkg_resources module and copy it to the folder where it needed.  **in my case that folder was C:\\Python27\\Lib\\site-packages\\autobahn     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?","A_Content":"  In my case, package python-pygments was missed. You can fix it by command:  sudo apt-get install python-pygments  If there is problem with pandoc. You should install pandoc and pandoc-citeproc.  sudo apt-get install pandoc pandoc-citeproc     ","Language":"Python","Tags":["python","ipython"],"URL":"https://stackoverflow.com/questions/1756721/what-is-causing-importerror-no-module-named-pkg-resources-after-upgrade-of-pyth","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I just updated Python to 2.6.4 on my Mac.  I installed from the dmg package.  The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile  >>> pprint.pprint(sys.path)   ['', '/Users/Bryan/work/django-trunk',  '/usr/local/lib/python2.6/site-packages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',   '/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']   Apparently that is not all the required paths because I can't run iPython.  $ ipython   Traceback (most recent call last):     File \"/usr/local/bin/ipython\", line 5, in <module>     from pkg_resources import load_entry_point   ImportError: No module named `pkg_resources`   I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.  What do I need to do to fix this?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  You could use row_factory, as in the example in the docs:  import sqlite3  def dict_factory(cursor, row):     d = {}     for idx, col in enumerate(cursor.description):         d[col[0]] = row[idx]     return d  con = sqlite3.connect(\":memory:\") con.row_factory = dict_factory cur = con.cursor() cur.execute(\"select 1 as a\") print cur.fetchone()[\"a\"]   or follow the advice that's given right after this example in the docs:     If returning a tuple doesnt suffice   and you want name-based access to   columns, you should consider setting   row_factory to the highly-optimized   sqlite3.Row type. Row provides both   index-based and case-insensitive   name-based access to columns with   almost no memory overhead. It will   probably be better than your own   custom dictionary-based approach or   even a db_row based solution.      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  Even using the sqlite3.Row class-- you still can't use string formatting in the form of:  print \"%(id)i - %(name)s: %(value)s\" % row   In order to get past this, I use a helper function that takes the row and converts to a dictionary. I only use this when the dictionary object is preferable to the Row object (e.g. for things like string formatting where the Row object doesn't natively support the dictionary API as well). But use the Row object all other times.   def dict_from_row(row):     return dict(zip(row.keys(), row))             ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  I thought I answer this question even though the answer is partly mentioned in both Adam Schmideg's  and Alex Martelli's answers. In order for others like me that have the same question, to find the answer easily.  conn = sqlite3.connect(\":memory:\")  #This is the important part, here we are setting row_factory property of #connection object to sqlite3.Row(sqlite3.Row is an implementation of #row_factory) conn.row_factory = sqlite3.Row c = conn.cursor() c.execute('select * from stocks')  result = c.fetchall() #returns a list of dictionaries, each item in list(each dictionary) #represents a row of the table      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  From PEP 249:  Question:      How can I construct a dictionary out of the tuples returned by    .fetch*():  Answer:     There are several existing tools available which provide    helpers for this task. Most of them use the approach of using    the column names defined in the cursor attribute .description    as basis for the keys in the row dictionary.     Note that the reason for not extending the DB API specification    to also support dictionary return values for the .fetch*()    methods is that this approach has several drawbacks:     * Some databases don't support case-sensitive column names or      auto-convert them to all lowercase or all uppercase      characters.     * Columns in the result set which are generated by the query      (e.g.  using SQL functions) don't map to table column names      and databases usually generate names for these columns in a      very database specific way.     As a result, accessing the columns through dictionary keys    varies between databases and makes writing portable code    impossible.   So yes, do it yourself.     ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  Shorter version:  db.row_factory = lambda c, r: dict([(col[0], r[idx]) for idx, col in enumerate(c.description)])      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  Fastest on my tests:  conn.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r)) c = conn.cursor()  %timeit c.execute('SELECT * FROM table').fetchall() 19.8 s  1.05 s per loop (mean  std. dev. of 7 runs, 100000 loops each)   vs:  conn.row_factory = lambda c, r: dict([(col[0], r[idx]) for idx, col in enumerate(c.description)]) c = conn.cursor()  %timeit c.execute('SELECT * FROM table').fetchall() 19.4 s  75.6 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)   You decide :)     ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  Or you could convert the sqlite3.Rows to a dictionary as follows. This will give a dictionary with a list for each row.      def from_sqlite_Row_to_dict(list_with_rows):     ''' Turn a list with sqlite3.Row objects into a dictionary'''     d ={} # the dictionary to be filled with the row data and to be returned      for i, row in enumerate(list_with_rows): # iterate throw the sqlite3.Row objects                     l = [] # for each Row use a separate list         for col in range(0, len(row)): # copy over the row date (ie. column data) to a list             l.append(row[col])         d[i] = l # add the list to the dictionary        return d      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  A generic alternative, using just three lines  def select_column_and_value(db, sql, parameters=()):     execute = db.execute(sql, parameters)     fetch = execute.fetchone()     return {k[0]: v for k, v in list(zip(execute.description, fetch))}  con = sqlite3.connect('/mydatabase.db') c = con.cursor() print(select_column_and_value(c, 'SELECT * FROM things WHERE id=?', (id,)))   But if your query returns nothing, will result in error. In this case...  def select_column_and_value(self, sql, parameters=()):     execute = self.execute(sql, parameters)     fetch = execute.fetchone()      if fetch is None:         return {k[0]: None for k in execute.description}      return {k[0]: v for k, v in list(zip(execute.description, fetch))}   or  def select_column_and_value(self, sql, parameters=()):     execute = self.execute(sql, parameters)     fetch = execute.fetchone()      if fetch is None:         return {}      return {k[0]: v for k, v in list(zip(execute.description, fetch))}      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  import sqlite3  db = sqlite3.connect('mydatabase.db') cursor = db.execute('SELECT * FROM students ORDER BY CREATE_AT') studentList = cursor.fetchall()  columnNames = list(map(lambda x: x[0], cursor.description)) #students table column names list studentsAssoc = {} #Assoc format is dictionary similarly   #THIS IS ASSOC PROCESS for lineNumber, student in enumerate(studentList):     studentsAssoc[lineNumber] = {}      for columnNumber, value in enumerate(student):         studentsAssoc[lineNumber][columnNames[columnNumber]] = value   print(studentsAssoc)   The result is definitely true, but I do not know the best.     ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How can I get dict from sqlite query?","A_Content":"  Similar like before-mentioned solutions, but most compact:  db.row_factory = lambda C, R: { c[0]: R[i] for i, c in enumerate(C.description) }      ","Language":"Python","Tags":["python","sql","sqlite","dictionary","dataformat"],"URL":"https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    db = sqlite.connect(\"test.sqlite\") res = db.execute(\"select * from table\")   With iteration I get lists coresponding to the rows.  for row in res:     print row   I can get name of the columns  col_name_list = [tuple[0] for tuple in res.description]   But is there some function or setting to get dictionaries instead of list?  {'col1': 'value', 'col2': 'value'}   or I have to do myself?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  vec <- vector()   See also vector help  ?vector      ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"87","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  I pre-allocate a vector with  > (a <- rep(NA, 10))  [1] NA NA NA NA NA NA NA NA NA NA   You can then use [] to insert values into it.     ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"44","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  You can create an empty vector like so  vec <- numeric(0)   And then add elements using c()  vec <- c(vec, 1:5)   However as romunov says, it's much better to pre-allocate a vector and then populate it (as this avoids reallocating a new copy of your vector every time you add elements)     ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  I've also seen  x <- {}   Now  you can concatenate or bind  a vector of any dimension to x  rbind(x, 1:10) cbind(x, 1:10) c(x, 10)      ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  To create an empty vector use:  vec <- c();   Please note, I am not making any assumptions about the type of vector you require, e.g. numeric.  Once the vector has been created you can add elements to it as follows:  For example, to add the numeric value 1:  vec <- c(vec, 1);   or, to add a string value \"a\"  vec <- c(vec, \"a\");      ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  As pointed out by Brani, vector() is a solution, e.g.  newVector <- vector(mode = \"numeric\", length = 50)  will return a vector named \"newVector\" with 50 \"0\"'s as initial values. It is also fairly common to just add the new scalar to an existing vector to arrive at an expanded vector, e.g.  aVector <- c(aVector, newScalar)     ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"How to create an empty R vector to add new items","A_Content":"  In rpy2, the way to get the very same operator as \"[\" with R is to use \".rx\". See the documentation about extracting with rpy2  For creating vectors, if you know your way around with Python there should not be any issue. See the documentation about creating vectors     ","Language":"Python","Tags":["python","r","vector","rpy2"],"URL":"https://stackoverflow.com/questions/3413879/how-to-create-an-empty-r-vector-to-add-new-items","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want to use R in Python, as provided by the module Rpy2. I notice that R has very convenient [] operations by which you can extract the specific columns or lines. How could I achieve such a function by Python scripts?  My idea is to create an R vector and add those wanted elements into this vector so that the final vector is the same as that in R. I created a seq(), but it seems that it has an initial digit 1, so the final result would always start with the digit 1, which is not what I want. So, is there a better way to do this?     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  this is actually quite tricky - particularly if you want a useful error message when things are inconsistent, while correctly accepting duplicate but consistent entries (something no other answer here does....)  assuming you don't have huge numbers of entries a recursive function is easiest:  def merge(a, b, path=None):     \"merges b into a\"     if path is None: path = []     for key in b:         if key in a:             if isinstance(a[key], dict) and isinstance(b[key], dict):                 merge(a[key], b[key], path + [str(key)])             elif a[key] == b[key]:                 pass # same leaf value             else:                 raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))         else:             a[key] = b[key]     return a  # works print(merge({1:{\"a\":\"A\"},2:{\"b\":\"B\"}}, {2:{\"c\":\"C\"},3:{\"d\":\"D\"}})) # has conflict merge({1:{\"a\":\"A\"},2:{\"b\":\"B\"}}, {1:{\"a\":\"A\"},2:{\"b\":\"C\"}})   note that this mutates a - the contents of b are added to a (which is also returned).  if you want to keep a you could call it like merge(dict(a), b).  agf pointed out (below) that you may have more than two dicts, in which case you can use:  reduce(merge, [dict1, dict2, dict3...])   where everything will be added to dict1.  [note - i edited my initial answer to mutate the first argument; that makes the \"reduce\" easier to explain]  ps in python 3, you will also need from functools import reduce     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"94","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Here's an easy way to do it using generators:  def mergedicts(dict1, dict2):     for k in set(dict1.keys()).union(dict2.keys()):         if k in dict1 and k in dict2:             if isinstance(dict1[k], dict) and isinstance(dict2[k], dict):                 yield (k, dict(mergedicts(dict1[k], dict2[k])))             else:                 # If one of the values is not a dict, you can't continue merging it.                 # Value from second dict overrides one in first and we move on.                 yield (k, dict2[k])                 # Alternatively, replace this with exception raiser to alert you of value conflicts         elif k in dict1:             yield (k, dict1[k])         else:             yield (k, dict2[k])  dict1 = {1:{\"a\":\"A\"},2:{\"b\":\"B\"}} dict2 = {2:{\"c\":\"C\"},3:{\"d\":\"D\"}}  print dict(mergedicts(dict1,dict2))   This prints:  {1: {'a': 'A'}, 2: {'c': 'C', 'b': 'B'}, 3: {'d': 'D'}}      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  One issue with this question is that the values of the dict can be arbitrarily complex pieces of data. Based upon these and other answers I came up with this code:   class YamlReaderError(Exception):     pass  def data_merge(a, b):     \"\"\"merges b into a and return merged result      NOTE: tuples and arbitrary objects are not handled as it is totally ambiguous what should happen\"\"\"     key = None     # ## debug output     # sys.stderr.write(\"DEBUG: %s to %s\\n\" %(b,a))     try:         if a is None or isinstance(a, str) or isinstance(a, unicode) or isinstance(a, int) or isinstance(a, long) or isinstance(a, float):             # border case for first run or if a is a primitive             a = b         elif isinstance(a, list):             # lists can be only appended             if isinstance(b, list):                 # merge lists                 a.extend(b)             else:                 # append to list                 a.append(b)         elif isinstance(a, dict):             # dicts must be merged             if isinstance(b, dict):                 for key in b:                     if key in a:                         a[key] = data_merge(a[key], b[key])                     else:                         a[key] = b[key]             else:                 raise YamlReaderError('Cannot merge non-dict \"%s\" into dict \"%s\"' % (b, a))         else:             raise YamlReaderError('NOT IMPLEMENTED \"%s\" into \"%s\"' % (b, a))     except TypeError, e:         raise YamlReaderError('TypeError \"%s\" in key \"%s\" when merging \"%s\" into \"%s\"' % (e, key, b, a))     return a   My use case is merging YAML files where I only have to deal with a subset of possible data types. Hence I can ignore tuples and other objects. For me a sensible merge logic means   replace scalars append lists merge dicts by adding missing keys and updating existing keys   Everything else and the unforeseens results in an error.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Based on @andrew cooke. This version handles nested lists of dicts and also allows the option to update the values   def merge(a, b, path=None, update=True):     \"http://stackoverflow.com/questions/7204805/python-dictionaries-of-dictionaries-merge\"     \"merges b into a\"     if path is None: path = []     for key in b:         if key in a:             if isinstance(a[key], dict) and isinstance(b[key], dict):                 merge(a[key], b[key], path + [str(key)])             elif a[key] == b[key]:                 pass # same leaf value             elif isinstance(a[key], list) and isinstance(b[key], list):                 for idx, val in enumerate(b[key]):                     a[key][idx] = merge(a[key][idx], b[key][idx], path + [str(key), str(idx)], update=update)             elif update:                 a[key] = b[key]             else:                 raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))         else:             a[key] = b[key]     return a      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"     Dictionaries of dictionaries merge   As this is the canonical question (in spite of certain non-generalities) I'm providing the canonical Pythonic approach to solving this issue.  Simplest Case: \"leaves are nested dicts that end in empty dicts\":  d1 = {'a': {1: {'foo': {}}, 2: {}}} d2 = {'a': {1: {}, 2: {'bar': {}}}} d3 = {'b': {3: {'baz': {}}}} d4 = {'a': {1: {'quux': {}}}}   This is the simplest case for recursion, and I would recommend two naive approaches:  def rec_merge1(d1, d2):     '''return new merged dict of dicts'''     for k, v in d1.items(): # in Python 2, use .iteritems()!         if k in d2:             d2[k] = rec_merge1(v, d2[k])     d3 = d1.copy()     d3.update(d2)     return d3  def rec_merge2(d1, d2):     '''update first dict with second recursively'''     for k, v in d1.items(): # in Python 2, use .iteritems()!         if k in d2:             d2[k] = rec_merge2(v, d2[k])     d1.update(d2)     return d1   I believe I would prefer the second to the first, but keep in mind that the original state of the first would have to be rebuilt from its origin. Here's the usage:  >>> from functools import reduce # only required for Python 3. >>> reduce(rec_merge1, (d1, d2, d3, d4)) {'a': {1: {'quux': {}, 'foo': {}}, 2: {'bar': {}}}, 'b': {3: {'baz': {}}}} >>> reduce(rec_merge2, (d1, d2, d3, d4)) {'a': {1: {'quux': {}, 'foo': {}}, 2: {'bar': {}}}, 'b': {3: {'baz': {}}}}   Complex Case: \"leaves are of any other type:\"  So if they end in dicts, it's a simple case of merging the end empty dicts. If not, it's not so trivial. If strings, how do you merge them? Sets can be updated similarly, so we could give that treatment, but we lose the order in which they were merged. So does order matter?   So in lieu of more information, the simplest approach will be to give them the standard update treatment if both values are not dicts: i.e. the second dict's value will overwrite the first, even if the second dict's value is None and the first's value is a dict with a lot of info.  d1 = {'a': {1: 'foo', 2: None}} d2 = {'a': {1: None, 2: 'bar'}} d3 = {'b': {3: 'baz'}} d4 = {'a': {1: 'quux'}}  from collections import MutableMapping  def rec_merge(d1, d2):     '''     Update two dicts of dicts recursively,      if either mapping has leaves that are non-dicts,      the second's leaf overwrites the first's.     '''     for k, v in d1.items(): # in Python 2, use .iteritems()!         if k in d2:             # this next check is the only difference!             if all(isinstance(e, MutableMapping) for e in (v, d2[k])):                 d2[k] = rec_merge(v, d2[k])             # we could further check types and merge as appropriate here.     d3 = d1.copy()     d3.update(d2)     return d3   And now  from functools import reduce reduce(rec_merge, (d1, d2, d3, d4))   returns  {'a': {1: 'quux', 2: 'bar'}, 'b': {3: 'baz'}}   Application to the original question:  I've had to remove the curly braces around the letters and put them in single quotes for this to be legit Python (else they would be set literals in Python 2.7+) as well as append a missing brace:  dict1 = {1:{\"a\":'A'}, 2:{\"b\":'B'}} dict2 = {2:{\"c\":'C'}, 3:{\"d\":'D'}}   and rec_merge(dict1, dict2) now returns:  {1: {'a': 'A'}, 2: {'c': 'C', 'b': 'B'}, 3: {'d': 'D'}}   Which matches the desired outcome of the original question (after changing, e.g. the {A} to 'A'.)     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  If you have an unknown level of dictionaries, then I would suggest a recursive function:  def combineDicts(dictionary1, dictionary2):     output = {}     for item, value in dictionary1.iteritems():         if dictionary2.has_key(item):             if isinstance(dictionary2[item], dict):                 output[item] = combineDicts(value, dictionary2.pop(item))         else:             output[item] = value     for item, value in dictionary2.iteritems():          output[item] = value     return output      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Based on answers from @andrew cooke. It takes care of nested lists in a better way.  def deep_merge_lists(original, incoming):     \"\"\"     Deep merge two lists. Modifies original.     Reursively call deep merge on each correlated element of list.      If item type in both elements are      a. dict: call deep_merge_dicts on both values.      b. list: Calls deep_merge_lists on both values.      c. any other type: Value is overridden.      d. conflicting types: Value is overridden.      If length of incoming list is more that of original then extra values are appended.     \"\"\"     common_length = min(len(original), len(incoming))     for idx in range(common_length):         if isinstance(original[idx], dict) and isinstance(incoming[idx], dict):             deep_merge_dicts(original[idx], incoming[idx])          elif isinstance(original[idx], list) and isinstance(incoming[idx], list):             deep_merge_lists(original[idx], incoming[idx])          else:             orginal[idx] = incoming[idx]      for idx in range(common_length, len(incoming)):         original.append(incoming[idx])   def deep_merge_dicts(original, incoming):     \"\"\"     Deep merge two dictionaries. Modfies original.     For key conflicts if both values are:      a. dict: Recursivley call deep_merge_dicts on both values.      b. list: Calls deep_merge_lists on both values.      c. any other type: Value is overridden.      d. conflicting types: Value is overridden.      \"\"\"     for key in incoming:         if key in original:             if isinstance(original[key], dict) and isinstance(incoming[key], dict):                 deep_merge_dicts(original[key], incoming[key])              elif isinstance(original[key], list) and isinstance(incoming[key], list):                 deep_merge_lists(original[key], incoming[key])              else:                 original[key] = incoming[key]         else:             original[key] = incoming[key]      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  This version of the function will account for N number of dictionaries, and only dictionaries -- no improper parameters can be passed, or it will raise a TypeError. The merge itself accounts for key conflicts, and instead of overwriting data from a dictionary further down the merge chain, it creates a set of values and appends to that; no data is lost.  It might not be the most effecient on the page, but it's the most thorough and you're not going to lose any information when you merge your 2 to N dicts.  def merge_dicts(*dicts):     if not reduce(lambda x, y: isinstance(y, dict) and x, dicts, True):         raise TypeError, \"Object in *dicts not of type dict\"     if len(dicts) < 2:         raise ValueError, \"Requires 2 or more dict objects\"       def merge(a, b):         for d in set(a.keys()).union(b.keys()):             if d in a and d in b:                 if type(a[d]) == type(b[d]):                     if not isinstance(a[d], dict):                         ret = list({a[d], b[d]})                         if len(ret) == 1: ret = ret[0]                         yield (d, sorted(ret))                     else:                         yield (d, dict(merge(a[d], b[d])))                 else:                     raise TypeError, \"Conflicting key:value type assignment\"             elif d in a:                 yield (d, a[d])             elif d in b:                 yield (d, b[d])             else:                 raise KeyError      return reduce(lambda x, y: dict(merge(x, y)), dicts[1:], dicts[0])  print merge_dicts({1:1,2:{1:2}},{1:2,2:{3:1}},{4:4})   output: {1: [1, 2], 2: {1: 2, 3: 1}, 4: 4}     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  This simple recursive procedure will merge one dictionary into another while overriding conflicting keys:  #!/usr/bin/env python2.7  def merge_dicts(dict1, dict2):     \"\"\" Recursively merges dict2 into dict1 \"\"\"     if not isinstance(dict1, dict) or not isinstance(dict2, dict):         return dict2     for k in dict2:         if k in dict1:             dict1[k] = merge_dicts(dict1[k], dict2[k])         else:             dict1[k] = dict2[k]     return dict1  print (merge_dicts({1:{\"a\":\"A\"}, 2:{\"b\":\"B\"}}, {2:{\"c\":\"C\"}, 3:{\"d\":\"D\"}})) print (merge_dicts({1:{\"a\":\"A\"}, 2:{\"b\":\"B\"}}, {1:{\"a\":\"A\"}, 2:{\"b\":\"C\"}}))   Output:  {1: {'a': 'A'}, 2: {'c': 'C', 'b': 'B'}, 3: {'d': 'D'}} {1: {'a': 'A'}, 2: {'b': 'C'}}      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Since dictviews support set operations, I was able to greatly simplify jterrace's answer.  def merge(dict1, dict2):     for k in dict1.keys() - dict2.keys():         yield (k, dict1[k])      for k in dict2.keys() - dict1.keys():         yield (k, dict2[k])      for k in dict1.keys() & dict2.keys():         yield (k, dict(merge(dict1[k], dict2[k])))   Any attempt to combine a dict with a non dict (technically, an object with a 'keys' method and an object without a 'keys' method) will raise an AttributeError. This includes both the initial call to the function and recursive calls. This is exactly what I wanted so I left it. You could easily catch an AttributeErrors thrown by the recursive call and then yield any value you please.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  This should help in merging all items from dict2 into dict1:  for item in dict2:     if item in dict1:         for leaf in dict2[item]:             dict1[item][leaf] = dict2[item][leaf]     else:         dict1[item] = dict2[item]   Please test it and tell us whether this is what you wanted.  EDIT:  The above mentioned solution merges only one level, but correctly solves the example given by OP. To merge multiple levels, the recursion should be used.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  There's a slight problem with andrew cookes answer: In some cases it modifies the second argument b when you modify the returned dict. Specifically it's because of this line:  if key in a:     ... else:     a[key] = b[key]   If b[key] is a dict, it will simply be assigned to a, meaning any subsequent modifications to that dict will affect both a and b.  a={} b={'1':{'2':'b'}} c={'1':{'3':'c'}} merge(merge(a,b), c) # {'1': {'3': 'c', '2': 'b'}} a # {'1': {'3': 'c', '2': 'b'}} (as expected) b # {'1': {'3': 'c', '2': 'b'}} <---- c # {'1': {'3': 'c'}} (unmodified)   To fix this, the line would have to be substituted with this:  if isinstance(b[key], dict):     a[key] = clone_dict(b[key]) else:     a[key] = b[key]   Where clone_dict is:  def clone_dict(obj):     clone = {}     for key, value in obj.iteritems():         if isinstance(value, dict):             clone[key] = clone_dict(value)         else:             clone[key] = value     return   Still. This obviously doesn't account for list, set and other stuff, but I hope it illustrates the pitfalls when trying to merge dicts.  And for completeness sake, here is my version, where you can pass it multiple dicts:  def merge_dicts(*args):     def clone_dict(obj):         clone = {}         for key, value in obj.iteritems():             if isinstance(value, dict):                 clone[key] = clone_dict(value)             else:                 clone[key] = value         return      def merge(a, b, path=[]):         for key in b:             if key in a:                 if isinstance(a[key], dict) and isinstance(b[key], dict):                     merge(a[key], b[key], path + [str(key)])                 elif a[key] == b[key]:                     pass                 else:                     raise Exception('Conflict at `{path}\\''.format(path='.'.join(path + [str(key)])))             else:                 if isinstance(b[key], dict):                     a[key] = clone_dict(b[key])                 else:                     a[key] = b[key]         return a     return reduce(merge, args, {})      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  I had two dictionaries (a and b) which could each contain any number of nested dictionaries. I wanted to recursively merge them, with b taking precedence over a.  Considering the nested dictionaries as trees, what I wanted was:   To update a so that every path to every leaf in b would be represented in a To overwrite subtrees of a if a leaf is found in the corresponding path in b   Maintain the invariant that all b leaf nodes remain leafs.    The existing answers were a little complicated for my taste and left some details on the shelf. I hacked together the following, which passes unit tests for my data set.    def merge_map(a, b):     if not isinstance(a, dict) or not isinstance(b, dict):       return b      for key in b.keys():       a[key] = merge_map(a[key], b[key]) if key in a else b[key]     return a   Example (formatted for clarity):   a = {     1 : {'a': 'red',           'b': {'blue': 'fish', 'yellow': 'bear' },          'c': { 'orange': 'dog'},     },     2 : {'d': 'green'},     3: 'e'   }    b = {     1 : {'b': 'white'},     2 : {'d': 'black'},     3: 'e'   }     >>> merge_map(a, b)   {1: {'a': 'red',         'b': 'white',        'c': {'orange': 'dog'},},    2: {'d': 'black'},    3: 'e'}   The paths in b that needed to be maintained were:   1 -> 'b' -> 'white' 2 -> 'd' -> 'black' 3 -> 'e'.   a had the unique and non-conflicting paths of:   1 -> 'a' -> 'red'  1 -> 'c' -> 'orange' -> 'dog'   so they are still represented in the merged map.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Overview  The following approach subdivides the problem of a deep merge of dicts into:    A parameterized shallow merge function merge(f)(a,b) that uses a function f to merge two dicts a and b A recursive merger function f to be used together with merge     Implementation  A function for merging two (non nested) dicts can be written in a lot of ways. I personally like  def merge(f):     def merge(a,b):          keys = a.keys() | b.keys()         return {key:f(*[a.get(key), b.get(key)]) for key in keys}     return merge     A nice way of defining an appropriate recurrsive merger function f is using multipledispatch which allows to define functions that evaluate along different paths depending on the type of their arguments.  from multipledispatch import dispatch  #for anything that is not a dict return @dispatch(object, object) def f(a, b):     return b if b is not None else a  #for dicts recurse  @dispatch(dict, dict) def f(a,b):     return merge(f)(a,b)     Example  To merge two nested dicts simply use merge(f) e.g.:  dict1 = {1:{\"a\":\"A\"},2:{\"b\":\"B\"}} dict2 = {2:{\"c\":\"C\"},3:{\"d\":\"D\"}} merge(f)(dict1, dict2) #returns {1: {'a': 'A'}, 2: {'b': 'B', 'c': 'C'}, 3: {'d': 'D'}}      Notes:  The advantages of this approach are:   The function is build from smaller functions that each do a single thing which makes the code simpler to reason about and test The behaviour is not hard-coded but can be changed and extended as needed which improves code reuse (see example below).      Customization  Some answers also considered dicts that contain lists e.g. of other (potentially nested) dicts. In this case one might want map over the lists and merge them based on position. This can be done by adding another definition to the merger function f:  import itertools @dispatch(list, list) def f(a,b):     return [merge(f)(*arg) for arg in itertools.zip_longest(a,b,fillvalue={})]      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  The code will depend on your rules for resolving merge conflicts, of course. Here's a version which can take an arbitrary number of arguments and merges them recursively to an arbitrary depth, without using any object mutation. It uses the following rules to resolve merge conflicts:   dictionaries take precedence over non-dict values ({\"foo\": {...}} takes precedence over {\"foo\": \"bar\"}) later arguments take precedence over earlier arguments (if you merge {\"a\": 1}, {\"a\", 2}, and {\"a\": 3} in order, the result will be {\"a\": 3})   try:     from collections import Mapping except ImportError:     Mapping = dict  def merge_dicts(*dicts):                                                                 \"\"\"                                                                                  Return a new dictionary that is the result of merging the arguments together.        In case of conflicts, later arguments take precedence over earlier arguments.        \"\"\"                                                                                  updated = {}                                                                         # grab all keys                                                                      keys = set()                                                                         for d in dicts:                                                                          keys = keys.union(set(d))                                                         for key in keys:                                                                         values = [d[key] for d in dicts if key in d]                                         # which ones are mapping types? (aka dict)                                           maps = [value for value in values if isinstance(value, Mapping)]                     if maps:                                                                                 # if we have any mapping types, call recursively to merge them                       updated[key] = merge_dicts(*maps)                                                else:                                                                                    # otherwise, just grab the last value we have, since later arguments                 # take precedence over earlier arguments                                             updated[key] = values[-1]                                                    return updated        ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  I've been testing your solutions and decided to use this one in my project:  def mergedicts(dict1, dict2, conflict, no_conflict):     for k in set(dict1.keys()).union(dict2.keys()):         if k in dict1 and k in dict2:             yield (k, conflict(dict1[k], dict2[k]))         elif k in dict1:             yield (k, no_conflict(dict1[k]))         else:             yield (k, no_conflict(dict2[k]))  dict1 = {1:{\"a\":\"A\"}, 2:{\"b\":\"B\"}} dict2 = {2:{\"c\":\"C\"}, 3:{\"d\":\"D\"}}  #this helper function allows for recursion and the use of reduce def f2(x, y):     return dict(mergedicts(x, y, f2, lambda x: x))  print dict(mergedicts(dict1, dict2, f2, lambda x: x)) print dict(reduce(f2, [dict1, dict2]))   Passing functions as parameteres is key to extend jterrace solution to behave as all the other recursive solutions.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Easiest way i can think of is :  #!/usr/bin/python  from copy import deepcopy def dict_merge(a, b):     if not isinstance(b, dict):         return b     result = deepcopy(a)     for k, v in b.iteritems():         if k in result and isinstance(result[k], dict):                 result[k] = dict_merge(result[k], v)         else:             result[k] = deepcopy(v)     return result  a = {1:{\"a\":'A'}, 2:{\"b\":'B'}} b = {2:{\"c\":'C'}, 3:{\"d\":'D'}}  print dict_merge(a,b)   Output:  {1: {'a': 'A'}, 2: {'c': 'C', 'b': 'B'}, 3: {'d': 'D'}}      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  I have another slightly different solution here:  def deepMerge(d1, d2, inconflict = lambda v1,v2 : v2) : ''' merge d2 into d1. using inconflict function to resolve the leaf conflicts '''     for k in d2:         if k in d1 :              if isinstance(d1[k], dict) and isinstance(d2[k], dict) :                 deepMerge(d1[k], d2[k], inconflict)             elif d1[k] != d2[k] :                 d1[k] = inconflict(d1[k], d2[k])         else :             d1[k] = d2[k]     return d1   By default it resolves conflicts in favor of values from the second dict, but you can easily override this, with some witchery you may be able to even throw exceptions out of it. :).     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  class Utils(object):      \"\"\"      >>> a = { 'first' : { 'all_rows' : { 'pass' : 'dog', 'number' : '1' } } }     >>> b = { 'first' : { 'all_rows' : { 'fail' : 'cat', 'number' : '5' } } }     >>> Utils.merge_dict(b, a) == { 'first' : { 'all_rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }     True      >>> main = {'a': {'b': {'test': 'bug'}, 'c': 'C'}}     >>> suply = {'a': {'b': 2, 'd': 'D', 'c': {'test': 'bug2'}}}     >>> Utils.merge_dict(main, suply) == {'a': {'b': {'test': 'bug'}, 'c': 'C', 'd': 'D'}}     True      \"\"\"      @staticmethod     def merge_dict(main, suply):         \"\"\"         main,suply,main         :return:         \"\"\"         for key, value in suply.items():             if key in main:                 if isinstance(main[key], dict):                     if isinstance(value, dict):                         Utils.merge_dict(main[key], value)                     else:                         pass                 else:                     pass             else:                 main[key] = value         return main  if __name__ == '__main__':     import doctest     doctest.testmod()      ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"Dictionaries of dictionaries merge","A_Content":"  Short-n-sweet:  from collections import MutableMapping as Map  def nested_update(d, v): \"\"\" Nested update of dict-like 'd' with dict-like 'v'. \"\"\"  for key in v:     if key in d and isinstance(d[key], Map) and isinstance(v[key], Map):         nested_update(d[key], v[key])     else:         d.update(v)   This works like (and is build on) Python's dict.update method. It returns None (you can always add return d if you prefer) as it updates dict d in-place. Keys in v will overwrite any existing keys in d (it does not try to interpret the dict's contents).   It will also work for other (\"dict-like\") mappings.     ","Language":"Python","Tags":["python","dictionary","merge","array-merge"],"URL":"https://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to merge multiple dictionaries, here's what I have for instance:  dict1 = {1:{\"a\":{A}}, 2:{\"b\":{B}}}  dict2 = {2:{\"c\":{C}}, 3:{\"d\":{D}}   With A B C and D being leaves of the tree, like {\"info1\":\"value\", \"info2\":\"value2\"}  There is an unknown level(depth) of dictionaries, it could be {2:{\"c\":{\"z\":{\"y\":{C}}}}}  In my case it represents a directory/files structure with nodes being docs and leaves being files.  I want to merge them to obtain:   dict3 = {1:{\"a\":{A}}, 2:{\"b\":{B},\"c\":{C}}, 3:{\"d\":{D}}}   I'm not sure how I could do that easily with Python.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  From \"Programming Python\" by Mark Lutz:  curs.execute(\"Select * FROM people\") colnames = [desc[0] for desc in curs.description]      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"132","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  To get the column names in a separate query, you can query the information_schema.columns table.  #!/usr/bin/env python3  import psycopg2  if __name__ == '__main__':   DSN = 'host=YOUR_DATABASE_HOST port=YOUR_DATABASE_PORT dbname=YOUR_DATABASE_NAME user=YOUR_DATABASE_USER'    column_names = []    with psycopg2.connect(DSN) as connection:       with connection.cursor() as cursor:           cursor.execute(\"select column_name from information_schema.columns where table_schema = 'YOUR_SCHEMA_NAME' and table_name='YOUR_TABLE_NAME'\")           column_names = [row[0] for row in cursor]    print(\"Column names: {}\\n\".format(column_names))   To get column names in the same query as data rows, you can use the description field of the cursor:    #!/usr/bin/env python3  import psycopg2  if __name__ == '__main__':   DSN = 'host=YOUR_DATABASE_HOST port=YOUR_DATABASE_PORT dbname=YOUR_DATABASE_NAME user=YOUR_DATABASE_USER'    column_names = []   data_rows = []    with psycopg2.connect(DSN) as connection:     with connection.cursor() as cursor:       cursor.execute(\"select field1, field2, fieldn from table1\")       column_names = [desc[0] for desc in cursor.description]       for row in cursor:         data_rows.append(row)    print(\"Column names: {}\\n\".format(column_names))      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  Another thing you can do is to create a cursor with which you will be able to reference your columns by their names (that's a need which led me to this page in the first place):  import psycopg2 from psycopg2.extras import RealDictCursor  ps_conn = psycopg2.connect(...) ps_cursor = psql_conn.cursor(cursor_factory=RealDictCursor)  ps_cursor.execute('select 1 as col_a, 2 as col_b') my_record = ps_cursor.fetchone() print (my_record['col_a'],my_record['col_b'])  >> 1, 2      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  If you want to have namedtuple obj from db query you can use the following snippet:  from collections import namedtuple  def create_record(obj, fields):     ''' given obj from db returns namedtuple with fields mapped to values '''     Record = namedtuple(\"Record\", fields)     mappings = dict(zip(fields, obj))     return Record(**mappings)  cur.execute(\"Select * FROM people\") colnames = [desc[0] for desc in cur.description] rows = cur.fetchall() cur.close() result = [] for row in rows:     result.append(create_record(row, colnames))   This allowes you to asses record values as if they were class properties i.e.     record.id,  record.other_table_column_name,   etc.   or even shorter  from psycopg2.extras import NamedTupleCursor with cursor(cursor_factory=NamedTupleCursor) as cur:    cur.execute(\"Select * ...\")    return cur.fetchall()      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  I also used to face similar issue. I use a simple trick to solve this. Suppose you have column names in a list like  col_name = ['a', 'b', 'c']   Then you can do following  for row in cursor.fetchone():     print zip(col_name, row)      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  I have noticed that you must use cursor.fetchone() after the query to get the list of columns in cursor.description (i.e in [desc[0] for desc in curs.description])     ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"How do I get a list of column names from a psycopg2 cursor?","A_Content":"  After executing SQL query write following python script written in 2.7  total_fields = len(cursor.description)     fields_names = [i[0] for i in cursor.description        Print fields_names      ","Language":"Python","Tags":["python","psycopg2"],"URL":"https://stackoverflow.com/questions/10252247/how-do-i-get-a-list-of-column-names-from-a-psycopg2-cursor","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I would like a general way to generate column labels directly from the selected column names, and recall seeing that python's psycopg2 module supports this feature.     ","Q_Votes":"79"},{"Q_Title":"Pythonic way of checking if a condition holds for any element of a list","A_Content":"  any():  if any(t < 0 for t in x):     # do something   Also, if you're going to use \"True in ...\", make it a generator expression so it doesn't take O(n) memory:  if True in (t < 0 for t in x):      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/1342601/pythonic-way-of-checking-if-a-condition-holds-for-any-element-of-a-list","A_Votes":"133","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a list in Python, and I want to check if any elements are negative.  Specman has the has() method for lists which does:  x: list of uint; if (x.has(it < 0)) {     // do something };   Where it is a Specman keyword mapped to each element of the list in turn.  I find this rather elegant.  I looked through the Python documentation and couldn't find anything similar.  The best I could come up with was:  if (True in [t < 0 for t in x]):     # do something   I find this rather inelegant.  Is there a better way to do this in Python?     ","Q_Votes":"79"},{"Q_Title":"Pythonic way of checking if a condition holds for any element of a list","A_Content":"  Use any().  if any(t < 0 for t in x):     # do something      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/1342601/pythonic-way-of-checking-if-a-condition-holds-for-any-element-of-a-list","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I have a list in Python, and I want to check if any elements are negative.  Specman has the has() method for lists which does:  x: list of uint; if (x.has(it < 0)) {     // do something };   Where it is a Specman keyword mapped to each element of the list in turn.  I find this rather elegant.  I looked through the Python documentation and couldn't find anything similar.  The best I could come up with was:  if (True in [t < 0 for t in x]):     # do something   I find this rather inelegant.  Is there a better way to do this in Python?     ","Q_Votes":"79"},{"Q_Title":"Pythonic way of checking if a condition holds for any element of a list","A_Content":"  Python has a built in any() function for exactly this purpose.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/1342601/pythonic-way-of-checking-if-a-condition-holds-for-any-element-of-a-list","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have a list in Python, and I want to check if any elements are negative.  Specman has the has() method for lists which does:  x: list of uint; if (x.has(it < 0)) {     // do something };   Where it is a Specman keyword mapped to each element of the list in turn.  I find this rather elegant.  I looked through the Python documentation and couldn't find anything similar.  The best I could come up with was:  if (True in [t < 0 for t in x]):     # do something   I find this rather inelegant.  Is there a better way to do this in Python?     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  Use Python's readline bindings.  For example,  import readline  def completer(text, state):     options = [i for i in commands if i.startswith(text)]     if state < len(options):         return options[state]     else:         return None  readline.parse_and_bind(\"tab: complete\") readline.set_completer(completer)   The official module docs aren't much more detailed, see the readline docs for more info.     ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"51","_type":"dict","isAccepted":"Yes","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  Follow the cmd documentation and you'll be fine  import cmd  addresses = [     'here@blubb.com',     'foo@bar.com',     'whatever@wherever.org', ]  class MyCmd(cmd.Cmd):     def do_send(self, line):         pass      def complete_send(self, text, line, start_index, end_index):         if text:             return [                 address for address in addresses                 if address.startswith(text)             ]         else:             return addresses   if __name__ == '__main__':     my_cmd = MyCmd()     my_cmd.cmdloop()   Output for tab -> tab -> send -> tab -> tab -> f -> tab  (Cmd) help  send (Cmd) send foo@bar.com            here@blubb.com         whatever@wherever.org (Cmd) send foo@bar.com (Cmd)      ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"53","_type":"dict","isAccepted":"No","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  Since you say \"NOT interpreter\" in your question, I guess you don't want answers involving python readline and suchlike. (edit: in hindsight, that's obviously not the case. Ho hum. I think this info is interesting anyway, so I'll leave it here.)  I think you might be after this.  It's about adding shell-level completion to arbitrary commands, extending bash's own tab-completion.  In a nutshell, you'll create a file containing a shell-function that will generate possible completions, save it into /etc/bash_completion.d/ and register it with the command complete. Here's a snippet from the linked page:  _foo()  {     local cur prev opts     COMPREPLY=()     cur=\"${COMP_WORDS[COMP_CWORD]}\"     prev=\"${COMP_WORDS[COMP_CWORD-1]}\"     opts=\"--help --verbose --version\"      if [[ ${cur} == -* ]] ; then         COMPREPLY=( $(compgen -W \"${opts}\" -- ${cur}) )         return 0     fi } complete -F _foo foo   In this case, the typing foo --[TAB] will give you the values in the variable opts, i.e. --help, --verbose and --version. For your purposes, you'll essentially want to customise the values that are put into opts.  Do have a look at the example on the linked page, it's all pretty straightforward.      ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  I am surprised that nobody has mentioned argcomplete, here is an example from the docs:  from argcomplete.completers import ChoicesCompleter  parser.add_argument(\"--protocol\", choices=('http', 'https', 'ssh', 'rsync', 'wss')) parser.add_argument(\"--proto\").completer=ChoicesCompleter(('http', 'https', 'ssh', 'rsync', 'wss'))      ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  Here is a full-working version of the code that was very supplied by ephemient here (thank you).  import readline  addrs = ['angela@domain.com', 'michael@domain.com', 'david@test.com']  def completer(text, state):     options = [x for x in addrs if x.startswith(text)]     try:         return options[state]     except IndexError:         return None  readline.set_completer(completer) readline.parse_and_bind(\"tab: complete\")  while 1:     a = raw_input(\"> \")     print \"You entered\", a      ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"How to make a python, command-line program autocomplete arbitrary things NOT interpreter","A_Content":"  # ~/.pythonrc import rlcompleter, readline readline.parse_and_bind('tab:complete')  # ~/.bashrc export PYTHONSTARTUP=~/.pythonrc      ","Language":"Python","Tags":["python","linux","unix","command-line","autocomplete"],"URL":"https://stackoverflow.com/questions/187621/how-to-make-a-python-command-line-program-autocomplete-arbitrary-things-not-int","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am aware of how to setup autocompletion of python objects in the python interpreter (on unix).     Google shows many hits for explanations on how to do this. Unfortunately, there are so many references to that it is difficult to find what I need to do, which is slightly different.   I need to know how to enable, tab/auto completion of arbitrary items in a command-line program written in python.  My specific use case is a command-line python program that needs to send emails.  I want to be able to autocomplete email addresses (I have the addresses on disk) when the user types part of it (and optionally presses the TAB key).  I do not need it to work on windows or mac, just linux.     ","Q_Votes":"79"},{"Q_Title":"Using print statements only to debug","A_Content":"  The logging module has everything you could want. It may seem excessive at first, but only use the parts you need. I'd recommend using logging.basicConfig to toggle the logging level to stderr and the simple log methods, debug, info, warning, error and critical.  import logging, sys logging.basicConfig(stream=sys.stderr, level=logging.DEBUG) logging.debug('A debug message!') logging.info('We processed %d records', len(processed_records))      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6579496/using-print-statements-only-to-debug","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"    I have been coding a lot in Python of late. And I have been working with data that I haven't worked with before, using formulae never seen before and dealing with huge files.  All this made me write a lot of print statements to verify if it's all going right and identify the points of failure. But, generally, outputting so much information is not a good practice. How do I use the print statements only when I want to debug and let them be skipped when I don't want them to be printed?      ","Q_Votes":"79"},{"Q_Title":"Using print statements only to debug","A_Content":"  A simple way to do this is to call a logging function:  DEBUG = True  def log(s):     if DEBUG:         print s  log(\"hello world\")   Then you can change the value of DEBUG and run your code with or without logging.  The standard logging module has a more elaborate mechanism for this.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6579496/using-print-statements-only-to-debug","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I have been coding a lot in Python of late. And I have been working with data that I haven't worked with before, using formulae never seen before and dealing with huge files.  All this made me write a lot of print statements to verify if it's all going right and identify the points of failure. But, generally, outputting so much information is not a good practice. How do I use the print statements only when I want to debug and let them be skipped when I don't want them to be printed?      ","Q_Votes":"79"},{"Q_Title":"Using print statements only to debug","A_Content":"  Use the logging built-in library module instead of printing.  You create a Logger object (say logger), and then after that, whenever you insert a debug print, you just put:  logger.debug(\"Some string\")   You can use logger.setLevel at the start of the program to set the output level. If you set it to DEBUG, it will print all the debugs. Set it to INFO or higher and immediately all of the debugs will disappear.  You can also use it to log more serious things, at different levels (INFO, WARNING and ERROR).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6579496/using-print-statements-only-to-debug","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I have been coding a lot in Python of late. And I have been working with data that I haven't worked with before, using formulae never seen before and dealing with huge files.  All this made me write a lot of print statements to verify if it's all going right and identify the points of failure. But, generally, outputting so much information is not a good practice. How do I use the print statements only when I want to debug and let them be skipped when I don't want them to be printed?      ","Q_Votes":"79"},{"Q_Title":"Using print statements only to debug","A_Content":"  I don't know about others, but I was used to define a \"global constant\" (DEBUG) and then a global function (debug(msg)) that would print msg only if DEBUG == True.  Then I write my debug statements like:  debug('My value: %d' % value)   ...then I pick up unit testing and never did this again! :)     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6579496/using-print-statements-only-to-debug","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have been coding a lot in Python of late. And I have been working with data that I haven't worked with before, using formulae never seen before and dealing with huge files.  All this made me write a lot of print statements to verify if it's all going right and identify the points of failure. But, generally, outputting so much information is not a good practice. How do I use the print statements only when I want to debug and let them be skipped when I don't want them to be printed?      ","Q_Votes":"79"},{"Q_Title":"Using print statements only to debug","A_Content":"  First off, I will second the nomination of python's logging framework.  Be a little careful about how you use it, however.  Specifically: let the logging framework expand your variables, don't do it yourself.  For instance, instead of:  logging.debug(\"datastructure: %r\" % complex_dict_structure)   make sure you do:  logging.debug(\"datastructure: %r\", complex_dict_structure)   because while they look similar, the first version incurs the repr() cost even if it's disabled.  The second version avoid this.  Similarly, if you roll your own, I'd suggest something like:  def debug_stdout(sfunc):     print(sfunc())  debug = debug_stdout   called via:  debug(lambda: \"datastructure: %r\" % complex_dict_structure)   which will, again, avoid the overhead if you disable it by doing:  def debug_noop(*args, **kwargs):     pass  debug = debug_noop   The overhead of computing those strings probably doesn't matter unless they're either 1) expensive to compute or 2) the debug statement is in the middle of, say, an n^3 loop or something.  Not that I would know anything about that.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6579496/using-print-statements-only-to-debug","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have been coding a lot in Python of late. And I have been working with data that I haven't worked with before, using formulae never seen before and dealing with huge files.  All this made me write a lot of print statements to verify if it's all going right and identify the points of failure. But, generally, outputting so much information is not a good practice. How do I use the print statements only when I want to debug and let them be skipped when I don't want them to be printed?      ","Q_Votes":"79"},{"Q_Title":"Why does Python allow function calls with wrong number of arguments?","A_Content":"  Python cannot know up-front what object you'll end up calling, because being dynamic, you can swap out the function object. At any time. And each of these objects can have a different number of arguments.  Here is an extreme example:  import random  def foo(): pass def bar(arg1): pass def baz(arg1, arg2): pass  the_function = random.choice([foo, bar, baz]) print(the_function())   The above code has a 2 in 3 chance of raising an exception. But Python cannot know a-priori if that'll be the case or not!  And I haven't even started with dynamic module imports, dynamic function generation, other callable objects (any object with a __call__ method can be called), or catch-all arguments (*args and **kwargs).  But to make this extra clear, you state in your question:     It is not going to change while the program is running.   This is not the case, not in Python, once the module is loaded you can delete, add or replace any object in the module namespace, including function objects.     ","Language":"Python","Tags":["python","arguments"],"URL":"https://stackoverflow.com/questions/34567770/why-does-python-allow-function-calls-with-wrong-number-of-arguments","A_Votes":"144","_type":"dict","isAccepted":"Yes","Q_Content":"    Python is my first dynamic language. I recently coded a function call incorrectly supplying a wrong number of arguments. This failed with an exception at the time that function was called. I expected that even in a dynamic language, this kind of error can be detected when the source file is parsed.  I understand that the type of actual arguments is not known until the function is called, because the same variable may contain values of any type at different times. But the number of arguments is known as soon as the source file is parsed. It is not going to change while the program is running.  So that this is not a philosophical question  To keep this in scope of Stack Overflow, let me phrase the question like this. Is there some feature, that Python offers, that requires it to delay checking the number of arguments in a function call until the code actually executes?     ","Q_Votes":"79"},{"Q_Title":"Why does Python allow function calls with wrong number of arguments?","A_Content":"    The number of arguments being passed is known, but not the function which is actually called. See this example:  def foo():     print(\"I take no arguments.\")  def bar():     print(\"I call foo\")     foo()   This might seem obvious, but let us put these into a file called \"fubar.py\". Now, in an interactive Python session, do this:  >>> import fubar >>> fubar.foo() I take no arguments. >>> fubar.bar() I call foo I take no arguments.   That was obvious. Now for the fun part. Well define a function which requires a non-zero amount of arguments:  >>> def notfoo(a): ...    print(\"I take arguments!\") ...   Now we do something which is called monkey patching. We can in fact replace the function foo in the fubar module:  >>> fubar.foo = notfoo   Now, when we call bar, a TypeError will be raised; the name foo now refers to the function we defined above instead of the original function formerly-known-as-foo.  >>> fubar.bar() I call foo Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/home/horazont/tmp/fubar.py\", line 6, in bar     foo() TypeError: notfoo() missing 1 required positional argument: 'a'   So even in a situation like this, where it might seem very obvious that the called function foo takes no arguments, Python can only know that it is actually the foo function which is being called when it executes that source line.  This is a property of Python which makes it powerful, but it also causes some of its slowness. In fact, making modules read-only to improve performance has been discussed on the python-ideas mailinglist some time ago, but it didn't gain any real support.     ","Language":"Python","Tags":["python","arguments"],"URL":"https://stackoverflow.com/questions/34567770/why-does-python-allow-function-calls-with-wrong-number-of-arguments","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    Python is my first dynamic language. I recently coded a function call incorrectly supplying a wrong number of arguments. This failed with an exception at the time that function was called. I expected that even in a dynamic language, this kind of error can be detected when the source file is parsed.  I understand that the type of actual arguments is not known until the function is called, because the same variable may contain values of any type at different times. But the number of arguments is known as soon as the source file is parsed. It is not going to change while the program is running.  So that this is not a philosophical question  To keep this in scope of Stack Overflow, let me phrase the question like this. Is there some feature, that Python offers, that requires it to delay checking the number of arguments in a function call until the code actually executes?     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  You could use an instance of the csv module's Sniffer class to deduce the format of a CSV file and detect whether a header row is present along with the built-in next() function to skip over the first row only when necessary:  import csv  with open('all16.csv', 'r', newline='') as file:     has_header = csv.Sniffer().has_header(file.read(1024))     file.seek(0)  # Rewind.     reader = csv.reader(file)     if has_header:         next(reader)  # Skip header row.     column = 1     datatype = float     data = (datatype(row[column]) for row in reader)     least_value = min(data)      print(least_value)   Since datatype and column are hardcoded in your example, it would be slightly faster to process the row like this:      data = (float(row[1]) for row in reader)   Note: the code above is for Python 3.x. For Python 2.x use the following line to open the file instead of what is shown:  with open('all16.csv', 'rb') as file:      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"86","_type":"dict","isAccepted":"Yes","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  To skip the first line just call:  next(inf)   Files in Python are iterators over lines.     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  You would normally use next(incsv) which advances the iterator one row, so you skip the header. The other (say you wanted to skip 30 rows) would be:  from itertools import islice for row in islice(incsv, 30, None):     # process      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  In a similar use case I had to skip annoying lines before the line with my actual column names. This solution worked nicely. Read the file first, then pass the list to csv.DictReader.  with open('all16.csv') as tmp:     # Skip first line (if any)     next(tmp, None)      # {line_num: row}     data = dict(enumerate(csv.DictReader(tmp)))      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  use csv.DictReader instead of csv.Reader. If the fieldnames parameter is omitted, the values in the first row of the csvfile will be used as field names. you would then be able to access field values using row[\"1\"] etc     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  Borrowed from python cookbook,  A more concise template code might look like this:   import csv with open('stocks.csv') as f:     f_csv = csv.reader(f)      headers = next(f_csv)      for row in f_csv:         # Process row ...      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  The new 'pandas' package might be more relevant than 'csv'. The code below will read a CSV file, by default interpreting the first line as the column header and find the minimum across columns.  import pandas as pd  data = pd.read_csv('all16.csv') data.min()      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  Well, my mini wrapper library would do the job as well.  >>> import pyexcel as pe >>> data = pe.load('all16.csv', name_columns_by_row=0) >>> min(data.column[1])   Meanwhile, if you know what header column index one is, for example \"Column 1\", you can do this instead:  >>> min(data.column[\"Column 1\"])      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  For me the easiest way to go is to use range.     import csv  with open('files/filename.csv') as I:     reader = csv.reader(I)     fulllist = list(reader)  # Starting with data skipping header for item in range(1, len(fulllist)):      # Print each row using \"item\" as the index value     print (fulllist[item])        ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  I would use tail to get rid of the unwanted first line:  tail -n +2 $INFIL | whatever_script.py       ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  just add [1:]  example below:  data = pd.read_csv(\"/Users/xyz/Desktop/xyxData/xyz.csv\", sep=',', header=None)**[1:]**   that works for me in iPython     ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  Python 3.X  Handles UTF8 BOM + HEADER  It was quite frustrating that the csv module could not easily get the header, there is also a bug with the UTF-8 BOM (first char in file). This works for me using only the csv module:  import csv  def read_csv(self, csv_path, delimiter):     with open(csv_path, newline='', encoding='utf-8') as f:         # https://bugs.python.org/issue7185         # Remove UTF8 BOM.         txt = f.read()[1:]      # Remove header line.     header = txt.splitlines()[:1]     lines = txt.splitlines()[1:]      # Convert to list.     csv_rows = list(csv.reader(lines, delimiter=delimiter))      for row in csv_rows:         value = row[INDEX_HERE]      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"When processing CSV data, how do I ignore the first line of data?","A_Content":"  Because this is related to something I was doing, I'll share here.   What if we're not sure if there's a header and you also don't feel like importing sniffer and other things?   If your task is basic, such as printing or appending to a list or array, you could just use an if statement:  # Let's say there's 4 columns with open('file.csv') as csvfile:      csvreader = csv.reader(csvfile) # read first line      first_line = next(csvreader) # My headers were just text. You can use any suitable conditional here      if len(first_line) == 4:           array.append(first_line) # Now we'll just iterate over everything else as usual:      for row in csvreader:           array.append(row)      ","Language":"Python","Tags":["python","csv"],"URL":"https://stackoverflow.com/questions/11349333/when-processing-csv-data-how-do-i-ignore-the-first-line-of-data","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?  This is the code so far:  import csv  with open('all16.csv', 'rb') as inf:     incsv = csv.reader(inf)     column = 1                     datatype = float               data = (datatype(column) for row in incsv)        least_value = min(data)  print least_value   Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.     ","Q_Votes":"79"},{"Q_Title":"Python module os.chmod(file, 664) does not change the permission to rw-rw-r but -w--wx----","A_Content":"  Found this on a different forum     If you're wondering why that leading zero is important, it's because   permissions are set as an octal integer, and Python automagically   treats any integer with a leading zero as octal. So os.chmod(\"file\",   484) (in decimal) would give the same result.   What you are doing is passing 664 which in octal is 1230  In your case you would need   os.chmod(\"/tmp/test_file\", 436)     [Update]  Note, for Python 3 you have prefix with 0o (zero oh). E.G, 0o666     ","Language":"Python","Tags":["python","file","permissions","chmod"],"URL":"https://stackoverflow.com/questions/15607903/python-module-os-chmodfile-664-does-not-change-the-permission-to-rw-rw-r-bu","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    Recently I am using Python module os, when I tried to change the permission of a file, I did not get the expected result. For example, I intended to change the permission to rw-rw-r--,  os.chmod(\"/tmp/test_file\", 664)   The ownership permission is actually -w--wx--- (230)  --w--wx--- 1 ag ag 0 Mar 25 05:45 test_file   However, if I change 664 to 0664 in the code, the result is just what I need, e.g.  os.chmod(\"/tmp/test_file\", 0664)   The result is:  -rw-rw-r-- 1 ag ag 0 Mar 25 05:55 test_file   Could anybody help explaining why does that leading 0 is so important to get the correct result?     ","Q_Votes":"79"},{"Q_Title":"Python module os.chmod(file, 664) does not change the permission to rw-rw-r but -w--wx----","A_Content":"  So for people who want semantics similar to:  $ chmod 755 somefile   In python 2:  $ python -c \"import os; os.chmod('somefile', 0755)\"   In python 3:  $ python3 -c \"import os; os.chmod('somefile', 0o755)\"      ","Language":"Python","Tags":["python","file","permissions","chmod"],"URL":"https://stackoverflow.com/questions/15607903/python-module-os-chmodfile-664-does-not-change-the-permission-to-rw-rw-r-bu","A_Votes":"92","_type":"dict","isAccepted":"No","Q_Content":"    Recently I am using Python module os, when I tried to change the permission of a file, I did not get the expected result. For example, I intended to change the permission to rw-rw-r--,  os.chmod(\"/tmp/test_file\", 664)   The ownership permission is actually -w--wx--- (230)  --w--wx--- 1 ag ag 0 Mar 25 05:45 test_file   However, if I change 664 to 0664 in the code, the result is just what I need, e.g.  os.chmod(\"/tmp/test_file\", 0664)   The result is:  -rw-rw-r-- 1 ag ag 0 Mar 25 05:55 test_file   Could anybody help explaining why does that leading 0 is so important to get the correct result?     ","Q_Votes":"79"},{"Q_Title":"Python module os.chmod(file, 664) does not change the permission to rw-rw-r but -w--wx----","A_Content":"  leading \"0\" means this is octal constant, not the decimal one. and you need an octal to change file mode.  permissions are a bit mask, for example, rwxrwx--- is 111111000 in binary, and it's very easy to group bits by 3 to convert to the octal, than calculate the decimal representation.  0644 (octal) is 0.110.100.100 in binary (i've added dots for readability), or, as you may calculate, 420 in decimal.     ","Language":"Python","Tags":["python","file","permissions","chmod"],"URL":"https://stackoverflow.com/questions/15607903/python-module-os-chmodfile-664-does-not-change-the-permission-to-rw-rw-r-bu","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Recently I am using Python module os, when I tried to change the permission of a file, I did not get the expected result. For example, I intended to change the permission to rw-rw-r--,  os.chmod(\"/tmp/test_file\", 664)   The ownership permission is actually -w--wx--- (230)  --w--wx--- 1 ag ag 0 Mar 25 05:45 test_file   However, if I change 664 to 0664 in the code, the result is just what I need, e.g.  os.chmod(\"/tmp/test_file\", 0664)   The result is:  -rw-rw-r-- 1 ag ag 0 Mar 25 05:55 test_file   Could anybody help explaining why does that leading 0 is so important to get the correct result?     ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  On Ubuntu you may need to install the package manager pip first:  sudo apt-get install python-pip   Then install the python-dateutil package with:  sudo pip install python-dateutil      ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"158","_type":"dict","isAccepted":"Yes","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  You can find the dateutil package at https://pypi.python.org/pypi/python-dateutil. Extract it to somewhere and run the command:  python setup.py install  It worked for me!     ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  None of the solutions worked for me. If you are using PIP do:    pip install pycrypto==2.6.1     ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  If you're using a virtualenv, make sure that you are running pip from within the virtualenv.   $ which pip /Library/Frameworks/Python.framework/Versions/Current/bin/pip $ find . -name pip -print ./flask/bin/pip ./flask/lib/python2.7/site-packages/pip $ ./flask/bin/pip install python-dateutil      ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  For Python 3 above, use:  sudo apt-get install python3-dateutil      ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"ImportError: No module named dateutil.parser","A_Content":"  If you are using Pipenv, you may need to add this to your Pipfile:  [packages] python-dateutil = \"*\"      ","Language":"Python","Tags":["python","pandas","pip"],"URL":"https://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am receiving the following error when importing pandas in a Python program  monas-mbp:book mona$ sudo pip install python-dateutil Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python Cleaning up... monas-mbp:book mona$ python t1.py No module named dateutil.parser Traceback (most recent call last):   File \"t1.py\", line 4, in <module>     import pandas as pd   File \"/Library/Python/2.7/site-packages/pandas/__init__.py\", line 6, in <module>     from . import hashtable, tslib, lib   File \"tslib.pyx\", line 31, in init pandas.tslib (pandas/tslib.c:48782) ImportError: No module named dateutil.parser   Also here's the program:  import codecs  from math import sqrt import numpy as np import pandas as pd  users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,                       \"Norah Jones\": 4.5, \"Phoenix\": 5.0,                       \"Slightly Stoopid\": 1.5,                       \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},           \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,                  \"Deadmau5\": 4.0, \"Phoenix\": 2.0,                  \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},           \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,                   \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,                   \"Slightly Stoopid\": 1.0},           \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,                  \"Deadmau5\": 4.5, \"Phoenix\": 3.0,                  \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                  \"Vampire Weekend\": 2.0},           \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,                     \"Norah Jones\": 4.0, \"The Strokes\": 4.0,                     \"Vampire Weekend\": 1.0},           \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,                      \"Norah Jones\": 5.0, \"Phoenix\": 5.0,                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,                      \"Vampire Weekend\": 4.0},           \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,                  \"Norah Jones\": 3.0, \"Phoenix\": 5.0,                  \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},           \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,                       \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,                       \"The Strokes\": 3.0}         }    class recommender:      def __init__(self, data, k=1, metric='pearson', n=5):         \"\"\" initialize recommender         currently, if data is dictionary the recommender is initialized         to it.         For all other data types of data, no initialization occurs         k is the k value for k nearest neighbor         metric is which distance formula to use         n is the maximum number of recommendations to make\"\"\"         self.k = k         self.n = n         self.username2id = {}         self.userid2name = {}         self.productid2name = {}         # for some reason I want to save the name of the metric         self.metric = metric         if self.metric == 'pearson':             self.fn = self.pearson         #         # if data is dictionary set recommender data to it         #         if type(data).__name__ == 'dict':             self.data = data      def convertProductID2name(self, id):         \"\"\"Given product id number return product name\"\"\"         if id in self.productid2name:             return self.productid2name[id]         else:             return id       def userRatings(self, id, n):         \"\"\"Return n top ratings for user with id\"\"\"         print (\"Ratings for \" + self.userid2name[id])         ratings = self.data[id]         print(len(ratings))         ratings = list(ratings.items())         ratings = [(self.convertProductID2name(k), v)                    for (k, v) in ratings]         # finally sort and return         ratings.sort(key=lambda artistTuple: artistTuple[1],                      reverse = True)         ratings = ratings[:n]         for rating in ratings:             print(\"%s\\t%i\" % (rating[0], rating[1]))         def loadBookDB(self, path=''):         \"\"\"loads the BX book dataset. Path is where the BX files are         located\"\"\"         self.data = {}         i = 0         #         # First load book ratings into self.data         #         f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             user = fields[0].strip('\"')             book = fields[1].strip('\"')             rating = int(fields[2].strip().strip('\"'))             if user in self.data:                 currentRatings = self.data[user]             else:                 currentRatings = {}             currentRatings[book] = rating             self.data[user] = currentRatings         f.close()         #         # Now load books into self.productid2name         # Books contains isbn, title, and author among other fields         #         f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')         for line in f:             i += 1             #separate line into fields             fields = line.split(';')             isbn = fields[0].strip('\"')             title = fields[1].strip('\"')             author = fields[2].strip().strip('\"')             title = title + ' by ' + author             self.productid2name[isbn] = title         f.close()         #         #  Now load user info into both self.userid2name and         #  self.username2id         #         f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')         for line in f:             i += 1             #print(line)             #separate line into fields             fields = line.split(';')             userid = fields[0].strip('\"')             location = fields[1].strip('\"')             if len(fields) > 3:                 age = fields[2].strip().strip('\"')             else:                 age = 'NULL'             if age != 'NULL':                 value = location + '  (age: ' + age + ')'             else:                 value = location             self.userid2name[userid] = value             self.username2id[location] = userid         f.close()         print(i)       def pearson(self, rating1, rating2):         sum_xy = 0         sum_x = 0         sum_y = 0         sum_x2 = 0         sum_y2 = 0         n = 0         for key in rating1:             if key in rating2:                 n += 1                 x = rating1[key]                 y = rating2[key]                 sum_xy += x * y                 sum_x += x                 sum_y += y                 sum_x2 += pow(x, 2)                 sum_y2 += pow(y, 2)         if n == 0:             return 0         # now compute denominator         denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)                        * sqrt(sum_y2 - pow(sum_y, 2) / n))         if denominator == 0:             return 0         else:             return (sum_xy - (sum_x * sum_y) / n) / denominator       def computeNearestNeighbor(self, username):         \"\"\"creates a sorted list of users based on their distance to         username\"\"\"         distances = []         for instance in self.data:             if instance != username:                 distance = self.fn(self.data[username],                                    self.data[instance])                 distances.append((instance, distance))         # sort based on distance -- closest first         distances.sort(key=lambda artistTuple: artistTuple[1],                        reverse=True)         return distances      def recommend(self, user):        \"\"\"Give list of recommendations\"\"\"        recommendations = {}        # first get list of users  ordered by nearness        nearest = self.computeNearestNeighbor(user)        #        # now get the ratings for the user        #        userRatings = self.data[user]        #        # determine the total distance        totalDistance = 0.0        for i in range(self.k):           totalDistance += nearest[i][1]        # now iterate through the k nearest neighbors        # accumulating their ratings        for i in range(self.k):           # compute slice of pie            weight = nearest[i][1] / totalDistance           # get the name of the person           name = nearest[i][0]           # get the ratings for this person           neighborRatings = self.data[name]           # get the name of the person           # now find bands neighbor rated that user didn't           for artist in neighborRatings:              if not artist in userRatings:                 if artist not in recommendations:                    recommendations[artist] = (neighborRatings[artist]                                               * weight)                 else:                    recommendations[artist] = (recommendations[artist]                                               + neighborRatings[artist]                                               * weight)        # now make list from dictionary        recommendations = list(recommendations.items())        recommendations = [(self.convertProductID2name(k), v)                           for (k, v) in recommendations]        # finally sort and return        recommendations.sort(key=lambda artistTuple: artistTuple[1],                             reverse = True)        # Return the first n items        return recommendations[:self.n]  r = recommender(users) # The author implementation r.loadBookDB('/Users/mona/Downloads/BX-Dump/')  ratings = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Book-Ratings.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") books = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Books.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\") users = pd.read_csv('/Users/danialt/BX-CSV-Dump/BX-Users.csv', sep=\";\", quotechar=\"\\\"\", escapechar=\"\\\\\")    pivot_rating = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating')      ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  Personally, one of the things I love about python is the tuple-dict combination. What you have here is effectively a 2d array (where x = fruit name and y = color), and I am generally a supporter of the dict of tuples for implementing 2d arrays, at least when something like numpy or a database isn't more appropriate. So in short, I think you've got a good approach.  Note that you can't use dicts as keys in a dict without doing some extra work, so that's not a very good solution.   That said, you should also consider namedtuple(). That way you could do this:  >>> from collections import namedtuple >>> Fruit = namedtuple(\"Fruit\", [\"name\", \"color\"]) >>> f = Fruit(name=\"banana\", color=\"red\") >>> print f Fruit(name='banana', color='red') >>> f.name 'banana' >>> f.color 'red'   Now you can use your fruitcount dict:  >>> fruitcount = {Fruit(\"banana\", \"red\"):5} >>> fruitcount[f] 5   Other tricks:  >>> fruits = fruitcount.keys() >>> fruits.sort() >>> print fruits [Fruit(name='apple', color='green'),   Fruit(name='apple', color='red'),   Fruit(name='banana', color='blue'),   Fruit(name='strawberry', color='blue')] >>> fruits.sort(key=lambda x:x.color) >>> print fruits [Fruit(name='banana', color='blue'),   Fruit(name='strawberry', color='blue'),   Fruit(name='apple', color='green'),   Fruit(name='apple', color='red')]   Echoing chmullig, to get a list of all colors of one fruit, you would have to filter the keys, i.e.   bananas = [fruit for fruit in fruits if fruit.name=='banana']      ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"123","_type":"dict","isAccepted":"Yes","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  Your best option will be to create a simple data structure to model what you have.  Then you can store these objects in a simple list and sort/retrieve them any way you wish.  For this case, I'd use the following class:  class Fruit:     def __init__(self, name, color, quantity):          self.name = name         self.color = color         self.quantity = quantity      def __str__(self):         return \"Name: %s, Color: %s, Quantity: %s\" % \\      (self.name, self.color, self.quantity)   Then you can simply construct \"Fruit\" instances and add them to a list, as shown in the following manner:  fruit1 = Fruit(\"apple\", \"red\", 12) fruit2 = Fruit(\"pear\", \"green\", 22) fruit3 = Fruit(\"banana\", \"yellow\", 32) fruits = [fruit3, fruit2, fruit1]    The simple list fruits will be much easier, less confusing, and better-maintained.    Some examples of use:  All outputs below is the result after running the given code snippet followed by:  for fruit in fruits:     print fruit   Unsorted list:  Displays:  Name: banana, Color: yellow, Quantity: 32 Name: pear, Color: green, Quantity: 22 Name: apple, Color: red, Quantity: 12   Sorted alphabetically by name:  fruits.sort(key=lambda x: x.name.lower())   Displays:  Name: apple, Color: red, Quantity: 12 Name: banana, Color: yellow, Quantity: 32 Name: pear, Color: green, Quantity: 22   Sorted by quantity:  fruits.sort(key=lambda x: x.quantity)   Displays:  Name: apple, Color: red, Quantity: 12 Name: pear, Color: green, Quantity: 22 Name: banana, Color: yellow, Quantity: 32   Where color == red:  red_fruit = filter(lambda f: f.color == \"red\", fruits)   Displays:  Name: apple, Color: red, Quantity: 12      ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  Database, dict of dicts, dictionary of list of dictionaries, named tuple (it's a subclass), sqlite, redundancy...  I didn't believe my eyes. What else ?     \"It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.\"      \"my gut feeling is that a database is overkill for the OP's needs; \"   Yeah! I thought  So, in my opinion, a list of tuples is plenty enough :  from operator import itemgetter  li = [  ('banana',     'blue'   , 24) ,         ('apple',      'green'  , 12) ,         ('strawberry', 'blue'   , 16 ) ,         ('banana',     'yellow' , 13) ,         ('apple',      'gold'   , 3 ) ,         ('pear',       'yellow' , 10) ,         ('strawberry', 'orange' , 27) ,         ('apple',      'blue'   , 21) ,         ('apple',      'silver' , 0 ) ,         ('strawberry', 'green'  , 4 ) ,         ('banana',     'brown'  , 14) ,         ('strawberry', 'yellow' , 31) ,         ('apple',      'pink'   , 9 ) ,         ('strawberry', 'gold'   , 0 ) ,         ('pear',       'gold'   , 66) ,         ('apple',      'yellow' , 9 ) ,         ('pear',       'brown'  , 5 ) ,         ('strawberry', 'pink'   , 8 ) ,         ('apple',      'purple' , 7 ) ,         ('pear',       'blue'   , 51) ,         ('chesnut',    'yellow',  0 )   ]   print set( u[1] for u in li ),': all potential colors' print set( c for f,c,n in li if n!=0),': all effective colors' print [ c for f,c,n in li if f=='banana' ],': all potential colors of bananas' print [ c for f,c,n in li if f=='banana' and n!=0],': all effective colors of bananas' print  print set( u[0] for u in li ),': all potential fruits' print set( f for f,c,n in li if n!=0),': all effective fruits' print [ f for f,c,n in li if c=='yellow' ],': all potential fruits being yellow' print [ f for f,c,n in li if c=='yellow' and n!=0],': all effective fruits being yellow' print  print len(set( u[1] for u in li )),': number of all potential colors' print len(set(c for f,c,n in li if n!=0)),': number of all effective colors' print len( [c for f,c,n in li if f=='strawberry']),': number of potential colors of strawberry' print len( [c for f,c,n in li if f=='strawberry' and n!=0]),': number of effective colors of strawberry' print  # sorting li by name of fruit print sorted(li),'  sorted li by name of fruit' print  # sorting li by number  print sorted(li, key = itemgetter(2)),'  sorted li by number' print  # sorting li first by name of color and secondly by name of fruit print sorted(li, key = itemgetter(1,0)),'  sorted li first by name of color and secondly by name of fruit' print   result  set(['blue', 'brown', 'gold', 'purple', 'yellow', 'pink', 'green', 'orange', 'silver']) : all potential colors set(['blue', 'brown', 'gold', 'purple', 'yellow', 'pink', 'green', 'orange']) : all effective colors ['blue', 'yellow', 'brown'] : all potential colors of bananas ['blue', 'yellow', 'brown'] : all effective colors of bananas  set(['strawberry', 'chesnut', 'pear', 'banana', 'apple']) : all potential fruits set(['strawberry', 'pear', 'banana', 'apple']) : all effective fruits ['banana', 'pear', 'strawberry', 'apple', 'chesnut'] : all potential fruits being yellow ['banana', 'pear', 'strawberry', 'apple'] : all effective fruits being yellow  9 : number of all potential colors 8 : number of all effective colors 6 : number of potential colors of strawberry 5 : number of effective colors of strawberry  [('apple', 'blue', 21), ('apple', 'gold', 3), ('apple', 'green', 12), ('apple', 'pink', 9), ('apple', 'purple', 7), ('apple', 'silver', 0), ('apple', 'yellow', 9), ('banana', 'blue', 24), ('banana', 'brown', 14), ('banana', 'yellow', 13), ('chesnut', 'yellow', 0), ('pear', 'blue', 51), ('pear', 'brown', 5), ('pear', 'gold', 66), ('pear', 'yellow', 10), ('strawberry', 'blue', 16), ('strawberry', 'gold', 0), ('strawberry', 'green', 4), ('strawberry', 'orange', 27), ('strawberry', 'pink', 8), ('strawberry', 'yellow', 31)]   sorted li by name of fruit  [('apple', 'silver', 0), ('strawberry', 'gold', 0), ('chesnut', 'yellow', 0), ('apple', 'gold', 3), ('strawberry', 'green', 4), ('pear', 'brown', 5), ('apple', 'purple', 7), ('strawberry', 'pink', 8), ('apple', 'pink', 9), ('apple', 'yellow', 9), ('pear', 'yellow', 10), ('apple', 'green', 12), ('banana', 'yellow', 13), ('banana', 'brown', 14), ('strawberry', 'blue', 16), ('apple', 'blue', 21), ('banana', 'blue', 24), ('strawberry', 'orange', 27), ('strawberry', 'yellow', 31), ('pear', 'blue', 51), ('pear', 'gold', 66)]   sorted li by number  [('apple', 'blue', 21), ('banana', 'blue', 24), ('pear', 'blue', 51), ('strawberry', 'blue', 16), ('banana', 'brown', 14), ('pear', 'brown', 5), ('apple', 'gold', 3), ('pear', 'gold', 66), ('strawberry', 'gold', 0), ('apple', 'green', 12), ('strawberry', 'green', 4), ('strawberry', 'orange', 27), ('apple', 'pink', 9), ('strawberry', 'pink', 8), ('apple', 'purple', 7), ('apple', 'silver', 0), ('apple', 'yellow', 9), ('banana', 'yellow', 13), ('chesnut', 'yellow', 0), ('pear', 'yellow', 10), ('strawberry', 'yellow', 31)]   sorted li first by name of color and secondly by name of fruit      ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  A dictionary probably isn't what you should be using in this case. A more full featured library would be a better alternative. Probably a real database. The easiest would be sqlite. You can keep the whole thing in memory by passing in the string ':memory:' instead of a filename.  If you do want to continue down this path, you can do it with the extra attributes in the key or the value. However a dictionary can't be the key to a another dictionary, but a tuple can. The docs explain what's allowable. It must be an immutable object, which includes strings, numbers and tuples that contain only strings and numbers (and more tuples containing only those types recursively...).   You could do your first example with d = {('apple', 'red') : 4}, but it'll be very hard to query for what you want. You'd need to do something like this:  #find all apples apples = [d[key] for key in d.keys() if key[0] == 'apple']  #find all red items red = [d[key] for key in d.keys() if key[1] == 'red']  #the red apple redapples = d[('apple', 'red')]      ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  With keys as tuples, you just filter the keys with given second component and sort it:  blue_fruit = sorted([k for k in data.keys() if k[1] == 'blue']) for k in blue_fruit:   print k[0], data[k] # prints 'banana 24', etc   Sorting works because tuples have natural ordering if their components have natural ordering.  With keys as rather full-fledged objects, you just filter by k.color == 'blue'.   You can't really use dicts as keys, but you can create a simplest class like class Foo(object): pass and add any attributes to it on the fly:  k = Foo() k.color = 'blue'   These instances can serve as dict keys, but beware their mutability!     ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  You could have a dictionary where the entries are a list of other dictionaries:  fruit_dict = dict() fruit_dict['banana'] = [{'yellow': 24}] fruit_dict['apple'] = [{'red': 12}, {'green': 14}] print fruit_dict   Output:     {'banana': [{'yellow': 24}], 'apple': [{'red': 12}, {'green': 14}]}   Edit:  As eumiro pointed out, you could use a dictionary of dictionaries:  fruit_dict = dict() fruit_dict['banana'] = {'yellow': 24} fruit_dict['apple'] = {'red': 12, 'green': 14} print fruit_dict   Output:     {'banana': {'yellow': 24}, 'apple':   {'green': 14, 'red': 12}}      ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  This type of data is efficiently pulled from a Trie-like data structure.  It also allows for fast sorting. The memory efficiency might not be that great though.  A traditional trie stores each letter of a word as a node in the tree.  But in your case your \"alphabet\" is different.  You are storing strings instead of characters.  it might look something like this:  root:                Root                      /|\\                     / | \\                    /  |  \\      fruit:       Banana Apple Strawberry               / |      |     \\              /  |      |      \\ color:     Blue Yellow Green  Blue             /   |       |       \\            /    |       |        \\ end:      24   100      12        0   see this link: trie in python     ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"Python: Tuples/dictionaries as keys, select, sort","A_Content":"  You want to use two keys independently, so you have two choices:   Store the data redundantly with two dicts as {'banana' : {'blue' : 4, ...}, .... } and {'blue': {'banana':4, ...} ...}. Then, searching and sorting is easy but you have to make sure you modify the dicts together. Store it just one dict, and then write functions that iterate over them eg.:  d = {'banana' : {'blue' : 4, 'yellow':6}, 'apple':{'red':1} }  blueFruit = [(fruit,d[fruit]['blue']) if d[fruit].has_key('blue') for fruit in d.keys()]       ","Language":"Python","Tags":["python","select","dictionary","key","tuples"],"URL":"https://stackoverflow.com/questions/4878881/python-tuples-dictionaries-as-keys-select-sort","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    suppose I have quantities of fruits of different colors, e.g., 24 blue bananas, 12 green apples, 0 blue strawberries and so on. I'd like to organize them in a data structure in Python that allows for easy selection and sorting. My idea was to put them into a dictionary with tuples as keys, e.g.,  { ('banana',    'blue' ): 24,   ('apple',     'green'): 12,   ('strawberry','blue' ): 0,   ... }   or even dictionaries, e.g.,  { {'fruit': 'banana',    'color': 'blue' }: 24,   {'fruit': 'apple',     'color': 'green'}: 12,   {'fruit': 'strawberry','color': 'blue' }: 0,   ... }   I'd like to retrieve a list of all blue fruit, or bananas of all colors, for example, or to sort this dictionary by the name of the fruit. Are there ways to do this in a clean way?  It might well be that dictionaries with tuples as keys are not the proper way to handle this situation.  All suggestions welcome!     ","Q_Votes":"79"},{"Q_Title":"binning data in python with scipy/numpy","A_Content":"  It's probably faster and easier to use numpy.digitize():  import numpy data = numpy.random.random(100) bins = numpy.linspace(0, 1, 10) digitized = numpy.digitize(data, bins) bin_means = [data[digitized == i].mean() for i in range(1, len(bins))]   An alternative to this is to use numpy.histogram():  bin_means = (numpy.histogram(data, bins, weights=data)[0] /              numpy.histogram(data, bins)[0])   Try for yourself which one is faster... :)     ","Language":"Python","Tags":["python","numpy","scipy","scientific-computing"],"URL":"https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy","A_Votes":"136","_type":"dict","isAccepted":"Yes","Q_Content":"    is there a more efficient way to take an average of an array in prespecified bins? for example, i have an array of numbers and an array corresponding to bin start and end positions in that array, and I want to just take the mean in those bins? I have code that does it below but i am wondering how it can be cut down and improved. thanks.  from scipy import * from numpy import *  def get_bin_mean(a, b_start, b_end):     ind_upper = nonzero(a >= b_start)[0]     a_upper = a[ind_upper]     a_range = a_upper[nonzero(a_upper < b_end)[0]]     mean_val = mean(a_range)     return mean_val   data = rand(100) bins = linspace(0, 1, 10) binned_data = []  n = 0 for n in range(0, len(bins)-1):     b_start = bins[n]     b_end = bins[n+1]     binned_data.append(get_bin_mean(data, b_start, b_end))  print binned_data      ","Q_Votes":"79"},{"Q_Title":"binning data in python with scipy/numpy","A_Content":"  The Scipy (>=0.11) function scipy.stats.binned_statistic specifically addresses the above question.  For the same example as in the previous answers, the Scipy solution would be  import numpy as np from scipy.stats import binned_statistic  data = np.random.rand(100) bin_means = binned_statistic(data, data, bins=10, range=(0, 1))[0]      ","Language":"Python","Tags":["python","numpy","scipy","scientific-computing"],"URL":"https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    is there a more efficient way to take an average of an array in prespecified bins? for example, i have an array of numbers and an array corresponding to bin start and end positions in that array, and I want to just take the mean in those bins? I have code that does it below but i am wondering how it can be cut down and improved. thanks.  from scipy import * from numpy import *  def get_bin_mean(a, b_start, b_end):     ind_upper = nonzero(a >= b_start)[0]     a_upper = a[ind_upper]     a_range = a_upper[nonzero(a_upper < b_end)[0]]     mean_val = mean(a_range)     return mean_val   data = rand(100) bins = linspace(0, 1, 10) binned_data = []  n = 0 for n in range(0, len(bins)-1):     b_start = bins[n]     b_end = bins[n+1]     binned_data.append(get_bin_mean(data, b_start, b_end))  print binned_data      ","Q_Votes":"79"},{"Q_Title":"binning data in python with scipy/numpy","A_Content":"  Not sure why this thread got necroed; but here is a 2014 approved answer, which should be far faster:  import numpy as np  data = np.random.rand(100) bins = 10 slices = np.linspace(0, 100, bins+1, True).astype(np.int) counts = np.diff(slices)  mean = np.add.reduceat(data, slices[:-1]) / counts print mean      ","Language":"Python","Tags":["python","numpy","scipy","scientific-computing"],"URL":"https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    is there a more efficient way to take an average of an array in prespecified bins? for example, i have an array of numbers and an array corresponding to bin start and end positions in that array, and I want to just take the mean in those bins? I have code that does it below but i am wondering how it can be cut down and improved. thanks.  from scipy import * from numpy import *  def get_bin_mean(a, b_start, b_end):     ind_upper = nonzero(a >= b_start)[0]     a_upper = a[ind_upper]     a_range = a_upper[nonzero(a_upper < b_end)[0]]     mean_val = mean(a_range)     return mean_val   data = rand(100) bins = linspace(0, 1, 10) binned_data = []  n = 0 for n in range(0, len(bins)-1):     b_start = bins[n]     b_end = bins[n+1]     binned_data.append(get_bin_mean(data, b_start, b_end))  print binned_data      ","Q_Votes":"79"},{"Q_Title":"binning data in python with scipy/numpy","A_Content":"  The numpy_indexed package (disclaimer: I am its author) contains functionality to efficiently perform operations of this type:  import numpy_indexed as npi print(npi.group_by(np.digitize(data, bins)).mean(data))   This is essentially the same solution as the one I posted earlier; but now wrapped in a nice interface, with tests and all :)     ","Language":"Python","Tags":["python","numpy","scipy","scientific-computing"],"URL":"https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    is there a more efficient way to take an average of an array in prespecified bins? for example, i have an array of numbers and an array corresponding to bin start and end positions in that array, and I want to just take the mean in those bins? I have code that does it below but i am wondering how it can be cut down and improved. thanks.  from scipy import * from numpy import *  def get_bin_mean(a, b_start, b_end):     ind_upper = nonzero(a >= b_start)[0]     a_upper = a[ind_upper]     a_range = a_upper[nonzero(a_upper < b_end)[0]]     mean_val = mean(a_range)     return mean_val   data = rand(100) bins = linspace(0, 1, 10) binned_data = []  n = 0 for n in range(0, len(bins)-1):     b_start = bins[n]     b_end = bins[n+1]     binned_data.append(get_bin_mean(data, b_start, b_end))  print binned_data      ","Q_Votes":"79"},{"Q_Title":"binning data in python with scipy/numpy","A_Content":"  I would add, and also to answer the question find mean bin values using histogram2d python that the scipy also have a function specially designed to compute a bidimensional binned statistic for one or more sets of data  import numpy as np from scipy.stats import binned_statistic_2d  x = np.random.rand(100) y = np.random.rand(100) values = np.random.rand(100) bin_means = binned_statistic_2d(x, y, values, bins=10).statistic   the function scipy.stats.binned_statistic_dd is a generalization of this funcion for higher dimensions datasets     ","Language":"Python","Tags":["python","numpy","scipy","scientific-computing"],"URL":"https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    is there a more efficient way to take an average of an array in prespecified bins? for example, i have an array of numbers and an array corresponding to bin start and end positions in that array, and I want to just take the mean in those bins? I have code that does it below but i am wondering how it can be cut down and improved. thanks.  from scipy import * from numpy import *  def get_bin_mean(a, b_start, b_end):     ind_upper = nonzero(a >= b_start)[0]     a_upper = a[ind_upper]     a_range = a_upper[nonzero(a_upper < b_end)[0]]     mean_val = mean(a_range)     return mean_val   data = rand(100) bins = linspace(0, 1, 10) binned_data = []  n = 0 for n in range(0, len(bins)-1):     b_start = bins[n]     b_end = bins[n+1]     binned_data.append(get_bin_mean(data, b_start, b_end))  print binned_data      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I had the same problem (building python2.5 from source on Ubuntu Lucid), and import sqlite3 threw this same exception. I've installed libsqlite3-dev from the package manager, recompiled python2.5, and then the import worked.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  It seems your makefile didn't include the appropriate .so file. You can correct this problem with the steps below:   Install sqlite-devel (or libsqlite3-dev on some Debian-based systems) Re-configure and re-compiled Python with ./configure --enable-loadable-sqlite-extensions && make && sudo make install     Note  The sudo make install part will set that python version to be the system-wide standard, which can have unforseen consequences. If you run this command on your workstation, you'll probably want to have it installed alongside the existing python, which can be done with sudo make altinstall.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  This is what I did to get it to work.  I am using pythonbrew(which is using pip) with python 2.7.5 installed.  I first did what Zubair(above) said and ran this command:  sudo apt-get install libsqlite3-dev   Then I ran this command:  pip install pysqlite   This fixed the database problem and I got confirmation of this when I ran:  python manager.py syncdb      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I had the same problem with Python 3.5 on Ubuntu while using pyenv.  If you're installing the python using pyenv, it's listed as one of the common build problems. To solve it, remove the installed python version, install the requirements (for this particular case libsqlite3-dev), then reinstall the python version.      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"   Install the sqlite-devel package:  yum install sqlite-devel -y Recompile python from the source:  ./configure make make altinstall       ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  My _sqlite3.so is in /usr/lib/python2.5/lib-dynload/_sqlite3.so.  Judging from your paths, you should have the file /usr/local/lib/python2.5/lib-dynload/_sqlite3.so.  Try the following:  find /usr/local -name _sqlite3.so   If the file isn't found, something may be wrong with your Python installation.  If it is, make sure the path it's installed to is in the Python path.  In the Python shell,  import sys print sys.path   In my case, /usr/lib/python2.5/lib-dynload is in the list, so it's able to find /usr/lib/python2.5/lib-dynload/_sqlite3.so.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I recently tried installing python 2.6.7 on my Ubuntu 11.04 desktop for some dev work. Came across similar problems to this thread. I mamaged to fix it by:   Adjusting the setup.py file to include the correct sqlite dev path. Code snippet from setup.py:  def sqlite_incdir: sqlite_dirs_to_check = [ os.path.join(sqlite_incdir, '..', 'lib64'), os.path.join(sqlite_incdir, '..', 'lib'), os.path.join(sqlite_incdir, '..', '..', 'lib64'), os.path.join(sqlite_incdir, '..', '..', 'lib'), '/usr/lib/x86_64-linux-gnu/' ]   With the bit that I added being '/usr/lib/x86_64-linux-gnu/'. After running make I did not get any warnings saying the sqlite support was not built (i.e., it built correctly :P ), but after running make install, sqlite3 still did not import with the same \"ImportError: No module named _sqlite3\" whe running \"import sqlite3\".  So, the library was compiled, but not moved to the correct installation path, so I copied the .so file (cp /usr/src/python/Python-2.6.7/build/lib.linux-x86_64-2.6/_sqlite3.so /usr/local/python-2.6.7/lib/python2.6/sqlite3/  these are my build paths, you will probably need to adjust them to your setup).   Voila! SQLite3 support now works.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  This worked for me in Redhat Centos 6.5:  yum install sqlite-devel pip install pysqlite      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I found lots of people meet this problem because the Multi-version Python, on my own vps (cent os 7 x64), I solved it in this way:   Find the file \"_sqlite3.so\"   find / -name _sqlite3.so   out:  /usr/lib64/python2.7/lib-dynload/_sqlite3.so Find the dir of python Standard library you want to use,  for me /usr/local/lib/python3.6/lib-dynload Copy the file:  cp   /usr/lib64/python2.7/lib-dynload/_sqlite3.so /usr/local/lib/python3.6/lib-dynload    Finally, everything will be ok.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I have the  problem in FreeBSD 8.1:  - No module named _sqlite3 -   It is solved by stand the port ----------  /usr/ports/databases/py-sqlite3   after this one can see:  OK ---------- '>>>' import sqlite3 ----- '>>>' sqlite3.apilevel ----- '2.0'      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  sqlite3 ships with Python. I also had the same problem, I just uninstalled python3.6 and installed it again.  Uninstall existing python:  sudo apt-get remove --purge python3.6   Install python3.6:  sudo apt install build-essential checkinstall sudo apt install libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0.tar.xz tar xvf Python-3.6.0.tar.xz cd Python-3.6.0/ ./configure sudo make altinstall      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  Checking your settings.py file. Did you not just write \"sqlite\" instead of \"sqlite3\" for the database engine?     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  Is the python-pysqlite2 package installed?  sudo apt-get install python-pysqlite2      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  you must be in centos or redhat and compile python yourself it is pythons bug do this in your python source code dir and do this below  curl -sk https://gist.github.com/msabramo/2727063/raw/59ea097a1f4c6f114c32f7743308a061698b17fd/gistfile1.diff | patch -p1      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  I got the same problem, nothing worked for me from the above ans but now I fixed it by  just remove python.pip and sqlite3 and reinstall   sudo apt-get remove python.pip sudo apt-get remove sqlite3   now install it again   sudo apt-get install python.pip sudo apt-get install sqlite3   in my case while installing sqlite3 again it showed some error  then I typed    sqlite3    on terminal to check if it was removed or not and it started unpacking it  once the sqlite3 is installed fireup terminal and write   sqlite3 database.db (to create a database)   I'm sure this will definitely help you     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  Download sqlite3:  wget http://www.sqlite.org/2016/sqlite-autoconf-3150000.tar.gz   Follow these steps to install:  $tar xvfz sqlite-autoconf-3071502.tar.gz $cd sqlite-autoconf-3071502 $./configure --prefix=/usr/local $make install      ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"No module named _sqlite3","A_Content":"  Try copying _sqlite3.so so that Python can find it.  It should be as simple as:  cp /usr/lib64/python2.6/lib-dynload/_sqlite3.so /usr/local/lib/python2.7/   Trust me, try it.     ","Language":"Python","Tags":["python","django","sqlite","debian"],"URL":"https://stackoverflow.com/questions/1210664/no-module-named-sqlite3","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run a Django app on my VPS running Debian 5. When I run a demo app, it comes back with this error:    File \"/usr/local/lib/python2.5/site-packages/django/utils/importlib.py\", line 35, in     import_module     __import__(name)    File \"/usr/local/lib/python2.5/site-packages/django/db/backends/sqlite3/base.py\", line 30, in <module>     raise ImproperlyConfigured, \"Error loading %s: %s\" % (module, exc)  ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that     order): No module named _sqlite3   Looking at the Python install, it gives the same error:  Python 2.5.2 (r252:60911, May 12 2009, 07:46:31)  [GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sqlite3 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.5/sqlite3/__init__.py\", line 24, in <module>     from dbapi2 import *   File \"/usr/local/lib/python2.5/sqlite3/dbapi2.py\", line 27, in <module>     from _sqlite3 import * ImportError: No module named _sqlite3 >>>   Reading on the web, I learn that Python 2.5 should come with all the necessary SQLite wrappers included. Do I need to reinstall Python, or is there another way to get this module up and running?      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  Maybe there is a better way, but how about:  >>> import glob >>> types = ('*.pdf', '*.cpp') # the tuple of file types >>> files_grabbed = [] >>> for files in types: ...     files_grabbed.extend(glob.glob(files)) ...  >>> files_grabbed   # the list of pdf and cpp files   Perhaps there is another way, so wait in case someone else comes up with a better answer.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"89","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  Chain the results:  import itertools as it, glob  def multiple_file_types(*patterns):     return it.chain.from_iterable(glob.iglob(pattern) for pattern in patterns)   Then:  for filename in multiple_file_types(\"*.txt\", \"*.sql\", \"*.log\"):     # do stuff      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  from glob import glob  files = glob('*.gif') files.extend(glob('*.png')) files.extend(glob('*.jpg'))  print(files)   If you need to specify a path, loop over match patterns and keep the join inside the loop for simplicity:  from os.path import join from glob import glob  files = [] for ext in ('*.gif', '*.png', '*.jpg'):    files.extend(glob(join(\"path/to/dir\", ext)))  print(files)      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  glob returns a list: why not just run it multiple times and concatenate the results?  from glob import glob ProjectFiles = glob('*.txt') + glob('*.mdown') + glob('*markdown')      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  with glob it is not possible. you can use only: * matches everything ? matches any single character [seq] matches any character in seq [!seq] matches any character not in seq    use os.listdir and a regexp to check patterns:  for x in os.listdir('.'):   if re.match('.*\\.txt|.*\\.sql', x):     print x      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  For example, for *.mp3 and *.flac on multiple folders, you can do:  mask = r'music/*/*.[mf][pl][3a]*' glob.glob(mask)   The idea can be extended to more file extensions, but you have to check that the combinations won't match any other unwanted file extension you may have on those folders. So, be careful with this.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  After coming here for help, I made my own solution and wanted to share it. It's based on user2363986's answer, but I think this is more scalable. Meaning, that if you have 1000 extensions, the code will still look somewhat elegant.  from glob import glob  directoryPath  = \"C:\\\\temp\\\\*.\"  fileExtensions = [ \"jpg\", \"jpeg\", \"png\", \"bmp\", \"gif\" ] listOfFiles    = []  for extension in fileExtensions:     listOfFiles.extend( glob( directoryPath + extension ))  for file in listOfFiles:     print(file)   # Or do other stuff      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  I have released Formic which implements multiple includes in a similar way to Apache Ant's FileSet and Globs.  The search can be implemented:  import formic patterns = [\"*.txt\", \"*.markdown\", \"*.mdown\"] fileset = formic.FileSet(directory=projectDir, include=patterns) for file_name in fileset.qualified_files():     # Do something with file_name   Because the full Ant glob is implemented, you can include different directories with each pattern, so you could choose only those .txt files in one subdirectory, and the .markdown in another, for example:  patterns = [ \"/unformatted/**/*.txt\", \"/formatted/**/*.mdown\" ]   I hope this helps.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  Not glob, but here's another way using a list comprehension:  extensions = 'txt mdown markdown'.split() projectFiles = [f for f in os.listdir(projectDir)                    if os.path.splitext(f)[1][1:] in extensions]      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  The following function _glob globs for multiple file extensions.  import glob import os def _glob(path, *exts):     \"\"\"Glob for multiple file extensions      Parameters     ----------     path : str         A file name without extension, or directory name     exts : tuple         File extensions to glob for      Returns     -------     files : list         list of files matching extensions in exts in path      \"\"\"     path = os.path.join(path, \"*\") if os.path.isdir(path) else path + \"*\"     return [f for files in [glob.glob(path + ext) for ext in exts] for f in files]  files = _glob(projectDir, \".txt\", \".mdown\", \".markdown\")      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  Here is one-line list-comprehension variant of Pat's answer (which also includes that you wanted to glob in a specific project directory):  import os, glob exts = ['*.txt', '*.mdown', '*.markdown'] files = [f for ext in exts for f in glob.glob(os.path.join(project_dir, ext))]   You loop over the extensions (for ext in exts), and then for each extension you take each file matching the glob pattern (for f in glob.glob(os.path.join(project_dir, ext)).  This solution is short, and without any unnecessary for-loops, nested list-comprehensions, or functions to clutter the code. Just pure, expressive, pythonic Zen.   This solution allows you to have a custom list of exts that can be changed without having to update your code. (This is always a good practice!)  The list-comprehension is the same used in Laurent's solution (which I've voted for). But I would argue that it is usually unnecessary to factor out a single line to a separate function, which is why I'm providing this as an alternative solution.  Bonus:   If you need to search not just a single directory, but also all sub-directories, you can pass recursive=True and use the multi-directory glob symbol ** 1:  files = [f for ext in exts           for f in glob.glob(os.path.join(project_dir, '**', ext), recursive=True)]   This will invoke glob.glob('<project_dir>/**/*.txt', recursive=True) and so on for each extension.  1 Technically, the ** glob symbol simply matches one or more characters including forward-slash / (unlike the singular * glob symbol). In practice, you just need to remember that as long as you surround ** with forward slashes (path separators), it matches zero or more directories.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  This is a Python 3.4+ pathlib solution:  exts = \".pdf\", \".doc\", \".xls\", \".csv\", \".ppt\" filelist = (str(i) for i in map(pathlib.Path, os.listdir(src)) if i.suffix.lower() in exts and not i.stem.startswith(\"~\"))   Also it ignores all file names starting with ~.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  A one-liner, Just for the hell of it..  folder = \"C:\\\\multi_pattern_glob_one_liner\" files = [item for sublist in [glob.glob(folder + ext) for ext in [\"/*.txt\", \"/*.bat\"]] for item in sublist]   output:  ['C:\\\\multi_pattern_glob_one_liner\\\\dummy_txt.txt', 'C:\\\\multi_pattern_glob_one_liner\\\\dummy_bat.bat']      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  To glob multiple file types, you need to call glob() function several times in a loop. Since this function returns a list, you need to concatenate the lists.  For instance, this function do the job:  import glob import os   def glob_filetypes(root_dir, *patterns):     return [path             for pattern in patterns             for path in glob.glob(os.path.join(root_dir, pattern))]   Simple usage:  project_dir = \"path/to/project/dir\" for path in sorted(glob_filetypes(project_dir, '*.txt', '*.mdown', '*.markdown')):     print(path)   You can also use glob.iglob() to have an iterator:     Return an iterator which yields the same values as glob() without actually storing them all simultaneously.   def iglob_filetypes(root_dir, *patterns):     return (path             for pattern in patterns             for path in glob.iglob(os.path.join(root_dir, pattern)))      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  files = glob.glob('*.txt') files.extend(glob.glob('*.dat'))      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  You can try to make a manual list comparing the extension of existing with those you require.  ext_list = ['gif','jpg','jpeg','png']; file_list = [] for file in glob.glob('*.*'):   if file.rsplit('.',1)[1] in ext_list :     file_list.append(file)      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  You could use filter:  import os import glob  projectFiles = filter(     lambda x: os.path.splitext(x)[1] in [\".txt\", \".mdown\", \".markdown\"]     glob.glob(os.path.join(projectDir, \"*\")) )      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  You could also use reduce() like so:  import glob file_types = ['*.txt', '*.mdown', '*.markdown'] project_files = reduce(lambda list1, list2: list1 + list2, (glob.glob(t) for t in file_types))   this creates a list from glob.glob() for each pattern and reduces them to a single list.     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  import os     import glob import operator from functools import reduce  types = ('*.jpg', '*.png', '*.jpeg') lazy_paths = (glob.glob(os.path.join('my_path', t)) for t in types) paths = reduce(operator.add, lazy_paths, [])   https://docs.python.org/3.5/library/functools.html#functools.reduce https://docs.python.org/3.5/library/operator.html#operator.add     ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  One glob, many extensions... but imperfect solution (might match other files).  filetypes = ['tif', 'jpg']  filetypes = zip(*[list(ft) for ft in filetypes]) filetypes = [\"\".join(ch) for ch in filetypes] filetypes = [\"[%s]\" % ch for ch in filetypes] filetypes = \"\".join(filetypes) + \"*\" print(filetypes) # => [tj][ip][fg]*  glob.glob(\"/path/to/*.%s\" % filetypes)      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  I had the same issue and this is what I came up with   import os, sys, re  #without glob  src_dir = '/mnt/mypics/' src_pics = [] ext = re.compile('.*\\.(|{}|)$'.format('|'.join(['png', 'jpeg', 'jpg']).encode('utf-8'))) for root, dirnames, filenames in os.walk(src_dir):   for filename in filter(lambda name:ext.search(name),filenames):     src_pics.append(os.path.join(root, filename))      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  For example:  import glob lst_img = [] base_dir = '/home/xy/img/'  # get all the jpg file in base_dir  lst_img += glob.glob(base_dir + '*.jpg') print lst_img # ['/home/xy/img/2.jpg', '/home/xy/img/1.jpg']  # append all the png file in base_dir to lst_img lst_img += glob.glob(base_dir + '*.png') print lst_img # ['/home/xy/img/2.jpg', '/home/xy/img/1.jpg', '/home/xy/img/3.png']   A function:  import glob def get_files(base_dir='/home/xy/img/', lst_extension=['*.jpg', '*.png']):     \"\"\"     :param base_dir:base directory     :param lst_extension:lst_extension: list like ['*.jpg', '*.png', ...]     :return:file lists like ['/home/xy/img/2.jpg','/home/xy/img/3.png']     \"\"\"     lst_files = []     for ext in lst_extension:         lst_files += glob.glob(base_dir+ext)     return lst_files      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  Use a list of extension and iterate through  from os.path import join from glob import glob  files = ['*.gif', '*.png', '*.jpg'] for ext in files:    files.extend(glob(join(\"path/to/dir\", ext)))  print(files)      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  This Should Work:  import glob extensions = ('*.txt', '*.mdown', '*.markdown') for i in extensions:     for files in glob.glob(i):         print (files)      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Python glob multiple filetypes","A_Content":"  this worked for me:  import glob images = glob.glob('*.JPG' or '*.jpg' or '*.png')      ","Language":"Python","Tags":["python","glob"],"URL":"https://stackoverflow.com/questions/4568580/python-glob-multiple-filetypes","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Is there a better way to use glob.glob in python to get a list of multiple file types such as .txt, .mdown, and .markdown?  Right now I have something like this:  projectFiles1 = glob.glob( os.path.join(projectDir, '*.txt') ) projectFiles2 = glob.glob( os.path.join(projectDir, '*.mdown') ) projectFiles3 = glob.glob( os.path.join(projectDir, '*.markdown') )      ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  If you do not have any interoperability requirements (e.g. you are just going to use the data with Python) and a binary format is fine, go with cPickle which gives you really fast Python object serialization.  If you want interoperability or you want a text format to store your data, go with JSON (or some other appropriate format depending on your constraints).     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  I prefer JSON over pickle for my serialization. Unpickling can run arbitrary code, and using pickle to transfer data between programs or store data between sessions is a security hole. JSON does not introduce a security hole and is standardized, so the data can be accessed by programs in different languages if you ever need to.     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"80","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  You might also find this interesting, with some charts to compare: http://kovshenin.com/archives/pickle-vs-json-which-is-faster/     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"37","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  If you are primarily concerned with speed and space, use cPickle because cPickle is faster than JSON.  If you are more concerned with interoperability, security, and/or human readability, then use JSON.    The tests results referenced in other answers were recorded in 2010, and the updated tests in 2016 with cPickle protocol 2 show:   cPickle 3.8x faster loading cPickle 1.5x faster reading cPickle slightly smaller encoding   Reproduce this yourself with this gist, which is based on the Konstantin's benchmark referenced in other answers, but using cPickle with protocol 2 instead of pickle, and using json instead of simplejson (since json is faster than simplejson), e.g.  wget https://gist.github.com/jdimatteo/af317ef24ccf1b3fa91f4399902bb534/raw/03e8dbab11b5605bc572bc117c8ac34cfa959a70/pickle_vs_json.py python pickle_vs_json.py   Results with python 2.7 on a decent 2015 Xeon processor:  Dir Entries Method  Time    Length  dump    10  JSON    0.017   1484510 load    10  JSON    0.375   - dump    10  Pickle  0.011   1428790 load    10  Pickle  0.098   - dump    20  JSON    0.036   2969020 load    20  JSON    1.498   - dump    20  Pickle  0.022   2857580 load    20  Pickle  0.394   - dump    50  JSON    0.079   7422550 load    50  JSON    9.485   - dump    50  Pickle  0.055   7143950 load    50  Pickle  2.518   - dump    100 JSON    0.165   14845100 load    100 JSON    37.730  - dump    100 Pickle  0.107   14287900 load    100 Pickle  9.907   -   Python 3.4 with pickle protocol 3 is even faster.     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  JSON or pickle?  How about JSON and pickle! You can use jsonpickle.  It easy to use and the file on disk is readable because it's JSON.  http://jsonpickle.github.com/     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  Personally, I generally prefer JSON because the data is human-readable. Definitely, if you need to serialize something that JSON won't take, than use pickle.  But for most data storage, you won't need to serialize anything weird and JSON is much easier and always allows you to pop it open in a text editor and check out the data yourself.  The speed is nice, but for most datasets the difference is negligible; Python generally isn't too fast anyways.     ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Pickle or json?","A_Content":"  I have tried several methods and found out that using cPickle with setting the protocol argument of the dumps method as: cPickle.dumps(obj, protocol=cPickle.HIGHEST_PROTOCOL) is the fastest dump method.  import msgpack import json import pickle import timeit import cPickle import numpy as np  num_tests = 10  obj = np.random.normal(0.5, 1, [240, 320, 3])  command = 'pickle.dumps(obj)' setup = 'from __main__ import pickle, obj' result = timeit.timeit(command, setup=setup, number=num_tests) print(\"pickle:  %f seconds\" % result)  command = 'cPickle.dumps(obj)' setup = 'from __main__ import cPickle, obj' result = timeit.timeit(command, setup=setup, number=num_tests) print(\"cPickle:   %f seconds\" % result)   command = 'cPickle.dumps(obj, protocol=cPickle.HIGHEST_PROTOCOL)' setup = 'from __main__ import cPickle, obj' result = timeit.timeit(command, setup=setup, number=num_tests) print(\"cPickle highest:   %f seconds\" % result)  command = 'json.dumps(obj.tolist())' setup = 'from __main__ import json, obj' result = timeit.timeit(command, setup=setup, number=num_tests) print(\"json:   %f seconds\" % result)   command = 'msgpack.packb(obj.tolist())' setup = 'from __main__ import msgpack, obj' result = timeit.timeit(command, setup=setup, number=num_tests) print(\"msgpack:   %f seconds\" % result)   Output:  pickle         :   0.847938 seconds cPickle        :   0.810384 seconds cPickle highest:   0.004283 seconds json           :   1.769215 seconds msgpack        :   0.270886 seconds      ","Language":"Python","Tags":["python","json","pickle"],"URL":"https://stackoverflow.com/questions/2259270/pickle-or-json","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I need to save to disk a little dict object whose keys are of the type str and values are ints and then recover it. Something like this:  {'juanjo': 2, 'pedro':99, 'other': 333}   What is the best option and why? Serialize it with pickle or with simplejson?  I am using Python 2.6.     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  You can run your program into pdb from the command line by running     python -m pdb your_script.py   It will break on the 1st line, then you'll be able to add a breakpoint wherever you want in your code using the break command, its syntax is:     b(reak) [[filename:]lineno | function[, condition]]   It is flexible enough to give you the ability to add a breakpoint anywhere.     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"95","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  You can use:   from pdb import set_trace as bp  code code bp() code code      ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  In vim, I have a macro set up for this (in my .vimrc file):  map <silent> <leader>b oimport pdb; pdb.set_trace()<esc> map <silent> <leader>B Oimport pdb; pdb.set_trace()<esc>   so I can just press \\b (when not in Insert Mode) and it adds in a breakpoint after the current line, or \\B (note the capital) and it puts one before the current line.  which seems to work alright.  Most other 'simple' programmers editors (emacs, sublimetext, etc) should have similar easy ways to do this.  Edit: I actually have:  au FileType python map <silent> <leader>b oimport pdb; pdb.set_trace()<esc> au FileType python map <silent> <leader>B Oimport pdb; pdb.set_trace()<esc>   which turns it on only for python source files.  You could very easily add similar lines for javascript or whatever other languages you use.     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  If you don't want to manually set breakpoints every time running the program (in Python 3.2+), e.g. say you want to directly create a breakpoint at line 3 and stop the execution there:  python -m pdb -c \"b 3\" -c c your_script.py  The following information may help:     If a file .pdbrc exists in the users home directory or in the current directory, it is read in and executed as if it had been typed at the debugger prompt. This is particularly useful for aliases. If both files exist, the one in the home directory is read first and aliases defined there can be overridden by the local file.      Changed in version 3.2: .pdbrc can now contain commands that continue debugging, such as continue or next. Previously, these commands had no effect.      New in version 3.2: pdb.py now accepts a -c option that executes commands as if given in a .pdbrc file, see Debugger Commands.    Source: https://docs.python.org/3.2/library/pdb.html      ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  This is how you would use pdb in the command line without implementing anything in your source code (the documentation and other online resources don't do a good job explaining this to a programmer who has only used visual debuggers in the past):  Start pdb by typing the following in a shell prompt:  python -m pdb 'python_script'   This command initializes pdb and the pdb debugger will break at the first line of your python_script and wait for an input from you:  (Pdb)   This is the interface for communicating with the debugger. Now, you can specify your commands here. Opposed to using buttons or keyboard shortcuts in visual debuggers, here you will use commands to derive the same results.  You can go to the next line in your code by command \"n\" (next):  (Pdb) n   Performing a next would display the line number, and the specific code in the source:  > python_script(line number)method name -> current line in the source code   You can set a breakpoint by specifying a line number in your source code.  (Pdb) b 50   Here, the debugger is set to break at line 50. If there aren't any other breakpoints, the breakpoint at line 50 will be the first and it could be referenced by the breakpoint id which is 1 in this case. If you add more break points they will get identifiers sequentially (i.e., 2, 3 etc.)  Once a breakpoint is set, you would continue executing your program until pdb gets to the breakpoint as follows:  (Pdb) c   Once you get to a breakpoint you could go to the next line, with the n command as described before. If you want to examine the values of variables, you would execute the parameter command as follows:  (Pdb) p variable_name   If you no longer need a breakpoint, you can clear it by passing in the id of the breakpoint with the clear command:  (Pdb) clear 1   Finally, when you are done with the debugger you can exit the execution as you would exit the python command line interpreter.   (Pdb) exit()   I hope this will help anybody get started with pdb. Here is a list of commands you can use with the debugger: pdb so question and answers     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  You could use an IDE which supports python debugging, or you can check out the excellent Winpdb tool. Which works on any platform and provides graphical debugging facilities to your python script.  http://winpdb.org/     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  I haven't tried it yet but they just implemented a new built-in called breakpoint() in Python 3.7 which means you can insert a breakpoint with one statement now:  breakpoint()      ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  You can use:   wing ide eclipse with the pydev plugin pycharms   All of the above support python debugging from inside an IDE.     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  In Atom if Python plugins installed, you can just type in 'pdb' and hit enter and the snippet will type import and trace back for you.  I've used to this now that sometimes I just type it in even if I'm editing it in vim and waiting for the dropdown to appear.     ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Simpler way to put PDB breakpoints in Python code?","A_Content":"  The simplest way to run the debugger on your script is just  pdb your_script.py   Running pdb on a Linux command-line gives  usage: pdb.py scriptfile [arg] ...      ","Language":"Python","Tags":["python","pdb"],"URL":"https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Just a convenience question. I've been a bit spoiled with debuggers in IDEs like Visual Studio and XCode. I find it a bit clumsy to have to type import pdb; pdb.set_trace() to set a breakpoint (I'd rather not import pdb at the top of the file as I might forget and leave it in).  Is there a simpler way of setting a breakpoint in Python code, as straightforward and unobtrusive as what you see in an IDE?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  The first part is similar to Constantine, you can get the boolean of which rows are empty*:  In [21]: ne = (df1 != df2).any(1)  In [22]: ne Out[22]: 0    False 1     True 2     True dtype: bool   Then we can see which entries have changed:  In [23]: ne_stacked = (df1 != df2).stack()  In [24]: changed = ne_stacked[ne_stacked]  In [25]: changed.index.names = ['id', 'col']  In [26]: changed Out[26]: id  col 1   score         True 2   isEnrolled    True     Comment       True dtype: bool   Here the first entry is the index and the second the columns which has been changed.  In [27]: difference_locations = np.where(df1 != df2)  In [28]: changed_from = df1.values[difference_locations]  In [29]: changed_to = df2.values[difference_locations]  In [30]: pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index) Out[30]:                from           to id col 1  score       1.11         1.21 2  isEnrolled  True        False    Comment     None  On vacation   * Note: it's important that df1 and df2 share the same index here. To overcome this ambiguity, you can ensure you only look at the shared labels using df1.index & df2.index, but I think I'll leave that as an exercise.     ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"88","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  Highlighting the difference between two DataFrames  It is possible to use the DataFrame style property to highlight the background color of the cells where there is a difference.  Using the example data from the original question  The first step is to concatenate the DataFrames horizontally with the concat function and distinguish each frame with the keys parameter:  df_all = pd.concat([df.set_index('id'), df2.set_index('id')],                     axis='columns', keys=['First', 'Second']) df_all     It's probably easier to swap the column levels and put the same column names next to each other:  df_final = df_all.swaplevel(axis='columns')[df.columns[1:]] df_final     Now, its much easier to spot the differences in the frames. But, we can go further and use the style property to highlight the cells that are different. We define a custom function to do this which you can see in this part of the documentation.  def highlight_diff(data, color='yellow'):     attr = 'background-color: {}'.format(color)     other = data.xs('First', axis='columns', level=-1)     return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),                         index=data.index, columns=data.columns)  df_final.style.apply(highlight_diff, axis=None)     This will highlight cells that both have missing values. You can either fill them or provide extra logic so that they don't get highlighted.     ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  This answer simply extends @Andy Hayden's, making it resilient to when numeric fields are nan, and wrapping it up into a function.  import pandas as pd import numpy as np   def diff_pd(df1, df2):     \"\"\"Identify differences between two pandas DataFrames\"\"\"     assert (df1.columns == df2.columns).all(), \\         \"DataFrame column names are different\"     if any(df1.dtypes != df2.dtypes):         \"Data Types are different, trying to convert\"         df2 = df2.astype(df1.dtypes)     if df1.equals(df2):         return None     else:         # need to account for np.nan != np.nan returning True         diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())         ne_stacked = diff_mask.stack()         changed = ne_stacked[ne_stacked]         changed.index.names = ['id', 'col']         difference_locations = np.where(diff_mask)         changed_from = df1.values[difference_locations]         changed_to = df2.values[difference_locations]         return pd.DataFrame({'from': changed_from, 'to': changed_to},                             index=changed.index)   So with your data (slightly edited to have a NaN in the score column):  import sys if sys.version_info[0] < 3:     from StringIO import StringIO else:     from io import StringIO  DF1 = StringIO(\"\"\"id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 \"He was late to class\" 112  Nick   1.11                     False                \"Graduated\" 113  Zoe    NaN                     True                  \" \" \"\"\") DF2 = StringIO(\"\"\"id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 \"He was late to class\" 112  Nick   1.21                     False                \"Graduated\" 113  Zoe    NaN                     False                \"On vacation\" \"\"\") df1 = pd.read_table(DF1, sep='\\s+', index_col='id') df2 = pd.read_table(DF2, sep='\\s+', index_col='id') diff_pd(df1, df2)   Output:                  from           to id  col                           112 score       1.11         1.21 113 isEnrolled  True        False     Comment           On vacation      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  I have faced this issue, but found an answer before finding this post :  Based on unutbu's answer, load your data...  import pandas as pd import io  texts = ['''\\ id   Name   score                    isEnrolled                       Date 111  Jack                            True              2013-05-01 12:00:00 112  Nick   1.11                     False             2013-05-12 15:05:23      Zoe    4.12                     True                                  ''',           '''\\ id   Name   score                    isEnrolled                       Date 111  Jack   2.17                     True              2013-05-01 12:00:00 112  Nick   1.21                     False                                      Zoe    4.12                     False             2013-05-01 12:00:00''']   df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4]) df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])   ...define your diff function...  def report_diff(x):     return x[0] if x[0] == x[1] else '{} | {}'.format(*x)   Then you can simply use a Panel to conclude :  my_panel = pd.Panel(dict(df1=df1,df2=df2)) print my_panel.apply(report_diff, axis=0)  #          id  Name        score    isEnrolled                       Date #0        111  Jack   nan | 2.17          True        2013-05-01 12:00:00 #1        112  Nick  1.11 | 1.21         False  2013-05-12 15:05:23 | NaT #2  nan | nan   Zoe         4.12  True | False  NaT | 2013-05-01 12:00:00   By the way, if you're in IPython Notebook, you may like to use a colored diff function to give colors depending whether cells are different, equal or left/right null :  from IPython.display import HTML pd.options.display.max_colwidth = 500  # You need this, otherwise pandas #                          will limit your HTML strings to 50 characters  def report_diff(x):     if x[0]==x[1]:         return unicode(x[0].__str__())     elif pd.isnull(x[0]) and pd.isnull(x[1]):         return u'<table style=\"background-color:#00ff00;font-weight:bold;\">'+\\             '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', 'nan')     elif pd.isnull(x[0]) and ~pd.isnull(x[1]):         return u'<table style=\"background-color:#ffff00;font-weight:bold;\">'+\\             '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', x[1])     elif ~pd.isnull(x[0]) and pd.isnull(x[1]):         return u'<table style=\"background-color:#0000ff;font-weight:bold;\">'+\\             '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0],'nan')     else:         return u'<table style=\"background-color:#ff0000;font-weight:bold;\">'+\\             '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0], x[1])  HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  import pandas as pd import io  texts = ['''\\ id   Name   score                    isEnrolled                        Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                           Graduated 113  Zoe    4.12                     True       ''',           '''\\ id   Name   score                    isEnrolled                        Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                           Graduated 113  Zoe    4.12                     False                         On vacation''']   df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20]) df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20]) df = pd.concat([df1,df2])   print(df) #     id  Name  score isEnrolled               Comment # 0  111  Jack   2.17       True  He was late to class # 1  112  Nick   1.11      False             Graduated # 2  113   Zoe   4.12       True                   NaN # 0  111  Jack   2.17       True  He was late to class # 1  112  Nick   1.21      False             Graduated # 2  113   Zoe   4.12      False           On vacation  df.set_index(['id', 'Name'], inplace=True) print(df) #           score isEnrolled               Comment # id  Name                                         # 111 Jack   2.17       True  He was late to class # 112 Nick   1.11      False             Graduated # 113 Zoe    4.12       True                   NaN # 111 Jack   2.17       True  He was late to class # 112 Nick   1.21      False             Graduated # 113 Zoe    4.12      False           On vacation  def report_diff(x):     return x[0] if x[0] == x[1] else '{} | {}'.format(*x)  changes = df.groupby(level=['id', 'Name']).agg(report_diff) print(changes)   prints                  score    isEnrolled               Comment id  Name                                                  111 Jack         2.17          True  He was late to class 112 Nick  1.11 | 1.21         False             Graduated 113 Zoe          4.12  True | False     nan | On vacation      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  If your two dataframes have the same ids in them, then finding out what changed is actually pretty easy. Just doing frame1 != frame2 will give you a boolean DataFrame where each True is data that has changed. From that, you could easily get the index of each changed row by doing changedids = frame1.index[np.any(frame1 != frame2,axis=1)].     ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  A different approach using concat and drop_duplicates:  import sys if sys.version_info[0] < 3:     from StringIO import StringIO else:     from io import StringIO import pandas as pd  DF1 = StringIO(\"\"\"id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 \"He was late to class\" 112  Nick   1.11                     False                \"Graduated\" 113  Zoe    NaN                     True                  \" \" \"\"\") DF2 = StringIO(\"\"\"id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 \"He was late to class\" 112  Nick   1.21                     False                \"Graduated\" 113  Zoe    NaN                     False                \"On vacation\" \"\"\")  df1 = pd.read_table(DF1, sep='\\s+', index_col='id') df2 = pd.read_table(DF2, sep='\\s+', index_col='id') #%% dictionary = {1:df1,2:df2} df=pd.concat(dictionary) df.drop_duplicates(keep=False)   Output:         Name  score isEnrolled      Comment   id                                       1 112  Nick   1.11      False    Graduated   113   Zoe    NaN       True              2 112  Nick   1.21      False    Graduated   113   Zoe    NaN      False  On vacation      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  Extending answer of @cge, which is pretty cool for more readability of result:  a[a != b][np.any(a != b, axis=1)].join(DataFrame('a<->b', index=a.index, columns=['a<=>b'])).join(         b[a != b][np.any(a != b, axis=1)]         ,rsuffix='_b', how='outer' ).fillna('')   Full demonstration example:  a = DataFrame(np.random.randn(7,3), columns=list('ABC')) b = a.copy() b.iloc[0,2] = np.nan b.iloc[1,0] = 7 b.iloc[3,1] = 77 b.iloc[4,2] = 777  a[a != b][np.any(a != b, axis=1)].join(DataFrame('a<->b', index=a.index, columns=['a<=>b'])).join(         b[a != b][np.any(a != b, axis=1)]         ,rsuffix='_b', how='outer' ).fillna('')      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  After fiddling around with @journois's answer, I was able to get it to work using MultiIndex instead of Panel due to Panel's deprication.  First, create some dummy data:  df1 = pd.DataFrame({     'id': ['111', '222', '333', '444', '555'],     'let': ['a', 'b', 'c', 'd', 'e'],     'num': ['1', '2', '3', '4', '5'] }) df2 = pd.DataFrame({     'id': ['111', '222', '333', '444', '666'],     'let': ['a', 'b', 'c', 'D', 'f'],     'num': ['1', '2', 'Three', '4', '6'], })   Then, define your diff function, in this case I'll use the one from his answer report_diff stays the same:  def report_diff(x):     return x[0] if x[0] == x[1] else '{} | {}'.format(*x)   Then, I'm going to concatenate the data into a MultiIndex dataframe:  df_all = pd.concat(     [df1.set_index('id'), df2.set_index('id')],      axis='columns',      keys=['df1', 'df2'],     join='outer' ) df_all = df_all.swaplevel(axis='columns')[df1.columns[1:]]   And finally I'm going to apply the report_diff down each column group:  df_final.groupby(level=0, axis=1).apply(lambda frame: frame.apply(report_diff, axis=1))   This outputs:           let        num 111        a          1 222        b          2 333        c  3 | Three 444    d | D          4 555  e | nan    5 | nan 666  nan | f    nan | 6   And that is all!     ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  Here is another way using select and merge:  In [6]: # first lets create some dummy dataframes with some column(s) different    ...: df1 = pd.DataFrame({'a': range(-5,0), 'b': range(10,15), 'c': range(20,25)})    ...: df2 = pd.DataFrame({'a': range(-5,0), 'b': range(10,15), 'c': [20] + list(range(101,105))})   In [7]: df1 Out[7]:    a   b   c 0 -5  10  20 1 -4  11  21 2 -3  12  22 3 -2  13  23 4 -1  14  24   In [8]: df2 Out[8]:    a   b    c 0 -5  10   20 1 -4  11  101 2 -3  12  102 3 -2  13  103 4 -1  14  104   In [10]: # make condition over the columns you want to comapre     ...: condition = df1['c'] != df2['c']     ...:     ...: # select rows from each dataframe where the condition holds     ...: diff1 = df1[condition]     ...: diff2 = df2[condition]   In [11]: # merge the selected rows (dataframes) with some suffixes (optional)     ...: diff1.merge(diff2, on=['a','b'], suffixes=('_before', '_after')) Out[11]:    a   b  c_before  c_after 0 -4  11        21      101 1 -3  12        22      102 2 -2  13        23      103 3 -1  14        24      104   Here is the same thing from a Jupyter screenshot:       ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"Outputting difference in two Pandas dataframes side by side - highlighting the difference","A_Content":"  A function that finds asymmetrical  difference between two data frames is implemented below: (Based on set difference for pandas) GIST: https://gist.github.com/oneryalcin/68cf25f536a25e65f0b3c84f9c118e03  def diff_df(df1, df2, how=\"left\"):     \"\"\"       Find Difference of rows for given two dataframes       this function is not symmetric, means             diff(x, y) != diff(y, x)       however             diff(x, y, how='left') == diff(y, x, how='right')        Ref: https://stackoverflow.com/questions/18180763/set-difference-for-pandas/40209800#40209800     \"\"\"     if (df1.columns != df2.columns).any():         raise ValueError(\"Two dataframe columns must match\")      if df1.equals(df2):         return None     elif how == 'right':         return pd.concat([df2, df1, df1]).drop_duplicates(keep=False)     elif how == 'left':         return pd.concat([df1, df2, df2]).drop_duplicates(keep=False)     else:         raise ValueError('how parameter supports only \"left\" or \"right keywords\"')   Example:  df1 = pd.DataFrame(d1) Out[1]:                  Comment  Name  isEnrolled  score 0  He was late to class  Jack        True   2.17 1             Graduated  Nick       False   1.11 2                         Zoe        True   4.12   df2 = pd.DataFrame(d2)  Out[2]:                  Comment  Name  isEnrolled  score 0  He was late to class  Jack        True   2.17 1           On vacation   Zoe        True   4.12  diff_df(df1, df2) Out[3]:       Comment  Name  isEnrolled  score 1  Graduated  Nick       False   1.11 2              Zoe        True   4.12  diff_df(df2, df1) Out[4]:         Comment Name  isEnrolled  score 1  On vacation  Zoe        True   4.12  # This gives the same result as above diff_df(df1, df2, how='right') Out[22]:         Comment Name  isEnrolled  score 1  On vacation  Zoe        True   4.12      ","Language":"Python","Tags":["python","html","pandas","dataframe","panel"],"URL":"https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to highlight exactly what changed between two dataframes.  Suppose I have two Python Pandas dataframes:  \"StudentRoster Jan-1\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.11                     False                Graduated 113  Zoe    4.12                     True         \"StudentRoster Jan-2\": id   Name   score                    isEnrolled           Comment 111  Jack   2.17                     True                 He was late to class 112  Nick   1.21                     False                Graduated 113  Zoe    4.12                     False                On vacation   My goal is to output an HTML table that:   Identifies rows that have changed (could be int, float, boolean, string) Outputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes:   \"StudentRoster Difference Jan-1 - Jan-2\":   id   Name   score                    isEnrolled           Comment 112  Nick   was 1.11| now 1.21       False                Graduated 113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"    I suppose I could do a row by row and column by column comparison, but is there an easier way?     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Check if the cross product of (b-a) and (c-a) is 0, as tells Darius Bacon, tells you if the points a, b and c are aligned.  But, as you want to know if c is between a and b, you also have to check that the dot product of (b-a) and (c-a) is positive and is less than the square of the distance between a and b.  In non-optimized pseudocode:  def isBetween(a, b, c):     crossproduct = (c.y - a.y) * (b.x - a.x) - (c.x - a.x) * (b.y - a.y)      # compare versus epsilon for floating point values, or != 0 if using integers     if abs(crossproduct) > epsilon:         return False      dotproduct = (c.x - a.x) * (b.x - a.x) + (c.y - a.y)*(b.y - a.y)     if dotproduct < 0:         return False      squaredlengthba = (b.x - a.x)*(b.x - a.x) + (b.y - a.y)*(b.y - a.y)     if dotproduct > squaredlengthba:         return False      return True      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here's how I'd do it:  def distance(a,b):     return sqrt((a.x - b.x)**2 + (a.y - b.y)**2)  def is_between(a,c,b):     return distance(a,c) + distance(c,b) == distance(a,b)      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"37","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Check if the cross product of b-a and c-a is0: that means all the points are collinear. If they are, check if c's coordinates are between a's and b's. Use either the x or the y coordinates, as long as a and b are separate on that axis (or they're the same on both).  def is_on(a, b, c):     \"Return true iff point c intersects the line segment from a to b.\"     # (or the degenerate case that all 3 points are coincident)     return (collinear(a, b, c)             and (within(a.x, c.x, b.x) if a.x != b.x else                   within(a.y, c.y, b.y)))  def collinear(a, b, c):     \"Return true iff a, b, and c all lie on the same line.\"     return (b.x - a.x) * (c.y - a.y) == (c.x - a.x) * (b.y - a.y)  def within(p, q, r):     \"Return true iff q is between p and r (inclusive).\"     return p <= q <= r or r <= q <= p   This answer used to be a mess of three updates. The worthwhile info from them: Brian Hayes's chapter in Beautiful Code covers the design space for a collinearity-test function -- useful background. Vincent's answer helped to improve this one. And it was Hayes who suggested testing only one of the x or the y coordinates; originally the code had and in place of if a.x != b.x else.     ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here's another approach:     Lets assume the two points be A (x1,y1) and B (x2,y2) The equation of the line passing through those points is (x-x1)/(y-y1)=(x2-x1)/(y2-y1) .. (just making equating the slopes)   Point C (x3,y3) will lie between A & B if:   x3,y3 satisfies the above equation. x3 lies between x1 & x2 and y3 lies between y1 & y2 (trivial check)      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  The length of the segment is not important, thus using a square root is not required and should be avoided since we could lose some precision.  class Point:     def __init__(self, x, y):         self.x = x         self.y = y  class Segment:     def __init__(self, a, b):         self.a = a         self.b = b      def is_between(self, c):         # Check if slope of a to c is the same as a to b ;         # that is, when moving from a.x to c.x, c.y must be proportionally         # increased than it takes to get from a.x to b.x .          # Then, c.x must be between a.x and b.x, and c.y must be between a.y and b.y.         # => c is after a and before b, or the opposite         # that is, the absolute value of cmp(a, b) + cmp(b, c) is either 0 ( 1 + -1 )         #    or 1 ( c == a or c == b)          a, b = self.a, self.b                       return ((b.x - a.x) * (c.y - a.y) == (c.x - a.x) * (b.y - a.y) and                  abs(cmp(a.x, c.x) + cmp(b.x, c.x)) <= 1 and                 abs(cmp(a.y, c.y) + cmp(b.y, c.y)) <= 1)   Some random example of usage :  a = Point(0,0) b = Point(50,100) c = Point(25,50) d = Point(0,8)  print Segment(a,b).is_between(c) print Segment(a,b).is_between(d)      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Using a more geometric approach, calculate the following distances:  ab = sqrt((a.x-b.x)**2 + (a.y-b.y)**2) ac = sqrt((a.x-c.x)**2 + (a.y-c.y)**2) bc = sqrt((b.x-c.x)**2 + (b.y-c.y)**2)   and test whether ac+bc equals ab:  is_on_segment = abs(ac + bc - ab) < EPSILON   That's because there are three possibilities:   The 3 points form a triangle => ac+bc > ab They are collinear and c is outside the ab segment => ac+bc > ab They are collinear and c is inside the ab segment => ac+bc = ab      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Ok, lots of mentions of linear algebra (cross product of vectors) and this works in a real (ie continuous or floating point) space but the question specifically stated that the two points were expressed as integers and thus a cross product is not the correct solution although it can give an approximate solution.  The correct solution is to use Bresenham's Line Algorithm between the two points and to see if the third point is one of the points on the line.  If the points are sufficiently distant that calculating the algorithm is non-performant (and it'd have to be really large for that to be the case) I'm sure you could dig around and find optimisations.     ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here's a different way to go about it, with code given in C++. Given two points, l1 and l2 it's trivial to express the line segment between them as  l1 + A(l2 - l1)   where 0 <= A <= 1. This is known as the vector representation of a line if you're interested any more beyond just using it for this problem. We can split out the x and y components of this, giving:  x = l1.x + A(l2.x - l1.x) y = l1.y + A(l2.y - l1.y)   Take a point (x, y) and substitute its x and y components into these two expressions to solve for A. The point is on the line if the solutions for A in both expressions are equal and 0 <= A <= 1. Because solving for A requires division, there's special cases that need handling to stop division by zero when the line segment is horizontal or vertical. The final solution is as follows:  // Vec2 is a simple x/y struct - it could very well be named Point for this use  bool isBetween(double a, double b, double c) {     // return if c is between a and b     double larger = (a >= b) ? a : b;     double smaller = (a != larger) ? a : b;      return c <= larger && c >= smaller; }  bool pointOnLine(Vec2<double> p, Vec2<double> l1, Vec2<double> l2) {     if(l2.x - l1.x == 0) return isBetween(l1.y, l2.y, p.y); // vertical line     if(l2.y - l1.y == 0) return isBetween(l1.x, l2.x, p.x); // horizontal line      double Ax = (p.x - l1.x) / (l2.x - l1.x);     double Ay = (p.y - l1.y) / (l2.y - l1.y);      // We want Ax == Ay, so check if the difference is very small (floating     // point comparison is fun!)      return fabs(Ax - Ay) < 0.000001 && Ax >= 0.0 && Ax <= 1.0; }      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  The scalar product between (c-a) and (b-a) must be equal to the product of their lengths (this means that the vectors (c-a) and (b-a) are aligned and with the same direction). Moreover, the length of (c-a) must be less than or equal to that of (b-a). Pseudocode:  # epsilon = small constant  def isBetween(a, b, c):     lengthca2  = (c.x - a.x)*(c.x - a.x) + (c.y - a.y)*(c.y - a.y)     lengthba2  = (b.x - a.x)*(b.x - a.x) + (b.y - a.y)*(b.y - a.y)     if lengthca2 > lengthba2: return False     dotproduct = (c.x - a.x)*(b.x - a.x) + (c.y - a.y)*(b.y - a.y)     if dotproduct < 0.0: return False     if abs(dotproduct*dotproduct - lengthca2*lengthba2) > epsilon: return False      return True      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  I needed this for javascript for use in an html5 canvas for detecting if the users cursor was over or near a certain line. So I modified the answer given by Darius Bacon into coffeescript:  is_on = (a,b,c) ->     # \"Return true if point c intersects the line segment from a to b.\"     # (or the degenerate case that all 3 points are coincident)     return (collinear(a,b,c) and withincheck(a,b,c))  withincheck = (a,b,c) ->     if a[0] != b[0]         within(a[0],c[0],b[0])      else          within(a[1],c[1],b[1])  collinear = (a,b,c) ->     # \"Return true if a, b, and c all lie on the same line.\"     ((b[0]-a[0])*(c[1]-a[1]) < (c[0]-a[0])*(b[1]-a[1]) + 1000) and ((b[0]-a[0])*(c[1]-a[1]) > (c[0]-a[0])*(b[1]-a[1]) - 1000)  within = (p,q,r) ->     # \"Return true if q is between p and r (inclusive).\"     p <= q <= r or r <= q <= p      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here's how I did it at school. I forgot why it is not a good idea.  EDIT:   @Darius Bacon: cites a \"Beautiful Code\" book which contains an explanation why the belowed code is not a good idea.  #!/usr/bin/env python from __future__ import division  epsilon = 1e-6  class Point:     def __init__(self, x, y):         self.x, self.y = x, y  class LineSegment:     \"\"\"     >>> ls = LineSegment(Point(0,0), Point(2,4))     >>> Point(1, 2) in ls     True     >>> Point(.5, 1) in ls     True     >>> Point(.5, 1.1) in ls     False     >>> Point(-1, -2) in ls     False     >>> Point(.1, 0.20000001) in ls     True     >>> Point(.1, 0.2001) in ls     False     >>> ls = LineSegment(Point(1, 1), Point(3, 5))     >>> Point(2, 3) in ls     True     >>> Point(1.5, 2) in ls     True     >>> Point(0, -1) in ls     False     >>> ls = LineSegment(Point(1, 2), Point(1, 10))     >>> Point(1, 6) in ls     True     >>> Point(1, 1) in ls     False     >>> Point(2, 6) in ls      False     >>> ls = LineSegment(Point(-1, 10), Point(5, 10))     >>> Point(3, 10) in ls     True     >>> Point(6, 10) in ls     False     >>> Point(5, 10) in ls     True     >>> Point(3, 11) in ls     False     \"\"\"     def __init__(self, a, b):         if a.x > b.x:             a, b = b, a         (self.x0, self.y0, self.x1, self.y1) = (a.x, a.y, b.x, b.y)         self.slope = (self.y1 - self.y0) / (self.x1 - self.x0) if self.x1 != self.x0 else None      def __contains__(self, c):         return (self.x0 <= c.x <= self.x1 and                 min(self.y0, self.y1) <= c.y <= max(self.y0, self.y1) and                 (not self.slope or -epsilon < (c.y - self.y(c.x)) < epsilon))      def y(self, x):                 return self.slope * (x - self.x0) + self.y0  if __name__ == '__main__':     import  doctest     doctest.testmod()      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  c# From http://www.faqs.org/faqs/graphics/algorithms-faq/ -> Subject 1.02: How do I find the distance from a point to a line?  Boolean Contains(PointF from, PointF to, PointF pt, double epsilon)         {              double segmentLengthSqr = (to.X - from.X) * (to.X - from.X) + (to.Y - from.Y) * (to.Y - from.Y);             double r = ((pt.X - from.X) * (to.X - from.X) + (pt.Y - from.Y) * (to.Y - from.Y)) / segmentLengthSqr;             if(r<0 || r>1) return false;             double sl = ((from.Y - pt.Y) * (to.X - from.X) - (from.X - pt.X) * (to.Y - from.Y)) / System.Math.Sqrt(segmentLengthSqr);             return -epsilon <= sl && sl <= epsilon;         }      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here is some Java code that worked for me:  boolean liesOnSegment(Coordinate a, Coordinate b, Coordinate  c) {      double dotProduct = (c.x - a.x) * (c.x - b.x) + (c.y - a.y) * (c.y - b.y);     if (dotProduct < 0) return true;     return false; }      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  how about just ensuring that the slope is the same and the point is between the others?  given points (x1, y1) and (x2, y2) ( with x2 > x1) and candidate point (a,b)  if  (b-y1) / (a-x1) = (y2-y2) / (x2-x1)  And x1 < a < x2   Then (a,b) must be on line between (x1,y1) and (x2, y2)     ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Any point on the line segment (a, b) (where a and b are vectors) can be expressed as a linear combination of the two vectors a and b:  In other words, if c lies on the line segment (a, b):  c = ma + (1 - m)b, where 0 <= m <= 1   Solving for m, we get:  m = (c.x - b.x)/(a.x - b.x) = (c.y - b.y)/(a.y - b.y)   So, our test becomes (in Python):  def is_on(a, b, c):     \"\"\"Is c on the line segment ab?\"\"\"      def _is_zero( val ):         return -epsilon < val < epsilon      x1 = a.x - b.x     x2 = c.x - b.x     y1 = a.y - b.y     y2 = c.y - b.y      if _is_zero(x1) and _is_zero(y1):         # a and b are the same point:         # so check that c is the same as a and b         return _is_zero(x2) and _is_zero(y2)      if _is_zero(x1):         # a and b are on same vertical line         m2 = y2 * 1.0 / y1         return _is_zero(x2) and 0 <= m2 <= 1     elif _is_zero(y1):         # a and b are on same horizontal line         m1 = x2 * 1.0 / x1         return _is_zero(y2) and 0 <= m1 <= 1     else:         m1 = x2 * 1.0 / x1         if m1 < 0 or m1 > 1:             return False         m2 = y2 * 1.0 / y1         return _is_zero(m2 - m1)      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  An answer in C# using a Vector2D class  public static bool IsOnSegment(this Segment2D @this, Point2D c, double tolerance) {      var distanceSquared = tolerance*tolerance;      // Start of segment to test point vector      var v = new Vector2D( @this.P0, c ).To3D();      // Segment vector      var s = new Vector2D( @this.P0, @this.P1 ).To3D();      // Dot product of s      var ss = s*s;      // k is the scalar we multiply s by to get the projection of c onto s      // where we assume s is an infinte line      var k = v*s/ss;      // Convert our tolerance to the units of the scalar quanity k      var kd = tolerance / Math.Sqrt( ss );      // Check that the projection is within the bounds      if (k <= -kd || k >= (1+kd))      {         return false;      }      // Find the projection point      var p = k*s;      // Find the vector between test point and it's projection      var vp = (v - p);      // Check the distance is within tolerance.      return vp * vp < distanceSquared; }   Note that  s * s   is the dot product of the segment vector via operator overloading in C#  The key is taking advantage of the projection of the point onto the infinite line and observing that the scalar quantity of the projection tells us trivially if the projection is on the segment or not. We can adjust the bounds of the scalar quantity to use a fuzzy tolerance.  If the projection is within bounds we just test if the distance from the point to the projection is within bounds.  The benefit over the cross product approach is that the tolerance has a meaningful value.     ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  You can use the wedge and dot product:  def dot(v,w): return v.x*w.x + v.y*w.y def wedge(v,w): return v.x*w.y - v.y*w.x  def is_between(a,b,c):    v = a - b    w = b - c    return wedge(v,w) == 0 and dot(v,w) > 0      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How can you determine a point is between two other points on a line segment?","A_Content":"  Here is my solution with C# in Unity.  private bool _isPointOnLine( Vector2 ptLineStart, Vector2 ptLineEnd, Vector2 ptPoint ) {     bool bRes = false;     if((Mathf.Approximately(ptPoint.x, ptLineStart.x) || Mathf.Approximately(ptPoint.x, ptLineEnd.x)))     {         if(ptPoint.y > ptLineStart.y && ptPoint.y < ptLineEnd.y)         {             bRes = true;         }     }     else if((Mathf.Approximately(ptPoint.y, ptLineStart.y) || Mathf.Approximately(ptPoint.y, ptLineEnd.y)))     {         if(ptPoint.x > ptLineStart.x && ptPoint.x < ptLineEnd.x)         {             bRes = true;         }     }     return bRes; }      ","Language":"Python","Tags":["python","math","geometry"],"URL":"https://stackoverflow.com/questions/328107/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Let's say you have a two dimensional plane with 2 points (called a and b) on it represented by an x integer and a y integer for each point.  How can you determine if another point c is on the line segment defined by a and b?  I use python most, but examples in any language would be helpful.     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  You will have to split your string into a list of values using split()  So,  lines = text_file.read().split(',')      ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"87","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  python's file.readLines() method returns a list of the lines in the file:   f = open('file_name.ext', 'r') x = f.readlines() f.close()   Now you should be able to iterate through the array of lines x.  If you want to use the file and not have to remember to close it afterward, do this:  with open('file_name.ext', 'r') as f:     x = f.readlines()      ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"67","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  You can also use numpy loadtxt like  from numpy import loadtxt lines = loadtxt(\"filename.dat\", comments=\"#\", delimiter=\",\", unpack=False)      ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  So you want to create a list of lists... We need to start with an empty list  list_of_lists = []   next, we read the file content, line by line  with open('data') as f:     for line in f:         inner_list = [elt.strip() for elt in line.split(',')]         # in alternative, if you need to use the file content as numbers         # inner_list = [int(elt.strip()) for elt in line.split(',')]         list_of_lists.append(inner_list)   A common use case is that of columnar data, but our units of storage are the rows of the file, that we have read one by one, so you may want to transpose your list of lists.  This can be done with the following idiom  by_cols = zip(*list_of_lists)   Another common use is to give a name to each column  col_names = ('apples sold', 'pears sold', 'apples revenue', 'pears revenue') by_names = {} for i, col_name in enumerate(col_names):     by_names[col_name] = by_cols[i]   so that you can operate on homogeneous data items   mean_apple_prices = [money/fruits for money, fruits in                      zip(by_names['apples revenue'], by_names['apples_sold'])]   Most of what I've written can be speeded up using the csv module, from the standard library.  Another third party module is pandas, that lets you automate most aspects of a typical data analysis (but has a number of dependencies).    Update While in Python 2 zip(*list_of_lists) returns a different (transposed) list of lists, in Python 3 the situation has changed and zip(*list_of_lists) returns a zip object that is not subscriptable.  If you need indexed access you can use  by_cols = list(zip(*list_of_lists))   that gives you a list of lists in both versions of Python.  On the other hand, if you don't need indexed access and what you want is just to build a dictionary indexed by column names, a zip object is just fine...  file = open('some_data.csv') names = get_names(next(file)) columns = zip(*((x.strip() for x in line.split(',')) for line in file))) d = {} for name, column in zip(names, columns): d[name] = column      ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  This question is asking how to read the comma-separated value contents from a file into an iterable list:   0,0,200,0,53,1,0,255,...,0.  The easiest way to do this is with the csv module as follows:  import csv with open('filename.dat', newline='') as csvfile:     spamreader = csv.reader(csvfile, delimiter=',')   Now, you can easily iterate over spamreader like this:  for row in spamreader:     print(', '.join(row))   See documentation for more examples.     ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"How to read a text file into a list or an array with Python","A_Content":"  with open('D:\\python\\positive.txt', 'r') as myfile: data=myfile.read().replace('\\n', '')      ","Language":"Python","Tags":["python","arrays","list","text"],"URL":"https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to read the lines of a text file into a list or array in python.  I just need to be able to individually access any item in the list or array after it is created.  The text file is formatted as follows:  0,0,200,0,53,1,0,255,...,0.   Where the ... is above, there actual text file has hundreds or thousands more items.  I'm using the following code to try to read the file into a list:  text_file = open(\"filename.dat\", \"r\") lines = text_file.readlines() print lines print len(lines) text_file.close()   The output I get is:  ['0,0,200,0,53,1,0,255,...,0.'] 1   Apparently it is reading the entire file into a list of just one item, rather than a list of individual items.  What am I doing wrong?     ","Q_Votes":"79"},{"Q_Title":"What is an 'endpoint' in Flask?","A_Content":"  How Flask Routing Works  The entire idea of Flask (and the underlying Werkzeug library) is to map URL paths to some logic that you will run (typically, the \"view function\"). Your basic view is defined like this:  @app.route('/greeting/<name>') def give_greeting(name):     return 'Hello, {0}!'.format(name)   Note that the function you referred to (add_url_rule) achieves the same goal, just without using the decorator notation. Therefore, the following is the same:  # No \"route\" decorator here. We will add routing using a different method below. def give_greeting(name):     return 'Hello, {0}!'.format(name)  app.add_url_rule('/greeting/<name>', 'give_greeting', give_greeting)   Let's say your website is located at 'www.example.org' and uses the above view. The user enters the following URL into their browser:  http://www.example.org/greeting/Mark   The job of Flask is to take this URL, figure out what the user wants to do, and pass it on to one of your many python functions for handling. It takes the path:  /greeting/Mark   ...and matches it to the list of routes. In our case, we defined this path to go to the give_greeting function.  However, while this is the typical way that you might go about creating a view, it actually abstracts some extra info from you. Behind the scenes, Flask did not make the leap directly from URL to the view function that should handle this request. It does not simply say...  URL (http://www.example.org/greeting/Mark) should be handled by View Function (the function \"my_greeting\")   Actually, it there is another step, where it maps the URL to an endpoint:  URL (http://www.example.org/greeting/Mark) should be handled by Endpoint \"my_greeting\". Requests to Endpoint \"my_greeting\" should be handled by View Function \"my_greeting\"   Basically, the \"endpoint\" is an identifier that is used in determining what logical unit of your code should handle the request. Normally, an endpoint is just the name of a view function. However, you can actually change the endpoint, as is done in the following example.  @app.route('/greeting/<name>', endpoint='say_hello') def give_greeting(name):     return 'Hello, {0}!'.format(name)   Now, when Flask routes the request, the logic looks like this:  URL (http://www.example.org/greeting/Mark) should be handled by Endpoint \"say_hello\". Endpoint \"say_hello\" should be handled by View Function \"my_greeting\"   How You Use the Endpoint  The endpoint is commonly used for the \"reverse lookup\". For example, in one view of your Flask application, you want to reference another view (perhaps when you are linking from one area of the site to another). Rather than hard-code the URL, you can use url_for(). Assume the following  @app.route('/') def index():     print url_for('give_greeting', name='Mark') # This will print '/greeting/Mark'  @app.route('/greeting/<name>') def give_greeting(name):     return 'Hello, {0}!'.format(name)   This is advantageous, as now we can change the URLs of our application without needing to change the line where we reference that resource.  Why not just always use the name of the view function?  One question that might come up is the following: \"Why do we need this extra layer?\" Why map a path to an endpoint, then an endpoint to a view function? Why not just skip that middle step?  The reason is because it is more powerful this way. For example, Flask Blueprints allow you to split your application into various parts. I might have all of my admin-side resources in a blueprint called \"admin\", and all of my user-level resources in an endpoint called \"user\".  Blueprints allow you to separate these into namespaces. For example...  main.py:  from flask import Flask, Blueprint from admin import admin from user import user  app = Flask(__name__) app.register_blueprint(admin, url_prefix='admin') app.register_blueprint(user, url_prefix='user')   admin.py:  admin = Blueprint('admin', __name__)  @admin.route('/greeting') def greeting():     return 'Hello, administrative user!'   user.py:  user = Blueprint('user', __name__) @user.route('/greeting') def greeting():     return 'Hello, lowly normal user!'   Note that in both blueprints, the '/greeting' route is a function called \"greeting\". If I wanted to refer to the admin \"greeting\" function, I couldn't just say \"greeting\" because there is also a user \"greeting\" function. Endpoints allow for a sort of namespacing by having you specify the name of the blueprint as part of the endpoint. So, I could do the following...  print url_for('admin.greeting') # Prints '/admin/greeting' print url_for('user.greeting') # Prints '/user/greeting'      ","Language":"Python","Tags":["python","flask"],"URL":"https://stackoverflow.com/questions/19261833/what-is-an-endpoint-in-flask","A_Votes":"181","_type":"dict","isAccepted":"Yes","Q_Content":"    The Flask documentation shows:  add_url_rule(*args, **kwargs)       Connects a URL rule. Works exactly like the route() decorator.       If a view_func is provided it will be registered with the endpoint.       endpoint  the endpoint for the registered URL rule. Flask itself assumes the name of the view function as endpoint   What exactly is meant by an \"endpoint\"?     ","Q_Votes":"79"},{"Q_Title":"What is an 'endpoint' in Flask?","A_Content":"  Endpoint is the name used to reverse-lookup the url rules with url_for and it defaults to the name of the view function.  Small example:  from flask import Flask, url_for  app = Flask(__name__)  # We can use url_for('foo_view') for reverse-lookups in templates or view functions @app.route('/foo') def foo_view():     pass  # We now specify the custom endpoint named 'bufar'. url_for('bar_view') will fail! @app.route('/bar', endpoint='bufar') def bar_view():     pass  with app.test_request_context('/'):     print url_for('foo_view')     print url_for('bufar')     # url_for('bar_view') will raise werkzeug.routing.BuildError     print url_for('bar_view')      ","Language":"Python","Tags":["python","flask"],"URL":"https://stackoverflow.com/questions/19261833/what-is-an-endpoint-in-flask","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    The Flask documentation shows:  add_url_rule(*args, **kwargs)       Connects a URL rule. Works exactly like the route() decorator.       If a view_func is provided it will be registered with the endpoint.       endpoint  the endpoint for the registered URL rule. Flask itself assumes the name of the view function as endpoint   What exactly is meant by an \"endpoint\"?     ","Q_Votes":"79"},{"Q_Title":"Open S3 object as a string with Boto3","A_Content":"  read will return bytes. At least for Python 3, if you want to return a string, you have to decode using the right encoding:  import boto3  s3 = boto3.resource('s3')  obj = s3.Object(bucket, key) obj.get()['Body'].read().decode('utf-8')       ","Language":"Python","Tags":["python","amazon-s3","boto","boto3"],"URL":"https://stackoverflow.com/questions/31976273/open-s3-object-as-a-string-with-boto3","A_Votes":"114","_type":"dict","isAccepted":"No","Q_Content":"    I'm aware that with Boto 2 it's possible to open an S3 object as a string with:  get_contents_as_string() http://boto.readthedocs.org/en/latest/ref/file.html?highlight=contents%20string#boto.file.key.Key.get_contents_as_string  Is there an equivalent function in boto3 ?      ","Q_Votes":"79"},{"Q_Title":"Open S3 object as a string with Boto3","A_Content":"  This isn't in the boto3 documentation. This worked for me:  object.get()[\"Body\"].read()   object being an s3 object: http://boto3.readthedocs.org/en/latest/reference/services/s3.html#object     ","Language":"Python","Tags":["python","amazon-s3","boto","boto3"],"URL":"https://stackoverflow.com/questions/31976273/open-s3-object-as-a-string-with-boto3","A_Votes":"63","_type":"dict","isAccepted":"No","Q_Content":"    I'm aware that with Boto 2 it's possible to open an S3 object as a string with:  get_contents_as_string() http://boto.readthedocs.org/en/latest/ref/file.html?highlight=contents%20string#boto.file.key.Key.get_contents_as_string  Is there an equivalent function in boto3 ?      ","Q_Votes":"79"},{"Q_Title":"Open S3 object as a string with Boto3","A_Content":"  I had a problem to read/parse the object from S3 because of .get() using Python 2.7 inside an AWS Lambda.  I added json to the example to show it became parsable :)  import boto3 import json  s3 = boto3.client('s3')  obj = s3.get_object(Bucket=bucket, Key=key) j = json.loads(obj['Body'].read())   NOTE (for python 2.7): My object is all ascii, so I don't need .decode('utf-8')  NOTE (for python 3.6+): We moved to python 3.6 and discovered that read() now returns bytes so if you want to get a string out of it, you must use:  j = json.loads(obj['Body'].read().decode('utf-8'))     ","Language":"Python","Tags":["python","amazon-s3","boto","boto3"],"URL":"https://stackoverflow.com/questions/31976273/open-s3-object-as-a-string-with-boto3","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I'm aware that with Boto 2 it's possible to open an S3 object as a string with:  get_contents_as_string() http://boto.readthedocs.org/en/latest/ref/file.html?highlight=contents%20string#boto.file.key.Key.get_contents_as_string  Is there an equivalent function in boto3 ?      ","Q_Votes":"79"},{"Q_Title":"Open S3 object as a string with Boto3","A_Content":"  If body contains a io.StringIO, you have to do like below:  object.get()['Body'].getvalue()      ","Language":"Python","Tags":["python","amazon-s3","boto","boto3"],"URL":"https://stackoverflow.com/questions/31976273/open-s3-object-as-a-string-with-boto3","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I'm aware that with Boto 2 it's possible to open an S3 object as a string with:  get_contents_as_string() http://boto.readthedocs.org/en/latest/ref/file.html?highlight=contents%20string#boto.file.key.Key.get_contents_as_string  Is there an equivalent function in boto3 ?      ","Q_Votes":"79"},{"Q_Title":"How do I add a path to PYTHONPATH in virtualenv","A_Content":"  You can usually avoid having to do anything with PYTHONPATH by using .pth files. Just put a file with a .pth extension (any basename works) in your virtualenv's site-packages folder, e.g. lib\\python2.7\\site-packages, with the absolute path to the directory containing your package as its only contents.     ","Language":"Python","Tags":["python","virtualenv"],"URL":"https://stackoverflow.com/questions/10738919/how-do-i-add-a-path-to-pythonpath-in-virtualenv","A_Votes":"131","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to add a path to the PYTHONPATH environment variable, that would be only visible from a particular virtualenv environment.   I tried SET PYTHONPATH=... under a virtualenv command prompt, but that sets the variable for the whole environment.  How do I achieve that?     ","Q_Votes":"79"},{"Q_Title":"How do I add a path to PYTHONPATH in virtualenv","A_Content":"  If you're using virtualenv, you should probably also be using virtualenvwrapper, in which case you can use the add2virtualenv command to add paths to the Python path for the current virtualenv:  add2virtualenv directory1 directory2        ","Language":"Python","Tags":["python","virtualenv"],"URL":"https://stackoverflow.com/questions/10738919/how-do-i-add-a-path-to-pythonpath-in-virtualenv","A_Votes":"84","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to add a path to the PYTHONPATH environment variable, that would be only visible from a particular virtualenv environment.   I tried SET PYTHONPATH=... under a virtualenv command prompt, but that sets the variable for the whole environment.  How do I achieve that?     ","Q_Votes":"79"},{"Q_Title":"How do I add a path to PYTHONPATH in virtualenv","A_Content":"  You can also try to put symlink to one of your virtualenv.  eg. 1) activate your virtualenv 2) run python 3) import sys and check sys.path 4) you will find python search path there. Choose one of those (eg. site-packages)  5) go there and create symlink to your package like: ln -s path-to-your-package name-with-which-you'll-be-importing  That way you should be able to import it even without activating your virtualenv. Simply try: path-to-your-virtualenv-folder/bin/python and import your package.     ","Language":"Python","Tags":["python","virtualenv"],"URL":"https://stackoverflow.com/questions/10738919/how-do-i-add-a-path-to-pythonpath-in-virtualenv","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to add a path to the PYTHONPATH environment variable, that would be only visible from a particular virtualenv environment.   I tried SET PYTHONPATH=... under a virtualenv command prompt, but that sets the variable for the whole environment.  How do I achieve that?     ","Q_Votes":"79"},{"Q_Title":"How do I add a path to PYTHONPATH in virtualenv","A_Content":"  In Python 3.6.4  import sys import os  print(str(sys.path))  dir_path = os.path.dirname(os.path.realpath(__file__)) print(f\"current working dir: {dir_path}\")  sys.path.insert(0, dir_path)   I strongly suggest you use virtualenv and virtualenvwrapper to avoid cluttering path     ","Language":"Python","Tags":["python","virtualenv"],"URL":"https://stackoverflow.com/questions/10738919/how-do-i-add-a-path-to-pythonpath-in-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to add a path to the PYTHONPATH environment variable, that would be only visible from a particular virtualenv environment.   I tried SET PYTHONPATH=... under a virtualenv command prompt, but that sets the variable for the whole environment.  How do I achieve that?     ","Q_Votes":"79"},{"Q_Title":"Python - why use self in a class?","A_Content":"  A.x is a class variable. B's self.x is an instance variable.  i.e. A's x is shared between instances.  It would be easier to demonstrate the difference with something that can be modified like a list:  #!/usr/bin/env python  class A:     x = []      def add(self):         self.x.append(1)   class B:     def __init__(self):         self.x = []      def add(self):         self.x.append(1)   x = A() y = A() x.add() y.add() print \"A's x:\",x.x  x = B() y = B() x.add() y.add() print \"B's x:\",x.x   Output     A's x: [1, 1]   B's x: [1]      ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/475871/python-why-use-self-in-a-class","A_Votes":"131","_type":"dict","isAccepted":"Yes","Q_Content":"    How do these 2 classes differ?  class A():     x=3  class B():     def __init__(self):         self.x=3   Is there any significant difference?      ","Q_Votes":"79"},{"Q_Title":"Python - why use self in a class?","A_Content":"  Just as a side note: self is actually just a randomly chosen word, that everyone uses, but you could also use this, foo, or myself or anything else you want, it's just the first parameter of every non static method for a class. This means that the word self is not a language construct but just a name:  >>> class A: ...     def __init__(s): ...        s.bla = 2 ...  >>>  >>> a = A() >>> a.bla 2      ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/475871/python-why-use-self-in-a-class","A_Votes":"52","_type":"dict","isAccepted":"No","Q_Content":"    How do these 2 classes differ?  class A():     x=3  class B():     def __init__(self):         self.x=3   Is there any significant difference?      ","Q_Votes":"79"},{"Q_Title":"Python - why use self in a class?","A_Content":"  A.x is a class variable, and will be shared across all instances of A, unless specifically overridden within an instance. B.x is an instance variable, and each instance of B has its own version of it.  I hope the following Python example can clarify:       >>> class Foo():     ...     i = 3     ...     def bar(self):     ...             print 'Foo.i is', Foo.i     ...             print 'self.i is', self.i     ...      >>> f = Foo() # Create an instance of the Foo class     >>> f.bar()     Foo.i is 3     self.i is 3     >>> Foo.i = 5 # Change the global value of Foo.i over all instances     >>> f.bar()     Foo.i is 5     self.i is 5     >>> f.i = 3 # Override this instance's definition of i     >>> f.bar()     Foo.i is 5     self.i is 3      ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/475871/python-why-use-self-in-a-class","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    How do these 2 classes differ?  class A():     x=3  class B():     def __init__(self):         self.x=3   Is there any significant difference?      ","Q_Votes":"79"},{"Q_Title":"Python - why use self in a class?","A_Content":"  I used to explain it with this example  # By TMOTTM  class Machine:      # Class Variable counts how many machines have been created.     # The value is the same for all objects of this class.     counter = 0      def __init__(self):          # Notice: no 'self'.         Machine.counter += 1          # Instance variable.         # Different for every object of the class.         self.id = Machine.counter  if __name__ == '__main__':     machine1 = Machine()     machine2 = Machine()     machine3 = Machine()      #The value is different for all objects.     print 'machine1.id', machine1.id     print 'machine2.id', machine2.id     print 'machine3.id', machine3.id      #The value is the same for all objects.     print 'machine1.counter', machine1.counter     print 'machine2.counter', machine2.counter     print 'machine3.counter', machine3.counter   The output then will by   machine1.id 1 machine2.id 2 machine3.id 3  machine1.counter 3 machine2.counter 3 machine3.counter 3      ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/475871/python-why-use-self-in-a-class","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    How do these 2 classes differ?  class A():     x=3  class B():     def __init__(self):         self.x=3   Is there any significant difference?      ","Q_Votes":"79"},{"Q_Title":"Python - why use self in a class?","A_Content":"  I've just started learning Python and this confused me as well for some time. Trying to figure out how it all works in general I came up with this very simple piece of code:  # Create a class with a variable inside and an instance of that class class One:     color = 'green'  obj2 = One()   # Here we create a global variable(outside a class suite). color = 'blue'           # Create a second class and a local variable inside this class.        class Two:                  color = \"red\"      # Define 3 methods. The only difference between them is the \"color\" part.     def out(self):              print(self.color + '!')      def out2(self):         print(color + '!')      def out3(self):         print(obj2.color + '!')  # Create an object of the class One obj = Two()   When we call out() we get:  >>> obj.out()  red!   When we call out2():  >>> obj.out2()  blue!   When we call out3():  >>> obj.out3()  green!   So, in the first method self specifies that Python should use the variable(attribute), that \"belongs\" to the class object we created, not a global one(outside the class). So it uses color = \"red\". In the method Python implicitly substitutes self for the name of an object we created(obj). self.color means \"I am getting color=\"red\" from the obj\"  In the second method there is no self to specify the object where the color should be taken from, so it gets the global one color = 'blue'.  In the third method instead of self we used obj2 - a name of another object to get color from. It gets color = 'green'.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/475871/python-why-use-self-in-a-class","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How do these 2 classes differ?  class A():     x=3  class B():     def __init__(self):         self.x=3   Is there any significant difference?      ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  New Update:  Install the latest version of setuptools. If you still get the error, install wheel as well.  pip install -U setuptools pip install -U wheel     Original Answer / More Details:  --single-version-externally-managed is an option used for Python packages instructing the setuptools module to create a Python package which can be easily managed by the host's package manager if needed, like Yum or Apt.  If you're seeing this message, you may have an old version of setuptools or Python. Try using Distribute, which is a newer version of setuptools and is backwards compatible. These packages may expect that you have it already.  https://pypi.python.org/pypi/distribute  Edit: At this point, distribute has been merged into the main setuptools project. Just install the latest version of setuptools. As @wynemo indicated, you may wish to use the --egg option instead, as it's more appropriate for those doing manual installations where you're not intending to create a system package for distribution.     ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  Add --egg option  pip install --egg SCons   I use pip version 1.4.1     ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"134","_type":"dict","isAccepted":"No","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  Installing wheel resolved this issue with recent pip (I used 8.1.2):  pip install wheel      ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  Try upgrading setuptools like this:  pip install --upgrade setuptools     ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  I was having this problem. It turned out it was a problem with the file permissions on my pip cache.  If you see a message at the very beginning of your pip output like  The directory '/home/ubuntu/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag. The directory '/home/ubuntu/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.   you might have the same problem. You can resolve it by either ensuring that you have proper file permissions on your pip cache (something like chown -R $(whoami) /home/ubuntu/.cache/pip) or, if you're on a UNIX, you can set the pip cache location with the XDG_CACHE_HOME env var to some folder you do own.     ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"What does error: option --single-version-externally-managed not recognized indicate?","A_Content":"  I have this problem on my macbook also when I try to upgrade one python package. I check pip version in OS X, it's too old: 1.1. I use follow cmd to upgrade pip to 1.5.6  easy_install -U pip   Then this error is fixed.     ","Language":"Python","Tags":["python","pip","distribute"],"URL":"https://stackoverflow.com/questions/14296531/what-does-error-option-single-version-externally-managed-not-recognized-ind","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I seem to have suddenly started encounter the error error: option --single-version-externally-managed not recognized when pip installing varions packages (including PyObjC and astropy).  I've never seen this error before, but it's now also showing up on travis-ci builds for which nothing has changed.  Does this error indicate an out of date distribute?  Or some incorrectly specified option in setup.py?  Or something else entirely?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  You can use the find command to search for a file:  find / -name virtualenvwrapper.sh  This will search all directories from the root for the file.    on ubuntu 12.04 LTS, installing through pip, it is installed to  /usr/local/bin/virtualenvwrapper.sh    on ubuntu 17.04, installing through pip as a normal user, it is installed to  ~/.local/bin/virtualenvwrapper.sh     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  did you already try this ?  $ which virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"51","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  I just reinstalled it with pip.  sudo pip uninstall virtualenvwrapper sudo pip install virtualenvwrapper   And this time it put it in /usr/local/bin.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  The exact path where      virtualenvwrapper.sh         is stored/located varies from OS to OS. Even with in same OS, it varies from version to version. So we need a generic solution that works for all OS versions.  Easiest way I have found to find its path is: Do  pip uninstall virtualenvwrapper   This will prompt a confirmation. Say \"No\" But first line of confirmation shows the path of virtualenvwrapper.sh (Prompt gives a list of files it will delete, if you say Yes. First entry in this list contains path to virtualenvwrapper.sh in your machine)     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  or, like I did..just uninstall virtualenvwrapper      sudo pip uninstall virtualenvwrapper   and then install it with easy_install      sudo easy_install virtualenvwrapper   this time I found the file \"/usr/local/bin/virtualenvwrapper.sh\" installed... Before that I weren't finding that file anywhere even by this command      find / -name virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  On Mac OS  which virtualenvwrapper.sh   u got   /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh   and u can   sudo ln /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh /usr/local/bin/virtualenvwrapper.sh   and in your .bash_profile  source /usr/local/bin/virtualenvwrapper.sh   or u can  source /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  In OSx EI captain, I installed the virtualenvwrapper as  sudo pip3 install virtualenvwrapper   , however I cannot find the virtualenvwrapper.sh in /user/local/bin, it was finally found at /Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenvwrapper.sh , and you can make an soft link to /usr/local/bin as  ln -s /Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenvwrapper.sh  /usr/local/bin/virtualenvwrapper.sh, and everything you can just follow the setup guide as the official document does.  Good luck!     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  In OS X 10.8.2, with Python 2.7:  /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  I have the same problem. If you have older version of virtualenvwrapper, then pip wont work.  download src from http://pypi.python.org/pypi/virtualenvwrapper/3.6 and python setup.py install. Then the problem solved.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  For RPM-based distributions(like Fedora 19), after running the sudo pip install virtualenvwrapper command, you may find the file at:  /usr/bin/virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  For me it was in :  ~/Library/Python/2.7/bin/virtualenvwrapper.sh   (With OS X, with a pip install --user installation)     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  Installed it using pip on Ubuntu 15.10 using a normal user, it was put in ~/.local/bin/virtualenvwrapper.sh which I found by running:  $ find / -name virtualenvwrapper.sh 2>/dev/null     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  Using   find / -name virtualenvwrapper.sh   I got a TON of \"permissions denied\"s, and exactly one printout of the file location. I missed it until I found that file location when I uninstall/installed it again with pip.   In case you were curious, it was in   /usr/local/share/python/virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  In my case (OSX El Capitan, version 10.11.5) I needed to edit the .profile like so:  In the terminal:     vim ~/.profile   export WORKON_HOME=$HOME/.virtualenvs export MSYS_HOME=C:\\msys\\1.0 source /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh                                                                                      And then reload the profile (that it will be availuble in the current session.)     source ~/.profile   Hope it will help someone.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  Although this is an OS X question, here's what worked for me on Linux (Red Hat).  My virtualwrapper.sh was in  ~/.local/bin/virtualenvwrapper.sh   This is probably because I installed virtualenvwrapper locally, using the --user flag...  pip install --user virtualenvwrapper   ...as an alternative to the risky practice of using sudo pip.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  /usr/share/virtualenvwrapper/virtualenvwrapper.sh   I've installed it on Ubuntu 16.04 and it resulted in this location.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  /usr/local/bin/virtualenvwrapper.sh      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  I had the same issue in with the beagle bone black(debian).   Manually downloading the package and installing worked for me.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  For Ubuntu If you just installed it, check the output on Terminal, I'm posting mine :  Running setup.py install for virtualenv-clone     Installing virtualenv-clone script to /home/username/.local/bin Successfully installed virtualenvwrapper virtualenv virtualenv-clone stevedore pbr six Cleaning up...   Here the second line tells you the path. For me it was at /home/username/.local/bin     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  pip will not try to make things difficult for you on purpose.  The thing is commands based files are always installed in /bin folders they can be anywhere on the system path.  I had the same problem and I found that I have these files in my   ~/.local/bin/  folder instead of  /usr/loca/bin/  which is the common case, but I think they changed the default path to   ~ or $HOME  directory because its more isolate for the pip installations and provides a distinction between apt-get packages and pip packages.  So coming to the point you have two choices here either you go to your .bashrc and make changes like this  # for virtualenv wrapper export WORKON_HOME=$HOME/Envs export PROJECT_HOME=$HOME/Devel source $HOME/.local/bin/virtualenvwrapper.sh   and than create a directory virtualenvwrapper under /usr/share/ and than symlink your virtualwrapper_lazy.sh like this  sudo ln -s ~/.local/bin/virtualenvwrapper_lazy.sh /usr/share/virtualenvwrapper/virtualenvwrapper_lazy.sh   and you can check if your workon command is working which will list your existing virtualenv's.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  Have you installed it using sudo? Was the error in my case.     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  If you execute pip install virtualenvwrapper without sudo as a normal user pip will run but won't copy the files in the required locations because the lack of permissions.  mortiz@florida:~# sudo pip3 install virtualenvwrapper   Use sudo and the files will be created under their respective paths:  root@florida:/usr/local/bin# ls -ltr total 8008 -rwxr-xr-x 1 root staff 8136192 Jun 11 17:45 chromedriver -rwxr-xr-x 1 root staff   41697 Sep  5 16:06 virtualenvwrapper.sh -rwxr-xr-x 1 root staff    2210 Sep  5 16:06 virtualenvwrapper_lazy.sh -rwxr-xr-x 1 root staff     215 Sep  5 16:06 pbr -rwxr-xr-x 1 root staff     218 Sep  5 16:06 virtualenv-clone -rwxr-xr-x 1 root staff     213 Sep  5 16:06 virtualenv root@florida:/usr/local/bin#    Worked for me on Debian GNU/Linux 9      ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"Where is virtualenvwrapper.sh after pip install?","A_Content":"  in my case: /home/username/.local/bin/virtualenvwrapper.sh     ","Language":"Python","Tags":["python","macos","virtualenv","pip","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/12647266/where-is-virtualenvwrapper-sh-after-pip-install","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to setup virtualenvwrapper on OSX, and all the instructions and tutorials I've found tell me to add a source command to .profile, pointing towards virtualenvwrapper.sh. I've checked all the python and site-packages directories, and I can't find any virtualenvwrapper.sh. Is this something I need to download separately? Is pip not installing correctly?  This is the contents of /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/virtualenvwrapper:  hook_loader.py      hook_loader.pyc     project.py      project.pyc     user_scripts.py     user_scripts.pyc   As you can see, no virtualenvwrapper.sh. Where is it?     ","Q_Votes":"79"},{"Q_Title":"How to update SQLAlchemy row entry?","A_Content":"  user.no_of_logins += 1 session.commit()      ","Language":"Python","Tags":["python","sqlalchemy","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/9667138/how-to-update-sqlalchemy-row-entry","A_Votes":"76","_type":"dict","isAccepted":"Yes","Q_Content":"    Assume table has three columns: username, password and no_of_logins.  When user tries to login, it's checked for an entry with a query like  user=User.query.filter_by(username=form.username.data).first()   If password matches, he proceeds further. What I would like to do is count how many times the user logged in. Thus whenever he successfully logs in, I would like to increment the no_of_logins field and store it back to the user table. I'm not sure how to run update query with SqlAlchemy.     ","Q_Votes":"79"},{"Q_Title":"How to update SQLAlchemy row entry?","A_Content":"  There are several ways to UPDATE using sqlalchemy  1) user.no_of_logins += 1    session.commit()  2) session.query().\\        filter(User.username == form.username.data).\\        update({\"no_of_logins\": (User.no_of_logins +1)})    session.commit()  3) conn = engine.connect()    stmt = User.update().\\        values(no_of_logins=(User.no_of_logins + 1)).\\        where(User.username == form.username.data)    conn.execute(stmt)  4) setattr(user, 'no_of_logins', user.no_of_logins+1)    session.commit()      ","Language":"Python","Tags":["python","sqlalchemy","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/9667138/how-to-update-sqlalchemy-row-entry","A_Votes":"218","_type":"dict","isAccepted":"No","Q_Content":"    Assume table has three columns: username, password and no_of_logins.  When user tries to login, it's checked for an entry with a query like  user=User.query.filter_by(username=form.username.data).first()   If password matches, he proceeds further. What I would like to do is count how many times the user logged in. Thus whenever he successfully logs in, I would like to increment the no_of_logins field and store it back to the user table. I'm not sure how to run update query with SqlAlchemy.     ","Q_Votes":"79"},{"Q_Title":"How to update SQLAlchemy row entry?","A_Content":"  With the help of user=User.query.filter_by(username=form.username.data).first() statement you will get the specified user in user variable.   Now you can change the value of the new object variable like user.no_of_logins += 1 and save the changes with the session's commit method.     ","Language":"Python","Tags":["python","sqlalchemy","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/9667138/how-to-update-sqlalchemy-row-entry","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Assume table has three columns: username, password and no_of_logins.  When user tries to login, it's checked for an entry with a query like  user=User.query.filter_by(username=form.username.data).first()   If password matches, he proceeds further. What I would like to do is count how many times the user logged in. Thus whenever he successfully logs in, I would like to increment the no_of_logins field and store it back to the user table. I'm not sure how to run update query with SqlAlchemy.     ","Q_Votes":"79"},{"Q_Title":"Inherit docstrings in Python class inheritance [closed]","A_Content":"  You're not the only one! There was a discussion on comp.lang.python about this a while ago, and a recipe was created. Check it out here.  \"\"\" doc_inherit decorator  Usage:  class Foo(object):     def foo(self):         \"Frobber\"         pass  class Bar(Foo):     @doc_inherit     def foo(self):         pass   Now, Bar.foo.__doc__ == Bar().foo.__doc__ == Foo.foo.__doc__ == \"Frobber\" \"\"\"  from functools import wraps  class DocInherit(object):     \"\"\"     Docstring inheriting method descriptor      The class itself is also used as a decorator     \"\"\"      def __init__(self, mthd):         self.mthd = mthd         self.name = mthd.__name__      def __get__(self, obj, cls):         if obj:             return self.get_with_inst(obj, cls)         else:             return self.get_no_inst(cls)      def get_with_inst(self, obj, cls):          overridden = getattr(super(cls, obj), self.name, None)          @wraps(self.mthd, assigned=('__name__','__module__'))         def f(*args, **kwargs):             return self.mthd(obj, *args, **kwargs)          return self.use_parent_doc(f, overridden)      def get_no_inst(self, cls):          for parent in cls.__mro__[1:]:             overridden = getattr(parent, self.name, None)             if overridden: break          @wraps(self.mthd, assigned=('__name__','__module__'))         def f(*args, **kwargs):             return self.mthd(*args, **kwargs)          return self.use_parent_doc(f, overridden)      def use_parent_doc(self, func, source):         if source is None:             raise NameError, (\"Can't find '%s' in parents\"%self.name)         func.__doc__ = source.__doc__         return func  doc_inherit = DocInherit       ","Language":"Python","Tags":["python","inheritance","documentation"],"URL":"https://stackoverflow.com/questions/2025562/inherit-docstrings-in-python-class-inheritance","A_Votes":"33","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to do some class inheritance in Python. I'd like each class and inherited class to have good docstrings. So I think for the inherited class, I'd like it to:   inherit the base class docstring maybe append relevant extra documentation to the docstring   Is there any (possibly elegant or pythonic) way of doing this sort of docstring manipulation in a class inheritance situation? How about for multiple inheritance?     ","Q_Votes":"78"},{"Q_Title":"Inherit docstrings in Python class inheritance [closed]","A_Content":"  You can concatenate the docstrings easily:  class Foo(object):     \"\"\"     Foo Class.     This class foos around.     \"\"\"     pass  class Bar(Foo):     \"\"\"     Bar class, children of Foo     Use this when you want to Bar around.     parent:     \"\"\"      __doc__ += Foo.__doc__     pass   However, that is useless. Most documentation generation tool (Sphinx and Epydoc included) will already pull parent docstring, including for methods. So you don't have to do anything.     ","Language":"Python","Tags":["python","inheritance","documentation"],"URL":"https://stackoverflow.com/questions/2025562/inherit-docstrings-in-python-class-inheritance","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to do some class inheritance in Python. I'd like each class and inherited class to have good docstrings. So I think for the inherited class, I'd like it to:   inherit the base class docstring maybe append relevant extra documentation to the docstring   Is there any (possibly elegant or pythonic) way of doing this sort of docstring manipulation in a class inheritance situation? How about for multiple inheritance?     ","Q_Votes":"78"},{"Q_Title":"Inherit docstrings in Python class inheritance [closed]","A_Content":"  Not particularly elegant, but simple and direct:  class X(object):   \"\"\"This class has a method foo().\"\"\"   def foo(): pass  class Y(X):   __doc__ = X.__doc__ + ' Also bar().'   def bar(): pass   Now:  >>> print Y.__doc__ This class has a method foo(). Also bar().      ","Language":"Python","Tags":["python","inheritance","documentation"],"URL":"https://stackoverflow.com/questions/2025562/inherit-docstrings-in-python-class-inheritance","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to do some class inheritance in Python. I'd like each class and inherited class to have good docstrings. So I think for the inherited class, I'd like it to:   inherit the base class docstring maybe append relevant extra documentation to the docstring   Is there any (possibly elegant or pythonic) way of doing this sort of docstring manipulation in a class inheritance situation? How about for multiple inheritance?     ","Q_Votes":"78"},{"Q_Title":"Inherit docstrings in Python class inheritance [closed]","A_Content":"  A mixed stile that can preserve both the inherited docstring syntax and the preferred ordering can be:  class X(object):   \"\"\"This class has a method foo().\"\"\"   def foo(): pass  class Y(X):   \"\"\" Also bar().\"\"\"   __doc__ = X.__doc__ + __doc__   def bar(): pass   With the same output as Alex's one:  >>> print Y.__doc__ This class has a method foo(). Also bar().   Thin ice: playing with docstring can make your module unusable with python -OO, expect some:  TypeError: cannot concatenate 'str' and 'NoneType' objects      ","Language":"Python","Tags":["python","inheritance","documentation"],"URL":"https://stackoverflow.com/questions/2025562/inherit-docstrings-in-python-class-inheritance","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to do some class inheritance in Python. I'd like each class and inherited class to have good docstrings. So I think for the inherited class, I'd like it to:   inherit the base class docstring maybe append relevant extra documentation to the docstring   Is there any (possibly elegant or pythonic) way of doing this sort of docstring manipulation in a class inheritance situation? How about for multiple inheritance?     ","Q_Votes":"78"},{"Q_Title":"Inherit docstrings in Python class inheritance [closed]","A_Content":"  I wrote custom_inherit to provide some simple, light weight tools for handling docstring inheritance.   It also comes with some nice default styles for merging different types of docstrings (e.g. Numpy, Google, and reST formatted docstrings). You can also provide your own style very easily.  Overlapping docstring sections will defer to the child's section, otherwise they are merged together with nice formatting.     ","Language":"Python","Tags":["python","inheritance","documentation"],"URL":"https://stackoverflow.com/questions/2025562/inherit-docstrings-in-python-class-inheritance","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to do some class inheritance in Python. I'd like each class and inherited class to have good docstrings. So I think for the inherited class, I'd like it to:   inherit the base class docstring maybe append relevant extra documentation to the docstring   Is there any (possibly elegant or pythonic) way of doing this sort of docstring manipulation in a class inheritance situation? How about for multiple inheritance?     ","Q_Votes":"78"},{"Q_Title":"Generator as function argument","A_Content":"  Both 3. and 4. should be syntax errors on all Python versions. However you've found a bug that affects Python versions 2.5 - 3.4, and which was subsequently posted to the Python issue tracker. Because of the bug, an unparenthesized generator expression was accepted as an argument to a function if it was accompanied only by *args and/or **kwargs. While Python 2.6+ allowed both cases 3. and 4., Python 2.5 allowed only case 3. - yet both of them were against the documented grammar:  call    ::=     primary \"(\" [argument_list [\",\"]                             | expression genexpr_for] \")\"   i.e. the documentation says a function call comprises of primary (the expression that evaluates to a callable), followed by, in parentheses, either an argument list or just an unparenthesized generator expression; and within the argument list, all generator expressions must be in parentheses.    This bug (though it seems it had not been known), had been fixed in Python 3.5 prereleases. In Python 3.5 parentheses are always required around a generator expression, unless it is the only argument to the function:  Python 3.5.0a4+ (default:a3f2b171b765, May 19 2015, 16:14:41)  [GCC 4.9.2] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> f(1 for i in [42], *a)   File \"<stdin>\", line 1 SyntaxError: Generator expression must be parenthesized if not sole argument   This is now documented in the What's New in Python 3.5, thanks to DeTeReR spotting this bug.    Analysis of the bug  There was a change made to Python 2.6 which allowed the use of keyword arguments after *args:     Its also become legal to provide keyword arguments after a *args   argument to a function call.  >>> def f(*args, **kw): ...     print args, kw ... >>> f(1,2,3, *(4,5,6), keyword=13) (1, 2, 3, 4, 5, 6) {'keyword': 13}       Previously this would have been a syntax error. (Contributed by Amaury   Forgeot dArc; issue 3473.)     However, the Python 2.6 grammar does not make any distinction between keyword arguments, positional arguments, or bare generator expressions - they are all of type argument to the parser.  As per Python rules, a generator expression must be parenthesized if it is not the sole argument to the function. This is validated in the Python/ast.c:  for (i = 0; i < NCH(n); i++) {     node *ch = CHILD(n, i);     if (TYPE(ch) == argument) {         if (NCH(ch) == 1)             nargs++;         else if (TYPE(CHILD(ch, 1)) == gen_for)             ngens++;         else             nkeywords++;     } } if (ngens > 1 || (ngens && (nargs || nkeywords))) {     ast_error(n, \"Generator expression must be parenthesized \"               \"if not sole argument\");     return NULL; }   However this function does not consider the *args at all - it specifically only looks for ordinary positional arguments and keyword arguments.  Further down in the same function, there is an error message generated for non-keyword arg after keyword arg:  if (TYPE(ch) == argument) {     expr_ty e;     if (NCH(ch) == 1) {         if (nkeywords) {             ast_error(CHILD(ch, 0),                       \"non-keyword arg after keyword arg\");             return NULL;         }         ...   But this again applies to arguments that are not unparenthesized generator expressions as evidenced by the else if statement:  else if (TYPE(CHILD(ch, 1)) == gen_for) {     e = ast_for_genexp(c, ch);     if (!e)         return NULL;     asdl_seq_SET(args, nargs++, e); }   Thus an unparenthesized generator expression was allowed to slip pass.    Now in Python 3.5 one can use the *args anywhere in a function call, so the Grammar was changed to accommodate for this:  arglist: argument (',' argument)*  [',']   and   argument: ( test [comp_for] |             test '=' test |             '**' test |             '*' test )   and the for loop was changed to  for (i = 0; i < NCH(n); i++) {     node *ch = CHILD(n, i);     if (TYPE(ch) == argument) {         if (NCH(ch) == 1)             nargs++;         else if (TYPE(CHILD(ch, 1)) == comp_for)             ngens++;         else if (TYPE(CHILD(ch, 0)) == STAR)             nargs++;         else             /* TYPE(CHILD(ch, 0)) == DOUBLESTAR or keyword argument */             nkeywords++;     } }   Thus fixing the bug.  However the inadvertent change is that the valid looking constructions  func(i for i in [42], *args)   and  func(i for i in [42], **kwargs)   where an unparenthesized generator precedes *args or **kwargs now stopped working.    To locate this bug, I tried various Python versions. In 2.5 you'd get SyntaxError:  Python 2.5.5 (r255:77872, Nov 28 2010, 16:43:48)  [GCC 4.4.5] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> f(*[1], 2 for x in [2])   File \"<stdin>\", line 1     f(*[1], 2 for x in [2])   And this was fixed before some prerelease of Python 3.5:  Python 3.5.0a4+ (default:a3f2b171b765, May 19 2015, 16:14:41)  [GCC 4.9.2] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> f(*[1], 2 for x in [2])   File \"<stdin>\", line 1 SyntaxError: Generator expression must be parenthesized if not sole argument   However, the parenthesized generator expression, it works in Python 3.5, but it does not work not in Python 3.4:  f(*[1], (2 for x in [2]))   And this is the clue. In Python 3.5 the *splatting is generalized; you can use it anywhere in a function call:  >>> print(*range(5), 42) 0 1 2 3 4 42   So the actual bug (generator working with *star without parentheses) was indeed fixed in Python 3.5, and the bug could be found in that what changed between Python 3.4 and 3.5     ","Language":"Python","Tags":["python","python-2.7","syntax","generator-expression"],"URL":"https://stackoverflow.com/questions/32521140/generator-as-function-argument","A_Votes":"73","_type":"dict","isAccepted":"Yes","Q_Content":"    Can anyone explain why passing a generator as the only positional argument to a function seems to have special rules?  If we have:   >>> def f(*args): >>>    print \"Success!\" >>>    print args    This works, as expected.  >>> f(1, *[2]) Success! (1, 2)  This does not work, as expected.  >>> f(*[2], 1)   File \"<stdin>\", line 1 SyntaxError: only named arguments may follow *expression  This works, as expected  >>> f(1 for x in [1], *[2]) Success!  (generator object <genexpr> at 0x7effe06bdcd0>, 2)  This works, but I don't understand why. Shouldn't it fail in the same way as 2)  >>> f(*[2], 1 for x in [1])                                                Success! (generator object <genexpr> at 0x7effe06bdcd0>, 2)       ","Q_Votes":"78"},{"Q_Title":"Where is Python's sys.path initialized from?","A_Content":"  \"Initialized from the environment variable PYTHONPATH, plus an installation-dependent default\"  -- http://docs.python.org/library/sys.html#sys.path     ","Language":"Python","Tags":["python","path","sys"],"URL":"https://stackoverflow.com/questions/897792/where-is-pythons-sys-path-initialized-from","A_Votes":"37","_type":"dict","isAccepted":"Yes","Q_Content":"    Where is Python's sys.path initialized from?  UPD: Python is adding some paths before refering to PYTHONPATH:      >>> import sys     >>> from pprint import pprint as p     >>> p(sys.path)     ['',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\setuptools-0.6c9-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\orbited-0.7.8-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\morbid-0.8.6.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\demjson-1.4-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\stomper-0.2.2-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\uuid-1.30-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\stompservice-0.1.0-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\cherrypy-3.0.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\pyorbited-0.2.2-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\flup-1.0.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\wsgilog-0.1-py2.5.egg',      'c:\\\\testdir',      'C:\\\\Windows\\\\system32\\\\python25.zip',      'C:\\\\Python25\\\\DLLs',      'C:\\\\Python25\\\\lib',      'C:\\\\Python25\\\\lib\\\\plat-win',      'C:\\\\Python25\\\\lib\\\\lib-tk',      'C:\\\\Python25',      'C:\\\\Python25\\\\lib\\\\site-packages',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\PIL',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\win32',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\win32\\\\lib',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\Pythonwin']   My PYTHONPATH is:      PYTHONPATH=c:\\testdir   I wonder where those paths before PYTHONPATH's ones come from?     ","Q_Votes":"78"},{"Q_Title":"Where is Python's sys.path initialized from?","A_Content":"  Python really tries hard to intelligently set sys.path. How it is set can get really complicated. The following guide is a watered-down, somewhat-incomplete, somewhat-wrong, but hopefully-useful guide for the rank-and-file python programmer of what happens when python figures out what to use as the initial values of sys.path, sys.executable, sys.exec_prefix, and sys.prefix on a normal python installation.  First, python does its level best to figure out its actual physical location on the filesystem based on what the operating system tells it. If the OS just says \"python\" is running, it finds itself in $PATH. It resolves any symbolic links. Once it has done this, the path of the executable that it finds is used as the value for sys.executable, no ifs, ands, or buts.  Next, it determines the initial values for sys.exec_prefix and  sys.prefix.  If there is a file called pyvenv.cfg in the same directory as sys.executable or one directory up, python looks at it. Different OSes do different things with this file.  One of the values in this config file that python looks for is the configuration option home = <DIRECTORY>. Python will use this directory instead of the directory containing sys.executable when it dynamically sets the initial value of sys.prefix later. If the applocal = true setting appears in the pyvenv.cfg file on Windows, but not the home = <DIRECTORY> setting, then sys.prefix will be set to the directory containing sys.executable.  Next, the PYTHONHOME environment variable is examined. On Linux and Mac, sys.prefix and sys.exec_prefix are set to the PYTHONHOME environment variable, if it exists, superseding any home = <DIRECTORY> setting in pyvenv.cfg. On Windows, sys.prefix and sys.exec_prefix is set to the PYTHONHOME environment variable, if it exists, unless a home = <DIRECTORY> setting is present in pyvenv.cfg, which is used instead.  Otherwise, these sys.prefix and sys.exec_prefix are found by walking backwards from the location of sys.executable, or the home directory given by pyvenv.cfg if any.  If the file lib/python<version>/dyn-load is found in that directory or any of its parent directories, that directory is set to be to be sys.exec_prefix on Linux or Mac. If the file lib/python<version>/os.py is is found in the directory or any of its subdirectories, that directory is set to be sys.prefix on Linux, Mac, and Windows, with sys.exec_prefix set to the same value as sys.prefix on Windows. This entire step is skipped on Windows if applocal = true is set. Either the directory of sys.executable is used or, if home is set in pyvenv.cfg, that is used instead for the initial value of sys.prefix.  If it can't find these \"landmark\" files or sys.prefix hasn't been found yet, then python sets sys.prefix to a \"fallback\" value. Linux and Mac, for example, use pre-compiled defaults as the values of sys.prefix and sys.exec_prefix.  Windows waits until sys.path is fully figured out to set a fallback value for sys.prefix.  Then, (what you've all been waiting for,) python determines the initial values that are to be contained in sys.path.   The directory of the script which python is executing is added to sys.path. On Windows, this is always the empty string, which tells python to use the present working directory instead. The contents of PYTHONPATH environment variable, if set, is added to sys.path, unless you're on Windows and applocal is set to true in pyvenv.cfg. The zip file path, which is <prefix>/lib/python35.zip on Linux/Mac and os.path.join(os.dirname(sys.executable), \"python.zip\") on Windows, is added to sys.path. If on Windows and no applocal = true was set in pyvenv.cfg, then the contents of the subkeys of the registry key HK_CURRENT_USER\\Software\\Python\\PythonCore\\<DLLVersion>\\PythonPath\\ are added, if any. If on Windows and no applocal = true was set in pyvenv.cfg, and sys.prefix could not be found,  then the core contents of the of the registry key HK_CURRENT_USER\\Software\\Python\\PythonCore\\<DLLVersion>\\PythonPath\\ is added, if it exists; If on Windows and no applocal = true was set in pyvenv.cfg, then the contents of the subkeys of the registry key HK_LOCAL_MACHINE\\Software\\Python\\PythonCore\\<DLLVersion>\\PythonPath\\ are added, if any. If on Windows and no applocal = true was set in pyvenv.cfg, and sys.prefix could not be found,  then the core contents of the of the registry key HK_CURRENT_USER\\Software\\Python\\PythonCore\\<DLLVersion>\\PythonPath\\ is added, if it exists; If on Windows, and PYTHONPATH was not set, the prefix was not found, and no registry keys were present, then the relative compile-time value of PYTHONPATH is added; otherwise, this step is ignored. Paths in the compile-time macro PYTHONPATH are added relative to the dynamically-found sys.prefix. On Mac and Linux, the value of sys.exec_prefix is added. On Windows, the directory which was used (or would have been used) to search dynamically for sys.prefix is added.   At this stage on Windows, if no prefix was found, then python will try to determine it by searching all the directories in sys.path for the landmark files, as it tried to do with the directory of sys.executable previously, until it finds something. If it doesn't, sys.prefix is left blank.  Finally, after all this, Python loads the site module, which adds stuff yet further to sys.path:     It starts by constructing up to four directories from a head and a   tail part. For the head part, it uses sys.prefix and sys.exec_prefix;   empty heads are skipped. For the tail part, it uses the empty string   and then lib/site-packages (on Windows) or lib/pythonX.Y/site-packages   and then lib/site-python (on Unix and Macintosh). For each of the   distinct head-tail combinations, it sees if it refers to an existing   directory, and if so, adds it to sys.path and also inspects the newly   added path for configuration files.      ","Language":"Python","Tags":["python","path","sys"],"URL":"https://stackoverflow.com/questions/897792/where-is-pythons-sys-path-initialized-from","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    Where is Python's sys.path initialized from?  UPD: Python is adding some paths before refering to PYTHONPATH:      >>> import sys     >>> from pprint import pprint as p     >>> p(sys.path)     ['',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\setuptools-0.6c9-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\orbited-0.7.8-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\morbid-0.8.6.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\demjson-1.4-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\stomper-0.2.2-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\uuid-1.30-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\stompservice-0.1.0-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\cherrypy-3.0.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\pyorbited-0.2.2-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\flup-1.0.1-py2.5.egg',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\wsgilog-0.1-py2.5.egg',      'c:\\\\testdir',      'C:\\\\Windows\\\\system32\\\\python25.zip',      'C:\\\\Python25\\\\DLLs',      'C:\\\\Python25\\\\lib',      'C:\\\\Python25\\\\lib\\\\plat-win',      'C:\\\\Python25\\\\lib\\\\lib-tk',      'C:\\\\Python25',      'C:\\\\Python25\\\\lib\\\\site-packages',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\PIL',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\win32',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\win32\\\\lib',      'C:\\\\Python25\\\\lib\\\\site-packages\\\\Pythonwin']   My PYTHONPATH is:      PYTHONPATH=c:\\testdir   I wonder where those paths before PYTHONPATH's ones come from?     ","Q_Votes":"78"},{"Q_Title":"Difference between python3 and python3m executables","A_Content":"  Credit for this goes to chepner for pointing out that I already had the link to the solution.     Python implementations MAY include additional flags in the file name   tag as appropriate. For example, on POSIX systems these flags will   also contribute to the file name:      --with-pydebug (flag: d)      --with-pymalloc (flag: m)      --with-wide-unicode (flag: u)   via PEP 3149.  Regarding the m flag specifically, this is what Pymalloc is:     Pymalloc, a specialized object allocator written by Vladimir   Marangozov, was a feature added to Python 2.1. Pymalloc is intended to   be faster than the system malloc() and to have less memory overhead   for allocation patterns typical of Python programs. The allocator uses   C's malloc() function to get large pools of memory and then fulfills   smaller memory requests from these pools.   via What's New in Python 2.3  Finally, the two files may be hardlinked on some systems. While the two files have different inode numbers on my Ubuntu 13.04 system (thus are different files), a comp.lang.python post from two years ago shows that they once were hardlinked.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/16675865/difference-between-python3-and-python3m-executables","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the difference between the /usr/bin/python3 and /usr/bin/python3m executibles?  I am observing them on Ubuntu 13.04, but Google suggests that they exist on other distributions too.  The two files have the same md5sum, but do not seem to be symbolic links or hard links; the two files have different inode numbers returned by ls -li and testing find -xdev -samefile /usr/bin/python3.3 does not return any other files.  Someone asked a similar question on AskUbuntu, but I wanted to find out more about the difference between the two files.      ","Q_Votes":"78"},{"Q_Title":"How can I set the aspect ratio in matplotlib?","A_Content":"  Third times the charm. My guess is that this is a bug and Zhenya's answer suggests it's fixed in the latest version. I have version 0.99.1.1 and I've created the following solution:   import matplotlib.pyplot as plt import numpy as np  def forceAspect(ax,aspect=1):     im = ax.get_images()     extent =  im[0].get_extent()     ax.set_aspect(abs((extent[1]-extent[0])/(extent[3]-extent[2]))/aspect)  data = np.random.rand(10,20)  fig = plt.figure() ax = fig.add_subplot(111) ax.imshow(data) ax.set_xlabel('xlabel') ax.set_aspect(2) fig.savefig('equal.png') ax.set_aspect('auto') fig.savefig('auto.png') forceAspect(ax,aspect=1) fig.savefig('force.png')   This is 'force.png':   Below are my unsuccessful, yet hopefully informative attempts.   Second Answer:  My 'original answer' below is overkill, as it does something similar to axes.set_aspect(). I think you want to use axes.set_aspect('auto'). I don't understand why this is the case, but it produces a square image plot for me, for example this script:  import matplotlib.pyplot as plt import numpy as np  data = np.random.rand(10,20)  fig = plt.figure() ax = fig.add_subplot(111) ax.imshow(data) ax.set_aspect('equal') fig.savefig('equal.png') ax.set_aspect('auto') fig.savefig('auto.png')   Produces an image plot with 'equal' aspect ratio:  and one with 'auto' aspect ratio:   The code provided below in the 'original answer' provides a starting off point for an explicitly controlled aspect ratio, but it seems to be ignored once an imshow is called.   Original Answer:  Here's an example of a routine that will adjust the subplot parameters so that you get the desired aspect ratio:  import matplotlib.pyplot as plt  def adjustFigAspect(fig,aspect=1):     '''     Adjust the subplot parameters so that the figure has the correct     aspect ratio.     '''     xsize,ysize = fig.get_size_inches()     minsize = min(xsize,ysize)     xlim = .4*minsize/xsize     ylim = .4*minsize/ysize     if aspect < 1:         xlim *= aspect     else:         ylim /= aspect     fig.subplots_adjust(left=.5-xlim,                         right=.5+xlim,                         bottom=.5-ylim,                         top=.5+ylim)  fig = plt.figure() adjustFigAspect(fig,aspect=.5) ax = fig.add_subplot(111) ax.plot(range(10),range(10))  fig.savefig('axAspect.png')   This produces a figure like so:   I can imagine if your having multiple subplots within the figure, you would want to include the number of y and x subplots as keyword parameters (defaulting to 1 each) to the routine provided. Then using those numbers and the hspace and wspace keywords, you can make all the subplots have the correct aspect ratio.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/7965743/how-can-i-set-the-aspect-ratio-in-matplotlib","A_Votes":"57","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to make a square plot (using imshow), i.e. aspect ratio of 1:1, but I can't. None of these work:  import matplotlib.pyplot as plt  ax = fig.add_subplot(111,aspect='equal') ax = fig.add_subplot(111,aspect=1.0) ax.set_aspect('equal') plt.axes().set_aspect('equal')   It seems like the calls are just being ignored (a problem I often seem to have with matplotlib).     ","Q_Votes":"78"},{"Q_Title":"How can I set the aspect ratio in matplotlib?","A_Content":"  What is the matplotlib version you are running? I have recently had to upgrade to 1.1.0, and with it, add_subplot(111,aspect='equal') works for me.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/7965743/how-can-i-set-the-aspect-ratio-in-matplotlib","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a square plot (using imshow), i.e. aspect ratio of 1:1, but I can't. None of these work:  import matplotlib.pyplot as plt  ax = fig.add_subplot(111,aspect='equal') ax = fig.add_subplot(111,aspect=1.0) ax.set_aspect('equal') plt.axes().set_aspect('equal')   It seems like the calls are just being ignored (a problem I often seem to have with matplotlib).     ","Q_Votes":"78"},{"Q_Title":"How can I set the aspect ratio in matplotlib?","A_Content":"  you should try with figaspect. It works for me. From the docs:     Create a figure with specified aspect ratio.  If arg is a number, use that aspect ratio.  > If arg is an array, figaspect will   determine the width and height for a figure that would fit array   preserving aspect ratio.  The figure width, height in inches are   returned.  Be sure to create an axes with equal with and height, eg      Example usage:     # make a figure twice as tall as it is wide   w, h = figaspect(2.)   fig = Figure(figsize=(w,h))   ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])   ax.imshow(A, **kwargs)    # make a figure with the proper aspect for an array   A = rand(5,3)   w, h = figaspect(A)   fig = Figure(figsize=(w,h))   ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])   ax.imshow(A, **kwargs)   Edit: I am not sure of what you are looking for. The above code changes the canvas (the plot size). If you want to change the size of the matplotlib window, of the figure, then use:   In [68]: f = figure(figsize=(5,1))   this does produce a window of 5x1 (wxh).     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/7965743/how-can-i-set-the-aspect-ratio-in-matplotlib","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a square plot (using imshow), i.e. aspect ratio of 1:1, but I can't. None of these work:  import matplotlib.pyplot as plt  ax = fig.add_subplot(111,aspect='equal') ax = fig.add_subplot(111,aspect=1.0) ax.set_aspect('equal') plt.axes().set_aspect('equal')   It seems like the calls are just being ignored (a problem I often seem to have with matplotlib).     ","Q_Votes":"78"},{"Q_Title":"How can I set the aspect ratio in matplotlib?","A_Content":"  This answer is based on  Yann's answer.  It will set the aspect ratio for linear or log-log plots.  I've used additional information from https://stackoverflow.com/a/16290035/2966723 to test if the axes are log-scale.  def forceAspect(ax,aspect=1):     #aspect is width/height     scale_str = ax.get_yaxis().get_scale()     xmin,xmax = ax.get_xlim()     ymin,ymax = ax.get_ylim()     if scale_str=='linear':         asp = abs((xmax-xmin)/(ymax-ymin))/aspect     elif scale_str=='log':         asp = abs((scipy.log(xmax)-scipy.log(xmin))/(scipy.log(ymax)-scipy.log(ymin)))/aspect     ax.set_aspect(asp)   Obviously you can use any version of log you want, I've used scipy, but numpy or math should be fine.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/7965743/how-can-i-set-the-aspect-ratio-in-matplotlib","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to make a square plot (using imshow), i.e. aspect ratio of 1:1, but I can't. None of these work:  import matplotlib.pyplot as plt  ax = fig.add_subplot(111,aspect='equal') ax = fig.add_subplot(111,aspect=1.0) ax.set_aspect('equal') plt.axes().set_aspect('equal')   It seems like the calls are just being ignored (a problem I often seem to have with matplotlib).     ","Q_Votes":"78"},{"Q_Title":"Shared-memory objects in multiprocessing","A_Content":"  If you use an operating system that uses copy-on-write fork() semantics (like any common unix), then as long as you never alter your data structure it will be available to all child processes without taking up additional memory.  You will not have to do anything special (except make absolutely sure you don't alter the object).  The most efficient thing you can do for your problem would be to pack your array into an efficient array structure (using numpy or array), place that in shared memory, wrap it with multiprocessing.Array, and pass that to your functions. This answer shows how to do that.  If you want a writeable shared object, then you will need to wrap it with some kind of synchronization or locking. multiprocessing provides two methods of doing this: one using shared memory (suitable for simple values, arrays, or ctypes) or a Manager proxy, where one process holds the memory and a manager arbitrates access to it from other processes (even over a network).  The Manager approach can be used with arbitrary Python objects, but will be slower than the equivalent using shared memory because the objects need to be serialized/deserialized and sent between processes.  There are a wealth of parallel processing libraries and approaches available in Python. multiprocessing is an excellent and well rounded library, but if you have special needs perhaps one of the other approaches may be better.     ","Language":"Python","Tags":["python","numpy","parallel-processing","multiprocessing","shared-memory"],"URL":"https://stackoverflow.com/questions/10721915/shared-memory-objects-in-multiprocessing","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    Suppose I have a large in memory numpy array, I have a function func that takes in this giant array as input (together with some other parameters). func with different parameters can be run in parallel. For example:  def func(arr, param):     # do stuff to arr, param  # build array arr  pool = Pool(processes = 6) results = [pool.apply_async(func, [arr, param]) for param in all_params] output = [res.get() for res in results]   If I use multiprocessing library, then that giant array will be copied for multiple times into different processes.   Is there a way to let different processes share the same array? This array object is read-only and will never be modified.   What's more complicated, if arr is not an array, but an arbitrary python object, is there a way to share it?   [EDITED]  I read the answer but I am still a bit confused. Since fork() is copy-on-write, we should not invoke any additional cost when spawning new processes in python multiprocessing library. But the following code suggests there is a huge overhead:   from multiprocessing import Pool, Manager import numpy as np;  import time  def f(arr):     return len(arr)  t = time.time() arr = np.arange(10000000) print \"construct array = \", time.time() - t;   pool = Pool(processes = 6)  t = time.time() res = pool.apply_async(f, [arr,]) res.get() print \"multiprocessing overhead = \", time.time() - t;   output (and by the way, the cost increases as the size of the array increases, so I suspect there is still overhead related to memory copying):   construct array =  0.0178790092468 multiprocessing overhead =  0.252444982529   Why is there such huge overhead, if we didn't copy the array? And what part does the shared memory save me?      ","Q_Votes":"78"},{"Q_Title":"Shared-memory objects in multiprocessing","A_Content":"  I run into the same problem and wrote a little shared-memory utility class to work around it.  I'm using multiprocessing.RawArray (lockfree), and also the access to the arrays is not synchronized at all (lockfree), be careful not to shoot your own feet.  With the solution I get speedups by a factor of approx 3 on a quad-core i7.  Here's the code: Feel free to use and improve it, and please report back any bugs.  ''' Created on 14.05.2013  @author: martin '''  import multiprocessing import ctypes import numpy as np  class SharedNumpyMemManagerError(Exception):     pass  ''' Singleton Pattern ''' class SharedNumpyMemManager:          _initSize = 1024      _instance = None      def __new__(cls, *args, **kwargs):         if not cls._instance:             cls._instance = super(SharedNumpyMemManager, cls).__new__(                                 cls, *args, **kwargs)         return cls._instance              def __init__(self):         self.lock = multiprocessing.Lock()         self.cur = 0         self.cnt = 0         self.shared_arrays = [None] * SharedNumpyMemManager._initSize      def __createArray(self, dimensions, ctype=ctypes.c_double):          self.lock.acquire()          # double size if necessary         if (self.cnt >= len(self.shared_arrays)):             self.shared_arrays = self.shared_arrays + [None] * len(self.shared_arrays)          # next handle         self.__getNextFreeHdl()                  # create array in shared memory segment         shared_array_base = multiprocessing.RawArray(ctype, np.prod(dimensions))          # convert to numpy array vie ctypeslib         self.shared_arrays[self.cur] = np.ctypeslib.as_array(shared_array_base)          # do a reshape for correct dimensions                     # Returns a masked array containing the same data, but with a new shape.         # The result is a view on the original array         self.shared_arrays[self.cur] = self.shared_arrays[self.cnt].reshape(dimensions)          # update cnt         self.cnt += 1          self.lock.release()          # return handle to the shared memory numpy array         return self.cur      def __getNextFreeHdl(self):         orgCur = self.cur         while self.shared_arrays[self.cur] is not None:             self.cur = (self.cur + 1) % len(self.shared_arrays)             if orgCur == self.cur:                 raise SharedNumpyMemManagerError('Max Number of Shared Numpy Arrays Exceeded!')      def __freeArray(self, hdl):         self.lock.acquire()         # set reference to None         if self.shared_arrays[hdl] is not None: # consider multiple calls to free             self.shared_arrays[hdl] = None             self.cnt -= 1         self.lock.release()      def __getArray(self, i):         return self.shared_arrays[i]      @staticmethod     def getInstance():         if not SharedNumpyMemManager._instance:             SharedNumpyMemManager._instance = SharedNumpyMemManager()         return SharedNumpyMemManager._instance      @staticmethod     def createArray(*args, **kwargs):         return SharedNumpyMemManager.getInstance().__createArray(*args, **kwargs)      @staticmethod     def getArray(*args, **kwargs):         return SharedNumpyMemManager.getInstance().__getArray(*args, **kwargs)      @staticmethod         def freeArray(*args, **kwargs):         return SharedNumpyMemManager.getInstance().__freeArray(*args, **kwargs)  # Init Singleton on module load SharedNumpyMemManager.getInstance()  if __name__ == '__main__':      import timeit      N_PROC = 8     INNER_LOOP = 10000     N = 1000      def propagate(t):         i, shm_hdl, evidence = t         a = SharedNumpyMemManager.getArray(shm_hdl)         for j in range(INNER_LOOP):             a[i] = i      class Parallel_Dummy_PF:          def __init__(self, N):             self.N = N             self.arrayHdl = SharedNumpyMemManager.createArray(self.N, ctype=ctypes.c_double)                         self.pool = multiprocessing.Pool(processes=N_PROC)          def update_par(self, evidence):             self.pool.map(propagate, zip(range(self.N), [self.arrayHdl] * self.N, [evidence] * self.N))          def update_seq(self, evidence):             for i in range(self.N):                 propagate((i, self.arrayHdl, evidence))          def getArray(self):             return SharedNumpyMemManager.getArray(self.arrayHdl)      def parallelExec():         pf = Parallel_Dummy_PF(N)         print(pf.getArray())         pf.update_par(5)         print(pf.getArray())      def sequentialExec():         pf = Parallel_Dummy_PF(N)         print(pf.getArray())         pf.update_seq(5)         print(pf.getArray())      t1 = timeit.Timer(\"sequentialExec()\", \"from __main__ import sequentialExec\")     t2 = timeit.Timer(\"parallelExec()\", \"from __main__ import parallelExec\")      print(\"Sequential: \", t1.timeit(number=1))         print(\"Parallel: \", t2.timeit(number=1))      ","Language":"Python","Tags":["python","numpy","parallel-processing","multiprocessing","shared-memory"],"URL":"https://stackoverflow.com/questions/10721915/shared-memory-objects-in-multiprocessing","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    Suppose I have a large in memory numpy array, I have a function func that takes in this giant array as input (together with some other parameters). func with different parameters can be run in parallel. For example:  def func(arr, param):     # do stuff to arr, param  # build array arr  pool = Pool(processes = 6) results = [pool.apply_async(func, [arr, param]) for param in all_params] output = [res.get() for res in results]   If I use multiprocessing library, then that giant array will be copied for multiple times into different processes.   Is there a way to let different processes share the same array? This array object is read-only and will never be modified.   What's more complicated, if arr is not an array, but an arbitrary python object, is there a way to share it?   [EDITED]  I read the answer but I am still a bit confused. Since fork() is copy-on-write, we should not invoke any additional cost when spawning new processes in python multiprocessing library. But the following code suggests there is a huge overhead:   from multiprocessing import Pool, Manager import numpy as np;  import time  def f(arr):     return len(arr)  t = time.time() arr = np.arange(10000000) print \"construct array = \", time.time() - t;   pool = Pool(processes = 6)  t = time.time() res = pool.apply_async(f, [arr,]) res.get() print \"multiprocessing overhead = \", time.time() - t;   output (and by the way, the cost increases as the size of the array increases, so I suspect there is still overhead related to memory copying):   construct array =  0.0178790092468 multiprocessing overhead =  0.252444982529   Why is there such huge overhead, if we didn't copy the array? And what part does the shared memory save me?      ","Q_Votes":"78"},{"Q_Title":"ropemacs USAGE tutorial","A_Content":"  Well, you first need to select your project root folder. Quite simply, this is the folder at the top level of your project, or the current folder if you're dealing with a single file. Once you've selected the root folder, then other options will work, such as code assist, showing documentation, jumping to other symbols, etc.  For full benefit of ropemacs, I suggest getting autocomplete.el, putting it in ~/.emacs.d, and then adding this to your .emacs  (add-to-list 'load-path \"~/.emacs.d/\") (add-to-list 'load-path \"~/.emacs.d/auto-complete-1.2\") (autoload 'python-mode \"python-mode\" \"Python Mode.\" t) (add-to-list 'auto-mode-alist '(\"\\\\.py\\\\'\" . python-mode)) (add-to-list 'interpreter-mode-alist '(\"python\" . python-mode)) (require 'python-mode) (autoload 'pymacs-apply \"pymacs\") (autoload 'pymacs-call \"pymacs\") (autoload 'pymacs-eval \"pymacs\" nil t) (autoload 'pymacs-exec \"pymacs\" nil t) (autoload 'pymacs-load \"pymacs\" nil t) (pymacs-load \"ropemacs\" \"rope-\") (setq ropemacs-enable-autoimport t)  (require 'auto-complete) (global-auto-complete-mode t)   This assumes you install autocomplete in ~/.emacs.d/auto-complete-1.2. After you do this, you will get autocomplete automatically after typing a few characters of a word or symbol.  You can modify your ROOT/.ropeproject/config.py file to add more directories to the rope lookup path, in order to provide better autocomplete.  EDIT: Two of the most important functions for me are looking up documentation and jumping directly to a function definition. This is dependent on setting the rope lookup path correctly for your project as mentioned above.  Documentation: Put the cursor over a symbol (function name, class name, etc), and do:  C-c d   This will show you the docstring for the symbol in question.  Jumping to definition:Put the cursor over a symbol (function name, class name, etc), and do:  C-c g   This will immediately open the file where the symbol resides and jump to the beginning of the definition. This is great for times when the documentation is sparse and you want to see the actual code. Also, it's really nice for navigating around inside your own code.  Find occurrences:  C-c f   Smart search in your entire project for the symbol at the cursor.  Code assist:  M-/   Just type the first characters of a function, class, etc, and this will show a list of possible completions. Note that due to python's nature, it will not always be a complete list.  Refactorings: There are quite a few options under Rope->Refactor. These are to organize your code better. How to use them should be mostly self-explanatory; in general, select the region of code you want to refactor, then choose the command.  Edit: In response to a comment below, here's exactly how to add other paths to your python path so autocomplete will look for those symbols as well.  prefs.add('python_path', '~/path/to/virtualenv/lib/python2.6/site-packages')   This goes in .ropeproject/config.py     ","Language":"Python","Tags":["python","emacs","ide","autocomplete"],"URL":"https://stackoverflow.com/questions/2855378/ropemacs-usage-tutorial","A_Votes":"63","_type":"dict","isAccepted":"Yes","Q_Content":"    There are many sites with instructions on installing ropemacs, but so far I couldn't find any with instructions on how to use it after it's already installed. I have it installed, or at least it seems so, Emacs has \"Rope\" menu in it's top menu bar. Now what? So far I could use only \"Show documentation\" (C-c d by default). An attempt to use code assist (which is auto-complete, I presume?) only causes Emacs to ask about \"Rope project root folder\" (what's that?) in the minibuffer and then showing nothing.  So, once ropemacs is installed, what are the steps to see it in action on some simple python scripts? Something like \"if you have this script in your emacs and put the blinking square here and press this, it does that\" would be an answer.  (I've been thinking if I should ask this or not for some time, because nobody else seems to have the same problem)     ","Q_Votes":"78"},{"Q_Title":"ropemacs USAGE tutorial","A_Content":"  The best usage information I've found is a readme in the ropemacs source, here:  https://github.com/python-rope/ropemacs     ","Language":"Python","Tags":["python","emacs","ide","autocomplete"],"URL":"https://stackoverflow.com/questions/2855378/ropemacs-usage-tutorial","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    There are many sites with instructions on installing ropemacs, but so far I couldn't find any with instructions on how to use it after it's already installed. I have it installed, or at least it seems so, Emacs has \"Rope\" menu in it's top menu bar. Now what? So far I could use only \"Show documentation\" (C-c d by default). An attempt to use code assist (which is auto-complete, I presume?) only causes Emacs to ask about \"Rope project root folder\" (what's that?) in the minibuffer and then showing nothing.  So, once ropemacs is installed, what are the steps to see it in action on some simple python scripts? Something like \"if you have this script in your emacs and put the blinking square here and press this, it does that\" would be an answer.  (I've been thinking if I should ask this or not for some time, because nobody else seems to have the same problem)     ","Q_Votes":"78"},{"Q_Title":"ropemacs USAGE tutorial","A_Content":"  You can set the root folder with rope-open-project . Once you've set the root project a .ropeproject dir will be created.   Inside it, a config.py file has hooks where you can run (python) code once the project is set. The project_opened(project): function is a good place to run code. I usually activate the virtual environment imp.load_source('/path-to-env/activate_this.py') , so that I can get source coverage for other libs in the virtual env.     ","Language":"Python","Tags":["python","emacs","ide","autocomplete"],"URL":"https://stackoverflow.com/questions/2855378/ropemacs-usage-tutorial","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    There are many sites with instructions on installing ropemacs, but so far I couldn't find any with instructions on how to use it after it's already installed. I have it installed, or at least it seems so, Emacs has \"Rope\" menu in it's top menu bar. Now what? So far I could use only \"Show documentation\" (C-c d by default). An attempt to use code assist (which is auto-complete, I presume?) only causes Emacs to ask about \"Rope project root folder\" (what's that?) in the minibuffer and then showing nothing.  So, once ropemacs is installed, what are the steps to see it in action on some simple python scripts? Something like \"if you have this script in your emacs and put the blinking square here and press this, it does that\" would be an answer.  (I've been thinking if I should ask this or not for some time, because nobody else seems to have the same problem)     ","Q_Votes":"78"},{"Q_Title":"ropemacs USAGE tutorial","A_Content":"  For general usage of the rope library that ropemacs depends on, then check out:     Rope Overview   It describes in some detail what each of the refactorings does such as extract method.  Note that according to the author this doc is a bit outdated. However, it should provide enough of an intro to ropes' features to get started.  To execute the ropemacs commands in Emacs, you can try one or more of the following:   Use the 'Keybinding' section in the README docs link from freyley's answer as a guide to learn the the mappings.  If you can't remember the keybindings, then execute M-x rope-<specific command name> and fill in the related refactoring name. For example, extract method   would be M-x rope-extract-method. Select in Emacs <menu-bar> -> Rope.  For example, for extract method then select <menu-bar> -> Rope -> Refactorings -> Extract Method.  It will also show you the associated keybindings (e.g. C-c r m)      ","Language":"Python","Tags":["python","emacs","ide","autocomplete"],"URL":"https://stackoverflow.com/questions/2855378/ropemacs-usage-tutorial","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    There are many sites with instructions on installing ropemacs, but so far I couldn't find any with instructions on how to use it after it's already installed. I have it installed, or at least it seems so, Emacs has \"Rope\" menu in it's top menu bar. Now what? So far I could use only \"Show documentation\" (C-c d by default). An attempt to use code assist (which is auto-complete, I presume?) only causes Emacs to ask about \"Rope project root folder\" (what's that?) in the minibuffer and then showing nothing.  So, once ropemacs is installed, what are the steps to see it in action on some simple python scripts? Something like \"if you have this script in your emacs and put the blinking square here and press this, it does that\" would be an answer.  (I've been thinking if I should ask this or not for some time, because nobody else seems to have the same problem)     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  Here's an idea... Expire the session on browser close with the SESSION_EXPIRE_AT_BROWSER_CLOSE setting. Then set a timestamp in the session on every request like so.  request.session['last_activity'] = datetime.now()   and add a middleware to detect if the session is expired. something like this should handle the whole process...  from datetime import datetime from django.http import HttpResponseRedirect  class SessionExpiredMiddleware:     def process_request(request):         last_activity = request.session['last_activity']         now = datetime.now()          if (now - last_activity).minutes > 10:             # Do logout / expire session             # and then...             return HttpResponseRedirect(\"LOGIN_PAGE_URL\")          if not request.is_ajax():             # don't set this for ajax requests or else your             # expired session checks will keep the session from             # expiring :)             request.session['last_activity'] = now   Then you just have to make some urls and views to return relevant data to the ajax calls regarding the session expiry.  when the user opts to \"renew\" the session, so to speak, all you have to do is set requeset.session['last_activity'] to the current time again  Obviously this code is only a start... but it should get you on the right path     ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  django-session-security does just that...  ... with an additional requirement: if the server doesn't respond or an attacker disconnected the internet connection: it should expire anyway.  Disclamer: I maintain this app. But I've been watching this thread for a very, very long time :)     ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  I am just pretty new to use Django.  I wanted to make session expire if logged user close browser or are in idle(inactivity timeout) for some amount of time. When I googled it to figure out, this SOF question came up first. Thanks to nice answer, I looked up resources to understand how middlewares works during request/response cycle in Django. It was very helpful.  I was about to apply custom middleware into my code following top answer in here. But I was still little bit suspicious because best answer in here was edited in 2011. I took more time to search little bit from recent search result and came up with simple way.  SESSION_EXPIRE_AT_BROWSER_CLOSE = True SESSION_COOKIE_AGE = 10 # set just 10 seconds to test SESSION_SAVE_EVERY_REQUEST = True   I didn't check other browsers but chrome. 1. A session expired when I closed a browser even if SESSION_COOKIE_AGE set. 2. Only when I was idle for more than 10 seconds, A session expired. Thanks to SESSION_SAVE_EVERY_REQUEST, whenever you occur new request, It saves the session and updates timeout to expire  To change this default behavior, set the SESSION_SAVE_EVERY_REQUEST setting to True. When set to True, Django will save the session to the database on every single request.  Note that the session cookie is only sent when a session has been created or modified. If SESSION_SAVE_EVERY_REQUEST is True, the session cookie will be sent on every request.  Similarly, the expires part of a session cookie is updated each time the session cookie is sent.  django manual 1.10  I just leave answer so that some people who is a kind of new in Django like me don't spend much time to find out solution as a way I did.      ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  One easy way to satisfy your second requirement would be to set SESSION_COOKIE_AGE value in settings.py to a suitable amount of seconds. For instance:  SESSION_COOKIE_AGE = 600      #10 minutes.   However, by only doing this the session will expire after 10 minutes whether or not the user exhibits some activity. To deal with this issue, expiration time can be automatically renewed (for another extra 10 minutes) every time the user performs any kind of request with the following sentence:  request.session.set_expiry(request.session.get_expiry_age())      ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  also you can use  stackoverflow build in functions  SESSION_SAVE_EVERY_REQUEST = True      ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"How to expire session due to inactivity in Django?","A_Content":"  In the first request, you can set the session expiry as  self.request.session['access_key'] = access_key self.request.session['access_token'] = access_token self.request.session.set_expiry(set_age) #in seconds    And when using the access_key and token,  try:     key = self.request.session['access_key'] except KeyError:     age = self.request.session.get_expiry_age()     if age > set_age:         #redirect to login page      ","Language":"Python","Tags":["python","django","session","cookies"],"URL":"https://stackoverflow.com/questions/3024153/how-to-expire-session-due-to-inactivity-in-django","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Our Django application has the following session management requirements.   Sessions expire when the user closes the browser. Sessions expire after a period of inactivity. Detect when a session expires due to inactivity and display appropriate message to the user. Warn users of a impending session expiry a few minutes before the end of the inactivity period. Along with the warning, provide users an option to extend their session. If user is working on a long business activity within the app that doesn't involve requests being sent to the server, the session must not timeout.   After reading the documentation, Django code and some blog posts related to this, I have come up with the following implementation approach.  Requirement 1 This requirement is easily implemented by setting SESSION_EXPIRE_AT_BROWSER_CLOSE to True.  Requirement 2 I have seen a few recommendations to use SESSION_COOKIE_AGE to set the session expiry period. But this method has the following problems.   The session always expires at the end of the SESSION_COOKIE_AGE even if the user is actively using the application. (This can be prevented by setting the session expiry to SESSION_COOKIE_AGE on every request using a custom middleware or by saving the session on every request by setting SESSION_SAVE_EVERY_REQUEST to true. But the next problem is unavoidable due to the use of SESSION_COOKIE_AGE.) Due to the way cookies work, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE are mutually exclusive i.e. the cookie either expires on browser close or at the specified expiry time. If SESSION_COOKIE_AGE is used and the user closes the browser before the cookie expires, the cookie is retained and reopening the browser will allow the user (or anyone else) into the system without being re-authenticated. Django relies only on the cookie being present to determine if the session is active. It doesn't check the session expiry date stored with the session.   The following method could be used to implemented this requirement and to workaround the problems mentioned above.   Do not set SESSION_COOKIE_AGE. Set the expiry date of the session to be 'current time + inactivity period' on every request. Override process_request in SessionMiddleware and check for session expiry. Discard the session if it has expired.   Requirement 3 When we detect that the session has expired (in the custom SessionMiddleware above), set an attribute on the request to indicate session expiry. This attribute can be used to display an appropriate message to the user.  Requirement 4 Use JavaScript to detect user inactivity, provide the warning and also an option to extend the session. If the user wishes to extend, send a keep alive pulse to the server to extend the session.  Requirement 5 Use JavaScript to detect user activity (during the long business operation) and send keep alive pulses to the server to prevent session from expiring.    The above implementation approach seem very elaborate and I was wondering if there might a simpler method (especially for Requirement 2).   Any insights will be highly appreciated.     ","Q_Votes":"78"},{"Q_Title":"Is there a recommended format for multi-line imports?","A_Content":"  Personally I go with parentheses when importing more than one component and sort them alphabetically. Like so:  from Tkinter import (     Button,     Canvas,     DISABLED,     END,     Entry,     Frame,     LEFT,     NORMAL,     RIDGE,     Text,     Tk, )   This has the added advantage of easily seeing what components have been added / removed in each commit or PR.  Overall though it's a personal preference and I would advise you to go with whatever looks best to you.     ","Language":"Python","Tags":["python","python-2.7","pep8"],"URL":"https://stackoverflow.com/questions/14376900/is-there-a-recommended-format-for-multi-line-imports","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    I have read there are three ways for coding multi-line imports in python  With slashes:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text, \\     LEFT, DISABLED, NORMAL, RIDGE, END   Duplicating senteces:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text from Tkinter import LEFT, DISABLED, NORMAL, RIDGE, END   With parenthesis:  from Tkinter import (Tk, Frame, Button, Entry, Canvas, Text,     LEFT, DISABLED, NORMAL, RIDGE, END)   Is there a recomended format or a more elegant way for this statements?     ","Q_Votes":"78"},{"Q_Title":"Is there a recommended format for multi-line imports?","A_Content":"  Your examples seem to stem from PEP 328. There, the parenthesis-notation is proposed for exactly this problem, so probably I'd choose this one.     ","Language":"Python","Tags":["python","python-2.7","pep8"],"URL":"https://stackoverflow.com/questions/14376900/is-there-a-recommended-format-for-multi-line-imports","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I have read there are three ways for coding multi-line imports in python  With slashes:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text, \\     LEFT, DISABLED, NORMAL, RIDGE, END   Duplicating senteces:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text from Tkinter import LEFT, DISABLED, NORMAL, RIDGE, END   With parenthesis:  from Tkinter import (Tk, Frame, Button, Entry, Canvas, Text,     LEFT, DISABLED, NORMAL, RIDGE, END)   Is there a recomended format or a more elegant way for this statements?     ","Q_Votes":"78"},{"Q_Title":"Is there a recommended format for multi-line imports?","A_Content":"  I would go with the parenthesis notation from the PEP328 with newlines added before and after parentheses:  from Tkinter import (     Tk, Frame, Button, Entry, Canvas, Text,      LEFT, DISABLED, NORMAL, RIDGE, END )   This is the format which Django uses:  from django.test.client import Client, RequestFactory from django.test.testcases import (     LiveServerTestCase, SimpleTestCase, TestCase, TransactionTestCase,     skipIfDBFeature, skipUnlessAnyDBFeature, skipUnlessDBFeature, ) from django.test.utils import (     ignore_warnings, modify_settings, override_settings,     override_system_checks, tag, )      ","Language":"Python","Tags":["python","python-2.7","pep8"],"URL":"https://stackoverflow.com/questions/14376900/is-there-a-recommended-format-for-multi-line-imports","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have read there are three ways for coding multi-line imports in python  With slashes:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text, \\     LEFT, DISABLED, NORMAL, RIDGE, END   Duplicating senteces:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text from Tkinter import LEFT, DISABLED, NORMAL, RIDGE, END   With parenthesis:  from Tkinter import (Tk, Frame, Button, Entry, Canvas, Text,     LEFT, DISABLED, NORMAL, RIDGE, END)   Is there a recomended format or a more elegant way for this statements?     ","Q_Votes":"78"},{"Q_Title":"Is there a recommended format for multi-line imports?","A_Content":"  Usually with Tkinter, it is okay to just use from Tkinter import * as the module will only export names that are clearly widgets.  PEP 8 does not list any conventions for such a case, so I guess it is up to you to decide what is the best option. It is all about readability, so choose whatever makes it clear that you are importing stuff from a single module.  As all those names are made available in your scope, I personally think that options 2 is the most clearest as you can see the imported names the best. You then could even split it up more to maybe group those names together that belong with each other. In your example I might put Tk, Frame and Canvas separately as they group widgets together, while having Button and Text separately as they are smaller components in a view.     ","Language":"Python","Tags":["python","python-2.7","pep8"],"URL":"https://stackoverflow.com/questions/14376900/is-there-a-recommended-format-for-multi-line-imports","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I have read there are three ways for coding multi-line imports in python  With slashes:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text, \\     LEFT, DISABLED, NORMAL, RIDGE, END   Duplicating senteces:  from Tkinter import Tk, Frame, Button, Entry, Canvas, Text from Tkinter import LEFT, DISABLED, NORMAL, RIDGE, END   With parenthesis:  from Tkinter import (Tk, Frame, Button, Entry, Canvas, Text,     LEFT, DISABLED, NORMAL, RIDGE, END)   Is there a recomended format or a more elegant way for this statements?     ","Q_Votes":"78"},{"Q_Title":"Pandas: create two new columns in a dataframe with values calculated from a pre-existing column","A_Content":"  I'd just use zip:  In [1]: from pandas import *  In [2]: def calculate(x):    ...:     return x*2, x*3    ...:   In [3]: df = DataFrame({'a': [1,2,3], 'b': [2,3,4]})  In [4]: df Out[4]:     a  b 0  1  2 1  2  3 2  3  4  In [5]: df[\"A1\"], df[\"A2\"] = zip(*df[\"a\"].map(calculate))  In [6]: df Out[6]:     a  b  A1  A2 0  1  2   2   3 1  2  3   4   6 2  3  4   6   9      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/12356501/pandas-create-two-new-columns-in-a-dataframe-with-values-calculated-from-a-pre","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    I am working with the pandas library and I want to add two new columns to a dataframe df with n columns (n > 0). These new columns result from the application of a function to one of the columns in the dataframe.  The function to apply is like:  def calculate(x):     ...operate...     return z, y   One method for creating a new column for a function returning only a value is:  df['new_col']) = df['column_A'].map(a_function)   So, what I want, and tried unsuccesfully (*), is something like:  (df['new_col_zetas'], df['new_col_ys']) = df['column_A'].map(calculate)   What the best way to accomplish this could be ? I scanned the documentation with no clue.   **df['column_A'].map(calculate) returns a pandas Series each item consisting of a tuple z, y. And trying to assign this to two dataframe columns produces a ValueError.*      ","Q_Votes":"78"},{"Q_Title":"Pandas: create two new columns in a dataframe with values calculated from a pre-existing column","A_Content":"  The top answer is flawed in my opinion. Hopefully, no one is mass importing all of pandas into their namespace with from pandas import *. Also, the map method should be reserved for those times when passing it a dictionary or Series. It can take a function but this is what apply is used for.  So, if you must use the above approach, I would write it like this  df[\"A1\"], df[\"A2\"] = zip(*df[\"a\"].apply(calculate))   There's actually no reason to use zip here. You can simply do this:  df[\"A1\"], df[\"A2\"] = calculate(df['a'])   This second method is also much faster on larger DataFrames  df = pd.DataFrame({'a': [1,2,3] * 100000, 'b': [2,3,4] * 100000})   DataFrame created with 300,000 rows  %timeit df[\"A1\"], df[\"A2\"] = calculate(df['a']) 2.65 ms  92.4 s per loop (mean  std. dev. of 7 runs, 100 loops each)  %timeit df[\"A1\"], df[\"A2\"] = zip(*df[\"a\"].apply(calculate)) 159 ms  5.24 ms per loop (mean  std. dev. of 7 runs, 10 loops each)   60x faster than zip    In general, avoid using apply  Apply is generally not much faster than iterating over a Python list. Let's test the performance of a for-loop to do the same thing as above  %%timeit A1, A2 = [], [] for val in df['a']:     A1.append(val**2)     A2.append(val**3)  df['A1'] = A1 df['A2'] = A2  298 ms  7.14 ms per loop (mean  std. dev. of 7 runs, 1 loop each)   So this is twice as slow which isn't a terrible performance regression, but if we cythonize the above, we get much better performance. Assuming, you are using ipython:  %load_ext cython  %%cython cpdef power(vals):     A1, A2 = [], []     cdef double val     for val in vals:         A1.append(val**2)         A2.append(val**3)      return A1, A2  %timeit df['A1'], df['A2'] = power(df['a']) 72.7 ms  2.16 ms per loop (mean  std. dev. of 7 runs, 10 loops each)     Directly assigning without apply  You can get even greater speed improvements if you use the direct vectorized operations.  %timeit df['A1'], df['A2'] = df['a'] ** 2, df['a'] ** 3 5.13 ms  320 s per loop (mean  std. dev. of 7 runs, 100 loops each)   This takes advantage of NumPy's extremely fast vectorized operations instead of our loops. We now have a 30x speedup over the original.    The simplest speed test with apply  The above example should clearly show how slow apply can be, but just so its extra clear let's look at the most basic example. Let's square a Series of 10 million numbers with and without apply  s = pd.Series(np.random.rand(10000000))  %timeit s.apply(calc) 3.3 s  57.4 ms per loop (mean  std. dev. of 7 runs, 1 loop each)   Without apply is 50x faster  %timeit s ** 2 66 ms  2 ms per loop (mean  std. dev. of 7 runs, 10 loops each)      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/12356501/pandas-create-two-new-columns-in-a-dataframe-with-values-calculated-from-a-pre","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I am working with the pandas library and I want to add two new columns to a dataframe df with n columns (n > 0). These new columns result from the application of a function to one of the columns in the dataframe.  The function to apply is like:  def calculate(x):     ...operate...     return z, y   One method for creating a new column for a function returning only a value is:  df['new_col']) = df['column_A'].map(a_function)   So, what I want, and tried unsuccesfully (*), is something like:  (df['new_col_zetas'], df['new_col_ys']) = df['column_A'].map(calculate)   What the best way to accomplish this could be ? I scanned the documentation with no clue.   **df['column_A'].map(calculate) returns a pandas Series each item consisting of a tuple z, y. And trying to assign this to two dataframe columns produces a ValueError.*      ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  There is no one-to-one correlation.  For a really good article please see Efficient String Concatenation in Python:     Building long strings in the Python   progamming language can sometimes   result in very slow running code. In   this article I investigate the   computational performance of various   string concatenation methods.      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"68","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  I have used the code of Oliver Crow (link given by Andrew Hare) and adapted it a bit to tailor Python 2.7.3. (by using timeit package). I ran on my personal computer, Lenovo T61, 6GB RAM, Debian GNU/Linux 6.0.6 (squeeze).   Here is the result for 10,000 iterations:   method1:  0.0538418292999 secs process size 4800 kb method2:  0.22602891922 secs process size 4960 kb method3:  0.0605459213257 secs process size 4980 kb method4:  0.0544030666351 secs process size 5536 kb method5:  0.0551080703735 secs process size 5272 kb method6:  0.0542731285095 secs process size 5512 kb   and for 5,000,000 iterations (method 2 was ignored because it ran tooo slowly, like forever):   method1:  5.88603997231 secs process size 37976 kb method3:  8.40748500824 secs process size 38024 kb method4:  7.96380496025 secs process size 321968 kb method5:  8.03666186333 secs process size 71720 kb method6:  6.68192911148 secs process size 38240 kb   It is quite obvious that Python guys have done pretty great job to optimize string concatenation, and as Hoare said: \"premature optimization is the root of all evil\" :-)     ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  Python has several things that fulfill similar purposes:    One common way to build large strings from pieces is to grow a list of strings and join it when you are done. This is a frequently-used Python idiom.   To build strings incorporating data with formatting, you would do the formatting separately.   For insertion and deletion at a character level, you would keep a list of length-one strings. (To make this from a string, you'd call list(your_string). You could also use a UserString.MutableString for this. (c)StringIO.StringIO is useful for things that would otherwise take a file, but less so for general string building.      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  Using method 5 from above (The Pseudo File) we can get very good perf and flexibility  from cStringIO import StringIO  class StringBuilder:      _file_str = None       def __init__(self):          self._file_str = StringIO()       def Append(self, str):          self._file_str.write(str)       def __str__(self):          return self._file_str.getvalue()   now using it   sb = StringBuilder()  sb.Append(\"Hello\\n\") sb.Append(\"World\")  print sb      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  Relying on compiler optimizations is fragile. The benchmarks linked in the accepted answer and numbers given by Antoine-tran are not to be trusted. Andrew Hare makes the mistake of including a call to repr in his methods. That slows all the methods equally but obscures the real penalty in constructing the string.  Use join. It's very fast and more robust.  $ ipython3 Python 3.5.1 (default, Mar  2 2016, 03:38:02)  IPython 4.1.2 -- An enhanced Interactive Python.  In [1]: values = [str(num) for num in range(int(1e3))]  In [2]: %%timeit    ...: ''.join(values)    ...:  100000 loops, best of 3: 7.37 s per loop  In [3]: %%timeit    ...: result = ''    ...: for value in values:    ...:     result += value    ...:  10000 loops, best of 3: 82.8 s per loop  In [4]: import io  In [5]: %%timeit    ...: writer = io.StringIO()    ...: for value in values:    ...:     writer.write(value)    ...: writer.getvalue()    ...:  10000 loops, best of 3: 81.8 s per loop      ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  you can try StringIO or cStringIO     ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  There is no explicit analogue - i think you are expected to use string concatenations(likely optimized as said before) or third-party class(i doubt that they are a lot more efficient - lists in python are dynamic-typed so no fast-working char[] for buffer as i assume).  Stringbuilder-like classes are not premature optimization because of innate feature of strings in many languages(immutability) - that allows many optimizations(for example, referencing same buffer for slices/substrings).  Stringbuilder/stringbuffer/stringstream-like classes work a lot faster than concatenating strings(producing many small temporary objects that still need allocations and garbage collection) and even string formatting printf-like tools, not needing of interpreting formatting pattern overhead that is pretty consuming for a lot of format calls.     ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"Python string class like StringBuilder in C#?","A_Content":"  In case you are here looking for a fast string concatenation method in Python, then you do not need a special StringBuilder class. Simple concatenation works just as well without the performance penalty seen in C#.  resultString = \"\"  resultString += \"Append 1\" resultString += \"Append 2\"   See Antoine-tran's answer for performance results     ","Language":"Python","Tags":["python","string"],"URL":"https://stackoverflow.com/questions/2414667/python-string-class-like-stringbuilder-in-c","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Is there some string class in Python like StringBuilder in C#?     ","Q_Votes":"78"},{"Q_Title":"How can I convert a tensor into a numpy array in TensorFlow?","A_Content":"  Any tensor returned by Session.run or eval is a NumPy array.  >>> print(type(tf.Session().run(tf.constant([1,2,3])))) <class 'numpy.ndarray'>   Or:  >>> sess = tf.InteractiveSession() >>> print(type(tf.constant([1,2,3]).eval())) <class 'numpy.ndarray'>   Or, equivalently:  >>> sess = tf.Session() >>> with sess.as_default(): >>>    print(type(tf.constant([1,2,3]).eval())) <class 'numpy.ndarray'>   EDIT: Not any tensor returned by Session.run or eval() is a NumPy array. Sparse Tensors for example are returned as SparseTensorValue:  >>> print(type(tf.Session().run(tf.SparseTensor([[0, 0]],[1],[1,2])))) <class 'tensorflow.python.framework.sparse_tensor.SparseTensorValue'>      ","Language":"Python","Tags":["python","numpy","tensorflow"],"URL":"https://stackoverflow.com/questions/34097281/how-can-i-convert-a-tensor-into-a-numpy-array-in-tensorflow","A_Votes":"65","_type":"dict","isAccepted":"Yes","Q_Content":"    How to convert a tensor into a numpy array when using Tensorflow with Python bindings?     ","Q_Votes":"78"},{"Q_Title":"How can I convert a tensor into a numpy array in TensorFlow?","A_Content":"  To convert back from tensor to numpy array you can simply run .eval() on the transformed tensor.     ","Language":"Python","Tags":["python","numpy","tensorflow"],"URL":"https://stackoverflow.com/questions/34097281/how-can-i-convert-a-tensor-into-a-numpy-array-in-tensorflow","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    How to convert a tensor into a numpy array when using Tensorflow with Python bindings?     ","Q_Votes":"78"},{"Q_Title":"How can I convert a tensor into a numpy array in TensorFlow?","A_Content":"  You need to:    encode the image tensor in some format (jpeg, png) to binary tensor  evaluate (run) the binary tensor in a session  turn the binary to stream   feed to PIL image   (optional) displaythe image with matplotlib   Code:  import tensorflow as tf import matplotlib.pyplot as plt import PIL  ...  image_tensor = <your decoded image tensor> jpeg_bin_tensor = tf.image.encode_jpeg(image_tensor)  with tf.Session() as sess:     # display encoded back to image data     jpeg_bin = sess.run(jpeg_bin_tensor)     jpeg_str = StringIO.StringIO(jpeg_bin)     jpeg_image = PIL.Image.open(jpeg_str)     plt.imshow(jpeg_image)   This worked for me. You can try it in a ipython notebook. Just don't forget to add the following line:  %matplotlib inline      ","Language":"Python","Tags":["python","numpy","tensorflow"],"URL":"https://stackoverflow.com/questions/34097281/how-can-i-convert-a-tensor-into-a-numpy-array-in-tensorflow","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How to convert a tensor into a numpy array when using Tensorflow with Python bindings?     ","Q_Votes":"78"},{"Q_Title":"How can I convert a tensor into a numpy array in TensorFlow?","A_Content":"  Maybe you can trythis method:  import tensorflow as tf W1 = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) init = tf.global_variables_initializer() sess = tf.Session() sess.run(init) array = W1.eval(sess) print (array)      ","Language":"Python","Tags":["python","numpy","tensorflow"],"URL":"https://stackoverflow.com/questions/34097281/how-can-i-convert-a-tensor-into-a-numpy-array-in-tensorflow","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How to convert a tensor into a numpy array when using Tensorflow with Python bindings?     ","Q_Votes":"78"},{"Q_Title":"Using python with statement with try-except block","A_Content":"   The two code blocks you gave are not equivalent The code you described as old way of doing things has a serious bug: in case opening the file fails you will get a second exception in the finally clause because f is not bound.   The equivalent old style code would be:  try:     f = open(\"file\", \"r\")     try:         line = f.readline()     finally:         f.close() except IOError:     <whatever>   As you can see, the with statement can make things less error prone. In newer versions of Python (2.7, 3.1), you can also combine multiple expressions in one with statement. For example:  with open(\"input\", \"r\") as inp, open(\"output\", \"w\") as out:     out.write(inp.read())   Besides that, I personally regard it as bad habit to catch any exception as early as possible. This is not the purpose of exceptions. If the IO function that can fail is part of a more complicated operation, in most cases the IOError should abort the whole operation and so be handled at an outer level. Using with statements, you can get rid of all these try...finally statements at inner levels.      ","Language":"Python","Tags":["python","finally","with-statement","try-catch","except"],"URL":"https://stackoverflow.com/questions/3642080/using-python-with-statement-with-try-except-block","A_Votes":"118","_type":"dict","isAccepted":"Yes","Q_Content":"    Is this the right way to use the python \"with\" statement in combination with a try-except block?:  try:     with open(\"file\", \"r\") as f:         line = f.readline() except IOError:     <whatever>   If it is, then considering the old way of doing things:  try:     f = open(\"file\", \"r\")     line = f.readline() except IOError:     <whatever> finally:     f.close()   Is the primary benefit of the \"with\" statement here that we can get rid of three lines of code?  It doesn't seem that compelling to me for this use case (though I understand that the \"with\" statement has other uses).  EDIT: Is the functionality of the above two blocks of code identical?  EDIT2: The first few answers talk generally about the benefits of using \"with\", but those seem of marginal benefit here.  We've all been (or should have been) explicitly calling f.close() for years.  I suppose one benefit is that sloppy coders will benefit from using \"with\".     ","Q_Votes":"78"},{"Q_Title":"Using python with statement with try-except block","A_Content":"  If the contents of the finally block are determined by the properties of the file object being opened, why shouldn't the implementer of the file object be the one to write the finally block? That's the benefit of the with statement, much more than saving you three lines of code in this particular instance.  And yes, the way you've combined with and try-except is pretty much the only way to do it, as exceptional errors caused within the open statement itself can't be caught within the with block.     ","Language":"Python","Tags":["python","finally","with-statement","try-catch","except"],"URL":"https://stackoverflow.com/questions/3642080/using-python-with-statement-with-try-except-block","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is this the right way to use the python \"with\" statement in combination with a try-except block?:  try:     with open(\"file\", \"r\") as f:         line = f.readline() except IOError:     <whatever>   If it is, then considering the old way of doing things:  try:     f = open(\"file\", \"r\")     line = f.readline() except IOError:     <whatever> finally:     f.close()   Is the primary benefit of the \"with\" statement here that we can get rid of three lines of code?  It doesn't seem that compelling to me for this use case (though I understand that the \"with\" statement has other uses).  EDIT: Is the functionality of the above two blocks of code identical?  EDIT2: The first few answers talk generally about the benefits of using \"with\", but those seem of marginal benefit here.  We've all been (or should have been) explicitly calling f.close() for years.  I suppose one benefit is that sloppy coders will benefit from using \"with\".     ","Q_Votes":"78"},{"Q_Title":"Using python with statement with try-except block","A_Content":"  I think you got it wrong about \"with\" statement that it only reduces lines. It actually does initialization and handle teardown.   In your case \"with\" does    open a file, process its contents, and make sure to close it.   Here is link for understanding \"with\" statement : http://effbot.org/zone/python-with-statement.htm  Edit: Yes your usage of \"with\" is correct and functionality of both blocks of code is identical. Question about why to use \"with\" ? it's because of benefits you get with it. like you mentioned about accidentally missing f.close().      ","Language":"Python","Tags":["python","finally","with-statement","try-catch","except"],"URL":"https://stackoverflow.com/questions/3642080/using-python-with-statement-with-try-except-block","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is this the right way to use the python \"with\" statement in combination with a try-except block?:  try:     with open(\"file\", \"r\") as f:         line = f.readline() except IOError:     <whatever>   If it is, then considering the old way of doing things:  try:     f = open(\"file\", \"r\")     line = f.readline() except IOError:     <whatever> finally:     f.close()   Is the primary benefit of the \"with\" statement here that we can get rid of three lines of code?  It doesn't seem that compelling to me for this use case (though I understand that the \"with\" statement has other uses).  EDIT: Is the functionality of the above two blocks of code identical?  EDIT2: The first few answers talk generally about the benefits of using \"with\", but those seem of marginal benefit here.  We've all been (or should have been) explicitly calling f.close() for years.  I suppose one benefit is that sloppy coders will benefit from using \"with\".     ","Q_Votes":"78"},{"Q_Title":"Using python with statement with try-except block","A_Content":"  The more Pythonic way for the following codes is:  try:     f = open(\"file\", \"r\")     try:         line = f.readline()     finally:         f.close() except IOError:     <whatever>  try:     f = open(\"file\", \"r\") except IOError:     <whatever> else:     f.close()      ","Language":"Python","Tags":["python","finally","with-statement","try-catch","except"],"URL":"https://stackoverflow.com/questions/3642080/using-python-with-statement-with-try-except-block","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    Is this the right way to use the python \"with\" statement in combination with a try-except block?:  try:     with open(\"file\", \"r\") as f:         line = f.readline() except IOError:     <whatever>   If it is, then considering the old way of doing things:  try:     f = open(\"file\", \"r\")     line = f.readline() except IOError:     <whatever> finally:     f.close()   Is the primary benefit of the \"with\" statement here that we can get rid of three lines of code?  It doesn't seem that compelling to me for this use case (though I understand that the \"with\" statement has other uses).  EDIT: Is the functionality of the above two blocks of code identical?  EDIT2: The first few answers talk generally about the benefits of using \"with\", but those seem of marginal benefit here.  We've all been (or should have been) explicitly calling f.close() for years.  I suppose one benefit is that sloppy coders will benefit from using \"with\".     ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  You might want to do this when the \"inner\" class is a one-off, which will never be used outside the definition of the outer class. For example to use a metaclass, it's sometimes handy to do  class Foo(object):     class __metaclass__(type):         ....    instead of defining a metaclass separately, if you're only using it once.  The only other time I've used nested classes like that, I used the outer class only as a namespace to group a bunch of closely related classes together:  class Group(object):     class cls1(object):        ...      class cls2(object):        ...   Then from another module, you can import Group and refer to these as Group.cls1, Group.cls2 etc. However one might argue that you can accomplish exactly the same (perhaps in a less confusing way) by using a module.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  I don't know Python, but your question seems very general. Ignore me if it's specific to Python.  Class nesting is all about scope. If you think that one class will only make sense in the context of another one, then the former is probably a good candidate to become a nested class.  It is a common pattern make helper classes as private, nested classes.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  There is really no benefit to doing this, except if you are dealing with metaclasses.  the class: suite really isn't what you think it is. It is a weird scope, and it does strange things. It really doesn't even make a class! It is just a way of collecting some variables - the name of the class, the bases, a little dictionary of attributes, and a metaclass.  The name, the dictionary and the bases are all passed to the function that is the metaclass, and then it is assigned to the variable 'name' in the scope where the class: suite was.  What you can gain by messing with metaclasses, and indeed by nesting classes within your stock standard classes, is harder to read code, harder to understand code, and odd errors that are terribly difficult to understand without being intimately familiar with why the 'class' scope is entirely different to any other python scope.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  You could be using a class as class generator. Like (in some off the cuff code :)  class gen(object):     class base_1(object): pass     ...     class base_n(object): pass      def __init__(self, ...):         ...     def mk_cls(self, ..., type):         '''makes a class based on the type passed in, the current state of            the class, and the other inputs to the method'''   I feel like when you need this functionality it will be very clear to you. If you don't need to be doing something similar than it probably isn't a good use case.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  No, composition does not mean nesting. It would make sense to have a nested class if you want to hide it more in the namespace of the outer class.  Anyway, I don't see any practical use for nesting in your case. It would make the code harder to read (understand) and it would also increase the indentation which would make the lines shorter and more prone to splitting.     ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"Is there a benefit to defining a class inside another class in Python?","A_Content":"  There is another usage for nested class, when one wants to construct inherited classes whose enhanced functionalities are encapsulated in a specific nested class.  See this example:  class foo:    class bar:     ...  # functionalities of a specific sub-feature of foo    def __init__(self):     self.a = self.bar()     ...    ...  # other features of foo   class foo2(foo):    class bar(foo.bar):     ... # enhanced functionalities for this specific feature    def __init__(self):     foo.__init__(self)   Note that in the constructor of foo, the line self.a = self.bar() will construct a foo.bar when the object being constructed is actually a foo object, and a foo2.bar object when the object being constructed is actually a foo2 object.   If the class bar was defined outside of class foo instead, as well as its inherited version (which would be called bar2 for example), then defining the new class foo2 would be much more painful, because the constuctor of foo2 would need to have its first line replaced by self.a = bar2(), which implies re-writing the whole constructor.      ","Language":"Python","Tags":["python","oop"],"URL":"https://stackoverflow.com/questions/78799/is-there-a-benefit-to-defining-a-class-inside-another-class-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What I'm talking about here are nested classes. Essentially, I have two classes that I'm modeling. A DownloadManager class and a DownloadThread class. The obvious OOP concept here is composition. However, composition doesn't necessarily mean nesting, right?  I have code that looks something like this:  class DownloadThread:     def foo(self):         pass  class DownloadManager():     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadThread())   But now I'm wondering if there's a situation where nesting would be better. Something like:  class DownloadManager():     class DownloadThread:         def foo(self):             pass     def __init__(self):         dwld_threads = []     def create_new_thread():         dwld_threads.append(DownloadManager.DownloadThread())      ","Q_Votes":"78"},{"Q_Title":"What is the Bash equivalent of Python's pass statement","A_Content":"  You can use : for this.     ","Language":"Python","Tags":["python","bash","language-comparisons"],"URL":"https://stackoverflow.com/questions/2421586/what-is-the-bash-equivalent-of-pythons-pass-statement","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a Bash equivalent to the Python's pass statement?     ","Q_Votes":"78"},{"Q_Title":"What is the Bash equivalent of Python's pass statement","A_Content":"  true is a command that successfully does nothing.  (false would, in a way, be the opposite: it doesn't do anything, but claims that a failure occurred.)     ","Language":"Python","Tags":["python","bash","language-comparisons"],"URL":"https://stackoverflow.com/questions/2421586/what-is-the-bash-equivalent-of-pythons-pass-statement","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Is there a Bash equivalent to the Python's pass statement?     ","Q_Votes":"78"},{"Q_Title":"How to use Sphinx's autodoc to document a class's __init__(self) method?","A_Content":"  Here are three alternatives:   To ensure that __init__() is always documented, you can use autodoc-skip-member in conf.py. Like this:  def skip(app, what, name, obj, skip, options):     if name == \"__init__\":         return False     return skip  def setup(app):     app.connect(\"autodoc-skip-member\", skip)   This explicitly defines __init__ not to be skipped (which it is by default). This configuration is specified once, and it does not require any additional markup for every class in the .rst source. The special-members option was added in Sphinx 1.1. It makes \"special\" members (those with names like __special__) be documented by autodoc.  Since Sphinx 1.2, this option takes arguments which makes it more useful than it was previously. Use automethod:   .. autoclass:: MyClass         :members:      .. automethod:: __init__   This has to be added for every class (cannot be used with automodule, as pointed out in a comment to the first revision of this answer).      ","Language":"Python","Tags":["python","python-sphinx","autodoc"],"URL":"https://stackoverflow.com/questions/5599254/how-to-use-sphinxs-autodoc-to-document-a-classs-init-self-method","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    Sphinx doesn't generate docs for __init__(self) by default. I have tried the following:  .. automodule:: mymodule     :members:   and  ..autoclass:: MyClass     :members:   In conf.py, setting the following only appends the __init__(self) docstring to the class docstring (the Sphinx autodoc documentation seems to agree that this is the expected behavior, but mentions nothing regarding the problem I'm trying to solve):  autoclass_content = 'both'      ","Q_Votes":"78"},{"Q_Title":"How to use Sphinx's autodoc to document a class's __init__(self) method?","A_Content":"  You were close. You can use the autoclass_content option in your conf.py file:  autoclass_content = 'both'      ","Language":"Python","Tags":["python","python-sphinx","autodoc"],"URL":"https://stackoverflow.com/questions/5599254/how-to-use-sphinxs-autodoc-to-document-a-classs-init-self-method","A_Votes":"50","_type":"dict","isAccepted":"No","Q_Content":"    Sphinx doesn't generate docs for __init__(self) by default. I have tried the following:  .. automodule:: mymodule     :members:   and  ..autoclass:: MyClass     :members:   In conf.py, setting the following only appends the __init__(self) docstring to the class docstring (the Sphinx autodoc documentation seems to agree that this is the expected behavior, but mentions nothing regarding the problem I'm trying to solve):  autoclass_content = 'both'      ","Q_Votes":"78"},{"Q_Title":"How to use Sphinx's autodoc to document a class's __init__(self) method?","A_Content":"  Over the past years I've written several variants of autodoc-skip-member callbacks for various unrelated Python projects because I wanted methods like __init__(), __enter__() and __exit__() to show up in my API documentation (after all, these \"special methods\" are part of the API and what better place to document them than inside the special method's docstring).  Recently I took the best implementation and made it part of one of my Python projects (here's the documentation). The implementation basically comes down to this:    def enable_special_methods(app):     \"\"\"     Enable documenting \"special methods\" using the autodoc_ extension.      :param app: The Sphinx application object.      This function connects the :func:`special_methods_callback()` function to     ``autodoc-skip-member`` events.      .. _autodoc: http://www.sphinx-doc.org/en/stable/ext/autodoc.html     \"\"\"     app.connect('autodoc-skip-member', special_methods_callback)   def special_methods_callback(app, what, name, obj, skip, options):     \"\"\"     Enable documenting \"special methods\" using the autodoc_ extension.      Refer to :func:`enable_special_methods()` to enable the use of this     function (you probably don't want to call     :func:`special_methods_callback()` directly).      This function implements a callback for ``autodoc-skip-member`` events to     include documented \"special methods\" (method names with two leading and two     trailing underscores) in your documentation. The result is similar to the     use of the ``special-members`` flag with one big difference: Special     methods are included but other types of members are ignored. This means     that attributes like ``__weakref__`` will always be ignored (this was my     main annoyance with the ``special-members`` flag).      The parameters expected by this function are those defined for Sphinx event     callback functions (i.e. I'm not going to document them here :-).     \"\"\"     if getattr(obj, '__doc__', None) and isinstance(obj, (types.FunctionType, types.MethodType)):         return False     else:         return skip   Yes, there's more documentation than logic :-). The advantage of defining an autodoc-skip-member callback like this over the use of the special-members option (for me) is that the special-members option also enables documentation of properties like __weakref__ (available on all new-style classes, AFAIK) which I consider noise and not useful at all. The callback approach avoids this (because it only works on functions/methods and ignores other attributes).      ","Language":"Python","Tags":["python","python-sphinx","autodoc"],"URL":"https://stackoverflow.com/questions/5599254/how-to-use-sphinxs-autodoc-to-document-a-classs-init-self-method","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Sphinx doesn't generate docs for __init__(self) by default. I have tried the following:  .. automodule:: mymodule     :members:   and  ..autoclass:: MyClass     :members:   In conf.py, setting the following only appends the __init__(self) docstring to the class docstring (the Sphinx autodoc documentation seems to agree that this is the expected behavior, but mentions nothing regarding the problem I'm trying to solve):  autoclass_content = 'both'      ","Q_Votes":"78"}]