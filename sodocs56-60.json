[
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  Contrary to other answers already posted you cannot modify locals() directly and expect it to work.  >>> def foo():     lcl = locals()     lcl['xyz'] = 42     print(xyz)   >>> foo()  Traceback (most recent call last):   File \"<pyshell#6>\", line 1, in <module>     foo()   File \"<pyshell#5>\", line 4, in foo     print(xyz) NameError: global name 'xyz' is not defined   Modifying locals() is undefined. Outside a function when locals() and globals() are the same it will work; inside a function it will usually not work.  Use a dictionary, or set an attribute on an object:  d = {} d['xyz'] = 42 print(d['xyz'])   or if you prefer, use a class:  class C: pass  obj = C() setattr(obj, 'xyz', 42) print(obj.xyz)   Edit: Access to variables in namespaces that aren't functions (so modules, class definitions, instances) are usually done by dictionary lookups (as Sven points out in the comments there are exceptions, for example classes that define __slots__). Function locals can be optimised for speed because the compiler (usually) knows all the names in advance, so there isn't a dictionary until you call locals().  In the C implementation of Python locals() (called from inside a function) creates an ordinary dictionary initialised from the current values of the local variables. Within each function any number of calls to locals() will return the same dictionary, but every call to locals() will update it with the current values of the local variables. This can give the impression that assignment to elements of the dictionary are ignored (I originally wrote that this was the case). Modifications to existing keys within the dictionary returned from locals() therefore only last until the next call to locals() in the same scope.  In IronPython things work a bit differently. Any function that calls locals() inside it uses a dictionary for its local variables so assignments to local variables change the dictionary and assignments to the dictionary change the variables BUT that's only if you explicitly call locals() under that name. If you bind a different name to the locals function in IronPython then calling it gives you the local variables for the scope where the name was bound and there's no way to access the function locals through it:  >>> def foo(): ...     abc = 123 ...     lcl = zzz() ...     lcl['abc'] = 456 ...     deF = 789 ...     print(abc) ...     print(zzz()) ...     print(lcl) ... >>> zzz =locals >>> foo() 123 {'__doc__': None, '__builtins__': <module '__builtin__' (built-in)>, 'zzz': <built-in function locals>, 'foo': <function foo at 0x000000000000002B>, '__name__': '__main__', 'abc': 456} {'__doc__': None, '__builtins__': <module '__builtin__' (built-in)>, 'zzz': <built-in function locals>, 'foo': <function foo at 0x000000000000002B>, '__name__': '__main__', 'abc': 456} >>>   This could all change at any time. The only thing guaranteed is that you cannot depend on the results of assigning to the dictionary returned by locals().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  Others have suggested assigning to locals(). This won't work inside a function, where locals are accessed using the LOAD_FAST opcode, unless you have an exec statement somewhere in the function. To support this statement, which could create new variables that are not known at compile time, Python is then forced to access local variables by name within the function, so writing to locals() works. The exec can be out of the code path that is executed.  def func(varname):     locals()[varname] = 42     return answer           # only works if we passed in \"answer\" for varname     exec \"\"                 # never executed  func(\"answer\") >>> 42   Note: This only works in Python 2.x. They did away with this foolishness in Python 3, and other implementations (Jython, IronPython, etc.) may not support it either.  This is a bad idea, though. How will you access the variables if you don't know their name? By locals()[xxx] probably. So why not just use your own dictionary rather than polluting locals() (and taking the chance of overwriting a variable your function actually needs)?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  (Just a quick note for others googlin')  Ok, so modifying locals() is not the way to go ( while modifying globals() is supposed to work). In the meantime, exec could be, but it's painfully slow, so, as with regular expressions, we may want to compile() it first:  # var0 = 0; var1 = 1; var2 = 2 code_text = '\\n'.join( \"var%d = %d\" % (n, n) for n in xrange(3) )  filename = '' code_chunk = compile( code_text, filename, 'exec' )  # now later we can use exec: exec code_chunk # executes in the current context      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  I've spent the last... couple hours, I guess, trying to hack around the lack of function closures, and I came up with this, which might help:  common_data = ...stuff... def process(record):     ...logic...  def op():     for fing in op.func_dict: # Key line number 1         exec(fing + \" = op.func_dict[fing]\") # Key line number 2      while common_data.still_recieving:         with common_data._lock:             if common_data.record_available:                 process(common_data.oldest_record)         time.sleep(1.0)  op.func_dict.update(locals()) # Key line number 3 threading.Thread(target = op).start()  ...   It's a pretty heavy handed / contrived example, but if there are a lot of locals or you're still in the process of prototyping this pattern becomes useful.  Mostly I was just bitter about all the data stores being replicated or moved in order to handle callback delegates, etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  You could modify locals() directly:  locals()['foo'] = 'bar'    But a better way would be to have some dict that holds all your dynamic variable names as dictionary keys:  d = {} for some in thing:     d[some] = 'whatever'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  You can use a local dictionary and put all the dynamic bindings as items into the dictionary. Then knowing the name of such a \"dynamic variable\" you can use the name as the key to get its value.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Dynamically set local variable [duplicate]",
        "A_Content": "  Let's say We have the below dictionary:  DictionaryA = {'No Rating': ['Hobbit', 'Movie C', 'Movie G'],                'Forget It': ['Avenger', 'Movie B'],                 'Must See': ['Children of Men', 'Skyfall', 'Movie F'],                 '3': ['X-Men', 'Movie D'],                '2': ['Captain America', 'Movie E'],                 '4': ['Transformers', 'Movie A']}    I want to create new dictionaries as below:  NewDictionary1 = {'No Rating': ['Hobbit', 'Movie C', 'Movie G']}  NewDictionary2 = {'Forget It': ['Avenger', 'Movie B']}  NewDictionary3 = {'Must See': ['Children of Men', 'Skyfall', 'Movie F']}   a oneliner:  dics = [{k:v} for k,v in DictionaryA.iteritems()]   would be outputted to:  [{'Must See': ['Children of Men', 'Skyfall', 'Movie F']}, {'Forget It': ['Avenger', 'Movie B']}, {'No Rating': ['Hobbit', 'Movie C', 'Movie G']}, {'3': ['X-Men', 'Movie D']}, {'2': ['Captain America', 'Movie E']}, {'4': ['Transformers', 'Movie A']}]   But to precisely declaring variables we could go with:  >>> i=0 >>> lcl = locals() >>> for key,val in DictionaryA.iteritems():         lcl[\"Dict\" + str(i)] = {key:val}         i += 1   As can be seen the first 3 Dict variables:  >>> Dict0 {'Must See': ['Children of Men', 'Skyfall', 'Movie F']} >>> Dict1 {'Forget It': ['Avenger', 'Movie B']} >>> Dict2 {'No Rating': ['Hobbit', 'Movie C', 'Movie G']}   As mentioned by others, if you want to put it in a function you should add it to the globals():  >>> glb = globals() >>> for key,val in DictionaryA.iteritems():         glb[\"Dict\" + str(i)] = {key:val}         i += 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dynamic"
        ],
        "URL": "https://stackoverflow.com/questions/8028708/dynamically-set-local-variable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can you dynamically create variables via a while loop? [duplicate]                                        8 answers                                          How do you dynamically set local variable in Python?  (where the variable name is dynamic)  UPDATE: I'm aware this isn't good practice, and the remarks are legit, but this doesn't make it a bad question, just a more theoretical one - I don't see why this justifies downvotes.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  Short and dense: http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html     The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.      However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .   From the NLTK docs:     Lemmatization and stemming are special cases of normalization. They identify a canonical representative for a set of related word forms.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "     Lemmatisation is closely related to stemming. The difference is that a   stemmer operates on a single word without knowledge of the context,   and therefore cannot discriminate between words which have different   meanings depending on part of speech. However, stemmers are typically   easier to implement and run faster, and the reduced accuracy may not   matter for some applications.      For instance:         The word \"better\" has \"good\" as its lemma. This link is missed by   stemming, as it requires a dictionary look-up.   The word \"walk\" is the base form for word \"walking\", and hence this   is matched in both stemming and lemmatisation.   The word \"meeting\" can be either the base form of a noun or a form   of a verb (\"to meet\") depending on the context, e.g., \"in our last   meeting\" or \"We are meeting again tomorrow\". Unlike stemming,   lemmatisation can in principle select the appropriate lemma   depending on the context.      Source: https://en.wikipedia.org/wiki/Lemmatisation     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  The purpose of both stemming and lemmatization is to reduce morphological variation. This is in contrast to the the more general \"term conflation\" procedures, which may also address lexico-semantic, syntactic, or orthographic variations.   The real difference between stemming and lemmatization is threefold:   Stemming reduces word-forms to (pseudo)stems, whereas lemmatization reduces the word-forms to linguistically valid lemmas. This difference is apparent in languages with more complex morphology, but may be irrelevant for many IR applications; Lemmatization deals only with inflectional variance, whereas stemming may also deal with derivational variance; In terms of implementation, lemmatization is usually more sophisticated (especially for morphologically complex languages) and usually requires some sort of lexica. Satisfatory stemming, on the other hand, can be achieved with rather simple rule-based approaches.   Lemmatization may also be backed up by a part-of-speech tagger in order to disambiguate homonyms.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  As MYYN pointed out, stemming is the process of removing inflectional and sometimes derivational affixes to a base form that all of the original words are probably related to.  Lemmatization is concerned with obtaining the single word that allows you to group together a bunch of inflected forms.  This is harder than stemming because it requires taking the context into account (and thus the meaning of the word), while stemming ignores context.  As for when you would use one or the other, it's a matter of how much your application depends on getting the meaning of a word in context correct.  If you're doing machine translation, you probably want lemmatization to avoid mistranslating a word.  If you're doing information retrieval over a billion documents with 99% of your queries ranging from 1-3 words, you can settle for stemming.  As for NLTK, the WordNetLemmatizer does use the part of speech, though you have to provide it (otherwise it defaults to nouns).  Passing it \"dove\" and \"v\" yields \"dive\" while \"dove\" and \"n\" yields \"dove\".     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  There are two aspects to show their differences:   A stemmer will return the stem of a word, which needn't be identical to the morphological root of the word. It usually sufficient that related words map to the same stem,even if the stem is not in itself a valid root, while in lemmatisation, it will return the dictionary form of a word, which must be a valid word.  In lemmatisation, the part of speech of a word should be first determined and the normalisation rules will be different for different part of speech, while the stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech.    Reference http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  An example-driven explanation on the differenes between lemmatization and stemming:  Lemmatization handles matching “car” to “cars” along with matching “car” to “automobile”.    Stemming handles matching “car” to “cars” .     Lemmatization implies a broader scope of fuzzy word matching that is   still handled by the same subsystems.  It implies certain techniques   for low level processing within the engine, and may also reflect an   engineering preference for terminology.      [...] Taking FAST as an example,   their lemmatization engine handles not only basic word variations like   singular vs. plural, but also thesaurus operators like having “hot”   match “warm”.      This is not to say that other engines don’t handle synonyms, of course   they do, but the low level implementation may be in a different   subsystem than those that handle base stemming.   http://www.ideaeng.com/stemming-lemmatization-0601     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "what is the true difference between lemmatization vs stemming?",
        "A_Content": "  ianacl but i think Stemming is a rough hack people use to get all the different forms of the same word down to a base form which need not be a legit word on its own Something like the Porter Stemmer can uses simple regexes to eliminate common word suffixes  Lemmatization brings a word down to its actual base form which, in the case of irregular verbs, might look nothing like the input word Something like Morpha which uses FSTs to bring nouns and verbs to their base form     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nlp",
            "nltk",
            "lemmatization"
        ],
        "URL": "https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When do I use each ?  Also...is the NLTK lemmatization dependent upon Parts of Speech? Wouldn't it be more accurate if it was?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "     numpy.zeros      Return a new array of given shape and   type, filled with zeros.   or     numpy.ones      Return a new array of given shape and   type, filled with ones.   or     numpy.empty      Return a new array of given shape and   type, without initializing entries.     However, the mentality in which we construct an array by appending elements to a list is not much used in numpy, because it's less efficient (numpy datatypes are much closer to the underlying C arrays). Instead, you should preallocate the array to the size that you need it to be, and then fill in the rows. You can use numpy.append if you must, though.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "109",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  The way I usually do that is by creating a regular list, then append my stuff into it, and finally transform the list to a numpy array as follows :  import numpy as np big_array = [] #  empty regular list for i in range(5):     arr = i*np.ones((2,4)) # for instance     big_array.append(arr) big_np_array = np.array(big_array)  # transformed to a numpy array   of course your final object takes twice the space in the memory at the creation step, but appending on python list is very fast, and creation using np.array() also.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  Array analogue for the python's  a = [] for i in range(5):     a.append(i)   is:  import numpy as np  a = np.empty((0)) for i in range(5):     a = np.append(a, i)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  numpy.fromiter() is what you are looking for:  big_array = numpy.fromiter(xrange(5), dtype=\"int\")   It also works with generator expressions, e.g.:  big_array = numpy.fromiter( (i*(i+1)/2 for i in xrange(5)), dtype=\"int\" )   If you know the length of the array in advance, you can specify it with an optional 'count' argument.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  Introduced in numpy 1.8:     numpy.full      Return a new array of given shape and type, filled with fill_value.   Examples:  >>> import numpy as np >>> np.full((2, 2), np.inf) array([[ inf,  inf],        [ inf,  inf]]) >>> np.full((2, 2), 10) array([[10, 10],        [10, 10]])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  For your first array example use,  a = numpy.arange(5)   To initialize big_array, use  big_array = numpy.zeros((10,4))   This assumes you want to initialize with zeros, which is pretty typical, but there are many other ways to initialize an array in numpy.  Edit: If you don't know the size of big_array in advance, it's generally best to first build a Python list using append, and when you have everything collected in the list, convert this list to a numpy array using numpy.array(mylist).  The reason for this is that lists are meant to grow very efficiently and quickly, whereas numpy.concatenate would be very inefficient since numpy arrays don't change size easily.  But once everything is collected in a list, and you know the final array size, a numpy array can be efficiently constructed.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  You do want to avoid explicit loops as much as possible when doing array computing, as that reduces the speed gain from that form of computing. There are multiple ways to initialize a numpy array. If you want it filled with zeros, do as katrielalex said:  big_array = numpy.zeros((10,4))  EDIT: What sort of sequence is it you're making? You should check out the different numpy functions that create arrays, like numpy.linspace(start, stop, size) (equally spaced number), or numpy.arange(start, stop, inc). Where possible, these functions will make arrays substantially faster than doing the same work in explicit loops     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  I realize that this is a bit late, but I did not notice any of the other answers mentioning indexing into the empty array:  big_array = numpy.empty(10, 4) for i in range(5):     array_i = numpy.random.random(2, 4)     big_array[2 * i:2 * (i + 1), :] = array_i   This way, you preallocate the entire result array with numpy.empty and fill in the rows as you go using indexed assignment.  It is perfectly safe to preallocate with empty instead of zeros in the example you gave since you are guaranteeing that the entire array will be filled with the chunks you generate.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  I'd suggest defining shape first.  Then iterate over it to insert values.  big_array= np.zeros(shape = ( 6, 2 )) for it in range(6):     big_array[it] = (it,it) # For example  >>>big_array  array([[ 0.,  0.],        [ 1.,  1.],        [ 2.,  2.],        [ 3.,  3.],        [ 4.,  4.],        [ 5.,  5.]])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  Whenever you are in the following situation:  a = [] for i in range(5):     a.append(i)   and you want something similar in numpy, several previous answers have pointed out ways to do it, but as @katrielalex pointed out these methods are not efficient. The efficient way to do this is to build a long list and then reshape it the way you want after you have a long list. For example, let's say I am reading some lines from a file and each row has a list of numbers and I want to build a numpy array of shape (number of lines read, length of vector in each row). Here is how I would do it more efficiently:  long_list = [] counter = 0 with open('filename', 'r') as f:     for row in f:         row_list = row.split()         long_list.extend(row_list)         counter++ #  now we have a long list and we are ready to reshape result = np.array(long_list).reshape(counter, len(row_list)) #  desired numpy array      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  Maybe something like this will fit your needs..  import numpy as np  N = 5 res = []  for i in range(N):     res.append(np.cumsum(np.ones(shape=(2,4))))  res = np.array(res).reshape((10, 4)) print(res)   Which produces the following output  [[ 1.  2.  3.  4.]  [ 5.  6.  7.  8.]  [ 1.  2.  3.  4.]  [ 5.  6.  7.  8.]  [ 1.  2.  3.  4.]  [ 5.  6.  7.  8.]  [ 1.  2.  3.  4.]  [ 5.  6.  7.  8.]  [ 1.  2.  3.  4.]  [ 5.  6.  7.  8.]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "initialize a numpy array",
        "A_Content": "  import numpy as np  mat = np.array([[1, 1, 0, 0, 0],                 [0, 1, 0, 0, 1],                 [1, 0, 0, 1, 1],                 [0, 0, 0, 0, 0],                 [1, 0, 1, 0, 1]])  print mat.shape print mat   output:  (5, 5) [[1 1 0 0 0]  [0 1 0 0 1]  [1 0 0 1 1]  [0 0 0 0 0]  [1 0 1 0 1]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4535374/initialize-a-numpy-array",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there way to initialize a numpy array of a shape and add to it? I will explain what I need with a list example. If I want to create a list of objects generated in a loop, I can do:  a = [] for i in range(5):     a.append(i)   I want to do something similar with a numpy array. I know about vstack, concatenate etc. However, it seems these require two numpy arrays as inputs. What I need is:  big_array # Initially empty. This is where I don't know what to specify for i in range(5):     array i of shape = (2,4) created.     add to big_array   The big_array should have a shape (10,4). How to do this?    EDIT:  I want to add the following clarification. I am aware that I can define big_array = numpy.zeros((10,4)) and then fill it up. However, this requires specifying the size of big_array in advance. I know the size in this case, but what if I do not? When we use the .append function for extending the list in python, we don't need to know its final size in advance. I am wondering if something similar exists for creating a bigger array from smaller arrays, starting with an empty array.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I upgrade to Python 3.6 with conda?",
        "A_Content": "  Anaconda has not updated python internally to 3.6.  a) Method 1   If you wanted to update you will type conda update python To update anaconda type conda update anaconda If you want to upgrade between major python version like 3.5 to 3.6, you'll have to do  conda install python==$pythonversion$`    b) Method 2 - Create a new enviroment (Better Method)  conda create --name py36 python=3.6   c) To get the absolute latest python(3.6.5 at time time of writing)  conda create --name py365 python=3.6.5 --channel conda-forge   You can see all this from here  Also refer to this for force upgrading   EDIT: Anaconda now has a Python 3.6 version here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "anaconda",
            "conda"
        ],
        "URL": "https://stackoverflow.com/questions/41535881/how-do-i-upgrade-to-python-3-6-with-conda",
        "A_Votes": "106",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to Conda package management and I want to get the latest version of Python to use f-strings in my code. Currently my version is (python -V):  Python 3.5.2 :: Anaconda 4.2.0 (x86_64)   How would I upgrade to Python 3.6?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I upgrade to Python 3.6 with conda?",
        "A_Content": "  Creating a new environment will install python 3.6:  $ conda create --name 3point6 python=3.6 Fetching package metadata ....... Solving package specifications: ..........  Package plan for installation in environment /Users/dstansby/miniconda3/envs/3point6:  The following NEW packages will be INSTALLED:      openssl:    1.0.2j-0          pip:        9.0.1-py36_1      python:     3.6.0-0           readline:   6.2-2             setuptools: 27.2.0-py36_0     sqlite:     3.13.0-0          tk:         8.5.18-0          wheel:      0.29.0-py36_0     xz:         5.2.2-1           zlib:       1.2.8-3       ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "anaconda",
            "conda"
        ],
        "URL": "https://stackoverflow.com/questions/41535881/how-do-i-upgrade-to-python-3-6-with-conda",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Conda package management and I want to get the latest version of Python to use f-strings in my code. Currently my version is (python -V):  Python 3.5.2 :: Anaconda 4.2.0 (x86_64)   How would I upgrade to Python 3.6?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I upgrade to Python 3.6 with conda?",
        "A_Content": "  I found this page with detailed instructions to upgrade Anaconda to a major newer version of Python (from Anaconda 4.0+).  First,  conda update conda conda remove argcomplete conda-manager   I also had to conda remove some packages not on the official list:    backports_abc beautiful-soup blaze-core   Depending on packages installed on your system, you may get additional UnsatisfiableError errors - simply add those packages to the remove list. Next, install the version of Python,  conda install python==3.6   which takes a while, after which a message indicated to conda install anaconda-client, so I did  conda install anaconda-client   which said it's already there.  Finally, following the directions,   conda update anaconda   I did this in the Windows 10 command prompt, but things should be similar in Mac OS X.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "anaconda",
            "conda"
        ],
        "URL": "https://stackoverflow.com/questions/41535881/how-do-i-upgrade-to-python-3-6-with-conda",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Conda package management and I want to get the latest version of Python to use f-strings in my code. Currently my version is (python -V):  Python 3.5.2 :: Anaconda 4.2.0 (x86_64)   How would I upgrade to Python 3.6?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I upgrade to Python 3.6 with conda?",
        "A_Content": "  In the past, I found it quite difficult to try to upgrade in-place.   Note: my use-case for Anaconda is as an all-in-one Python environment. I don't bother with separate virtual environments. If you're using conda to create environments, this may be destructive because conda creates environments with hard-links inside your Anaconda/envs directory.   So if you use environments, you may first want to export your environments. After activated your environment, do something like:  conda env export > environment.yml   After backing up your environments, if necessary, you may remove your old Anaconda (very simple to uninstall Anaconda):  $ rm -rf ~/anaconda3/   and replace it by downloading the new Anaconda, e.g. Linux, 64 bit:  $ cd ~/Downloads $ wget https://repo.continuum.io/archive/Anaconda3-4.3.0-Linux-x86_64.sh    (see here for a more recent one),  then executing it:  $ bash Anaconda3-4.3.0-Linux-x86_64.sh       ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "anaconda",
            "conda"
        ],
        "URL": "https://stackoverflow.com/questions/41535881/how-do-i-upgrade-to-python-3-6-with-conda",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Conda package management and I want to get the latest version of Python to use f-strings in my code. Currently my version is (python -V):  Python 3.5.2 :: Anaconda 4.2.0 (x86_64)   How would I upgrade to Python 3.6?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I upgrade to Python 3.6 with conda?",
        "A_Content": "  Best method I found:  source activate old_env conda env export > old_env.yml   Then process it with something like this:  with open('old_env.yml', 'r') as fin, open('new_env.yml', 'w') as fout:     for line in fin:         if 'py35' in line:  # replace by the version you want to supersede             line = line[:line.rfind('=')] + '\\n'         fout.write(line)   then edit manually the first (name: ...) and last line (prefix: ...) to reflect your new environment name and run:  conda env create -f new_env.yml   you might need to remove or change manually the version pin of a few packages for which which the pinned version from old_env is found incompatible or missing for the new python version.  I wish there was a built-in, easier way...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "anaconda",
            "conda"
        ],
        "URL": "https://stackoverflow.com/questions/41535881/how-do-i-upgrade-to-python-3-6-with-conda",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Conda package management and I want to get the latest version of Python to use f-strings in my code. Currently my version is (python -V):  Python 3.5.2 :: Anaconda 4.2.0 (x86_64)   How would I upgrade to Python 3.6?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can I use __init__.py to define global variables?",
        "A_Content": "  You should be able to put them in __init__.py.  This is done all the time.  mypackage/__init__.py:  MY_CONSTANT = 42   mypackage/mymodule.py:  from mypackage import MY_CONSTANT print \"my constant is\", MY_CONSTANT   Then, import mymodule:  >>> from mypackage import mymodule my constant is 42   Still, if you do have constants, it would be reasonable (best practices, probably) to put them in a separate module (constants.py, config.py, ...) and then if you want them in the package namespace, import them.  mypackage/__init__.py:  from mypackage.constants import *   Still, this doesn't automatically include the constants in the namespaces of the package modules.  Each of the modules in the package will still have to import constants explicitly either from mypackage or from mypackage.constants.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "global-variables",
            "module",
            "packages",
            "init"
        ],
        "URL": "https://stackoverflow.com/questions/1383239/can-i-use-init-py-to-define-global-variables",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to define a constant that should be available in all of the submodules of a package. I've thought that the best place would be in in the __init__.py file of the root package. But I don't know how to do this. Suppose I have a few subpackages and each with several modules. How can I access that variable from these modules?  Of course, if this is totally wrong, and there is a better alternative, I'd like to know it.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can I use __init__.py to define global variables?",
        "A_Content": "  You cannot do that. You will have to explicitely import your constants into each individual module's namespace. The best way to achieve this is to define your constants in a \"config\" module and import it everywhere you require it:  # mypackage/config.py MY_CONST = 17  # mypackage/main.py from mypackage.config import *      ",
        "Language": "Python",
        "Tags": [
            "python",
            "global-variables",
            "module",
            "packages",
            "init"
        ],
        "URL": "https://stackoverflow.com/questions/1383239/can-i-use-init-py-to-define-global-variables",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to define a constant that should be available in all of the submodules of a package. I've thought that the best place would be in in the __init__.py file of the root package. But I don't know how to do this. Suppose I have a few subpackages and each with several modules. How can I access that variable from these modules?  Of course, if this is totally wrong, and there is a better alternative, I'd like to know it.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can I use __init__.py to define global variables?",
        "A_Content": "  You can define global variables from anywhere, but it is a really bad idea. import the __builtin__ module and modify or add attributes to this modules, and suddenly you have new builtin constants or functions. In fact, when my application installs gettext, I get the _() function in all my modules, without importing anything. So this is possible, but of course only for Application-type projects, not for reusable packages or modules.  And I guess no one would recommend this practice anyway. What's wrong with a namespace? Said application has the version module, so that I have \"global\" variables available like version.VERSION, version.PACKAGE_NAME etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "global-variables",
            "module",
            "packages",
            "init"
        ],
        "URL": "https://stackoverflow.com/questions/1383239/can-i-use-init-py-to-define-global-variables",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to define a constant that should be available in all of the submodules of a package. I've thought that the best place would be in in the __init__.py file of the root package. But I don't know how to do this. Suppose I have a few subpackages and each with several modules. How can I access that variable from these modules?  Of course, if this is totally wrong, and there is a better alternative, I'd like to know it.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can I use __init__.py to define global variables?",
        "A_Content": "  Just wanted to add that constants can be employed using a config.ini file and parsed in the script using the configparser library. This way you could have constants for multiple circumstances. For instance if you had parameter constants for two separate url requests just label them like so:  mymodule/config.ini [request0] conn = 'admin@localhost' pass = 'admin' ...  [request1] conn = 'barney@localhost' pass = 'dinosaur' ...   I found the documentation on the Python website very helpful. I am not sure if there are any differences between Python 2 and 3 so here are the links to both:  For Python 3: https://docs.python.org/3/library/configparser.html#module-configparser   For Python 2: https://docs.python.org/2/library/configparser.html#module-configparser     ",
        "Language": "Python",
        "Tags": [
            "python",
            "global-variables",
            "module",
            "packages",
            "init"
        ],
        "URL": "https://stackoverflow.com/questions/1383239/can-i-use-init-py-to-define-global-variables",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to define a constant that should be available in all of the submodules of a package. I've thought that the best place would be in in the __init__.py file of the root package. But I don't know how to do this. Suppose I have a few subpackages and each with several modules. How can I access that variable from these modules?  Of course, if this is totally wrong, and there is a better alternative, I'd like to know it.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  in the CLI you can do this:  >>> import django >>> django <module 'django' from '/usr/local/lib/python2.6/dist-packages/django/__init__.pyc'>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  $ python >>> import django >>> django.__file__ '/usr/local/lib/python2.7/site-packages/django/__init__.pyc'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  On Microsft-Windows OS: In the Lib/site-packages folder inside your python installation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  The current top answer doesn't work, at least on linux.  From the Django tutorial:     If you have difficulty finding where the Django source files are   located on your system, run the following command:   python -c \" import sys sys.path = sys.path[1:] import django print(django.__path__)\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  This approach I am describing works across operating systems...  You try this on your command line - python -c \"from distutils.sysconfig import get_python_lib; print get_python_lib()\"  This gives you the base directory. From there, type /django/ and here you find all the default templates, admin templates, etc.  Hope this helps...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  import django django.__file__   output will be given location of the django folder  'C:\\\\Users\\\\saigopi\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\lib\\\\site-packages\\\\django\\\\__init__.py'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  Worth mentioning that if you are using a virtual env all the packages will be in your project's root venv folder under \"lib\" ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  If you are using virtualenv then it will be: /home/user/path where you installed django/django_directory/lib/python2.7/site-packages/Django-1.8.1-py2.7.egg/django/contrib/admin/templates/admin/base_site.html base-site.html is the default template.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  Try this on an terminal.  $ python -v import django # directory /home/user/.virtualenvs/myenv/local/lib/python2.7/site-packages/django # some other imports.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Where is my Django installation?",
        "A_Content": "  As the comments on @olafure's answer https://stackoverflow.com/a/12974642/4515198 rightly say, the sys.path assignment is not required.  the following will be enough:  $ python -c \" $ import django $ print(django.__path__)\"   here the -c option is used to tell python that a \"program is being passed in as string\" (source: command $ python --help on bash)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "path",
            "installation"
        ],
        "URL": "https://stackoverflow.com/questions/7037468/where-is-my-django-installation",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use Django but I need to find the default templates and applications.  I don't know where it's installed.  How can I find that?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Elegant setup of Python logging in Django",
        "A_Content": "  The best way I've found so far is to initialize logging setup in settings.py - nowhere else. You can either use a configuration file or do it programmatically step-by-step - it just depends on your requirements. The key thing is that I usually add the handlers I want to the root logger, using levels and sometimes logging.Filters to get the events I want to the appropriate files, console, syslogs etc. You can of course add handlers to any other loggers too, but there isn't commonly a need for this in my experience.  In each module, I define a logger using  logger = logging.getLogger(__name__)   and use that for logging events in the module (and, if I want to differentiate further) use a logger which is a child of the logger created above.  If my app is going to be potentially used in a site which doesn't configure logging in settings.py, I define a NullHandler somewhere as follows:  #someutils.py  class NullHandler(logging.Handler):     def emit(self, record):         pass  null_handler = NullHandler()   and ensure that an instance of it is added to all loggers created in the modules in my apps which use logging. (Note: NullHandler is already in the logging package for Python 3.1, and will be in Python 2.7.) So:  logger = logging.getLogger(__name__) logger.addHandler(someutils.null_handler)   This is done to ensure that your modules play nicely in a site which doesn't configure logging in settings.py, and that you don't get any annoying \"No handlers could be found for logger X.Y.Z\" messages (which are warnings about potentially misconfigured logging).  Doing it this way meets your stated requirements:   You can set up different log handlers for different events, as you currently do. Easy access to loggers in your modules - use getLogger(__name__). Easily applicable to command-line modules - they also import settings.py.   Update: Note that as of version 1.3, Django now incorporates support for logging.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/1598823/elegant-setup-of-python-logging-in-django",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have yet to find a way of setting up Python logging with Django that I'm happy with. My requirements are fairly simple:   Different log handlers for different events - that is, I want to be able to log to different files Easy access to loggers in my modules. The module should be able to find its logger with little effort. Should be easily applicable to command-line modules. Parts of the system are stand-alone command line or daemon processes. Logging should be easily usable with these modules.   My current setup is to use a logging.conf file and setup logging in each module I log from. It doesn't feel right.   Do you have a logging setup that you like? Please detail it: how do you setup the configuration (do you use logging.conf or set it up in code), where/when do you initiate the loggers, and how do you get access to them in your modules, etc.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Elegant setup of Python logging in Django",
        "A_Content": "  I know this is a solved answer already, but as per django >= 1.3 there's a new logging setting.  Moving from old to new is not automatic, so I thought i'll write it down here.  And of course checkout the django doc for some more.  This is the basic conf, created by default with django-admin createproject v1.3 - mileage might change with latest django versions:  LOGGING = {     'version': 1,     'disable_existing_loggers': False,     'handlers': {         'mail_admins': {             'level': 'ERROR',             'class': 'django.utils.log.AdminEmailHandler',         }     },     'loggers': {         'django.request': {             'handlers': ['mail_admins'],             'level': 'ERROR',             'propagate': True,         }     } }   This structure is based upon the standard Python logging dictConfig, that dictates the following blocks:   formatters - the corresponding value will be a dict in which each key is a formatter id and each value is a dict describing how to configure the corresponding Formatter instance. filters - the corresponding value will be a dict in which each key is a filter id and each value is a dict describing how to configure the corresponding Filter instance. handlers - the corresponding value will be a dict in which each key is a handler id and each value is a dict describing how to configure the corresponding Handler instance. Each handler has the following keys:   class (mandatory). This is the fully qualified name of the handler class. level (optional). The level of the handler. formatter (optional). The id of the formatter for this handler. filters (optional). A list of ids of the filters for this handler.    I usually do at least this:   add a .log file configure my apps to write to this log   Which translates into:  LOGGING = {     'version': 1,     'disable_existing_loggers': False,     'formatters': {         'verbose': {             'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'         },         'simple': {             'format': '%(levelname)s %(message)s'         },     },     'filters': {         'require_debug_false': {             '()': 'django.utils.log.RequireDebugFalse'         }     },     'handlers': {         'null': {             'level':'DEBUG',             'class':'django.utils.log.NullHandler',         },         'console':{             'level': 'DEBUG',             'class': 'logging.StreamHandler',             'formatter': 'simple'         },         # I always add this handler to facilitate separating loggings         'log_file':{             'level': 'DEBUG',             'class': 'logging.handlers.RotatingFileHandler',             'filename': os.path.join(VAR_ROOT, 'logs/django.log'),             'maxBytes': '16777216', # 16megabytes             'formatter': 'verbose'         },         'mail_admins': {             'level': 'ERROR',             'filters': ['require_debug_false'],             'class': 'django.utils.log.AdminEmailHandler',             'include_html': True,         }     },     'loggers': {         'django.request': {             'handlers': ['mail_admins'],             'level': 'ERROR',             'propagate': True,         },         'apps': { # I keep all my of apps under 'apps' folder, but you can also add them one by one, and this depends on how your virtualenv/paths are set             'handlers': ['log_file'],             'level': 'INFO',             'propagate': True,         },     },     # you can also shortcut 'loggers' and just configure logging for EVERYTHING at once     'root': {         'handlers': ['console', 'mail_admins'],         'level': 'INFO'     }, }   edit  See request exceptions are now always logged and Ticket #16288:   I updated the above sample conf to explicitly include the correct filter for mail_admins so that, by default, emails are not sent when debug is True.  You should add a filter:  'filters': {     'require_debug_false': {         '()': 'django.utils.log.RequireDebugFalse'     } },   and apply it to the mail_admins handler:      'mail_admins': {         'level': 'ERROR',         'filters': ['require_debug_false'],         'class': 'django.utils.log.AdminEmailHandler',         'include_html': True,     }   Otherwise the django.core.handers.base.handle_uncaught_exception doesn't pass errors to the 'django.request' logger if settings.DEBUG is True.  If you don't do this in Django 1.5 you'll get a      DeprecationWarning: You have no filters defined on the 'mail_admins' logging handler: adding implicit debug-false-only filter   but things will still work correctly BOTH in django 1.4 and django 1.5.  ** end edit **  That conf is strongly inspired by the sample conf in the django doc, but adding the log file part.  I often also do the following:  LOG_LEVEL = 'DEBUG' if DEBUG else 'INFO'  ...     'level': LOG_LEVEL ...   Then in my python code I always add a NullHandler in case no logging conf is defined whatsoever. This avoid warnings for no Handler specified. Especially useful for libs that are not necessarily called only in Django (ref)  import logging # Get an instance of a logger logger = logging.getLogger(__name__) class NullHandler(logging.Handler): #exists in python 3.1     def emit(self, record):         pass nullhandler = logger.addHandler(NullHandler())  # here you can also add some local logger should you want: to stdout with streamhandler, or to a local file...   [...]  logger.warning('etc.etc.')   Hope this helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/1598823/elegant-setup-of-python-logging-in-django",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have yet to find a way of setting up Python logging with Django that I'm happy with. My requirements are fairly simple:   Different log handlers for different events - that is, I want to be able to log to different files Easy access to loggers in my modules. The module should be able to find its logger with little effort. Should be easily applicable to command-line modules. Parts of the system are stand-alone command line or daemon processes. Logging should be easily usable with these modules.   My current setup is to use a logging.conf file and setup logging in each module I log from. It doesn't feel right.   Do you have a logging setup that you like? Please detail it: how do you setup the configuration (do you use logging.conf or set it up in code), where/when do you initiate the loggers, and how do you get access to them in your modules, etc.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Elegant setup of Python logging in Django",
        "A_Content": "  We initialize logging in the top-level urls.py by using a logging.ini file.  The location of the logging.ini is provided in settings.py, but that's all.  Each module then does  logger = logging.getLogger(__name__)   To distinguish testing, development and production instances, we have different logging.ini files.  For the most part, we have a \"console log\" that goes to stderr with Errors only.  We have an \"application log\" that uses a regular rolling log file that goes to a logs directory.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/1598823/elegant-setup-of-python-logging-in-django",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have yet to find a way of setting up Python logging with Django that I'm happy with. My requirements are fairly simple:   Different log handlers for different events - that is, I want to be able to log to different files Easy access to loggers in my modules. The module should be able to find its logger with little effort. Should be easily applicable to command-line modules. Parts of the system are stand-alone command line or daemon processes. Logging should be easily usable with these modules.   My current setup is to use a logging.conf file and setup logging in each module I log from. It doesn't feel right.   Do you have a logging setup that you like? Please detail it: how do you setup the configuration (do you use logging.conf or set it up in code), where/when do you initiate the loggers, and how do you get access to them in your modules, etc.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Elegant setup of Python logging in Django",
        "A_Content": "  I am currently using a logging system, which I created myself. It uses CSV format for logging.  django-csvlog  This project still doesn't have full documentation, but I am working on it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/1598823/elegant-setup-of-python-logging-in-django",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have yet to find a way of setting up Python logging with Django that I'm happy with. My requirements are fairly simple:   Different log handlers for different events - that is, I want to be able to log to different files Easy access to loggers in my modules. The module should be able to find its logger with little effort. Should be easily applicable to command-line modules. Parts of the system are stand-alone command line or daemon processes. Logging should be easily usable with these modules.   My current setup is to use a logging.conf file and setup logging in each module I log from. It doesn't feel right.   Do you have a logging setup that you like? Please detail it: how do you setup the configuration (do you use logging.conf or set it up in code), where/when do you initiate the loggers, and how do you get access to them in your modules, etc.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Django URL Redirect",
        "A_Content": "  You can try the Class Based View called RedirectView  from django.views.generic.base import RedirectView  urlpatterns = patterns('',     url(r'^$', 'macmonster.views.home'),     #url(r'^macmon_home$', 'macmonster.views.home'),     url(r'^macmon_output/$', 'macmonster.views.output'),     url(r'^macmon_about/$', 'macmonster.views.about'),     url(r'^.*$', RedirectView.as_view(url='<url_to_home_view>', permanent=False), name='index') )   Notice how as url in the <url_to_home_view> you need to actually specify the url.  permanent=False will return HTTP 302, while permanent=True will return HTTP 301.  Alternatively you can use django.shortcuts.redirect     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14959217/django-url-redirect",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I redirect traffic that doesnt match any of my other URLs back to the home page. My urls.py looks like,  urlpatterns = patterns('',     url(r'^$', 'macmonster.views.home'),     #url(r'^macmon_home$', 'macmonster.views.home'),     url(r'^macmon_output/$', 'macmonster.views.output'),     url(r'^macmon_about/$', 'macmonster.views.about'),     url(r'^.*$',  'macmonster.views.home'), )   As it stands the last entry sends all \"other\" traffic to the home page but I want to redirect via either a HTTP 301 or 302.  Thanks,     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Django URL Redirect",
        "A_Content": "  In Django 1.8, this is how I did mine.  from django.views.generic.base import RedirectView  url(r'^$', views.comingSoon, name='homepage'), # whatever urls you might have in here # make sure the 'catch-all' url is placed last url(r'^.*$', RedirectView.as_view(pattern_name='homepage', permanent=False))   Instead of using url, you can use the pattern_name, which is a bit un-DRY, and will ensure you change your url, you don't have to change the redirect too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14959217/django-url-redirect",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I redirect traffic that doesnt match any of my other URLs back to the home page. My urls.py looks like,  urlpatterns = patterns('',     url(r'^$', 'macmonster.views.home'),     #url(r'^macmon_home$', 'macmonster.views.home'),     url(r'^macmon_output/$', 'macmonster.views.output'),     url(r'^macmon_about/$', 'macmonster.views.about'),     url(r'^.*$',  'macmonster.views.home'), )   As it stands the last entry sends all \"other\" traffic to the home page but I want to redirect via either a HTTP 301 or 302.  Thanks,     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Django URL Redirect",
        "A_Content": "  If you are stuck on django 1.2 like I am and RedirectView doesn't exist, another route-centric way to add the redirect mapping is using:  (r'^match_rules/$', 'django.views.generic.simple.redirect_to', {'url': '/new_url'}),     You can also re-route everything on a match. This is useful when changing the folder of an app but wanting to preserve bookmarks:  (r'^match_folder/(?P<path>.*)', 'django.views.generic.simple.redirect_to', {'url': '/new_folder/%(path)s'}),     This is preferable to django.shortcuts.redirect if you are only trying to modify your url routing and do not have access to .htaccess, etc (I'm on Appengine and app.yaml doesn't allow url redirection at that level like an .htaccess).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14959217/django-url-redirect",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I redirect traffic that doesnt match any of my other URLs back to the home page. My urls.py looks like,  urlpatterns = patterns('',     url(r'^$', 'macmonster.views.home'),     #url(r'^macmon_home$', 'macmonster.views.home'),     url(r'^macmon_output/$', 'macmonster.views.output'),     url(r'^macmon_about/$', 'macmonster.views.about'),     url(r'^.*$',  'macmonster.views.home'), )   As it stands the last entry sends all \"other\" traffic to the home page but I want to redirect via either a HTTP 301 or 302.  Thanks,     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Django URL Redirect",
        "A_Content": "  Another way of doing it is using HttpResponsePermanentRedirect like so:  In view.py  def url_redirect(request):     return HttpResponsePermanentRedirect(\"/new_url/\")   In the url.py  url(r'^old_url/$', \"website.views.url_redirect\", name=\"url-redirect\"),      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14959217/django-url-redirect",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I redirect traffic that doesnt match any of my other URLs back to the home page. My urls.py looks like,  urlpatterns = patterns('',     url(r'^$', 'macmonster.views.home'),     #url(r'^macmon_home$', 'macmonster.views.home'),     url(r'^macmon_output/$', 'macmonster.views.output'),     url(r'^macmon_about/$', 'macmonster.views.about'),     url(r'^.*$',  'macmonster.views.home'), )   As it stands the last entry sends all \"other\" traffic to the home page but I want to redirect via either a HTTP 301 or 302.  Thanks,     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  for i in ...:     for j in ...:         for k in ...:             if something:                 # continue loop i   In a general case, when you have multiple levels of looping and break does not work for you (because you want to continue one of the upper loops, not the one right above the current one), you can do one of the following  Refactor the loops you want to escape from into a function  def inner():     for j in ...:         for k in ...:             if something:                 return   for i in ...:     inner()   The disadvantage is that you may need to pass to that new function some variables, which were previously in scope. You can either just pass them as parameters, make them instance variables on an object (create a new object just for this function, if it makes sense), or global variables, singletons, whatever (ehm, ehm).  Or you can define inner as a nested function and let it just capture what it needs (may be slower?)  for i in ...:     def inner():         for j in ...:             for k in ...:                 if something:                     return     inner()   Use exceptions  Philosophically, this is what exceptions are for, breaking the program flow through the structured programming building blocks (if, for, while) when necessary.  The advantage is that you don't have to break the single piece of code into multiple parts. This is good if it is some kind of computation that you are designing while writing it in Python. Introducing abstractions at this early point may slow you down.  Bad thing with this approach is that interpreter/compiler authors usually assume that exceptions are exceptional and optimize for them accordingly.  class ContinueI(Exception):     pass   continue_i = ContinueI()  for i in ...:     try:         for j in ...:             for k in ...:                 if something:                     raise continue_i     except ContinueI:         continue   Create a special exception class for this, so that you don't risk accidentally silencing some other exception.  Something else entirely  I am sure there are still other solutions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             break     else:         ...block1...   Break will break the inner loop, and block1 won't be executed (it will run only if the inner loop is exited normally).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  In other languages you can label the loop and break from the labelled loop.  Python Enhancement Proposal (PEP) 3136 suggested adding these to Python but Guido rejected it:     However, I'm rejecting it on the basis that code so complicated to   require this feature is very rare. In most cases there are existing   work-arounds that produce clean code, for example using 'return'.   While I'm sure there are some (rare) real cases where clarity of the   code would suffer from a refactoring that makes it possible to use   return, this is offset by two issues:         The complexity added to the language, permanently. This affects not   only all Python implementations, but also every source analysis tool,   plus of course all documentation for the language.   My expectation that the feature will be abused more than it will be   used right, leading to a net decrease in code clarity (measured across   all Python code written henceforth). Lazy programmers are everywhere,   and before you know it you have an incredible mess on your hands of   unintelligible code.      So if that's what you were hoping for you're out of luck, but look at one of the other answers as there are good options there.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  I think you could do something like this:  for ii in range(200):     restart = False     for jj in range(200, 400):         ...block0...         if something:             restart = True             break     if restart:         continue     ...block1...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  We want to find something and then stop the inner iteration. I use a flag system.  for l in f:     flag = True     for e in r:         if flag==False:continue         if somecondition:             do_something()             flag=False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  I just did something like this. My solution for this was to replace the interior for loop with a list comprehension.   for ii in range(200):     done = any([op(ii, jj) for jj in range(200, 400)])     ...block0...     if done:         continue     ...block1...   where op is some boolean operator acting on a combination of ii and jj. In my case, if any of the operations returned true, I was done.  This is really not that different from breaking the code out into a function, but I thought that using the \"any\" operator to do a logical OR on a list of booleans and doing the logic all in one line was interesting. It also avoids the function call.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  I think one of the easiest ways to achieve this is to replace \"continue\" with \"break\" statement,i.e.  for ii in range(200):  for jj in range(200, 400):     ...block0...     if something:         break  ...block1...          For example, here is the easy code to see how exactly it goes on:  for i in range(10):     print(\"doing outer loop\")     print(\"i=\",i)     for p in range(10):         print(\"doing inner loop\")         print(\"p=\",p)         if p==3:             print(\"breaking from inner loop\")             break     print(\"doing some code in outer loop\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python: Continuing to next iteration in outer loop",
        "A_Content": "  Another way to deal with this kind of problem is to use Exception().  for ii in range(200):     try:         for jj in range(200, 400):             ...block0...             if something:                 raise Exception()     except Exception:         continue     ...block1...   For example:  for n in range(1,4):     for m in range(1,4):         print n,'-',m   result:      1-1     1-2     1-3     2-1     2-2     2-3     3-1     3-2     3-3   Assuming we want to jump to the outer n loop from m loop if m =3:  for n in range(1,4):     try:         for m in range(1,4):             if m == 3:                 raise Exception()                         print n,'-',m     except Exception:         continue   result:      1-1     1-2     2-1     2-2     3-1     3-2   Reference link:http://www.programming-idioms.org/idiom/42/continue-outer-loop/1264/python     ",
        "Language": "Python",
        "Tags": [
            "python",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/1859072/python-continuing-to-next-iteration-in-outer-loop",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I wanted to know if there are any built-in ways to continue to next iteration in outer loop in python.  For example,  consider the code:  for ii in range(200):     for jj in range(200, 400):         ...block0...         if something:             continue     ...block1...   I want this continue statement to exit the jj loop and goto next item in the ii loop.  I can implement this logic in some other way (by setting a flag variable), but is there an easy way to do this, or is this like asking for too much?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "how to iterate through dictionary in a dictionary in django template?",
        "A_Content": "  Lets say your data is -  data = {'a': [ [1, 2] ], 'b': [ [3, 4] ],'c':[ [5,6]] }  You can use the data.items() method to get the dictionary elements. Note, in django templates we do NOT put (). Also some users mentioned values[0] does not work, if that is the case then try values.items.  <table>     <tr>         <td>a</td>         <td>b</td>         <td>c</td>     </tr>      {% for key, values in data.items %}     <tr>         <td>{{key}}</td>         {% for v in values[0] %}         <td>{{v}}</td>         {% endfor %}     </tr>     {% endfor %} </table>   Am pretty sure you can extend this logic to your specific dict.    To iterate over dict keys in a sorted order - First we sort in python then iterate & render in django template.  return render_to_response('some_page.html', {'data': sorted(data.items())})  In template file:  {% for key, value in data %}     <tr>         <td> Key: {{ key }} </td>          <td> Value: {{ value }} </td>     </tr> {% endfor %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "dictionary",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/8018973/how-to-iterate-through-dictionary-in-a-dictionary-in-django-template",
        "A_Votes": "179",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    My dictionary looks like this(Dictionary within a dictionary):     {'0': {'chosen_unit': , 'cost': Decimal('10.0000'),   'unit__name_abbrev': u'G', 'supplier_supplier': u\"Steve's Meat   Locker\", 'price': Decimal('5.00'), 'supplier_address':   u'No\\r\\naddress here', 'chosen_unit_amount': u'2', 'city_name':   u'Joburg, Central', 'supplier_phone_number': u'02299944444',   'supplier_website': None, 'supplier_price_list': u'',   'supplier_email': u'ss.sss@ssssss.com', 'unit_name': u'Gram',   'name': u'Rump Bone'}}   Now I'm just trying to display the information on my template but I'm struggling. My code for the template looks like:          {% if landing_dict.ingredients %}             <hr>             {% for ingredient in landing_dict.ingredients %}                 {{ ingredient }}             {% endfor %}             <a href=\"/\">Print {{ landing_dict.recipe_name }}</a>         {% else %}             Please search for an ingredient below         {% endif %}   It just shows me '0' on my template?  I also tried:               {% for ingredient in landing_dict.ingredients %}                 {{ ingredient.cost }}             {% endfor %}   This doesn't even display a result.  I thought perhaps I need to iterate one level deeper so tried this:          {% if landing_dict.ingredients %}             <hr>             {% for ingredient in landing_dict.ingredients %}                 {% for field in ingredient %}                     {{ field }}                 {% endfor %}             {% endfor %}             <a href=\"/\">Print {{ landing_dict.recipe_name }}</a>         {% else %}             Please search for an ingredient below         {% endif %}   But this doesn't display anything.  What am I doing wrong?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "how to convert a string date into datetime format in python? [duplicate]",
        "A_Content": "  The particular format for strptime:  datetime.datetime.strptime(string_date, \"%Y-%m-%d %H:%M:%S.%f\") #>>> datetime.datetime(2013, 9, 28, 20, 30, 55, 782000)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/19068269/how-to-convert-a-string-date-into-datetime-format-in-python",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Converting string into datetime                                        18 answers                                          How do I convert a a string of datetime into datetime format in python so that it can be compared with another date?  string_date = \"2013-09-28 20:30:55.78200\" abc = datetime.datetime.now()  if abc  > string_date :     print True      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "how to convert a string date into datetime format in python? [duplicate]",
        "A_Content": "  You should use datetime.datetime.strptime:  import datetime  dt = datetime.datetime.strptime(string_date, fmt)   fmt will need to be the appropriate format for your string. You'll find the reference on how to build your format here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/19068269/how-to-convert-a-string-date-into-datetime-format-in-python",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Converting string into datetime                                        18 answers                                          How do I convert a a string of datetime into datetime format in python so that it can be compared with another date?  string_date = \"2013-09-28 20:30:55.78200\" abc = datetime.datetime.now()  if abc  > string_date :     print True      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  From the Django documentation:  MAYBECHOICE = (     ('y', 'Yes'),     ('n', 'No'),     ('u', 'Unknown'), )   And you define a charfield in your model :  married = models.CharField(max_length=1, choices=MAYBECHOICE)   You can do the same with integer fields if you don't like to have letters in your db.  In that case, rewrite your choices:  MAYBECHOICE = (     (0, 'Yes'),     (1, 'No'),     (2, 'Unknown'), )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  from django.db import models  class EnumField(models.Field):     \"\"\"     A field class that maps to MySQL's ENUM type.      Usage:      class Card(models.Model):         suit = EnumField(values=('Clubs', 'Diamonds', 'Spades', 'Hearts'))      c = Card()     c.suit = 'Clubs'     c.save()     \"\"\"     def __init__(self, *args, **kwargs):         self.values = kwargs.pop('values')         kwargs['choices'] = [(v, v) for v in self.values]         kwargs['default'] = self.values[0]         super(EnumField, self).__init__(*args, **kwargs)      def db_type(self):         return \"enum({0})\".format( ','.join(\"'%s'\" % v for v in self.values) )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  Using the choices parameter won't use the ENUM db type; it will just create a VARCHAR or INTEGER, depending on whether you use choices with a CharField or IntegerField.  Generally, this is just fine.  If it's important to you that the ENUM type is used at the database level, you have three options:   Use \"./manage.py sql appname\" to see the SQL Django generates, manually modify it to use the ENUM type, and run it yourself.  If you create the table manually first, \"./manage.py syncdb\" won't mess with it. If you don't want to do this manually every time you generate your DB, put some custom SQL in appname/sql/modelname.sql to perform the appropriate ALTER TABLE command. Create a custom field type and define the db_type method appropriately.   With any of these options, it would be your responsibility to deal with the implications for cross-database portability.  In option 2, you could use database-backend-specific custom SQL to ensure your ALTER TABLE is only run on MySQL.  In option 3, your db_type method would need to check the database engine and set the db column type to a type that actually exists in that database.  UPDATE: Since the migrations framework was added in Django 1.7, options 1 and 2 above are entirely obsolete. Option 3 was always the best option anyway. The new version of options 1/2 would involve a complex custom migration using SeparateDatabaseAndState -- but really you want option 3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  Setting choices on the field will allow some validation on the Django end, but it won't define any form of an enumerated type on the database end.  As others have mentioned, the solution is to specify db_type on a custom field.  If you're using a SQL backend (e.g. MySQL), you can do this like so:  from django.db import models   class EnumField(models.Field):     def __init__(self, *args, **kwargs):         super(EnumField, self).__init__(*args, **kwargs)         assert self.choices, \"Need choices for enumeration\"      def db_type(self, connection):         if not all(isinstance(col, basestring) for col, _ in self.choices):             raise ValueError(\"MySQL ENUM values should be strings\")         return \"ENUM({})\".format(','.join(\"'{}'\".format(col)                                            for col, _ in self.choices))   class IceCreamFlavor(EnumField, models.CharField):     def __init__(self, *args, **kwargs):         flavors = [('chocolate', 'Chocolate'),                    ('vanilla', 'Vanilla'),                   ]         super(IceCreamFlavor, self).__init__(*args, choices=flavors, **kwargs)   class IceCream(models.Model):     price = models.DecimalField(max_digits=4, decimal_places=2)     flavor = IceCreamFlavor(max_length=20)   Run syncdb, and inspect your table to see that the ENUM was created properly.  mysql> SHOW COLUMNS IN icecream; +--------+-----------------------------+------+-----+---------+----------------+ | Field  | Type                        | Null | Key | Default | Extra          | +--------+-----------------------------+------+-----+---------+----------------+ | id     | int(11)                     | NO   | PRI | NULL    | auto_increment | | price  | decimal(4,2)                | NO   |     | NULL    |                | | flavor | enum('chocolate','vanilla') | NO   |     | NULL    |                | +--------+-----------------------------+------+-----+---------+----------------+      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  http://www.b-list.org/weblog/2007/nov/02/handle-choices-right-way/   class Entry(models.Model):     LIVE_STATUS = 1     DRAFT_STATUS = 2     HIDDEN_STATUS = 3     STATUS_CHOICES = (         (LIVE_STATUS, 'Live'),         (DRAFT_STATUS, 'Draft'),         (HIDDEN_STATUS, 'Hidden'),     )     # ...some other fields here...     status = models.IntegerField(choices=STATUS_CHOICES, default=LIVE_STATUS)  live_entries = Entry.objects.filter(status=Entry.LIVE_STATUS) draft_entries = Entry.objects.filter(status=Entry.DRAFT_STATUS)  if entry_object.status == Entry.LIVE_STATUS:    This is another nice and easy way of implementing enums although it doesn't really save enums in the database.  However it does allow you to reference the 'label' whenever querying or specifying defaults as opposed to the top-rated answer where you have to use the 'value' (which may be a number).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  If you really want to use your databases ENUM type:   Use Django 1.x Recognize your application will only work on some databases. Puzzle through this documentation page:http://docs.djangoproject.com/en/dev/howto/custom-model-fields/#howto-custom-model-fields   Good luck!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  There're currently two github projects based on adding these, though I've not looked into exactly how they're implemented:   Django-EnumField: Provides an enumeration Django model field (using IntegerField) with reusable enums and transition validation.  Django-EnumFields: This package lets you use real Python (PEP435-style) enums with Django.   I don't think either use DB enum types, but they are in the works for first one.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Specifying a mySQL ENUM in a Django model",
        "A_Content": "  A the top of your models.py file, add this line after you do your imports:      enum = lambda *l: [(s,_(s)) for s in l]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django",
            "django-models",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/21454/specifying-a-mysql-enum-in-a-django-model",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I go about specifying and using an ENUM in a Django model?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  In general, for any thread safety problem you will need to protect your internal data structures with locks. This can be done with various levels of granularity.   You can use fine-grained locking, where every separate structure has its own lock. You can use coarse-grained locking where one lock protects everything (the GIL approach).   There are various pros and cons of each method.  Fine-grained locking allows greater parallelism - two threads can execute in parallel when they don't share any resources.  However there is a much larger administrative overhead.  For every line of code, you may need to acquire and release several locks.  The coarse grained approach is the opposite.  Two threads can't run at the same time, but an individual thread will run faster because its not doing so much bookkeeping.  Ultimately it comes down to a tradeoff between single-threaded speed and parallelism.  There have been a few attempts to remove the GIL in python, but the extra overhead for single threaded machines was generally too large.  Some cases can actually be slower even on multi-processor machines due to lock contention.       Do other languages that are compiled to bytecode employ a similar mechanism?   It varies, and it probably shouldn't be considered a language property so much as an implementation property. For instance, there are Python implementations such as Jython and IronPython which use the threading approach of their underlying VM, rather than a GIL approach. Additionally, the next version of Ruby looks to be moving towards introducing a GIL.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  The following is from the official Python/C API Reference Manual:     The Python interpreter is not fully   thread safe. In order to support   multi-threaded Python programs,   there's a global lock that must be   held by the current thread before it   can safely access Python objects.   Without the lock, even the simplest   operations could cause problems in a   multi-threaded program: for example,   when two threads simultaneously   increment the reference count of the   same object, the reference count could   end up being incremented only once   instead of twice.       Therefore, the rule exists that only   the thread that has acquired the   global interpreter lock may operate on   Python objects or call Python/C API   functions. In order to support   multi-threaded Python programs, the   interpreter regularly releases and   reacquires the lock -- by default,   every 100 bytecode instructions (this   can be changed with   sys.setcheckinterval()). The lock is   also released and reacquired around   potentially blocking I/O operations   like reading or writing a file, so   that other threads can run while the   thread that requests the I/O is   waiting for the I/O operation to   complete.   I think it sums up the issue pretty well.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  The global interpreter lock is a big mutex-type lock that protects reference counters from getting hosed.  If you are writing pure python code, this all happens behind the scenes, but if you embedding Python into C, then you might have to explicitly take/release the lock.  This mechanism is not related to Python being compiled to bytecode.  It's not needed for Java.  In fact, it's not even needed for Jython (python compiled to jvm).  see also this question     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  Python, like perl 5, was not designed from the ground up to be thread safe. Threads were grafted on after the fact, so the global interpreter lock is used to maintain mutual exclusion to where only one thread is executing code at a given time in the bowels of the interpreter.  Individual Python threads are cooperatively multitasked by the interpreter itself by cycling the lock every so often.  Grabbing the lock yourself is needed when you are talking to Python from C when other Python threads are active to 'opt in' to this protocol and make sure that nothing unsafe happens behind your back.  Other systems that have a single-threaded heritage that later evolved into mulithreaded systems often have some mechanism of this sort. For instance, the Linux kernel has the \"Big Kernel Lock\" from its early SMP days. Gradually over time as multi-threading performance becomes an issue there is a tendency to try to break these sorts of locks up into smaller pieces or replace them with lock-free algorithms and data structures where possible to maximize throughput.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  Regarding your second question, not all scripting languages use this, but it only makes them less powerful. For instance, the threads in Ruby are green and not native.  In Python, the threads are native and the GIL only prevents them from running on different cores.  In Perl, the threads are even worse. They just copy the whole interpreter, and are far from being as usable as in Python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why the Global Interpreter Lock?",
        "A_Content": "  Maybe this article by the BDFL will help.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "scripting",
            "locking",
            "bytecode"
        ],
        "URL": "https://stackoverflow.com/questions/265687/why-the-global-interpreter-lock",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is exactly the function of Python's Global Interpreter Lock? Do other languages that are compiled to bytecode employ a similar mechanism?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  In your particular case it looks like you're trying to import SomeObject from the myapp.py and TestCase.py scripts. From myapp.py, do  import SomeObject   since it is in the same folder. For TestCase.py, do  from ..myapp import SomeObject   However, this will work only if you are importing TestCase from the package. If you want to directly run python TestCase.py, you would have to mess with your path. This can be done within Python:  import sys sys.path.append(\"..\") from myapp import SomeObject   though that is generally not recommended.  In general, if you want other people to use your Python package, you should use distutils to create a setup script. That way, anyone can install your package easily using a command like python setup.py install and it will be available everywhere on their machine. If you're serious about the package, you could even add it to the Python Package Index, PyPI.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  The function import looks for files into your PYTHONPATH env. variable and your local directory. So you can either put all your files in the same directory, or export the path typing into a terminal::  export PYTHONPATH=\"$PYTHONPATH:/path_to_myapp/myapp/myapp/\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  exporting path is a good way.  Another way is to add a .pth to your site-packages location.    On my mac my python keeps site-packages in /Library/Python shown below  /Library/Python/2.7/site-packages   I created a file called awesome.pth at /Library/Python/2.7/site-packages/awesome.pth and in the file put the following path that references my awesome modules  /opt/awesome/custom_python_modules      ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  You can try  from myapp.myapp import SomeObject   because your project name is the same as the myapp.py which makes it search the project document first     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  In your first myapp directory ,u can add a setup.py file and add two python code in setup.py  from setuptools import setup setup(name='myapp')   in your first myapp directory in commandline , use  pip install -e .  to install the package         ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  In my case it was Windows vs Python surprise, despite Windows filenames are not case sensitive, Python import is. So if you have Stuff.py file you need to import this name as-is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Can't import my own modules in Python",
        "A_Content": "  pip install on Windows 10 defaults to installing in 'Program Files/PythonXX/Lib/site-packages' which is a directory that requires administrative privileges. So I fixed my issue by  running pip install as Administrator (you have to open command prompt as administrator even if you are logged in with an admin account). Also, it is safer to call pip from python. e.g. python -m pip install <package-name> instead of pip install <package-name>     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import",
            "module",
            "package"
        ],
        "URL": "https://stackoverflow.com/questions/9383014/cant-import-my-own-modules-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a hard time understanding how module importing works in Python (I've never done it in any other language before either).  Let's say I have:  myapp/__init__.py myapp/myapp/myapp.py myapp/myapp/SomeObject.py myapp/tests/TestCase.py   Now I'm trying to get something like this:  myapp.py =================== from myapp import SomeObject # stuff ...  TestCase.py =================== from myapp import SomeObject # some tests on SomeObject   However, I'm definitely doing something wrong as Python can't see that myapp is a module:  ImportError: No module named myapp      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Having options in argparse with a dash",
        "A_Content": "  As indicated in the argparse docs:     For optional argument actions, the value of dest is normally inferred from the option strings. ArgumentParser generates the value of dest by taking the first long option string and stripping away the initial -- string. Any internal - characters will be converted to _ characters to make sure the string is a valid attribute name   So you should be using args.pm_export.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/12834785/having-options-in-argparse-with-a-dash",
        "A_Votes": "115",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to have some options in argparse module such as --pm-export however when I try to use it like args.pm-export I get the error that there is not attribute pm. How can I get around this issue? Is it possible to have - in command line options?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Having options in argparse with a dash",
        "A_Content": "  Unfortunately, dash-to-underscore replacement doesn't work for positionalarguments (not prefixed by --) like  parser = argparse.ArgumentParser(description='Process some integers.') parser.add_argument('logs-dir',                     help='Directory with .log and .log.gz files') parser.add_argument('results-csv', type=argparse.FileType('w'),                     default=sys.stdout,                     help='Output .csv filename') args = parser.parse_args() print args  # gives # Namespace(logs-dir='./', results-csv=<open file 'lool.csv', mode 'w' at 0x9020650>)   So, you should use 1'st argument to add_argument() as attribute name and metavar kwarg to set how it should look in help:  parser = argparse.ArgumentParser(description='Process some integers.') parser.add_argument('logs_dir', metavar='logs-dir',                     nargs=1,                     help='Directory with .log and .log.gz files') parser.add_argument('results_csv', metavar='results-csv',                     nargs=1,                     type=argparse.FileType('w'),                     default=sys.stdout,                     help='Output .csv filename') args = parser.parse_args() print args  # gives # Namespace(logs_dir=['./'], results_csv=[<open file 'lool.csv', mode 'w' at 0xb71385f8>])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/12834785/having-options-in-argparse-with-a-dash",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have some options in argparse module such as --pm-export however when I try to use it like args.pm-export I get the error that there is not attribute pm. How can I get around this issue? Is it possible to have - in command line options?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Having options in argparse with a dash",
        "A_Content": "  Dashes are converted to underscores:  import argparse pa = argparse.ArgumentParser() pa.add_argument('--foo-bar') args = pa.parse_args(['--foo-bar', '24']) print args # Namespace(foo_bar='24')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/12834785/having-options-in-argparse-with-a-dash",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have some options in argparse module such as --pm-export however when I try to use it like args.pm-export I get the error that there is not attribute pm. How can I get around this issue? Is it possible to have - in command line options?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do you do a simple “chmod +x” from within python?",
        "A_Content": "  Use os.stat() to get the current permissions, use | to or the bits together, and use os.chmod() to set the updated permissions.  Example:  import os import stat  st = os.stat('somefile') os.chmod('somefile', st.st_mode | stat.S_IEXEC)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "chmod"
        ],
        "URL": "https://stackoverflow.com/questions/12791997/how-do-you-do-a-simple-chmod-x-from-within-python",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to create a file from within a python script that is executable.  import os import stat os.chmod('somefile', stat.S_IEXEC)   it appears os.chmod doesn't 'add' permissions the way unix chmod does. With the last line commented out, the file has the filemode -rw-r--r--, with it not commented out, the file mode is ---x------. How can I just add the u+x flag while keeping the rest of the modes intact?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do you do a simple “chmod +x” from within python?",
        "A_Content": "  For tools that generate executable files (e.g. scripts), the following code might be helpful:  def make_executable(path):     mode = os.stat(path).st_mode     mode |= (mode & 0o444) >> 2    # copy R bits to X     os.chmod(path, mode)   This makes it (more or less) respect the umask that was in effect when the file was created: Executable is only set for those that can read.  Usage:  path = 'foo.sh' with open(path, 'w') as f:           # umask in effect when file is created     f.write('#!/bin/sh\\n')     f.write('echo \"hello world\"\\n')  make_executable(path)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "chmod"
        ],
        "URL": "https://stackoverflow.com/questions/12791997/how-do-you-do-a-simple-chmod-x-from-within-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a file from within a python script that is executable.  import os import stat os.chmod('somefile', stat.S_IEXEC)   it appears os.chmod doesn't 'add' permissions the way unix chmod does. With the last line commented out, the file has the filemode -rw-r--r--, with it not commented out, the file mode is ---x------. How can I just add the u+x flag while keeping the rest of the modes intact?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do you do a simple “chmod +x” from within python?",
        "A_Content": "  If you know the permissions you want then the following example may be the way to keep it simple.  Python 2:  os.chmod(\"/somedir/somefile\", 0775)   Python 3:  os.chmod(\"/somedir/somefile\", 0o775)   Compatible with either (octal conversion):  os.chmod(\"/somedir/somefile\", 509)   reference permissions examples     ",
        "Language": "Python",
        "Tags": [
            "python",
            "chmod"
        ],
        "URL": "https://stackoverflow.com/questions/12791997/how-do-you-do-a-simple-chmod-x-from-within-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a file from within a python script that is executable.  import os import stat os.chmod('somefile', stat.S_IEXEC)   it appears os.chmod doesn't 'add' permissions the way unix chmod does. With the last line commented out, the file has the filemode -rw-r--r--, with it not commented out, the file mode is ---x------. How can I just add the u+x flag while keeping the rest of the modes intact?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do you do a simple “chmod +x” from within python?",
        "A_Content": "  You can also do this  >>> import os >>> st = os.stat(\"hello.txt\")   Current listing of file  $ ls -l hello.txt -rw-r--r--  1 morrison  staff  17 Jan 13  2014 hello.txt   Now do this.  >>> os.chmod(\"hello.txt\", st.st_mode | 0o111)   and you will see this in the terminal.  ls -l hello.txt     -rwxr-xr-x  1 morrison  staff  17 Jan 13  2014 hello.txt   You can bitwise or with 0o111 to make all executable, 0o222 to make all writable, and 0o444 to make all readable.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "chmod"
        ],
        "URL": "https://stackoverflow.com/questions/12791997/how-do-you-do-a-simple-chmod-x-from-within-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a file from within a python script that is executable.  import os import stat os.chmod('somefile', stat.S_IEXEC)   it appears os.chmod doesn't 'add' permissions the way unix chmod does. With the last line commented out, the file has the filemode -rw-r--r--, with it not commented out, the file mode is ---x------. How can I just add the u+x flag while keeping the rest of the modes intact?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do I go straight to template, in Django's urls.py?",
        "A_Content": "  Django 2.0+  Use the class based generic views but register with the django 2.0+ pattern.  from django.urls import include, path from django.views.generic import TemplateView  urlpatterns = [     path('foo/', TemplateView.as_view(template_name='foo.html')) ]   https://docs.djangoproject.com/en/2.0/ref/class-based-views/base/#templateview  Django 1.5+  Use the class based generic views.  from django.views.generic import TemplateView  urlpatterns = patterns('',     (r'^foo/$', TemplateView.as_view(template_name='foo.html')), )   Django <= 1.4  Docs: https://docs.djangoproject.com/en/1.4/ref/generic-views/#django-views-generic-simple-direct-to-template  urlpatterns = patterns('django.views.generic.simple',     (r'^foo/$',             'direct_to_template', {'template': 'foo_index.html'}),     (r'^foo/(?P<id>\\d+)/$', 'direct_to_template', {'template': 'foo_detail.html'}), )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/5201346/how-do-i-go-straight-to-template-in-djangos-urls-py",
        "A_Votes": "217",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Instead of going to views.py, I want it to go to to a template, robots.txt.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do I go straight to template, in Django's urls.py?",
        "A_Content": "  A further update for more recent versions and including mime type from this site:  http://www.techstricks.com/adding-robots-txt-to-your-django-project/  from django.conf.urls import url from django.views.generic import TemplateView  urlpatterns = [     #... your project urls     url(r'^robots.txt$', TemplateView.as_view(template_name=\"robots.txt\", content_type=\"text/plain\"), name=\"robots_file\") ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/5201346/how-do-i-go-straight-to-template-in-djangos-urls-py",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Instead of going to views.py, I want it to go to to a template, robots.txt.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'strptime'",
        "A_Content": "  If I had to guess, you did this:  import datetime   at the top of your code.  This means that you have to do this:  datetime.datetime.strptime(date, \"%Y-%m-%d\")   to access the strptime method.  Or, you could change the import statement to this:  from datetime import datetime   and access it as you are.  The people who made the datetime module also named their class datetime:  #module  class    method datetime.datetime.strptime(date, \"%Y-%m-%d\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/19480028/attributeerror-module-object-has-no-attribute-strptime",
        "A_Votes": "220",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Here is my Transaction class:  class Transaction(object):     def __init__(self, company, num, price, date, is_buy):         self.company = company         self.num = num         self.price = price         self.date = datetime.strptime(date, \"%Y-%m-%d\")         self.is_buy = is_buy   And when I'm trying to run the date function:  tr = Transaction('AAPL', 600, '2013-10-25') print tr.date   I'm getting the following error:     self.date = datetime.strptime(self.d, \"%Y-%m-%d\")  AttributeError: 'module' object has no attribute 'strptime'   How can I fix that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'strptime'",
        "A_Content": "  Use the correct call: strptime is a classmethod of the datetime.datetime class, it's not a function in the datetime module.  self.date = datetime.datetime.strptime(self.d, \"%Y-%m-%d\")     As mentioned by Jon Clements in the comments, some people do from datetime import datetime, which would bind the datetime name to the datetime class, and make your initial code work.  To identify which case you're facing (in the future), look at your import statements   import datetime: that's the module (that's what you have right now). from datetime import datetime: that's the class.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/19480028/attributeerror-module-object-has-no-attribute-strptime",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my Transaction class:  class Transaction(object):     def __init__(self, company, num, price, date, is_buy):         self.company = company         self.num = num         self.price = price         self.date = datetime.strptime(date, \"%Y-%m-%d\")         self.is_buy = is_buy   And when I'm trying to run the date function:  tr = Transaction('AAPL', 600, '2013-10-25') print tr.date   I'm getting the following error:     self.date = datetime.strptime(self.d, \"%Y-%m-%d\")  AttributeError: 'module' object has no attribute 'strptime'   How can I fix that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  The simplest is to convert to a set then back to a list:  my_list = list(set(my_list))   One disadvantage with this is that it won't preserve the order. You may also want to consider if a set would be a better data structure to use in the first place, instead of a list.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "174",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  Modified versions of http://www.peterbe.com/plog/uniqifiers-benchmark  To preserve the order:  def f(seq): # Order preserving   ''' Modified version of Dave Kirby solution '''   seen = set()   return [x for x in seq if x not in seen and not seen.add(x)]   OK, now how does it work, because it's a little bit tricky here if x not in seen and not seen.add(x):  In [1]: 0 not in [1,2,3] and not print('add') add Out[1]: True   Why does it return True? print (and set.add) returns nothing:  In [3]: type(seen.add(10)) Out[3]: <type 'NoneType'>   and not None == True, but:  In [2]: 1 not in [1,2,3] and not print('add') Out[2]: False   Why does it print 'add' in [1] but not in [2]? See False and print('add'), and doesn't check the second argument, because it already knows the answer, and returns true only if both arguments are True.  More generic version, more readable, generator based, adds the ability to transform values with a function:  def f(seq, idfun=None): # Order preserving   return list(_f(seq, idfun))  def _f(seq, idfun=None):     ''' Originally proposed by Andrew Dalke '''   seen = set()   if idfun is None:     for x in seq:       if x not in seen:         seen.add(x)         yield x   else:     for x in seq:       x = idfun(x)       if x not in seen:         seen.add(x)         yield x   Without order (it's faster):  def f(seq): # Not order preserving   return list(set(seq))      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  one-liner and preserve order  list(OrderedDict.fromkeys([2,1,1,3]))   although you'll need  from collections import OrderedDict      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  To preserve the order:  l = [1, 1, 2, 2, 3] result = list() map(lambda x: not x in result and result.append(x), l) result # [1, 2, 3]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  Let me explain to you by an example:  if you have Python list  >>> randomList = [\"a\",\"f\", \"b\", \"c\", \"d\", \"a\", \"c\", \"e\", \"d\", \"f\", \"e\"]   and you want to remove duplicates from it.  >>> uniqueList = []  >>> for letter in randomList:     if letter not in uniqueList:         uniqueList.append(letter)  >>> uniqueList ['a', 'f', 'b', 'c', 'd', 'e']   This is how you can remove duplicates from the list.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  How about dictionary comprehensions?  >>> mylist = [3, 2, 1, 3, 4, 4, 4, 5, 5, 3]  >>> {x:1 for x in mylist}.keys() [1, 2, 3, 4, 5]   EDIT To @Danny's comment: my original suggestion does not keep the keys ordered. If you need the keys sorted, try:  >>> from collections import OrderedDict  >>> OrderedDict( (x,1) for x in mylist ).keys() [3, 2, 1, 4, 5]   which keeps elements in the order by the first occurrence of the element (not extensively tested)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  From http://www.peterbe.com/plog/uniqifiers-benchmark:  def f5(seq, idfun=None):       # order preserving     if idfun is None:         def idfun(x): return x     seen = {}     result = []     for item in seq:         marker = idfun(item)         # in old Python versions:         # if seen.has_key(marker)         # but in new ones:         if marker in seen: continue         seen[marker] = 1         result.append(item)     return result      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  If all elements of the list may be used as dictionary keys (i.e. they are all hashable) this is often faster. Python Programming FAQ  d = {} for x in mylist:     d[x] = 1 mylist = list(d.keys())      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  The simplest way to remove duplicates whilst preserving order is to use collections.OrderedDict (Python 2.7+).  from collections import OrderedDict d = OrderedDict() for x in mylist:     d[x] = True print d.iterkeys()      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make lists contain only distinct element in Python? [duplicate]",
        "A_Content": "  The characteristics of sets in Python are that the data items in a set are unordered and duplicates are not allowed. If you try to add a data item to a set that already contains the data item, Python simply ignores it.  >>> l = ['a', 'a', 'bb', 'b', 'c', 'c', '10', '10', '8','8', 10, 10, 6, 10, 11.2, 11.2, 11, 11] >>> distinct_l = set(l) >>> print(distinct_l) set(['a', '10', 'c', 'b', 6, 'bb', 10, 11, 11.2, '8'])      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Removing duplicates in lists                                        39 answers                                          I have a list in Python, how can I make it's values unique?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make inline plots in Jupyter Notebook larger?",
        "A_Content": "  Yes, play with figuresize like so (before you call your subplot):  fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/36367986/how-to-make-inline-plots-in-jupyter-notebook-larger",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have made my plots inline on my Ipython Notebook with \"%matplotlib inline.\"  Now, the plot appears.  However, it is very small.  Is there a way to make it appear larger using either notebook settings or plot settings?       ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make inline plots in Jupyter Notebook larger?",
        "A_Content": "  The default figure size (in inches) is controlled by  matplotlib.rcParams['figure.figsize'] = [width, height]   For example:  import matplotlib.pyplot as plt plt.rcParams['figure.figsize'] = [10, 5]   creates a figure with 10 (width) x 5 (height) inches     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/36367986/how-to-make-inline-plots-in-jupyter-notebook-larger",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have made my plots inline on my Ipython Notebook with \"%matplotlib inline.\"  Now, the plot appears.  However, it is very small.  Is there a way to make it appear larger using either notebook settings or plot settings?       ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make inline plots in Jupyter Notebook larger?",
        "A_Content": "  I have found that %matplotlib notebook works better for me than inline with Jupyter notebooks.  Note that you may need to restart the kernel if you were using %matplotlib inline before.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/36367986/how-to-make-inline-plots-in-jupyter-notebook-larger",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have made my plots inline on my Ipython Notebook with \"%matplotlib inline.\"  Now, the plot appears.  However, it is very small.  Is there a way to make it appear larger using either notebook settings or plot settings?       ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to make inline plots in Jupyter Notebook larger?",
        "A_Content": "  The question is about matplotlib, but for the sake of any R users that end up here given the language-agnostic title:  If you're using an R kernel, just use:  options(repr.plot.width=4, repr.plot.height=3)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/36367986/how-to-make-inline-plots-in-jupyter-notebook-larger",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have made my plots inline on my Ipython Notebook with \"%matplotlib inline.\"  Now, the plot appears.  However, it is very small.  Is there a way to make it appear larger using either notebook settings or plot settings?       ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  You can list all files in the current directory using:  import os for filename in os.listdir(os.getcwd()):    # do your stuff   Or you can list only some files, depending on the file pattern using the glob module:  import glob for filename in glob.glob('*.txt'):    # do your stuff   It doesn't have to be the current directory you can list them in any path you want:  path = '/some/path/to/file'  for filename in os.listdir(path):     # do your stuff  for filename in glob.glob(os.path.join(path, '*.txt')):     # do your stuff   Or you can even use the pipe as you specified using fileinput  import fileinput for line in fileinput.input():     # do your stuff   And then use it with piping:  ls -1 | python parse.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "225",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  you should try using os.walk  yourpath = 'path'  import os for root, dirs, files in os.walk(yourpath, topdown=False):     for name in files:         print(os.path.join(root, name))         stuff     for name in dirs:         print(os.path.join(root, name))         stuff      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  You can actually just use os module to do both:   list all files in a folder sort files by file type, file name etc.    Here's a simple example:  import os #os module imported here location = os.getcwd() # get present working directory location here counter = 0 #keep a count of all files found csvfiles = [] #list to store all csv files found at location filebeginwithhello = [] # list to keep all files that begin with 'hello' otherfiles = [] #list to keep any other file that do not match the criteria  for file in os.listdir(location):     try:         if file.endswith(\".csv\"):             print \"csv file found:\\t\", file             csvfiles.append(str(file))             counter = counter+1          elif file.startswith(\"hello\") and file.endswith(\".csv\"): #because some files may start with hello and also be a csv file             print \"csv file found:\\t\", file             csvfiles.append(str(file))             counter = counter+1          elif file.startswith(\"hello\"):             print \"hello files found: \\t\", file             filebeginwithhello.append(file)             counter = counter+1          else:             otherfiles.append(file)             counter = counter+1     except Exception as e:         raise e         print \"No files found here!\"  print \"Total files found:\\t\", counter     Now you have not only listed all the files in a folder but also have them (optionally) sorted by starting name, file type and others. Just now iterate over each list and do your stuff.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  Easy Solution  If you want to just open all the files in the root of a directory. I've run across this problem a lot of times so I created an easy to use module for both Python 3.5 and Python 2.7. If your Python version is not supported just ask me on GreyCadet IRC and I will add the support.  Installing the module  pip install filemapper   Usage  Consider a directory structure like this and that main.py is your code.  -Program     -resources         nouns.txt         config.dat         help.txt      main.py   Contents of main.py  import filemapper as fm all_files = fm.load('resources') # fm.load('resources','w') will open in write mode for f in all_files:     for i in fm.read(f):print i   This will print out the lines of each file in the resources folder. You can also pass any mode.  Doing more  If you want to do more than just open files using this module then visit the filemapper GitHub Page for more details.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  I was looking for this answer:  import os,glob folder_path = '/some/path/to/file' for filename in glob.glob(os.path.join(folder_path, '*.htm')):   with open(filename, 'r') as f:     text = f.read()     print (filename)     print (len(text))   you can choose as well '*.txt' or other ends of your filename     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to open every file in a folder?",
        "A_Content": "  import pyautogui import keyboard import time import os import pyperclip  os.chdir(\"target directory)  cwd=os.getcwd()  files=[]  for i in os.walk(cwd):     for j in i[2]:         files.append(os.path.abspath(j))  os.startfile(\"C:\\Program Files (x86)\\Adobe\\Acrobat 11.0\\Acrobat\\Acrobat.exe\") time.sleep(1)   for i in files:     print(i)     pyperclip.copy(i)     keyboard.press('ctrl')     keyboard.press_and_release('o')     keyboard.release('ctrl')     time.sleep(1)      keyboard.press('ctrl')     keyboard.press_and_release('v')     keyboard.release('ctrl')     time.sleep(1)     keyboard.press_and_release('enter')     keyboard.press('ctrl')     keyboard.press_and_release('p')     keyboard.release('ctrl')     keyboard.press_and_release('enter')     time.sleep(3)     keyboard.press('ctrl')     keyboard.press_and_release('w')     keyboard.release('ctrl')     pyperclip.copy('')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "pipe",
            "stdout",
            "stdin"
        ],
        "URL": "https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script parse.py, which in the script open a file, say file1, and then do something maybe print out the total number of characters.   filename = 'file1' f = open(filename, 'r') content = f.read() print filename, len(content)   Right now, I am using stdout to direct the result to my output file - output  python parse.py >> output   However, I don't want to do this file by file manually, is there a way to take care of every single file automatically? Like  ls | awk '{print}' | python parse.py >> output    Then the problem is how could I read the file name from standardin?  or there are already some built-in functions to do the ls and those kind of work easily?  Thanks!     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  True is equal to 1.  >>> sum([True, True, False, False, False, True]) 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  list has a count method:  >>> [True,True,False].count(True) 2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "81",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  If you are only concerned with the constant True, a simple sum is fine.  However, keep in mind that in Python other values evaluate as True as well.  A more robust solution would be to use the bool builtin:  >>> l = [1, 2, True, False] >>> sum(bool(x) for x in l) 3   UPDATE: Here's another similarly robust solution that has the advantage of being more transparent:  >>> sum(1 for x in l if x) 3   P.S. Python trivia: True could be true without being 1.  Warning: do not try this at work!  >>> True = 2 >>> if True: print('true') ...  true >>> l = [True, True, False, True] >>> sum(l) 6 >>> sum(bool(x) for x in l) 3 >>> sum(1 for x in l if x) 3   Much more evil:  True = False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  You can use sum():  >>> sum([True, True, False, False, False, True]) 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  Just for completeness' sake (sum is usually preferable), I wanted to mention that we can also use filter to get the truthy values. In the usual case, filter accepts a function as the first argument, but if you pass it None, it will filter for all \"truthy\" values. This feature is somewhat surprising, but is well documented and works in both Python 2 and 3.  The difference between the versions, is that in Python 2 filter returns a list, so we can use len:  >>> bool_list = [True, True, False, False, False, True] >>> filter(None, bool_list) [True, True, True] >>> len(filter(None, bool_list)) 3   But in Python 3, filter returns an iterator, so we can't use len, and if we want to avoid using sum (for any reason) we need to resort to converting the iterator to a list (which makes this much less pretty):  >>> bool_list = [True, True, False, False, False, True] >>> filter(None, bool_list) <builtins.filter at 0x7f64feba5710> >>> list(filter(None, bool_list)) [True, True, True] >>> len(list(filter(None, bool_list))) 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  It is safer to run through bool first. This is easily done:  >>> sum(map(bool,[True, True, False, False, False, True])) 3   Then you will catch everything that Python considers True or False into the appropriate bucket:  >>> allTrue=[True, not False, True+1,'0', ' ', 1, [0], {0:0}, set([0])] >>> list(map(bool,allTrue)) [True, True, True, True, True, True, True, True, True]   If you prefer, you can use a comprehension:  >>> allFalse=['',[],{},False,0,set(),(), not True, True-1] >>> [bool(i) for i in allFalse] [False, False, False, False, False, False, False, False, False]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Counting the number of True Booleans in a Python List",
        "A_Content": "  I prefer len([b for b in boollist if b is True]) (or the generator-expression equivalent), as it's quite self-explanatory. Less 'magical' than the answer proposed by Ignacio Vazquez-Abrams.  Alternatively, you can do this, which still assumes that bool is convertable to int, but makes no assumptions about the value of True: ntrue = sum(boollist) / int(True)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "boolean",
            "counting"
        ],
        "URL": "https://stackoverflow.com/questions/12765833/counting-the-number-of-true-booleans-in-a-python-list",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of Booleans:  [True, True, False, False, False, True]   and I am looking for a way to count the number of True in the list (so in the example above, I want the return to be 3.)  I have found examples of looking for the number of occurrences of specific elements, but is there a more efficient way to do it since I'm working with Booleans? I'm thinking of something analogous to all or any.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  It is easy to install it manually:   Download (there may be newer releases on Python.org):   $ wget https://www.python.org/ftp/python/3.4.3/Python-3.4.3.tar.xz  Unzip  $ tar xf Python-3.*  $ cd Python-3.*  Prepare compilation  $ ./configure  Build  $ make  Install  $ make install   OR if you don't want to overwrite the python executable (safer, at least on some distros yum needs python to be 2.x, such as for RHEL6) - you can install python3.* as a concurrent instance to the system default with an altinstall:  $ make altinstall    Now if you want an alternative installation directory, you can pass --prefix to the configurecommand.  Example: for 'installing' Python in /opt/local, just add --prefix=/opt/local.   After the make install step: In order to use your new Python installation, it could be, that you still have to add the [prefix]/bin to the $PATH and [prefix]/lib to the $LD_LIBRARY_PATH (depending of the --prefix you passed)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "147",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Installing from RPM is generally better, because:   you can install and uninstall (properly) python3. the installation time is way faster. If you work in a cloud environment with multiple VMs, compiling python3 on each VMs is not acceptable.   Solution 1: Red Hat & EPEL repositories  Red Hat has added Python 3.4 for CentOS 6 and 7 through the EPEL repository.  Unfortunately:   pip3 is not bundled in any RPM. You need to install it manually (see below). pyvenv is bugged and doesn't work. You need to use virtualenv.   [EPEL] How to install Python 3.4 on CentOS 6 & 7  sudo yum install -y epel-release sudo yum install -y python34  # Install pip3 sudo yum install -y python34-setuptools  # install easy_install-3.4 sudo easy_install-3.4 pip  # I guess you would like to install virtualenv or virtualenvwrapper sudo pip3 install virtualenv sudo pip3 install virtualenvwrapper   If you want to use pyvenv, you can do the following to install pip3 in your virtualenv:  pyvenv --without-pip my_env curl https://bootstrap.pypa.io/get-pip.py | my_env/bin/python   But if you want to have it out-of-the-box, you can add this bash function (alias) in your .bashrc:  pyvenv() { /usr/bin/pyvenv --without-pip $@; for env in $@; do curl https://bootstrap.pypa.io/get-pip.py | \"$env/bin/python\"; done; }   Solution 2: IUS Community repositories  The IUS Community provides some up-to-date packages for RHEL & CentOS. The guys behind are from Rackspace, so I think that they are quite trustworthy...  https://ius.io/  Check the right repo for you here:  https://ius.io/GettingStarted/  [IUS] How to install Python 3.5 on CentOS 6  sudo yum install -y https://centos6.iuscommunity.org/ius-release.rpm sudo yum install -y python35u python35u-pip  # I guess you would like to install virtualenv or virtualenvwrapper sudo pip3.5 install virtualenv sudo pip3.5 install virtualenvwrapper   Note: you have pyvenv-3.5 available out-of-the-box if you don't want to use virtualenv.  [IUS] How to install Python 3.5 on CentOS 7  sudo yum install -y https://centos7.iuscommunity.org/ius-release.rpm sudo yum install -y python35u python35u-pip  # I guess you would like to install virtualenv or virtualenvwrapper sudo pip3.5 install virtualenv sudo pip3.5 install virtualenvwrapper   Note: you have pyvenv-3.5 available out-of-the-box if you don't want to use virtualenv.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "184",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  In addition to gecco's answer I would change step 3 from:  ./configure   to:  ./configure --prefix=/opt/python3   Then after installation you could also:  # ln -s /opt/python3/bin/python3 /usr/bin/python3   It is to ensure that installation will not conflict with python installed with yum.  See explanation I have found on Internet:  http://www.hosting.com/support/linux/installing-python-3-on-centosredhat-5x-from-source     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Use the SCL repos.  sudo sh -c 'wget -qO- http://people.redhat.com/bkabrda/scl_python33.repo >> /etc/yum.repos.d/scl.repo' sudo yum install python33 scl enable python27   (This last command will have to be run each time you want to use python27 rather than the system default.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  You can download a source RPMs and binary RPMs for RHEL6 / CentOS6 from here  This is a backport from the newest Fedora development source rpm to RHEL6 / CentOS6     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Along with Python 2.7 and 3.3, Red Hat Software Collections now includes Python 3.4 - all work on both RHEL 6 and 7.  RHSCL 2.0 docs are at https://access.redhat.com/documentation/en-US/Red_Hat_Software_Collections/  Plus lot of articles at developerblog.redhat.com.  edit  Follow these instructions to install Python 3.4 on RHEL 6/7 or CentOS 6/7:  # 1. Install the Software Collections tools: yum install scl-utils  # 2. Download a package with repository for your system. #  (See the Yum Repositories on external link. For RHEL/CentOS 6:) wget https://www.softwarecollections.org/en/scls/rhscl/rh-python34/epel-6-x86_64/download/rhscl-rh-python34-epel-6-x86_64.noarch.rpm #  or for RHEL/CentOS 7 wget https://www.softwarecollections.org/en/scls/rhscl/rh-python34/epel-7-x86_64/download/rhscl-rh-python34-epel-7-x86_64.noarch.rpm  # 3. Install the repo package (on RHEL you will need to enable optional channel first): yum install rhscl-rh-python34-*.noarch.rpm  # 4. Install the collection: yum install rh-python34  # 5. Start using software collections: scl enable rh-python34 bash      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Python3 was recently added to EPEL7 as Python34.  There is ongoing (currently) effort to make packaging guidelines about how to package things for Python3 in EPEL7.  See https://bugzilla.redhat.com/show_bug.cgi?id=1219411 and https://lists.fedoraproject.org/pipermail/python-devel/2015-July/000721.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  I was having the same issue using the python 2.7. Follow the below steps to upgrade successfully to 3.6. You can also try this one-   See before upgrading version is 2.x  python --version Python 2.7.5  Use below command to upgrade your python to 3.x version-  yum install python3x  replace x with the version number you want.  i.e. for installing python 3.6 execute  yum install python36  After that if you want to set this python for your default version then in bashrc file add   vi ~/.bashrc      alias python='python3.6'  execute bash command to apply the settings  bash   Now you can see the version below  python --version Python 3.6.3       ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  If you want official RHEL packages you can use RHSCL (Red Hat Software Collections)  More details:   Guide to Python 3.3 in RHSCL 1.1 How to access and download Red Hat Software Collections (RHSCL) and/or Red Hat Developer Toolset (DTS)?   You have to have access to Red Hat Customer Portal to read full articles.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Here are the steps i followed to install Python3:  yum install wget wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0.tar.xz   sudo tar xvf Python-3.*    cd Python-3.*  sudo ./configure --prefix=/opt/python3     sudo make    sudo make install    sudo ln -s /opt/python3/bin/python3 /usr/bin/python3  $ /usr/bin/python3     Python 3.6.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Just to make a very brief self-contained answer to compete with the \"install from source\" suggestions.  The package isn't called python3 but there is one package for each Python3 release.  yum install python36   will get you Python 3.6.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  Three steps using Python 3.5 by Software Collections:  sudo yum install centos-release-scl sudo yum install rh-python35 scl enable rh-python35 bash   Note that sudo is not needed for the last command. Now we can see that python 3 is the default for the current shell:  python --version Python 3.5.1   Simply skip the last command if you'd rather have Python 2 as the default for the current shell.  Now let's say that your Python 3 scripts give you an error like /usr/bin/env: python3: No such file or directory. That's because the installation is usually done to an unusual path:  /opt/rh/rh-python35/root/bin/python3   The above would normally be a symlink. If you want python3 to be automatically added to the $PATH for all users on startup, one way to do this is adding a file like:  sudo vim /etc/profile.d/rh-python35.sh   Which would have something like:  #!/bin/bash  PATH=$PATH:/opt/rh/rh-python35/root/bin/   And now after a reboot, if we do  python3 --version   It should just work. One exception would be an auto-generated user like \"jenkins\" in a Jenkins server which doesn't have a shell. In that case, manually adding the path to $PATH in scripts would be one way to go.  Finally, if you're using sudo pip3 to install packages, but it tells you that pip3 cannot be found, it could be that you have a secure_path in /etc/sudoers. Checking with sudo visudo should confirm that. To temporarily use the standard PATH when running commands you can do, for example:  sudo env \"PATH=$PATH\" pip3 --version   See this question for more details.  NOTE: There is a newer Python 3.6 by Software Collections, but I wouldn't recommend it at this time, because I had major headaches trying to install Pycurl. For Python 3.5 that isn't an issue because I just did sudo yum install sclo-python35-python-pycurl which worked out of the box.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  If you are on RHEL and want a Red Hat supported Python, use Red Hat Software collections (RHSCL). The EPEL and IUS packages are not supported by Red Hat.  Also many of the answers above point to the CentOS software collections. While you can install those, they aren't the Red Hat supported packages for RHEL.    Also, the top voted answer gives bad advice - On RHEL you do not want to change /usr/bin/python, /usr/bin/python2 because you will likely break yum and other RHEL admin tools. Take a look at /bin/yum, it is a Python script that starts with #!/usr/bin/python.  If you compile Python from source, do not do a make install as root.  That will overwrite /usr/bin/python. If you break yum it can be difficult to restore your system.  For more info, see How to install Python 3, pip, venv, virtualenv, and pipenv on RHEL on developers.redhat.com.  It covers installing and using Python 3 from RHSCL, using Python Virtual Environments, and a number of tips for working with software collections and working with Python on RHEL.  In a nutshell, to install Python 3.6 via Red Hat Software Collections:  $ su - # subscription-manager repos --enable rhel-7-server-optional-rpms \\    --enable rhel-server-rhscl-7-rpms # yum -y install @development # yum -y install rh-python36  # yum -y install rh-python36-numpy \\    rh-python36-scipy \\     rh-python36-python-tools \\    rh-python36-python-six   To use a software collection you have to enable it:  scl enable rh-python36 bash   However if you want Python 3 permanently enabled, you can add the following to your ~/.bashrc and then log out and back in again. Now Python 3 is permanently in your path.  # Add RHSCL Python 3 to my login environment source scl_source enable rh-python36   Note: once you do that, typing python now gives you Python 3.6 instead of Python 2.7.  See the above article for all of this and a lot more detail.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  yum install python34.x86_64 works if you have epel-release installed, which this answer explains how to, and I confirmed it worked on RHEL 7.3  $ cat /etc/*-release NAME=\"Red Hat Enterprise Linux Server\" VERSION=\"7.3 (Maipo)  $ type python3 python3 is hashed (/usr/bin/python3)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  For RHEL on Amazon Linux, using python3 I had to do :     sudo yum install python34-devel      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Installing Python 3 on RHEL",
        "A_Content": "  I see all the answers as either asking to compile python3 from code or installing the binary RPM package. Here is another answer to enable EPEL (Extra Packages for Enterprise Linux) and then install python using yum. Steps for RHEL 7.5 (Maipo)  yum install wget –y wget https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm rpm –ivh epel-*.rpm yum install python36   Also see link     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "rhel"
        ],
        "URL": "https://stackoverflow.com/questions/8087184/installing-python-3-on-rhel",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to install python3 on RHEL using the following steps:  yum search python3   Which returned  No matches found for: python3  Followed by:  yum search python   None of the search results contained python3. What should I try next?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  I've only used one, but I've had good results with Michael Foord's Mock: http://www.voidspace.org.uk/python/mock/.  Michael's introduction says it better than I could:     There are already several Python mocking libraries available, so why another one?      Most mocking libraries follow the 'record -> replay' pattern of mocking. I prefer the 'action -> assertion' pattern, which is more readable and intuitive particularly when working with the Python unittest module.      ...      It also provides utility functions / objects to assist with testing, particularly monkey patching.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  Mox, from Google     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  Mocker from Gustavo Niemeyer.  It's not perfect, but it is very powerful and flexible.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  Dingus, by Gary Bernhardt.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  pyDoubles the test doubles framework for Python, by iExpertos.com. It supports mocks, stubs, spies and matchers, including Hamcrest matchers     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  I'm the author for mocktest. I think it's pretty fully featured and easy to use, but I might be biased:  http://gfxmonk.net/dist/doc/mocktest/doc/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is your favorite Python mocking library? [closed]",
        "A_Content": "  I've used pMock in the past, and didn't mind it, it had pretty decent docs too. However, Foord's Mock as mentioned above is also nice.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/98053/what-is-your-favorite-python-mocking-library",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is your single favorite mocking library for Python?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Efficiently applying a function to a grouped pandas DataFrame in parallel",
        "A_Content": "  From the comments above, it seems that this is planned for pandas some time (there's also an interesting-looking rosetta project which I just noticed).  However, until every parallel functionality is incorporated into pandas, I noticed that it's very easy to write efficient & non-memory-copying parallel augmentations to pandas directly using cython + OpenMP and C++.  Here's a short example of writing a parallel groupby-sum, whose use is something like this:  import pandas as pd import para_group_demo  df = pd.DataFrame({'a': [1, 2, 1, 2, 1, 1, 0], 'b': range(7)}) print para_group_demo.sum(df.a, df.b)   and output is:       sum key      0      6 1      11 2      4     Note Doubtlessly, this simple example's functionality will eventually be part of pandas. Some things, however, will be more natural to parallelize in C++ for some time, and it's important to be aware of how easy it is to combine this into pandas.    To do this, I wrote a simple single-source-file extension whose code follows.  It starts with some imports and type definitions  from libc.stdint cimport int64_t, uint64_t from libcpp.vector cimport vector from libcpp.unordered_map cimport unordered_map  cimport cython from cython.operator cimport dereference as deref, preincrement as inc from cython.parallel import prange  import pandas as pd  ctypedef unordered_map[int64_t, uint64_t] counts_t ctypedef unordered_map[int64_t, uint64_t].iterator counts_it_t ctypedef vector[counts_t] counts_vec_t   The C++ unordered_map type is for summing by a single thread, and the vector is for summing by all threads.  Now to the function sum. It starts off with typed memory views for fast access:  def sum(crit, vals):     cdef int64_t[:] crit_view = crit.values     cdef int64_t[:] vals_view = vals.values   The function continues by dividing the semi-equally to the threads (here hardcoded to 4), and having each thread sum the entries in its range:      cdef uint64_t num_threads = 4     cdef uint64_t l = len(crit)     cdef uint64_t s = l / num_threads + 1     cdef uint64_t i, j, e     cdef counts_vec_t counts     counts = counts_vec_t(num_threads)     counts.resize(num_threads)     with cython.boundscheck(False):         for i in prange(num_threads, nogil=True):              j = i * s             e = j + s             if e > l:                 e = l             while j < e:                 counts[i][crit_view[j]] += vals_view[j]                 inc(j)   When the threads have completed, the function merges all the results (from the different ranges) into a single unordered_map:      cdef counts_t total     cdef counts_it_t it, e_it     for i in range(num_threads):         it = counts[i].begin()         e_it = counts[i].end()         while it != e_it:             total[deref(it).first] += deref(it).second             inc(it)           All that's left is to create a DataFrame and return the results:      key, sum_ = [], []     it = total.begin()     e_it = total.end()     while it != e_it:         key.append(deref(it).first)         sum_.append(deref(it).second)         inc(it)      df = pd.DataFrame({'key': key, 'sum': sum_})     df.set_index('key', inplace=True)     return df      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "multiprocessing",
            "shared-memory"
        ],
        "URL": "https://stackoverflow.com/questions/11728836/efficiently-applying-a-function-to-a-grouped-pandas-dataframe-in-parallel",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I often need to apply a function to the groups of a very large DataFrame (of mixed data types) and would like to take advantage of multiple cores.  I can create an iterator from the groups and use the multiprocessing module, but it is not efficient because every group and the results of the function must be pickled for messaging between processes.  Is there any way to avoid the pickling or even avoid the copying of the DataFrame completely? It looks like the shared memory functions of the multiprocessing modules are limited to numpy arrays. Are there any other options?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Public free web services for testing soap client [closed]",
        "A_Content": "  There is a bunch on here:  http://www.webservicex.net/WS/wscatlist.aspx  Just google for \"Free WebService\" or \"Open WebService\" and you'll find tons of open SOAP endpoints.  Remember, you can get a WSDL from any ASMX endpoint by adding ?WSDL to the url.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-services",
            "soap",
            "soappy",
            "zsi"
        ],
        "URL": "https://stackoverflow.com/questions/311654/public-free-web-services-for-testing-soap-client",
        "A_Votes": "72",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Are there any publicly available SOAP 1.2/WSDL 2.0 compliant free web services for testing a Python based soap client library (e.g. Zolera SOAP Infrastructure)?   So far, it appears to me that Google Web API may be the only option.  Otherwise, how can one test a SOAP 1.2 compliant client library?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between Python datetime vs time modules",
        "A_Content": "  the time module is principally for working with unix time stamps; expressed as a floating point number taken to be seconds since the unix epoch.  the datetime module can support many of the same operations, but provides a more object oriented set of types, and also has some limited support for time zones.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "time"
        ],
        "URL": "https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules",
        "A_Votes": "69",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to figure out the differences between the datetime and time modules, and what each should be used for.  I know that datetime provides both dates and time.  What is the use of the time module?  Examples would be appreciated and differences concerning timezones would especially be of interest.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between Python datetime vs time modules",
        "A_Content": "  The time module can be used when you just need the time of a particular record - like lets say you have a seperate table/file for the transactions for each day, then you would just need the time.  However the time datatype is usually used to store the time difference between 2 points of time.  This can also be done using datetime, but if we are only dealing with time for a particular day, then time module can be used.  Datetime is used to store a particular data and time for a record. Like in a rental agency. The due date would be a datetime datatype.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "time"
        ],
        "URL": "https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to figure out the differences between the datetime and time modules, and what each should be used for.  I know that datetime provides both dates and time.  What is the use of the time module?  Examples would be appreciated and differences concerning timezones would especially be of interest.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between Python datetime vs time modules",
        "A_Content": "  If you are interested in timezones, you should consider the use of pytz.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "time"
        ],
        "URL": "https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to figure out the differences between the datetime and time modules, and what each should be used for.  I know that datetime provides both dates and time.  What is the use of the time module?  Examples would be appreciated and differences concerning timezones would especially be of interest.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between Python datetime vs time modules",
        "A_Content": "  Stick to time to prevent DST ambiguity.  Personally, I prefer to use only the system time module in order to prevent ambiguity issues with daylight savings time (DST).  Conversion to any time format including local time from there is pretty easy:  import time t = time.time() t_str = time.strftime('%Y-%m-%d %H:%M %Z', time.localtime(t))   If the system additionally runs the network time protocol (NTP) dæmon, one ends up with a pretty solid time base.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "time"
        ],
        "URL": "https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to figure out the differences between the datetime and time modules, and what each should be used for.  I know that datetime provides both dates and time.  What is the use of the time module?  Examples would be appreciated and differences concerning timezones would especially be of interest.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How does python numpy.where() work?",
        "A_Content": "     How do they achieve internally that you are able to pass something like x > 5 into a method?   The short answer is that they don't.  Any sort of logical operation on a numpy array returns a boolean array. (i.e. __gt__, __lt__, etc all return boolean arrays where the given condition is true).  E.g.   x = np.arange(9).reshape(3,3) print x > 5   yields:  array([[False, False, False],        [False, False, False],        [ True,  True,  True]], dtype=bool)   This is the same reason why something like if x > 5: raises a ValueError if x is a numpy array.  It's an array of True/False values, not a single value.  Furthermore, numpy arrays can be indexed by boolean arrays. E.g. x[x>5] yields [6 7 8], in this case.  Honestly, it's fairly rare that you actually need numpy.where but it just returns the indicies where a boolean array is True.  Usually you can do what you need with simple boolean indexing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/5642457/how-does-python-numpy-where-work",
        "A_Votes": "72",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am playing with numpy and digging through documentation and I have come across some magic. Namely I am talking about numpy.where():  >>> x = np.arange(9.).reshape(3, 3) >>> np.where( x > 5 ) (array([2, 2, 2]), array([0, 1, 2]))   How do they achieve internally that you are able to pass something like x > 5 into a method? I guess it has something to do with __gt__ but I am looking for a detailed explanation.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How does python numpy.where() work?",
        "A_Content": "  Old Answer it is kind of confusing.  It gives you the LOCATIONS (all of them) of where your statment is true.  so:  >>> a = np.arange(100) >>> np.where(a > 30) (array([31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,        65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,        99]),) >>> np.where(a == 90) (array([90]),)  a = a*40 >>> np.where(a > 1000) (array([26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,        43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,        77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,        94, 95, 96, 97, 98, 99]),) >>> a[25] 1000 >>> a[26] 1040   I use it as an alternative to list.index(), but it has many other uses as well.  I have never used it with 2D arrays.  http://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html  New Answer It seems that the person was asking something more fundamental.  The question was how could YOU implement something that allows a function (such as where) to know what was requested.  First note that calling any of the comparison operators do an interesting thing.  a > 1000 array([False, False, False, False, False, False, False, False, False,        False, False, False, False, False, False, False, False, False,        False, False, False, False, False, False, False, False,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True,  True,  True,  True,  True,  True,  True,  True,  True,         True`,  True,  True,  True,  True,  True,  True,  True,  True,  True], dtype=bool)`   This is done by overloading the \"__gt__\" method.  For instance:  >>> class demo(object):     def __gt__(self, item):         print item   >>> a = demo() >>> a > 4 4   As you can see, \"a > 4\" was valid code.  You can get a full list and documentation of all overloaded functions here: http://docs.python.org/reference/datamodel.html  Something that is incredible is how simple it is to do this.  ALL operations in python are done in such a way.  Saying a > b is equivalent to a.gt(b)!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/5642457/how-does-python-numpy-where-work",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am playing with numpy and digging through documentation and I have come across some magic. Namely I am talking about numpy.where():  >>> x = np.arange(9.).reshape(3, 3) >>> np.where( x > 5 ) (array([2, 2, 2]), array([0, 1, 2]))   How do they achieve internally that you are able to pass something like x > 5 into a method? I guess it has something to do with __gt__ but I am looking for a detailed explanation.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How does python numpy.where() work?",
        "A_Content": "  np.where returns a tuple of length equal to the dimension of the numpy ndarray on which it is called (in other words ndim) and each item of tuple is a numpy ndarray of indices of all those values in the initial ndarray for which the condition is True. (Please don't confuse dimension with shape)  For example:  x=np.arange(9).reshape(3,3) print(x) array([[0, 1, 2],       [3, 4, 5],       [6, 7, 8]]) y = np.where(x>4) print(y) array([1, 2, 2, 2], dtype=int64), array([2, 0, 1, 2], dtype=int64))    y is a tuple of length 2 because x.ndim is 2. The 1st item in tuple contains row numbers of all elements greater than 4 and the 2nd item contains column numbers of all items greater than 4. As you can see, [1,2,2,2] corresponds to row numbers of 5,6,7,8 and [2,0,1,2] corresponds to column numbers of 5,6,7,8 Note that the ndarray is traversed along first dimension(row-wise).  Similarly,  x=np.arange(27).reshape(3,3,3) np.where(x>4)    will return a tuple of length 3 because x has 3 dimensions.  But wait, there's more to np.where!  when two additional arguments are added to np.where; it will do a replace operation for all those pairwise row-column combinations which are obtained by the above tuple.   x=np.arange(9).reshape(3,3) y = np.where(x>4, 1, 0) print(y) array([[0, 0, 0],    [0, 0, 1],    [1, 1, 1]])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/5642457/how-does-python-numpy-where-work",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am playing with numpy and digging through documentation and I have come across some magic. Namely I am talking about numpy.where():  >>> x = np.arange(9.).reshape(3, 3) >>> np.where( x > 5 ) (array([2, 2, 2]), array([0, 1, 2]))   How do they achieve internally that you are able to pass something like x > 5 into a method? I guess it has something to do with __gt__ but I am looking for a detailed explanation.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  As a general rule (i.e. in vanilla kernels), fork/clone failures with ENOMEM occur specifically because of either an honest to God out-of-memory condition (dup_mm, dup_task_struct, alloc_pid, mpol_dup, mm_init etc. croak), or because security_vm_enough_memory_mm failed you while enforcing the overcommit policy.  Start by checking the vmsize of the process that failed to fork, at the time of the fork attempt, and then compare to the amount of free memory (physical and swap) as it relates to the overcommit policy (plug the numbers in.)  In your particular case, note that Virtuozzo has additional checks in overcommit enforcement.  Moreover, I'm not sure how much control you truly have, from within your container, over swap and overcommit configuration (in order to influence the outcome of the enforcement.)  Now, in order to actually move forward I'd say you're left with two options:   switch to a larger instance, or put some coding effort into more effectively controlling your script's memory footprint   NOTE that the coding effort may be all for naught if it turns out that it's not you, but some other guy collocated in a different instance on the same server as you running amock.  Memory-wise, we already know that subprocess.Popen uses fork/clone under the hood, meaning that every time you call it you're requesting once more as much memory as Python is already eating up, i.e. in the hundreds of additional MB, all in order to then exec a puny 10kB executable such as free or ps.  In the case of an unfavourable overcommit policy, you'll soon see ENOMEM.  Alternatives to fork that do not have this parent page tables etc. copy problem are vfork and posix_spawn.  But if you do not feel like rewriting chunks of subprocess.Popen in terms of vfork/posix_spawn, consider using suprocess.Popen only once, at the beginning of your script (when Python's memory footprint is minimal), to spawn a shell script that then runs free/ps/sleep and whatever else in a loop parallel to your script; poll the script's output or read it synchronously, possibly from a separate thread if you have other stuff to take care of asynchronously -- do your data crunching in Python but leave the forking to the subordinate process.  HOWEVER, in your particular case you can skip invoking ps and free altogether; that information is readily available to you in Python directly from procfs, whether you choose to access it yourself or via existing libraries and/or packages.  If ps and free were the only utilities you were running, then you can do away with subprocess.Popen completely.  Finally, whatever you do as far as subprocess.Popen is concerned, if your script leaks memory you will still hit the wall eventually.  Keep an eye on it, and check for memory leaks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "70",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  Looking at the output of free -m it seems to me that you actually do not have swap memory available. I am not sure if in Linux the swap always will be available automatically on demand, but I was having the same problem and none of the answers here really helped me. Adding some swap memory however, fixed the problem in my case so since this might help other people facing the same problem, I post my answer on how to add a 1GB swap (on Ubuntu 12.04 but it should work similarly for other distributions.)  You can first check if there is any swap memory enabled.  $sudo swapon -s   if it is empty, it means you don't have any swap enabled. To add a 1GB swap:  $sudo dd if=/dev/zero of=/swapfile bs=1024 count=1024k $sudo mkswap /swapfile $sudo swapon /swapfile   Add the following line to the fstab to make the swap permanent.  $sudo vim /etc/fstab       /swapfile       none    swap    sw      0       0    Source and more information can be found here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  swap may not be the red herring previously suggested.  How big is the python process in question just before the ENOMEM?  Under kernel 2.6, /proc/sys/vm/swappiness controls how aggressively the kernel will turn to swap, and overcommit* files how much and how precisely the kernel may apportion memory with a wink and a nod.  Like your facebook relationship status, it's complicated.     ...but swap is actually available on demand (according to the web host)...   but not according to the output of your free(1) command, which shows no swap space recognized by your server instance.  Now, your web host may certainly know much more than I about this topic, but virtual RHEL/CentOS systems I've used have reported swap available to the guest OS.  Adapting Red Hat KB Article 15252:     A Red Hat Enterprise Linux 5 system   will run just fine with no swap space   at all as long as the sum of anonymous   memory and system V shared memory is   less than about 3/4 the amount of RAM.   .... Systems with 4GB of ram or less   [are recommended to have] a minimum of   2GB of swap space.   Compare your /proc/sys/vm settings to a plain CentOS 5.3 installation.  Add a swap file.  Ratchet down swappiness and see if you live any longer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  I continue to suspect that your customer/user has some kernel module or driver loaded which is interfering with the clone() system call (perhaps some obscure security enhancement, something like LIDS but more obscure?) or is somehow filling up some of the kernel data structures that are necessary for fork()/clone() to operate (process table, page tables, file descriptor tables, etc).  Here's the relevant portion of the fork(2) man page:   ERRORS        EAGAIN fork() cannot allocate sufficient memory to copy the parent's page tables and allocate a task  structure  for  the               child.         EAGAIN It  was not possible to create a new process because the caller's RLIMIT_NPROC resource limit was encountered.  To               exceed this limit, the process must have either the CAP_SYS_ADMIN or the CAP_SYS_RESOURCE capability.         ENOMEM fork() failed to allocate the necessary kernel structures because memory is tight.   I suggest having the user try this after booting into a stock, generic kernel and with only a minimal set of modules and drivers loaded (minimum necessary to run your application/script).  From there, assuming it works in that configuration, they can perform a binary search between that and the configuration which exhibits the issue.  This is standard sysadmin troubleshooting 101.  The relevant line in your strace is:  clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory)   ... I know others have talked about swap and memory availability (and I would recommend that you set up at least a small swap partition, ironically even if it's on a RAM disk ... the code paths through the Linux kernel when it has even a tiny bit of swap available have been exercised far more extensively than those (exception handling paths) in which there is zero swap available.  However I suspect that this is still a red herring.  The fact that free is reporting 0 (ZERO) memory in use by the cache and buffers is very disturbing.  I suspect that the free output ... and possibly your application issue here, are caused by some proprietary kernel module which is interfering with the memory allocation in some way.  According to the man pages for fork()/clone() the fork() system call should return EAGAIN if your call would cause a resource limit violation (RLIMIT_NPROC) ... however, it doesn't say if EAGAIN is to be returned by other RLIMIT* violations.  In any event if your target/host has some sort of weird Vormetric or other security settings (or even if your process is running under some weird SELinux policy) then it might be causing this -ENOMEM failure.  It's pretty unlikely to be a normal run-of-the-mill Linux/UNIX issue. You've got something non-standard going on there.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  Have you tried using:  (status,output) = commands.getstatusoutput(\"ps aux\")   I thought this had fixed the exact same problem for me. But then my process ended up getting killed instead of failing to spawn, which is even worse..  After some testing I found that this only occurred on older versions of python: it happens with 2.6.5 but not with 2.7.2  My search had led me here python-close_fds-issue, but unsetting closed_fds had not solved the issue. It is still well worth a read.  I found that python was leaking file descriptors by just keeping an eye on it:  watch \"ls /proc/$PYTHONPID/fd | wc -l\"   Like you, I do want to capture the command's output, and I do want to avoid OOM errors... but it looks like the only way is for people to use a less buggy version of Python. Not ideal...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "     munmap(0xb7d28000, 4096)                = 0   write(2, \"OSError\", 7)                  = 7     I've seen sloppy code that looks like this:  serrno = errno; some_Syscall(...) if (serrno != errno) /* sound alarm: CATROSTOPHIC ERROR !!! */   You should check to see if this is what is happening in the python code.  Errno is only valid if the proceeding system call failed.  Edited to add:    You don't say how long this process lives.  Possible consumers of memory     forked processes unused data structures shared libraries memory mapped files      ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Python subprocess.Popen “OSError: [Errno 12] Cannot allocate memory”",
        "A_Content": "  For an easy fix, you could  echo 1 > /proc/sys/vm/overcommit_memory   if your're sure that your system has enough memory. See Linux over commit heuristic.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "memory"
        ],
        "URL": "https://stackoverflow.com/questions/1367373/python-subprocess-popen-oserror-errno-12-cannot-allocate-memory",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Note: This question was originally asked here but the bounty time expired even though an acceptable answer was not actually found. I am re-asking this question including all details provided in the original question.  A python script is running a set of class functions every 60 seconds using the sched module:  # sc is a sched.scheduler instance sc.enter(60, 1, self.doChecks, (sc, False))   The script is running as a daemonised process using the code here.  A number of class methods that are called as part of doChecks use the subprocess module to call system functions in order to get system statistics:  ps = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE).communicate()[0]   This runs fine for a period of time before the entire script crashing with the following error:  File \"/home/admin/sd-agent/checks.py\", line 436, in getProcesses File \"/usr/lib/python2.4/subprocess.py\", line 533, in __init__ File \"/usr/lib/python2.4/subprocess.py\", line 835, in _get_handles OSError: [Errno 12] Cannot allocate memory   The output of free -m on the server once the script has crashed is:  $ free -m                   total       used       free     shared     buffers    cached Mem:                894        345        549          0          0          0 -/+ buffers/cache:  345        549 Swap:                 0          0          0   The server is running CentOS 5.3. I am unable to reproduce on my own CentOS boxes nor with any other user reporting the same problem.  I have tried a number of things to debug this as suggested in the original question:   Logging the output of free -m before and after the Popen call. There is no significant change in memory usage i.e. memory is not gradually being used up as the script runs. I added close_fds=True to the Popen call but this made no difference - the script still crashed with the same error. Suggested here and here. I checked the rlimits which showed (-1, -1) on both RLIMIT_DATA and RLIMIT_AS as suggested here. An article suggested the having no swap space might be the cause but swap is actually available on demand (according to the web host) and this was also suggested as a bogus cause here. The processes are being closed because that is the behaviour of using .communicate() as backed up by the Python source code and comments here.   The entire checks can be found at on GitHub here with the getProcesses function defined from line 442. This is called by doChecks() starting at line 520.  The script was run with strace with the following output before the crash:  recv(4, \"Total Accesses: 516662\\nTotal kBy\"..., 234, 0) = 234 gettimeofday({1250893252, 887805}, NULL) = 0 write(3, \"2009-08-21 17:20:52,887 - checks\"..., 91) = 91 gettimeofday({1250893252, 888362}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 74) = 74 gettimeofday({1250893252, 888897}, NULL) = 0 write(3, \"2009-08-21 17:20:52,888 - checks\"..., 67) = 67 gettimeofday({1250893252, 889184}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 81) = 81 close(4)                                = 0 gettimeofday({1250893252, 889591}, NULL) = 0 write(3, \"2009-08-21 17:20:52,889 - checks\"..., 63) = 63 pipe([4, 5])                            = 0 pipe([6, 7])                            = 0 fcntl64(7, F_GETFD)                     = 0 fcntl64(7, F_SETFD, FD_CLOEXEC)         = 0 clone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb7f12708) = -1 ENOMEM (Cannot allocate memory) write(2, \"Traceback (most recent call last\"..., 35) = 35 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 52) = 52 open(\"/home/admin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/daemon.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/home/admin/sd-agent/dae\"..., 60) = 60 open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/agent.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/agent.\"..., 54) = 54 open(\"/usr/lib/python2.4/sched.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/sched\"..., 55) = 55 fstat64(8, {st_mode=S_IFREG|0644, st_size=4054, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"\\\"\\\"\\\"A generally useful event sche\"..., 4096) = 4054 write(2, \"    \", 4)                     = 4 write(2, \"void = action(*argument)\\n\", 25) = 25 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 60) = 60 open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/bin/sd-agent/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python24.zip/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/plat-linux2/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOMEM (Cannot allocate memory) open(\"/usr/lib/python2.4/lib-tk/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/lib-dynload/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) open(\"/usr/lib/python2.4/site-packages/checks.py\", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory) write(2, \"  File \\\"/usr/bin/sd-agent/checks\"..., 64) = 64 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 65) = 65 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"errread, errwrite)\\n\", 19)    = 19 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 open(\"/usr/lib/python2.4/subprocess.py\", O_RDONLY|O_LARGEFILE) = 8 write(2, \"  File \\\"/usr/lib/python2.4/subpr\"..., 71) = 71 fstat64(8, {st_mode=S_IFREG|0644, st_size=39931, ...}) = 0 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7d28000 read(8, \"# subprocess - Subprocesses with\"..., 4096) = 4096 read(8, \"lso, the newlines attribute of t\"..., 4096) = 4096 read(8, \"code < 0:\\n        print >>sys.st\"..., 4096) = 4096 read(8, \"alse does not exist on 2.2.0\\ntry\"..., 4096) = 4096 read(8, \" p2cread\\n        # c2pread    <-\"..., 4096) = 4096 read(8, \"table(self, handle):\\n           \"..., 4096) = 4096 read(8, \"rrno using _sys_errlist (or siml\"..., 4096) = 4096 read(8, \" p2cwrite = None, None\\n         \"..., 4096) = 4096 write(2, \"    \", 4)                     = 4 write(2, \"self.pid = os.fork()\\n\", 21)  = 21 close(8)                                = 0 munmap(0xb7d28000, 4096)                = 0 write(2, \"OSError\", 7)                  = 7 write(2, \": \", 2)                       = 2 write(2, \"[Errno 12] Cannot allocate memor\"..., 33) = 33 write(2, \"\\n\", 1)                       = 1 unlink(\"/var/run/sd-agent.pid\")         = 0 close(3)                                = 0 munmap(0xb7e0d000, 4096)                = 0 rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x589978}, {0xb89a60, [], SA_RESTORER, 0x589978}, 8) = 0 brk(0xa022000)                          = 0xa022000 exit_group(1)                           = ?      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Preserving signatures of decorated functions",
        "A_Content": "   Install decorator module:  $ pip install decorator  Adapt definition of args_as_ints():  import decorator  @decorator.decorator def args_as_ints(f, *args, **kwargs):     args = [int(x) for x in args]     kwargs = dict((k, int(v)) for k, v in kwargs.items())     return f(*args, **kwargs)  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  print funny_function(\"3\", 4.0, z=\"5\") # 22 help(funny_function) # Help on function funny_function in module __main__: #  # funny_function(x, y, z=3) #     Computes x*y + 2*z      Python 3.4+  functools.wraps() from stdlib preserves signatures since Python 3.4:  import functools   def args_as_ints(func):     @functools.wraps(func)     def wrapper(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return func(*args, **kwargs)     return wrapper   @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   print(funny_function(\"3\", 4.0, z=\"5\")) # 22 help(funny_function) # Help on function funny_function in module __main__: # # funny_function(x, y, z=3) #     Computes x*y + 2*z   functools.wraps() is available at least since Python 2.5 but it does not preserve the signature there:  help(funny_function) # Help on function funny_function in module __main__: # # funny_function(*args, **kwargs) #    Computes x*y + 2*z   Notice: *args, **kwargs instead of x, y, z=3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator"
        ],
        "URL": "https://stackoverflow.com/questions/147816/preserving-signatures-of-decorated-functions",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I have written a decorator that does something very generic. For example, it might convert all arguments to a specific type, perform logging, implement memoization, etc.  Here is an example:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  >>> funny_function(\"3\", 4.0, z=\"5\") 22   Everything well so far. There is one problem, however. The decorated function does not retain the documentation of the original function:  >>> help(funny_function) Help on function g in module __main__:  g(*args, **kwargs)   Fortunately, there is a workaround:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   This time, the function name and documentation are correct:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z   But there is still a problem: the function signature is wrong. The information \"*args, **kwargs\" is next to useless.  What to do? I can think of two simple but flawed workarounds:  1 -- Include the correct signature in the docstring:  def funny_function(x, y, z=3):     \"\"\"funny_function(x, y, z=3) -- computes x*y + 2*z\"\"\"     return x*y + 2*z   This is bad because of the duplication. The signature will still not be shown properly in automatically generated documentation. It's easy to update the function and forget about changing the docstring, or to make a typo. [And yes, I'm aware of the fact that the docstring already duplicates the function body. Please ignore this; funny_function is just a random example.]  2 -- Not use a decorator, or use a special-purpose decorator for every specific signature:  def funny_functions_decorator(f):     def g(x, y, z=3):         return f(int(x), int(y), z=int(z))     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g   This works fine for a set of functions that have identical signature, but it's useless in general. As I said in the beginning, I want to be able to use decorators entirely generically.  I'm looking for a solution that is fully general, and automatic.  So the question is: is there a way to edit the decorated function signature after it has been created?  Otherwise, can I write a decorator that extracts the function signature and uses that information instead of \"*kwargs, **kwargs\" when constructing the decorated function? How do I extract that information? How should I construct the decorated function -- with exec?  Any other approaches?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Preserving signatures of decorated functions",
        "A_Content": "  This is solved with Python's standard library functools and specifically functools.wraps function, which is designed to \"update a wrapper function to look like the wrapped function\". It's behaviour depends on Python version, however, as shown below. Applied to the example from the question, the code would look like:  from functools import wraps  def args_as_ints(f):     @wraps(f)      def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g   @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   When executed in Python 3, this would produce the following:  >>> funny_function(\"3\", 4.0, z=\"5\") 22 >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(x, y, z=3)     Computes x*y + 2*z   Its only drawback is that in Python 2 however, it doesn't update function's argument list. When executed in Python 2, it will produce:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z      ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator"
        ],
        "URL": "https://stackoverflow.com/questions/147816/preserving-signatures-of-decorated-functions",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have written a decorator that does something very generic. For example, it might convert all arguments to a specific type, perform logging, implement memoization, etc.  Here is an example:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  >>> funny_function(\"3\", 4.0, z=\"5\") 22   Everything well so far. There is one problem, however. The decorated function does not retain the documentation of the original function:  >>> help(funny_function) Help on function g in module __main__:  g(*args, **kwargs)   Fortunately, there is a workaround:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   This time, the function name and documentation are correct:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z   But there is still a problem: the function signature is wrong. The information \"*args, **kwargs\" is next to useless.  What to do? I can think of two simple but flawed workarounds:  1 -- Include the correct signature in the docstring:  def funny_function(x, y, z=3):     \"\"\"funny_function(x, y, z=3) -- computes x*y + 2*z\"\"\"     return x*y + 2*z   This is bad because of the duplication. The signature will still not be shown properly in automatically generated documentation. It's easy to update the function and forget about changing the docstring, or to make a typo. [And yes, I'm aware of the fact that the docstring already duplicates the function body. Please ignore this; funny_function is just a random example.]  2 -- Not use a decorator, or use a special-purpose decorator for every specific signature:  def funny_functions_decorator(f):     def g(x, y, z=3):         return f(int(x), int(y), z=int(z))     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g   This works fine for a set of functions that have identical signature, but it's useless in general. As I said in the beginning, I want to be able to use decorators entirely generically.  I'm looking for a solution that is fully general, and automatic.  So the question is: is there a way to edit the decorated function signature after it has been created?  Otherwise, can I write a decorator that extracts the function signature and uses that information instead of \"*kwargs, **kwargs\" when constructing the decorated function? How do I extract that information? How should I construct the decorated function -- with exec?  Any other approaches?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Preserving signatures of decorated functions",
        "A_Content": "  There is a decorator module with decorator decorator you can use:  @decorator def args_as_ints(f, *args, **kwargs):     args = [int(x) for x in args]     kwargs = dict((k, int(v)) for k, v in kwargs.items())     return f(*args, **kwargs)   Then the signature and help of the method is preserved:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(x, y, z=3)     Computes x*y + 2*z   EDIT: J. F. Sebastian pointed out that I didn't modify args_as_ints function -- it is fixed now.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator"
        ],
        "URL": "https://stackoverflow.com/questions/147816/preserving-signatures-of-decorated-functions",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have written a decorator that does something very generic. For example, it might convert all arguments to a specific type, perform logging, implement memoization, etc.  Here is an example:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  >>> funny_function(\"3\", 4.0, z=\"5\") 22   Everything well so far. There is one problem, however. The decorated function does not retain the documentation of the original function:  >>> help(funny_function) Help on function g in module __main__:  g(*args, **kwargs)   Fortunately, there is a workaround:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   This time, the function name and documentation are correct:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z   But there is still a problem: the function signature is wrong. The information \"*args, **kwargs\" is next to useless.  What to do? I can think of two simple but flawed workarounds:  1 -- Include the correct signature in the docstring:  def funny_function(x, y, z=3):     \"\"\"funny_function(x, y, z=3) -- computes x*y + 2*z\"\"\"     return x*y + 2*z   This is bad because of the duplication. The signature will still not be shown properly in automatically generated documentation. It's easy to update the function and forget about changing the docstring, or to make a typo. [And yes, I'm aware of the fact that the docstring already duplicates the function body. Please ignore this; funny_function is just a random example.]  2 -- Not use a decorator, or use a special-purpose decorator for every specific signature:  def funny_functions_decorator(f):     def g(x, y, z=3):         return f(int(x), int(y), z=int(z))     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g   This works fine for a set of functions that have identical signature, but it's useless in general. As I said in the beginning, I want to be able to use decorators entirely generically.  I'm looking for a solution that is fully general, and automatic.  So the question is: is there a way to edit the decorated function signature after it has been created?  Otherwise, can I write a decorator that extracts the function signature and uses that information instead of \"*kwargs, **kwargs\" when constructing the decorated function? How do I extract that information? How should I construct the decorated function -- with exec?  Any other approaches?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Preserving signatures of decorated functions",
        "A_Content": "  Take a look at the decorator module - specifically the decorator decorator, which solves this problem.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator"
        ],
        "URL": "https://stackoverflow.com/questions/147816/preserving-signatures-of-decorated-functions",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have written a decorator that does something very generic. For example, it might convert all arguments to a specific type, perform logging, implement memoization, etc.  Here is an example:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  >>> funny_function(\"3\", 4.0, z=\"5\") 22   Everything well so far. There is one problem, however. The decorated function does not retain the documentation of the original function:  >>> help(funny_function) Help on function g in module __main__:  g(*args, **kwargs)   Fortunately, there is a workaround:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   This time, the function name and documentation are correct:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z   But there is still a problem: the function signature is wrong. The information \"*args, **kwargs\" is next to useless.  What to do? I can think of two simple but flawed workarounds:  1 -- Include the correct signature in the docstring:  def funny_function(x, y, z=3):     \"\"\"funny_function(x, y, z=3) -- computes x*y + 2*z\"\"\"     return x*y + 2*z   This is bad because of the duplication. The signature will still not be shown properly in automatically generated documentation. It's easy to update the function and forget about changing the docstring, or to make a typo. [And yes, I'm aware of the fact that the docstring already duplicates the function body. Please ignore this; funny_function is just a random example.]  2 -- Not use a decorator, or use a special-purpose decorator for every specific signature:  def funny_functions_decorator(f):     def g(x, y, z=3):         return f(int(x), int(y), z=int(z))     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g   This works fine for a set of functions that have identical signature, but it's useless in general. As I said in the beginning, I want to be able to use decorators entirely generically.  I'm looking for a solution that is fully general, and automatic.  So the question is: is there a way to edit the decorated function signature after it has been created?  Otherwise, can I write a decorator that extracts the function signature and uses that information instead of \"*kwargs, **kwargs\" when constructing the decorated function? How do I extract that information? How should I construct the decorated function -- with exec?  Any other approaches?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Preserving signatures of decorated functions",
        "A_Content": "  Second option:   Install wrapt module:   $ easy_install wrapt  wrapt have a bonus, preserve class signature.   import wrapt import inspect  @wrapt.decorator def args_as_ints(wrapped, instance, args, kwargs):     if instance is None:         if inspect.isclass(wrapped):             # Decorator was applied to a class.             return wrapped(*args, **kwargs)         else:             # Decorator was applied to a function or staticmethod.             return wrapped(*args, **kwargs)     else:         if inspect.isclass(instance):             # Decorator was applied to a classmethod.             return wrapped(*args, **kwargs)         else:             # Decorator was applied to an instancemethod.             return wrapped(*args, **kwargs)   @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x * y + 2 * z   >>> funny_function(3, 4, z=5)) # 22  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(x, y, z=3)     Computes x*y + 2*z      ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator"
        ],
        "URL": "https://stackoverflow.com/questions/147816/preserving-signatures-of-decorated-functions",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have written a decorator that does something very generic. For example, it might convert all arguments to a specific type, perform logging, implement memoization, etc.  Here is an example:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z  >>> funny_function(\"3\", 4.0, z=\"5\") 22   Everything well so far. There is one problem, however. The decorated function does not retain the documentation of the original function:  >>> help(funny_function) Help on function g in module __main__:  g(*args, **kwargs)   Fortunately, there is a workaround:  def args_as_ints(f):     def g(*args, **kwargs):         args = [int(x) for x in args]         kwargs = dict((k, int(v)) for k, v in kwargs.items())         return f(*args, **kwargs)     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g  @args_as_ints def funny_function(x, y, z=3):     \"\"\"Computes x*y + 2*z\"\"\"     return x*y + 2*z   This time, the function name and documentation are correct:  >>> help(funny_function) Help on function funny_function in module __main__:  funny_function(*args, **kwargs)     Computes x*y + 2*z   But there is still a problem: the function signature is wrong. The information \"*args, **kwargs\" is next to useless.  What to do? I can think of two simple but flawed workarounds:  1 -- Include the correct signature in the docstring:  def funny_function(x, y, z=3):     \"\"\"funny_function(x, y, z=3) -- computes x*y + 2*z\"\"\"     return x*y + 2*z   This is bad because of the duplication. The signature will still not be shown properly in automatically generated documentation. It's easy to update the function and forget about changing the docstring, or to make a typo. [And yes, I'm aware of the fact that the docstring already duplicates the function body. Please ignore this; funny_function is just a random example.]  2 -- Not use a decorator, or use a special-purpose decorator for every specific signature:  def funny_functions_decorator(f):     def g(x, y, z=3):         return f(int(x), int(y), z=int(z))     g.__name__ = f.__name__     g.__doc__ = f.__doc__     return g   This works fine for a set of functions that have identical signature, but it's useless in general. As I said in the beginning, I want to be able to use decorators entirely generically.  I'm looking for a solution that is fully general, and automatic.  So the question is: is there a way to edit the decorated function signature after it has been created?  Otherwise, can I write a decorator that extracts the function signature and uses that information instead of \"*kwargs, **kwargs\" when constructing the decorated function? How do I extract that information? How should I construct the decorated function -- with exec?  Any other approaches?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  I highly recommend xlrd for reading .xls files.  voyager mentioned the use of COM automation. Having done this myself a few years ago, be warned that doing this is a real PITA. The number of caveats is huge and the documentation is lacking and annoying. I ran into many weird bugs and gotchas, some of which took many hours to figure out.  UPDATE: For newer .xlsx files, the recommended library for reading and writing appears to be openpyxl.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "74",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  Using pandas:  import pandas as pd  xls = pd.ExcelFile(\"yourfilename.xls\")  sheetX = xls.parse(2) #2 is the sheet number  var1 = sheetX['ColumnName']  print(var1[1]) #1 is the row number...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  python xlrd library can better solution for this problem   import xlrd   to open a workbook   workbook = xlrd.open_workbook('your_file_name.xlsx')   open sheet by name  worksheet = workbook.sheet_by_name('Name of the Sheet')   open sheet by index  worksheet = workbook.sheet_by_index(0)   read  cell value   worksheet.cell(0, 0).value          ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  You can use any of the libraries listed here (like Pyxlreader that is based on JExcelApi, or xlwt), plus COM automation to use Excel itself for the reading of the files, but for that you are introducing Office as a dependency of your software, which might not be always an option.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  You might also consider running the (non-python) program xls2csv. Feed it an xls file, and you should get back a csv.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  I think Pandas is the best way to go. There is already one answer here with Pandas using ExcelFile function, but it did not work properly for me. From here I found the read_excel function which works just fine:  import pandas as pd dfs = pd.read_excel(\"your_file_name.xlsx\", sheet_name=\"your_sheet_name\") print(dfs.head(10))   P.S. You need to have the xlrd installed for read_excel function to work     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  For older Excel files there is the OleFileIO_PL module that can read the OLE structured storage format used.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Reading/parsing Excel (xls) files with Python",
        "A_Content": "  Python Excelerator handles this task as well. http://ghantoos.org/2007/10/25/python-pyexcelerator-small-howto/  It's also available in Debian and Ubuntu:   sudo apt-get install python-excelerator      ",
        "Language": "Python",
        "Tags": [
            "python",
            "xls"
        ],
        "URL": "https://stackoverflow.com/questions/2942889/reading-parsing-excel-xls-files-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to read Excel (XLS) files with Python (not CSV files).  Is there a built-in package which is supported by default in Python to do this task?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to check if a variable is a dictionary in python [duplicate]",
        "A_Content": "  You could use if type(ele) is dict or  use isinstance(ele, dict) which would work if you had subclassed dict:  d = {'abc':'abc','def':{'ghi':'ghi','jkl':'jkl'}} for ele in d.values():     if isinstance(ele,dict):        for k, v in ele.items():            print(k,' ',v)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/25231989/how-to-check-if-a-variable-is-a-dictionary-in-python",
        "A_Votes": "118",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              What are the differences between type() and isinstance()?                                        6 answers                                          How would you check if a variable is a dictionary in python?  For example id like it to loop through the values in the dictionary till it finds a dictionary then loop through the one it finds:  dict = {'abc':'abc','def':{'ghi':'ghi','jkl':'jkl'}} for k, v in dict.iteritems():     if ###check if v is a dictionary:         for k, v in v.iteritems():             print(k,' ',v)     else:         print(k,' ',v)   Any help would be greatly appreciated.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Creating hidden arguments with Python argparse",
        "A_Content": "  Yes, you can set the help option to add_argument to argparse.SUPPRESS. Here's an example from the argparse documentation:  >>> parser = argparse.ArgumentParser(prog='frobble') >>> parser.add_argument('--foo', help=argparse.SUPPRESS) >>> parser.print_help() usage: frobble [-h]  optional arguments:   -h, --help  show this help message and exit      ",
        "Language": "Python",
        "Tags": [
            "python",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/11114589/creating-hidden-arguments-with-python-argparse",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is it possible to add an Argument to an python argparse.ArgumentParser without it showing up in the usage or help (script.py --help)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What is the difference between the AWS boto and boto3 [closed]",
        "A_Content": "  The boto package is the hand-coded Python library that has been around since 2006.  It is very popular and is fully supported by AWS but because it is hand-coded and there are so many services available (with more appearing all the time) it is difficult to maintain.  So, boto3 is a new version of the boto library based on botocore.  All of the low-level interfaces to AWS are driven from JSON service descriptions that are generated automatically from the canonical descriptions of the services.  So, the interfaces are always correct and always up to date.  There is a resource layer on top of the client-layer that provides a nicer, more Pythonic interface.  The boto3 library is being actively developed by AWS and is the one I would recommend people use if they are starting new development.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/32322503/what-is-the-difference-between-the-aws-boto-and-boto3",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to AWS using Python and I'm trying to learn the boto API however I noticed that there are two major versions/packages for Python.  That would be boto and boto3.  What is the difference between the AWS boto and boto3 libraries?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "__lt__ instead of __cmp__",
        "A_Content": "  Yep, it's easy to implement everything in terms of e.g. __lt__ with a mixin class (or a metaclass, or a class decorator if your taste runs that way).  For example:  class ComparableMixin:   def __eq__(self, other):     return not self<other and not other<self   def __ne__(self, other):     return self<other or other<self   def __gt__(self, other):     return other<self   def __ge__(self, other):     return not self<other   def __le__(self, other):     return not other<self   Now your class can define just __lt__ and multiply inherit from ComparableMixin (after whatever other bases it needs, if any). A class decorator would be quite similar, just inserting similar functions as attributes of the new class it's decorating (the result might be microscopically faster at runtime, at equally minute cost in terms of memory).  Of course, if your class has some particularly fast way to implement (e.g.) __eq__ and __ne__, it should define them directly so the mixin's versions are not use (for example, that is the case for dict) -- in fact __ne__ might well be defined to facilitate that as:  def __ne__(self, other):   return not self == other   but in the code above I wanted to keep the pleasing symmetry of only using <;-). As to why __cmp__ had to go, since we did have __lt__ and friends, why keep another, different way to do exactly the same thing around?  It's just so much dead-weight in every Python runtime (Classic, Jython, IronPython, PyPy, ...).  The code that definitely won't have bugs is the code that isn't there -- whence Python's principle that there ought to be ideally one obvious way to perform a task (C has the same principle in the \"Spirit of C\" section of the ISO standard, btw).  This doesn't mean we go out of our way to prohibit things (e.g., near-equivalence between mixins and class decorators for some uses), but it definitely does mean that we don't like to carry around code in the compilers and/or runtimes that redundantly exists just to support multiple equivalent approaches to perform exactly the same task.  Further edit: there's actually an even better way to provide comparison AND hashing for many classes, including that in the question -- a __key__ method, as I mentioned on my comment to the question. Since I never got around to writing the PEP for it, you must currently implement it with a Mixin (&c) if you like it:  class KeyedMixin:   def __lt__(self, other):     return self.__key__() < other.__key__()   # and so on for other comparators, as above, plus:   def __hash__(self):     return hash(self.__key__())   It's a very common case for an instance's comparisons with other instances to boil down to comparing a tuple for each with a few fields -- and then, hashing should be implemented on exactly the same basis. The __key__ special method addresses that need directly.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "operator-overloading"
        ],
        "URL": "https://stackoverflow.com/questions/1061283/lt-instead-of-cmp",
        "A_Votes": "82",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Python 2.x has two ways to overload comparison operators, __cmp__ or the \"rich comparison operators\" such as __lt__.  The rich comparison overloads are said to be preferred, but why is this so?  Rich comparison operators are simpler to implement each, but you must implement several of them with nearly identical logic.  However, if you can use the builtin cmp and tuple ordering, then __cmp__ gets quite simple and fulfills all the comparisons:  class A(object):   def __init__(self, name, age, other):     self.name = name     self.age = age     self.other = other   def __cmp__(self, other):     assert isinstance(other, A) # assumption for this example     return cmp((self.name, self.age, self.other),                (other.name, other.age, other.other))   This simplicity seems to meet my needs much better than overloading all 6(!) of the rich comparisons.  (However, you can get it down to \"just\" 4 if you rely on the \"swapped argument\"/reflected behavior, but that results in a net increase of complication, in my humble opinion.)  Are there any unforeseen pitfalls I need to be made aware of if I only overload __cmp__?  I understand the <, <=, ==, etc. operators can be overloaded for other purposes, and can return any object they like.  I am not asking about the merits of that approach, but only about differences when using these operators for comparisons in the same sense that they mean for numbers.  Update: As Christopher pointed out, cmp is disappearing in 3.x. Are there any alternatives that make implementing comparisons as easy as the above __cmp__?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "__lt__ instead of __cmp__",
        "A_Content": "  To simplify this case there's a class decorator in Python 2.7+/3.2+, functools.total_ordering, that can be used to implement what Alex suggests. Example from the docs:  @total_ordering class Student:     def __eq__(self, other):         return ((self.lastname.lower(), self.firstname.lower()) ==                 (other.lastname.lower(), other.firstname.lower()))     def __lt__(self, other):         return ((self.lastname.lower(), self.firstname.lower()) <                 (other.lastname.lower(), other.firstname.lower()))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "operator-overloading"
        ],
        "URL": "https://stackoverflow.com/questions/1061283/lt-instead-of-cmp",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python 2.x has two ways to overload comparison operators, __cmp__ or the \"rich comparison operators\" such as __lt__.  The rich comparison overloads are said to be preferred, but why is this so?  Rich comparison operators are simpler to implement each, but you must implement several of them with nearly identical logic.  However, if you can use the builtin cmp and tuple ordering, then __cmp__ gets quite simple and fulfills all the comparisons:  class A(object):   def __init__(self, name, age, other):     self.name = name     self.age = age     self.other = other   def __cmp__(self, other):     assert isinstance(other, A) # assumption for this example     return cmp((self.name, self.age, self.other),                (other.name, other.age, other.other))   This simplicity seems to meet my needs much better than overloading all 6(!) of the rich comparisons.  (However, you can get it down to \"just\" 4 if you rely on the \"swapped argument\"/reflected behavior, but that results in a net increase of complication, in my humble opinion.)  Are there any unforeseen pitfalls I need to be made aware of if I only overload __cmp__?  I understand the <, <=, ==, etc. operators can be overloaded for other purposes, and can return any object they like.  I am not asking about the merits of that approach, but only about differences when using these operators for comparisons in the same sense that they mean for numbers.  Update: As Christopher pointed out, cmp is disappearing in 3.x. Are there any alternatives that make implementing comparisons as easy as the above __cmp__?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "__lt__ instead of __cmp__",
        "A_Content": "  This is covered by PEP 207 - Rich Comparisons  Also, __cmp__ goes away in python 3.0.  ( Note that it is not present on http://docs.python.org/3.0/reference/datamodel.html but it IS on http://docs.python.org/2.7/reference/datamodel.html )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "operator-overloading"
        ],
        "URL": "https://stackoverflow.com/questions/1061283/lt-instead-of-cmp",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python 2.x has two ways to overload comparison operators, __cmp__ or the \"rich comparison operators\" such as __lt__.  The rich comparison overloads are said to be preferred, but why is this so?  Rich comparison operators are simpler to implement each, but you must implement several of them with nearly identical logic.  However, if you can use the builtin cmp and tuple ordering, then __cmp__ gets quite simple and fulfills all the comparisons:  class A(object):   def __init__(self, name, age, other):     self.name = name     self.age = age     self.other = other   def __cmp__(self, other):     assert isinstance(other, A) # assumption for this example     return cmp((self.name, self.age, self.other),                (other.name, other.age, other.other))   This simplicity seems to meet my needs much better than overloading all 6(!) of the rich comparisons.  (However, you can get it down to \"just\" 4 if you rely on the \"swapped argument\"/reflected behavior, but that results in a net increase of complication, in my humble opinion.)  Are there any unforeseen pitfalls I need to be made aware of if I only overload __cmp__?  I understand the <, <=, ==, etc. operators can be overloaded for other purposes, and can return any object they like.  I am not asking about the merits of that approach, but only about differences when using these operators for comparisons in the same sense that they mean for numbers.  Update: As Christopher pointed out, cmp is disappearing in 3.x. Are there any alternatives that make implementing comparisons as easy as the above __cmp__?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "__lt__ instead of __cmp__",
        "A_Content": "  Inspired by Alex Martelli's ComparableMixin & KeyedMixin answers, I came up with the following mixin. It allows you to implement a single _compare_to() method, which uses key-based comparisons similar to KeyedMixin, but allows your class to pick the most efficient comparison key based on the type of other. (Note that this mixin doesn't help much for objects which can be tested for equality but not order).   class ComparableMixin(object):     \"\"\"mixin which implements rich comparison operators in terms of a single _compare_to() helper\"\"\"      def _compare_to(self, other):         \"\"\"return keys to compare self to other.          if self and other are comparable, this function          should return ``(self key, other key)``.         if they aren't, it should return ``None`` instead.         \"\"\"         raise NotImplementedError(\"_compare_to() must be implemented by subclass\")      def __eq__(self, other):         keys = self._compare_to(other)         return keys[0] == keys[1] if keys else NotImplemented      def __ne__(self, other):         return not self == other      def __lt__(self, other):         keys = self._compare_to(other)         return keys[0] < keys[1] if keys else NotImplemented      def __le__(self, other):         keys = self._compare_to(other)         return keys[0] <= keys[1] if keys else NotImplemented      def __gt__(self, other):         keys = self._compare_to(other)         return keys[0] > keys[1] if keys else NotImplemented      def __ge__(self, other):         keys = self._compare_to(other)         return keys[0] >= keys[1] if keys else NotImplemented      ",
        "Language": "Python",
        "Tags": [
            "python",
            "operator-overloading"
        ],
        "URL": "https://stackoverflow.com/questions/1061283/lt-instead-of-cmp",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python 2.x has two ways to overload comparison operators, __cmp__ or the \"rich comparison operators\" such as __lt__.  The rich comparison overloads are said to be preferred, but why is this so?  Rich comparison operators are simpler to implement each, but you must implement several of them with nearly identical logic.  However, if you can use the builtin cmp and tuple ordering, then __cmp__ gets quite simple and fulfills all the comparisons:  class A(object):   def __init__(self, name, age, other):     self.name = name     self.age = age     self.other = other   def __cmp__(self, other):     assert isinstance(other, A) # assumption for this example     return cmp((self.name, self.age, self.other),                (other.name, other.age, other.other))   This simplicity seems to meet my needs much better than overloading all 6(!) of the rich comparisons.  (However, you can get it down to \"just\" 4 if you rely on the \"swapped argument\"/reflected behavior, but that results in a net increase of complication, in my humble opinion.)  Are there any unforeseen pitfalls I need to be made aware of if I only overload __cmp__?  I understand the <, <=, ==, etc. operators can be overloaded for other purposes, and can return any object they like.  I am not asking about the merits of that approach, but only about differences when using these operators for comparisons in the same sense that they mean for numbers.  Update: As Christopher pointed out, cmp is disappearing in 3.x. Are there any alternatives that make implementing comparisons as easy as the above __cmp__?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "__lt__ instead of __cmp__",
        "A_Content": "  (Edited 6/17/17 to take comments into account.)  I tried out the comparable mixin answer above.  I ran into trouble with \"None\".  Here is a modified version that handles equality comparisons with \"None\".  (I saw no reason to bother with inequality comparisons with None as lacking semantics):   class ComparableMixin(object):      def __eq__(self, other):         if not isinstance(other, type(self)):              return NotImplemented         else:             return not self<other and not other<self      def __ne__(self, other):         return not __eq__(self, other)      def __gt__(self, other):         if not isinstance(other, type(self)):              return NotImplemented         else:             return other<self      def __ge__(self, other):         if not isinstance(other, type(self)):              return NotImplemented         else:             return not self<other      def __le__(self, other):         if not isinstance(other, type(self)):              return NotImplemented         else:             return not other<self          ",
        "Language": "Python",
        "Tags": [
            "python",
            "operator-overloading"
        ],
        "URL": "https://stackoverflow.com/questions/1061283/lt-instead-of-cmp",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python 2.x has two ways to overload comparison operators, __cmp__ or the \"rich comparison operators\" such as __lt__.  The rich comparison overloads are said to be preferred, but why is this so?  Rich comparison operators are simpler to implement each, but you must implement several of them with nearly identical logic.  However, if you can use the builtin cmp and tuple ordering, then __cmp__ gets quite simple and fulfills all the comparisons:  class A(object):   def __init__(self, name, age, other):     self.name = name     self.age = age     self.other = other   def __cmp__(self, other):     assert isinstance(other, A) # assumption for this example     return cmp((self.name, self.age, self.other),                (other.name, other.age, other.other))   This simplicity seems to meet my needs much better than overloading all 6(!) of the rich comparisons.  (However, you can get it down to \"just\" 4 if you rely on the \"swapped argument\"/reflected behavior, but that results in a net increase of complication, in my humble opinion.)  Are there any unforeseen pitfalls I need to be made aware of if I only overload __cmp__?  I understand the <, <=, ==, etc. operators can be overloaded for other purposes, and can return any object they like.  I am not asking about the merits of that approach, but only about differences when using these operators for comparisons in the same sense that they mean for numbers.  Update: As Christopher pointed out, cmp is disappearing in 3.x. Are there any alternatives that make implementing comparisons as easy as the above __cmp__?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between a -= b and a = a - b in Python",
        "A_Content": "  Note: using in-place operations on NumPy arrays that share memory in no longer a problem in version 1.13.0 onward (see details here). The two operation will produce the same result. This answer only applies to earlier versions of NumPy.    Mutating arrays while they're being used in computations can lead to unexpected results!  In the example in the question, subtraction with -= modifies the second element of a and then immediately uses that modified second element in the operation on the third element of a.  Here is what happens with a[1:] -= a[:-1] step by step:   a is the array with the data [1, 2, 3]. We have two views onto this data: a[1:] is [2, 3], and a[:-1] is [1, 2]. The in-place subtraction -= begins. The first element of a[:-1], 1, is subtracted from the first element of a[1:]. This has modified a to be [1, 1, 3]. Now we have that a[1:] is a view of the data [1, 3], and a[:-1] is a view of the data [1, 1] (the second element of array a has been changed). a[:-1] is now [1, 1] and NumPy must now subtract its second element which is 1 (not 2 anymore!) from the second element of a[1:]. This makes a[1:] a view of the values [1, 2]. a is now an array with the values [1, 1, 2].   b[1:] = b[1:] - b[:-1] does not have this problem because b[1:] - b[:-1] creates a new array first and then assigns the values in this array to b[1:]. It does not modify b itself during the subtraction, so the views b[1:] and b[:-1] do not change.    The general advice is to avoid modifying one view inplace with another if they overlap. This includes the operators -=, *=, etc. and using the out parameter in universal functions (like np.subtract and np.multiply) to write back to one of the arrays.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy",
            "variable-assignment",
            "in-place"
        ],
        "URL": "https://stackoverflow.com/questions/35036126/difference-between-a-b-and-a-a-b-in-python",
        "A_Votes": "79",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have recently applied this solution for averaging every N rows of matrix. Although the solution works in general I had problems when applied to a 7x1 array. I have noticed that the problem is when using the -= operator. To make a small example:  import numpy as np  a = np.array([1,2,3]) b = np.copy(a)  a[1:] -= a[:-1] b[1:] = b[1:] - b[:-1]  print a print b   which outputs:  [1 1 2] [1 1 1]   So, in the case of an array a -= b produces a different result than a = a - b. I thought until now that these two ways are exactly the same. What is the difference?  How come the method I am mentioning for summing every N rows in a matrix is working e.g. for a 7x4 matrix but not for a 7x1 array?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between a -= b and a = a - b in Python",
        "A_Content": "  Internally, the difference is that this:  a[1:] -= a[:-1]   is equivalent to this:  a[1:] = a[1:].__isub__(a[:-1]) a.__setitem__(slice(1, None, None), a.__getitem__(slice(1, None, None)).__isub__(a.__getitem__(slice(1, None, None)))   while this:  b[1:] = b[1:] - b[:-1]   maps to this:  b[1:] = b[1:].__sub__(b[:-1]) b.__setitem__(slice(1, None, None), b.__getitem__(slice(1, None, None)).__sub__(b.__getitem__(slice(1, None, None)))   In some cases, __sub__() and __isub__() work in a similar way. But mutable objects should mutate and return themselves when using __isub__(), while they should return a new object with __sub__().  Applying slice operations on numpy objects creates views on them, so using them directly accesses the memory of the \"original\" object.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy",
            "variable-assignment",
            "in-place"
        ],
        "URL": "https://stackoverflow.com/questions/35036126/difference-between-a-b-and-a-a-b-in-python",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently applied this solution for averaging every N rows of matrix. Although the solution works in general I had problems when applied to a 7x1 array. I have noticed that the problem is when using the -= operator. To make a small example:  import numpy as np  a = np.array([1,2,3]) b = np.copy(a)  a[1:] -= a[:-1] b[1:] = b[1:] - b[:-1]  print a print b   which outputs:  [1 1 2] [1 1 1]   So, in the case of an array a -= b produces a different result than a = a - b. I thought until now that these two ways are exactly the same. What is the difference?  How come the method I am mentioning for summing every N rows in a matrix is working e.g. for a 7x4 matrix but not for a 7x1 array?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between a -= b and a = a - b in Python",
        "A_Content": "  The docs say :     The idea behind augmented assignment in Python is that it isn't       just an easier way to write the common practice of storing the       result of a binary operation in its left-hand operand, but also a       way for the left-hand operand in question to know that it should       operate `on itself', rather than creating a modified copy of       itself.   As a thumb rule, augmented substraction (x-=y) is x.__isub__(y),  for IN-place operation  IF possible, when normal substraction (x = x-y) is x=x.__sub__(y) .  On non mutable objects like integers it's equivalent.  But for mutable ones like arrays or lists, as in your example, they can be very different things.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "numpy",
            "variable-assignment",
            "in-place"
        ],
        "URL": "https://stackoverflow.com/questions/35036126/difference-between-a-b-and-a-a-b-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently applied this solution for averaging every N rows of matrix. Although the solution works in general I had problems when applied to a 7x1 array. I have noticed that the problem is when using the -= operator. To make a small example:  import numpy as np  a = np.array([1,2,3]) b = np.copy(a)  a[1:] -= a[:-1] b[1:] = b[1:] - b[:-1]  print a print b   which outputs:  [1 1 2] [1 1 1]   So, in the case of an array a -= b produces a different result than a = a - b. I thought until now that these two ways are exactly the same. What is the difference?  How come the method I am mentioning for summing every N rows in a matrix is working e.g. for a 7x4 matrix but not for a 7x1 array?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  and tests whether both expressions are logically True while & (when used with True/False values) tests if both are True.  In Python, empty built-in objects are typically treated as logically False while non-empty built-ins are logically True. This facilitates the common use case where you want to do something if a list is empty and something else if the list is not. Note that this means that the list [False] is logically True:  >>> if [False]: ...    print 'True' ... True   So in Example 1, the first list is non-empty and therefore logically True, so the truth value of the and is the same as that of the second list. (In our case, the second list is non-empty and therefore logically True, but identifying that would require an unnecessary step of calculation.)  For example 2, lists cannot meaningfully be combined in a bitwise fashion because they can contain arbitrary unlike elements. Things that can be combined bitwise include: Trues and Falses, integers.  NumPy objects, by contrast, support vectorized calculations. That is, they let you perform the same operations on multiple pieces of data.  Example 3 fails because NumPy arrays (of length > 1) have no truth value as this prevents vector-based logic confusion.  Example 4 is simply a vectorized bit and operation.  Bottom Line   If you are not dealing with arrays and are not performing math manipulations of integers, you probably want and. If you have vectors of truth values that you wish to combine, use numpy with &.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "73",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  The short-circuiting boolean operators (and, or) can't be overriden because there is no satisfying way to do this without introducing new language features or sacrificing short circuiting. As you may or may not know, they evaluate the first operand for its truth value, and depending on that value, either evaluate and return the second argument, or don't evaluate the second argument and return the first:  something_true and x -> x something_false and x -> something_false something_true or x -> something_true something_false or x -> x   Note that the (result of evaluating the) actual operand is returned, not truth value thereof.  The only way to customize their behavior is to override __nonzero__ (renamed to __bool__ in Python 3), so you can affect which operand gets returned, but not return something different. Lists (and other collections) are defined to be \"truthy\" when they contain anything at all, and \"falsey\" when they are empty.  NumPy arrays reject that notion: For the use cases they aim at, two different notions of truth are common: (1) Whether any element is true, and (2) whether all elements are true. Since these two are completely (and silently) incompatible, and neither is clearly more correct or more common, NumPy refuses to guess and requires you to explicitly use .any() or .all().  & and | (and not, by the way) can be fully overriden, as they don't short circuit. They can return anything at all when overriden, and NumPy makes good use of that to do element-wise operations, as they do with practically any other scalar operation. Lists, on the other hand, don't broadcast operations across their elements. Just as mylist1 - mylist2 doesn't mean anything and mylist1 + mylist2 means something completely different, there is no & operator for lists.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  About list  First a very important point, from which everything will follow (I hope).  In ordinary Python, list is not special in any way (except having cute syntax for constructing, which is mostly a historical accident). Once a list [3,2,6] is made, it is for all intents and purposes just an ordinary Python object, like a number 3, set {3,7}, or a function lambda x: x+5.  (Yes, it supports changing its elements, and it supports iteration, and many other things, but that's just what a type is: it supports some operations, while not supporting some others. int supports raising to a power, but that doesn't make it very special - it's just what an int is. lambda supports calling, but that doesn't make it very special - that's what lambda is for, after all:).  About and  and is not an operator (you can call it \"operator\", but you can call \"for\" an operator too:). Operators in Python are (implemented through) methods called on objects of some type, usually written as part of that type. There is no way for a method to hold an evaluation of some of its operands, but and can (and must) do that.  The consequence of that is that and cannot be overloaded, just like for cannot be overloaded. It is completely general, and communicates through a specified protocol. What you can do is customize your part of the protocol, but that doesn't mean you can alter the behavior of and completely. The protocol is:  Imagine Python interpreting \"a and b\" (this doesn't happen literally this way, but it helps understanding). When it comes to \"and\", it looks at the object it has just evaluated (a), and asks it: are you true? (NOT: are you True?) If you are an author of a's class, you can customize this answer. If a answers \"no\", and (skips b completely, it is not evaluated at all, and) says: a is my result (NOT: False is my result).  If a doesn't answer, and asks it: what is your length? (Again, you can customize this as an author of a's class). If a answers 0, and does the same as above - considers it false (NOT False), skips b, and gives a as result.  If a answers something other than 0 to the second question (\"what is your length\"), or it doesn't answer at all, or it answers \"yes\" to the first one (\"are you true\"), and evaluates b, and says: b is my result. Note that it does NOT ask b any questions.  The other way to say all of this is that a and b is almost the same as b if a else a, except a is evaluated only once.  Now sit for a few minutes with a pen and paper, and convince yourself that when {a,b} is a subset of {True,False}, it works exactly as you would expect of Boolean operators. But I hope I have convinced you it is much more general, and as you'll see, much more useful this way.  Putting those two together  Now I hope you understand your example 1. and doesn't care if mylist1 is a number, list, lambda or an object of a class Argmhbl. It just cares about mylist1's answer to the questions of the protocol. And of course, mylist1 answers 5 to the question about length, so  and returns mylist2. And that's it. It has nothing to do with elements of mylist1 and mylist2 - they don't enter the picture anywhere.  Second example: & on list  On the other hand, & is an operator like any other, like + for example. It can be defined for a type by defining a special method on that class. int defines it as bitwise \"and\", and bool defines it as logical \"and\", but that's just one option: for example, sets and some other objects like dict keys views define it as a set intersection. list just doesn't define it, probably because Guido didn't think of any obvious way of defining it.  numpy  On the other leg:-D, numpy arrays are special, or at least they are trying to be. Of course, numpy.array is just a class, it cannot override and in any way, so it does the next best thing: when asked \"are you true\", numpy.array raises a ValueError, effectively saying \"please rephrase the question, my view of truth doesn't fit into your model\". (Note that the ValueError message doesn't speak about and - because numpy.array doesn't know who is asking it the question; it just speaks about truth.)  For &, it's completely different story. numpy.array can define it as it wishes, and it defines & consistently with other operators: pointwise. So you finally get what you want.  HTH,     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  Example 1:  This is how the and operator works.   x and y  =>  if x is false, then x, else y  So in other words, since mylist1 is not False, the result of the expression is mylist2. (Only empty lists evaluate to False.)  Example 2:  The & operator is for a bitwise and, as you mention. Bitwise operations only work on numbers. The result of a & b is a number composed of 1s in bits that are 1 in both a and b. For example:   >>> 3 & 1 1   It's easier to see what's happening using a binary literal (same numbers as above):   >>> 0b0011 & 0b0001 0b0001   Bitwise operations are similar in concept to boolean (truth) operations, but they work only on bits.   So, given a couple statements about my car   My car is red My car has wheels   The logical \"and\" of these two statements is:      (is my car red?) and (does car have wheels?) => logical true of false value   Both of which are true, for my car at least. So the value of the statement as a whole is logically true.   The bitwise \"and\" of these two statements is a little more nebulous:     (the numeric value of the statement 'my car is red') & (the numeric value of the statement 'my car has wheels') => number   If python knows how to convert the statements to numeric values, then it will do so and compute the bitwise-and of the two values. This may lead you to believe that & is interchangeable with and, but as with the above example they are different things. Also, for the objects that can't be converted, you'll just get a TypeError.   Example 3 and 4:  Numpy implements arithmetic operations for arrays:      Arithmetic and comparison operations on ndarrays are defined as element-wise operations, and generally yield ndarray objects as results.   But does not implement logical operations for arrays, because you can't overload logical operators in python. That's why example three doesn't work, but example four does.   So to answer your and vs & question: Use and.   The bitwise operations are used for examining the structure of a number (which bits are set, which bits aren't set). This kind of information is mostly used in low-level operating system interfaces (unix permission bits, for example). Most python programs won't need to know that.   The logical operations (and, or, not), however, are used all the time.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "   In Python an expression of X and Y returns Y, given that bool(X) == True or any of X or Y evaluate to False, e.g.:  True and 20  >>> 20  False and 20 >>> False  20 and [] >>> []  Bitwise operator is simply not defined for lists. But it is defined for integers - operating over the binary representation of the numbers. Consider 16 (01000) and 31 (11111):  16 & 31 >>> 16  NumPy is not a psychic, it does not know, whether you mean that e.g. [False, False] should be equal to True in a logical expression. In this it overrides a standard Python behaviour, which is: \"Any empty collection with len(collection) == 0 is False\". Probably an expected behaviour of NumPy's arrays's & operator.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  Operations with a Python list operate on the list. list1 and list2 will check if list1 is empty, and return list1 if it is, and list2 if it isn't. list1 + list2 will append list2 to list1, so you get a new list with len(list1) + len(list2) elements.   Operators that only make sense when applied element-wise, such as &, raise a TypeError, as element-wise operations aren't supported without looping through the elements.  Numpy arrays support element-wise operations. array1 & array2 will calculate the bitwise or for each corresponding element in array1 and array2. array1 + array2 will calculate the sum for each corresponding element in array1 and array2.   This does not work for and and or.  array1 and array2 is essentially a short-hand for the following code:  if bool(array1):     return array2 else:     return array1   For this you need a good definition of bool(array1). For global operations like used on Python lists, the definition is that bool(list) == True if list is not empty, and False if it is empty. For numpy's element-wise operations, there is some disambiguity whether to check if any element evaluates to True, or all elements evaluate to True. Because both are arguably correct, numpy doesn't guess and raises a ValueError when bool() is (indirectly) called on an array.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Difference between 'and' (boolean) vs. '&' (bitwise) in python. Why difference in behavior with lists vs numpy arrays?",
        "A_Content": "  For the first example and base on the django's doc It will always return the second list, indeed a non empty list is see as a True value for Python thus python return the 'last' True value so the second list  In [74]: mylist1 = [False] In [75]: mylist2 = [False, True, False,  True, False] In [76]: mylist1 and mylist2 Out[76]: [False, True, False, True, False] In [77]: mylist2 and mylist1 Out[77]: [False]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "bit-manipulation",
            "boolean-expression",
            "ampersand"
        ],
        "URL": "https://stackoverflow.com/questions/22646463/difference-between-and-boolean-vs-bitwise-in-python-why-difference-i",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What explains the difference in behavior of boolean and bitwise operations on lists vs numpy.arrays?   I'm getting confused about the appropriate use of the '&' vs 'and' in python, illustrated in the following simple examples.       mylist1 = [True,  True,  True,  False,  True]     mylist2 = [False, True, False,  True, False]        >>> len(mylist1) == len(mylist2)     True      # ---- Example 1 ----     >>>mylist1 and mylist2      [False, True, False, True, False]     #I am confused: I would have expected [False, True, False, False, False]      # ---- Example 2 ----     >>>mylist1 & mylist2      *** TypeError: unsupported operand type(s) for &: 'list' and 'list'     #I am confused: Why not just like example 1?       # ---- Example 3 ----     >>>import numpy as np      >>> np.array(mylist1) and np.array(mylist2)      *** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()     #I am confused: Why not just like Example 4?        # ---- Example 4 ----     >>> np.array(mylist1) & np.array(mylist2)      array([False,  True, False, False, False], dtype=bool)     #This is the output I was expecting!    This answer, and this answer both helped me understand that 'and' is a boolean operation but '&' is a bitwise operation.   I was reading some information to better understand the concept of bitwise operations, but I am struggling to use that information to make sense of  my above 4 examples.   Note, in my particular situation, my desired output is a newlist where:      len(newlist) == len(mylist1)      newlist[i] == (mylist1[i] and mylist2[i]) #for every element of newlist   Example 4, above, led me to my desired output, so that is fine.   But I am left feeling confused about when/how/why I should use 'and' vs '&'. Why do lists and numpy arrays behave differently with these operators?   Can anyone help me understand the difference between boolean and bitwise operations to explain why they handle lists and numpy.arrays differently?   I just want to make sure I continue to use these operations correctly going forward. Thanks a lot for the help!  Numpy version 1.7.1  python 2.7  References all inline with text.   EDITS  1) Thanks @delnan for pointing out that in my original examples I had am ambiguity that was masking my deeper confusion. I have updated my examples to clarify my question.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Split string based on a regular expression",
        "A_Content": "  By using (,), you are capturing the group, if you simply remove them you will not have this problem.  >>> str1 = \"a    b     c      d\" >>> re.split(\" +\", str1) ['a', 'b', 'c', 'd']   However there is no need for regex, str.split without any delimiter specified will split this by whitespace for you. This would be the best way in this case.  >>> str1.split() ['a', 'b', 'c', 'd']   If you really wanted regex you can use this ('\\s' represents whitespace and it's clearer):  >>> re.split(\"\\s+\", str1) ['a', 'b', 'c', 'd']   or you can find all non-whitespace characters  >>> re.findall(r'\\S+',str1) ['a', 'b', 'c', 'd']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex"
        ],
        "URL": "https://stackoverflow.com/questions/10974932/split-string-based-on-a-regular-expression",
        "A_Votes": "115",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have the output of a command in tabular form. I'm parsing this output from a result file and storing it in a string. Each element in one row is separated by one or more whitespace characters, thus I'm using regular expressions to match 1 or more spaces and split it. However, a space is being inserted between every element:  >>> str1=\"a    b     c      d\" # spaces are irregular >>> str1 'a    b     c      d' >>> str2=re.split(\"( )+\", str1) >>> str2 ['a', ' ', 'b', ' ', 'c', ' ', 'd'] # 1 space element between!!!   Is there a better way to do this?   After each split str2 is appended to a list.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Split string based on a regular expression",
        "A_Content": "  The str.split method will automatically remove all white space between items:  >>> str1 = \"a    b     c      d\" >>> str1.split() ['a', 'b', 'c', 'd']   Docs are here: http://docs.python.org/library/stdtypes.html#str.split     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex"
        ],
        "URL": "https://stackoverflow.com/questions/10974932/split-string-based-on-a-regular-expression",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the output of a command in tabular form. I'm parsing this output from a result file and storing it in a string. Each element in one row is separated by one or more whitespace characters, thus I'm using regular expressions to match 1 or more spaces and split it. However, a space is being inserted between every element:  >>> str1=\"a    b     c      d\" # spaces are irregular >>> str1 'a    b     c      d' >>> str2=re.split(\"( )+\", str1) >>> str2 ['a', ' ', 'b', ' ', 'c', ' ', 'd'] # 1 space element between!!!   Is there a better way to do this?   After each split str2 is appended to a list.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Split string based on a regular expression",
        "A_Content": "  When you use re.split and the split pattern contains capturing groups, the groups are retained in the output.  If you don't want this, use a non-capturing group instead.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex"
        ],
        "URL": "https://stackoverflow.com/questions/10974932/split-string-based-on-a-regular-expression",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the output of a command in tabular form. I'm parsing this output from a result file and storing it in a string. Each element in one row is separated by one or more whitespace characters, thus I'm using regular expressions to match 1 or more spaces and split it. However, a space is being inserted between every element:  >>> str1=\"a    b     c      d\" # spaces are irregular >>> str1 'a    b     c      d' >>> str2=re.split(\"( )+\", str1) >>> str2 ['a', ' ', 'b', ' ', 'c', ' ', 'd'] # 1 space element between!!!   Is there a better way to do this?   After each split str2 is appended to a list.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Split string based on a regular expression",
        "A_Content": "  Its very simple actually. Try this:  str1=\"a    b     c      d\" splitStr1 = str1.split() print splitStr1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex"
        ],
        "URL": "https://stackoverflow.com/questions/10974932/split-string-based-on-a-regular-expression",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the output of a command in tabular form. I'm parsing this output from a result file and storing it in a string. Each element in one row is separated by one or more whitespace characters, thus I'm using regular expressions to match 1 or more spaces and split it. However, a space is being inserted between every element:  >>> str1=\"a    b     c      d\" # spaces are irregular >>> str1 'a    b     c      d' >>> str2=re.split(\"( )+\", str1) >>> str2 ['a', ' ', 'b', ' ', 'c', ' ', 'd'] # 1 space element between!!!   Is there a better way to do this?   After each split str2 is appended to a list.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What does preceding a string literal with “r” mean? [duplicate]",
        "A_Content": "  The r means that the string is to be treated as a raw string, which means all escape codes will be ignored.  For an example:  '\\n' will be treated as a newline character, while r'\\n' will be treated as the characters \\ followed by n.     When an 'r' or 'R' prefix is present,   a character following a backslash is   included in the string without change,   and all backslashes are left in the   string. For example, the string   literal r\"\\n\" consists of two   characters: a backslash and a   lowercase 'n'. String quotes can be   escaped with a backslash, but the   backslash remains in the string; for   example, r\"\\\"\" is a valid string   literal consisting of two characters:   a backslash and a double quote; r\"\\\"   is not a valid string literal (even a   raw string cannot end in an odd number   of backslashes). Specifically, a raw   string cannot end in a single   backslash (since the backslash would   escape the following quote character).   Note also that a single backslash   followed by a newline is interpreted   as those two characters as part of the   string, not as a line continuation.   Source: Python string literals     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "syntax",
            "literals",
            "rawstring"
        ],
        "URL": "https://stackoverflow.com/questions/4780088/what-does-preceding-a-string-literal-with-r-mean",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              What exactly do “u” and “r” string flags do, and what are raw string literals?                                        6 answers                                          I first saw it used in building regular expressions across multiple lines as a method argument to re.compile(), so I assumed that r stands for RegEx.  For example:  regex = re.compile(     r'^[A-Z]'     r'[A-Z0-9-]'     r'[A-Z]$', re.IGNORECASE )   So what does r mean in this case? Why do we need it?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What does preceding a string literal with “r” mean? [duplicate]",
        "A_Content": "  It means that escapes won’t be translated. For example:  r'\\n'   is a string with a backslash followed by the letter n. (Without the r it would be a newline.)  b does stand for byte-string and is used in Python 3, where strings are Unicode by default. In Python 2.x strings were byte-strings by default and you’d use u to indicate Unicode.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "syntax",
            "literals",
            "rawstring"
        ],
        "URL": "https://stackoverflow.com/questions/4780088/what-does-preceding-a-string-literal-with-r-mean",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              What exactly do “u” and “r” string flags do, and what are raw string literals?                                        6 answers                                          I first saw it used in building regular expressions across multiple lines as a method argument to re.compile(), so I assumed that r stands for RegEx.  For example:  regex = re.compile(     r'^[A-Z]'     r'[A-Z0-9-]'     r'[A-Z]$', re.IGNORECASE )   So what does r mean in this case? Why do we need it?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to get http headers in flask?",
        "A_Content": "  from flask import request request.headers.get('your-header-name')   request.headers is a dictionary, so you can also get your header like you would any dictionary:  request.headers['your-header-name']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "http",
            "flask",
            "http-headers",
            "authorization"
        ],
        "URL": "https://stackoverflow.com/questions/29386995/how-to-get-http-headers-in-flask",
        "A_Votes": "146",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am newbie to python and using Python Flask and generating REST API service.  I want to check authorization header which is sent by angularjs.  But I can't find way to get HTTP header in flask.  Any help for getting HTTP header authorization is appreciated.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  IBM's ICU library does that (and a lot more). It has Python bindings: PyICU.   Update: The core difference in sorting between ICU and locale.strcoll is that ICU uses the full Unicode Collation Algorithm while strcoll uses ISO 14651.  The differences between those two algorithms are briefly summarized here: http://unicode.org/faq/collation.html#13. These are rather exotic special cases, which should rarely matter in practice.  >>> import icu # pip install PyICU >>> sorted(['a','b','c','ä']) ['a', 'b', 'c', 'ä'] >>> collator = icu.Collator.createInstance(icu.Locale('de_DE.UTF-8')) >>> sorted(['a','b','c','ä'], key=collator.getSortKey) ['a', 'ä', 'b', 'c']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  I don't see this in the answers. My Application sorts according to the locale using python's standard library. It is pretty easy.  # python2.5 code below # corpus is our unicode() strings collection as a list corpus = [u\"Art\", u\"Älg\", u\"Ved\", u\"Wasa\"]  import locale # this reads the environment and inits the right locale locale.setlocale(locale.LC_ALL, \"\") # alternatively, (but it's bad to hardcode) # locale.setlocale(locale.LC_ALL, \"sv_SE.UTF-8\")  corpus.sort(cmp=locale.strcoll)  # in python2.x, locale.strxfrm is broken and does not work for unicode strings # in python3.x however: # corpus.sort(key=locale.strxfrm)     Question to Lennart and other answerers: Doesn't anyone know 'locale' or is it not up to this task?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  Try James Tauber's Python Unicode Collation Algorithm. It may not do exactly as you want, but seems well worth a look. For a bit more information about the issues, see this post by Christopher Lenz.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  You might also be interested in pyuca:  http://jtauber.com/blog/2006/01/27/python_unicode_collation_algorithm/  Though it is certainly not the most exact way, it is a very simple way to at least get it somewhat right. It also beats locale in a webapp as locale is not threadsafe and sets the language settings process-wide. It also easier to set up than PyICU which relies on an external C library.   I uploaded the script to github as the original was down at the time of this writing and I had to resort to web caches to get it:  https://github.com/href/Python-Unicode-Collation-Algorithm  I successfully used this script to sanely sort German/French/Italian text in a plone module.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  A summary and extended answer:  locale.strcoll under Python 2, and locale.strxfrm will in fact solve the problem, and does a good job, assuming that you have the locale in question installed. I tested it under Windows too, where the locale names confusingly are different, but on the other hand it seems to have all locales that are supported installed by default.  ICU doesn't necessarily do this better in practice, it however does way more. Most notably it has support for splitters that can split texts in different languages into words. This is very useful for languages that doesn't have word separators. You'll need to have a corpus of words to use as a base for the splitting, because that's not included, though.  It also has long names for the locales so you can get pretty display names for the locale, support for other calendars than Gregorian (although I'm not sure the Python interface supports that) and tons and tons of other more or less obscure locale supports.  So all in all: If you want to sort alphabetically and locale-dependent, you can use the locale module, unless you have special requirements, or also need more locale dependent functionality, like words splitter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  I see the answers have already done an excellent job, just wanted to point out one coding inefficiency in Human Sort. To apply a selective char-by-char translation to a unicode string s, it uses the code:  spec_dict = {'Å':'A', 'Ä':'A'}  def spec_order(s):     return ''.join([spec_dict.get(ch, ch) for ch in s])   Python has a much better, faster and more concise way to perform this auxiliary task (on Unicode strings -- the analogous method for byte strings has a different and somewhat less helpful specification!-):  spec_dict = dict((ord(k), spec_dict[k]) for k in spec_dict)  def spec_order(s):     return s.translate(spec_dict)   The dict you pass to the translate method has Unicode ordinals (not strings) as keys, which is why we need that rebuilding step from the original char-to-char spec_dict. (Values in the dict you pass to translate [as opposed to keys, which must be ordinals] can be Unicode ordinals, arbitrary Unicode strings, or None to remove the corresponding character as part of the translation, so it's easy to specify \"ignore a certain character for sorting purposes\", \"map ä to ae for sorting purposes\", and the like).  In Python 3, you can get the \"rebuilding\" step more simply, e.g.:  spec_dict = ''.maketrans(spec_dict)   See the docs for other ways you can use this maketrans static method in Python 3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  A Complete UCA Solution  The simplest, easiest, and most straightforward way to do this it to make a callout to the Perl library module, Unicode::Collate::Locale, which is  a subclass of the standard Unicode::Collate module. All you need do is pass the constructor a locale value of \"xv\" for Sweden.    (You may not neccesarily appreciate this for Swedish text, but because Perl uses abstract characters, you can use any Unicode code point you please — no matter the platform or build! Few languages offer such convenience. I mention it because I’ve fighting a losing battle with Java a lot over this maddening problem lately.)  The problem is that I do not know how to access a Perl module from Python — apart, that is, from using a shell callout or two-sided pipe. To that end, I have therefore provided you with a complete working script called ucsort that you can call to do exactly what you have asked for with perfect ease.   This script is 100% compliant with the full Unicode Collation Algorithm, with all tailoring options supported!!  And if you have an optional module installed or run Perl 5.13 or better, then you have full access to easy-to-use CLDR locales.  See below.  Demonstration  Imagine an input set ordered this way:  b o i j n l m å y e v s k h d f g t ö r x p z a ä c u q   A default sort by code point yields:  a b c d e f g h i j k l m n o p q r s t u v x y z ä å ö   which is incorrect by everybody’s book.  Using my script, which uses the Unicode Collation Algorithm, you get this order:  % perl ucsort /tmp/swedish_alphabet | fmt a å ä b c d e f g h i j k l m n o ö p q r s t u v x y z   That is the default UCA sort.  To get the Swedish locale, call ucsort this way:  % perl ucsort --locale=sv /tmp/swedish_alphabet | fmt a b c d e f g h i j k l m n o p q r s t u v x y z å ä ö   Here is a better input demo. First, the input set:  % fmt /tmp/swedish_set cTD cDD Cöd Cbd cAD cCD cYD Cud cZD Cod cBD Cnd cQD cFD Ced Cfd cOD cLD cXD Cid Cpd cID Cgd cVD cMD cÅD cGD Cqd Cäd cJD Cdd Ckd cÖD cÄD Ctd Czd Cxd cHD cND cKD Cvd Chd Cyd cUD Cld Cmd cED Crd Cad Cåd Ccd cRD cSD Csd Cjd cPD   By code point, that sorts this way:  Cad Cbd Ccd Cdd Ced Cfd Cgd Chd Cid Cjd Ckd Cld Cmd Cnd Cod Cpd Cqd Crd Csd Ctd Cud Cvd Cxd Cyd Czd Cäd Cåd Cöd cAD cBD cCD cDD cED cFD cGD cHD cID cJD cKD cLD cMD cND cOD cPD cQD cRD cSD cTD cUD cVD cXD cYD cZD cÄD cÅD cÖD   But using the default UCA makes it sort this way:  % ucsort /tmp/swedish_set | fmt cAD Cad cÅD Cåd cÄD Cäd cBD Cbd cCD Ccd cDD Cdd cED Ced cFD Cfd cGD Cgd cHD Chd cID Cid cJD Cjd cKD Ckd cLD Cld cMD Cmd cND Cnd cOD Cod cÖD Cöd cPD Cpd cQD Cqd cRD Crd cSD Csd cTD Ctd cUD Cud cVD Cvd cXD Cxd cYD Cyd cZD Czd   But in the Swedish locale, this way:  % ucsort --locale=sv /tmp/swedish_set | fmt cAD Cad cBD Cbd cCD Ccd cDD Cdd cED Ced cFD Cfd cGD Cgd cHD Chd cID Cid cJD Cjd cKD Ckd cLD Cld cMD Cmd cND Cnd cOD Cod cPD Cpd cQD Cqd cRD Crd cSD Csd cTD Ctd cUD Cud cVD Cvd cXD Cxd cYD Cyd cZD Czd cÅD Cåd cÄD Cäd cÖD Cöd   If you prefer uppercase to sort before lowercase, do this:  % ucsort --upper-before-lower --locale=sv /tmp/swedish_set | fmt Cad cAD Cbd cBD Ccd cCD Cdd cDD Ced cED Cfd cFD Cgd cGD Chd cHD Cid cID Cjd cJD Ckd cKD Cld cLD Cmd cMD Cnd cND Cod cOD Cpd cPD Cqd cQD Crd cRD Csd cSD Ctd cTD Cud cUD Cvd cVD Cxd cXD Cyd cYD Czd cZD Cåd cÅD Cäd cÄD Cöd cÖD   Customized Sorts  You can do many other things with ucsort. For example, here is how to sort titles in English:  % ucsort --preprocess='s/^(an?|the)\\s+//i' /tmp/titles Anathem The Book of Skulls A Civil Campaign The Claw of the Conciliator The Demolished Man Dune An Early Dawn The Faded Sun: Kesrith The Fall of Hyperion A Feast for Crows Flowers for Algernon The Forbidden Tower Foundation and Empire Foundation’s Edge The Goblin Reservation The High Crusade Jack of Shadows The Man in the High Castle The Ringworld Engineers The Robots of Dawn A Storm of Swords Stranger in a Strange Land There Will Be Time The White Dragon   You will need Perl 5.10.1 or better to run the script in general. For locale support, you must either install the optional CPAN module Unicode::Collate::Locale. Alternately, you can install a development versions of Perl, 5.13+, which include that module standardly.  Calling Conventions  This is a rapid prototype, so ucsort is mostly un(der)documented. But this is its SYNOPSIS of what switches/options it accepts on the command line:      # standard options     --help|?     --man|m     --debug|d      # collator constructor options     --backwards-levels=i     --collation-level|level|l=i     --katakana-before-hiragana     --normalization|n=s     --override-CJK=s     --override-Hangul=s     --preprocess|P=s     --upper-before-lower|u     --variable=s      # program specific options     --case-insensitive|insensitive|i     --input-encoding|e=s     --locale|L=s     --paragraph|p     --reverse-fields|last     --reverse-output|r     --right-to-left|reverse-input   Yeah, ok: that’s really the argument list I use for the call to Getopt::Long, but you get the idea. :)   If you can figure out how to call Perl library modules from Python directly without calling a Perl script, by all means do so.  I just don’t know how myself.  I’d love to learn how.  In the meantime, I believe this script will do what you need done in all its particular — and more!  I now use this for all of text sorting. It finally does what I’ve needed for a long, long time.   The only downside is that --locale argument causes performance to go down the tubes, although it’s plenty fast enough for regular, non-locale but still 100% UCA compliant sorting.  Since it loads everything in memory, you probably don’t want to use this on gigabyte documents. I use it many times a day, and it sure it great having sane text sorting at last.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Solving “DLL load failed: %1 is not a valid Win32 application.” for Pygame",
        "A_Content": "  It could be due to the architecture of your OS. Is your OS 64 Bit and have you installed 64 bit version of Python? It may help to install both 32 bit version Python 3.1 and Pygame, which is available officially only in 32 bit and you won't face this problem.  I see that 64 bit pygame is maintained here, you might also want to try uninstalling Pygame only and install the 64 bit version on your existing python3.1, if not choose go for both 32-bit version.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pygame"
        ],
        "URL": "https://stackoverflow.com/questions/4676433/solving-dll-load-failed-1-is-not-a-valid-win32-application-for-pygame",
        "A_Votes": "145",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I recently installed Python 3.1 and the Pygame module for Python 3.1  When I type import python in the console I get the following error:  Traceback (most recent call last):   File \"<pyshell#2>\", line 1, in <module>     import pygame   File \"C:\\Python31\\lib\\site-packages\\pygame\\__init__.py\", line 95, in <module>     from pygame.base import * ImportError: DLL load failed: %1 is not a valid Win32 application.   Please help!     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  To implement it you will need to read about \"Unicode collation algorithm\" see http://en.wikipedia.org/wiki/Unicode_collation_algorithm  http://www.unicode.org/unicode/reports/tr10/  a sample implementation is here  http://jtauber.com/blog/2006/01/27/python_unicode_collation_algorithm/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  Lately I've been using zope.ucol (https://pypi.python.org/pypi/zope.ucol) for this task. For example, sorting the german ß:  >>> import zope.ucol >>> collator = zope.ucol.Collator(\"de-de\") >>> mylist = [u\"a\", u'x', u'\\u00DF'] >>> print mylist [u'a', u'x', u'\\xdf'] >>> print sorted(mylist, key=collator.key) [u'a', u'\\xdf', u'x']   zope.ucol also wraps ICU, so would be an alternative to PyICU.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  Jeff Atwood wrote a good post on Natural Sort Order, in it he linked to a script which does pretty much what you ask.  It's not a trivial script, by any means, but it does the trick.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I sort unicode strings alphabetically in Python?",
        "A_Content": "  It is far from a complete solution for your use case, but you could take a look at the unaccent.py script from effbot.org. What it basically does is remove all accents from a text. You can use that 'sanitized' text to sort alphabetically. (For a better description see this page.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "unicode",
            "internationalization",
            "collation"
        ],
        "URL": "https://stackoverflow.com/questions/1097908/how-do-i-sort-unicode-strings-alphabetically-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python sorts by byte value by default, which means é comes after z and other equally funny things. What is the best way to sort alphabetically in Python?  Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that åäö should be sorted after z in Swedish, but that ü should be sorted by u, etc. Unicode support is thereby pretty much a requirement.  If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Solving “DLL load failed: %1 is not a valid Win32 application.” for Pygame",
        "A_Content": "  Looks like the question has been long ago answered but the solution did not work for me.  When I was getting that error, I was able to fix the problem by downloading PyWin32     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pygame"
        ],
        "URL": "https://stackoverflow.com/questions/4676433/solving-dll-load-failed-1-is-not-a-valid-win32-application-for-pygame",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently installed Python 3.1 and the Pygame module for Python 3.1  When I type import python in the console I get the following error:  Traceback (most recent call last):   File \"<pyshell#2>\", line 1, in <module>     import pygame   File \"C:\\Python31\\lib\\site-packages\\pygame\\__init__.py\", line 95, in <module>     from pygame.base import * ImportError: DLL load failed: %1 is not a valid Win32 application.   Please help!     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Solving “DLL load failed: %1 is not a valid Win32 application.” for Pygame",
        "A_Content": "  I had installed Python 32 bit version and psycopg2 64 bit version to get this problem. I installed psycopg2 32 bit version and then it worked.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pygame"
        ],
        "URL": "https://stackoverflow.com/questions/4676433/solving-dll-load-failed-1-is-not-a-valid-win32-application-for-pygame",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently installed Python 3.1 and the Pygame module for Python 3.1  When I type import python in the console I get the following error:  Traceback (most recent call last):   File \"<pyshell#2>\", line 1, in <module>     import pygame   File \"C:\\Python31\\lib\\site-packages\\pygame\\__init__.py\", line 95, in <module>     from pygame.base import * ImportError: DLL load failed: %1 is not a valid Win32 application.   Please help!     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Solving “DLL load failed: %1 is not a valid Win32 application.” for Pygame",
        "A_Content": "  Had this issue on Python 2.7.9, solved by updating to Python 2.7.10 (unreleased when this question was asked and answered).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pygame"
        ],
        "URL": "https://stackoverflow.com/questions/4676433/solving-dll-load-failed-1-is-not-a-valid-win32-application-for-pygame",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently installed Python 3.1 and the Pygame module for Python 3.1  When I type import python in the console I get the following error:  Traceback (most recent call last):   File \"<pyshell#2>\", line 1, in <module>     import pygame   File \"C:\\Python31\\lib\\site-packages\\pygame\\__init__.py\", line 95, in <module>     from pygame.base import * ImportError: DLL load failed: %1 is not a valid Win32 application.   Please help!     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Solving “DLL load failed: %1 is not a valid Win32 application.” for Pygame",
        "A_Content": "  Another possible cause of similar issue could be wrong processorArchitecture in the cx_freeze manifest, trying to load x86 common controls dll in x64 process - should be fixed by this patch:  https://bitbucket.org/anthony_tuininga/cx_freeze/pull-request/71/changed-x86-in-windows-manifest-to/diff     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pygame"
        ],
        "URL": "https://stackoverflow.com/questions/4676433/solving-dll-load-failed-1-is-not-a-valid-win32-application-for-pygame",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently installed Python 3.1 and the Pygame module for Python 3.1  When I type import python in the console I get the following error:  Traceback (most recent call last):   File \"<pyshell#2>\", line 1, in <module>     import pygame   File \"C:\\Python31\\lib\\site-packages\\pygame\\__init__.py\", line 95, in <module>     from pygame.base import * ImportError: DLL load failed: %1 is not a valid Win32 application.   Please help!     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  To add to the end of the list:  list.append('foo')   To insert at the beginning:  list.insert(0, 'foo')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  Sticking to the method you are using to insert it, use  list[:0] = ['foo']   http://docs.python.org/release/2.6.6/library/stdtypes.html#mutable-sequence-types     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  Another option is using the overloaded + operator:  >>> l = ['hello','world'] >>> l = ['foo'] + l >>> l ['foo', 'hello', 'world']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  >>> li = ['aaa', 'bbb'] >>> li.insert(0, 'wow!') >>> li ['wow!', 'aaa', 'bbb']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  Don't use list as a variable name. It's a built in that you are masking.  To insert, use the insert function of lists.  l = ['hello','world'] l.insert(0, 'foo') print l ['foo', 'hello', 'world']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  best put brackets around foo, and use +=  list+=['foo']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Inserting a string into a list without getting split into characters",
        "A_Content": "  You have to add another list:  list[:0]=['foo']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8243188/inserting-a-string-into-a-list-without-getting-split-into-characters",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and can't find a way to insert a string into a list without it getting split into individual characters:  >>> list=['hello','world'] >>> list ['hello', 'world'] >>> list[:0]='foo' >>> list ['f', 'o', 'o', 'hello', 'world']   What should I do to have:  ['foo', 'hello', 'world']   Searched the docs and the Web, but it has not been my day.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  Update: For Python 3, check Ben's answer    To attach a message to the current exception and re-raise it: (the outer try/except is just to show the effect)  For python 2.x where x>=6:  try:     try:       raise ValueError  # something bad...     except ValueError as err:       err.message=err.message+\" hello\"       raise              # re-raise current exception except ValueError as e:     print(\" got error of type \"+ str(type(e))+\" with message \" +e.message)   This will also do the right thing if err is derived from ValueError. For example UnicodeDecodeError.   Note that you can add whatever you like to err. For example err.problematic_array=[1,2,3].    Edit: @Ducan points in a comment the above does not work with python 3 since .message is not a member of ValueError. Instead you could use this (valid python 2.6 or later or 3.x):  try:     try:       raise ValueError     except ValueError as err:        if not err.args:             err.args=('',)        err.args = err.args + (\"hello\",)        raise  except ValueError as e:     print(\" error was \"+ str(type(e))+str(e.args))   Edit2:  Depending on what the purpose is, you can also opt for adding the extra information under your own variable name. For both python2 and python3:  try:     try:       raise ValueError     except ValueError as err:        err.extra_info = \"hello\"        raise  except ValueError as e:     print(\" error was \"+ str(type(e))+str(e))     if 'extra_info' in dir(e):        print e.extra_info      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  I realize this question has been around for awhile, but once you're lucky enough to only support python 3.x, this really becomes a thing of beauty :)  raise from  We can chain the exceptions using raise from.  try:     1 / 0 except ZeroDivisionError as e:     raise Exception('Smelly socks') from e   In this case, the exception your caller would catch has the line number of the place where we raise our exception.  Traceback (most recent call last):   File \"test.py\", line 2, in <module>     1 / 0 ZeroDivisionError: division by zero  The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File \"test.py\", line 4, in <module>     raise Exception('Smelly socks') from e Exception: Smelly socks   Notice the bottom exception only has the stacktrace from where we raised our exception. Your caller could still get the original exception by accessing the __cause__ attribute of the exception they catch.  with_traceback  Or you can use with_traceback.  try:     1 / 0 except ZeroDivisionError as e:     raise Exception('Smelly socks').with_traceback(e.__traceback__)   Using this form, the exception your caller would catch has the traceback from where the original error occurred.  Traceback (most recent call last):   File \"test.py\", line 2, in <module>     1 / 0 ZeroDivisionError: division by zero  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File \"test.py\", line 4, in <module>     raise Exception('Smelly socks').with_traceback(e.__traceback__)   File \"test.py\", line 2, in <module>     1 / 0 Exception: Smelly socks   Notice the bottom exception has the line where we performed the invalid division as well as the line where we reraise the exception.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  try:     try:         int('a')     except ValueError as e:         raise ValueError('There is a problem: {0}'.format(e)) except ValueError as err:     print err   prints:  There is a problem: invalid literal for int() with base 10: 'a'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  It seems all the answers are adding info to e.args[0], thereby altering the existing error message.  Is there a downside to extending the args tuple instead?  I think the possible upside is, you can leave the original error message alone for cases where parsing that string is needed; and you could add multiple elements to the tuple if your custom error handling produced several messages or error codes, for cases where the traceback would be parsed programmatically (like via a system monitoring tool).  ## Approach #1, if the exception may not be derived from Exception and well-behaved:  def to_int(x):     try:         return int(x)     except Exception as e:         e.args = (e.args if e.args else tuple()) + ('Custom message',)         raise  >>> to_int('12') 12  >>> to_int('12 monkeys') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in to_int ValueError: (\"invalid literal for int() with base 10: '12 monkeys'\", 'Custom message')   or  ## Approach #2, if the exception is always derived from Exception and well-behaved:  def to_int(x):     try:         return int(x)     except Exception as e:         e.args += ('Custom message',)         raise  >>> to_int('12') 12  >>> to_int('12 monkeys') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in to_int ValueError: (\"invalid literal for int() with base 10: '12 monkeys'\", 'Custom message')   Can you see a downside to this approach?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  This is the function I use to modify the exception message in Python 2.7 and 3.x while preserving the original traceback. It requires six  def reraise_modify(caught_exc, append_msg, prepend=False):     \"\"\"Append message to exception while preserving attributes.      Preserves exception class, and exception traceback.      Note:         This function needs to be called inside an except because         `sys.exc_info()` requires the exception context.      Args:         caught_exc(Exception): The caught exception object         append_msg(str): The message to append to the caught exception         prepend(bool): If True prepend the message to args instead of appending      Returns:         None      Side Effects:         Re-raises the exception with the preserved data / trace but         modified message     \"\"\"     ExceptClass = type(caught_exc)     # Keep old traceback     traceback = sys.exc_info()[2]     if not caught_exc.args:         # If no args, create our own tuple         arg_list = [append_msg]     else:         # Take the last arg         # If it is a string         # append your message.         # Otherwise append it to the         # arg list(Not as pretty)         arg_list = list(caught_exc.args[:-1])         last_arg = caught_exc.args[-1]         if isinstance(last_arg, str):             if prepend:                 arg_list.append(append_msg + last_arg)             else:                 arg_list.append(last_arg + append_msg)         else:             arg_list += [last_arg, append_msg]     caught_exc.args = tuple(arg_list)     six.reraise(ExceptClass,                 caught_exc,                 traceback)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  This code template should allow you to raise an exception with a custom message.  try:      raise ValueError except ValueError as err:     raise type(err)(\"my message\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  The current answer did not work good for me, if the exception is not re-caught the appended message is not shown.  But doing like below both keeps the trace and shows the appended message regardless if the exception is re-caught or not.  try:   raise ValueError(\"Original message\") except ValueError as err:   t, v, tb = sys.exc_info()   raise t, ValueError(err.message + \" Appended Info\"), tb   ( I used Python 2.7, have not tried it in Python 3 )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  Python 3 built-in exceptions have the strerror field:  except ValueError as err:   err.strerror = \"New error message\"   raise err      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  Either raise the new exception with your error message using  raise Exception('your error message')   or  raise ValueError('your error message')   within the place where you want to raise it OR attach (replace) error message into current exception using 'from':  except ValueError as e:   raise ValueError('your message') from e      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I raise the same Exception with a custom message in Python?",
        "A_Content": "  if you want to custom the error type, a simple thing you can do is to define an error class based on ValueError.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "message"
        ],
        "URL": "https://stackoverflow.com/questions/9157210/how-do-i-raise-the-same-exception-with-a-custom-message-in-python",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this try block in my code:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise ValueError(errmsg)   Strictly speaking, I am actually raising another ValueError, not the ValueError thrown by do_something...(), which is referred to as err in this case. How do I attach a custom message to err? I try the following code but fails due to err, a ValueError instance, not being callable:  try:     do_something_that_might_raise_an_exception() except ValueError as err:     errmsg = 'My custom error message.'     raise err(errmsg)      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  The Snack Sound Toolkit can play wav, au and mp3 files.    s = Sound()  s.read('sound.wav')  s.play()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  For Windows, you can use winsound. It's built in  import winsound  winsound.PlaySound('sound.wav', winsound.SND_FILENAME)   You should be able to use ossaudiodev for linux:  from wave import open as waveOpen from ossaudiodev import open as ossOpen s = waveOpen('tada.wav','rb') (nc,sw,fr,nf,comptype, compname) = s.getparams( ) dsp = ossOpen('/dev/dsp','w') try:   from ossaudiodev import AFMT_S16_NE except ImportError:   from sys import byteorder   if byteorder == \"little\":     AFMT_S16_NE = ossaudiodev.AFMT_S16_LE   else:     AFMT_S16_NE = ossaudiodev.AFMT_S16_BE dsp.setparameters(AFMT_S16_NE, nc, fr) data = s.readframes(nf) s.close() dsp.write(data) dsp.close()   (Credit for ossaudiodev: Bill Dandreta http://mail.python.org/pipermail/python-list/2004-October/288905.html)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "87",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  This seems ridiculous and far fetched but you could always use Windows (or whatever OS you prefer) to manage the sound for you!  import os os.system(\"start C:/thepathyouwant/file\")   Simple, no extensions, somewhat slow and junky, but working.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  Definitely use Pyglet for this. It's kind of a large package, but it is pure python with no extension modules. That will definitely be the easiest for deployment. It's also got great format and codec support.  import pyglet  music = pyglet.resource.media('music.mp3') music.play()  pyglet.app.run()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  After the play() command add a delay of say 10 secs or so, it'll work  import pygame  import time  pygame.init()  pygame.mixer.music.load(\"test.wav\")  pygame.mixer.music.play()  time.sleep(10)   This also plays .mp3 files.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  pyMedia's sound example does just that. This should be all you need.  import time, wave, pymedia.audio.sound as sound f= wave.open( 'YOUR FILE NAME', 'rb' ) sampleRate= f.getframerate() channels= f.getnchannels() format= sound.AFMT_S16_LE snd= sound.Output( sampleRate, channels, format ) s= f.readframes( 300000 ) snd.play( s )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  wxPython has support for playing wav files on Windows and Unix - I am not sure if this includes Macs.  However it only support wav files as far as I can tell - it does not support other common formats such as mp3 or ogg.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  I like pygame, and the command below should work:  pygame.init() pygame.mixer.Sound('sound.wav').play()   but it doesn't on either of my computers, and there is limited help on the subject out there. edit: I figured out why the pygame sound isn't working for me, it's not loading most sounds correctly, the 'length' attribute is ~0.0002 when I load them. maybe loading them using something other than mygame will get it morking more generally.  with pyglet I'm getting a resource not found error Using the above example, wigh both relative and full paths to the files.  using pyglet.media.load() instead of pyglet.resource.media() lets me load the files.  but sound.play() only plays the first fraction of a second of the file, unless I run pyglet.app.run() which blocks everything else...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  I just released a simple python wrapper around sox that will play a sound with Python.  It's very easy to install as you need Python 2.6 or greater, sox (easy to get binaries for most architectures) and the wrapper ( https://github.com/standarddeviant/sound4python ).  If you don't have sox, go here: http://sourceforge.net/projects/sox/files/sox/  You would play audio with it by:  from sound4python import sound import random a = [] for idx in xrange(1*16000):     a.append(random.randint(-16384,16384)) sound(a)   Keep in mind, the only parts actually involved in playing audio are just these:  from sound4python import sound ... sound(a)          ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Play a Sound with Python [duplicate]",
        "A_Content": "  For Linux user, if low level pcm data manipulation is needed, try alsaaudio module. There is a playwav.py example inside the package too.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio",
            "platform-independent"
        ],
        "URL": "https://stackoverflow.com/questions/307305/play-a-sound-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Play audio with Python                                        21 answers                                          What's the easiest way to play a sound file (.wav) in Python? By easiest I mean both most platform independent and requiring the least dependencies. pygame is certainly an option, but it seems overkill for just sound.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What version of Visual Studio is Python on my computer compiled with?",
        "A_Content": "  For this version of Visual C++  Use this compiler version Visual C++ 4.x                  MSC_VER=1000 Visual C++ 5                    MSC_VER=1100 Visual C++ 6                    MSC_VER=1200 Visual C++ .NET                 MSC_VER=1300 Visual C++ .NET 2003            MSC_VER=1310 Visual C++ 2005  (8.0)          MSC_VER=1400 Visual C++ 2008  (9.0)          MSC_VER=1500 Visual C++ 2010 (10.0)          MSC_VER=1600 Visual C++ 2012 (11.0)          MSC_VER=1700 Visual C++ 2013 (12.0)          MSC_VER=1800 Visual C++ 2015 (14.0)          MSC_VER=1900 Visual C++ 2017 (15.0)          MSC_VER=1910      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "visual-studio",
            "visual-c++"
        ],
        "URL": "https://stackoverflow.com/questions/2676763/what-version-of-visual-studio-is-python-on-my-computer-compiled-with",
        "A_Votes": "155",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to find out the version of Visual Studio that is used to compile the Python on my computer  It says   Python 2.6.2 (r262:71605, Apr 14 2009, 22:40:02) [MSC v.1500 32 bit (Intel)] on win32   What I do not understand is this MSC V.1500 designation. Does it mean it is compiled with Visual Studio 2005? I cannot find this information on http://python.org.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "What version of Visual Studio is Python on my computer compiled with?",
        "A_Content": "  MSC v.1500 appears to be Visual C++ 2008 according to this thread on the OpenCobol forums (of all places).    The MSDN page on Predefined Macros indicates 1500 to be the result of the _MSC_VER macro.  This other forum post mentions that      (For reference, Visual Studio 2003 has _MSC_VER = 1310; Visual Studio 2005 has _MSC_VER = 1400; Visual Studio 2008 has _MSC_VER = 1500.)    The above MSDN link said that 1600 indicates VS2010.  Strangely, I wasn't able to find that info about the earlier _MSC_VER values on MSDN.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "visual-studio",
            "visual-c++"
        ],
        "URL": "https://stackoverflow.com/questions/2676763/what-version-of-visual-studio-is-python-on-my-computer-compiled-with",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to find out the version of Visual Studio that is used to compile the Python on my computer  It says   Python 2.6.2 (r262:71605, Apr 14 2009, 22:40:02) [MSC v.1500 32 bit (Intel)] on win32   What I do not understand is this MSC V.1500 designation. Does it mean it is compiled with Visual Studio 2005? I cannot find this information on http://python.org.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to read keyboard-input?",
        "A_Content": "  try   raw_input('Enter your input:')  # If you use Python 2 input('Enter your input:')      # If you use Python 3   and if you want to have a numeric value  just convert it:   try:     mode=int(raw_input('Input:')) except ValueError:     print \"Not a number\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "input",
            "keyboard"
        ],
        "URL": "https://stackoverflow.com/questions/5404068/how-to-read-keyboard-input",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to read data from the keyboard in python  I try this:  nb = input('Choose a number') print ('Number%s \\n' % (nb))   But it doesn't work, neither with eclipse nor in the terminal, it's always stop of the question. I can type a number but after nothing happen.  Do you know why?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to read keyboard-input?",
        "A_Content": "  It seems that you are mixing different Pythons here (Python 2.x vs. Python 3.x)... This is basically correct:  nb = input('Choose a number: ')   The problem is that it is only supported in Python 3. As @sharpner answered, for older versions of Python (2.x), you have to use the function raw_input:  nb = raw_input('Choose a number: ')   If you want to convert that to a number, then you should try:  number = int(nb)   ... though you need to take into account that this can raise an exception:  try:     number = int(nb) except ValueError:     print(\"Invalid number\")   And if you want to print the number using formatting, in Python 3 str.format() is recommended:  print(\"Number: {0}\\n\".format(number))   Instead of:  print('Number %s \\n' % (nb))   But both options (str.format() and %) do work in both Python 2.7 and Python 3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "input",
            "keyboard"
        ],
        "URL": "https://stackoverflow.com/questions/5404068/how-to-read-keyboard-input",
        "A_Votes": "76",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to read data from the keyboard in python  I try this:  nb = input('Choose a number') print ('Number%s \\n' % (nb))   But it doesn't work, neither with eclipse nor in the terminal, it's always stop of the question. I can type a number but after nothing happen.  Do you know why?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to read keyboard-input?",
        "A_Content": "  input([prompt]) is equivalent to eval(raw_input(prompt)) and available since python 2.6  As it is unsafe (because of eval), raw_input should be preferred for critical applications.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "input",
            "keyboard"
        ],
        "URL": "https://stackoverflow.com/questions/5404068/how-to-read-keyboard-input",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to read data from the keyboard in python  I try this:  nb = input('Choose a number') print ('Number%s \\n' % (nb))   But it doesn't work, neither with eclipse nor in the terminal, it's always stop of the question. I can type a number but after nothing happen.  Do you know why?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to read keyboard-input?",
        "A_Content": "  This should work   yourvar = input('Choose a number: ') print('you entered: ' + yourvar)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "input",
            "keyboard"
        ],
        "URL": "https://stackoverflow.com/questions/5404068/how-to-read-keyboard-input",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to read data from the keyboard in python  I try this:  nb = input('Choose a number') print ('Number%s \\n' % (nb))   But it doesn't work, neither with eclipse nor in the terminal, it's always stop of the question. I can type a number but after nothing happen.  Do you know why?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "ImportError: No module named 'Tkinter' [closed]",
        "A_Content": "  I have been using Tkinter for a while now. Why don't you try this and let me know if it worked?  try:     # for Python2     from Tkinter import *   ## notice capitalized T in Tkinter  except ImportError:     # for Python3     from tkinter import *   ## notice lowercase 't' in tkinter here   Here is the reference link and here is the doc     ",
        "Language": "Python",
        "Tags": [
            "python",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/25905540/importerror-no-module-named-tkinter",
        "A_Votes": "136",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    For some reason I can't use the Tkinter module.. I have no idea what could cause it, and it's so annoying, is there anything wrong with this line?  import Tkinter   Also tried running it, in the python terminal, still don't work..     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "ImportError: No module named 'Tkinter' [closed]",
        "A_Content": "  As you are using Python 3, the module has been renamed to tkinter, as stated in the documentation:     Note Tkinter has been renamed to tkinter in Python 3. The 2to3 tool   will automatically adapt imports when converting your sources to   Python 3.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/25905540/importerror-no-module-named-tkinter",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason I can't use the Tkinter module.. I have no idea what could cause it, and it's so annoying, is there anything wrong with this line?  import Tkinter   Also tried running it, in the python terminal, still don't work..     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Good examples of python-memcache (memcached) being used in Python? [closed]",
        "A_Content": "  It's fairly simple. You write values using keys and expiry times. You get values using keys. You can expire keys from the system.  Most clients follow the same rules. You can read the generic instructions and best practices on the memcached homepage.  If you really want to dig into it, I'd look at the source. Here's the header comment:  \"\"\" client module for memcached (memory cache daemon)  Overview ========  See U{the MemCached homepage<http://www.danga.com/memcached>} for more about memcached.  Usage summary =============  This should give you a feel for how this module operates::      import memcache     mc = memcache.Client(['127.0.0.1:11211'], debug=0)      mc.set(\"some_key\", \"Some value\")     value = mc.get(\"some_key\")      mc.set(\"another_key\", 3)     mc.delete(\"another_key\")      mc.set(\"key\", \"1\")   # note that the key used for incr/decr must be a string.     mc.incr(\"key\")     mc.decr(\"key\")  The standard way to use memcache with a database is like this::      key = derive_key(obj)     obj = mc.get(key)     if not obj:         obj = backend_api.get(...)         mc.set(key, obj)      # we now have obj, and future passes through this code     # will use the object from the cache.  Detailed Documentation ======================  More detailed documentation is available in the L{Client} class. \"\"\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "memcached"
        ],
        "URL": "https://stackoverflow.com/questions/868690/good-examples-of-python-memcache-memcached-being-used-in-python",
        "A_Votes": "140",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm writing a web app using Python and the web.py framework, and I need to use memcached throughout.  I've been searching the internet trying to find some good documentation on the python-memcached module, but all I could find was this example on the MySQL website, and the documentation on its methods isn't great.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Good examples of python-memcache (memcached) being used in Python? [closed]",
        "A_Content": "  I would advise you to use pylibmc instead.  It can act as a drop-in replacement of python-memcache, but a lot faster(as it's written in C). And you can find handy documentation for it here.  And to the question, as pylibmc just acts as a drop-in replacement, you can still refer to documentations of pylibmc for your python-memcache programming.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "memcached"
        ],
        "URL": "https://stackoverflow.com/questions/868690/good-examples-of-python-memcache-memcached-being-used-in-python",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a web app using Python and the web.py framework, and I need to use memcached throughout.  I've been searching the internet trying to find some good documentation on the python-memcached module, but all I could find was this example on the MySQL website, and the documentation on its methods isn't great.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Good examples of python-memcache (memcached) being used in Python? [closed]",
        "A_Content": "  A good rule of thumb: use the built-in help system in Python. Example below...  jdoe@server:~$ python Python 2.7.3 (default, Aug  1 2012, 05:14:39)  [GCC 4.6.3] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import memcache >>> dir() ['__builtins__', '__doc__', '__name__', '__package__', 'memcache'] >>> help(memcache)  ------------------------------------------ NAME     memcache - client module for memcached (memory cache daemon)  FILE     /usr/lib/python2.7/dist-packages/memcache.py  MODULE DOCS     http://docs.python.org/library/memcache  DESCRIPTION     Overview     ========      See U{the MemCached homepage<http://www.danga.com/memcached>} for more about memcached.      Usage summary     ============= ... ------------------------------------------      ",
        "Language": "Python",
        "Tags": [
            "python",
            "memcached"
        ],
        "URL": "https://stackoverflow.com/questions/868690/good-examples-of-python-memcache-memcached-being-used-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a web app using Python and the web.py framework, and I need to use memcached throughout.  I've been searching the internet trying to find some good documentation on the python-memcached module, but all I could find was this example on the MySQL website, and the documentation on its methods isn't great.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  There are a few options:   You could use Selenium Grid so that the browser is opened on a completely different machine (or virtual machine) that you can then connect to via VNC or Remote Desktop Connection if you wanted to see the browser.   Also, another option: if you run a Jenkins foreground process on that remote server, it can execute your test project on the desktop. You can run Selenium 'headless' on Linux in XVFB. I've never tried doing this and doubt it's really worth the effort. http://www.alittlemadness.com/2008/03/05/running-selenium-headless/ You can wrap Selenium RC in a Windows service. http://support.microsoft.com/kb/137890 . Except that permissions constraints on later versions of windows will probably prevent Selenium from accessing the desktop like Windows 2000 used to allow us to do. Another option would be to use something like WebDriver HTMLUnitDriver, which doesn't launch a 'real' browser. http://code.google.com/p/webdriver/  .  Also there is a PhantomJS option as well as a 'headless Chrome' that you could use. Of course there's also the option of using a service like SauceLabs, where you can get your tests to be run in the cloud. After your tests have completed you can watch a video of them running.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "84",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  On Linux, you can run WebDriver in a headless (virtual) display to hide the browser.  This can be done with Xvfb (X virtual framebuffer).  You can control Xvfb directly from Python code using xvfbwrapper: https://github.com/cgoldberg/xvfbwrapper  Python code for running headless would look like this:  from selenium import webdriver from xvfbwrapper import Xvfb  display = Xvfb() display.start()  # now Firefox will run in a virtual display.  # you will not see the browser. driver = webdriver.Firefox() driver.get('http://www.google.com')  print(driver.title) driver.quit()  display.stop()   Install dependencies on Debian/Ubuntu:  $ sudo apt-get install xvfb $ pip install xvfbwrapper      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  I easily managed to hide the browser window.  Just install PhantomJS. Then, change this line:  driver = webdriver.Firefox()   to:  driver = webdriver.PhantomJS()   The rest of your code won't need to be changed and no browser will open. For debugging purposes, use driver.save_screenshot('screen.png') at different steps of your code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  +1 for Selenium RC as a windows service.  For having the tests run completely hidden, I think you don't have much solutions if you're on windows.   What I'd do it to dedicate a computer in your LAN to be online all the time and have a selenium RC server running. So you use that computer's IP instead of localhost to run your tests. For example:  browser = selenium(\"10.15.12.34\",4444,\"*firefox\",\"http://saucelabs.com\")   (considering that that's the ip of the computer running the server).  Having that setup, you run your tests in you computer, the browsers and the RC server window are in another computer and the go back to yours once done.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  On Linux, you can run your test browser on a virtual display. You will need the xvfb package for creating a virtual X server. On Debian based distros, just run  sudo apt-get install xvfb   There is a nice tool ephemeral-x.sh that will conveniently set up any command to run on the virtual display. Download it and make it executable:  wget https://raw.github.com/jordansissel/xdotool/master/t/ephemeral-x.sh chmod +x ephemeral-x.sh   Then you can simply use it to start the Selenium server:  ./ephemeral-x.sh java -jar selenium-standalone.jar   All browser windows created by Selenium will now use the virtual display and will be invisible to you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  If you're on Windows, one option is to run the tests under a different user account. This means the browser and java server will not be visible to your own account.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  This is how I run my tests with maven on a linux desktop (Ubuntu). I got fed up not being able to work with the firefox webdriver always taking focus.  I installed xvfb      xvfb-run -a mvn clean install   Thats it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  In many cases PhantomJS will not completely suit your needs, I would like to elaborate on the headless chrome option mentioned in Dave Hunt's answer.   chrome 57 has just launched this feature. You can use it by passing the --headless flag via ChromeDriver, for more info see the discussion in this question     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  There is a PhantomJS related project called GhostDriver , that is meant to run PhantomJS instances in a Selenium Grid using webdriver wire JSON protocol.  That is probably what you are looking for, although this question is 4 years old now.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  On MacOSX, I haven't been able to hide the browser window, but at least I figured out how to move it to a different display so it doesn't disrupt my workflow so much. While Firefox is running tests, just control-click its icon in the dock, select Options, and Assign to Display 2.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Is it possible to hide the browser in Selenium RC?",
        "A_Content": "  curl -k https://gist.githubusercontent.com/terrancesnyder/995250/raw/cdd1f52353bb614a5a016c2e8e77a2afb718f3c3/ephemeral-x.sh -o ~/ephemeral-x.sh chmod +x ~/ephemeral-x.sh ~/ephemeral-x.sh TestsStarterCommand   By the way this is a feature needed by any developer running e2e that logically will spawn browsers. In a development environment it is annoying to deal with the window that keeps popping up and which which you can accidentally interact making the test fail.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-rc"
        ],
        "URL": "https://stackoverflow.com/questions/1418082/is-it-possible-to-hide-the-browser-in-selenium-rc",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  From the docs:     ... Fabric defaults to a “fail-fast” behavior pattern: if anything goes wrong, such as a remote program returning a nonzero return value or your fabfile’s Python code encountering an exception, execution will halt immediately.      This is typically the desired behavior, but there are many exceptions to the rule, so Fabric provides env.warn_only, a Boolean setting. It defaults to False, meaning an error condition will result in the program aborting immediately. However, if env.warn_only is set to True at the time of failure – with, say, the settings context manager – Fabric will emit a warning message but continue executing.   Looks like you can exercise fine-grained control over where errors are ignored by using the settings context manager, something like so:  from fabric.api import settings  sudo('mkdir tmp') # can't fail with settings(warn_only=True):     sudo('touch tmp/test') # can fail sudo('rm tmp') # can't fail      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "141",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  As of Fabric 1.5, there is a ContextManager that makes this easier:  from fabric.api import sudo, warn_only  with warn_only():     sudo('mkdir foo')   Update: I re-confirmed that this works in ipython using the following code.  from fabric.api import local, warn_only  #aborted with SystemExit after 'bad command' local('bad command'); local('bad command 2')  #executes both commands, printing errors for each with warn_only():     local('bad command'); local('bad command 2')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  You can also set the entire script's warn_only setting to be true with   def local():     env.warn_only = True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  You should set the abort_exception environment variable and catch the exception.  For example:  from fabric.api        import env from fabric.operations import sudo  class FabricException(Exception):     pass  env.abort_exception = FabricException # ... set up the rest of the environment...  try:     sudo('reboot') except FabricException:     pass  # This is expected, we can continue.   You can also set it in a with block. See the documentation here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  In Fabric 1.3.2 at least, you can recover the exception by catching the SystemExit exception. That's helpful if you have more than one command to run in a batch (like a deploy) and want to cleanup if one of them fails.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to continue a task when Fabric receives an error",
        "A_Content": "  In Fabric 2.x you can just use invoke's run with the warn=True argument. Anyway, invoke is a dependency of Fabric 2.x:  from invoke import run run('bad command', warn=True)   From within a task:  from invoke import task  @task def my_task(c):     c.run('bad command', warn=True)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/3876936/how-to-continue-a-task-when-fabric-receives-an-error",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I define a task to run on several remote servers, if the task runs on server one and exits with an error, Fabric will stop and abort the task. But I want to make fabric ignore the error and run the task on the next server. How can I make it do this?  For example:  $ fab site1_service_gw [site1rpt1] Executing task 'site1_service_gw'  [site1fep1] run: echo 'Nm123!@#' | sudo -S route [site1fep1] err: [site1fep1] err: We trust you have received the usual lecture from the local System [site1fep1] err: Administrator. It usually boils down to these three things: [site1fep1] err: [site1fep1] err:     #1) Respect the privacy of others. [site1fep1] err:     #2) Think before you type. [site1fep1] err:     #3) With great power comes great responsibility. [site1fep1] err: root's password: [site1fep1] err: sudo: route: command not found  Fatal error: run() encountered an error (return code 1) while executing 'echo 'Nm123!@#' | sudo -S route '  Aborting.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Pandas get topmost n records within each group",
        "A_Content": "  Did you try df.groupby('id').head(2)  Ouput generated:   >>> df.groupby('id').head(2)        id  value id              1  0   1      1    1   1      2  2  3   2      1    4   2      2 3  7   3      1 4  8   4      1   (Keep in mind that you might need to order/sort before, depending on your data)  EDIT: As mentioned by the questioner, use df.groupby('id').head(2).reset_index(drop=True) to remove the multindex and flatten the results.  >>> df.groupby('id').head(2).reset_index(drop=True)     id  value 0   1      1 1   1      2 2   2      1 3   2      2 4   3      1 5   4      1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "greatest-n-per-group",
            "window-functions",
            "top-n"
        ],
        "URL": "https://stackoverflow.com/questions/20069009/pandas-get-topmost-n-records-within-each-group",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I have pandas DataFrame like this:  >>> df = pd.DataFrame({'id':[1,1,1,2,2,2,2,3,4],'value':[1,2,3,1,2,3,4,1,1]}) >>> df    id  value 0   1      1 1   1      2 2   1      3 3   2      1 4   2      2 5   2      3 6   2      4 7   3      1 8   4      1   I want to get a new DataFrame with top 2 records for each id, like this:     id  value 0   1      1 1   1      2 3   2      1 4   2      2 7   3      1 8   4      1   I can do it with numbering records within group after group by:  >>> dfN = df.groupby('id').apply(lambda x:x['value'].reset_index()).reset_index() >>> dfN    id  level_1  index  value 0   1        0      0      1 1   1        1      1      2 2   1        2      2      3 3   2        0      3      1 4   2        1      4      2 5   2        2      5      3 6   2        3      6      4 7   3        0      7      1 8   4        0      8      1 >>> dfN[dfN['level_1'] <= 1][['id', 'value']]    id  value 0   1      1 1   1      2 3   2      1 4   2      2 7   3      1 8   4      1   But is there more effective/elegant approach to do this? And also is there more elegant approach to number records within each group (like SQL window function row_number()).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Pandas get topmost n records within each group",
        "A_Content": "  Since 0.14.1, you can now do nlargest and nsmallest on a groupby object:  In [23]: df.groupby('id')['value'].nlargest(2) Out[23]:  id    1   2    3     1    2 2   6    4     5    3 3   7    1 4   8    1 dtype: int64   There's a slight weirdness that you get the original index in there as well, but this might be really useful depending on what your original index was.  If you're not interested in it, you can do .reset_index(level=1, drop=True) to get rid of it altogether.  (Note: From 0.17.1 you'll be able to do this on a DataFrameGroupBy too but for now it only works with Series and SeriesGroupBy.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "greatest-n-per-group",
            "window-functions",
            "top-n"
        ],
        "URL": "https://stackoverflow.com/questions/20069009/pandas-get-topmost-n-records-within-each-group",
        "A_Votes": "89",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have pandas DataFrame like this:  >>> df = pd.DataFrame({'id':[1,1,1,2,2,2,2,3,4],'value':[1,2,3,1,2,3,4,1,1]}) >>> df    id  value 0   1      1 1   1      2 2   1      3 3   2      1 4   2      2 5   2      3 6   2      4 7   3      1 8   4      1   I want to get a new DataFrame with top 2 records for each id, like this:     id  value 0   1      1 1   1      2 3   2      1 4   2      2 7   3      1 8   4      1   I can do it with numbering records within group after group by:  >>> dfN = df.groupby('id').apply(lambda x:x['value'].reset_index()).reset_index() >>> dfN    id  level_1  index  value 0   1        0      0      1 1   1        1      1      2 2   1        2      2      3 3   2        0      3      1 4   2        1      4      2 5   2        2      5      3 6   2        3      6      4 7   3        0      7      1 8   4        0      8      1 >>> dfN[dfN['level_1'] <= 1][['id', 'value']]    id  value 0   1      1 1   1      2 3   2      1 4   2      2 7   3      1 8   4      1   But is there more effective/elegant approach to do this? And also is there more elegant approach to number records within each group (like SQL window function row_number()).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  This is a little faster (and looks nicer)  np.argmax(aa>5)   Since argmax will stop at the first True (\"In case of multiple occurrences of the maximum values, the indices corresponding to the first occurrence are returned.\") and doesn't save another list.  In [2]: N = 10000  In [3]: aa = np.arange(-N,N)  In [4]: timeit np.argmax(aa>N/2) 100000 loops, best of 3: 52.3 us per loop  In [5]: timeit np.where(aa>N/2)[0][0] 10000 loops, best of 3: 141 us per loop  In [6]: timeit np.nonzero(aa>N/2)[0][0] 10000 loops, best of 3: 142 us per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  given the sorted content of your array, there is an even faster method: searchsorted.  import time N = 10000 aa = np.arange(-N,N) %timeit np.searchsorted(aa, N/2)+1 %timeit np.argmax(aa>N/2) %timeit np.where(aa>N/2)[0][0] %timeit np.nonzero(aa>N/2)[0][0]  # Output 100000 loops, best of 3: 5.97 µs per loop 10000 loops, best of 3: 46.3 µs per loop 10000 loops, best of 3: 154 µs per loop 10000 loops, best of 3: 154 µs per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "62",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  In [34]: a=np.arange(-10,10)  In [35]: a Out[35]: array([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,          3,   4,   5,   6,   7,   8,   9])  In [36]: np.where(a>5) Out[36]: (array([16, 17, 18, 19]),)  In [37]: np.where(a>5)[0][0] Out[37]: 16      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  I was also interested in this and I've compared all the suggested answers with perfplot. (Disclaimer: I'm the author of perfplot.)  If you know that the array you're looking through is already sorted, then    numpy.searchsorted(a, alpha)   is for you. It's a constant-time operation, i.e., the speed does not depend on the size of the array. You can't get faster than that.  If you don't know anything about your array, you're not going wrong with    numpy.argmax(a > alpha)   Already sorted:    Unsorted:    Code to reproduce the plot:    import numpy import perfplot   alpha = 0.5  def argmax(data):     return numpy.argmax(data > alpha)  def where(data):     return numpy.where(data > alpha)[0][0]  def nonzero(data):     return numpy.nonzero(data > alpha)[0][0]  def searchsorted(data):     return numpy.searchsorted(data, alpha)  out = perfplot.show(     # setup=numpy.random.rand,     setup=lambda n: numpy.sort(numpy.random.rand(n)),     kernels=[         argmax, where,         nonzero,         searchsorted         ],     n_range=[2**k for k in range(2, 20)],     logx=True,     logy=True,     xlabel='len(array)'     )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  Arrays that have a constant step between elements  In case of a range or any other linearly increasing array you can simply calculate the index programmatically, no need to actually iterate over the array at all:  def first_index_calculate_range_like(val, arr):     if len(arr) == 0:         raise ValueError('no value greater than {}'.format(val))     elif len(arr) == 1:         if arr[0] > val:             return 0         else:             raise ValueError('no value greater than {}'.format(val))      first_value = arr[0]     step = arr[1] - first_value     # For linearly decreasing arrays or constant arrays we only need to check     # the first element, because if that does not satisfy the condition     # no other element will.     if step <= 0:         if first_value > val:             return 0         else:             raise ValueError('no value greater than {}'.format(val))      calculated_position = (val - first_value) / step      if calculated_position < 0:         return 0     elif calculated_position > len(arr) - 1:         raise ValueError('no value greater than {}'.format(val))      return int(calculated_position) + 1   One could probably improve that a bit. I have made sure it works correctly for a few sample arrays and values but that doesn't mean there couldn't be mistakes in there, especially considering that it uses floats...  >>> import numpy as np >>> first_index_calculate_range_like(5, np.arange(-10, 10)) 16 >>> np.arange(-10, 10)[16]  # double check 6  >>> first_index_calculate_range_like(4.8, np.arange(-10, 10)) 15   Given that it can calculate the position without any iteration it will be constant time (O(1)) and can probably beat all other mentioned approaches. However it requires a constant step in the array, otherwise it will produce wrong results.  General solution using numba  A more general approach would be using a numba function:  @nb.njit def first_index_numba(val, arr):     for idx in range(len(arr)):         if arr[idx] > val:             return idx     return -1   That will work for any array but it has to iterate over the array, so in the average case it will be O(n):  >>> first_index_numba(4.8, np.arange(-10, 10)) 15 >>> first_index_numba(5, np.arange(-10, 10)) 16   Benchmark  Even though Nico Schlömer already provided some benchmarks I thought it might be useful to include my new solutions and to test for different \"values\".  The test setup:  import numpy as np import math import numba as nb  def first_index_using_argmax(val, arr):     return np.argmax(arr > val)  def first_index_using_where(val, arr):     return np.where(arr > val)[0][0]  def first_index_using_nonzero(val, arr):     return np.nonzero(arr > val)[0][0]  def first_index_using_searchsorted(val, arr):     return np.searchsorted(arr, val) + 1  def first_index_using_min(val, arr):     return np.min(np.where(arr > val))  def first_index_calculate_range_like(val, arr):     if len(arr) == 0:         raise ValueError('empty array')     elif len(arr) == 1:         if arr[0] > val:             return 0         else:             raise ValueError('no value greater than {}'.format(val))      first_value = arr[0]     step = arr[1] - first_value     if step <= 0:         if first_value > val:             return 0         else:             raise ValueError('no value greater than {}'.format(val))      calculated_position = (val - first_value) / step      if calculated_position < 0:         return 0     elif calculated_position > len(arr) - 1:         raise ValueError('no value greater than {}'.format(val))      return int(calculated_position) + 1  @nb.njit def first_index_numba(val, arr):     for idx in range(len(arr)):         if arr[idx] > val:             return idx     return -1  funcs = [     first_index_using_argmax,      first_index_using_min,      first_index_using_nonzero,     first_index_calculate_range_like,      first_index_numba,      first_index_using_searchsorted,      first_index_using_where ]  from simple_benchmark import benchmark, MultiArgument   and the plots were generated using:  %matplotlib notebook b.plot()   item is at the beginning  b = benchmark(     funcs,     {2**i: MultiArgument([0, np.arange(2**i)]) for i in range(2, 20)},     argument_name=\"array size\")     The numba function performs best followed by the calculate-function and the searchsorted function. The other solutions perform much worse.  item is at the end  b = benchmark(     funcs,     {2**i: MultiArgument([2**i-2, np.arange(2**i)]) for i in range(2, 20)},     argument_name=\"array size\")     For small arrays the numba function performs amazingly fast, however for bigger arrays it's outperformed by the calculate-function and the searchsorted function.  item is at sqrt(len)  b = benchmark(     funcs,     {2**i: MultiArgument([np.sqrt(2**i), np.arange(2**i)]) for i in range(2, 20)},     argument_name=\"array size\")     This is more interesting. Again numba and the calculate function perform great, however this is actually triggering the worst case of searchsorted which really doesn't work well in this case.  Comparison of the functions when no value satisfies the condition  Another interesting point is how these function behave if there is no value whose index should be returned:  arr = np.ones(100) value = 2  for func in funcs:     print(func.__name__)     try:         print('-->', func(value, arr))     except Exception as e:         print('-->', e)   With this result:  first_index_using_argmax --> 0 first_index_using_min --> zero-size array to reduction operation minimum which has no identity first_index_using_nonzero --> index 0 is out of bounds for axis 0 with size 0 first_index_calculate_range_like --> no value greater than 2 first_index_numba --> -1 first_index_using_searchsorted --> 101 first_index_using_where --> index 0 is out of bounds for axis 0 with size 0   Searchsorted, argmax, and numba simply return a wrong value. However searchsorted and numba return an index that is not a valid index for the array.  The functions where, min, nonzero and calculate throw an exception. However only the exception for calculate actually says anything helpful.  That means one actually has to wrap these calls in an appropriate wrapper function that catches exceptions or invalid return values and handle appropriately, at least if you aren't sure if the value could be in the array.    Note: The calculate and searchsorted options only work in special conditions. The \"calculate\" function requires a constant step and the searchsorted requires the array to be sorted. So these could be useful in the right circumstances but aren't general solutions for this problem. In case you're dealing with sorted Python lists you might want to take a look at the bisect module instead of using Numpys searchsorted.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  I would go with  i = np.min(np.where(V >= x))   where V is vector (1d array), x is the value and i is the resulting index.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Numpy first occurrence of value greater than existing value",
        "A_Content": "  I'd like to propose   np.min(np.append(np.where(aa>5)[0],np.inf))   This will return the smallest index where the condition is met, while returning infinity if the condition is never met (and where returns an empty array).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/16243955/numpy-first-occurrence-of-value-greater-than-existing-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a 1D array in numpy and I want to find the position of the index where a value exceeds the value in numpy array.  E.g.  aa = range(-10,10)   Find position in aa where, the value 5 gets exceeded.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  for line in reversed(open(\"filename\").readlines()):     print line.rstrip()   And in Python 3:  for line in reversed(list(open(\"filename\"))):     print(line.rstrip())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  A correct, efficient answer written as a generator.  import os  def reverse_readline(filename, buf_size=8192):     \"\"\"a generator that returns the lines of a file in reverse order\"\"\"     with open(filename) as fh:         segment = None         offset = 0         fh.seek(0, os.SEEK_END)         file_size = remaining_size = fh.tell()         while remaining_size > 0:             offset = min(file_size, offset + buf_size)             fh.seek(file_size - offset)             buffer = fh.read(min(remaining_size, buf_size))             remaining_size -= buf_size             lines = buffer.split('\\n')             # the first line of the buffer is probably not a complete line so             # we'll save it and append it to the last line of the next buffer             # we read             if segment is not None:                 # if the previous chunk starts right from the beginning of line                 # do not concact the segment to the last line of new chunk                 # instead, yield the segment first                  if buffer[-1] is not '\\n':                     lines[-1] += segment                 else:                     yield segment             segment = lines[0]             for index in range(len(lines) - 1, 0, -1):                 if len(lines[index]):                     yield lines[index]         # Don't yield None if the file was empty         if segment is not None:             yield segment      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "100",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  How about something like this:  import os   def readlines_reverse(filename):     with open(filename) as qfile:         qfile.seek(0, os.SEEK_END)         position = qfile.tell()         line = ''         while position >= 0:             qfile.seek(position)             next_char = qfile.read(1)             if next_char == \"\\n\":                 yield line[::-1]                 line = ''             else:                 line += next_char             position -= 1         yield line[::-1]   if __name__ == '__main__':     for qline in readlines_reverse(raw_input()):         print qline   Since the file is read character by character in reverse order, it will work even on very large files, as long as individual lines fit into memory.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  You can also use python module file_read_backwards.  After installing it, via pip install file_read_backwards (v1.2.1), you can read the entire file backwards (line-wise) in a memory efficient manner via:  #!/usr/bin/env python2.7  from file_read_backwards import FileReadBackwards  with FileReadBackwards(\"/path/to/file\", encoding=\"utf-8\") as frb:     for l in frb:          print l   It supports \"utf-8\",\"latin-1\", and \"ascii\" encodings.  Support is also available for python3. Further documentation can be found at http://file-read-backwards.readthedocs.io/en/latest/readme.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  for line in reversed(open(\"file\").readlines()):     print line.rstrip()   If you are on linux, you can use tac command.  $ tac file   2 recipes you can find in ActiveState here and here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  import re  def filerev(somefile, buffer=0x20000):   somefile.seek(0, os.SEEK_END)   size = somefile.tell()   lines = ['']   rem = size % buffer   pos = max(0, (size // buffer - 1) * buffer)   while pos >= 0:     somefile.seek(pos, os.SEEK_SET)     data = somefile.read(rem + buffer) + lines[0]     rem = 0     lines = re.findall('[^\\n]*\\n?', data)     ix = len(lines) - 2     while ix > 0:       yield lines[ix]       ix -= 1     pos -= buffer   else:     yield lines[0]  with open(sys.argv[1], 'r') as f:   for line in filerev(f):     sys.stdout.write(line)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  Here you can find my my implementation, you can limit the ram usage by changing the \"buffer\" variable, there is a bug that the program prints an empty line in the beginning.  And also ram usage may be increase if there is no new lines for more than buffer bytes, \"leak\" variable will increase until seeing a new line (\"\\n\").  This is also working for 16 GB files which is bigger then my total memory.  import os,sys buffer = 1024*1024 # 1MB f = open(sys.argv[1]) f.seek(0, os.SEEK_END) filesize = f.tell()  division, remainder = divmod(filesize, buffer) line_leak=''  for chunk_counter in range(1,division + 2):     if division - chunk_counter < 0:         f.seek(0, os.SEEK_SET)         chunk = f.read(remainder)     elif division - chunk_counter >= 0:         f.seek(-(buffer*chunk_counter), os.SEEK_END)         chunk = f.read(buffer)      chunk_lines_reversed = list(reversed(chunk.split('\\n')))     if line_leak: # add line_leak from previous chunk to beginning         chunk_lines_reversed[0] += line_leak      # after reversed, save the leakedline for next chunk iteration     line_leak = chunk_lines_reversed.pop()      if chunk_lines_reversed:         print \"\\n\".join(chunk_lines_reversed)     # print the last leaked line     if division - chunk_counter < 0:         print line_leak      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  Thanks for the answer @srohde. It has a small bug checking for newline character with 'is' operator, and I could not comment on the answer with 1 reputation. Also I'd like to manage file open outside because that enables me to embed my ramblings for luigi tasks.  What I needed to change has the form:  with open(filename) as fp:     for line in fp:         #print line,  # contains new line         print '>{}<'.format(line)   I'd love to change to:  with open(filename) as fp:     for line in reversed_fp_iter(fp, 4):         #print line,  # contains new line         print '>{}<'.format(line)   Here is a modified answer that wants a file handle and keeps newlines:  def reversed_fp_iter(fp, buf_size=8192):     \"\"\"a generator that returns the lines of a file in reverse order     ref: https://stackoverflow.com/a/23646049/8776239     \"\"\"     segment = None  # holds possible incomplete segment at the beginning of the buffer     offset = 0     fp.seek(0, os.SEEK_END)     file_size = remaining_size = fp.tell()     while remaining_size > 0:         offset = min(file_size, offset + buf_size)         fp.seek(file_size - offset)         buffer = fp.read(min(remaining_size, buf_size))         remaining_size -= buf_size         lines = buffer.splitlines(True)         # the first line of the buffer is probably not a complete line so         # we'll save it and append it to the last line of the next buffer         # we read         if segment is not None:             # if the previous chunk starts right from the beginning of line             # do not concat the segment to the last line of new chunk             # instead, yield the segment first             if buffer[-1] == '\\n':                 #print 'buffer ends with newline'                 yield segment             else:                 lines[-1] += segment                 #print 'enlarged last line to >{}<, len {}'.format(lines[-1], len(lines))         segment = lines[0]         for index in range(len(lines) - 1, 0, -1):             if len(lines[index]):                 yield lines[index]     # Don't yield None if the file was empty     if segment is not None:         yield segment      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  a simple function to create a second file reversed (linux only):  import os def tac(file1, file2):      print(os.system('tac %s > %s' % (file1,file2)))   how to use  tac('ordered.csv', 'reversed.csv') f = open('reversed.csv')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  If you are concerned about file size / memory usage, memory-mapping the file and scanning backwards for newlines is a solution:  How to search for a string in text files?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  def reverse_lines(filename):     y=open(filename).readlines()     return y[::-1]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  Always use with when working with files as it handles everything for you:  with open('filename', 'r') as f:     for line in reversed(f.readlines()):         print line   Or in Python 3:  with open('filename', 'r') as f:     for line in reversed(list(f.readlines())):         print(line)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  you would need to first open your file in read format, save it to a variable, then open the second file in write format where you would write or append the variable using a the [::-1] slice, completely reversing the file. You can also use readlines() to make it into a list of lines, which you can manipulate  def copy_and_reverse(filename, newfile):     with open(filename) as file:         text = file.read()     with open(newfile, \"w\") as file2:         file2.write(text[::-1])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  Most of the answers need to read the whole file before doing anything. This sample reads increasingly large samples from the end.  I only saw Murat Yükselen's answer while writing this answer. It's nearly the same, which I suppose is a good thing. The sample below also deals with \\r and increases its buffersize at each step. I also have some unit tests to back this code up.  def readlines_reversed(f):     \"\"\" Iterate over the lines in a file in reverse. The file must be     open in 'rb' mode. Yields the lines unencoded (as bytes), including the     newline character. Produces the same result as readlines, but reversed.     If this is used to reverse the line in a file twice, the result is     exactly the same.     \"\"\"     head = b\"\"     f.seek(0, 2)     t = f.tell()     buffersize, maxbuffersize = 64, 4096     while True:         if t <= 0:             break         # Read next block         buffersize = min(buffersize * 2, maxbuffersize)         tprev = t         t = max(0, t - buffersize)         f.seek(t)         lines = f.read(tprev - t).splitlines(True)         # Align to line breaks         if not lines[-1].endswith((b\"\\n\", b\"\\r\")):             lines[-1] += head  # current tail is previous head         elif head == b\"\\n\" and lines[-1].endswith(b\"\\r\"):             lines[-1] += head  # Keep \\r\\n together         elif head:             lines.append(head)         head = lines.pop(0)  # can be '\\n' (ok)         # Iterate over current block in reverse         for line in reversed(lines):             yield line     if head:         yield head      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Read a file in reverse order using python",
        "A_Content": "  I had to do this some time ago and used the below code. It pipes to the shell. I am afraid i do not have the complete script anymore. If you are on a unixish operating system, you can use \"tac\", however on e.g. Mac OSX tac command does not work, use tail -r. The below code snippet tests for which platform you're on, and adjusts the command accordingly  # We need a command to reverse the line order of the file. On Linux this # is 'tac', on OSX it is 'tail -r' # 'tac' is not supported on osx, 'tail -r' is not supported on linux.  if sys.platform == \"darwin\":     command += \"|tail -r\" elif sys.platform == \"linux2\":     command += \"|tac\" else:     raise EnvironmentError('Platform %s not supported' % sys.platform)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "reverse"
        ],
        "URL": "https://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to read a file in reverse order using python? I want to read a file from last line to first line.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  import datetime and then the magic timedelta stuff:  In [63]: datetime.datetime.now() Out[63]: datetime.datetime(2010, 12, 27, 14, 39, 19, 700401)  In [64]: datetime.datetime.now() - datetime.timedelta(minutes=15) Out[64]: datetime.datetime(2010, 12, 27, 14, 24, 21, 684435)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "164",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "   datetime.datetime.now() - datetime.timedelta(minutes=15)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  Use DateTime in addition to a timedelta object http://docs.python.org/library/datetime.html  datetime.datetime.now()-datetime.timedelta(minutes=15)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  from datetime import timedelta     datetime.datetime.now() - datetime.timedelta(0, 900)  Actually 900 is in seconds. Which is equal to 15 minutes. `15*60 = 900`      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  This is simply what to do:  datetime.datetime.now() - datetime.timedelta(minutes = 15)   timedeltas are specifically designed to allow you to subtract or add deltas (differences) to datetimes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  I have provide two methods for doing so for minutes as well as for years and hours if you want to see more examples:  import datetime print(datetime.datetime.now()) print(datetime.datetime.now() - datetime.timedelta(minutes = 15)) print(datetime.datetime.now() + datetime.timedelta(minutes = -15)) print(datetime.timedelta(hours = 5)) print(datetime.datetime.now() + datetime.timedelta(days = 3)) print(datetime.datetime.now() + datetime.timedelta(days = -9)) print(datetime.datetime.now() - datetime.timedelta(days = 9))   I get the following results:  2016-06-03 16:04:03.706615 2016-06-03 15:49:03.706622 2016-06-03 15:49:03.706642 5:00:00 2016-06-06 16:04:03.706665 2016-05-25 16:04:03.706676 2016-05-25 16:04:03.706687 2016-06-03 16:04:03.706716      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to create a DateTime equal to 15 minutes ago?",
        "A_Content": "  datetime.datetime.now() - datetime.timedelta(0, 15 * 60)  timedelta is a \"change in time\". It takes days as the first parameter and seconds in the second parameter. 15 * 60 seconds is 15 minutes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/4541629/how-to-create-a-datetime-equal-to-15-minutes-ago",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to create a DateTime object that represents the current time minus 15 minutes.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  To get a date string with milliseconds (3 decimal places behind seconds), use this:  from datetime import datetime  print datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]  >>>> OUTPUT >>>> 2018-10-04 10:18:32.926      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "203",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  print datetime.utcnow().strftime('%Y%m%d%H%M%S%f')   http://docs.python.org/library/datetime.html#strftime-strptime-behavior     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  @Cabbi raised the issue that on some systems, the microseconds format %f may give \"0\", so it's not portable to simply chop off the last three characters.  The following code carefully formats a timestamp with milliseconds:  from datetime import datetime (dt, micro) = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f').split('.') dt = \"%s.%03d\" % (dt, int(micro) / 1000) print dt   Example Output:  2016-02-26 04:37:53.133   To get the exact output that the OP wanted, we have to strip punctuation characters:  from datetime import datetime (dt, micro) = datetime.utcnow().strftime('%Y%m%d%H%M%S.%f').split('.') dt = \"%s%03d\" % (dt, int(micro) / 1000) print dt   Example Output:  20160226043839901      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  Probably like this :  import datetime now = datetime.datetime.now() now.strftime('%Y/%m/%d %H:%M:%S.%f')[:-3]   # [:-3] => Removing the 3 last characters as %f is for microsecs.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  I assume you mean you're looking for something that is faster than datetime.datetime.strftime(), and are essentially stripping the non-alpha characters from a utc timestamp.  You're approach is marginally faster, and I think you can speed things up even more by slicing the string:  >>> import timeit >>> t=timeit.Timer('datetime.utcnow().strftime(\"%Y%m%d%H%M%S%f\")',''' ... from datetime import datetime''') >>> t.timeit(number=10000000) 116.15451288223267  >>> def replaceutc(s): ...     return s\\ ...         .replace('-','') \\ ...         .replace(':','') \\ ...         .replace('.','') \\ ...         .replace(' ','') \\ ...         .strip() ...  >>> t=timeit.Timer('replaceutc(str(datetime.datetime.utcnow()))',''' ... from __main__ import replaceutc ... import datetime''') >>> t.timeit(number=10000000) 77.96774983406067  >>> def sliceutc(s): ...     return s[:4] + s[5:7] + s[8:10] + s[11:13] + s[14:16] + s[17:19] + s[20:] ...  >>> t=timeit.Timer('sliceutc(str(datetime.utcnow()))',''' ... from __main__ import sliceutc ... from datetime import datetime''') >>> t.timeit(number=10000000) 62.378515005111694      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  from datetime import datetime from time import clock  t = datetime.utcnow() print 't == %s    %s\\n\\n' % (t,type(t))  n = 100000  te = clock() for i in xrange(1):     t_stripped = t.strftime('%Y%m%d%H%M%S%f') print clock()-te print t_stripped,\" t.strftime('%Y%m%d%H%M%S%f')\"  print  te = clock() for i in xrange(1):     t_stripped = str(t).replace('-','').replace(':','').replace('.','').replace(' ','') print clock()-te print t_stripped,\" str(t).replace('-','').replace(':','').replace('.','').replace(' ','')\"  print  te = clock() for i in xrange(n):     t_stripped = str(t).translate(None,' -:.') print clock()-te print t_stripped,\" str(t).translate(None,' -:.')\"  print  te = clock() for i in xrange(n):     s = str(t)     t_stripped = s[:4] + s[5:7] + s[8:10] + s[11:13] + s[14:16] + s[17:19] + s[20:]  print clock()-te print t_stripped,\" s[:4] + s[5:7] + s[8:10] + s[11:13] + s[14:16] + s[17:19] + s[20:] \"   result  t == 2011-09-28 21:31:45.562000    <type 'datetime.datetime'>   3.33410112179 20110928212155046000  t.strftime('%Y%m%d%H%M%S%f')  1.17067364707 20110928212130453000 str(t).replace('-','').replace(':','').replace('.','').replace(' ','')  0.658806915404 20110928212130453000 str(t).translate(None,' -:.')  0.645189262881 20110928212130453000 s[:4] + s[5:7] + s[8:10] + s[11:13] + s[14:16] + s[17:19] + s[20:]   Use of translate() and slicing method run in same time translate() presents the advantage to be usable in one line  Comparing the times on the basis of the first one:     1.000 * t.strftime('%Y%m%d%H%M%S%f')      0.351 * str(t).replace('-','').replace(':','').replace('.','').replace('   ','')      0.198 * str(t).translate(None,' -:.')      0.194 * s[:4] + s[5:7] + s[8:10] + s[11:13] + s[14:16] + s[17:19] +   s[20:]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  I dealt with the same problem but in my case it was important that the millisecond was rounded and not truncated  from datetime import datetime, timedelta  def strftime_ms(datetime_obj):     y,m,d,H,M,S = datetime_obj.timetuple()[:6]     ms = timedelta(microseconds = round(datetime_obj.microsecond/1000.0)*1000)     ms_date = datetime(y,m,d,H,M,S) + ms     return ms_date.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  import datetime  # convert string into date time format.  str_date = '2016-10-06 15:14:54.322989' d_date = datetime.datetime.strptime(str_date , '%Y-%m-%d %H:%M:%S.%f') print(d_date) print(type(d_date)) # check d_date type.   # convert date time to regular format.  reg_format_date = d_date.strftime(\"%d %B %Y %I:%M:%S %p\") print(reg_format_date)  # some other date formats. reg_format_date = d_date.strftime(\"%Y-%m-%d %I:%M:%S %p\") print(reg_format_date) reg_format_date = d_date.strftime(\"%Y-%m-%d %H:%M:%S\") print(reg_format_date)      <<<<<< OUTPUT >>>>>>>   2016-10-06 15:14:54.322989     <class 'datetime.datetime'>     06 October 2016 03:14:54 PM     2016-10-06 03:14:54 PM     2016-10-06 15:14:54      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  python -c \"from datetime import datetime; print str(datetime.now())[:-3]\" 2017-02-09 10:06:37.006      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Format a datetime into a string with milliseconds",
        "A_Content": "  Just use datetime.datetime.strftime() with an appropriate format string.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/7588511/format-a-datetime-into-a-string-with-milliseconds",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to have a datetime string from the date with milliseconds. This code is typical for me and I'm eager to learn how to shorten it.  from datetime import datetime  timeformatted= str(datetime.utcnow()) semiformatted= timeformatted.replace(\"-\",\"\") almostformatted= semiformatted.replace(\":\",\"\") formatted=almostformatted.replace(\".\",\"\") withspacegoaway=formatted.replace(\" \",\"\") formattedstripped=withspacegoaway.strip() print formattedstripped      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  Unless your click is firing some kind of ajax call to populate your list, you don't actually need to execute the click.  Just find the element and then enumerate the options, selecting the option(s) you want.  Here is an example:  from selenium import webdriver b = webdriver.Firefox() b.find_element_by_xpath(\"//select[@name='element_name']/option[text()='option_text']\").click()   You can read more in:  https://sqa.stackexchange.com/questions/1355/unable-to-select-an-option-using-seleniums-python-webdriver     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "62",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  Selenium provides a convenient Select class to work with select -> option constructs:  from selenium import webdriver from selenium.webdriver.support.ui import Select  driver = webdriver.Firefox() driver.get('url')  select = Select(driver.find_element_by_id('fruits01'))  # select by visible text select.select_by_visible_text('Banana')  # select by value  select.select_by_value('1')   See also:   What is the correct way to select an  using Selenium's Python WebDriver?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "159",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  firstly you need to import the Select class and then you need to create the instance of Select class. After creating the instance of Select class, you can perform select methods on that instance to select the options from dropdown list. Here is the code  from selenium.webdriver.support.select import Select  select_fr = Select(driver.find_element_by_id(\"fruits01\")) select_fr.select_by_index(0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  I tried a lot many things, but my drop down was inside a table and I was not able to perform a simple select operation. Only the below solution worked. Here I am highlighting drop down elem and pressing down arrow until getting the desired value -           #identify the drop down element         elem = browser.find_element_by_name(objectVal)         for option in elem.find_elements_by_tag_name('option'):             if option.text == value:                 break              else:                 ARROW_DOWN = u'\\ue015'                 elem.send_keys(ARROW_DOWN)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  The best way to use selenium.webdriver.support.ui.Select class to work to with dropdown selection but some time it does not work as expected due to designing issue or other issues of the HTML.  In this type of situation you can also prefer as alternate solution using execute_script() as below :-  option_visible_text = \"Banana\" select = driver.find_element_by_id(\"fruits01\")  #now use this to select option from dropdown by visible text  driver.execute_script(\"var select = arguments[0]; for(var i = 0; i < select.options.length; i++){ if(select.options[i].text == arguments[1]){ select.options[i].selected = true; } }\", select, option_visible_text);      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Selenium - Python - drop-down menu option value",
        "A_Content": "  from selenium.webdriver.support.ui import Select driver = webdriver.Ie(\".\\\\IEDriverServer.exe\") driver.get(\"https://test.com\") select = Select(driver.find_element_by_xpath(\"\"\"//input[@name='n_name']\"\"\")) select.select_by_index(2)   It will work fine     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver",
            "web-scraping",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7867537/selenium-python-drop-down-menu-option-value",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to select an element from a drop-down menu.  For example, open this:   <select id=\"fruits01\" class=\"select\" name=\"fruits\">     <option value=\"0\">Choose your fruits:</option>     <option value=\"1\">Banana</option>     <option value=\"2\">Mango</option> </select>    So first I have to click on it. I do this:   inputElementFruits = driver.find_element_by_xpath(\"//select[\"id='fruits']).click()    (ok, it's opening the menu)   And after I have to select the good element, lets say Mango. I try different thing with inputElementFruits.send_keys(...) but it did not work.      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  The reason it isn't working is because you have UseShellExecute = false.  If you don't use the shell, you will have to supply the complete path to the python executable as FileName, and build the Arguments string to supply both your script and the file you want to read.  Also note, that you can't RedirectStandardOutput unless UseShellExecute = false.  I'm not quite sure how the argument string should be formatted for python, but you will need something like this:  private void run_cmd(string cmd, string args) {      ProcessStartInfo start = new ProcessStartInfo();      start.FileName = \"my/full/path/to/python.exe\";      start.Arguments = string.Format(\"{0} {1}\", cmd, args);      start.UseShellExecute = false;      start.RedirectStandardOutput = true;      using(Process process = Process.Start(start))      {          using(StreamReader reader = process.StandardOutput)          {              string result = reader.ReadToEnd();              Console.Write(result);          }      } }      ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  If you're willing to use IronPython, you can execute scripts directly in C#:  using IronPython.Hosting; using Microsoft.Scripting.Hosting;  private static void doPython() {     ScriptEngine engine = Python.CreateEngine();     engine.ExecuteFile(@\"test.py\"); }   Get IronPython here.     ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  Execute Python script from C  Create a C# project and write the following code.  using System; using System.Diagnostics; using System.IO; using System.Threading.Tasks; using System.Windows.Forms; namespace WindowsFormsApplication1 {     public partial class Form1 : Form     {         public Form1()         {             InitializeComponent();         }          private void button1_Click(object sender, EventArgs e)         {             run_cmd();         }          private void run_cmd()         {              string fileName = @\"C:\\sample_script.py\";              Process p = new Process();             p.StartInfo = new ProcessStartInfo(@\"C:\\Python27\\python.exe\", fileName)             {                 RedirectStandardOutput = true,                 UseShellExecute = false,                 CreateNoWindow = true             };             p.Start();              string output = p.StandardOutput.ReadToEnd();             p.WaitForExit();              Console.WriteLine(output);              Console.ReadLine();          }     } }   Python sample_script  print \"Python C# Test\"  You will see the 'Python C# Test' in the console of C#.     ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  I ran into the same problem and Master Morality's answer didn't do it for me.  The following, which is based on the previous answer, worked:  private void run_cmd(string cmd, string args) {  ProcessStartInfo start = new ProcessStartInfo();  start.FileName = cmd;//cmd is full path to python.exe  start.Arguments = args;//args is path to .py file and any cmd line args  start.UseShellExecute = false;  start.RedirectStandardOutput = true;  using(Process process = Process.Start(start))  {      using(StreamReader reader = process.StandardOutput)      {          string result = reader.ReadToEnd();          Console.Write(result);      }  } }   As an example, cmd would be @C:/Python26/python.exe and args would be C://Python26//test.py 100 if you wanted to execute test.py with cmd line argument 100.  Note that the path the the .py file does not have the @ symbol.     ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  I am having problems with stdin/stout - when payload size exceeds several kilobytes it hangs. I need to call Python functions not only with some short arguments, but with a custom payload that could be big.  A while ago, I wrote a virtual actor library that allows to distribute task on different machines via Redis. To call Python code, I added functionality to listen for messages from Python, process them and return results back to .NET.  Here is a brief description of how it works.  It works on a single machine as well, but requires a Redis instance. Redis adds some reliability guarantees - payload is stored until a worked acknowledges completion. If a worked dies, the payload is returned to a job queue and then is reprocessed by another worker.     ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How do I run a Python script from C#?",
        "A_Content": "  Set WorkingDirectory or specify the full path of the python script in the Argument  ProcessStartInfo start = new ProcessStartInfo(); start.FileName = \"C:\\\\Python27\\\\python.exe\"; //start.WorkingDirectory = @\"D:\\script\"; start.Arguments = string.Format(\"D:\\\\script\\\\test.py -a {0} -b {1} \", \"some param\", \"some other param\"); start.UseShellExecute = false; start.RedirectStandardOutput = true; using (Process process = Process.Start(start)) {     using (StreamReader reader = process.StandardOutput)     {         string result = reader.ReadToEnd();         Console.Write(result);     } }      ",
        "Language": "Python",
        "Tags": [
            "c#",
            "python",
            ".net",
            "ironpython",
            "python.net"
        ],
        "URL": "https://stackoverflow.com/questions/11779143/how-do-i-run-a-python-script-from-c",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This sort of question has been asked before in varying degrees, but I feel it has not been answered in a concise way and so I ask it again.  I want to run a script in Python. Let's say it's this:  if __name__ == '__main__':     f = open(sys.argv[1], 'r')     s = f.read()     f.close()     print s   Which gets a file location, reads it, then prints its contents. Not so complicated.  Okay, so how do I run this in C#?  This is what I have now:      private void run_cmd(string cmd, string args)     {         ProcessStartInfo start = new ProcessStartInfo();         start.FileName = cmd;         start.Arguments = args;         start.UseShellExecute = false;         start.RedirectStandardOutput = true;         using (Process process = Process.Start(start))         {             using (StreamReader reader = process.StandardOutput)             {                 string result = reader.ReadToEnd();                 Console.Write(result);             }         }     }   When I pass the code.py location as cmd and the filename location as args it doesn't work. I was told I should pass python.exe as the cmd, and then code.py filename as the args.  I have been looking for a while now and can only find people suggesting to use IronPython or such. But there must be a way to call a Python script from C#.  Some clarification:  I need to run it from C#, I need to capture the output, and I can't use IronPython or anything else. Whatever hack you have will be fine.  P.S.: The actual Python code I'm running is much more complex than this, and it returns output which I need in C#, and the C# code will be constantly calling the Python.  Pretend this is my code:      private void get_vals()     {         for (int i = 0; i < 100; i++)         {             run_cmd(\"code.py\", i);         }     }      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Adding a user to a group in django",
        "A_Content": "  Find the group using Group model with the name of the group, then add the user to the user_set  from django.contrib.auth.models import Group my_group = Group.objects.get(name='my_group_name')  my_group.user_set.add(your_user)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/6288661/adding-a-user-to-a-group-in-django",
        "A_Votes": "174",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How would I add a user to a group in django by the group's name?  I can do this:  user.groups.add(1) # add by id   How would I do something like this:  user.groups.add(name='groupname') # add by name      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Adding a user to a group in django",
        "A_Content": "  Here's how to do this in modern versions of Django (tested in Django 1.7):  from django.contrib.auth.models import Group group = Group.objects.get(name='groupname') user.groups.add(group)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/6288661/adding-a-user-to-a-group-in-django",
        "A_Votes": "61",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I add a user to a group in django by the group's name?  I can do this:  user.groups.add(1) # add by id   How would I do something like this:  user.groups.add(name='groupname') # add by name      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Adding a user to a group in django",
        "A_Content": "  here is the answer to create groups for users in django 1.8.4 version  from django.contrib.auth.models import Group group = Group.objects.get(name='groupname') user.group.addgroup()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/6288661/adding-a-user-to-a-group-in-django",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I add a user to a group in django by the group's name?  I can do this:  user.groups.add(1) # add by id   How would I do something like this:  user.groups.add(name='groupname') # add by name      ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  There is a very simple solution:  day_of_year = datetime.now().timetuple().tm_yday      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "186",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  Couldn't you use strftime?  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 15:37:02.484000 >>> today.strftime('%j') '065'   Edit  As noted in the comments, if you wish to do comparisons or calculations with this number, you would have to convert it to int() because strftime() returns a string. If that is the case, you are better off using DzinX's answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  DZinX's answer is a great answer for the question.  I found this question while looking for the inverse function.  I found this to work :  import datetime datetime.datetime.strptime('1936-077T13:14:15','%Y-%jT%H:%M:%S')  >>>> datetime.datetime(1936, 3, 17, 13, 14, 15)  datetime.datetime.strptime('1936-077T13:14:15','%Y-%jT%H:%M:%S').timetuple().tm_yday  >>>> 77   I'm not sure of etiquette around here, but I thought a pointer to the inverse function might be useful for others like me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  I want to present performance of different approaches, on Python 3.4, Linux x64. Excerpt from line profiler:        Line #      Hits         Time  Per Hit   % Time  Line Contents       ==============================================================          (...)          823      1508        11334      7.5     41.6          yday = int(period_end.strftime('%j'))          824      1508         2492      1.7      9.1          yday = period_end.toordinal() - date(period_end.year, 1, 1).toordinal() + 1          825      1508         1852      1.2      6.8          yday = (period_end - date(period_end.year, 1, 1)).days + 1          826      1508         5078      3.4     18.6          yday = period_end.timetuple().tm_yday          (...)   So most efficient is  yday = (period_end - date(period_end.year, 1, 1)).days      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  Just subtract january 1 from the date:  import datetime today = datetime.datetime.now() day_of_year = (today - datetime.datetime(today.year, 1, 1)).days + 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  If you have reason to avoid the use of the datetime module, then these functions will work.  def is_leap_year(year):     \"\"\" if year is a leap year return True         else return False \"\"\"     if year % 100 == 0:         return year % 400 == 0     return year % 4 == 0  def doy(Y,M,D):     \"\"\" given year, month, day return day of year         Astronomical Algorithms, Jean Meeus, 2d ed, 1998, chap 7 \"\"\"     if is_leap_year(Y):         K = 1     else:         K = 2     N = int((275 * M) / 9.0) - K * int((M + 9) / 12.0) + D - 30     return N  def ymd(Y,N):     \"\"\" given year = Y and day of year = N, return year, month, day         Astronomical Algorithms, Jean Meeus, 2d ed, 1998, chap 7 \"\"\"         if is_leap_year(Y):         K = 1     else:         K = 2     M = int((9 * (K + N)) / 275.0 + 0.98)     if N < 32:         M = 1     D = N - int((275 * M) / 9.0) + K * int((M + 9) / 12.0) + 30     return Y, M, D      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Convert Year/Month/Day to Day of Year in Python",
        "A_Content": "  This code takes a date as an input argument and returns the day of the year.  from datetime import datetime date = raw_input(\"Enter date: \")  ## format is 02-02-2016 adate = datetime.datetime.strptime(date,\"%d-%m-%Y\") day_of_year = adate.timetuple().tm_yday day_of_year      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/620305/convert-year-month-day-to-day-of-year-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Python \"datetime\" module, i.e.:  >>> import datetime >>> today = datetime.datetime.now() >>> print today 2009-03-06 13:24:58.857946   and I would like to compute the day of year that is sensitive of leap years. e.g. oday (March 6, 2009) is the 65th day of 2009.  Here's web-based DateTime calculator.  Anyway, I see a two options:   Create a number_of_days_in_month array = [31, 28, ...], decide if it's a leap year, manually sum up the days Use datetime.timedelta to make a guess & then binary search for the correct day of year:   .  >>> import datetime >>> YEAR = 2009 >>> DAY_OF_YEAR = 62 >>> d = datetime.date(YEAR, 1, 1) + datetime.timedelta(DAY_OF_YEAR - 1)   These both feel pretty clunky & I have a gut feeling that there's a more \"Pythonic\" way of calculating day of year.  Any ideas/suggestions?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Where does pip install its packages?",
        "A_Content": "  pip when used with virtualenv will generally install packages in the path <virtualenv_name>/lib/<python_ver>/site-packages.  For example, I created a test virtualenv named venv_test with Python 2.7, and the django folder is in venv_test/lib/python2.7/site-packages/django.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "pip",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I activated a virtualenv which has pip installed. I did  pip3 install Django==1.8   and Django successfully downloaded. Now, I want to open up the Django folder. Where is the folder located? Normally it would be in \"downloads\" but I'm not sure where it would be if I installed it using pip in a virtualenv.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Where does pip install its packages?",
        "A_Content": "  By popular demand, an option provided via posted answer:  pip show <package name> will provide the location for Windows and macOS, and I'm guessing any system.  :)  For example:  > pip show cvxopt Name: cvxopt Version: 1.2.0 ... Location: /usr/local/lib/python2.7/site-packages      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "pip",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages",
        "A_Votes": "200",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I activated a virtualenv which has pip installed. I did  pip3 install Django==1.8   and Django successfully downloaded. Now, I want to open up the Django folder. Where is the folder located? Normally it would be in \"downloads\" but I'm not sure where it would be if I installed it using pip in a virtualenv.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Where does pip install its packages?",
        "A_Content": "  By default, on Linux, Pip installs packages to /usr/local/lib/python2.7/dist-packages.  Using virtualenv or --user during install will change this default location. If you use pip show make sure you are using the right user or else pip may not see the packages you are referencing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "pip",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I activated a virtualenv which has pip installed. I did  pip3 install Django==1.8   and Django successfully downloaded. Now, I want to open up the Django folder. Where is the folder located? Normally it would be in \"downloads\" but I'm not sure where it would be if I installed it using pip in a virtualenv.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Check list of words in another string [duplicate]",
        "A_Content": "  if any(word in 'some one long two phrase three' for word in list_):      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3271478/check-list-of-words-in-another-string",
        "A_Votes": "216",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Check if multiple strings exist in another string                                        12 answers                                          I can do such thing in python:  l = ['one', 'two', 'three'] if 'some word' in l:    ...   This will check if 'some word' exists in the list. But can I do reverse thing?  l = ['one', 'two', 'three'] if l in 'some one long two phrase three':     ...   I have to check whether some words from array are in the string. I can do this using cycle but this way has more lines of code.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Check list of words in another string [duplicate]",
        "A_Content": "  If your list of words is of substantial length, and you need to do this test many times, it may be worth converting the list to a set and using set intersection to test (with the added benefit that you wil get the actual words that are in both lists):  >>> long_word_list = 'some one long two phrase three about above along after against' >>> long_word_set = set(long_word_list.split()) >>> set('word along river'.split()) & long_word_set set(['along'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3271478/check-list-of-words-in-another-string",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Check if multiple strings exist in another string                                        12 answers                                          I can do such thing in python:  l = ['one', 'two', 'three'] if 'some word' in l:    ...   This will check if 'some word' exists in the list. But can I do reverse thing?  l = ['one', 'two', 'three'] if l in 'some one long two phrase three':     ...   I have to check whether some words from array are in the string. I can do this using cycle but this way has more lines of code.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Check list of words in another string [duplicate]",
        "A_Content": "  Here are a couple of alternative ways of doing it, that may be faster or more suitable than KennyTM's answer, depending on the context.  1) use a regular expression:  import re words_re = re.compile(\"|\".join(list_of_words))  if words_re.search('some one long two phrase three'):    # do logic you want to perform   2) You could use sets if you want to match whole words, e.g. you do not want to find the word \"the\" in the phrase \"them theorems are theoretical\":  word_set = set(list_of_words) phrase_set = set('some one long two phrase three'.split()) if word_set.intersection(phrase_set):     # do stuff   Of course you can also do whole word matches with regex using the \"\\b\" token.  The performance of these and Kenny's solution are going to depend on several factors, such as how long the word list and phrase string are, and how often they change.  If performance is not an issue then go for the simplest, which is probably Kenny's.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3271478/check-list-of-words-in-another-string",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Check if multiple strings exist in another string                                        12 answers                                          I can do such thing in python:  l = ['one', 'two', 'three'] if 'some word' in l:    ...   This will check if 'some word' exists in the list. But can I do reverse thing?  l = ['one', 'two', 'three'] if l in 'some one long two phrase three':     ...   I have to check whether some words from array are in the string. I can do this using cycle but this way has more lines of code.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Check list of words in another string [duplicate]",
        "A_Content": "  Easiest and Simplest method of solving this problem is using re  import re  search_list = ['one', 'two', 'there'] long_string = 'some one long two phrase three' if re.compile('|'.join(search_list),re.IGNORECASE).search(long_string): #re.IGNORECASE is used to ignore case     # Do Something if word is present else:     # Do Something else if word is not present      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3271478/check-list-of-words-in-another-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Check if multiple strings exist in another string                                        12 answers                                          I can do such thing in python:  l = ['one', 'two', 'three'] if 'some word' in l:    ...   This will check if 'some word' exists in the list. But can I do reverse thing?  l = ['one', 'two', 'three'] if l in 'some one long two phrase three':     ...   I have to check whether some words from array are in the string. I can do this using cycle but this way has more lines of code.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  >>> thetuple = (1, 2, 3) >>> print \"this is a tuple: %s\" % (thetuple,) this is a tuple: (1, 2, 3)   Making a singleton tuple with the tuple of interest as the only item, i.e. the (thetuple,) part, is the key bit here.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  Note that the % syntax is obsolete. Use str.format, which is simpler and more readable:  t = 1,2,3 print 'This is a tuple {0}'.format(t)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  Many answers given above were correct. The right way to do it is:  >>> thetuple = (1, 2, 3) >>> print \"this is a tuple: %s\" % (thetuple,) this is a tuple: (1, 2, 3)   However, there was a dispute over if the '%' String operator is obsolete. As many have pointed out, it is definitely not obsolete, as the '%' String operator is easier to combine a String statement with a list data.  Example:  >>> tup = (1,2,3) >>> print \"First: %d, Second: %d, Third: %d\" % tup First: 1, Second: 2, Third: 3   However, using the .format() function, you will end up with a verbose statement.  Example:  >>> tup = (1,2,3) >>> print \"First: %d, Second: %d, Third: %d\" % tup >>> print 'First: {}, Second: {}, Third: {}'.format(1,2,3) >>> print 'First: {0[0]}, Second: {0[1]}, Third: {0[2]}'.format(tup)  First: 1, Second: 2, Third: 3 First: 1, Second: 2, Third: 3 First: 1, Second: 2, Third: 3   Further more, '%' string operator also useful for us to validate the data type such as %s, %d, %i, while .format() only support two conversion flags: '!s' and '!r'.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  >>> tup = (1, 2, 3) >>> print \"Here it is: %s\" % (tup,) Here it is: (1, 2, 3) >>>   Note that (tup,) is a tuple containing a tuple. The outer tuple is the argument to the % operator. The inner tuple is its content, which is actually printed.  (tup) is an expression in brackets, which when evaluated results in tup.  (tup,) with the trailing comma is a tuple, which contains tup as is only member.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  This doesn't use string formatting, but you should be able to do:  print 'this is a tuple ', (1, 2, 3)   If you really want to use string formatting:  print 'this is a tuple %s' % str((1, 2, 3)) # or print 'this is a tuple %s' % ((1, 2, 3),)   Note, this assumes you are using a Python version earlier than 3.0.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  t = (1, 2, 3)  # the comma (,) concatenates the strings and adds a space print \"this is a tuple\", (t)  # format is the most flexible way to do string formatting print \"this is a tuple {0}\".format(t)  # classic string formatting # I use it only when working with older Python versions print \"this is a tuple %s\" % repr(t) print \"this is a tuple %s\" % str(t)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  I think the best way to do this is:  t = (1,2,3)  print \"This is a tuple: %s\" % str(t)   If you're familiar with printf style formatting, then Python supports its own version. In Python, this is done using the \"%\" operator applied to strings (an overload of the modulo operator), which takes any string and applies printf-style formatting to it.  In our case, we are telling it to print \"This is a tuple: \", and then adding a string \"%s\", and for the actual string, we're passing in a string representation of the tuple (by calling str(t)).  If you're not familiar with printf style formatting, I highly suggest learning, since it's very standard. Most languages support it in one way or another.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  Please note a trailing comma will be added if the tuple only has one item. e.g:  t = (1,) print 'this is a tuple {}'.format(t)   and you'll get:  'this is a tuple (1,)'   in some cases e.g. you want to get a quoted list to be used in mysql query string like   SELECT name FROM students WHERE name IN ('Tom', 'Jerry');   you need to consider to remove the tailing comma use replace(',)', ')') after formatting because it's possible that the tuple has only 1 item like ('Tom',), so the tailing comma needs to be removed:  query_string = 'SELECT name FROM students WHERE name IN {}'.format(t).replace(',)', ')')   Please suggest if you have decent way of removing this comma in the output.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Printing tuple with string formatting in Python",
        "A_Content": "  Try this to get an answer:  >>>d = ('1', '2')  >>> print(\"Value: %s\" %(d)) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: not all arguments converted during string formatting   If we put only-one tuple inside (), it makes a tuple itself:  >>> (d) ('1', '2')   This means the above print statement will look like:  print(\"Value: %s\" %('1', '2')) which is an error!  Hence:  >>> (d,) (('1', '2'),) >>>    Above will be fed correctly to the print's arguments.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1455602/printing-tuple-with-string-formatting-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So, i have this problem. I got tuple (1,2,3) which i should print with string formatting. eg.  tup = (1,2,3) print \"this is a tuple %something\" % (tup)   and this should print tuple representation with brackets, like     This is a tuple (1,2,3)   But I get TypeError: not all arguments converted during string formatting instead.  How in the world am I able to do this? Kinda lost here so if you guys could point me to a right direction :)     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  There are two possible solutions:   Use a boolean mask, then use df.loc[mask] Set the date column as a DatetimeIndex, then use df[start_date : end_date]     Using a boolean mask:  Ensure df['date'] is a Series with dtype datetime64[ns]:  df['date'] = pd.to_datetime(df['date'])     Make a boolean mask. start_date and end_date can be datetime.datetimes, np.datetime64s, pd.Timestamps, or even datetime strings:  mask = (df['date'] > start_date) & (df['date'] <= end_date)   Select the sub-DataFrame:  df.loc[mask]   or re-assign to df  df = df.loc[mask]     For example,  import numpy as np import pandas as pd  df = pd.DataFrame(np.random.random((200,3))) df['date'] = pd.date_range('2000-1-1', periods=200, freq='D') mask = (df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10') print(df.loc[mask])   yields              0         1         2       date 153  0.208875  0.727656  0.037787 2000-06-02 154  0.750800  0.776498  0.237716 2000-06-03 155  0.812008  0.127338  0.397240 2000-06-04 156  0.639937  0.207359  0.533527 2000-06-05 157  0.416998  0.845658  0.872826 2000-06-06 158  0.440069  0.338690  0.847545 2000-06-07 159  0.202354  0.624833  0.740254 2000-06-08 160  0.465746  0.080888  0.155452 2000-06-09 161  0.858232  0.190321  0.432574 2000-06-10     Using a DatetimeIndex:  If you are going to do a lot of selections by date, it may be quicker to set the date column as the index first. Then you can select rows by date using df.loc[start_date:end_date].  import numpy as np import pandas as pd  df = pd.DataFrame(np.random.random((200,3))) df['date'] = pd.date_range('2000-1-1', periods=200, freq='D') df = df.set_index(['date']) print(df.loc['2000-6-1':'2000-6-10'])   yields                     0         1         2 date                                     2000-06-01  0.040457  0.326594  0.492136    # <- includes start_date 2000-06-02  0.279323  0.877446  0.464523 2000-06-03  0.328068  0.837669  0.608559 2000-06-04  0.107959  0.678297  0.517435 2000-06-05  0.131555  0.418380  0.025725 2000-06-06  0.999961  0.619517  0.206108 2000-06-07  0.129270  0.024533  0.154769 2000-06-08  0.441010  0.741781  0.470402 2000-06-09  0.682101  0.375660  0.009916 2000-06-10  0.754488  0.352293  0.339337   While Python list indexing, e.g. seq[start:end] includes start but not end, in contrast, Pandas df.loc[start_date : end_date] includes both end-points in the result if they are in the index. Neither start_date nor end_date has to be in the index however.    Also note that pd.read_csv has a parse_dates parameter which you could use to parse the date column as datetime64s. Thus, if you use parse_dates, you would not need to use df['date'] = pd.to_datetime(df['date']).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "208",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  I feel the best option will be to use the direct checks rather than using loc function:  df = df[(df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10')]   It works for me.  Major issue with loc function with a slice is that the limits should be present in the actual values, if not this will result in KeyError.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  You can use the isin method on the date column like so df[df[\"date\"].isin(pd.date_range(start_date, end_date))]  Note: This only works with dates (as the question asks) and not timestamps.  Example:     import numpy as np    import pandas as pd  # Make a DataFrame with dates and random numbers df = pd.DataFrame(np.random.random((30, 3))) df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')  # Select the rows between two dates in_range_df = df[df[\"date\"].isin(pd.date_range(\"2017-01-15\", \"2017-01-20\"))]  print(in_range_df)  # print result   which gives             0         1         2       date 14  0.960974  0.144271  0.839593 2017-01-15 15  0.814376  0.723757  0.047840 2017-01-16 16  0.911854  0.123130  0.120995 2017-01-17 17  0.505804  0.416935  0.928514 2017-01-18 18  0.204869  0.708258  0.170792 2017-01-19 19  0.014389  0.214510  0.045201 2017-01-20      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  You can also use between:  df[df.some_date.between(start_date, end_date)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  In case if you are going to do this frequently the best solution would be to first set the date column as index which will convert the column in DateTimeIndex and use the following condition to slice any range of dates.  import pandas as pd  data_frame = data_frame.set_index('date')  df = data_frame[(data_frame.index > '2017-08-10') & (data_frame.index <= '2017-08-15')]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Select DataFrame rows between two dates",
        "A_Content": "  I prefer not to alter the df.  An option is to retrieve the index of the start and end dates:  import numpy as np    import pandas as pd  #Dummy DataFrame df = pd.DataFrame(np.random.random((30, 3))) df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')  #Get the index of the start and end dates respectively start = df[df['date']=='2017-01-07'].index[0] end = df[df['date']=='2017-01-14'].index[0]  #Show the sliced df (from 2017-01-07 to 2017-01-14) df.loc[start:end]   which results in:       0   1   2       date 6  0.5 0.8 0.8 2017-01-07 7  0.0 0.7 0.3 2017-01-08 8  0.8 0.9 0.0 2017-01-09 9  0.0 0.2 1.0 2017-01-10 10 0.6 0.1 0.9 2017-01-11 11 0.5 0.3 0.9 2017-01-12 12 0.5 0.4 0.3 2017-01-13 13 0.4 0.9 0.9 2017-01-14      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a DataFrame from a csv as follows:  stock = pd.read_csv('data_in/' + filename + '.csv', skipinitialspace=True)   The DataFrame has a date column. Is there a way to create a new DataFrame (or just overwrite the existing one) which only contains rows with date values that fall within a specified date range or between two specified date values?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  On Windows, the only sure way is to use CtrlBreak. Stops every python script instantly!  (Note that on some keyboards, \"Break\" is labeled as \"Pause\".)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  Pressing Ctrl + c while a python program is running will cause python to raise a KeyboardInterupt exception.  It's likely that a program that makes lots of HTTP requests will have lots of exception handling code.  If the except part of the try-except block doesn't specify which exceptions it should catch, it will catch all exceptions including the KeyboardInterupt that you just caused.  A properly coded python program will make use of the python exception hierarchy and only catch exceptions that are derived from Exception.  #This is the wrong way to do things try:   #Some stuff might raise an IO exception except:   #Code that ignores errors  #This is the right way to do things try:   #Some stuff might raise an IO exception except Exception:   #This won't catch KeyboardInterupt   If you can't change the code (or need to kill the program so that your changes will take effect) then you can try pressing Ctrl + c rapidly.  The first of the KeyboardInterupt exceptions will knock your program out of the try block and hopefully one of the later KeyboardInterrupt exceptions will be raised when the program is outside of a try block.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "59",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  If it is running in the Python shell use Ctrl + Z, otherwise locate the python process and kill it.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  The interrupt process is hardware and OS dependent. So you will have very different behavior depending on where you run your python script. For example, on Windows machines we have Ctrl+C (SIGINT) and Ctrl+Break (SIGBREAK).   So while SIGINT is present on all systems and can be handled and caught, the SIGBREAK signal is Windows specific (and can be disabled in CONFIG.SYS) and is really handled by the BIOS as an interrupt vector INT 1Bh, which is why this key is much more powerful than any other. So if you're using some *nix flavored OS, you will get different results depending on the implementation, since that signal is not present there, but others are. In Linux you can check what signals are available to you by:   $ kill -l  1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP  6) SIGABRT      7) SIGEMT       8) SIGFPE       9) SIGKILL     10) SIGBUS 11) SIGSEGV     12) SIGSYS      13) SIGPIPE     14) SIGALRM     15) SIGTERM 16) SIGURG      17) SIGSTOP     18) SIGTSTP     19) SIGCONT     20) SIGCHLD 21) SIGTTIN     22) SIGTTOU     23) SIGIO       24) SIGXCPU     25) SIGXFSZ 26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGPWR      30) SIGUSR1 31) SIGUSR2     32) SIGRTMAX   So if you want to catch the CTRL+BREAK signal on a linux system you'll have to check to what POSIX signal they have mapped that key. Popular mappings are:  CTRL+\\     = SIGQUIT  CTRL+D     = SIGQUIT CTRL+C     = SIGINT CTRL+Z     = SIGTSTOP  CTRL+BREAK = SIGKILL or SIGTERM or SIGSTOP   In fact, many more functions are available under Linux, where the SysRq (System Request) key can take on a life of its own...      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  This post is old but I recently ran into the same problem of CTRL+C not terminating python scripts on my Linux. I used the CTRL + \\ (SIGQUIT).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  On Mac press:      \"control\" + \" \\ \"   to quit a python process attached to a terminal.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  On a mac / in Terminal:    Show Inspector (right click within the terminal window or Shell >Show Inspector) click the Settings icon above \"running processes\" choose from the list of options under \"Signal Process Group\" (Kill, terminate, interrupt, etc).      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Stopping python using ctrl+c",
        "A_Content": "  ctrl+q will instantly stop the running code and close all windows.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1364173/stopping-python-using-ctrlc",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python script that uses threads and makes lots of HTTP requests. I think what's happening is that while a HTTP request (using urllib2) is reading, it's blocking and not responding to CtrlC to stop the program. Is there any way around this?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  Also worth mentioning here that you can use the command line args for this:  fab command -i /path/to/key.pem [-H [user@]host[:port]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  Finding a simple fabfile with a working example of SSH keyfile usage isn't easy for some reason. I wrote a blog post about it (with a matching gist).  Basically, the usage goes something like this:  from fabric.api import *  env.hosts = ['host.name.com'] env.user = 'user' env.key_filename = '/path/to/keyfile.pem'  def local_uname():     local('uname -a')  def remote_uname():     run('uname -a')   The important part is setting the env.key_filename environment variable, so that the Paramiko configuration can look for it when connecting.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "144",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  Another cool feature available as of Fabric 1.4 - Fabric now supports SSH configs.  If you already have all the SSH connection parameters in your ~/.ssh/config file, Fabric will natively support it, all you need to do is add:  env.use_ssh_config = True   at the beginning of your fabfile.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  For me, the following didn't work:  env.user=[\"ubuntu\"] env.key_filename=['keyfile.pem'] env.hosts=[\"xxx-xx-xxx-xxx.ap-southeast-1.compute.amazonaws.com\"]   or   fab command -i /path/to/key.pem [-H [user@]host[:port]]   However, the following did:  env.key_filename=['keyfile.pem'] env.hosts=[\"ubuntu@xxx-xx-xxx-xxx-southeast-1.compute.amazonaws.com\"]   or  env.key_filename=['keyfileq.pem'] env.host_string=\"ubuntu@xxx-xx-xxx-xxx.ap-southeast-1.compute.amazonaws.com\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  I had to do this today, my .py file was as simple as possible, like the one posted in the answer of @YuvalAdam but still I kept getting prompted for a password...  Looking at the paramiko (the library used by fabric for ssh) log, I found the line:     Incompatible ssh peer (no acceptable kex algorithm)   I updated paramiko with:  sudo pip install paramiko --upgrade   And now it's working.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  For fabric 2.2.2 using fabfile you can use the following:  from fabric import task, Connection  @task def staging(ctx):     ctx.name = 'staging'     ctx.user = 'ubuntu'     ctx.host = '192.1.1.1'     ctx.connect_kwargs.key_filename = os.environ['ENV_VAR_POINTS_TO_PRIVATE_KEY_PATH']  @task def do_something_remote(ctx):     with Connection(ctx.host, ctx.user, connect_kwargs=ctx.connect_kwargs) as conn:         conn.sudo('supervisorctl status')   and run it with:  fab staging do_something_remote      ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Using an SSH keyfile with Fabric",
        "A_Content": "  As stated above, Fabric will support .ssh/config file settings after a fashion, but using a pem file for ec2 seems to be problematic.   IOW a properly setup .ssh/config file will work from the command line via 'ssh servername' and fail to work with 'fab sometask' when env.host=['servername'].  This was overcome by specifying the env.key_filename='keyfile' in my fabfile.py and duplicating the IdentityFile entry already in my .ssh/config.     This could be either Fabric or paramiko, which in my case was Fabric 1.5.3 and Paramiko 1.9.0.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "fabric"
        ],
        "URL": "https://stackoverflow.com/questions/5327465/using-an-ssh-keyfile-with-fabric",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you configure fabric to connect to remote hosts using SSH keyfiles (for example, Amazon EC2 instances)?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  Turns out that the pyspark bin is LOADING python and automatically loading the correct library paths.  Check out $SPARK_HOME/bin/pyspark :  # Add the PySpark classes to the Python path: export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH   I added this line to my .bashrc file and the modules are now correctly found!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  Here is a simple method (If you don't bother about how it works!!!)     Use findspark    Go to your python shell  pip install findspark  import findspark  findspark.init() import the necessary modules  from pyspark import SparkContext  from pyspark import SparkConf Done!!!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  If it prints such error:     ImportError: No module named py4j.java_gateway   Please add $SPARK_HOME/python/build to PYTHONPATH:  export SPARK_HOME=/Users/pzhang/apps/spark-1.1.0-bin-hadoop2.4 export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  By exporting the SPARK path and the Py4j path, it started to work:  export SPARK_HOME=/usr/local/Cellar/apache-spark/1.5.1 export PYTHONPATH=$SPARK_HOME/libexec/python:$SPARK_HOME/libexec/python/build:$PYTHONPATH PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.8.2.1-src.zip:$PYTHONPATH  export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH   So, if you don't want to type these everytime you want to fire up the Python shell, you might want to add it to your .bashrc file     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  dont run your py file as: python filename.py instead use: spark-submit filename.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  On Mac, I use Homebrew to install Spark (formula \"apache-spark\"). Then, I set the PYTHONPATH this way so the Python import works:  export SPARK_HOME=/usr/local/Cellar/apache-spark/1.2.0 export PYTHONPATH=$SPARK_HOME/libexec/python:$SPARK_HOME/libexec/python/build:$PYTHONPATH   Replace the \"1.2.0\" with the actual apache-spark version on your mac.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  For a Spark execution in pyspark two components are required to work together:   pyspark python package Spark instance in a JVM   When launching things with spark-submit or pyspark, these scripts will take care of both, i.e. they set up your PYTHONPATH, PATH, etc, so that your script can find pyspark, and they also start the spark instance, configuring according to your params, e.g. --master X  Alternatively, it is possible to bypass these scripts and run your spark application directly in the python interpreter likepython myscript.py. This is especially interesting when spark scripts start to become more complex and eventually receive their own args.   Ensure the pyspark package  can be found by the Python interpreter. As already discussed either add the spark/python dir to PYTHONPATH or directly install pyspark using pip install. Set the parameters of spark instance from your script (those that used to be passed to pyspark).    For spark configurations as you'd normally set with --conf they are defined with a config object (or string configs) in SparkSession.builder.config For main options (like --master, or --driver-mem) for the moment you can set them by writing to the PYSPARK_SUBMIT_ARGS environment variable. To make things cleaner and safer you can set it from within Python itself, and spark will read it when starting.  Start the instance, which just requires you to call getOrCreate() from the builder object.   Your script can therefore have something like this:  from pyspark.sql import SparkSession  if __name__ == \"__main__\":     if spark_main_opts:         # Set main options, e.g. \"--master local[4]\"         os.environ['PYSPARK_SUBMIT_ARGS'] = spark_main_opts + \" pyspark-shell\"      # Set spark config     spark = (SparkSession.builder              .config(\"spark.checkpoint.compress\", True)              .config(\"spark.jars.packages\", \"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")              .getOrCreate())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  To get rid of ImportError: No module named py4j.java_gateway, you need to add following lines:  import os import sys   os.environ['SPARK_HOME'] = \"D:\\python\\spark-1.4.1-bin-hadoop2.4\"   sys.path.append(\"D:\\python\\spark-1.4.1-bin-hadoop2.4\\python\") sys.path.append(\"D:\\python\\spark-1.4.1-bin-hadoop2.4\\python\\lib\\py4j-0.8.2.1-src.zip\")  try:     from pyspark import SparkContext     from pyspark import SparkConf      print (\"success\")  except ImportError as e:     print (\"error importing spark modules\", e)     sys.exit(1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  On Windows 10 the following worked for me. I added the following environment variables using Settings > Edit environment variables for your account:  SPARK_HOME=C:\\Programming\\spark-2.0.1-bin-hadoop2.7 PYTHONPATH=%SPARK_HOME%\\python;%PYTHONPATH%   (change \"C:\\Programming\\...\" to the folder in which you have installed spark)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  For Linux users, the following is the correct (and non-hard-coded)  way of including the pyspark libaray in PYTHONPATH. Both PATH parts are necessary:   The path to the pyspark Python module itself, and The path to the zipped library that that pyspark module relies on when imported   Notice below that the zipped library version is dynamically determined, so we do not hard-code it.  export PYTHONPATH=${SPARK_HOME}/python/:$(echo ${SPARK_HOME}/python/lib/py4j-*-src.zip):${PYTHONPATH}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  I am running a spark cluster, on CentOS VM, which is installed from cloudera yum packages.  Had to set the following variables to run pyspark.  export SPARK_HOME=/usr/lib/spark; export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  export PYSPARK_PYTHON=/home/user/anaconda3/bin/python export PYSPARK_DRIVER_PYTHON=jupyter export PYSPARK_DRIVER_PYTHON_OPTS='notebook'   This is what I did for using my Anaconda distribution with Spark. This is Spark version independent. You can change the first line to your users' python bin.  Also, as of Spark 2.2.0 PySpark is available as a Stand-alone package on PyPi but I am yet to test it out.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  I had the same problem.  Also make sure you are using right python version and you are installing it with right pip version. in my case: I had both python 2.7 and 3.x.  I have installed pyspark with   pip2.7 install pyspark  and it worked.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  I got this error because the python script I was trying to submit was called pyspark.py (facepalm).  The fix was to set my PYTHONPATH as recommended above, then rename the script to pyspark_test.py and clean up the pyspark.pyc that was created based on my scripts original name and that cleared this error up.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  I had this same problem and would add one thing to the proposed solutions above. When using Homebrew on Mac OS X to install Spark you will need to correct the py4j path address to include libexec in the path (remembering to change py4j version to the one you have);  PYTHONPATH=$SPARK_HOME/libexec/python/lib/py4j-0.9-src.zip:$PYTHONPATH      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "importing pyspark in python shell",
        "A_Content": "  In the case of DSE (DataStax Cassandra & Spark)  The following location needs to be added to PYTHONPATH  export PYTHONPATH=/usr/share/dse/resources/spark/python:$PYTHONPATH   Then use the dse pyspark to get the modules in path.  dse pyspark      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache-spark",
            "pyspark"
        ],
        "URL": "https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is a copy of someone else's question on another forum that was never answered, so I thought I'd re-ask it here, as I have the same issue.  (See http://geekple.com/blogs/feeds/Xgzu7/posts/351703064084736)  I have Spark installed properly on my machine and am able to run python programs with the pyspark modules without error when using ./bin/pyspark as my python interpreter.  However, when I attempt to run the regular Python shell, when I try to import pyspark modules I get this error:  from pyspark import SparkContext   and it says  \"No module named pyspark\".   How can I fix this?  Is there an environment variable I need to set to point Python to the pyspark headers/libraries/etc.?  If my spark installation is /spark/, which pyspark paths do I need to include?  Or can pyspark programs only be run from the pyspark interpreter?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to use Python's pip to download and keep the zipped files for a package?",
        "A_Content": "  The --download-cache option should do what you want:  pip install --download-cache=\"/pth/to/downloaded/files\" package   However, when I tested this, the main package downloaded, saved and installed ok, but the the dependencies were saved with their full url path as the name - a bit annoying, but all the tar.gz files were there.  The --download option downloads the main package and its dependencies and does not install any of them. (Note that prior to version 1.1 the --download option did not download dependencies.)  pip install package --download=\"/pth/to/downloaded/files\"   The pip documentation outlines using --download for fast & local installs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/7300321/how-to-use-pythons-pip-to-download-and-keep-the-zipped-files-for-a-package",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    If I want to use the pip command to download a package (and its dependencies), but keep all of the zipped files that get downloaded (say, django-socialregistration.tar.gz) - is there a way to do that?  I've tried various command-line options, but it always seems to unpack and delete the zipfile - or it gets the zipfile, but only for the original package, not the dependencies.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to use Python's pip to download and keep the zipped files for a package?",
        "A_Content": "  I always do this to download the packages:  pip install --download /path/to/download/to_packagename  OR  pip install --download=/path/to/packages/downloaded -r requirements.txt  And when I want to install all of those libraries I just downloaded, I do this:  pip install --no-index --find-links=\"/path/to/downloaded/dependencies\" packagename   OR   pip install --no-index --find-links=\"/path/to/downloaded/packages\" -r requirements.txt    Update  Also, to get all the packages installed on one system, you can export them all to requirement.txt that will be used to intall them on another system, we do this:  pip freeze > requirement.txt  Then, the requirement.txt can be used as above for download, or do this to install them from requirement.txt:  pip install -r requirement.txt  REFERENCE: pip installer     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/7300321/how-to-use-pythons-pip-to-download-and-keep-the-zipped-files-for-a-package",
        "A_Votes": "51",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the pip command to download a package (and its dependencies), but keep all of the zipped files that get downloaded (say, django-socialregistration.tar.gz) - is there a way to do that?  I've tried various command-line options, but it always seems to unpack and delete the zipfile - or it gets the zipfile, but only for the original package, not the dependencies.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to use Python's pip to download and keep the zipped files for a package?",
        "A_Content": "  pip install --download is deprecated. Starting from version 8.0.0 you should use pip download command:   pip download <package-name>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/7300321/how-to-use-pythons-pip-to-download-and-keep-the-zipped-files-for-a-package",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the pip command to download a package (and its dependencies), but keep all of the zipped files that get downloaded (say, django-socialregistration.tar.gz) - is there a way to do that?  I've tried various command-line options, but it always seems to unpack and delete the zipfile - or it gets the zipfile, but only for the original package, not the dependencies.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to use Python's pip to download and keep the zipped files for a package?",
        "A_Content": "  In version 7.1.2 pip downloads the wheel of a package (if available) with the following:  pip install package -d /path/to/downloaded/file   The following downloads a source distribution:  pip install package -d /path/to/downloaded/file --no-binary :all:   These download the dependencies as well, if pip is aware of them (e.g., if pip show package lists them).    Update  As noted by Anton Khodak, pip download command is preferred since version 8. In the above examples this means that /path/to/downloaded/file needs to be given with option -d, so replacing install with download works.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/7300321/how-to-use-pythons-pip-to-download-and-keep-the-zipped-files-for-a-package",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the pip command to download a package (and its dependencies), but keep all of the zipped files that get downloaded (say, django-socialregistration.tar.gz) - is there a way to do that?  I've tried various command-line options, but it always seems to unpack and delete the zipfile - or it gets the zipfile, but only for the original package, not the dependencies.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to use Python's pip to download and keep the zipped files for a package?",
        "A_Content": "  Use pip download <package1 package2 package n> to download all the packages including dependencies  Use pip install --no-index --find-links . <package1 package2 package n> to install all the packages including dependencies.  It gets all the files from CWD.  It will not download anything     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/7300321/how-to-use-pythons-pip-to-download-and-keep-the-zipped-files-for-a-package",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the pip command to download a package (and its dependencies), but keep all of the zipped files that get downloaded (say, django-socialregistration.tar.gz) - is there a way to do that?  I've tried various command-line options, but it always seems to unpack and delete the zipfile - or it gets the zipfile, but only for the original package, not the dependencies.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  Use , to separate strings and variables while printing:  print \"If there was a birth every 7 seconds, there would be: \",births,\"births\"   , in print statement separtes the items by a single space:  >>> print \"foo\",\"bar\",\"spam\" foo bar spam   or better use string formatting:  print \"If there was a birth every 7 seconds, there would be: {} births\".format(births)   String formatting is much more powerful and allows you to do some other things as well, like : padding, fill, alignment,width, set precision etc  >>> print \"{:d} {:03d} {:>20f}\".format(1,2,1.1) 1 002             1.100000   ^^^   0's padded to 2   Demo:  >>> births = 4 >>> print \"If there was a birth every 7 seconds, there would be: \",births,\"births\" If there was a birth every 7 seconds, there would be:  4 births  #formatting >>> print \"If there was a birth every 7 seconds, there would be: {} births\".format(births) If there was a birth every 7 seconds, there would be: 4 births      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "140",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  two more  The First one   >>>births = str(5)  >>>print \"there are \" + births + \" births.\"  there are 5 births.   When adding strings, they concatenate.   The Second One  Also the format (Python 2.6 and newer) method of strings is probably the standard way:  >>> births = str(5) >>> >>> print \"there are {} births.\".format(births) there are 5 births.   This format method can be used with lists as well  >>> format_list = ['five','three'] >>> print \"there are {} births and {} deaths\".format(*format_list) #unpack the list there are five births and three deaths   or dictionaries  >>> format_dictionary = {'births': 'five', 'deaths': 'three'} >>> print \"there are {births} births, and {deaths} deaths\".format(**format_dictionary) #yup, unpack the dictionary there are five births, and three deaths      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  If you want to work with python 3, it's very simple:   print(\"If there was a birth every 7 second, there would be %d births.\" % (births))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  You can either use a formatstring:  print \"There are %d births\" % (births,)   or in this simple case:  print \"There are \", births, \"births\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  On a current python version you have to use parenthesis, like so :  print (\"If there was a birth every 7 seconds\", X)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  You would first make a variable: for example: D = 1. Then Do This but replace the string with whatever you want:  D = 1 print(\"Here is a number!:\",D)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  You can use string formatting to do this:  print \"If there was a birth every 7 seconds, there would be: %d births\" % births   or you can give print multiple arguments, and it will automatically separate them by a space:  print \"If there was a birth every 7 seconds, there would be:\", births, \"births\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  I copied and pasted your script into a .py file. I ran it as-is with Python 2.7.10 and received the same syntax error. I also tried the script in Python 3.5 and received the following output:  File \"print_strings_on_same_line.py\", line 16 print fiveYears               ^ SyntaxError: Missing parentheses in call to 'print'   Then, I modified the last line where it prints the number of births as follows:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" + str(births) + \" births\"   The output was (Python 2.7.10):  157680000 If there was a birth every 7 seconds, there would be: 22525714 births   I hope this helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  use String formatting   print(\"If there was a birth every 7 seconds, there would be: {} births\".format(births))  # Will replace \"{}\" with births   if you doing a toy project use:   print('If there was a birth every 7 seconds, there would be:' births'births)    or  print('If there was a birth every 7 seconds, there would be: %d births' %(births)) # Will replace %d with births      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  As of python 3.6 you can use Literal String Interpolation.   births = 5.25487 >>> print(f'If there was a birth every 7 seconds, there would be: {births:.2f} births') If there was a birth every 7 seconds, there would be: 5.25 births      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I print variable and string on same line in Python?",
        "A_Content": "  Python is a very versatile language. You may print variables by different methods. I have listed below 4 methods. You may use them according to your convenience.  Example:  a=1 b='ball'   Method 1:  print('I have %d %s' %(a,b))   Method 2:  print('I have',a,b)   Method 3:  print('I have {} {}'.format(a,b))   Method 4:  print('I have ' + str(a) +' ' +b)   Output would be:  I have 1 ball      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "variables",
            "printing"
        ],
        "URL": "https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using python to work out how many children would be born in 5 years if a child was born every 7 seconds. The problem is on my last line. How do I get a variable to work when I'm printing text either side of it?   Here is my code:  currentPop = 312032486 oneYear = 365 hours = 24 minutes = 60 seconds = 60  # seconds in a single day secondsInDay = hours * minutes * seconds  # seconds in a year secondsInYear = secondsInDay * oneYear  fiveYears = secondsInYear * 5  #Seconds in 5 years print fiveYears  # fiveYears in seconds, divided by 7 seconds births = fiveYears // 7  print \"If there was a birth every 7 seconds, there would be: \" births \"births\"      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "get a list of all routes defined in the app",
        "A_Content": "  All the routes for an application are stored on app.url_map which is an instance of werkzeug.routing.Map.  You can iterate over the Rule instances by using the iter_rules method:  from flask import Flask, url_for  app = Flask(__name__)  def has_no_empty_params(rule):     defaults = rule.defaults if rule.defaults is not None else ()     arguments = rule.arguments if rule.arguments is not None else ()     return len(defaults) >= len(arguments)   @app.route(\"/site-map\") def site_map():     links = []     for rule in app.url_map.iter_rules():         # Filter out rules we can't navigate to in a browser         # and rules that require parameters         if \"GET\" in rule.methods and has_no_empty_params(rule):             url = url_for(rule.endpoint, **(rule.defaults or {}))             links.append((url, rule.endpoint))     # links is now a list of url, endpoint tuples   See Display links to new webpages created for a bit more information.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/13317536/get-a-list-of-all-routes-defined-in-the-app",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a complex Flask-based web app.  There are lots of separate files with view functions.  Their URLs are defined with the @app.route('/...') decorator.  Is there a way to get a list of all the routes that have been declared throughout my app?  Perhaps there is some method I can call on the app object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "get a list of all routes defined in the app",
        "A_Content": "  I make a helper method on my manage.py:  @manager.command def list_routes():     import urllib     output = []     for rule in app.url_map.iter_rules():          options = {}         for arg in rule.arguments:             options[arg] = \"[{0}]\".format(arg)          methods = ','.join(rule.methods)         url = url_for(rule.endpoint, **options)         line = urllib.unquote(\"{:50s} {:20s} {}\".format(rule.endpoint, methods, url))         output.append(line)      for line in sorted(output):         print line   It solves the the missing argument by building a dummy set of options.  The output looks like:  CampaignView:edit              HEAD,OPTIONS,GET     /account/[account_id]/campaigns/[campaign_id]/edit CampaignView:get               HEAD,OPTIONS,GET     /account/[account_id]/campaign/[campaign_id] CampaignView:new               HEAD,OPTIONS,GET     /account/[account_id]/new   Then to run it:  python manage.py list_routes  For more on manage.py checkout: http://flask-script.readthedocs.org/en/latest/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/13317536/get-a-list-of-all-routes-defined-in-the-app",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a complex Flask-based web app.  There are lots of separate files with view functions.  Their URLs are defined with the @app.route('/...') decorator.  Is there a way to get a list of all the routes that have been declared throughout my app?  Perhaps there is some method I can call on the app object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "get a list of all routes defined in the app",
        "A_Content": "  I just met the same question. Those solution above is too complex. Just open a new shell under your project:      python     >>> from app import app     >>> app.url_map   The first 'app' is my project script: app.py, another is my web's name.  (this solution is for tinny web with a little route)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/13317536/get-a-list-of-all-routes-defined-in-the-app",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a complex Flask-based web app.  There are lots of separate files with view functions.  Their URLs are defined with the @app.route('/...') decorator.  Is there a way to get a list of all the routes that have been declared throughout my app?  Perhaps there is some method I can call on the app object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "get a list of all routes defined in the app",
        "A_Content": "  Similar to Jonathan's answer I opted to do this instead. I don't see the point of using url_for as it will break if your arguments are not string e.g. float  @manager.command def list_routes():     import urllib      output = []     for rule in app.url_map.iter_rules():         methods = ','.join(rule.methods)         line = urllib.unquote(\"{:50s} {:20s} {}\".format(rule.endpoint, methods, rule))         output.append(line)      for line in sorted(output):         print(line)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/13317536/get-a-list-of-all-routes-defined-in-the-app",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a complex Flask-based web app.  There are lots of separate files with view functions.  Their URLs are defined with the @app.route('/...') decorator.  Is there a way to get a list of all the routes that have been declared throughout my app?  Perhaps there is some method I can call on the app object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "get a list of all routes defined in the app",
        "A_Content": "  Since you did not specify that it has to be run command-line, the following could easily be returned in json for a dashboard or other non-command-line interface.  The result and the output really shouldn't be commingled from a design perspective anyhow.  It's bad program design, even if it is a tiny program. The result below could then be used in a web application, command-line, or anything else that ingests json.  You also didn't specify that you needed to know the python function associated with each route, so this more precisely answers your original question.    I use below to add the output to a monitoring dashboard myself.  If you want the available route methods (GET, POST, PUT, etc.), you would need to combine it with other answers above.  Rule's repr() takes care of converting the required arguments in the route.  def list_routes():     routes = []      for rule in app.url_map.iter_rules():         routes.append('%s' % rule)      return routes   The same thing using a list comprehension:  def list_routes():     return ['%s' % rule for rule in app.url_map.iter_rules()]   Sample output:  {   \"routes\": [     \"/endpoint1\",      \"/nested/service/endpoint2\",      \"/favicon.ico\",      \"/static/<path:filename>\"   ] }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/13317536/get-a-list-of-all-routes-defined-in-the-app",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a complex Flask-based web app.  There are lots of separate files with view functions.  Their URLs are defined with the @app.route('/...') decorator.  Is there a way to get a list of all the routes that have been declared throughout my app?  Perhaps there is some method I can call on the app object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Does 'finally' always execute in Python?",
        "A_Content": "  \"Guaranteed\" is a much stronger word than any implementation of finally deserves. What is guaranteed is that if execution flows out of the whole try-finally construct, it will pass through the finally to do so. What is not guaranteed is that execution will flow out of the try-finally.   A finally in a generator or async coroutine might never run, if the object never executes to conclusion. There are a lot of ways that could happen; here's one:  def gen(text):     try:         for line in text:             try:                 yield int(line)             except:                 # Ignore blank lines - but catch too much!                 pass     finally:         print('Doing important cleanup')  text = ['1', '', '2', '', '3']  if any(n > 1 for n in gen(text)):     print('Found a number')  print('Oops, no cleanup.')   Note that this example is a bit tricky: when the generator is garbage collected, Python attempts to run the finally block by throwing in a GeneratorExit exception, but here we catch that exception and then yield again, at which point Python prints a warning (\"generator ignored GeneratorExit\") and gives up. See PEP 342 (Coroutines via Enhanced Generators) for details.  Other ways a generator or coroutine might not execute to conclusion include if the object is just never GC'ed (yes, that's possible, even in CPython), or if an async with awaits in __aexit__, or if the object awaits or yields in a finally block. This list is not intended to be exhaustive. A finally in a daemon thread might never execute if all non-daemon threads exit first. os._exit will halt the process immediately without executing finally blocks. os.fork may cause finally blocks to execute twice. As well as just the normal problems you'd expect from things happening twice, this could cause concurrent access conflicts (crashes, stalls, ...) if access to shared resources is not correctly synchronized.  Since multiprocessing uses fork-without-exec to create worker processes when using the fork start method (the default on Unix), and then calls os._exit in the worker once the worker's job is done, finally and multiprocessing interaction can be problematic (example). A C-level segmentation fault will prevent finally blocks from running. kill -SIGKILL will prevent finally blocks from running. SIGTERM and SIGHUP will also prevent finally blocks from running unless you install a handler to control the shutdown yourself; by default, Python does not handle SIGTERM or SIGHUP. An exception in finally can prevent cleanup from completing. One particularly noteworthy case is if the user hits control-C just as we're starting to execute the finally block. Python will raise a KeyboardInterrupt and skip every line of the finally block's contents. (KeyboardInterrupt-safe code is very hard to write). If the computer loses power, or if it hibernates and doesn't wake up, finally blocks won't run.   The finally block is not a transaction system; it doesn't provide atomicity guarantees or anything of the sort. Some of these examples might seem obvious, but it's easy to forget such things can happen and rely on finally for too much.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception-handling",
            "try-catch-finally",
            "finally"
        ],
        "URL": "https://stackoverflow.com/questions/49262379/does-finally-always-execute-in-python",
        "A_Votes": "152",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    For any possible try-finally block in Python, is it guaranteed that the finally block will always be executed?  For example, let’s say I return while in an except block:  try:     1/0 except ZeroDivisionError:     return finally:     print(\"Does this code run?\")   Or maybe I re-raise an Exception:  try:     1/0 except ZeroDivisionError:     raise finally:     print(\"What about this code?\")   Testing shows that finally does get executed for the above examples, but I imagine there are other scenarios I haven't thought of.  Are there any scenarios in which a finally block can fail to execute in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Does 'finally' always execute in Python?",
        "A_Content": "  Yes.  Finally always wins.    The only way to defeat it is to halt execution before finally: gets a chance to execute (e.g. crash the interpreter, turn off your computer, suspend a generator forever).       I imagine there are other scenarios I haven't thought of.   Here are a couple more you may not have thought about:  def foo():     # finally always wins     try:         return 1     finally:         return 2  def bar():     # even if he has to eat an unhandled exception, finally wins     try:         raise Exception('boom')     finally:         return 'no boom'   Depending on how you quit the interpreter, sometimes you can \"cancel\" finally, but not like this:  >>> import sys >>> try: ...     sys.exit() ... finally: ...     print('finally wins!') ...  finally wins! $   Using the precarious os._exit (this falls under \"crash the interpreter\" in my opinion):  >>> import os >>> try: ...     os._exit(1) ... finally: ...     print('finally!') ...  $   I'm currently running this code, to test if finally will still execute after the heat death of the universe:  try:     while True:        sleep(1) finally:     print('done')   However, I'm still waiting on the result, so check back here later.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception-handling",
            "try-catch-finally",
            "finally"
        ],
        "URL": "https://stackoverflow.com/questions/49262379/does-finally-always-execute-in-python",
        "A_Votes": "57",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For any possible try-finally block in Python, is it guaranteed that the finally block will always be executed?  For example, let’s say I return while in an except block:  try:     1/0 except ZeroDivisionError:     return finally:     print(\"Does this code run?\")   Or maybe I re-raise an Exception:  try:     1/0 except ZeroDivisionError:     raise finally:     print(\"What about this code?\")   Testing shows that finally does get executed for the above examples, but I imagine there are other scenarios I haven't thought of.  Are there any scenarios in which a finally block can fail to execute in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Does 'finally' always execute in Python?",
        "A_Content": "  According to the Python documentation:     No matter what happened previously, the final-block is executed once the code block is complete and any raised exceptions handled. Even if there's an error in an exception handler or the else-block and a new exception is raised, the code in the final-block is still run.   It should also be noted that if there are multiple return statements, including one in the finally block, then the finally block return is the only one that will execute.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception-handling",
            "try-catch-finally",
            "finally"
        ],
        "URL": "https://stackoverflow.com/questions/49262379/does-finally-always-execute-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For any possible try-finally block in Python, is it guaranteed that the finally block will always be executed?  For example, let’s say I return while in an except block:  try:     1/0 except ZeroDivisionError:     return finally:     print(\"Does this code run?\")   Or maybe I re-raise an Exception:  try:     1/0 except ZeroDivisionError:     raise finally:     print(\"What about this code?\")   Testing shows that finally does get executed for the above examples, but I imagine there are other scenarios I haven't thought of.  Are there any scenarios in which a finally block can fail to execute in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Does 'finally' always execute in Python?",
        "A_Content": "  Well, yes and no.  What is guaranteed is that Python will always try to execute the finally block. In the case where you return from the block or raise an uncaught exception, the finally block is executed just before actually returning or raising the exception.  (what you could have controlled yourself by simply running the code in your question)  The only case I can imagine where the finally block will not be executed is when the Python interpretor itself crashes for example inside C code or because of power outage.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception-handling",
            "try-catch-finally",
            "finally"
        ],
        "URL": "https://stackoverflow.com/questions/49262379/does-finally-always-execute-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For any possible try-finally block in Python, is it guaranteed that the finally block will always be executed?  For example, let’s say I return while in an except block:  try:     1/0 except ZeroDivisionError:     return finally:     print(\"Does this code run?\")   Or maybe I re-raise an Exception:  try:     1/0 except ZeroDivisionError:     raise finally:     print(\"What about this code?\")   Testing shows that finally does get executed for the above examples, but I imagine there are other scenarios I haven't thought of.  Are there any scenarios in which a finally block can fail to execute in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Flask-SQLAlchemy import/context issue",
        "A_Content": "  The flask_sqlalchemy module does not have to be initialized with the app right away - you can do this instead:  # apps.members.models from flask_sqlalchemy import SQLAlchemy  db = SQLAlchemy()  class Member(db.Model):     # fields here     pass   And then in your application setup you can call init_app:  # apps.application.py from flask import Flask from apps.members.models import db  app = Flask(__name__) # later on db.init_app(app)   This way you can avoid cyclical imports.  This pattern does not necessitate the you place all of your models in one file.  Simply import the db variable into each of your model modules.  Example  # apps.shared.models from flask_sqlalchemy import SQLAlchemy  db = SQLAlchemy()     # apps.members.models from apps.shared.models import db  class Member(db.Model):     # TODO: Implement this.     pass     # apps.reporting.members from flask import render_template from apps.members.models import Member  def report_on_members():     # TODO: Actually use arguments     members = Member.filter(1==1).all()     return render_template(\"report.html\", members=members)     # apps.reporting.routes from flask import Blueprint from apps.reporting.members import report_on_members  reporting = Blueprint(\"reporting\", __name__)  reporting.route(\"/member-report\", methods=[\"GET\",\"POST\"])(report_on_members)     # apps.application from flask import Flask from apps.shared import db from apps.reporting.routes import reporting  app = Flask(__name__) db.init_app(app) app.register_blueprint(reporting)   Note: this is a sketch of some of the power this gives you - there is obviously quite a bit more that you can do to make development even easier (using a create_app pattern, auto-registering blueprints in certain folders, etc.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/9692962/flask-sqlalchemy-import-context-issue",
        "A_Votes": "207",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to structure my Flask app something like:  ./site.py ./apps/members/__init__.py ./apps/members/models.py   apps.members is a Flask Blueprint.  Now, in order to create the model classes I need to have a hold of the app, something like:  # apps.members.models from flask import current_app from flaskext.sqlalchemy import SQLAlchemy  db = SQLAlchemy(current_app)  class Member(db.Model):     # fields here     pass   But if I try and import that model into my Blueprint app, I get the dreaded RuntimeError: working outside of request context. How can I get a hold of my app correctly here? Relative imports might work but they're pretty ugly and have their own context issues, e.g:  from ...site import app  # ValueError: Attempted relative import beyond toplevel package      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Flask-SQLAlchemy import/context issue",
        "A_Content": "  an original app.py: http://pythonhosted.org/Flask-SQLAlchemy/quickstart.html#quickstart  ...  app = flask.Flask(__name__) app.config['DEBUG'] = True app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:////tmp/test.db' db = flask.ext.sqlalchemy.SQLAlchemy(app)  class Person(db.Model):     id = db.Column(db.Integer, primary_key=True) ...  class Computer(db.Model):     id = db.Column(db.Integer, primary_key=True) ...  # Create the database tables. db.create_all()  ...  # start the flask loop app.run()   I just splitted one app.py to app.py and model.py without using Blueprint. In that case, the above answer dosen't work. A line code is needed to work.  before:  db.init_app(app)   after:  db.app = app db.init_app(app)   And, the following link is very useful.  http://piotr.banaszkiewicz.org/blog/2012/06/29/flask-sqlalchemy-init_app/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/9692962/flask-sqlalchemy-import-context-issue",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to structure my Flask app something like:  ./site.py ./apps/members/__init__.py ./apps/members/models.py   apps.members is a Flask Blueprint.  Now, in order to create the model classes I need to have a hold of the app, something like:  # apps.members.models from flask import current_app from flaskext.sqlalchemy import SQLAlchemy  db = SQLAlchemy(current_app)  class Member(db.Model):     # fields here     pass   But if I try and import that model into my Blueprint app, I get the dreaded RuntimeError: working outside of request context. How can I get a hold of my app correctly here? Relative imports might work but they're pretty ugly and have their own context issues, e.g:  from ...site import app  # ValueError: Attempted relative import beyond toplevel package      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to get the first column of a pandas DataFrame as a Series?",
        "A_Content": "  >>> import pandas as pd >>> df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]}) >>> df    x  y 0  1  4 1  2  5 2  3  6 3  4  7 >>> s = df.ix[:,0] >>> type(s) <class 'pandas.core.series.Series'> >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dataframe",
            "pandas",
            "series"
        ],
        "URL": "https://stackoverflow.com/questions/15360925/how-to-get-the-first-column-of-a-pandas-dataframe-as-a-series",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I tried:  x=pandas.DataFrame(...) s = x.take([0], axis=1)   And s gets a DataFrame, not a Series.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to get the first column of a pandas DataFrame as a Series?",
        "A_Content": "  You can get the first column as a Series by following code:  x[x.columns[0]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dataframe",
            "pandas",
            "series"
        ],
        "URL": "https://stackoverflow.com/questions/15360925/how-to-get-the-first-column-of-a-pandas-dataframe-as-a-series",
        "A_Votes": "70",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I tried:  x=pandas.DataFrame(...) s = x.take([0], axis=1)   And s gets a DataFrame, not a Series.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to get the first column of a pandas DataFrame as a Series?",
        "A_Content": "  in 0.11  In [7]: df.iloc[:,0] Out[7]:  0    1 1    2 2    3 3    4 Name: x, dtype: int64      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dataframe",
            "pandas",
            "series"
        ],
        "URL": "https://stackoverflow.com/questions/15360925/how-to-get-the-first-column-of-a-pandas-dataframe-as-a-series",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I tried:  x=pandas.DataFrame(...) s = x.take([0], axis=1)   And s gets a DataFrame, not a Series.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to get the first column of a pandas DataFrame as a Series?",
        "A_Content": "  Isn't this the simplest way?  By column name:  In [20]: df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]}) In [21]: df Out[21]:     x   y 0   1   4 1   2   5 2   3   6 3   4   7  In [23]: df.x Out[23]: 0    1 1    2 2    3 3    4 Name: x, dtype: int64  In [24]: type(df.x) Out[24]: pandas.core.series.Series      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dataframe",
            "pandas",
            "series"
        ],
        "URL": "https://stackoverflow.com/questions/15360925/how-to-get-the-first-column-of-a-pandas-dataframe-as-a-series",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I tried:  x=pandas.DataFrame(...) s = x.take([0], axis=1)   And s gets a DataFrame, not a Series.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to get the first column of a pandas DataFrame as a Series?",
        "A_Content": "  This works great when you want to load a series from a csv file  x = pd.read_csv('x.csv', index_col=False, names=['x'],header=None).iloc[:,0] print(type(x)) print(x.head(10))   <class 'pandas.core.series.Series'> 0    110.96 1    119.40 2    135.89 3    152.32 4    192.91 5    177.20 6    181.16 7    177.30 8    200.13 9    235.41 Name: x, dtype: float64      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dataframe",
            "pandas",
            "series"
        ],
        "URL": "https://stackoverflow.com/questions/15360925/how-to-get-the-first-column-of-a-pandas-dataframe-as-a-series",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I tried:  x=pandas.DataFrame(...) s = x.take([0], axis=1)   And s gets a DataFrame, not a Series.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  One way is to use the carriage return ('\\r') character to return to the start of the line without advancing to the next line:  for x in range(10):     print '{0}\\r'.format(x), print   The comma at the end of the print statement tells it not to go to the next line. The last print statement advances to the next line so your prompt won't overwrite your final output.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "95",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  Since I ended up here via Google but am using Python 3, here's how this would work in Python 3:  for x in range(10):     print(\"Progress {:2.1%}\".format(x / 10), end=\"\\r\")   Related answer here: How can I suppress the newline after a print statement?     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  @Mike DeSimone answer will probably work most of the time. But...  for x in ['abc', 1]:     print '{}\\r'.format(x),  -> 1bc   This is because the '\\r' only goes back to the beginning of the line but doesn't clear the output.  EDIT: Better solution (than my old proposal below)  If POSIX support is enough for you, the following would clear the current line and leave the cursor at its beginning:  print '\\x1b[2K\\r',   It uses ANSI escape code to clear the terminal line. More info can be found in wikipedia and in this great talk.  Old answer  The (not so good) solution I've found looks like this:  last_x = '' for x in ['abc', 1]:     print ' ' * len(str(last_x)) + '\\r',     print '{}\\r'.format(x),     last_x = x  -> 1   One advantage is that it will work on windows too.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  I had the same question before visiting this thread. For me the sys.stdout.write worked only if I properly flush the buffer i.e.  for x in range(10):     sys.stdout.write('\\r'+str(x))     sys.stdout.flush()   Without flushing, the result is printed only at the end out the script     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  Suppress the newline and print \\r.  print 1, print '\\r2'   or write to stdout:  sys.stdout.write('1') sys.stdout.write('\\r2')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  I couldn't get any of the solutions on this page to work for IPython, but a slight variation on @Mike-Desimone's solution did the job: instead of terminating the line with the carriage return, start the line with the carriage return:  for x in range(10):     print '\\r{0}'.format(x),   Additionally, this approach doesn't require the second print statement.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  Try this:  import time while True:     print(\"Hi \", end=\"\\r\")     time.sleep(1)     print(\"Bob\", end=\"\\r\")     time.sleep(1)   It worked for me. The  end=\"\\r\" part is making it overwrite the previous line.  WARNING!  If you print out hi, then print out hello using \\r, you’ll get hillo because the output wrote over the previous two letters. If you print out hi with spaces (which don’t show up here), then it will output hi. To fix this, print out spaces using \\r.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  I have used the following to create a loader:  for i in range(10):     print(i*'.', end='\\r')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  This works on Windows and python 3.6  import time for x in range(10):     time.sleep(0.5)     print(str(x)+'\\r',end='')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  A cleaner, more \"plug-and-play\", version to @Nagasaki45's answer:  def print_statusline(msg: str):     last_msg_length = len(print_statusline.last_msg) if hasattr(print_statusline, 'last_msg') else 0     print(' ' * last_msg_length, end='\\r')     print(msg, end='\\r')     sys.stdout.flush()  # Some say they needed this, I didn't.     print_statusline.last_msg = msg  # Then simply use like this: for msg in [\"Initializing...\", \"Initialization successful!\"]:     print_statusline(msg)     time.sleep(1)  # If you want to check that the line gets cleared properly: for i in range(9, 0, -1):     print_statusline(\"{}\".format(i) * i)     time.sleep(0.5)   Works properly with strings of different lengths as it clears the line with spaces, unlike many other answers here. Will also work on Windows.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  I'm a bit surprised nobody is using the backspace character. Here's one that uses it.  import sys import time  secs = 1000  while True:     time.sleep(1)  #wait for a full second to pass before assigning a second     secs += 1  #acknowledge a second has passed      sys.stdout.write(str(secs))      for i in range(len(str(secs))):         sys.stdout.write('\\b')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  for x in range(10):     time.sleep(0.5) # shows how its working     print(\"\\r {}\".format(x), end=\"\")   time.sleep(0.5) is to show how previous output is erased and new output is printed  \"\\r\" when its at the start of print message , it gonna erase previous output before  new output.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  The accepted answer is not perfect. The line that was printed first will stay there and if your second print does not cover the entire new line, you will end up with garbage text.   To illustrate the problem save this code as a script and run it (or just take a look):  import time  n = 100 for i in range(100):     for j in range(100):         print(\"Progress {:2.1%}\".format(j / 100), end=\"\\r\")         time.sleep(0.01)     print(\"Progress {:2.1%}\".format(i / 100))   The output will look something like this:  Progress 0.0%% Progress 1.0%% Progress 2.0%% Progress 3.0%%   What works for me is to clear the line before leaving a permanent print. Feel free to adjust to your specific problem:  import time  ERASE_LINE = '\\x1b[2K' # erase line command n = 100 for i in range(100):     for j in range(100):         print(\"Progress {:2.1%}\".format(j / 100), end=\"\\r\")         time.sleep(0.01)     print(ERASE_LINE + \"Progress {:2.1%}\".format(i / 100)) # clear the line first   And now it prints as expected:  Progress 0.0% Progress 1.0% Progress 2.0% Progress 3.0%      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to overwrite the previous print to stdout in python?",
        "A_Content": "  Here a simple code which can be useful for you !  import sys import time  for i in range(10):     sys.stdout.write(\"\\r\" + i)     sys.stdout.flush()     time.sleep(1)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5419389/how-to-overwrite-the-previous-print-to-stdout-in-python",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I had the following code:  for x in range(10):      print x   I would get the output of  1 2 etc..   What I would like to do is instead of printing a newline, I want to replace the previous value and overwrite it with the new value on the same line.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Django equivalent for count and group by",
        "A_Content": "  Here, as I just discovered, is how to do this with the Django 1.1 aggregation API:  from django.db.models import Count theanswer = Item.objects.values('category').annotate(Count('category'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/327807/django-equivalent-for-count-and-group-by",
        "A_Votes": "126",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a model that looks like this:  class Category(models.Model):     name = models.CharField(max_length=60)  class Item(models.Model):     name = models.CharField(max_length=60)     category = models.ForeignKey(Category)   I want select count (just the count) of items for each category, so in SQL it would be as simple as this:  select category_id, count(id) from item group by category_id   Is there an equivalent of doing this \"the Django way\"? Or is plain SQL the only option? I am familiar with the count( ) method in Django, however I don't see how group by would fit there.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Django equivalent for count and group by",
        "A_Content": "  (Update: Full ORM aggregation support is now included in Django 1.1. True to the below warning about using private APIs, the method documented here no longer works in post-1.1 versions of Django.  I haven't dug in to figure out why; if you're on 1.1 or later you should use the real aggregation API anyway.)  The core aggregation support was already there in 1.0; it's just undocumented, unsupported, and doesn't have a friendly API on top of it yet.  But here's how you can use it anyway until 1.1 arrives (at your own risk, and in full knowledge that the query.group_by attribute is not part of a public API and could change):  query_set = Item.objects.extra(select={'count': 'count(1)'},                                 order_by=['-count']).values('count', 'category') query_set.query.group_by = ['category_id']   If you then iterate over query_set, each returned value will be a dictionary with a \"category\" key and a \"count\" key.  You don't have to order by -count here, that's just included to demonstrate how it's done (it has to be done in the .extra() call, not elsewhere in the queryset construction chain).  Also, you could just as well say count(id) instead of count(1), but the latter may be more efficient.  Note also that when setting .query.group_by, the values must be actual DB column names ('category_id') not Django field names ('category').  This is because you're tweaking the query internals at a level where everything's in DB terms, not Django terms.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/327807/django-equivalent-for-count-and-group-by",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a model that looks like this:  class Category(models.Model):     name = models.CharField(max_length=60)  class Item(models.Model):     name = models.CharField(max_length=60)     category = models.ForeignKey(Category)   I want select count (just the count) of items for each category, so in SQL it would be as simple as this:  select category_id, count(id) from item group by category_id   Is there an equivalent of doing this \"the Django way\"? Or is plain SQL the only option? I am familiar with the count( ) method in Django, however I don't see how group by would fit there.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Django equivalent for count and group by",
        "A_Content": "  Since I was a little confused about how grouping in Django 1.1 works I thought I'd elaborate here on how exactly you go about using it. First, to repeat what Michael said:     Here, as I just discovered, is how to do this with the Django 1.1 aggregation API:  from django.db.models import Count theanswer = Item.objects.values('category').annotate(Count('category'))    Note also that you need to from django.db.models import Count!  This will select only the categories and then add an annotation called category__count. Depending on the default ordering this may be all you need, but if the default ordering uses a field other than category this will not work. The reason for this is that the fields required for ordering are also selected and make each row unique, so you won't get stuff grouped how you want it. One quick way to fix this is to reset the ordering:  Item.objects.values('category').annotate(Count('category')).order_by()   This should produce exactly the results you want. To set the name of the annotation you can use:  ...annotate(mycount = Count('category'))...   Then you will have an annotation called mycount in the results.  Everything else about grouping was very straightforward to me. Be sure to check out the Django aggregation API for more detailed info.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/327807/django-equivalent-for-count-and-group-by",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a model that looks like this:  class Category(models.Model):     name = models.CharField(max_length=60)  class Item(models.Model):     name = models.CharField(max_length=60)     category = models.ForeignKey(Category)   I want select count (just the count) of items for each category, so in SQL it would be as simple as this:  select category_id, count(id) from item group by category_id   Is there an equivalent of doing this \"the Django way\"? Or is plain SQL the only option? I am familiar with the count( ) method in Django, however I don't see how group by would fit there.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Django equivalent for count and group by",
        "A_Content": "  How's this?  (Other than slow.)  counts= [ (c, Item.filter( category=c.id ).count()) for c in Category.objects.all() ]   It has the advantage of being short, even if it does fetch a lot of rows.    Edit.  The one query version.  BTW, this is often faster than SELECT COUNT(*) in the database.  Try it to see.  counts = defaultdict(int) for i in Item.objects.all():     counts[i.category] += 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/327807/django-equivalent-for-count-and-group-by",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a model that looks like this:  class Category(models.Model):     name = models.CharField(max_length=60)  class Item(models.Model):     name = models.CharField(max_length=60)     category = models.ForeignKey(Category)   I want select count (just the count) of items for each category, so in SQL it would be as simple as this:  select category_id, count(id) from item group by category_id   Is there an equivalent of doing this \"the Django way\"? Or is plain SQL the only option? I am familiar with the count( ) method in Django, however I don't see how group by would fit there.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  The best way is to set static_url_path to root url  from flask import Flask  app = Flask(__name__, static_folder='static', static_url_path='')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  @vonPetrushev is right, in production you'll want to serve static files via nginx or apache, but for development it's nice to have your dev environment simple having your python app serving up the static content as well so you don't have to worry about changing configurations and multiple projects. To do that, you'll want to use the SharedDataMiddleware.  from flask import Flask app = Flask(__name__) ''' Your app setup and code ''' if app.config['DEBUG']:     from werkzeug import SharedDataMiddleware     import os     app.wsgi_app = SharedDataMiddleware(app.wsgi_app, {       '/': os.path.join(os.path.dirname(__file__), 'static')     })   This example assumes your static files are in the folder \"static\", adjust to whatever fits your environment.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  The cleanest answer to this question is the answer to this (identical) question:  from flask import Flask, request, send_from_directory app = Flask(__name__, static_folder='static')      @app.route('/robots.txt') @app.route('/sitemap.xml') def static_from_root():     return send_from_directory(app.static_folder, request.path[1:])   To summarize:   as David pointed out, with the right config it's ok to serve a few static files through prod looking for /robots.txt shouldn't result in a redirect to /static/robots.txt. (In Seans answer it's not immediately clear how that's achieved.) it's not clean to add static files into the app root folder finally, the proposed solution looks much cleaner than the adding middleware approach:      ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "54",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  Even though this is an old answered question, I'm answering this because this post comes up pretty high in the Google results.  While it's not covered in the documentation, if you read the API docs for the Flask Application object constructor it's covered. By passing the named parameter static_folder like so:  from flask import Flask app = Flask(__name__,             static_folder=\"/path/to/static\",             template_folder=\"/path/to/templates\")   ...you can define where static files are served from.  Similarly, you can define a template_folder, the name of you static_url_path.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  Serving static files has nothing to do with application that is meant to deliver dynamic content. The correct way of serving static files is dependent of what server you're using. After all, when you get your app up and running, you will need to bind it to a web server. I can speak only for apache httpd, so the way of serving static files is defined in the virtual host that you are binding to your application through mod-wsgi. Here is the guide that will show you how to serve sitemaps, robots.txt or any static content: http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide#Mounting_At_Root_Of_Site     ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  Another way to send static files is to use a catch-all rule like this:  @app.route('/<path:path>') def catch_all(path):     if not app.debug:         flask.abort(404)     try:         f = open(path)     except IOError, e:         flask.abort(404)         return     return f.read()   I use this to try to minimise the set-up when developing.  I got the idea from http://flask.pocoo.org/snippets/57/  Further, I'm developing using flask on my standalone machine but deploying with Apache in production server.  I use:  file_suffix_to_mimetype = {     '.css': 'text/css',     '.jpg': 'image/jpeg',     '.html': 'text/html',     '.ico': 'image/x-icon',     '.png': 'image/png',     '.js': 'application/javascript' } def static_file(path):     try:         f = open(path)     except IOError, e:         flask.abort(404)         return     root, ext = os.path.splitext(path)     if ext in file_suffix_to_mimetype:         return flask.Response(f.read(), mimetype=file_suffix_to_mimetype[ext])     return f.read()  [...]  if __name__ == '__main__':     parser = optparse.OptionParser()     parser.add_option('-d', '--debug', dest='debug', default=False,                       help='turn on Flask debugging', action='store_true')      options, args = parser.parse_args()      if options.debug:         app.debug = True         # set up flask to serve static content         app.add_url_rule('/<path:path>', 'static_file', static_file)     app.run()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  This might have been added since this question was asked, but I was looking through flask's \"helpers.py\" and I found flask.send_from_directory:  send_from_directory(directory, filename, **options) '''   send_from_directory(directory, filename, **options)   Send a file from a given directory with send_file.  This   is a secure way to quickly expose static files from an upload folder   or something similar. '''   ... which references flask.send_file:  send_file(filename_or_fp, mimetype=None, as_attachment=False, attachment_filename=None, add_etags=True, cache_timeout=43200, conditional=False)   ... which seems better for more control, although send_from_directory passes **options directly through to send_file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  From the documentation here: http://flask.pocoo.org/docs/quickstart/#static-files     Dynamic web applications need static   files as well. That’s usually where   the CSS and JavaScript files are   coming from. Ideally your web server   is configured to serve them for you,   but during development Flask can do   that as well. Just create a folder   called static in your package or next   to your module and it will be   available at /static on the   application.      To generate URLs to that part of the   URL, use the special 'static' URL   name:      url_for('static',   filename='style.css')      The file has to be stored on the   filesystem as static/style.css.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Static files in Flask - robot.txt, sitemap.xml (mod_wsgi)",
        "A_Content": "  I'm having the same dilemma as well. Did some search and found my answer(MHO):  Might as well quote from the documentation     Dynamic web applications need static files as well. That’s usually where the CSS and JavaScript files are coming from. Ideally your web server is configured to serve them for you, but during development Flask can do that as well. Just create a folder called static in your package or next to your module and it will be available at /static on the application.   IMHO: When your application is up for production, static file serving should be (or is ideally) configured on the webserver (nginx, apache); but during development, Flask made it available to serve static files. This is to help you develop rapidly - no need to setup webservers and such.   Hope it helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "static",
            "mod-wsgi",
            "flask",
            "robot"
        ],
        "URL": "https://stackoverflow.com/questions/4239825/static-files-in-flask-robot-txt-sitemap-xml-mod-wsgi",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any clever solution to store static files in Flask's application root directory. robots.txt and sitemap.xml are expected to be found in /, so my idea was to create routes for them:  @app.route('/sitemap.xml', methods=['GET']) def sitemap():   response = make_response(open('sitemap.xml').read())   response.headers[\"Content-type\"] = \"text/plain\"   return response   There must be something more convenient :)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Applying function with multiple arguments to create a new pandas column",
        "A_Content": "  Alternatively, you can use numpy underlying function:  >>> import numpy as np >>> df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]}) >>> df['new_column'] = np.multiply(df['A'], df['B']) >>> df     A   B  new_column 0  10  20         200 1  20  30         600 2  30  10         300   or vectorize arbitrary function in general case:  >>> def fx(x, y): ...     return x*y ... >>> df['new_column'] = np.vectorize(fx)(df['A'], df['B']) >>> df     A   B  new_column 0  10  20         200 1  20  30         600 2  30  10         300      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to create a new column in a pandas data frame by applying a function to two existing columns. Following this answer I've been able to create a new column when I only need one column as an argument:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  def fx(x):     return x * x  print(df) df['newcolumn'] = df.A.apply(fx) print(df)   However, I cannot figure out how to do the same thing when the function requires multiple arguments. For example, how do I create a new column by passing column A and column B to the function below?  def fxy(x, y):     return x * y      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Applying function with multiple arguments to create a new pandas column",
        "A_Content": "  You can go with @greenAfrican example, if it's possible for you to rewrite your function. But if you don't want to rewrite your function, you can wrap it into anonymous function inside apply, like this:  >>> def fxy(x, y): ...     return x * y  >>> df['newcolumn'] = df.apply(lambda x: fxy(x['A'], x['B']), axis=1) >>> df     A   B  newcolumn 0  10  20        200 1  20  30        600 2  30  10        300      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column",
        "A_Votes": "124",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a new column in a pandas data frame by applying a function to two existing columns. Following this answer I've been able to create a new column when I only need one column as an argument:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  def fx(x):     return x * x  print(df) df['newcolumn'] = df.A.apply(fx) print(df)   However, I cannot figure out how to do the same thing when the function requires multiple arguments. For example, how do I create a new column by passing column A and column B to the function below?  def fxy(x, y):     return x * y      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Applying function with multiple arguments to create a new pandas column",
        "A_Content": "  This solves the problem:  df['newcolumn'] = df.A * df.B   You could also do:  def fab(row):   return row['A'] * row['B']  df['newcolumn'] = df.apply(fab, axis=1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a new column in a pandas data frame by applying a function to two existing columns. Following this answer I've been able to create a new column when I only need one column as an argument:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  def fx(x):     return x * x  print(df) df['newcolumn'] = df.A.apply(fx) print(df)   However, I cannot figure out how to do the same thing when the function requires multiple arguments. For example, how do I create a new column by passing column A and column B to the function below?  def fxy(x, y):     return x * y      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Applying function with multiple arguments to create a new pandas column",
        "A_Content": "  If you need to create multiple columns at once:   Create the dataframe:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  Create the function:  def fab(row):                                                       return row['A'] * row['B'], row['A'] + row['B']  Assign the new columns:  df['newcolumn'], df['newcolumn2'] = zip(*df.apply(fab, axis=1))       ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a new column in a pandas data frame by applying a function to two existing columns. Following this answer I've been able to create a new column when I only need one column as an argument:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  def fx(x):     return x * x  print(df) df['newcolumn'] = df.A.apply(fx) print(df)   However, I cannot figure out how to do the same thing when the function requires multiple arguments. For example, how do I create a new column by passing column A and column B to the function below?  def fxy(x, y):     return x * y      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Applying function with multiple arguments to create a new pandas column",
        "A_Content": "  One more dict style clean syntax:  df[\"new_column\"] = df.apply(lambda x: x[\"A\"] * x[\"B\"], axis = 1)   or,  df[\"new_column\"] = df[\"A\"] * df[\"B\"]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to create a new column in a pandas data frame by applying a function to two existing columns. Following this answer I've been able to create a new column when I only need one column as an argument:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})  def fx(x):     return x * x  print(df) df['newcolumn'] = df.A.apply(fx) print(df)   However, I cannot figure out how to do the same thing when the function requires multiple arguments. For example, how do I create a new column by passing column A and column B to the function below?  def fxy(x, y):     return x * y      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  I would like to note that previous answers made many assumptions about the user's knowledge. This answer attempts to answer the question at a more tutorial level.  For every invocation of Python, sys.argv is automatically a list of strings representing the arguments (as separated by spaces) on the command-line. The name comes from the C programming convention in which argv and argc represent the command line arguments.  You'll want to learn more about lists and strings as you're familiarizing yourself with Python, but in the meantime, here are a few things to know.  You can simply create a script that prints the arguments as they're represented. It also prints the number of arguments, using the len function on the list.  from __future__ import print_function import sys print(sys.argv, len(sys.argv))   The script requires Python 2.6 or later. If you call this script print_args.py, you can invoke it with different arguments to see what happens.  > python print_args.py ['print_args.py'] 1  > python print_args.py foo and bar ['print_args.py', 'foo', 'and', 'bar'] 4  > python print_args.py \"foo and bar\" ['print_args.py', 'foo and bar'] 2  > python print_args.py \"foo and bar\" and baz ['print_args.py', 'foo and bar', 'and', 'baz'] 4   As you can see, the command-line arguments include the script name but not the interpreter name. In this sense, Python treats the script as the executable. If you need to know the name of the executable (python in this case), you can use sys.executable.  You can see from the examples that it is possible to receive arguments that do contain spaces if the user invoked the script with arguments encapsulated in quotes, so what you get is the list of arguments as supplied by the user.  Now in your Python code, you can use this list of strings as input to your program. Since lists are indexed by zero-based integers, you can get the individual items using the list[0] syntax. For example, to get the script name:  script_name = sys.argv[0] # this will always work.   Although interesting, you rarely need to know your script name. To get the first argument after the script for a filename, you could do the following:  filename = sys.argv[1]   This is a very common usage, but note that it will fail with an IndexError if no argument was supplied.  Also, Python lets you reference a slice of a list, so to get another list of just the user-supplied arguments (but without the script name), you can do  user_args = sys.argv[1:] # get everything after the script name   Additionally, Python allows you to assign a sequence of items (including lists) to variable names. So if you expect the user to always supply two arguments, you can assign those arguments (as strings) to two variables:  user_args = sys.argv[1:] fun, games = user_args # len(user_args) had better be 2   So, to answer your specific question, sys.argv[1] represents the first command-line argument (as a string) supplied to the script in question. It will not prompt for input, but it will fail with an IndexError if no arguments are supplied on the command-line following the script name.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "239",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  sys.argv[1] contains the first command line argument passed to your script.  For example, if your script is named hello.py and you issue:  $ python3.1 hello.py foo  or:  $ chmod +x hello.py  # make script executable $ ./hello.py foo   Your script will print:  Hello there foo     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  sys.argv is a list.  This list is created by your command line, it's a list of your command line arguments.  For example:  in your command line you input something like this,  python3.2 file.py something   sys.argv will become a list ['file.py', 'something']  In this case sys.argv[1] = 'something'     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  Just adding to Frederic's answer, for example if you call your script as follows:   ./myscript.py foo bar   sys.argv[0] would be \"./myscript.py\"  sys.argv[1] would be \"foo\" and sys.argv[2] would be \"bar\" ... and so forth.  In your example code, if you call the script as follows  ./myscript.py foo  , the script's output will be \"Hello there foo\".     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  Adding a few more points to Jason's Answer :   For taking all user provided arguments :  user_args = sys.argv[1:]  Consider the sys.argv as a list of strings as (mentioned by Jason). So all the list manipulations will apply here. This is called \"List Slicing\". For more info visit here.  The syntax is like this : list[start:end:step]. If you omit start, it will default to 0, and if you omit end, it will default to length of list.  Suppose you only want to take all the arguments after 3rd argument, then :   user_args = sys.argv[3:]   Suppose you only want the first two arguments, then :   user_args = sys.argv[0:2]  or  user_args = sys.argv[:2]   Suppose you want arguments 2 to 4 :  user_args = sys.argv[2:4]   Suppose you want the last argument (last argument is always -1, so what is happening here is we start the count from back. So start is last, no end, no step) :  user_args = sys.argv[-1]   Suppose you want the second last argument :  user_args = sys.argv[-2]   Suppose you want the last two arguments :  user_args = sys.argv[-2:]   Suppose you want the last two arguments. Here, start is -2, that is second last item and then to the end (denoted by \":\") :  user_args = sys.argv[-2:]   Suppose you want the everything except last two arguments. Here, start is 0 (by default),  and end is second last item :  user_args = sys.argv[:-2]   Suppose you want the arguments in reverse order :  user_args = sys.argv[::-1]   Hope this helps.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  sys.argv is a list containing the script path and command line arguments; i.e. sys.argv[0] is the path of the script you're running and all following members are arguments.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  To pass arguments to your python script  while running a script via command line          python create_thumbnail.py test1.jpg test2.jpg      here, script name - create_thumbnail.py, argument 1 - test1.jpg, argument 2 - test2.jpg  With in the create_thumbnail.py script i use  sys.argv[1:]   which give me the list of arguments i passed in command line as  ['test1.jpg', 'test2.jpg']     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "sys.argv[1] meaning in script",
        "A_Content": "  sys .argv will display the command line args passed when running a script or you can say sys.argv will store the command line arguments passed in python while running from terminal.   Just try this:   import sys print sys.argv   argv stores all the arguments passed in a python list. The above will print all arguments passed will running the script.  Now try this running your filename.py like this:  python filename.py example example1   this will print 3 arguments in a list.  sys.argv[0] #is the first argument passed, which is basically the filename.    Similarly, argv1 is the first argument passed, in this case 'example'  A similar question has been asked already here btw. Hope this helps!       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently teaching myself Python and was just wondering (In reference to my example below) in simplified terms what the sys.argv[1] represents. Is it simply asking for an input?  #!/usr/bin/python3.1  # import modules used here -- sys is a very standard one import sys  # Gather our code in a main() function def main():   print ('Hello there', sys.argv[1])   # Command line args are in sys.argv[1], sys.argv[2] ..   # sys.argv[0] is the script name itself and can be ignored  # Standard boilerplate to call the main() function to begin # the program. if __name__ == '__main__':   main()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  Suppose len(list1) >= len(list2). Then what you appear to want is to take all permutations of length len(list2) from list1 and match them with items from list2. In python:  import itertools list1=['a','b','c'] list2=[1,2]  [zip(x,list2) for x in itertools.permutations(list1,len(list2))]   Returns  [[('a', 1), ('b', 2)], [('a', 1), ('c', 2)], [('b', 1), ('a', 2)], [('b', 1), ('c', 2)], [('c', 1), ('a', 2)], [('c', 1), ('b', 2)]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  The simplest way is to use itertools.product:  a = [\"foo\", \"melon\"] b = [True, False] c = list(itertools.product(a, b)) >> [(\"foo\", True), (\"foo\", False), (\"melon\", True), (\"melon\", False)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "297",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  May be simpler than the simplest one above:  >>> a = [\"foo\", \"bar\"] >>> b = [1, 2, 3] >>> [(x,y) for x in a for y in b] [('foo', 1), ('foo', 2), ('foo', 3), ('bar', 1), ('bar', 2), ('bar', 3)]   without any import      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "51",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  You might want to try a one line list comprehension:  >>> [name+number for name in 'ab' for number in '12'] ['a1', 'a2', 'b1', 'b2'] >>> [name+number for name in 'abc' for number in '12'] ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  a tiny improvement for the answer from interjay, to make the result as a flatten list.  >>> list3 = [zip(x,list2) for x in itertools.permutations(list1,len(list2))] >>> import itertools >>> chain = itertools.chain(*list3) >>> list4 = list(chain) [('a', 1), ('b', 2), ('a', 1), ('c', 2), ('b', 1), ('a', 2), ('b', 1), ('c', 2), ('c', 1), ('a', 2), ('c', 1), ('b', 2)]   reference from this link     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  I was looking for a list multiplied by itself with only unique combinations, which is provided as this function.  import itertools itertools.combinations(list, n_times)     Here as an excerpt from the Python docs on  itertools That might help you find what your looking for.  Combinatoric generators:  Iterator                                 | Results -----------------------------------------+---------------------------------------- product(p, q, ... [repeat=1])            | cartesian product, equivalent to a                                           |   nested for-loop -----------------------------------------+---------------------------------------- permutations(p[, r])                     | r-length tuples, all possible                                           |   orderings, no repeated elements -----------------------------------------+---------------------------------------- combinations(p, r)                       | r-length tuples, in sorted order, no                                           |   repeated elements -----------------------------------------+---------------------------------------- combinations_with_replacement(p, r)      | r-length tuples, in sorted order,                                           | with repeated elements -----------------------------------------+---------------------------------------- product('ABCD', repeat=2)                | AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD permutations('ABCD', 2)                  | AB AC AD BA BC BD CA CB CD DA DB DC combinations('ABCD', 2)                  | AB AC AD BC BD CD combinations_with_replacement('ABCD', 2) | AA AB AC AD BB BC BD CC CD DD      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  Without itertools   [(list1[i], list2[j]) for i in xrange(len(list1)) for j in xrange(len(list2))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "combinations between two lists?",
        "A_Content": "  Answering the question \"given two lists, find all possible permutations of pairs of one item from each list\" and using basic Python functionality (i.e., without itertools) and, hence, making it easy to replicate for other programming languages:  def rec(a, b, ll, size):     ret = []     for i,e in enumerate(a):         for j,f in enumerate(b):             l = [e+f]             new_l = rec(a[i+1:], b[:j]+b[j+1:], ll, size)             if not new_l:                 ret.append(l)             for k in new_l:                 l_k = l + k                 ret.append(l_k)                 if len(l_k) == size:                     ll.append(l_k)     return ret  a = ['a','b','c'] b = ['1','2'] ll = [] rec(a,b,ll, min(len(a),len(b))) print(ll)   Returns  [['a1', 'b2'], ['a1', 'c2'], ['a2', 'b1'], ['a2', 'c1'], ['b1', 'c2'], ['b2', 'c1']]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm"
        ],
        "URL": "https://stackoverflow.com/questions/12935194/combinations-between-two-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It’s been a while and I’m having trouble wrapping my head around a algorithm I’m try to make.  Basically, I have two lists and want to get all the combinations of the two lists.  I might not be explaining it correct so here’s a example.  name = 'a', 'b' number = 1, 2   the output in this case would be:  1.  A1 B2 2.  B1 A2   The tricky part is I might have more items in the “name” variable than items in the “number” variable(number will always be equal to or less than the name variable).  I’m confused how to do all the combinations (nested for loop?) and even more confused on the logic to shift the items in the name variable in the event that there are more items in name than they are in the number list.  I’m not the best programmer but think I can give it a shot if someone can help me clarify the logic/algoriythm to achieve this. So I have just been stuck on nested for loops.  Update:  Here's the output with 3 variables and 2 numbers:  name = 'a', 'b', 'c' number = 1, 2   output:  1.  A1 B2 2.  B1 A2 3.  A1 C2 4.  C1 A2 5.  B1 C2 6.  C1 B2      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  An easy way to parse (and validate) URL's is the urlparse (py2, py3) module.    A regex is too much work.    There's no \"validate\" method because almost anything is a valid URL.  There are some punctuation rules for splitting it up.  Absent any punctuation, you still have a valid URL.  Check the RFC carefully and see if you can construct an \"invalid\" URL.  The rules are very flexible.    For example ::::: is a valid URL.  The path is \":::::\".  A pretty stupid filename, but a valid filename.  Also, ///// is a valid URL.  The netloc (\"hostname\") is \"\".  The path is \"///\".  Again, stupid.  Also valid.  This URL normalizes to \"///\" which is the equivalent.  Something like \"bad://///worse/////\" is perfectly valid.  Dumb but valid.  Bottom Line.  Parse it, and look at the pieces to see if they're displeasing in some way.    Do you want the scheme to always be \"http\"?  Do you want the netloc to always be \"www.somename.somedomain\"?  Do you want the path to look unix-like?  Or windows-like?  Do you want to remove the query string?  Or preserve it?  These are not RFC-specified validations.  These are validations unique to your application.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "137",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  Here's the complete regexp to parse a URL.  (?:http://(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\. )*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+) ){3}))(?::(?:\\d+))?)(?:/(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F \\d]{2}))|[;:@&=])*)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{ 2}))|[;:@&=])*))*)(?:\\?(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{ 2}))|[;:@&=])*))?)?)|(?:ftp://(?:(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(? :%[a-fA-F\\d]{2}))|[;?&=])*)(?::(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a- fA-F\\d]{2}))|[;?&=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|- )*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(? :\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))?))(?:/(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+! *'(),]|(?:%[a-fA-F\\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'() ,]|(?:%[a-fA-F\\d]{2}))|[?:@&=])*))*)(?:;type=[AIDaid])?)?)|(?:news:(?: (?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[;/?:&=])+@(?:(?:( ?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[ a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3})))|(?:[a-zA-Z]( ?:[a-zA-Z\\d]|[_.+-])*)|\\*))|(?:nntp://(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[ a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d ])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))?)/(?:[a-zA-Z](?:[a-zA-Z \\d]|[_.+-])*)(?:/(?:\\d+))?)|(?:telnet://(?:(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+ !*'(),]|(?:%[a-fA-F\\d]{2}))|[;?&=])*)(?::(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'() ,]|(?:%[a-fA-F\\d]{2}))|[;?&=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a -zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d] )?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))?))/?)|(?:gopher://(?:(?: (?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?: (?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+ ))?)(?:/(?:[a-zA-Z\\d$\\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\\d]{2}))(?:(?:(?:[ a-zA-Z\\d$\\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\\d]{2}))*)(?:%09(?:(?:(?:[a-zA -Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[;:@&=])*)(?:%09(?:(?:[a-zA-Z\\d$ \\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\\d]{2}))*))?)?)?)?)|(?:wais://(?:(?:(?: (?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?: [a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))? )/(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))*)(?:(?:/(?:(?:[a-zA -Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))*)/(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|( ?:%[a-fA-F\\d]{2}))*))|\\?(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d] {2}))|[;:@&=])*))?)|(?:mailto:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),;/?:@&=]|(?:% [a-fA-F\\d]{2}))+))|(?:file://(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d] |-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?: (?:\\d+)(?:\\.(?:\\d+)){3}))|localhost)?/(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'() ,]|(?:%[a-fA-F\\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|( ?:%[a-fA-F\\d]{2}))|[?:@&=])*))*))|(?:prospero://(?:(?:(?:(?:(?:[a-zA-Z \\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-) *[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))?)/(?:(?:(?:(? :[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a- zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[?:@&=])*))*)(?:(?:;(?:(?:(?:[ a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[?:@&])*)=(?:(?:(?:[a-zA-Z\\d $\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[?:@&])*)))*)|(?:ldap://(?:(?:(?:(?: (?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(?: [a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+))? ))?/(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\\d]|%(?:3\\d|[46][a-fA-F\\d]|[57][Aa\\d]) )|(?:%20))+|(?:OID|oid)\\.(?:(?:\\d+)(?:\\.(?:\\d+))*))(?:(?:%0[Aa])?(?:%2 0)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F \\d]{2}))*))(?:(?:(?:%0[Aa])?(?:%20)*)\\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(? :(?:(?:[a-zA-Z\\d]|%(?:3\\d|[46][a-fA-F\\d]|[57][Aa\\d]))|(?:%20))+|(?:OID |oid)\\.(?:(?:\\d+)(?:\\.(?:\\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa]) ?(?:%20)*))?(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))*)))*)(?:( ?:(?:(?:%0[Aa])?(?:%20)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))(?:(?:(?:(?:( ?:(?:[a-zA-Z\\d]|%(?:3\\d|[46][a-fA-F\\d]|[57][Aa\\d]))|(?:%20))+|(?:OID|o id)\\.(?:(?:\\d+)(?:\\.(?:\\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?( ?:%20)*))?(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))*))(?:(?:(?: %0[Aa])?(?:%20)*)\\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(?:(?:(?:[a-zA-Z\\d]|%( ?:3\\d|[46][a-fA-F\\d]|[57][Aa\\d]))|(?:%20))+|(?:OID|oid)\\.(?:(?:\\d+)(?: \\.(?:\\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a -zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))*)))*))*(?:(?:(?:%0[Aa])?(?:%2 0)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))?)(?:\\?(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+ !*'(),]|(?:%[a-fA-F\\d]{2}))+)(?:,(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-f A-F\\d]{2}))+))*)?)(?:\\?(?:base|one|sub)(?:\\?(?:((?:[a-zA-Z\\d$\\-_.+!*'( ),;/?:@&=]|(?:%[a-fA-F\\d]{2}))+)))?)?)?)|(?:(?:z39\\.50[rs])://(?:(?:(? :(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?)\\.)*(?:[a-zA-Z](?:(? :[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?:\\d+)){3}))(?::(?:\\d+)) ?)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))+)(?:\\+(?:(?: [a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))+))*(?:\\?(?:(?:[a-zA-Z\\d$\\-_ .+!*'(),]|(?:%[a-fA-F\\d]{2}))+))?)?(?:;esn=(?:(?:[a-zA-Z\\d$\\-_.+!*'(), ]|(?:%[a-fA-F\\d]{2}))+))?(?:;rs=(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA -F\\d]{2}))+)(?:\\+(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))+))*) ?))|(?:cid:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[;?:@&= ])*))|(?:mid:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[;?:@ &=])*)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[;?:@&=] )*))?)|(?:vemmi://(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z \\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\ .(?:\\d+)){3}))(?::(?:\\d+))?)(?:/(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a -fA-F\\d]{2}))|[/?:@&=])*)(?:(?:;(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a -fA-F\\d]{2}))|[/?:@&])*)=(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d ]{2}))|[/?:@&])*))*))?)|(?:imap://(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+ !*'(),]|(?:%[a-fA-F\\d]{2}))|[&=~])+)(?:(?:;[Aa][Uu][Tt][Hh]=(?:\\*|(?:( ?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[&=~])+))))?)|(?:(?:;[ Aa][Uu][Tt][Hh]=(?:\\*|(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2 }))|[&=~])+)))(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[ &=~])+))?))@)?(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d]) ?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?:\\.(?: \\d+)){3}))(?::(?:\\d+))?))/(?:(?:(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?: %[a-fA-F\\d]{2}))|[&=~:@/])+)?;[Tt][Yy][Pp][Ee]=(?:[Ll](?:[Ii][Ss][Tt]| [Ss][Uu][Bb])))|(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2})) |[&=~:@/])+)(?:\\?(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[ &=~:@/])+))?(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1- 9]\\d*)))?)|(?:(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[&=~ :@/])+)(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1-9]\\d* )))?(?:/;[Uu][Ii][Dd]=(?:[1-9]\\d*))(?:(?:/;[Ss][Ee][Cc][Tt][Ii][Oo][Nn ]=(?:(?:(?:[a-zA-Z\\d$\\-_.+!*'(),]|(?:%[a-fA-F\\d]{2}))|[&=~:@/])+)))?)) )?)|(?:nfs:(?:(?://(?:(?:(?:(?:(?:[a-zA-Z\\d](?:(?:[a-zA-Z\\d]|-)*[a-zA- Z\\d])?)\\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\\d]|-)*[a-zA-Z\\d])?))|(?:(?:\\d+)(?: \\.(?:\\d+)){3}))(?::(?:\\d+))?)(?:(?:/(?:(?:(?:(?:(?:[a-zA-Z\\d\\$\\-_.!~*' (),])|(?:%[a-fA-F\\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\\d\\$\\-_.!~*'(), ])|(?:%[a-fA-F\\d]{2})|[:@&=+])*))*)?)))?)|(?:/(?:(?:(?:(?:(?:[a-zA-Z\\d \\$\\-_.!~*'(),])|(?:%[a-fA-F\\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\\d\\$\\ -_.!~*'(),])|(?:%[a-fA-F\\d]{2})|[:@&=+])*))*)?))|(?:(?:(?:(?:(?:[a-zA- Z\\d\\$\\-_.!~*'(),])|(?:%[a-fA-F\\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\\d \\$\\-_.!~*'(),])|(?:%[a-fA-F\\d]{2})|[:@&=+])*))*)?)))   Given its complexibility, I think you should go the urlparse way.  For completeness, here's the pseudo-BNF of the above regex (as a documentation):  ; The generic form of a URL is:  genericurl     = scheme \":\" schemepart  ; Specific predefined schemes are defined here; new schemes ; may be registered with IANA  url            = httpurl | ftpurl | newsurl |                  nntpurl | telneturl | gopherurl |                  waisurl | mailtourl | fileurl |                  prosperourl | otherurl  ; new schemes follow the general syntax otherurl       = genericurl  ; the scheme is in lower case; interpreters should use case-ignore scheme         = 1*[ lowalpha | digit | \"+\" | \"-\" | \".\" ] schemepart     = *xchar | ip-schemepart   ; URL schemeparts for ip based protocols:  ip-schemepart  = \"//\" login [ \"/\" urlpath ]  login          = [ user [ \":\" password ] \"@\" ] hostport hostport       = host [ \":\" port ] host           = hostname | hostnumber hostname       = *[ domainlabel \".\" ] toplabel domainlabel    = alphadigit | alphadigit *[ alphadigit | \"-\" ] alphadigit toplabel       = alpha | alpha *[ alphadigit | \"-\" ] alphadigit alphadigit     = alpha | digit hostnumber     = digits \".\" digits \".\" digits \".\" digits port           = digits user           = *[ uchar | \";\" | \"?\" | \"&\" | \"=\" ] password       = *[ uchar | \";\" | \"?\" | \"&\" | \"=\" ] urlpath        = *xchar    ; depends on protocol see section 3.1  ; The predefined schemes:  ; FTP (see also RFC959)  ftpurl         = \"ftp://\" login [ \"/\" fpath [ \";type=\" ftptype ]] fpath          = fsegment *[ \"/\" fsegment ] fsegment       = *[ uchar | \"?\" | \":\" | \"@\" | \"&\" | \"=\" ] ftptype        = \"A\" | \"I\" | \"D\" | \"a\" | \"i\" | \"d\"  ; FILE  fileurl        = \"file://\" [ host | \"localhost\" ] \"/\" fpath  ; HTTP  httpurl        = \"http://\" hostport [ \"/\" hpath [ \"?\" search ]] hpath          = hsegment *[ \"/\" hsegment ] hsegment       = *[ uchar | \";\" | \":\" | \"@\" | \"&\" | \"=\" ] search         = *[ uchar | \";\" | \":\" | \"@\" | \"&\" | \"=\" ]  ; GOPHER (see also RFC1436)  gopherurl      = \"gopher://\" hostport [ / [ gtype [ selector                  [ \"%09\" search [ \"%09\" gopher+_string ] ] ] ] ] gtype          = xchar selector       = *xchar gopher+_string = *xchar  ; MAILTO (see also RFC822)  mailtourl      = \"mailto:\" encoded822addr encoded822addr = 1*xchar               ; further defined in RFC822  ; NEWS (see also RFC1036)  newsurl        = \"news:\" grouppart grouppart      = \"*\" | group | article group          = alpha *[ alpha | digit | \"-\" | \".\" | \"+\" | \"_\" ] article        = 1*[ uchar | \";\" | \"/\" | \"?\" | \":\" | \"&\" | \"=\" ] \"@\" host  ; NNTP (see also RFC977)  nntpurl        = \"nntp://\" hostport \"/\" group [ \"/\" digits ]  ; TELNET  telneturl      = \"telnet://\" login [ \"/\" ]  ; WAIS (see also RFC1625)  waisurl        = waisdatabase | waisindex | waisdoc waisdatabase   = \"wais://\" hostport \"/\" database waisindex      = \"wais://\" hostport \"/\" database \"?\" search waisdoc        = \"wais://\" hostport \"/\" database \"/\" wtype \"/\" wpath database       = *uchar wtype          = *uchar wpath          = *uchar  ; PROSPERO  prosperourl    = \"prospero://\" hostport \"/\" ppath *[ fieldspec ] ppath          = psegment *[ \"/\" psegment ] psegment       = *[ uchar | \"?\" | \":\" | \"@\" | \"&\" | \"=\" ] fieldspec      = \";\" fieldname \"=\" fieldvalue fieldname      = *[ uchar | \"?\" | \":\" | \"@\" | \"&\" ] fieldvalue     = *[ uchar | \"?\" | \":\" | \"@\" | \"&\" ]  ; Miscellaneous definitions  lowalpha       = \"a\" | \"b\" | \"c\" | \"d\" | \"e\" | \"f\" | \"g\" | \"h\" |                  \"i\" | \"j\" | \"k\" | \"l\" | \"m\" | \"n\" | \"o\" | \"p\" |                  \"q\" | \"r\" | \"s\" | \"t\" | \"u\" | \"v\" | \"w\" | \"x\" |                  \"y\" | \"z\" hialpha        = \"A\" | \"B\" | \"C\" | \"D\" | \"E\" | \"F\" | \"G\" | \"H\" | \"I\" |                  \"J\" | \"K\" | \"L\" | \"M\" | \"N\" | \"O\" | \"P\" | \"Q\" | \"R\" |                  \"S\" | \"T\" | \"U\" | \"V\" | \"W\" | \"X\" | \"Y\" | \"Z\" alpha          = lowalpha | hialpha digit          = \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" |                  \"8\" | \"9\" safe           = \"$\" | \"-\" | \"_\" | \".\" | \"+\" extra          = \"!\" | \"*\" | \"'\" | \"(\" | \")\" | \",\" national       = \"{\" | \"}\" | \"|\" | \"\\\" | \"^\" | \"~\" | \"[\" | \"]\" | \"`\" punctuation    = \"\" | \"#\" | \"%\" |    reserved       = \";\" | \"/\" | \"?\" | \":\" | \"@\" | \"&\" | \"=\" hex            = digit | \"A\" | \"B\" | \"C\" | \"D\" | \"E\" | \"F\" |                  \"a\" | \"b\" | \"c\" | \"d\" | \"e\" | \"f\" escape         = \"%\" hex hex  unreserved     = alpha | digit | safe | extra uchar          = unreserved | escape xchar          = unreserved | reserved | escape digits         = 1*digit      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "213",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  I admit, I find your regular expression totally incomprehensible.  I wonder if you could use urlparse instead?  Something like:  pieces = urlparse.urlparse(url) assert all([pieces.scheme, pieces.netloc]) assert set(pieces.netloc) <= set(string.letters + string.digits + '-.')  # and others? assert pieces.scheme in ['http', 'https', 'ftp']  # etc.   It might be slower, and maybe you'll miss conditions, but it seems (to me) a lot easier to read and debug than a regular expression for URLs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  I'm using the one used by Django and it seems to work pretty well:  def is_valid_url(url):     import re     regex = re.compile(         r'^https?://'  # http:// or https://         r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\.?|'  # domain...         r'localhost|'  # localhost...         r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip         r'(?::\\d+)?'  # optional port         r'(?:/?|[/?]\\S+)$', re.IGNORECASE)     return url is not None and regex.search(url)   You can always check the latest version here: https://github.com/django/django/blob/master/django/core/validators.py#L74     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  http://pypi.python.org/pypi/rfc3987 gives regular expressions for consistency with the rules in RFC 3986 and RFC 3987 (that is, not with scheme-specific rules).  A regexp for IRI_reference is:  (?P<scheme>[a-zA-Z][a-zA-Z0-9+.-]*):(?://(?P<iauthority>(?:(?P<iuserinfo>(?:(?:[ a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U0002 0000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U 00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009ff fd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U00 0dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:)*)@)?(?P<ihost>\\ \\[(?:(?:[0-9A-F]{1,4}:){6}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4] [0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|::(?:[0 -9A-F]{1,4}:){5}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01] ?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|[0-9A-F]{1,4}?::( ?:[0-9A-F]{1,4}:){4}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]| [01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F ]{1,4}:)?[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){3}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(? :(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[ 0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,2}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){2}(?: [0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3 }(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,3}[0-9A-F]{1, 4})?::(?:[0-9A-F]{1,4}:)(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0 -9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0- 9A-F]{1,4}:){,4}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5] |2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))| (?:(?:[0-9A-F]{1,4}:){,5}[0-9A-F]{1,4})?::[0-9A-F]{1,4}|(?:(?:[0-9A-F]{1,4}:){,6 }[0-9A-F]{1,4})?::|v[0-9A-F]+\\\\.(?:[a-zA-Z0-9_.~-]|[!$&'()*+,;=]|:)+)\\\\]|(?:(?:( ?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][ 0-9]?))|(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\ U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U000500 00-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00 090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd \\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=])*)( ?::(?P<port>[0-9]*))?)(?P<ipath>(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\uf dcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\ U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007f ffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U0 00bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A- F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>/(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7 ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000 -\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U0007 0000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U 000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000eff fd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff \\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\ U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U000700 00-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U00 0b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd ])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)?)|(?P<ipath>(?:(?:[a-zA-Z0-9._~-]|[\\ xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U 00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006ff fd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U00 0afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000- \\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa 0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00 030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd \\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000a fffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U 000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>))(?:\\\\?(?P<iquery >(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U000 1fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\ U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U000900 00-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U00 0d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|[\\ ue000-\\uf8ff\\U000f0000-\\U000ffffd\\U00100000-\\U0010fffd]|/|\\\\?)*))?(?:\\\\#(?P<ifra gment>(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000- \\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050 000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U0 0090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfff d\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:| @)|/|\\\\?)*))?|(?:(?://(?P<iauthority>(?:(?P<iuserinfo>(?:(?:[a-zA-Z0-9._~-]|[\\xa 0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00 030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd \\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000a fffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U 000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:)*)@)?(?P<ihost>\\\\[(?:(?:[0-9A-F]{1, 4}:){6}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0- 9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|::(?:[0-9A-F]{1,4}:){5}(?: [0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3 }(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|[0-9A-F]{1,4}?::(?:[0-9A-F]{1,4}:){4 }(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\ .){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:)?[0-9A-F]{1 ,4})?::(?:[0-9A-F]{1,4}:){3}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0- 4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(? :[0-9A-F]{1,4}:){,2}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){2}(?:[0-9A-F]{1,4}:[0-9A -F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][ 0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,3}[0-9A-F]{1,4})?::(?:[0-9A-F]{1 ,4}:)(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9] ?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,4}[0- 9A-F]{1,4})?::(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[ 0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4} :){,5}[0-9A-F]{1,4})?::[0-9A-F]{1,4}|(?:(?:[0-9A-F]{1,4}:){,6}[0-9A-F]{1,4})?::| v[0-9A-F]+\\\\.(?:[a-zA-Z0-9_.~-]|[!$&'()*+,;=]|:)+)\\\\]|(?:(?:(?:25[0-5]|2[0-4][0- 9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))|(?:(?:[a-zA -Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000 -\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U0006 0000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U 000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dff fd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=])*)(?::(?P<port>[0-9]*) )?)(?P<ipath>(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U0 0010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fff d\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U000 8fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\ U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()* +,;=]|:|@)*)*)|(?P<ipath>/(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufd f0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U000400 00-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00 080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd \\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A -F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0 -\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000 -\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U0008 0000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U 000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F ]|[!$&'()*+,;=]|:|@)*)*)?)|(?P<ipath>(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\u fdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd \\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007 fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U 000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A -F][0-9A-F]|[!$&'()*+,;=]|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf \\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00 040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd \\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000b fffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][ 0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>))(?:\\\\?(?P<iquery>(?:(?:(?:[a-zA-Z0-9. _~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U000 2fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\ U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a00 00-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U00 0e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|[\\ue000-\\uf8ff\\U000f000 0-\\U000ffffd\\U00100000-\\U0010fffd]|/|\\\\?)*))?(?:\\\\#(?P<ifragment>(?:(?:(?:[a-zA- Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000- \\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060 000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U0 00a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfff d\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|/|\\\\?)*))?)   In one line:  (?P<scheme>[a-zA-Z][a-zA-Z0-9+.-]*):(?://(?P<iauthority>(?:(?P<iuserinfo>(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:)*)@)?(?P<ihost>\\\\[(?:(?:[0-9A-F]{1,4}:){6}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|::(?:[0-9A-F]{1,4}:){5}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|[0-9A-F]{1,4}?::(?:[0-9A-F]{1,4}:){4}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:)?[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){3}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,2}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){2}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,3}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:)(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,4}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,5}[0-9A-F]{1,4})?::[0-9A-F]{1,4}|(?:(?:[0-9A-F]{1,4}:){,6}[0-9A-F]{1,4})?::|v[0-9A-F]+\\\\.(?:[a-zA-Z0-9_.~-]|[!$&'()*+,;=]|:)+)\\\\]|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))|(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=])*)(?::(?P<port>[0-9]*))?)(?P<ipath>(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>/(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)?)|(?P<ipath>(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>))(?:\\\\?(?P<iquery>(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|[\\ue000-\\uf8ff\\U000f0000-\\U000ffffd\\U00100000-\\U0010fffd]|/|\\\\?)*))?(?:\\\\#(?P<ifragment>(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|/|\\\\?)*))?|(?:(?://(?P<iauthority>(?:(?P<iuserinfo>(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:)*)@)?(?P<ihost>\\\\[(?:(?:[0-9A-F]{1,4}:){6}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|::(?:[0-9A-F]{1,4}:){5}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|[0-9A-F]{1,4}?::(?:[0-9A-F]{1,4}:){4}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:)?[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){3}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,2}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:){2}(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,3}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:)(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,4}[0-9A-F]{1,4})?::(?:[0-9A-F]{1,4}:[0-9A-F]{1,4}|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))|(?:(?:[0-9A-F]{1,4}:){,5}[0-9A-F]{1,4})?::[0-9A-F]{1,4}|(?:(?:[0-9A-F]{1,4}:){,6}[0-9A-F]{1,4})?::|v[0-9A-F]+\\\\.(?:[a-zA-Z0-9_.~-]|[!$&'()*+,;=]|:)+)\\\\]|(?:(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))|(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=])*)(?::(?P<port>[0-9]*))?)(?P<ipath>(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>/(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)?)|(?P<ipath>(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|@)+(?:/(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)*)*)|(?P<ipath>))(?:\\\\?(?P<iquery>(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|[\\ue000-\\uf8ff\\U000f0000-\\U000ffffd\\U00100000-\\U0010fffd]|/|\\\\?)*))?(?:\\\\#(?P<ifragment>(?:(?:(?:[a-zA-Z0-9._~-]|[\\xa0-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\uffef\\U00010000-\\U0001fffd\\U00020000-\\U0002fffd\\U00030000-\\U0003fffd\\U00040000-\\U0004fffd\\U00050000-\\U0005fffd\\U00060000-\\U0006fffd\\U00070000-\\U0007fffd\\U00080000-\\U0008fffd\\U00090000-\\U0009fffd\\U000a0000-\\U000afffd\\U000b0000-\\U000bfffd\\U000c0000-\\U000cfffd\\U000d0000-\\U000dfffd\\U000e1000-\\U000efffd])|%[0-9A-F][0-9A-F]|[!$&'()*+,;=]|:|@)|/|\\\\?)*))?)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  note - Lepl is no longer maintained or supported.  RFC 3696 defines \"best practices\" for URL validation - http://www.faqs.org/rfcs/rfc3696.html  The latest release of Lepl (a Python parser library) includes an implementation of RFC 3696.  You would use it something like:  from lepl.apps.rfc3696 import Email, HttpUrl  # compile the validators (do once at start of program) valid_email = Email() valid_http_url = HttpUrl()  # use the validators (as often as you like) if valid_email(some_email):     # email is ok else:     # email is bad if valid_http_url(some_url):     # url is ok else:     # url is bad   Although the validators are defined in Lepl, which is a recursive descent parser, they are largely compiled internally to regular expressions.  That combines the best of both worlds - a (relatively) easy to read definition that can be checked against RFC 3696 and an efficient implementation.  There's a post on my blog showing how this simplifies the parser - http://www.acooke.org/cute/LEPLOptimi0.html  Lepl is available at http://www.acooke.org/lepl and the RFC 3696 module is documented at http://www.acooke.org/lepl/rfc3696.html  This is completely new in this release, so may contain bugs.  Please contact me if you have any problems and I will fix them ASAP.  Thanks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  urlparse quite happily takes invalid URLs, it is more a string string-splitting library than any kind of validator. For example:  from urlparse import urlparse urlparse('http://----') # returns: ParseResult(scheme='http', netloc='----', path='', params='', query='', fragment='')   Depending on the situation, this might be fine..  If you mostly trust the data, and just want to verify the protocol is HTTP, then urlparse is perfect.  If you want to make the URL is actually a legal URL, use the ridiculous regex  If you want to make sure it's a real web address,  import urllib try:     urllib.urlopen(url) except IOError:     print \"Not a real URL\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  The regex provided should match any url of the form http://www.ietf.org/rfc/rfc3986.txt; and does when tested in the python interpreter.  What format have the URLs you've been having trouble parsing had?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  Nowadays In 90% of case if you working with URL in python than you probably use python-requests. So now is the question \"Why do not reuse URL validation from requests\" ?  from requests.models import PreparedRequest import requests.exceptions   def check_url(url):     prepared_request = PreparedRequest()     try:         prepared_request.prepare_url(url, None)         return prepared_request.url     except requests.exceptions.MissingSchema, e:         raise SomeException   feature:   don't reinvent wheel DRY work offline minimal resource      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  I've needed to do this many times over the years and always end up copying someone else's regular expression who has thought about it way more than I want to think about it.  Having said that, there is a regex in the Django forms code which should do the trick:  http://code.djangoproject.com/browser/django/trunk/django/forms/fields.py#L534     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  urlfinders = [     re.compile(\"([0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}|(((news|telnet|nttp|file|http|ftp|https)://)|(www|ftp)[-A-Za-z0-9]*\\\\.)[-A-Za-z0-9\\\\.]+)(:[0-9]*)?/[-A-Za-z0-9_\\\\$\\\\.\\\\+\\\\!\\\\*\\\\(\\\\),;:@&=\\\\?/~\\\\#\\\\%]*[^]'\\\\.}>\\\\),\\\\\\\"]\"),     re.compile(\"([0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}|(((news|telnet|nttp|file|http|ftp|https)://)|(www|ftp)[-A-Za-z0-9]*\\\\.)[-A-Za-z0-9\\\\.]+)(:[0-9]*)?\"),     re.compile(\"(~/|/|\\\\./)([-A-Za-z0-9_\\\\$\\\\.\\\\+\\\\!\\\\*\\\\(\\\\),;:@&=\\\\?/~\\\\#\\\\%]|\\\\\\\\ )+\"),     re.compile(\"'\\\\<((mailto:)|)[-A-Za-z0-9\\\\.]+@[-A-Za-z0-9\\\\.]+\"), ]   NOTE: As ugly as it looks in your browser just copy paste and the formatting should be good  Found at the python mailing lists and used for the gnome-terminal  source: http://mail.python.org/pipermail/python-list/2007-January/595436.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do you validate a URL with a regular expression in Python?",
        "A_Content": "  modified django url validation regex:  import re  ul = '\\u00a1-\\uffff'  # unicode letters range (must not be a raw string)  # IP patterns  ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'  ipv6_re = r'\\[[0-9a-f:\\.]+\\]'  # Host patterns  hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?' domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*' # domain names have max length of 63 characters tld_re = (      r'\\.'                                # dot      r'(?!-)'                             # can't start with a dash      r'(?:[a-z' + ul + '-]{2,63}'         # domain label      r'|xn--[a-z0-9]{1,59})'              # or punycode label      r'(?<!-)'                            # can't end with a dash      r'\\.?'                               # may have a trailing dot  )  host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'  regex = re.compile(      r'^(?:http|ftp)s?://' # http(s):// or ftp(s)://     r'(?:\\S+(?::\\S*)?@)?'  # user:pass authentication      r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')' # localhost or ip     r'(?::\\d{2,5})?'  # optional port     r'(?:[/?#][^\\s]*)?'  # resource path     r'\\Z', re.IGNORECASE)   source: https://github.com/django/django/blob/master/django/core/validators.py#L74     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.  I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL.   I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)  Below is a snipped which should work?   p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?') m = p.match(url) if m:   self.url = url   return url      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Calling parent class __init__ with multiple inheritance, what's the right way?",
        "A_Content": "  Both ways work fine.  The approach using super() leads to greater flexibility for subclasses.    In the direct call approach, C.__init__ can call both A.__init__ and B.__init__.  When using super(), the classes need to be designed for cooperative multiple inheritance where C calls super, which invokes A's code which will also call super which invokes B's code.  See http://rhettinger.wordpress.com/2011/05/26/super-considered-super for more detail on what can be done with super.  [Response question as later edited]     So it seems that unless I know/control the init's of the classes I   inherit from (A and B) I cannot make a safe choice for the class I'm   writing (C).   The referenced article shows how to handle this situation by adding a wrapper class around A and B.  There is a worked-out example in the section titled \"How to Incorporate a Non-cooperative Class\".  One might wish that multiple inheritance were easier, letting you effortlessly compose Car and Airplane classes to get a FlyingCar, but the reality is that separately designed components often need adapters or wrappers before fitting together as seamlessly as we would like :-)  One other thought:  if you're unhappy with composing functionality using multiple inheritance, you can use composition for complete control over which methods get called on which occasions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "inheritance",
            "multiple-inheritance",
            "super"
        ],
        "URL": "https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Say I have a multiple inheritance scenario:  class A(object):     # code for A here  class B(object):     # code for B here  class C(A, B):     def __init__(self):         # What's the right code to write here to ensure          # A.__init__ and B.__init__ get called?   There's two typical approaches to writing C's __init__:   (old-style) ParentClass.__init__(self) (newer-style) super(DerivedClass, self).__init__()   However, in either case, if the parent classes (A and B) don't follow the same convention, then the code will not work correctly (some may be missed, or get called multiple times).  So what's the correct way again?  It's easy to say \"just be consistent, follow one or the other\", but if A or B are from a 3rd party library, what then?  Is there an approach that can ensure that all parent class constructors get called (and in the correct order, and only once)?  Edit: to see what I mean, if I do:  class A(object):     def __init__(self):         print(\"entering A\")         super(A, self).__init__()         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         A.__init__(self)         B.__init__(self)         print(\"leaving c\")   Then I get:  entering c entering A entering B leaving B leaving A entering B leaving B leaving c   Note that B's init gets called twice.  If I do:   class A(object):     def __init__(self):         print(\"entering A\")         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         super(C, self).__init__()         print(\"leaving c\")   Then I get:   entering c entering A leaving A leaving c   Note that B's init never gets called.  So it seems that unless I know/control the init's of the classes I inherit from (A and B) I cannot make a safe choice for the class I'm writing (C).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Calling parent class __init__ with multiple inheritance, what's the right way?",
        "A_Content": "  The answer to your question depends on one very important aspect: Are your base classes designed for multiple inheritance?  There are 3 different scenarios:   The base classes are unrelated, standalone classes.  If your base classes are separate entities that are capable of functioning independently and they don't know each other, they're not designed for multiple inheritance.  In this case, you will have to call each parent constructor manually. This is easier without super.  Example:  class Foo:     def __init__(self):         self.foo = 'foo'  class Bar:     def __init__(self, bar):         self.bar = bar  class FooBar(Foo, Bar):     def __init__(self, bar='bar'):         Foo.__init__(self)  # explicit calls without super         Bar.__init__(self, bar)          # To get the same results with `super`, you'd have to do this:         #   super().__init__()         #   super(Foo, self).__init__(bar)         # Which is obviously much less intuitive.   Important: Notice that neither Foo nor Bar calls super().__init__()! This is why your code didn't work correctly. Because of the way diamond inheritance works in python, classes whose base class is object should not call super().__init__(). As you've noticed, doing so would break multiple inheritance because you end up calling another class's __init__ rather than object.__init__().  This also means that you should never write a class that inherits from object and doesn't have an __init__ method. Not defining a __init__ method at all has the same effect as calling super().__init__(). If your class inherits directly from object, make sure to add an empty constructor like so:  class Base(object):     def __init__(self):         pass  One of the classes is a mixin.  A mixin is a class that's designed to be used with multiple inheritance. This means we don't have to call both parent constructors manually, because the mixin will automatically call the 2nd constructor for us. Since we only have to call a single constructor this time, we can do so with super to avoid having to hard-code the parent class's name.  Example:  class FooMixin:     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.foo = 'foo'  class Bar:     def __init__(self, bar):         self.bar = bar  class FooBar(FooMixin, Bar):     def __init__(self, bar='bar'):         super().__init__(bar)  # a single call is enough to invoke                                # all parent constructors          # NOTE: `FooMixin.__init__(self, bar)` would also work, but isn't         # recommended because we don't want to hard-code the parent class.   The important details here are:   The mixin calls super().__init__() and passes through any arguments it receives. The subclass inherits from the mixin first: class FooBar(FooMixin, Bar). If the order of the base classes is wrong, the mixin's constructor will never be called.  All base classes are designed for cooperative inheritance.  Classes designed for cooperative inheritance are a lot like mixins: They pass through all unused arguments to the next class. Like before, we just have to call super().__init__() and all parent constructors will be chain-called.  Example:  class CoopFoo:     def __init__(self, **kwargs):         super().__init__(**kwargs)         self.foo = 'foo'  class CoopBar:     def __init__(self, bar, **kwargs):         super().__init__(**kwargs)         self.bar = bar  class CoopFooBar(CoopFoo, CoopBar):     def __init__(self, bar='bar'):         super().__init__(bar=bar)  # pass all arguments on as keyword                                    # arguments to avoid problems with                                    # positional arguments and the order                                    # of the parent classes   In this case, the order of the parent classes doesn't matter. We might as well inherit from CoopBar first, and the code would still work the same. But that's only true because all arguments are passed as keyword arguments. Using positional arguments would make it easy to get the order of the arguments wrong, so it's customary for cooperative classes to accept only keyword arguments.  This is also an exception to the rule I mentioned earlier: Both CoopFoo and CoopBar inherit from object, but they still call super().__init__(). If they didn't, there would be no cooperative inheritance.   Bottom line: The correct implementation depends on the classes you're inheriting from.  The constructor is part of a class's public interface. If the class is designed as a mixin or for cooperative inheritance, that must be documented. If the docs don't mention anything of the sort, it's safe to assume that the class isn't designed for multiple inheritance and you have to call each parent class's constructor explicitly (without super).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "inheritance",
            "multiple-inheritance",
            "super"
        ],
        "URL": "https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have a multiple inheritance scenario:  class A(object):     # code for A here  class B(object):     # code for B here  class C(A, B):     def __init__(self):         # What's the right code to write here to ensure          # A.__init__ and B.__init__ get called?   There's two typical approaches to writing C's __init__:   (old-style) ParentClass.__init__(self) (newer-style) super(DerivedClass, self).__init__()   However, in either case, if the parent classes (A and B) don't follow the same convention, then the code will not work correctly (some may be missed, or get called multiple times).  So what's the correct way again?  It's easy to say \"just be consistent, follow one or the other\", but if A or B are from a 3rd party library, what then?  Is there an approach that can ensure that all parent class constructors get called (and in the correct order, and only once)?  Edit: to see what I mean, if I do:  class A(object):     def __init__(self):         print(\"entering A\")         super(A, self).__init__()         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         A.__init__(self)         B.__init__(self)         print(\"leaving c\")   Then I get:  entering c entering A entering B leaving B leaving A entering B leaving B leaving c   Note that B's init gets called twice.  If I do:   class A(object):     def __init__(self):         print(\"entering A\")         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         super(C, self).__init__()         print(\"leaving c\")   Then I get:   entering c entering A leaving A leaving c   Note that B's init never gets called.  So it seems that unless I know/control the init's of the classes I inherit from (A and B) I cannot make a safe choice for the class I'm writing (C).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Calling parent class __init__ with multiple inheritance, what's the right way?",
        "A_Content": "  This article helps to explain cooperative multiple inheritance:  http://www.artima.com/weblogs/viewpost.jsp?thread=281127  It mentions the useful method mro() that shows you the method resolution order. In your 2nd example, where you call super in A, the super call continues on in MRO. The next class in the order is B, this is why B's init is called the first time.  Here's a more technical article from the official python site:  http://www.python.org/download/releases/2.3/mro/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "inheritance",
            "multiple-inheritance",
            "super"
        ],
        "URL": "https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have a multiple inheritance scenario:  class A(object):     # code for A here  class B(object):     # code for B here  class C(A, B):     def __init__(self):         # What's the right code to write here to ensure          # A.__init__ and B.__init__ get called?   There's two typical approaches to writing C's __init__:   (old-style) ParentClass.__init__(self) (newer-style) super(DerivedClass, self).__init__()   However, in either case, if the parent classes (A and B) don't follow the same convention, then the code will not work correctly (some may be missed, or get called multiple times).  So what's the correct way again?  It's easy to say \"just be consistent, follow one or the other\", but if A or B are from a 3rd party library, what then?  Is there an approach that can ensure that all parent class constructors get called (and in the correct order, and only once)?  Edit: to see what I mean, if I do:  class A(object):     def __init__(self):         print(\"entering A\")         super(A, self).__init__()         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         A.__init__(self)         B.__init__(self)         print(\"leaving c\")   Then I get:  entering c entering A entering B leaving B leaving A entering B leaving B leaving c   Note that B's init gets called twice.  If I do:   class A(object):     def __init__(self):         print(\"entering A\")         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         super(C, self).__init__()         print(\"leaving c\")   Then I get:   entering c entering A leaving A leaving c   Note that B's init never gets called.  So it seems that unless I know/control the init's of the classes I inherit from (A and B) I cannot make a safe choice for the class I'm writing (C).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Calling parent class __init__ with multiple inheritance, what's the right way?",
        "A_Content": "  If you are multiply sub-classing classes from third party libraries, then no, there is no blind approach to calling the base class __init__ methods (or any other methods) that actually works regardless of how the base classes are programmed.  super makes it possible to write classes designed to cooperatively implement methods as part of complex multiple inheritance trees which need not be known to the class author. But there's no way to use it to correctly inherit from arbitrary classes that may or may not use super.  Essentially, whether a class is designed to be sub-classed using super or with direct calls to the base class is a property which is part of the class' \"public interface\", and it should be documented as such. If you're using third-party libraries in the way that the library author expected and the library has reasonable documentation, it would normally tell you what you are required to do to subclass particular things. If not, then you'll have to look at the source code for the classes you're sub-classing and see what their base-class-invocation convention is. If you're combining multiple classes from one or more third-party libraries in a way that the library authors didn't expect, then it may not be possible to consistently invoke super-class methods at all; if class A is part of a hierarchy using super and class B is part of a hierarchy that doesn't use super, then neither option is guaranteed to work. You'll have to figure out a strategy that happens to work for each particular case.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "inheritance",
            "multiple-inheritance",
            "super"
        ],
        "URL": "https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have a multiple inheritance scenario:  class A(object):     # code for A here  class B(object):     # code for B here  class C(A, B):     def __init__(self):         # What's the right code to write here to ensure          # A.__init__ and B.__init__ get called?   There's two typical approaches to writing C's __init__:   (old-style) ParentClass.__init__(self) (newer-style) super(DerivedClass, self).__init__()   However, in either case, if the parent classes (A and B) don't follow the same convention, then the code will not work correctly (some may be missed, or get called multiple times).  So what's the correct way again?  It's easy to say \"just be consistent, follow one or the other\", but if A or B are from a 3rd party library, what then?  Is there an approach that can ensure that all parent class constructors get called (and in the correct order, and only once)?  Edit: to see what I mean, if I do:  class A(object):     def __init__(self):         print(\"entering A\")         super(A, self).__init__()         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         A.__init__(self)         B.__init__(self)         print(\"leaving c\")   Then I get:  entering c entering A entering B leaving B leaving A entering B leaving B leaving c   Note that B's init gets called twice.  If I do:   class A(object):     def __init__(self):         print(\"entering A\")         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         super(C, self).__init__()         print(\"leaving c\")   Then I get:   entering c entering A leaving A leaving c   Note that B's init never gets called.  So it seems that unless I know/control the init's of the classes I inherit from (A and B) I cannot make a safe choice for the class I'm writing (C).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Calling parent class __init__ with multiple inheritance, what's the right way?",
        "A_Content": "  As Raymond said in his answer, a direct call to A.__init__ and B.__init__ works fine, and your code would be readable.   However, it does not use the inheritance link between C and those classes. Exploiting that link gives you more consistancy and make eventual refactorings easier and less error-prone. An example of how to do that:   class C(A, B):     def __init__(self):         print(\"entering c\")         for base_class in C.__bases__:  # (A, B)              base_class.__init__(self)         print(\"leaving c\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "inheritance",
            "multiple-inheritance",
            "super"
        ],
        "URL": "https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have a multiple inheritance scenario:  class A(object):     # code for A here  class B(object):     # code for B here  class C(A, B):     def __init__(self):         # What's the right code to write here to ensure          # A.__init__ and B.__init__ get called?   There's two typical approaches to writing C's __init__:   (old-style) ParentClass.__init__(self) (newer-style) super(DerivedClass, self).__init__()   However, in either case, if the parent classes (A and B) don't follow the same convention, then the code will not work correctly (some may be missed, or get called multiple times).  So what's the correct way again?  It's easy to say \"just be consistent, follow one or the other\", but if A or B are from a 3rd party library, what then?  Is there an approach that can ensure that all parent class constructors get called (and in the correct order, and only once)?  Edit: to see what I mean, if I do:  class A(object):     def __init__(self):         print(\"entering A\")         super(A, self).__init__()         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         A.__init__(self)         B.__init__(self)         print(\"leaving c\")   Then I get:  entering c entering A entering B leaving B leaving A entering B leaving B leaving c   Note that B's init gets called twice.  If I do:   class A(object):     def __init__(self):         print(\"entering A\")         print(\"leaving A\")  class B(object):     def __init__(self):         print(\"entering B\")         super(B, self).__init__()         print(\"leaving B\")  class C(A, B):     def __init__(self):         print(\"entering c\")         super(C, self).__init__()         print(\"leaving c\")   Then I get:   entering c entering A leaving A leaving c   Note that B's init never gets called.  So it seems that unless I know/control the init's of the classes I inherit from (A and B) I cannot make a safe choice for the class I'm writing (C).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "What does from __future__ import absolute_import actually do?",
        "A_Content": "  The changelog is sloppily worded. from __future__ import absolute_import does not care about whether something is part of the standard library, and import string will not always give you the standard-library module with absolute imports on.  from __future__ import absolute_import means that if you import string, Python will always look for a top-level string module, rather than current_package.string. However, it does not affect the logic Python uses to decide what file is the string module. When you do  python pkg/script.py   pkg/script.py doesn't look like part of a package to Python. Following the normal procedures, the pkg directory is added to the path, and all .py files in the pkg directory look like top-level modules. import string finds pkg/string.py not because it's doing a relative import, but because pkg/string.py appears to be the top-level module string. The fact that this isn't the standard-library string module doesn't come up.  To run the file as part of the pkg package, you could do  python -m pkg.script   In this case, the pkg directory will not be added to the path. However, the current directory will be added to the path.  You can also add some boilerplate to pkg/script.py to make Python treat it as part of the pkg package even when run as a file:  if __name__ == '__main__' and __package__ is None:     __package__ = 'pkg'   However, this won't affect sys.path. You'll need some additional handling to remove the pkg directory from the path, and if pkg's parent directory isn't on the path, you'll need to stick that on the path too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-import",
            "python-2.5"
        ],
        "URL": "https://stackoverflow.com/questions/33743880/what-does-from-future-import-absolute-import-actually-do",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have answered a question regarding absolute imports in Python, which I thought I understood based on reading the Python 2.5 changelog and accompanying PEP. However, upon installing Python 2.5 and attempting to craft an example of properly using from __future__ import absolute_import, I realize things are not so clear.  Straight from the changelog linked above, this statement accurately summarized my understanding of the absolute import change:     Let's say you have a package directory like this:  pkg/ pkg/__init__.py pkg/main.py pkg/string.py       This defines a package named pkg containing the pkg.main and pkg.string submodules.      Consider the code in the main.py module. What happens if it executes the statement import string? In Python 2.4 and earlier, it will first look in the package's directory to perform a relative import, finds pkg/string.py, imports the contents of that file as the pkg.string module, and that module is bound to the name \"string\" in the pkg.main module's namespace.   So I created this exact directory structure:  $ ls -R .: pkg/  ./pkg: __init__.py  main.py  string.py   __init__.py and string.py are empty. main.py contains the following code:  import string print string.ascii_uppercase   As expected, running this with Python 2.5 fails with an AttributeError:  $ python2.5 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   However, further along in the 2.5 changelog, we find this (emphasis added):     In Python 2.5, you can switch import's behaviour to absolute imports using a from __future__ import absolute_import directive. This absolute-import behaviour will become the default in a future version (probably Python 2.7). Once absolute imports are the default, import string will always find the standard library's version.   I thus created pkg/main2.py, identical to main.py but with the additional future import directive. It now looks like this:  from __future__ import absolute_import import string print string.ascii_uppercase   Running this with Python 2.5, however... fails with an AttributeError:  $ python2.5 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   This pretty flatly contradicts the statement that import string will always find the std-lib version with absolute imports enabled. What's more, despite the warning that absolute imports are scheduled to become the \"new default\" behavior, I hit this same problem using both Python 2.7, with or without the __future__ directive:  $ python2.7 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'  $ python2.7 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   as well as Python 3.5, with or without (assuming the print statement is changed in both files):  $ python3.5 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print(string.ascii_uppercase) AttributeError: module 'string' has no attribute 'ascii_uppercase'  $ python3.5 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print(string.ascii_uppercase) AttributeError: module 'string' has no attribute 'ascii_uppercase'     I have tested other variations of this. Instead of string.py, I have created an empty module -- a directory named string containing only an empty __init__.py -- and instead of issuing imports from main.py, I have cd'd to pkg and run imports directly from the REPL. Neither of these variations (nor a combination of them) changed the results above. I cannot reconcile this with what I have read about the __future__ directive and absolute imports.  It seems to me that this is easily explicable by the following (this is from the Python 2 docs but this statement remains unchanged in the same docs for Python 3):     sys.path      (...)      As initialized upon program startup, the first item of this list, path[0], is the directory containing the script that was used to invoke the Python interpreter. If the script directory is not available (e.g. if the interpreter is invoked interactively or if the script is read from standard input), path[0] is the empty string, which directs Python to search modules in the current directory first.   So what am I missing? Why does the __future__ statement seemingly not do what it says, and what is the resolution of this contradiction between these two sections of documentation, as well as between described and actual behavior?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "What does from __future__ import absolute_import actually do?",
        "A_Content": "  The difference between absolute and relative imports come into play only when you import a module from a package and that module imports an other submodule from that package. See the difference:  $ mkdir pkg $ touch pkg/__init__.py $ touch pkg/string.py $ echo 'import string;print(string.ascii_uppercase)' > pkg/main1.py $ python2 Python 2.7.9 (default, Dec 13 2014, 18:02:08) [GCC] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import pkg.main1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"pkg/main1.py\", line 1, in <module>     import string;print(string.ascii_uppercase) AttributeError: 'module' object has no attribute 'ascii_uppercase' >>>  $ echo 'from __future__ import absolute_import;import string;print(string.ascii_uppercase)' > pkg/main2.py $ python2 Python 2.7.9 (default, Dec 13 2014, 18:02:08) [GCC] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import pkg.main2 ABCDEFGHIJKLMNOPQRSTUVWXYZ >>>    In particular:  $ python2 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 1, in <module>     from __future__ import absolute_import;import string;print(string.ascii_uppercase) AttributeError: 'module' object has no attribute 'ascii_uppercase' $ python2 Python 2.7.9 (default, Dec 13 2014, 18:02:08) [GCC] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import pkg.main2 ABCDEFGHIJKLMNOPQRSTUVWXYZ >>>  $ python2 -m pkg.main2 ABCDEFGHIJKLMNOPQRSTUVWXYZ   Note that python2 pkg/main2.py has a different behaviour then launching python2 and then importing pkg.main2 (which is equivalent to using the -m switch).  If you ever want to run a submodule of a package always use the -m switch which prevents the interpreter for chaning the sys.path list and correctly handles the semantics of the submodule.  Also, I much prefer using explicit relative imports for package submodules since they provide more semantics and better error messages in case of failure.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-import",
            "python-2.5"
        ],
        "URL": "https://stackoverflow.com/questions/33743880/what-does-from-future-import-absolute-import-actually-do",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have answered a question regarding absolute imports in Python, which I thought I understood based on reading the Python 2.5 changelog and accompanying PEP. However, upon installing Python 2.5 and attempting to craft an example of properly using from __future__ import absolute_import, I realize things are not so clear.  Straight from the changelog linked above, this statement accurately summarized my understanding of the absolute import change:     Let's say you have a package directory like this:  pkg/ pkg/__init__.py pkg/main.py pkg/string.py       This defines a package named pkg containing the pkg.main and pkg.string submodules.      Consider the code in the main.py module. What happens if it executes the statement import string? In Python 2.4 and earlier, it will first look in the package's directory to perform a relative import, finds pkg/string.py, imports the contents of that file as the pkg.string module, and that module is bound to the name \"string\" in the pkg.main module's namespace.   So I created this exact directory structure:  $ ls -R .: pkg/  ./pkg: __init__.py  main.py  string.py   __init__.py and string.py are empty. main.py contains the following code:  import string print string.ascii_uppercase   As expected, running this with Python 2.5 fails with an AttributeError:  $ python2.5 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   However, further along in the 2.5 changelog, we find this (emphasis added):     In Python 2.5, you can switch import's behaviour to absolute imports using a from __future__ import absolute_import directive. This absolute-import behaviour will become the default in a future version (probably Python 2.7). Once absolute imports are the default, import string will always find the standard library's version.   I thus created pkg/main2.py, identical to main.py but with the additional future import directive. It now looks like this:  from __future__ import absolute_import import string print string.ascii_uppercase   Running this with Python 2.5, however... fails with an AttributeError:  $ python2.5 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   This pretty flatly contradicts the statement that import string will always find the std-lib version with absolute imports enabled. What's more, despite the warning that absolute imports are scheduled to become the \"new default\" behavior, I hit this same problem using both Python 2.7, with or without the __future__ directive:  $ python2.7 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'  $ python2.7 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print string.ascii_uppercase AttributeError: 'module' object has no attribute 'ascii_uppercase'   as well as Python 3.5, with or without (assuming the print statement is changed in both files):  $ python3.5 pkg/main.py Traceback (most recent call last):   File \"pkg/main.py\", line 2, in <module>     print(string.ascii_uppercase) AttributeError: module 'string' has no attribute 'ascii_uppercase'  $ python3.5 pkg/main2.py Traceback (most recent call last):   File \"pkg/main2.py\", line 3, in <module>     print(string.ascii_uppercase) AttributeError: module 'string' has no attribute 'ascii_uppercase'     I have tested other variations of this. Instead of string.py, I have created an empty module -- a directory named string containing only an empty __init__.py -- and instead of issuing imports from main.py, I have cd'd to pkg and run imports directly from the REPL. Neither of these variations (nor a combination of them) changed the results above. I cannot reconcile this with what I have read about the __future__ directive and absolute imports.  It seems to me that this is easily explicable by the following (this is from the Python 2 docs but this statement remains unchanged in the same docs for Python 3):     sys.path      (...)      As initialized upon program startup, the first item of this list, path[0], is the directory containing the script that was used to invoke the Python interpreter. If the script directory is not available (e.g. if the interpreter is invoked interactively or if the script is read from standard input), path[0] is the empty string, which directs Python to search modules in the current directory first.   So what am I missing? Why does the __future__ statement seemingly not do what it says, and what is the resolution of this contradiction between these two sections of documentation, as well as between described and actual behavior?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  This would be a great feature, but AFAIK it isn't implemented in Matplotlib and likely would be difficult to implement yourself due to the way figures are stored.  I'd suggest either (a) separate processing the data from generating the figure (which saves data with a unique name) and write a figure generating script (loading a specified file of the saved data) and editing as you see fit or (b) save as PDF/SVG/PostScript format and edit in some fancy figure editor like Adobe Illustrator (or Inkscape).  EDIT post Fall 2012: As other's pointed out below (though mentioning here as this is the accepted answer), Matplotlib since version 1.2 has had allowed you to pickle figures.  As the release notes state, it is an experimental feature and does not support saving a figure in one matplotlib version and opening in another.  It's also generally insecure to restore a pickle from an untrusted source.   For sharing/later editing plots (that require significant data processing first and may need to be tweaked months later say during peer review for a scientific publication), I still recommend the workflow of (1) have a data processing script that before generating a plot saves the processed data (that goes into your plot) into a file, and (2) have a separate plot generation script (that you adjust as necessary) to recreate the plot.  This way for each plot you can quickly run a script and re-generate it (and quickly copy over your plot settings with new data).  That said, pickling a figure could be convenient for short term/interactive/exploratory data analysis.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  As of Matplotlib 1.2, we now have experimental pickle support. Give that a go and see if it works well for your case. If you have any issues, please let us know on the Matplotlib mailing list or by opening an issue on github.com/matplotlib/matplotlib.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  I just found out how to do this. The \"experimental pickle support\" mentioned by @pelson works quite well.  Try this:  # Plot something import matplotlib.pyplot as plt fig,ax = plt.subplots() ax.plot([1,2,3],[10,-10,30])   After your interactive tweaking, save the figure object as a binary file:  import pickle pickle.dump(fig, open('FigureObject.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`   Later, open the figure and the tweaks should be saved and GUI interactivity should be present:  import pickle figx = pickle.load(open('FigureObject.fig.pickle', 'rb'))  figx.show() # Show the figure, edit it, etc.!   You can even extract the data from the plots:  data = figx.axes[0].lines[0].get_data()   (It works for lines, pcolor & imshow - pcolormesh works with some tricks to reconstruct the flattened data.)  I got the excellent tip from Saving Matplotlib Figures Using Pickle.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  Why not just send the Python script? MATLAB's .fig files require the recipient to have MATLAB to display them, so that's about equivalent to sending a Python script that requires Matplotlib to display.  Alternatively (disclaimer: I haven't tried this yet), you could try pickling the figure:  import pickle output = open('interactive figure.pickle', 'wb') pickle.dump(gcf(), output) output.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  Good question. Here is the doc text from pylab.save:     pylab no longer provides a save function, though the old pylab       function is still available as matplotlib.mlab.save (you can still       refer to it in pylab as \"mlab.save\").  However, for plain text       files, we recommend numpy.savetxt.  For saving numpy arrays,       we recommend numpy.save, and its analog numpy.load, which are       available in pylab as np.save and np.load.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Saving interactive Matplotlib figures",
        "A_Content": "  I figured out a relatively simple way (yet slightly unconventional) to save my matplotlib figures. It works like this:  import libscript  import matplotlib.pyplot as plt import numpy as np  t = np.arange(0.0, 2.0, 0.01) s = 1 + np.sin(2*np.pi*t)  #<plot> plt.plot(t, s) plt.xlabel('time (s)') plt.ylabel('voltage (mV)') plt.title('About as simple as it gets, folks') plt.grid(True) plt.show() #</plot>  save_plot(fileName='plot_01.py',obj=sys.argv[0],sel='plot',ctx=libscript.get_ctx(ctx_global=globals(),ctx_local=locals()))   with function save_plot defined like this (simple version to understand the logic):  def save_plot(fileName='',obj=None,sel='',ctx={}):     \"\"\"     Save of matplolib plot to a stand alone python script containing all the data and configuration instructions to regenerate the interactive matplotlib figure.      Parameters     ----------     fileName : [string] Path of the python script file to be created.     obj : [object] Function or python object containing the lines of code to create and configure the plot to be saved.     sel : [string] Name of the tag enclosing the lines of code to create and configure the plot to be saved.     ctx : [dict] Dictionary containing the execution context. Values for variables not defined in the lines of code for the plot will be fetched from the context.      Returns     -------     Return ``'done'`` once the plot has been saved to a python script file. This file contains all the input data and configuration to re-create the original interactive matplotlib figure.     \"\"\"     import os     import libscript      N_indent=4      src=libscript.get_src(obj=obj,sel=sel)     src=libscript.prepend_ctx(src=src,ctx=ctx,debug=False)     src='\\n'.join([' '*N_indent+line for line in src.split('\\n')])      if(os.path.isfile(fileName)): os.remove(fileName)     with open(fileName,'w') as f:         f.write('import sys\\n')         f.write('sys.dont_write_bytecode=True\\n')         f.write('def main():\\n')         f.write(src+'\\n')          f.write('if(__name__==\"__main__\"):\\n')         f.write(' '*N_indent+'main()\\n')  return 'done'   or defining function save_plot like this (better version using zip compression to produce lighter figure files):  def save_plot(fileName='',obj=None,sel='',ctx={}):      import os     import json     import zlib     import base64     import libscript      N_indent=4     level=9#0 to 9, default: 6     src=libscript.get_src(obj=obj,sel=sel)     obj=libscript.load_obj(src=src,ctx=ctx,debug=False)     bin=base64.b64encode(zlib.compress(json.dumps(obj),level))      if(os.path.isfile(fileName)): os.remove(fileName)     with open(fileName,'w') as f:         f.write('import sys\\n')         f.write('sys.dont_write_bytecode=True\\n')         f.write('def main():\\n')         f.write(' '*N_indent+'import base64\\n')         f.write(' '*N_indent+'import zlib\\n')         f.write(' '*N_indent+'import json\\n')         f.write(' '*N_indent+'import libscript\\n')         f.write(' '*N_indent+'bin=\"'+str(bin)+'\"\\n')         f.write(' '*N_indent+'obj=json.loads(zlib.decompress(base64.b64decode(bin)))\\n')         f.write(' '*N_indent+'libscript.exec_obj(obj=obj,tempfile=False)\\n')          f.write('if(__name__==\"__main__\"):\\n')         f.write(' '*N_indent+'main()\\n')  return 'done'   This makes use a module libscript of my own, which mostly relies on modules inspect and ast. I can try to share it on Github if interest is expressed (it would first require some cleanup and me to get started with Github).  The idea behind this save_plot function and libscript module is to fetch the python instructions that create the figure (using module inspect), analyze them (using module ast) to extract all variables, functions and modules import it relies on, extract these from the execution context and serialize them as python instructions (code for variables will be like t=[0.0,2.0,0.01] ... and code for modules will be like import matplotlib.pyplot as plt ...) prepended to the figure instructions. The resulting python instructions are saved as a python script whose execution will re-build the original matplotlib figure.  As you can imagine, this works well for most (if not all) matplotlib figures.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/4348733/saving-interactive-matplotlib-figures",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to save a Matplotlib figure such that it can be re-opened and have typical interaction restored? (Like the .fig format in MATLAB?)  I find myself running the same scripts many times to generate these interactive figures. Or I'm sending my colleagues multiple static PNG files to show different aspects of a plot. I'd rather send the figure object and have them interact with it themselves.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python “raise from” usage",
        "A_Content": "  The difference is that when you use from, the __cause__ attribute is set and the message states that the exception was directly caused by. If you omit the from then no __cause__ is set, but the __context__ attribute may be set as well, and the traceback then shows the context as during handling something else happened.  Setting the __context__ happens if you used raise in an exception handler; if you used raise anywhere else no __context__ is set either.  If a __cause__ is set, a __suppress_context__ = True flag is also set on the exception; when __suppress_context__ is set to True, the __context__ is ignored when printing a traceback.  When raising from a exception handler where you don't want to show the context (don't want a during handling another exception happened message), then use raise ... from None to set __suppress_context__ to True.  In other words, Python sets a context on exceptions so you can introspect where an exception was raised, letting you see if another exception was replaced by it. You can also add a cause to an exception, making the traceback explicit about the other exception (use different wording), and the context is ignored (but can still be introspected when debugging). Using raise ... from None lets you suppress the context being printed.  See the raise statement documenation:     The from clause is used for exception chaining: if given, the second expression must be another exception class or instance, which will then be attached to the raised exception as the __cause__ attribute (which is writable). If the raised exception is not handled, both exceptions will be printed:  >>> try: ...     print(1 / 0) ... except Exception as exc: ...     raise RuntimeError(\"Something bad happened\") from exc ... Traceback (most recent call last):   File \"<stdin>\", line 2, in <module> ZeroDivisionError: int division or modulo by zero  The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File \"<stdin>\", line 4, in <module> RuntimeError: Something bad happened       A similar mechanism works implicitly if an exception is raised inside an exception handler: > the previous exception is then attached as the new exception’s __context__ attribute:  >>> try: ...     print(1 / 0) ... except: ...     raise RuntimeError(\"Something bad happened\") ... Traceback (most recent call last):   File \"<stdin>\", line 2, in <module> ZeroDivisionError: int division or modulo by zero  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File \"<stdin>\", line 4, in <module> RuntimeError: Something bad happened    Also see the Built-in Exceptions documentation for details on the context and cause information attached to exceptions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "syntax",
            "exception-handling"
        ],
        "URL": "https://stackoverflow.com/questions/24752395/python-raise-from-usage",
        "A_Votes": "93",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What's the difference between raise and raise from in Python?  try:     raise ValueError except Exception as e:     raise IndexError   which yields  Traceback (most recent call last):   File \"tmp.py\", line 2, in <module>     raise ValueError ValueError  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File \"tmp.py\", line 4, in <module>     raise IndexError IndexError   and  try:     raise ValueError except Exception as e:     raise IndexError from e   which yields  Traceback (most recent call last):   File \"tmp.py\", line 2, in <module>     raise ValueError ValueError  The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File \"tmp.py\", line 4, in <module>     raise IndexError from e IndexError      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Is there special significance to 16331239353195370.0?",
        "A_Content": "  pi isn't exactly representable as Python float (same as the platform C's double type).  The closest representable approximation is used.  Here's the exact approximation in use on my box (probably the same as on your box):  >>> import math >>> (math.pi / 2).as_integer_ratio() (884279719003555, 562949953421312)   To find the tangent of that ratio, I'm going to switch to wxMaxima now:  (%i1) fpprec: 32; (%o1) 32 (%i2) tan(bfloat(884279719003555) / 562949953421312); (%o2) 1.6331239353195369755967737041529b16   So essentially identical to what you got.  The binary approximation to pi/2 used is a little bit less than the mathematical (\"infinite precision\") value of pi/2.  So you get a very large tangent instead of infinity.  The computed tan() is appropriate for the actual input!  For exactly the same kinds of reasons, e.g.,  >>> math.sin(math.pi) 1.2246467991473532e-16   doesn't return 0.  The approximation math.pi is a little bit less than pi, and the displayed result is correct given that truth.  OTHER WAYS OF SEEING math.pi  There are several ways to see the exact approximation in use:  >>> import math >>> math.pi.as_integer_ratio() (884279719003555, 281474976710656)   math.pi is exactly equal to the mathematical (\"infinite precision\") value of that ratio.  Or as an exact float in hex notation:  >>> math.pi.hex() '0x1.921fb54442d18p+1'   Or in a way most easily understood by just about everyone:  >>> import decimal >>> decimal.Decimal(math.pi) Decimal('3.141592653589793115997963468544185161590576171875')   While it may not be immediately obvious, every finite binary float is exactly representable as a finite decimal float (the reverse is not true; e.g. the decimal 0.1 is not exactly representable as a finite binary float), and the Decimal(some_float) constructor produces the exact equivalent.  Here's the true value of pi followed by the exact decimal value of math.pi, and a caret on the third line points to the first digit where they differ:  true    3.14159265358979323846264338327950288419716939937510... math.pi 3.141592653589793115997963468544185161590576171875                          ^   math.pi is the same across \"almost all\" boxes now, because almost all boxes now use the same binary floating-point format (IEEE 754 double precision).  You can use any of the ways above to confirm that on your box, or to find the precise approximation in use if your box is an exception.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "numerical-methods"
        ],
        "URL": "https://stackoverflow.com/questions/38295501/is-there-special-significance-to-16331239353195370-0",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Using import numpy as np I've noticed that   np.tan(np.pi/2)   gives the number in the title and not np.inf  16331239353195370.0   I'm curious about this number. Is it related to some system machine precision parameter? Could I have calculated it from something? (I'm thinking along the lines of something similar to sys.float_info)  EDIT: The same result is indeed reproducible  in other environments such as Java, octace, matlab... The suggested dupe does not explain why, though.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "str performance in python",
        "A_Content": "  '%s' % 100000 is evaluated by the compiler and is equivalent to a constant at run-time.  >>> import dis >>> dis.dis(lambda: str(100000))   8           0 LOAD_GLOBAL              0 (str)               3 LOAD_CONST               1 (100000)               6 CALL_FUNCTION            1               9 RETURN_VALUE         >>> dis.dis(lambda: '%s' % 100000)   9           0 LOAD_CONST               3 ('100000')               3 RETURN_VALUE           % with a run-time expression is not (significantly) faster than str:  >>> Timer('str(x)', 'x=100').timeit() 0.25641703605651855 >>> Timer('\"%s\" % x', 'x=100').timeit() 0.2169809341430664   Do note that str is still slightly slower, as @DietrichEpp said, this is because str involves lookup and function call operations, while % compiles to a single immediate bytecode:  >>> dis.dis(lambda x: str(x))   9           0 LOAD_GLOBAL              0 (str)               3 LOAD_FAST                0 (x)               6 CALL_FUNCTION            1               9 RETURN_VALUE         >>> dis.dis(lambda x: '%s' % x)  10           0 LOAD_CONST               1 ('%s')               3 LOAD_FAST                0 (x)               6 BINARY_MODULO                      7 RETURN_VALUE           Of course the above is true for the system I tested on (CPython 2.7); other implementations may differ.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "performance",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/10530315/str-performance-in-python",
        "A_Votes": "105",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    While profiling a piece of python code (python 2.6 up to 3.2), I discovered that the str method to convert an object (in my case an integer) to a string is almost an order of magnitude slower than using string formatting.  Here is the benchmark  >>> from timeit import Timer >>> Timer('str(100000)').timeit() 0.3145311339386332 >>> Timer('\"%s\"%100000').timeit() 0.03803517023435887   Does anyone know why this is the case? Am I missing something?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "str performance in python",
        "A_Content": "  One reason that comes to mind is the fact that str(100000) involves a global lookup, but \"%s\"%100000 does not.  The str global has to be looked up in the global scope.  This does not account for the entire difference:  >>> Timer('str(100000)').timeit() 0.2941889762878418 >>> Timer('x(100000)', 'x=str').timeit() 0.24904918670654297   As noted by thg435,  >>> Timer('\"%s\"%100000',).timeit() 0.034214019775390625 >>> Timer('\"%s\"%x','x=100000').timeit() 0.2940788269042969      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "performance",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/10530315/str-performance-in-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    While profiling a piece of python code (python 2.6 up to 3.2), I discovered that the str method to convert an object (in my case an integer) to a string is almost an order of magnitude slower than using string formatting.  Here is the benchmark  >>> from timeit import Timer >>> Timer('str(100000)').timeit() 0.3145311339386332 >>> Timer('\"%s\"%100000').timeit() 0.03803517023435887   Does anyone know why this is the case? Am I missing something?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  Use the environment variable PYTHONSTARTUP. From the official documentation:     If this is the name of a readable file, the Python commands in that   file are executed before the first prompt is displayed in interactive   mode. The file is executed in the same namespace where interactive   commands are executed so that objects defined or imported in it can be   used without qualification in the interactive session.   So, just create a python script with the import statement and point the environment variable to it. Having said that, remember that 'Explicit is always better than implicit', so don't rely on this behavior for production scripts.  For Ipython, see this tutorial on how to make a ipython_config file     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  For ipython, there are two ways to achieve this. Both involve ipython's configuration directory which is located in ~/.ipython.   Create a custom ipython profile. Or you can add a startup file to ~/.ipython/profile_default/startup/   For simplicity, I'd use option 2. All you have to do is place a .py or .ipy file in the ~/.ipython/profile_default/startup directory and it will automatically be executed. So you could simple place import numpy as np in a simple file and you'll have np in the namespace of your ipython prompt.  Option 2 will actually work with a custom profile, but using a custom profile will allow you to change the startup requirements and other configuration based on a particular case. However, if you'd always like np to be available to you then by all means put it in the startup directory.  For more information on ipython configuration. The docs have a much more complete explanation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  I use a ~/.startup.py file like this:  # Ned's .startup.py file print(\"(.startup.py)\") import datetime, os, pprint, re, sys, time print(\"(imported datetime, os, pprint, re, sys, time)\")  pp = pprint.pprint   Then define PYTHONSTARTUP=~/.startup.py, and Python will use it when starting a shell.  The print statements are there so when I start the shell, I get a reminder that it's in effect, and what has been imported already.  The pp shortcut is really handy too...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  As a simpler alternative to the accepted answer, on linux:  just define an alias, e.g. put alias pynp='python -i -c\"import numpy as np\"' in your ~/.bash_aliases file. You can then invoke python+numpy with pynp, and you can still use just python with python. Python scripts' behaviour is left untouched.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  While creating a custom startup script like ravenac95 suggests is the best general answer for most cases, it won't work in circumstances where you want to use a from __future__ import X. If you sometimes work in Python 2.x but want to use modern division, there is only one way to do this. Once you create a profile, edit the profile_default (For Ubuntu this is located in ~/.ipython/profile_default) and add something like the following to the bottom:  c.InteractiveShellApp.exec_lines = [     'from __future__ import division, print_function',     'import numpy as np',     'import matplotlib.pyplot as plt',     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  As ravenac95 mentioned in his answer, you can either create a custom profile or modify the default profile. This answer is quick view of Linux commands needed to import numpy as np automatically.  If you want to use a custom profile called numpy, run:  ipython profile create numpy echo 'import numpy as np' >> $(ipython locate profile numpy)/startup/00_imports.py ipython --profile=numpy   Or if you want to modify the default profile to always import numpy:  echo 'import numpy as np' >> $(ipython locate profile default)/startup/00_imports.py ipython   Check out the IPython config tutorial to read more in depth about configuring profiles. See .ipython/profile_default/startup/README to understand how the startup directory works.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Automatically import modules when entering the python or ipython interpreter",
        "A_Content": "  My default ipython invocation is  ipython --pylab --nosep --InteractiveShellApp.pylab_import_all=False   --pylab has been a ipython option for some time.  It imports numpy and (parts of) matplotlib.  I've added the --Inter... option so it does not use the * import, since I prefer to use the explicit np.....  This can be a shortcut, alias or script.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11124578/automatically-import-modules-when-entering-the-python-or-ipython-interpreter",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I find myself typing import numpy as np almost every single time I fire up the python interpreter. How do I set up the python or ipython interpreter so that numpy is automatically imported?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  Looking at the C source for the Python dict operations, you can see that they do a pretty naive (but efficient) copy.  It essentially boils down to a call to PyDict_Merge:  PyDict_Merge(PyObject *a, PyObject *b, int override)   This does the quick checks for things like if they're the same object and if they've got objects in them.  After that it does a generous one-time resize/alloc to the target dict and then copies the elements one by one.  I don't see you getting much faster than the built-in copy().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "62",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  Appearantly dict.copy is faster, as you say.  [utdmr@utdmr-arch ~]$ python -m timeit -s \"d={1:1, 2:2, 3:3}\" \"new = d.copy()\" 1000000 loops, best of 3: 0.238 usec per loop [utdmr@utdmr-arch ~]$ python -m timeit -s \"d={1:1, 2:2, 3:3}\" \"new = dict(d)\" 1000000 loops, best of 3: 0.621 usec per loop [utdmr@utdmr-arch ~]$ python -m timeit -s \"from copy import copy; d={1:1, 2:2, 3:3}\" \"new = copy(d)\" 1000000 loops, best of 3: 1.58 usec per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "54",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  Can you provide a code sample so I can see how you are using copy() and in what context?  You could use   new = dict(old)   But I dont think it will be faster.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  Depending on things you leave to speculation, you may want to wrap the original dictionary and do a sort of copy-on-write.  The \"copy\" is then a dictionary which looks up stuff in the \"parent\" dictionary, if it doesn't already contain the key --- but stuffs modifications in itself.  This assumes that you won't be modifying the original and that the extra lookups don't end up costing more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  I realise this is an old thread, but this is a high result in search engines for \"dict copy python\", and the top result for \"dict copy performance\", and I believe this is relevant.  From Python 3.7, newDict = oldDict.copy() is up to 5.5x faster than it was previously. Notably, right now, newDict = dict(oldDict) does not seem to have this performance increase.  There is a little more information here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Fast way to copy dictionary in Python",
        "A_Content": "  The measurments are dependent on the dictionary size though.  For 10000 entries  copy(d) and d.copy() are almost the same.  a = {b: b for b in range(10000)}  In [5]: %timeit copy(a) 10000 loops, best of 3: 186 µs per loop In [6]: %timeit deepcopy(a) 100 loops, best of 3: 14.1 ms per loop In [7]: %timeit a.copy() 1000 loops, best of 3: 180 µs per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "dictionary",
            "copy"
        ],
        "URL": "https://stackoverflow.com/questions/5861498/fast-way-to-copy-dictionary-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python program that works with dictionaries a lot. I have to make copies of dictionaries thousands of times. I need a copy of both the keys and the associated contents. The copy will be edited and must not be linked to the original (e.g. changes in the copy must not affect the original.)  Keys are Strings, Values are Integers (0/1).  I currently use a simple way:  newDict = oldDict.copy()   Profiling my Code shows that the copy operation takes most of the time.  Are there faster alternatives to the dict.copy() method? What would be fastest?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  figlegend may be what you're looking for: http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.figlegend  Example here: http://matplotlib.org/examples/pylab_examples/figlegend_demo.html  Another example:  plt.figlegend( lines, labels, loc = 'lower center', ncol=5, labelspacing=0. )   or:  fig.legend( lines, labels, loc = (0.5, 0), ncol=5 )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "80",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  There is also a nice function get_legend_handles_labels() you can call on the last axis (if you iterate over them) that would collect everything you need from label= arguments:  handles, labels = ax.get_legend_handles_labels() fig.legend(handles, labels, loc='upper center')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  You just have to ask for the legend once, outside of your loop.  For example, in this case I have 4 subplots, with the same lines, and a single legend.  from matplotlib.pyplot import *  ficheiros = ['120318.nc', '120319.nc', '120320.nc', '120321.nc']  fig = figure() fig.suptitle('concentration profile analysis')  for a in range(len(ficheiros)):     # dados is here defined     level = dados.variables['level'][:]      ax = fig.add_subplot(2,2,a+1)     xticks(range(8), ['0h','3h','6h','9h','12h','15h','18h','21h'])      ax.set_xlabel('time (hours)')     ax.set_ylabel('CONC ($\\mu g. m^{-3}$)')      for index in range(len(level)):         conc = dados.variables['CONC'][4:12,index] * 1e9         ax.plot(conc,label=str(level[index])+'m')      dados.close()  ax.legend(bbox_to_anchor=(1.05, 0), loc='lower left', borderaxespad=0.)          # it will place the legend on the outer right-hand side of the last axes  show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  For the automatic positioning of a single legend in a figure with many axes, like those obtained with subplots(), the following solution works really well:  plt.legend( lines, labels, loc = 'lower center', bbox_to_anchor = (0,-0.1,1,1),             bbox_transform = plt.gcf().transFigure )   With bbox_to_anchor and bbox_transform=plt.gcf().transFigure you are defining a new bounding box of the size of your figureto be a reference for loc. Using (0,-0.1,1,1) moves this bouding box slightly downwards to prevent the legend to be placed over other artists.  OBS: use this solution AFTER you use fig.set_size_inches() and BEFORE you use fig.tight_layout()     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  While rather late to the game, I'll give another solution here as this is still one of the first links to show up on google. Using matplotlib 2.2.2, this can be achieved using the gridspec feature. In the example below the aim is to have four subplots arranged in a 2x2 fashion with the legend shown at the bottom. A 'faux' axis is created at the bottom to place the legend in a fixed spot. The 'faux' axis is then turned off so only the legend shows. Result: https://i.stack.imgur.com/5LUWM.png.  import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec  #Gridspec demo fig = plt.figure() fig.set_size_inches(8,9) fig.set_dpi(100)  rows   = 17 #the larger the number here, the smaller the spacing around the legend start1 = 0 end1   = int((rows-1)/2) start2 = end1 end2   = int(rows-1)  gspec = gridspec.GridSpec(ncols=4, nrows=rows)  axes = [] axes.append(fig.add_subplot(gspec[start1:end1,0:2])) axes.append(fig.add_subplot(gspec[start2:end2,0:2])) axes.append(fig.add_subplot(gspec[start1:end1,2:4])) axes.append(fig.add_subplot(gspec[start2:end2,2:4])) axes.append(fig.add_subplot(gspec[end2,0:4]))  line, = axes[0].plot([0,1],[0,1],'b')           #add some data axes[-1].legend((line,),('Test',),loc='center') #create legend on bottommost axis axes[-1].set_axis_off()                         #don't show bottommost axis  fig.tight_layout() plt.show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "how do I make a single legend for many subplots with matplotlib?",
        "A_Content": "  This answer is a complement to @Evert's on the legend position.  My first try on @Evert's solution failed due to overlaps of the legend and the subplot's title.  In fact, the overlaps are caused by fig.tight_layout(), which changes the subplots' layout without considering the figure legend. However, fig.tight_layout() is necessary.  In order to avoid the overlaps, we can tell fig.tight_layout() to leave spaces for the figure's legend by fig.tight_layout(rect=(0,0,1,0.9)).  Description of tight_layout() parameters.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9834452/how-do-i-make-a-single-legend-for-many-subplots-with-matplotlib",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting the same type of information, but for different countries, with multiple subplots with matplotlib. That is, I have 9 plots on a 3x3 grid, all with the same for lines (of course, different values per line).   However, I have not figured out how to put a single legend (since all 9 subplots have the same lines) on the figure just once.   How do I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“pip install --editable ./” vs “python setup.py develop”",
        "A_Content": "  There is no big difference.      With pip install -e for local projects, the \"SomeProject.egg-info\" directory is created   relative to the project path. This is one advantage over just using   setup.py develop, which creates the \"egg-info\" directly relative the   current working directory.   More: docs   Also read the setuptools' docs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/30306099/pip-install-editable-vs-python-setup-py-develop",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there any significant difference between  pip install -e /path/to/mypackage   and the setuptools variant?  python /path/to/mypackage/setup.py develop      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“pip install --editable ./” vs “python setup.py develop”",
        "A_Content": "  One more difference: pip install -e uses wheel while python setup.py develop doesn't use it.   With install, you could achieve the same behavior by using pip install -e /path/to/package --no-use-wheel  More info on wheels : python wheels     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/30306099/pip-install-editable-vs-python-setup-py-develop",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any significant difference between  pip install -e /path/to/mypackage   and the setuptools variant?  python /path/to/mypackage/setup.py develop      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“pip install --editable ./” vs “python setup.py develop”",
        "A_Content": "  Another difference that may favor pip install -e is that if your project has dependencies in install_requires in setup.py, then pip install -e . installs dependencies with pip, while python setup.py develop can installs with easy_install, and may cause problems re: 'egg-info' as mentioned above. When install-requires uses dependency_links with custom git URLs, with attached egg identifiers, this can be especially annoying.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/30306099/pip-install-editable-vs-python-setup-py-develop",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any significant difference between  pip install -e /path/to/mypackage   and the setuptools variant?  python /path/to/mypackage/setup.py develop      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Converting list to *args when calling function",
        "A_Content": "  You can use the * operator before an iterable to expand it within the function call. For example:  timeseries_list = [timeseries1 timeseries2 ...] r = scikits.timeseries.lib.reportlib.Report(*timeseries_list)   (notice the * before timeseries_list)  From the python documentation:     If the syntax *expression appears in the function call, expression   must evaluate to an iterable. Elements from this iterable are treated   as if they were additional positional arguments; if there are   positional arguments x1, ..., xN, and expression evaluates to a   sequence y1, ..., yM, this is equivalent to a call with M+N positional   arguments x1, ..., xN, y1, ..., yM.   This is also covered in the python tutorial, in a section titled Unpacking argument lists, where it also shows how to do a similar thing with dictionaries for keyword arguments with the ** operator.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "arguments",
            "function-calls"
        ],
        "URL": "https://stackoverflow.com/questions/3941517/converting-list-to-args-when-calling-function",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Python, how do I convert a list to *args?  I need to know because the function  scikits.timeseries.lib.reportlib.Report.__init__(*args)   wants several time_series objects passed as *args, whereas I have a list of timeseries objects.  Any help is greatly appreciated :)     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Converting list to *args when calling function",
        "A_Content": "  yes, using *arg passing args to a function will make python unpack the values in arg and pass it to the function.  so:  >>> def printer(*args):  print args   >>> printer(2,3,4) (2, 3, 4) >>> printer(*range(2, 5)) (2, 3, 4) >>> printer(range(2, 5)) ([2, 3, 4],) >>>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "arguments",
            "function-calls"
        ],
        "URL": "https://stackoverflow.com/questions/3941517/converting-list-to-args-when-calling-function",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how do I convert a list to *args?  I need to know because the function  scikits.timeseries.lib.reportlib.Report.__init__(*args)   wants several time_series objects passed as *args, whereas I have a list of timeseries objects.  Any help is greatly appreciated :)     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Converting list to *args when calling function",
        "A_Content": "  *args just means that the function takes a number of arguments, generally of the same type.  Check out this section in the Python tutorial for more info.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "arguments",
            "function-calls"
        ],
        "URL": "https://stackoverflow.com/questions/3941517/converting-list-to-args-when-calling-function",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how do I convert a list to *args?  I need to know because the function  scikits.timeseries.lib.reportlib.Report.__init__(*args)   wants several time_series objects passed as *args, whereas I have a list of timeseries objects.  Any help is greatly appreciated :)     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python __file__ attribute absolute or relative?",
        "A_Content": "  From the documentation:     __file__ is the pathname of the file from which the module was loaded, if it was loaded from a file. The __file__ attribute is not present for C modules that are statically linked into the interpreter; for extension modules loaded dynamically from a shared library, it is the pathname of the shared library file.   From the mailing list thread linked by @kindall in a comment to the question:     I haven't tried to repro this particular example, but the reason is   that we don't want to have to call getpwd() on every import nor do we   want to have some kind of in-process variable to cache the current   directory. (getpwd() is relatively slow and can sometimes fail   outright, and trying to cache it has a certain risk of being wrong.)      What we do instead, is code in site.py that walks over the elements of   sys.path and turns them into absolute paths. However this code runs   before '' is inserted in the front of sys.path, so that the initial   value of sys.path is ''.   For the rest of this, consider sys.path not to include ''.  So, if you are outside the part of sys.path that contains the module, you'll get an absolute path. If you are inside the part of sys.path that contains the module, you'll get a relative path.  If you load a module in the current directory, and the current directory isn't in sys.path, you'll get an absolute path.  If you load a module in the current directory, and the current directory is in sys.path, you'll get a relative path.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7116889/python-file-attribute-absolute-or-relative",
        "A_Votes": "86",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm having trouble understanding __file__. From what I understand, __file__ returns the absolute path from which the module was loaded.   I'm having problem producing this: I have a abc.py with one statement print __file__, running from /d/projects/ python abc.py returns abc.py. running from /d/ returns projects/abc.py. Any reasons why?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python __file__ attribute absolute or relative?",
        "A_Content": "  __file__ is absolute since Python 3.4, except when executing a script directly using a relative path:     Module __file__ attributes (and related values) should now always contain absolute paths by default, with the sole exception of __main__.__file__ when a script has been executed directly using a relative path. (Contributed by Brett Cannon in bpo-18416.)   Not sure if it resolves symlinks though.  Example of passing a relative path:  $ python script.py      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7116889/python-file-attribute-absolute-or-relative",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having trouble understanding __file__. From what I understand, __file__ returns the absolute path from which the module was loaded.   I'm having problem producing this: I have a abc.py with one statement print __file__, running from /d/projects/ python abc.py returns abc.py. running from /d/ returns projects/abc.py. Any reasons why?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python __file__ attribute absolute or relative?",
        "A_Content": "  Late simple example:  from os import path, getcwd, chdir  def print_my_path():     print('cwd:     {}'.format(getcwd()))     print('__file__:{}'.format(__file__))     print('abspath: {}'.format(path.abspath(__file__)))  print_my_path()  chdir('..')  print_my_path()   Under Python-2.*, the second call incorrectly determines the path.abspath(__file__) based on the current directory:  cwd:     C:\\codes\\py __file__:cwd_mayhem.py abspath: C:\\codes\\py\\cwd_mayhem.py cwd:     C:\\codes __file__:cwd_mayhem.py abspath: C:\\codes\\cwd_mayhem.py   As noted by @techtonik, in Python 3.4+, this will work fine since __file__ returns an absolute path.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7116889/python-file-attribute-absolute-or-relative",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having trouble understanding __file__. From what I understand, __file__ returns the absolute path from which the module was loaded.   I'm having problem producing this: I have a abc.py with one statement print __file__, running from /d/projects/ python abc.py returns abc.py. running from /d/ returns projects/abc.py. Any reasons why?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python __file__ attribute absolute or relative?",
        "A_Content": "  With the help of the of Guido mail provided by @kindall, we can understand the standard import process as trying to find the module in each member of sys.path, and file as the result of this lookup (more details in PyMOTW Modules and Imports.). So if the module is located in an absolute path in sys.path the result is absolute, but if it is located in a relative path in sys.path the result is relative.  Now the site.py startup file takes care of delivering only absolute path in sys.path, except the initial '', so if you don't change it by other means than setting the PYTHONPATH (whose path are also made absolute, before prefixing sys.path), you will get always an absolute path, but when the module is accessed through the current directory.  Now if you trick sys.path in a funny way you can get anything.  As example if you have a sample module foo.py in /tmp/ with the code:  import sys print(sys.path) print (__file__)   If you go in /tmp you get:  >>> import foo ['', '/tmp', '/usr/lib/python3.3', ...] ./foo.py   When in  in /home/user, if you add /tmp your PYTHONPATH you get:  >>> import foo ['', '/tmp', '/usr/lib/python3.3', ...] /tmp/foo.py   Even if you add ../../tmp, it will be normalized and the result is the same.  But if instead of using PYTHONPATH you use directly some funny path you get a result as funny as the cause.  >>> import sys >>> sys.path.append('../../tmp') >>> import foo ['', '/usr/lib/python3.3', .... , '../../tmp'] ../../tmp/foo.py   Guido explains in the above cited thread, why python do not try to transform all entries in absolute paths:     we don't want to have to call getpwd() on every import ....   getpwd() is relatively slow and can sometimes fail outright,   So your path is used as it is.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7116889/python-file-attribute-absolute-or-relative",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having trouble understanding __file__. From what I understand, __file__ returns the absolute path from which the module was loaded.   I'm having problem producing this: I have a abc.py with one statement print __file__, running from /d/projects/ python abc.py returns abc.py. running from /d/ returns projects/abc.py. Any reasons why?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  >>> k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]] >>> import itertools >>> k.sort() >>> list(k for k,_ in itertools.groupby(k)) [[1, 2], [3], [4], [5, 6, 2]]   itertools often offers the fastest and most powerful solutions to this kind of problems, and is well worth getting intimately familiar with!-)  Edit: as I mention in a comment, normal optimization efforts are focused on large inputs (the big-O approach) because it's so much easier that it offers good returns on efforts. But sometimes (essentially for \"tragically crucial bottlenecks\" in deep inner loops of code that's pushing the boundaries of performance limits) one may need to go into much more detail, providing probability distributions, deciding which performance measures to optimize (maybe the upper bound or the 90th centile is more important than an average or median, depending on one's apps), performing possibly-heuristic checks at the start to pick different algorithms depending on input data characteristics, and so forth.  Careful measurements of \"point\" performance (code A vs code B for a specific input) are a part of this extremely costly process, and standard library module timeit helps here. However, it's easier to use it at a shell prompt.  For example, here's a short module to showcase the general approach for this problem, save it as nodup.py:  import itertools  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]  def doset(k, map=map, list=list, set=set, tuple=tuple):   return map(list, set(map(tuple, k)))  def dosort(k, sorted=sorted, xrange=xrange, len=len):   ks = sorted(k)   return [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]  def dogroupby(k, sorted=sorted, groupby=itertools.groupby, list=list):   ks = sorted(k)   return [i for i, _ in itertools.groupby(ks)]  def donewk(k):   newk = []   for i in k:     if i not in newk:       newk.append(i)   return newk  # sanity check that all functions compute the same result and don't alter k if __name__ == '__main__':   savek = list(k)   for f in doset, dosort, dogroupby, donewk:     resk = f(k)     assert k == savek     print '%10s %s' % (f.__name__, sorted(resk))   Note the sanity check (performed when you just do python nodup.py) and the basic hoisting technique (make constant global names local to each function for speed) to put things on equal footing.  Now we can run checks on the tiny example list:  $ python -mtimeit -s'import nodup' 'nodup.doset(nodup.k)' 100000 loops, best of 3: 11.7 usec per loop $ python -mtimeit -s'import nodup' 'nodup.dosort(nodup.k)' 100000 loops, best of 3: 9.68 usec per loop $ python -mtimeit -s'import nodup' 'nodup.dogroupby(nodup.k)' 100000 loops, best of 3: 8.74 usec per loop $ python -mtimeit -s'import nodup' 'nodup.donewk(nodup.k)' 100000 loops, best of 3: 4.44 usec per loop   confirming that the quadratic approach has small-enough constants to make it attractive for tiny lists with few duplicated values.  With a short list without duplicates:  $ python -mtimeit -s'import nodup' 'nodup.donewk([[i] for i in range(12)])' 10000 loops, best of 3: 25.4 usec per loop $ python -mtimeit -s'import nodup' 'nodup.dogroupby([[i] for i in range(12)])' 10000 loops, best of 3: 23.7 usec per loop $ python -mtimeit -s'import nodup' 'nodup.doset([[i] for i in range(12)])' 10000 loops, best of 3: 31.3 usec per loop $ python -mtimeit -s'import nodup' 'nodup.dosort([[i] for i in range(12)])' 10000 loops, best of 3: 25 usec per loop   the quadratic approach isn't bad, but the sort and groupby ones are better.  Etc, etc.  If (as the obsession with performance suggests) this operation is at a core inner loop of your pushing-the-boundaries application, it's worth trying the same set of tests on other representative input samples, possibly detecting some simple measure that could heuristically let you pick one or the other approach (but the measure must be fast, of course).  It's also well worth considering keeping a different representation for k -- why does it have to be a list of lists rather than a set of tuples in the first place?  If the duplicate removal task is frequent, and profiling shows it to be the program's performance bottleneck, keeping a set of tuples all the time and getting a list of lists from it only if and where needed, might be faster overall, for example.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  >>> k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]] >>> k = sorted(k) >>> k [[1, 2], [1, 2], [3], [4], [4], [5, 6, 2]] >>> dedup = [k[i] for i in range(len(k)) if i == 0 or k[i] != k[i-1]] >>> dedup [[1, 2], [3], [4], [5, 6, 2]]   I don't know if it's necessarily faster, but you don't have to use to tuples and sets.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  Doing it manually, creating a new k list and adding entries not found so far:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]] new_k = [] for elem in k:     if elem not in new_k:         new_k.append(elem) k = new_k print k # prints [[1, 2], [4], [5, 6, 2], [3]]   Simple to comprehend, and you preserve the order of the first occurrence of each element should that be useful, but I guess it's quadratic in complexity as you're searching the whole of new_k for each element.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  Even your \"long\" list is pretty short. Also, did you choose them to match the actual data? Performance will vary with what these data actually look like. For example, you have a short list repeated over and over to make a longer list. This means that the quadratic solution is linear in your benchmarks, but not in reality.  For actually-large lists, the set code is your best bet—it's linear (although space-hungry). The sort and groupby methods are O(n log n) and the loop in method is obviously quadratic, so you know how these will scale as n gets really big. If this is the real size of the data you are analyzing, then who cares? It's tiny.  Incidentally, I'm seeing a noticeable speedup if I don't form an intermediate list to make the set, that is to say if I replace  kt = [tuple(i) for i in k] skt = set(kt)   with  skt = set(tuple(i) for i in k)   The real solution may depend on more information: Are you sure that a list of lists is really the representation you need?     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  List of tuple and {} can be used to remove duplicates  >>> [list(tupl) for tupl in {tuple(item) for item in k }] [[1, 2], [5, 6, 2], [3], [4]] >>>       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  All the set-related solutions to this problem thus far require creating an entire set before iteration.  It is possible to make this lazy, and at the same time preserve order, by iterating the list of lists and adding to a \"seen\" set. Then only yield a list if it is not found in this tracker set.  This unique_everseen recipe is available in the itertools docs. It's also available in the 3rd party toolz library:  from toolz import unique  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]  # lazy iterator res = map(list, unique(map(tuple, k)))  print(list(res))  [[1, 2], [4], [5, 6, 2], [3]]   Note that tuple conversion is necessary because lists are not hashable.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  Another probably more generic and simpler solution is to create a dictionary keyed by the string version of the objects and getting the values() at the end:  >>> dict([(unicode(a),a) for a in [[\"A\", \"A\"], [\"A\", \"A\"], [\"A\", \"B\"]]]).values() [['A', 'B'], ['A', 'A']]   The catch is that this only works for objects whose string representation is a good-enough unique key (which is true for most native objects).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  Create a dictionary with tuple as the key, and print the keys.   create dictionary with tuple as key and index as value print list of keys of dictionary     k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]  dict_tuple = {tuple(item): index for index, item in enumerate(k)}  print [list(itm) for itm in dict_tuple.keys()]  # prints [[1, 2], [5, 6, 2], [3], [4]]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python: removing duplicates from a list of lists",
        "A_Content": "  This should work.  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]  k_cleaned = [] for ele in k:     if set(ele) not in [set(x) for x in k_cleaned]:         k_cleaned.append(ele) print(k_cleaned)  # output: [[1, 2], [4], [5, 6, 2], [3]]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2213923/python-removing-duplicates-from-a-list-of-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of lists in Python:  k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [4]]   And I want to remove duplicate elements from it. Was if it a normal list not of lists I could used set. But unfortunate that list is not hashable and can't make set of lists. Only of tuples. So I can turn all lists to tuples then use set and back to lists. But this isn't fast.  How can this done in the most efficient way?  The result of above list should be:  k = [[5, 6, 2], [1, 2], [3], [4]]   I don't care about preserve order.  Note: this question is similar but not quite what I need. Searched SO but didn't find exact duplicate.    Benchmarking:  import itertools, time   class Timer(object):     def __init__(self, name=None):         self.name = name      def __enter__(self):         self.tstart = time.time()      def __exit__(self, type, value, traceback):         if self.name:             print '[%s]' % self.name,         print 'Elapsed: %s' % (time.time() - self.tstart)   k = [[1, 2], [4], [5, 6, 2], [1, 2], [3], [5, 2], [6], [8], [9]] * 5 N = 100000  print len(k)  with Timer('set'):     for i in xrange(N):         kt = [tuple(i) for i in k]         skt = set(kt)         kk = [list(i) for i in skt]   with Timer('sort'):     for i in xrange(N):         ks = sorted(k)         dedup = [ks[i] for i in xrange(len(ks)) if i == 0 or ks[i] != ks[i-1]]   with Timer('groupby'):     for i in xrange(N):         k = sorted(k)         dedup = list(k for k, _ in itertools.groupby(k))  with Timer('loop in'):     for i in xrange(N):         new_k = []         for elem in k:             if elem not in new_k:                 new_k.append(elem)   \"loop in\" (quadratic method) fastest of all for short lists. For long lists it's faster then everyone except groupby method. Does this make sense?  For short list (the one in the code), 100000 iterations:  [set] Elapsed: 1.3900001049 [sort] Elapsed: 0.891000032425 [groupby] Elapsed: 0.780999898911 [loop in] Elapsed: 0.578000068665   For longer list (the one in the code duplicated 5 times):  [set] Elapsed: 3.68700003624 [sort] Elapsed: 3.43799996376 [groupby] Elapsed: 1.03099989891 [loop in] Elapsed: 1.85900020599      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  Okay quick fix:   which python   gives you /usr/bin/python, right? Do  which ipython   and I bet that'll be /usr/local/bin/ipython. Let's look inside:  Edit 9/7/16 -- The file now looks like this:  cat /usr/local/bin/ipython  #!/usr/bin/python  # -*- coding: utf-8 -*- import re import sys  from IPython import start_ipython  if __name__ == '__main__':     sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0])     sys.exit(start_ipython())   And mine works properly like this, but my situation isn't exactly like the OP's.    Original answer -- 9/30/13:  cat /usr/local/bin/ipython  #!/usr/bin/python # EASY-INSTALL-ENTRY-SCRIPT: 'ipython==0.12.1','console_scripts','ipython' __requires__ = 'ipython==0.12.1' import sys from pkg_resources import load_entry_point  if __name__ == '__main__':     sys.exit(         load_entry_point('ipython==0.12.1', 'console_scripts', 'ipython')()     )   Aha - open /usr/local/bin/ipython in your editor (with privileges), and change the first line to   #!/usr/local/bin/python   save, start iPython, should say it's using the version you want now.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "134",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  What about using a virtualenv? I really like it. Maybe it's not the faster way, but I think it's very clear.  When you create a virtualenv, you can specify the python path with the -p flag.  for python 2.7  $ virtualenv -p /usr/bin/python2.7 venv2.7 $ source venv2.7/bin/activate (venv2.7)$ pip install ipython (venv2.7)$ ipython   for python 3.4  $ virtualenv -p /usr/bin/python3.4 venv3.4 $ source venv3.4/bin/activate (venv3.4)$ pip install ipython (venv3.4)$ ipython      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  First, I would make sure you're using the right python.  At a command prompt type:  which python python -V   The first will tell you the path, the second tells you the Python version you're using.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  A similar method using pyenv  pyenv install 3.4.5 pyenv local 3.4.5 pip install ipython ipython   Now it will show correct version of python  Python 3.4.5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  The absolute simplest solution I could think of, which requires no fiddling with environments, installed files, or anything else, relies on the facts that   The executable ipython is actually a Python script. The IPython package is installed separately for each interpreter that you ran pip intall with.   If the version of Python you are runninig with has an IPython package installed, you can just do  /path/to/desired/python $(which ipython)   This will run the ipython script with the interpreter you want instead of the one listed in the shebang.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  extremely relevant: http://conda.pydata.org/docs/troubleshooting.html#shell-command-location.  td;lr problems are encountered because of shell 'hashing' and path variables.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  Your problem is basically making ipython use the right python.  so the fix to the problem is to make ipython use the right python (which has the libraries like scipy installed)   I have written a solution here:  How to make iPython use Python 2 instead of Python 3     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  I came across the same issue but the following was the only solution what worked for me on OSX 12, Sierra.  ipython was always launching for python 3.6 but I needed it for 2.7. I could not find an ipython startup script for 2.7, nor could I find the IPython module to execute with python -m. None of brew instally ipython pip install ipython or pip2 install ipython could get me the 2.7 version. So I got it manually.  brew install ipython@5 installs the 2.7 version from here but won't put it on your $PATH because it knows the name conflicts with another package. ln -s /usr/local/Cellar/ipython@5/5.5.0_1/bin/ipython /usr/local/bin/ipython2 will fix this and let you just run ipython2 from your shell prompt  For me, because I was serious about using ipython for 2.7, I also ran the following commands.  ln -s /usr/local/Cellar/ipython/6.2.1/bin/ipython /usr/local/bin/ipython3 rm -f /usr/local/bin/ipython ln -s /usr/local/bin/ipython2 /usr/local/bin/ipython      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ipython reads wrong python version",
        "A_Content": "  My solution is simple, stupid but work.  I use python -V to make sure what version is  $ python -V Python 2.7.10   and then make alias in .bash_profile  $ vi ~/.bash_profile   Add a line  alias ipython=\"python -m IPython\"   then you will get an ipython in python 2.7. \uD83D\uDE42  (By the way, my ipython is install via homebrew, it default will got an ipython run in python 3.)  $ brew install ipython      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/9386048/ipython-reads-wrong-python-version",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been having trouble with Python, iPython and the libraries.  The following points show the chain of the problematics.  I'm running Python 2.7 on Mac Lion.    iPython doesn't read the libraries of scipy, matplotlib, but it does read numpy.  To fix this, I tried installing Python's source code version, and it only gave me more problems since now I have two different versions: 2.7.1 and 2.7.2 I noticed that running Python, uses version 2.7.2 and does import scipy, matplotlib, and numpy, but on iPython the version is 2.7.1 which doesn't open scipy or matplotlib.    I've tried several things that I've encountered from other blogposts.  But none of them have helped, and also unfortunately I don't quite know what I'm doing with some of them.  For example: I tried uninstalling and reinstalling ipython with easy_install and pip.  I also tried reinstalling everything through homebrew, and modifying the path .bash_profile.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Extract a part of the filepath (a directory) in Python",
        "A_Content": "  import os ## first file in current dir (with full path) file = os.path.join(os.getcwd(), os.listdir(os.getcwd())[0]) file os.path.dirname(file) ## directory of file os.path.dirname(os.path.dirname(file)) ## directory of directory of file ...   And you can continue doing this as many times as necessary...  Edit: from os.path, you can use either os.path.split or os.path.basename:  dir = os.path.dirname(os.path.dirname(file)) ## dir of dir of file ## once you're at the directory level you want, with the desired directory as the final path node: dirname1 = os.path.basename(dir)  dirname2 = os.path.split(dir)[1] ## if you look at the documentation, this is exactly what os.path.basename does.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory",
            "filepath"
        ],
        "URL": "https://stackoverflow.com/questions/10149263/extract-a-part-of-the-filepath-a-directory-in-python",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to extract the name of the parent directory of a certain path. This is what it looks like: c:\\ stuff \\ directory_i_need \\ subdir \\ file. I am modifying the content of the \"file\" with something that uses the directory_i_need name in it (not the path). I have created a function that will give me a list of all the files, and then...  for path in file_list:    #directory_name = os.path.dirname(path)   # this is not what I need, that's why it is commented    directories, files = path.split('\\\\')     line_replace_add_directory = line_replace + directories      # this is what I want to add in the text, with the directory name at the end     # of the line.   How can I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Extract a part of the filepath (a directory) in Python",
        "A_Content": "  In Python 3.4 you can use the pathlib module:  >>> from pathlib import Path >>> p = Path('C:\\Program Files\\Internet Explorer\\iexplore.exe') >>> p.name 'iexplore.exe' >>> p.suffix '.exe' >>> p.root '\\\\' >>> p.parts ('C:\\\\', 'Program Files', 'Internet Explorer', 'iexplore.exe') >>> p.relative_to('C:\\Program Files') WindowsPath('Internet Explorer/iexplore.exe') >>> p.exists() True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory",
            "filepath"
        ],
        "URL": "https://stackoverflow.com/questions/10149263/extract-a-part-of-the-filepath-a-directory-in-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to extract the name of the parent directory of a certain path. This is what it looks like: c:\\ stuff \\ directory_i_need \\ subdir \\ file. I am modifying the content of the \"file\" with something that uses the directory_i_need name in it (not the path). I have created a function that will give me a list of all the files, and then...  for path in file_list:    #directory_name = os.path.dirname(path)   # this is not what I need, that's why it is commented    directories, files = path.split('\\\\')     line_replace_add_directory = line_replace + directories      # this is what I want to add in the text, with the directory name at the end     # of the line.   How can I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Extract a part of the filepath (a directory) in Python",
        "A_Content": "  First, see if you have splitunc() as an available function within os.path. The first item returned should be what you want... but I am on Linux and I do not have this function when I import os and try to use it.  Otherwise, one semi-ugly way that gets the job done is to use:  >>> pathname = \"\\\\C:\\\\mystuff\\\\project\\\\file.py\" >>> pathname '\\\\C:\\\\mystuff\\\\project\\\\file.py' >>> print pathname \\C:\\mystuff\\project\\file.py >>> \"\\\\\".join(pathname.split('\\\\')[:-2]) '\\\\C:\\\\mystuff' >>> \"\\\\\".join(pathname.split('\\\\')[:-1]) '\\\\C:\\\\mystuff\\\\project'   which shows retrieving the directory just above the file, and the directory just above that.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory",
            "filepath"
        ],
        "URL": "https://stackoverflow.com/questions/10149263/extract-a-part-of-the-filepath-a-directory-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to extract the name of the parent directory of a certain path. This is what it looks like: c:\\ stuff \\ directory_i_need \\ subdir \\ file. I am modifying the content of the \"file\" with something that uses the directory_i_need name in it (not the path). I have created a function that will give me a list of all the files, and then...  for path in file_list:    #directory_name = os.path.dirname(path)   # this is not what I need, that's why it is commented    directories, files = path.split('\\\\')     line_replace_add_directory = line_replace + directories      # this is what I want to add in the text, with the directory name at the end     # of the line.   How can I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Extract a part of the filepath (a directory) in Python",
        "A_Content": "  This is what I did to extract the piece of the directory:  for path in file_list:   directories = path.rsplit('\\\\')   directories.reverse()   line_replace_add_directory = line_replace+directories[2]   Thank you for your help.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory",
            "filepath"
        ],
        "URL": "https://stackoverflow.com/questions/10149263/extract-a-part-of-the-filepath-a-directory-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to extract the name of the parent directory of a certain path. This is what it looks like: c:\\ stuff \\ directory_i_need \\ subdir \\ file. I am modifying the content of the \"file\" with something that uses the directory_i_need name in it (not the path). I have created a function that will give me a list of all the files, and then...  for path in file_list:    #directory_name = os.path.dirname(path)   # this is not what I need, that's why it is commented    directories, files = path.split('\\\\')     line_replace_add_directory = line_replace + directories      # this is what I want to add in the text, with the directory name at the end     # of the line.   How can I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Extract a part of the filepath (a directory) in Python",
        "A_Content": "  You have to put the entire path as a parameter to os.path.split. See The docs. It doesn't work like string split.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory",
            "filepath"
        ],
        "URL": "https://stackoverflow.com/questions/10149263/extract-a-part-of-the-filepath-a-directory-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to extract the name of the parent directory of a certain path. This is what it looks like: c:\\ stuff \\ directory_i_need \\ subdir \\ file. I am modifying the content of the \"file\" with something that uses the directory_i_need name in it (not the path). I have created a function that will give me a list of all the files, and then...  for path in file_list:    #directory_name = os.path.dirname(path)   # this is not what I need, that's why it is commented    directories, files = path.split('\\\\')     line_replace_add_directory = line_replace + directories      # this is what I want to add in the text, with the directory name at the end     # of the line.   How can I do that?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "numpy.where() detailed, step-by-step explanation / examples [closed]",
        "A_Content": "  After fiddling around for a while, I figured things out, and am posting them here hoping it will help others.  Intuitively, np.where is like asking \"tell me where in this array, entries satisfy a given condition\".  >>> a = np.arange(5,10) >>> np.where(a < 8)       # tell me where in a, entries are < 8 (array([0, 1, 2]),)       # answer: entries indexed by 0, 1, 2   It can also be used to get entries in array that satisfy the condition:  >>> a[np.where(a < 8)]  array([5, 6, 7])          # selects from a entries 0, 1, 2     When a is a 2d array, np.where() returns an array of row idx's, and an array of col idx's:  >>> a = np.arange(4,10).reshape(2,3) array([[4, 5, 6],        [7, 8, 9]]) >>> np.where(a > 8) (array(1), array(2))   So that as in the 1d case, we can use np.where() to get entries in the 2d array that satisfy the condition:  >>> a[np.where(a > 8)] # selects from a entries 0, 1, 2   array([9])    Note, when a is 1d, np.where() still returns an array of row idx's and an array of col idx's but columns are of length 1, so latter is empty array.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/34667282/numpy-where-detailed-step-by-step-explanation-examples",
        "A_Votes": "147",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have trouble properly understanding numpy.where() despite reading the doc, this post and this other post.  Can someone provide step-by-step commented examples with 1D and 2D arrays?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "numpy.where() detailed, step-by-step explanation / examples [closed]",
        "A_Content": "  Here is a little more fun. I've found that very often NumPy does exactly what I wish it would do - sometimes it's faster for me to just try things than it is to read the docs. Actually a mixture of both is best.  I think your answer is fine (and it's OK to accept it if you like). This is just \"extra\".  import numpy as np  a = np.arange(4,10).reshape(2,3)  wh = np.where(a>7) gt = a>7 x  = np.where(gt)  print \"wh: \", wh print \"gt: \", gt print \"x:  \", x   gives:  wh:  (array([1, 1]), array([1, 2])) gt:  [[False False False]       [False  True  True]] x:   (array([1, 1]), array([1, 2]))   ... but:   print \"a[wh]: \", a[wh] print \"a[gt]  \", a[gt] print \"a[x]:  \", a[x]   gives:  a[wh]:  [8 9] a[gt]   [8 9] a[x]:   [8 9]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/34667282/numpy-where-detailed-step-by-step-explanation-examples",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have trouble properly understanding numpy.where() despite reading the doc, this post and this other post.  Can someone provide step-by-step commented examples with 1D and 2D arrays?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django Setup Default Logging",
        "A_Content": "  Figured it out...  You set the 'catch all' logger by referencing it with the empty string: ''.  As an example, in the following setup I have the all log events getting saved to logs/mylog.log, with the exception of django.request log events which will be saved to logs/django_request.log. Because 'propagate' is set to False for my django.request logger, the log event will never reach the the 'catch all' logger.  LOGGING = {     'version': 1,     'disable_existing_loggers': True,     'formatters': {         'standard': {             'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'         },     },     'handlers': {         'default': {             'level':'DEBUG',             'class':'logging.handlers.RotatingFileHandler',             'filename': 'logs/mylog.log',             'maxBytes': 1024*1024*5, # 5 MB             'backupCount': 5,             'formatter':'standard',         },           'request_handler': {             'level':'DEBUG',             'class':'logging.handlers.RotatingFileHandler',             'filename': 'logs/django_request.log',             'maxBytes': 1024*1024*5, # 5 MB             'backupCount': 5,             'formatter':'standard',         },     },     'loggers': {         '': {             'handlers': ['default'],             'level': 'DEBUG',             'propagate': True         },         'django.request': {             'handlers': ['request_handler'],             'level': 'DEBUG',             'propagate': False         },     } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/5438642/django-setup-default-logging",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I can't seem to figure out how to setup a \"default\" logger for my Django installation. I would like to use Django 1.3's new LOGGING setting in settings.py.  I've looked at the Django Logging Doc's example, but it looks to me like they only setup handlers which will do logging for particular loggers. In the case of their example they setup handler for the loggers named 'django','django.request', and 'myproject.custom'.  All I want to do is setup a default logging.handlers.RotatingFileHandler which will handle all loggers by default. i.e., if I make a new module somewhere in my project and it is denoted by something like: my_app_name.my_new_module, I should be able to do this and have all logging goto the rotating file logs.  # In file './my_app_name/my_new_module.py' import logging logger = logging.getLogger('my_app_name.my_new_module') logger.debug('Hello logs!') # <-- This should get logged to my RotatingFileHandler that I setup in `settings.py`!      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django Setup Default Logging",
        "A_Content": "  As you said in your answer, Chris, one option to define a default logger is to use the empty string as its key.  However, I think the intended way is to define a special logger under the root key of the logging configuration dictionary. I found this in the Python documentation:     root - this will be the configuration for the root logger. Processing of the configuration will be as for any logger, except that the propagate setting will not be applicable.   Here's the configuration from your answer changed to use the root key:  LOGGING = {     'version': 1,     'disable_existing_loggers': True,     'formatters': {         'standard': {             'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'         },     },     'handlers': {         'default': {             'level':'DEBUG',             'class':'logging.handlers.RotatingFileHandler',             'filename': 'logs/mylog.log',             'maxBytes': 1024*1024*5, # 5 MB             'backupCount': 5,             'formatter':'standard',         },           'request_handler': {             'level':'DEBUG',             'class':'logging.handlers.RotatingFileHandler',             'filename': 'logs/django_request.log',             'maxBytes': 1024*1024*5, # 5 MB             'backupCount': 5,             'formatter':'standard',         },     },     'root': {         'handlers': ['default'],         'level': 'DEBUG'     },     'loggers': {         'django.request': {             'handlers': ['request_handler'],             'level': 'DEBUG',             'propagate': False         },     } }   To be fair, I can't see any difference in behaviour between the two configurations. It appears that defining a logger with an empty string key will modify the root logger, because logging.getLogger('') will return the root logger.  The only reason I prefer 'root' over '' is that it is explicit about modifying the root logger. In case you were curious, 'root' overrides '' if you define both, just because the root entry is processed last.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/5438642/django-setup-default-logging",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I can't seem to figure out how to setup a \"default\" logger for my Django installation. I would like to use Django 1.3's new LOGGING setting in settings.py.  I've looked at the Django Logging Doc's example, but it looks to me like they only setup handlers which will do logging for particular loggers. In the case of their example they setup handler for the loggers named 'django','django.request', and 'myproject.custom'.  All I want to do is setup a default logging.handlers.RotatingFileHandler which will handle all loggers by default. i.e., if I make a new module somewhere in my project and it is denoted by something like: my_app_name.my_new_module, I should be able to do this and have all logging goto the rotating file logs.  # In file './my_app_name/my_new_module.py' import logging logger = logging.getLogger('my_app_name.my_new_module') logger.debug('Hello logs!') # <-- This should get logged to my RotatingFileHandler that I setup in `settings.py`!      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django Setup Default Logging",
        "A_Content": "  import logging logger = logging.getLogger(__name__)   after add:  logging.basicConfig(     level = logging.DEBUG,     format = '%(name)s %(levelname)s %(message)s', )   we may change format to:   format = '\"%(levelname)s:%(name)s:%(message)s\"  ',   or   format = '%(name)s %(asctime)s %(levelname)s %(message)s',      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/5438642/django-setup-default-logging",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I can't seem to figure out how to setup a \"default\" logger for my Django installation. I would like to use Django 1.3's new LOGGING setting in settings.py.  I've looked at the Django Logging Doc's example, but it looks to me like they only setup handlers which will do logging for particular loggers. In the case of their example they setup handler for the loggers named 'django','django.request', and 'myproject.custom'.  All I want to do is setup a default logging.handlers.RotatingFileHandler which will handle all loggers by default. i.e., if I make a new module somewhere in my project and it is denoted by something like: my_app_name.my_new_module, I should be able to do this and have all logging goto the rotating file logs.  # In file './my_app_name/my_new_module.py' import logging logger = logging.getLogger('my_app_name.my_new_module') logger.debug('Hello logs!') # <-- This should get logged to my RotatingFileHandler that I setup in `settings.py`!      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  subprocess.Popen does exactly what you want.  from subprocess import Popen p = Popen(['watch', 'ls']) # something long running # ... do other stuff while subprocess is running p.terminate()   (Edit to complete the answer from comments)  The Popen instance can do various other things like you can poll() it to see if it is still running, and you can communicate() with it to send it data on stdin, and wait for it to terminate.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  If you want to run many processes in parallel and then handle them when they yield results, you can use polling like in the following:  from subprocess import Popen, PIPE import time  running_procs = [     Popen(['/usr/bin/my_cmd', '-i %s' % path], stdout=PIPE, stderr=PIPE)     for path in '/tmp/file0 /tmp/file1 /tmp/file2'.split()]  while running_procs:     for proc in running_procs:         retcode = proc.poll()         if retcode is not None: # Process finished.             running_procs.remove(proc)             break         else: # No process is done, wait a bit and check again.             time.sleep(.1)             continue      # Here, `proc` has finished with return code `retcode`     if retcode != 0:         \"\"\"Error handling.\"\"\"     handle_results(proc.stdout)   The control flow there is a little bit convoluted because I'm trying to make it small -- you can refactor to your taste. :-)  This has the advantage of servicing the early-finishing requests first. If you call communicate on the first running process and that turns out to run the longest, the other running processes will have been sitting there idle when you could have been handling their results.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  What I am wondering is if this [os.system()] is the proper way to accomplish such a thing?  No.  os.system() is not the proper way.  That's why everyone says to use subprocess.    For more information, read http://docs.python.org/library/os.html#os.system     The subprocess module provides more   powerful facilities for spawning new   processes and retrieving their   results; using that module is   preferable to using this function. Use   the subprocess module. Check   especially the Replacing Older   Functions with the subprocess Module   section.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  Using pexpect [ http://www.noah.org/wiki/Pexpect ] with non-blocking readlines is another way to do this.  Pexpect solves the deadlock problems, allows you to easily run the processes in the background, and gives easy ways to have callbacks when your process spits out predefined strings, and generally makes interacting with the process much easier.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  I've had good success with the asyncproc module, which deals nicely with the output from the processes. For example:  import os from asynproc import Process myProc = Process(\"myprogram.app\")  while True:     # check to see if process has ended     poll = myProc.wait(os.WNOHANG)     if poll is not None:         break     # print any new output     out = myProc.read()     if out != \"\":         print out      ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  I have the same problem trying to connect to an 3270 terminal using the s3270 scripting software in Python. Now I'm solving the problem with an subclass of Process that I found here:  http://code.activestate.com/recipes/440554/  And here is the sample taken from file:  def recv_some(p, t=.1, e=1, tr=5, stderr=0):     if tr < 1:         tr = 1     x = time.time()+t     y = []     r = ''     pr = p.recv     if stderr:         pr = p.recv_err     while time.time() < x or r:         r = pr()         if r is None:             if e:                 raise Exception(message)             else:                 break         elif r:             y.append(r)         else:             time.sleep(max((x-time.time())/tr, 0))     return ''.join(y)  def send_all(p, data):     while len(data):         sent = p.send(data)         if sent is None:             raise Exception(message)         data = buffer(data, sent)  if __name__ == '__main__':     if sys.platform == 'win32':         shell, commands, tail = ('cmd', ('dir /w', 'echo HELLO WORLD'), '\\r\\n')     else:         shell, commands, tail = ('sh', ('ls', 'echo HELLO WORLD'), '\\n')      a = Popen(shell, stdin=PIPE, stdout=PIPE)     print recv_some(a),     for cmd in commands:         send_all(a, cmd + tail)         print recv_some(a),     send_all(a, 'exit' + tail)     print recv_some(a, e=0)     a.wait()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I run an external command asynchronously from Python?",
        "A_Content": "  Considering \"I don't have to wait for it to return\", one of the easiest solutions will be this:  subprocess.Popen( \\     [path_to_executable, arg1, arg2, ... argN],     creationflags = subprocess.CREATE_NEW_CONSOLE, ).pid   But... From what I read this is not \"the proper way to accomplish such a thing\" because of security risks created by subprocess.CREATE_NEW_CONSOLE flag.  The key things that happen here is use of subprocess.CREATE_NEW_CONSOLE to create new console and .pid (returns process ID so that you could check program later on if you want to) so that not to wait for program to finish its job.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "asynchronous",
            "subprocess",
            "scheduler"
        ],
        "URL": "https://stackoverflow.com/questions/636561/how-can-i-run-an-external-command-asynchronously-from-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to run a shell command asynchronously from a Python script. By this I mean that I want my Python script to continue running while the external command goes off and does whatever it needs to do.  I read this post:      Calling an external command in Python    I then went off and did some testing, and it looks like os.system() will do the job provided that I use & at the end of the command so that I don't have to wait for it to return. What I am wondering is if this is the proper way to accomplish such a thing? I tried commands.call() but it will not work for me because it blocks on the external command.  Please let me know if using os.system() for this is advisable or if I should try some other route.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  Use shared variable to communicate. For example like this:  import multiprocessing  def worker(procnum, return_dict):     '''worker function'''     print str(procnum) + ' represent!'     return_dict[procnum] = procnum   if __name__ == '__main__':     manager = multiprocessing.Manager()     return_dict = manager.dict()     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,return_dict))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print return_dict.values()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  I think the approach suggested by @sega_sai is the better one. But it really needs a code example, so here goes:  import multiprocessing from os import getpid  def worker(procnum):     print 'I am number %d in process %d' % (procnum, getpid())     return getpid()  if __name__ == '__main__':     pool = multiprocessing.Pool(processes = 3)     print pool.map(worker, range(5))   Which will print the return values:  I am number 0 in process 19139 I am number 1 in process 19138 I am number 2 in process 19140 I am number 3 in process 19139 I am number 4 in process 19140 [19139, 19138, 19140, 19139, 19140]   If you are familiar with map (the Python 2 built-in) this should not be too challenging. Otherwise have a look at sega_Sai's link.  Note how little code is needed. (Also note how processes are re-used).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  This example shows how to use a list of multiprocessing.Pipe instances to return strings from an arbitrary number of processes:  import multiprocessing  def worker(procnum, send_end):     '''worker function'''     result = str(procnum) + ' represent!'     print result     send_end.send(result)  def main():     jobs = []     pipe_list = []     for i in range(5):         recv_end, send_end = multiprocessing.Pipe(False)         p = multiprocessing.Process(target=worker, args=(i, send_end))         jobs.append(p)         pipe_list.append(recv_end)         p.start()      for proc in jobs:         proc.join()     result_list = [x.recv() for x in pipe_list]     print result_list  if __name__ == '__main__':     main()   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! ['0 represent!', '1 represent!', '2 represent!', '3 represent!', '4 represent!']   This solution uses fewer resources than a multiprocessing.Queue which uses   a Pipe at least one Lock a buffer a thread   or a multiprocessing.SimpleQueue which uses   a Pipe at least one Lock   It is very instructive to look at the source for each of these types.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  It seems that you should use the multiprocessing.Pool class instead and use the methods .apply() .apply_async(), map()  http://docs.python.org/library/multiprocessing.html?highlight=pool#multiprocessing.pool.AsyncResult     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  You can use the exit built-in to set the exit code of a process. It can be obtained from the exitcode attribute of the process:  import multiprocessing  def worker(procnum):     print str(procnum) + ' represent!'     exit(procnum)  if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      result = []     for proc in jobs:         proc.join()         result.append(proc.exitcode)     print result   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [0, 1, 2, 3, 4]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  For anyone else who is seeking how to get a value from a Process using Queue:  import multiprocessing  ret = {'foo': False}  def worker(queue):     ret = queue.get()     ret['foo'] = True     queue.put(ret)  if __name__ == '__main__':     queue = multiprocessing.Queue()     queue.put(ret)     p = multiprocessing.Process(target=worker, args=(queue,))     p.start()     print queue.get()  # Prints {\"foo\": True}     p.join()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  For some reason, I couldn't find a general example of how to do this with Queue anywhere (even Python's doc examples don't spawn multiple processes), so here's what I got working after like 10 tries:  def add_helper(queue, arg1, arg2): # the func called in child processes     ret = arg1 + arg2     queue.put(ret)  def multi_add(): # spawns child processes     q = Queue()     processes = []     rets = []     for _ in range(0, 100):         p = Process(target=add_helper, args=(q, 1, 2))         processes.append(p)         p.start()     for p in processes:         ret = q.get() # will block         rets.append(ret)     for p in processes:         p.join()     return rets   Queue is a blocking, thread-safe queue that you can use to store the return values from the child processes. So you have to pass the queue to each process. Something less obvious here is that you have to get() from the queue before you join the Processes or else the queue fills up and blocks everything.  Update for those who are object-oriented (tested in Python 3.4):  from multiprocessing import Process, Queue  class Multiprocessor():      def __init__(self):         self.processes = []         self.queue = Queue()      @staticmethod     def _wrapper(func, queue, args, kwargs):         ret = func(*args, **kwargs)         queue.put(ret)      def run(self, func, *args, **kwargs):         args2 = [func, self.queue, args, kwargs]         p = Process(target=self._wrapper, args=args2)         self.processes.append(p)         p.start()      def wait(self):         rets = []         for p in self.processes:             ret = self.queue.get()             rets.append(ret)         for p in self.processes:             p.join()         return rets  # tester if __name__ == \"__main__\":     mp = Multiprocessor()     num_proc = 64     for _ in range(num_proc): # queue up multiple tasks running `sum`         mp.run(sum, [1, 2, 3, 4, 5])     ret = mp.wait() # get all results     print(ret)     assert len(ret) == num_proc and all(r == 15 for r in ret)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How can I recover the return value of a function passed to multiprocessing.Process?",
        "A_Content": "  I modified vartec's answer a bit since I needed to get the error codes from the function.  (Thanks vertec!!! its an awesome trick)  This can also be done with a manager.list but I think is better to have it in a dict and store a list within it.  That way, way we keep the function and the results since we can't be sure of the order in which the list will be populated.  from multiprocessing import Process import time import datetime import multiprocessing   def func1(fn, m_list):     print 'func1: starting'     time.sleep(1)     m_list[fn] = \"this is the first function\"     print 'func1: finishing'     # return \"func1\"  # no need for return since Multiprocess doesnt return it =(  def func2(fn, m_list):     print 'func2: starting'     time.sleep(3)     m_list[fn] = \"this is function 2\"     print 'func2: finishing'     # return \"func2\"  def func3(fn, m_list):     print 'func3: starting'     time.sleep(9)     # if fail wont join the rest because it never populate the dict     # or do a try/except to get something in return.     raise ValueError(\"failed here\")     # if we want to get the error in the manager dict we can catch the error     try:         raise ValueError(\"failed here\")         m_list[fn] = \"this is third\"     except:         m_list[fn] = \"this is third and it fail horrible\"         # print 'func3: finishing'         # return \"func3\"   def runInParallel(*fns):  # * is to accept any input in list     start_time = datetime.datetime.now()     proc = []     manager = multiprocessing.Manager()     m_list = manager.dict()     for fn in fns:         # print fn         # print dir(fn)         p = Process(target=fn, name=fn.func_name, args=(fn, m_list))         p.start()         proc.append(p)     for p in proc:         p.join()  # 5 is the time out      print datetime.datetime.now() - start_time     return m_list, proc  if __name__ == '__main__':     manager, proc = runInParallel(func1, func2, func3)     # print dir(proc[0])     # print proc[0]._name     # print proc[0].name     # print proc[0].exitcode      # here you can check what did fail     for i in proc:         print i.name, i.exitcode  # name was set up in the Process line 53      # here will only show the function that worked and where able to populate the      # manager dict     for i, j in manager.items():         print dir(i)  # things you can do to the function         print i, j      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the example code below, I'd like to recover the return value of the function worker.  How can I go about doing this?  Where is this value stored?  Example Code:  import multiprocessing  def worker(procnum):     '''worker function'''     print str(procnum) + ' represent!'     return procnum   if __name__ == '__main__':     jobs = []     for i in range(5):         p = multiprocessing.Process(target=worker, args=(i,))         jobs.append(p)         p.start()      for proc in jobs:         proc.join()     print jobs   Output:  0 represent! 1 represent! 2 represent! 3 represent! 4 represent! [<Process(Process-1, stopped)>, <Process(Process-2, stopped)>, <Process(Process-3, stopped)>, <Process(Process-4, stopped)>, <Process(Process-5, stopped)>]   I can't seem to find the relevant attribute in the objects stored in jobs.  Thanks in advance, blz     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do I know if I can disable SQLALCHEMY_TRACK_MODIFICATIONS?",
        "A_Content": "  Most likely your application doesn't use the Flask-SQLAlchemy event system, so you're probably safe to turn off. You'll need to audit the code to verify--you're looking for anything that hooks into models_committed or before_models_committed. If you do find that you're using the Flask-SQLAlchemy event system, you probably should update the code to use SQLAlchemy's built-in event system instead.  To turn off the Flask-SQLAlchemy event system (and disable the warning), just add:   SQLALCHEMY_TRACK_MODIFICATIONS = False   to your app config until the default is changed (most likely in Flask-SQLAlchemy v3).    Background--here's what the warning is telling you:   Flask-SQLAlchemy has its own event notification system that gets layered on top of SQLAlchemy. To do this, it tracks modifications to the SQLAlchemy session. This takes extra resources, so the option SQLALCHEMY_TRACK_MODIFICATIONS allows you to disable the modification tracking system. Currently the option defaults to True, but in the future, that default will change to False, thereby disabling the event system.  As far as I understand, the rationale for the change is three-fold:   Not many people use Flask-SQLAlchemy's event system, but most people don't realize they can save system resources by disabling it. So a saner default is to disable it and those who want it can turn it on. The event system in Flask-SQLAlchemy has been rather buggy (see issues linked to in the pull request mentioned below), requiring additional maintenance for a feature that few people use. In v0.7, SQLAlchemy itself added a powerful event system including the ability to create custom events. Ideally, the Flask-SQLAlchemy event system should do nothing more than create a few custom SQLAlchemy event hooks and listeners, and then let SQLAlchemy itself manage the event trigger.    You can see more in the discussion around the pull request that started triggering this warning.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "sqlalchemy",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/33738467/how-do-i-know-if-i-can-disable-sqlalchemy-track-modifications",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Every time I run my app that uses Flask-SQLAlchemy I get the following warning that the SQLALCHEMY_TRACK_MODIFICATIONS option will be disabled.  /home/david/.virtualenvs/flask-sqlalchemy/lib/python3.5/site-packages/flask_sqlalchemy/__init__.py:800: UserWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.   warnings.warn('SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.')   I tried to find out what this option does, but the Flask-SQLAlchemy documentation isn't clear about what uses this tracking.     SQLALCHEMY_TRACK_MODIFICATIONS      If set to True (the default) Flask-SQLAlchemy will track modifications of objects and emit signals. This requires extra memory and can be disabled if not needed.   How do I find out if my project requires SQLALCHEMY_TRACK_MODIFICATIONS = True or if I can safely disable this feature and save memory on my server?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do I know if I can disable SQLALCHEMY_TRACK_MODIFICATIONS?",
        "A_Content": "  Jeff Widman's detailed explanation is simply perfect.  Since I had some copy'n'paste fights before getting this right I'd like to make it easier for the next one that will be in my shoes.  In your code, after:  app = Flask(__name__)   If you want to enable track modifications simply add:  app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = True   Otherwise, if you are not using this feature, you may want to change the value to False in order not to waste system resources. This will still silence the warning since you're anyway explicitly setting the config.  Here's the same snippet with False value:  app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False   Thanks to Jeff Widman for this added suggestion and details.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "sqlalchemy",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/33738467/how-do-i-know-if-i-can-disable-sqlalchemy-track-modifications",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Every time I run my app that uses Flask-SQLAlchemy I get the following warning that the SQLALCHEMY_TRACK_MODIFICATIONS option will be disabled.  /home/david/.virtualenvs/flask-sqlalchemy/lib/python3.5/site-packages/flask_sqlalchemy/__init__.py:800: UserWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.   warnings.warn('SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.')   I tried to find out what this option does, but the Flask-SQLAlchemy documentation isn't clear about what uses this tracking.     SQLALCHEMY_TRACK_MODIFICATIONS      If set to True (the default) Flask-SQLAlchemy will track modifications of objects and emit signals. This requires extra memory and can be disabled if not needed.   How do I find out if my project requires SQLALCHEMY_TRACK_MODIFICATIONS = True or if I can safely disable this feature and save memory on my server?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How do I know if I can disable SQLALCHEMY_TRACK_MODIFICATIONS?",
        "A_Content": "  The above answers look good.  However, I wanted to point out this line in the Flask-SQLAlchemy documentation because I was still getting these warnings after setting SQLALCHEMY_TRACK_MODIFICATIONS = False in my application config.  On this page:  http://flask-sqlalchemy.pocoo.org/2.3/config/     The following configuration values exist for Flask-SQLAlchemy. Flask-SQLAlchemy loads these values from your main Flask config which can be populated in various ways. Note that some of those cannot be modified after the engine was created so make sure to configure as early as possible and to not modify them at runtime.   In other words, make sure to set up your app.config before creating your Flask-SQLAlchemy database.  For example, if you are configuring your application to set SQLALCHEMY_TRACK_MODIFICATIONS = False:  from flask import Flask app = Flask(__name__) app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False  db = SQLAlchemy(app)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "sqlalchemy",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/33738467/how-do-i-know-if-i-can-disable-sqlalchemy-track-modifications",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Every time I run my app that uses Flask-SQLAlchemy I get the following warning that the SQLALCHEMY_TRACK_MODIFICATIONS option will be disabled.  /home/david/.virtualenvs/flask-sqlalchemy/lib/python3.5/site-packages/flask_sqlalchemy/__init__.py:800: UserWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.   warnings.warn('SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True to suppress this warning.')   I tried to find out what this option does, but the Flask-SQLAlchemy documentation isn't clear about what uses this tracking.     SQLALCHEMY_TRACK_MODIFICATIONS      If set to True (the default) Flask-SQLAlchemy will track modifications of objects and emit signals. This requires extra memory and can be disabled if not needed.   How do I find out if my project requires SQLALCHEMY_TRACK_MODIFICATIONS = True or if I can safely disable this feature and save memory on my server?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  Roll your own. For example, just model your tree as list of list. You should detail your specific need before people can provide better recommendation.  In response to HelloGoodbye's question, this is a sample code to iterate a tree.  def walk(node):     \"\"\" iterate tree in pre-order depth-first search order \"\"\"     yield node     for child in node.children:         for n in walk(child):             yield n   One catch is this recursive implementation is O(n log n). It works fine for all trees I have to deal with. Maybe the subgenerator in Python 3 would help.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  You can build a nice tree of dicts of dicts like this:  import collections  def Tree():     return collections.defaultdict(Tree)   It might not be exactly what you want but it's quite useful! Values are saved only in the leaf nodes. Here is an example of how it works:  >>> t = Tree() >>> t defaultdict(<function tree at 0x2142f50>, {}) >>> t[1] = \"value\" >>> t[2][2] = \"another value\" >>> t defaultdict(<function tree at 0x2142f50>, {1: 'value', 2: defaultdict(<function tree at 0x2142f50>, {2: 'another value'})})    For more information take a look at the gist.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  I found a module written by Brett Alistair Kromkamp which was not completed. I finished it and make it public on github and renamed it as treelib (original pyTree):  https://github.com/caesar0301/treelib  May it help you....     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  For a tree with ordered children, I'd usually do something kind of like this (though a little less generic, tailored to what I'm doing):  class TreeNode(list):      def __init__(self, iterable=(), **attributes):         self.attr = attributes         list.__init__(self, iterable)      def __repr__(self):         return '%s(%s, %r)' % (type(self).__name__, list.__repr__(self),             self.attr)   You could do something comparable with a dict or using DictMixin or it's more modern descendants if you want unordered children accessed by key.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  Building on the answer given above with the single line Tree using defaultdict, you can make it a class. This will allow you to set up defaults in a constructor and build on it in other ways.  class Tree(defaultdict):     def __call__(self):         return Tree(self)      def __init__(self, parent):         self.parent = parent         self.default_factory = self   This example allows you to make a back reference so that each node can refer to its parent in the tree.  >>> t = Tree(None) >>> t[0][1][2] = 3 >>> t defaultdict(defaultdict(..., {...}), {0: defaultdict(defaultdict(..., {...}), {1: defaultdict(defaultdict(..., {...}), {2: 3})})}) >>> t[0][1].parent defaultdict(defaultdict(..., {...}), {1: defaultdict(defaultdict(..., {...}), {2: 3})}) >>> t2 = t[0][1] >>> t2 defaultdict(defaultdict(..., {...}), {2: 3}) >>> t2[2] 3   Next, you could even override __setattr__ on class Tree so that when reassigning the parent, it removes it as a child from that parent. Lots of cool stuff with this pattern.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  Another good and easy to use implementation of trees in Python is pyTree: https://github.com/caesar0301/pyTree  pyTree also provides the posibility visualizing the tree:  Harry[harry] |___ Jane[jane] |    |___ Diane[diane] |         |___ George[george] |              |___ Jill[jill] |         |___ Mary[mary] |    |___ Mark[mark] |___ Bill[bill]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  It might be worth writing your own tree wrapper based on an acyclic directed graph using the  networkx library.       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  Here's something I was working on.  class Tree:     def __init__(self, value, *children):         '''Singly linked tree, children do not know who their parent is.         '''         self.value = value         self.children = tuple(children)      @property     def arguments(self):         return (self.value,) + self.children      def __eq__(self, tree):         return self.arguments == tree.arguments      def __repr__(self):         argumentStr = ', '.join(map(repr, self.arguments))         return '%s(%s)' % (self.__class__.__name__, argumentStr)   Use as such (numbers used as example values): t = Tree(1, Tree(2, Tree(4)), Tree(3, Tree(5)))     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  Would BTrees help? They're part of the Zope Object Database code. Downloading the whole ZODB package is a bit of overkill, but I hope the BTrees module would be at least somewhat separable.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Looking for a good Python Tree data structure [closed]",
        "A_Content": "  I think, from my own experience on problems with more advanced data structures, that the most important thing you can do here, is to get a good knowledge on the general concept of tress as data structures. If you understand the basic mechanism behind the concept it will be quite easy to implement the solution that fits your problem. There are a lot of good sources out there describing the concept. What \"saved\" me years ago on this particular problem was section 2.3 in \"The Art of Computer Programming\".      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a good Tree data structure class. I have come across this package, but since I am relatively new to Python (not programming), I dont know if there are any better ones out there.  I'd like to hear from the Pythonistas on here - do you have a favorite tree script that you regularly use and would recommend?  [Edit]  To clarify, by 'Tree', I mean a simple unordered tree (Hmm, thats a bit of a recursive definition - but hopefully, that clarifies things somewhat). Regarding what I need the tree for (i.e. use case). I am reading tree data from a flat file and I need to build a tree from the data and traverse all nodes in the tree.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  It sounds like you do not have django installed. You should check the directory produced by this command:   python -c \"from distutils.sysconfig import get_python_lib; print get_python_lib()\"   To see if you have the django packages in there.   If there's no django folder inside of site-packages, then you do not have django installed (at least for that version of python).   It is possible you have more than one version of python installed and django is inside of another version. You can find out all the versions of python if you type python and then press TAB. Here are all the different python's I have.   $python python            python2-config    python2.6         python2.7-config  pythonw2.5 python-config     python2.5         python2.6-config  pythonw           pythonw2.6 python2           python2.5-config  python2.7         pythonw2          pythonw2.7   You can do the above command for each version of python and look inside the site-packages directory of each to see if any of them have django installed. For example:  python2.5 -c \"from distutils.sysconfig import get_python_lib; print get_python_lib()\" python2.6 -c \"from distutils.sysconfig import get_python_lib; print get_python_lib()\"   If you happen to find django inside of say python2.6, try your original command with  python2.6 manage.py ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  sudo pip install django --upgrade    did the trick for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I got the same error and I fixed it in this manner:  I had to activate my virtual environment using the following command   source python2.7/bin/activate      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  Most probably in your manage.py the first line starts with !/usr/bin/python which means you are using the system global python rather than the one in your virtual environment.   so replace   /usr/bin/python   with   ~/projectpath/venv/bin/python   and you should be good.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  well, I faced the same error today after installing virtualenv and django. For me it was that I had used sudo (sudo pip install django) for installing django, and I was trying to run the manage.py runserver without sudo. I just added sudo and it worked. :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  Are you using a Virtual Environment with Virtual Wrapper?  Are you on a Mac?  If so try this:  Enter the following into your command line to start up the virtual environment and then work on it  1.)   source virtualenvwrapper.sh   or  source /usr/local/bin/virtualenvwrapper.sh   2.)   workon [environment name]   Note (from a newbie) - do not put brackets around your environment name     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  This problem occurs when django is not installed on your computer. When django is not installed which means django.core.management module is also is not installed. So it didn't find this module and it gives error. For solving this problem we should install django using pip. Open comand line cmd(on windows) and type as  pip install django   This command will install django in your computer. If you don't have install pip. you should install pip. Here how to install pip on windows      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I am having the same problem while running the command-      python manage.py startapp < app_name >   but problem with me is that i was running that command out of virtual environment.So just activate your virtual environment first and run the command again -     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  Okay so it goes like this:  You have created a virtual environment and django module belongs to that environment only.Since virtualenv isolates itself from everything else,hence you are seeing this.  go through this for further assistance:  http://www.swegler.com/becky/blog/2011/08/27/python-django-mysql-on-windows-7-part-i-getting-started/   1.You can switch to the directory where your virtual environment is stored and then run the django module.  2.Alternatively you can install django globally to your python->site-packages by either running pip or easy_install  Command using pip: pip install django  then do this:  import django print (django.get_version()) (depending on which version of python you use.This for python 3+ series)  and then you can run this: python manage.py runserver and check on your web browser by typing :localhost:8000 and you should see django powered page.  Hope this helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  In case this is helpful to others... I had this issue because my virtualenv defaulted to python2.7 and I was calling Django using Python3 while using Ubuntu.    to check which python my virtualenv was using:  $ which python3 >> /usr/bin/python3   created new virtualenv with python3 specified (using virtualenv wrapper https://virtualenvwrapper.readthedocs.org/en/latest/):  $ mkvirtualenv --python=/usr/bin/python3 ENV_NAME   the python path should now point to the virtualenv python:  $ which python3 >> /home/user/.virtualenvs/ENV_NAME/bin/python3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I experience the same thing and this is what I do.  First my installation of      pip install -r requirements.txt   is not on my active environment. So I did is activate my environment then run again the      pip install -r requirements.txt      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  This also happens if you change the directory structure of your python project (I did this, and then puzzled over the change in behavior).  If you do so, you'll need to change a line in your /bin/activate file.  So, say your project was at   /User/me/CodeProjects/coolApp/   and your activate file is at  /User/me/CodeProjects/coolApp/venv/bin/activate   when you set up your project, then you changed your project to   /User/me/CodeProjects/v1-coolApp/   or something.  You would then need to open   /User/me/CodeProjects/v1-coolApp/venv/bin/activate   find the line where it says  VIRTUAL_ENV=\"/User/me/CodeProjects/coolApp\" export VIRTUAL_ENV   and change it to  VIRTUAL_ENV=\"/User/me/CodeProjects/v1-coolApp\"   before reactivating     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  In my case, I am using Ubuntu. The problem can be that I don't have the permission to write to that folder as a normal user. You can simply add the sudo before your command and it should work perfectly. In my case sudo python manage.py syncdb.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I had the same problem and following worked good, you should navigate main folder in your project than type:  source bin/activate       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  had the same problem.run command 'python manage.py migrate' as root. works fine with root access (sudo python manage.py migrate )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I had the same issue and the reason I was getting this message was because I was doing \"manage.py runserver\" whereas doing \"python manage.py runserver\" fixed it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  My case I used pyCharm 5 on mac. I also had this problem and after running this command my problem was solved  sudo pip install django --upgrade       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  You must choose your Project first before running the server , type this workon your_project_name then  python manage.py runserver     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  You can try it like so : python3 manage.py migrate (make sur to be in the src/ directory)   You can also try with pip install -r requirements.txt (make sur you see the requirements.txt file when you type ls after the migrate  If after all it still won't work try pip install django  Hope it helps     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  File and Directory ownership conflict will cause issues here.  Make sure the ownership of the directories and files under the project are to the current user.  (You can change them using the chown command with the -R option.) Try rerunning the command: this solved the problem for me when running through the \"First Django App\" sample:  python manage.py startapp polls      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django - “no module named django.core.management”",
        "A_Content": "  I got the same problem trying to use the python manage.py runserver. In my case I just use sudo su. Use the terminal as a root and  try it again an it works partially. So I use  python manage.py migrate comand and it fix it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/14013728/django-no-module-named-django-core-management",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I get the following error when trying to run Django from the command line.  File manage.py, line 8, in <module>      from django.core.management import execute_from_command_line ImportError: No module named django.core.management   Any ideas on how to solve this?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  You could try pipdeptree which displays dependencies as a tree structure e.g.:   $ pipdeptree Lookupy==0.1 wsgiref==0.1.2 argparse==1.2.1 psycopg2==2.5.2 Flask-Script==0.6.6   - Flask [installed: 0.10.1]     - Werkzeug [required: >=0.7, installed: 0.9.4]     - Jinja2 [required: >=2.4, installed: 2.7.2]       - MarkupSafe [installed: 0.18]     - itsdangerous [required: >=0.21, installed: 0.23] alembic==0.6.2   - SQLAlchemy [required: >=0.7.3, installed: 0.9.1]   - Mako [installed: 0.9.1]     - MarkupSafe [required: >=0.9.2, installed: 0.18] ipython==2.0.0 slugify==0.0.1 redis==2.9.1   To get it run:  pip install pipdeptree    EDIT: as noted by @Esteban in the comments you can also list the tree in reverse with -r or for a single package with -p <package_name> so to find what installed Werkzeug you could run:  $ pipdeptree -r -p Werkzeug Werkzeug==0.11.15   - Flask==0.12 [requires: Werkzeug>=0.7]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  The pip show command will show what packages are required for the specified package (note that the specified package must already be installed):  $ pip show specloud  Package: specloud Version: 0.4.4 Requires: nose figleaf pinocchio   pip show was introduced in pip version 1.4rc5     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  As I recently said on a hn thread, I'll recommend the following:  Have a commented requirements.txt file with your main dependencies:    ## this is needed for whatever reason package1   Install your dependencies: pip install -r requirements.txt. Now you get the full list of your dependencies with pip freeze -r requirements.txt:  ## this is needed for whatever reason package1==1.2.3  ## The following requirements were added by pip --freeze: package1-dependency1==1.2.3 package1-dependency1==1.2.3   This allows you to keep your file structure with comments, nicely separating your dependencies from the dependencies of your dependencies. This way you'll have a much nicer time the day you need to remove one of them :)  Note the following:   You can have a clean requirements.raw with version control to rebuild your full requirements.txt. Beware of git urls being replaced by egg names in the process. The dependencies of your dependencies are still alphabetically sorted so you don't directly know which one was required by which package but at this point you don't really need it. Use pip install --no-install <package_name> to list specific requirements. Use virtualenv if you don't.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  You may also use a one line command which pipes the packages in requirements to pip show.  cut -d'=' -f1 requirements.txt | xargs pip show      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  First of all pip freeze displays all currently installed packages Python, not necessarily using PIP.  Secondly Python packages do contain the information about dependent packages as well as required versions. You can see the dependencies of particular pkg using the methods described here. When you're upgrading a package the installer script like PIP will handle the upgrade of dependencies for you.  To solve updating of packages i recommend using PIP requirements files. You can define what packages and versions you need, and install them at once using pip install.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  I wrote a quick script to solve this problem. The following script will display the parent (dependant) package(s) for any given package. This way you can be sure it is safe to upgrade or install any particular package. It can be used as follows: dependants.py PACKAGENAME  #!/usr/bin/python3 # -*- coding: utf-8 -*-  \"\"\"Find dependants of a Python package\"\"\"  import logging import pip import pkg_resources import sys  __program__ = 'dependants.py'   def get_dependants(target_name):     for package in pip.get_installed_distributions():         for requirement_package in package.requires():             requirement_name = requirement_package.project_name             if requirement_name == target_name:                 package_name = package.project_name                 yield package_name   # configure logging logging.basicConfig(format='%(levelname)s: %(message)s',                     level=logging.INFO)  try:     target_name = sys.argv[1] except IndexError:     logging.error(\"missing package name\")     sys.exit(1)  try:     pkg_resources.get_distribution(target_name) except pkg_resources.DistributionNotFound:     logging.error(\"'%s' is not a valid package\", target_name)     sys.exit(1)  print(list(get_dependants(target_name)))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Identifying the dependency relationship for python packages installed with pip",
        "A_Content": "  (workaround, not true answer)  Had the same problem, with lxml not installing and me wanting to know who needed lxml.  Not who lxml needed.  Ended up bypassing the issue by.   noting where my site packages were being put. go there and recursive grep for the import (the last grep's --invert-match serves to remove lxml's own files from consideration).   Yes, not an answer as to how to use pip to do it, but I didn't get any success out of the suggestions here, for whatever reason.   site-packages me$ egrep -i --include=*.py  -r -n lxml . | grep import | grep --invert-match /lxml/      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9232568/identifying-the-dependency-relationship-for-python-packages-installed-with-pip",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I do a pip freeze I see large number of Python packages that I didn't explicitly install, e.g.  $ pip freeze Cheetah==2.4.3 GnuPGInterface==0.3.2 Landscape-Client==11.01 M2Crypto==0.20.1 PAM==0.4.2 PIL==1.1.7 PyYAML==3.09 Twisted-Core==10.2.0 Twisted-Web==10.2.0 (etc.)   Is there a way for me to determine why pip installed these particular dependent packages?  In other words, how do I determine the parent package that had these packages as dependencies?    For example, I might want to use Twisted and I don't want to depend on a package until I know more about not accidentally uninstalling it or upgrading it.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  The grouper()  recipe from the itertools documentation's recipes comes close to what you want:  def grouper(n, iterable, fillvalue=None):     \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"     args = [iter(iterable)] * n     return izip_longest(fillvalue=fillvalue, *args)   It will fill up the last chunk with a fill value, though.  A less general solution that only works on sequences but does handle the last chunk as desired is  [my_list[i:i + chunk_size] for i in range(0, len(my_list), chunk_size)]   Finally, a solution that works on general iterators an behaves as desired is  def grouper(n, iterable):     it = iter(iterable)     while True:        chunk = tuple(itertools.islice(it, n))        if not chunk:            return        yield chunk      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  Although OP asks function to return chunks as list or tuple, in case you need to return iterators, then Sven Marnach's solution can be modified:  def grouper_it(n, iterable):     it = iter(iterable)     while True:         chunk_it = itertools.islice(it, n)         try:             first_el = next(chunk_it)         except StopIteration:             return         yield itertools.chain((first_el,), chunk_it)   Some benchmarks: http://pastebin.com/YkKFvm8b  It will be slightly more efficient only if your function iterates through elements in every chunk.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  This will work on any iterable. It returns generator of generators (for full flexibility). I now realize that it's basically the same as @reclosedevs solution, but without the fluff. No need for try...except as the StopIteration propagates up, which is what we want.    The next(iterable) call is needed to raise the StopIteration when the iterable is empty, since islice will continue spawning empty generators forever if you let it.  It's better because it's only two lines long, yet easy to comprehend.   def grouper(iterable, n):     while True:         yield itertools.chain((next(iterable),), itertools.islice(iterable, n-1))   Note that next(iterable) is put into a tuple. Otherwise, if next(iterable) itself were iterable, then itertools.chain would flatten it out. Thanks to Jeremy Brown for pointing out this issue.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  I was working on something today and came up with what I think is a simple solution. It is similar to jsbueno's answer, but I believe his would yield empty groups when the length of iterable is divisible by n. My answer does a simple check when the iterable is exhausted.  def chunk(iterable, chunk_size):     \"\"\"Generate sequences of `chunk_size` elements from `iterable`.\"\"\"     iterable = iter(iterable)     while True:         chunk = []         try:             for _ in range(chunk_size):                 chunk.append(iterable.next())             yield chunk         except StopIteration:             if chunk:                 yield chunk             break      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  Here's one that returns lazy chunks; use map(list, chunks(...)) if you want lists.  from itertools import islice, chain from collections import deque  def chunks(items, n):     items = iter(items)     for first in items:         chunk = chain((first,), islice(items, n-1))         yield chunk         deque(chunk, 0)  if __name__ == \"__main__\":     for chunk in map(list, chunks(range(10), 3)):         print chunk      for i, chunk in enumerate(chunks(range(10), 3)):         if i % 2 == 1:             print \"chunk #%d: %s\" % (i, list(chunk))         else:             print \"skipping #%d\" % i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  A succinct implementation is:  chunker = lambda iterable, n: (ifilterfalse(lambda x: x == (), chunk) for chunk in (izip_longest(*[iter(iterable)]*n, fillvalue=())))   This works because [iter(iterable)]*n is a list containing the same iterator n times; zipping over that takes one item from each iterator in the list, which is the same iterator, with the result that each zip-element contains a group of n items.   izip_longest is needed to fully consume the underlying iterable, rather than iteration stopping when the first exhausted iterator is reached, which chops off any remainder from iterable. This results in the need to filter out the fill-value. A slightly more robust implementation would therefore be:  def chunker(iterable, n):     class Filler(object): pass     return (ifilterfalse(lambda x: x is Filler, chunk) for chunk in (izip_longest(*[iter(iterable)]*n, fillvalue=Filler)))   This guarantees that the fill value is never an item in the underlying iterable. Using the definition above:  iterable = range(1,11)  map(tuple,chunker(iterable, 3)) [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10,)]  map(tuple,chunker(iterable, 2)) [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]  map(tuple,chunker(iterable, 4)) [(1, 2, 3, 4), (5, 6, 7, 8), (9, 10)]     This implementation almost does what you want, but it has issues:  def chunks(it, step):   start = 0   while True:     end = start+step     yield islice(it, start, end)     start = end   (The difference is that because islice does not raise StopIteration or anything else on calls that go beyond the end of it this will yield forever; there is also the slightly tricky issue that the islice results must be consumed before this generator is iterated).  To generate the moving window functionally:  izip(count(0, step), count(step, step))   So this becomes:  (it[start:end] for (start,end) in izip(count(0, step), count(step, step)))   But, that still creates an infinite iterator. So, you need takewhile (or perhaps something else might be better) to limit it:  chunk = lambda it, step: takewhile((lambda x: len(x) > 0), (it[start:end] for (start,end) in izip(count(0, step), count(step, step))))  g = chunk(range(1,11), 3)  tuple(g) ([1, 2, 3], [4, 5, 6], [7, 8, 9], [10])        ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  \"Simpler is better than complex\" - a straightforward generator a few lines long can do the job. Just place it in some utilities module or so:  def grouper (iterable, n):     iterable = iter(iterable)     count = 0     group = []     while True:         try:             group.append(next(iterable))             count += 1             if count % n == 0:                 yield group                 group = []         except StopIteration:             yield group             break      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  I forget where I found the inspiration for this.  I've modified it a little to work with MSI GUID's in the Windows Registry:  def nslice(s, n, truncate=False, reverse=False):     \"\"\"Splits s into n-sized chunks, optionally reversing the chunks.\"\"\"     assert n > 0     while len(s) >= n:         if reverse: yield s[:n][::-1]         else: yield s[:n]         s = s[n:]     if len(s) and not truncate:         yield s   reverse doesn't apply to your question, but it's something I use extensively with this function.  >>> [i for i in nslice([1,2,3,4,5,6,7], 3)] [[1, 2, 3], [4, 5, 6], [7]] >>> [i for i in nslice([1,2,3,4,5,6,7], 3, truncate=True)] [[1, 2, 3], [4, 5, 6]] >>> [i for i in nslice([1,2,3,4,5,6,7], 3, truncate=True, reverse=True)] [[3, 2, 1], [6, 5, 4]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Iterate an iterator by chunks (of n) in Python? [duplicate]",
        "A_Content": "  Here you go.  def chunksiter(l, chunks):     i,j,n = 0,0,0     rl = []     while n < len(l)/chunks:                 rl.append(l[i:j+chunks])                 i+=chunks         j+=j+chunks                 n+=1     return iter(rl)   def chunksiter2(l, chunks):     i,j,n = 0,0,0     while n < len(l)/chunks:                 yield l[i:j+chunks]         i+=chunks         j+=j+chunks                 n+=1   Examples:  for l in chunksiter([1,2,3,4,5,6,7,8],3):     print(l)  [1, 2, 3] [4, 5, 6] [7, 8]  for l in chunksiter2([1,2,3,4,5,6,7,8],3):     print(l)  [1, 2, 3] [4, 5, 6] [7, 8]   for l in chunksiter2([1,2,3,4,5,6,7,8],5):     print(l)  [1, 2, 3, 4, 5] [6, 7, 8]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python generator that groups another iterable into groups of N [duplicate]                                        9 answers                                          Can you think of a nice way (maybe with itertools) to split an iterator into chunks of given size?  Therefore l=[1,2,3,4,5,6,7] with chunks(l,3) becomes an iterator [1,2,3], [4,5,6], [7]  I can think of a small program to do that but not a nice way with maybe itertools.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“Too many values to unpack” Exception",
        "A_Content": "  That exception means that you are trying to unpack a tuple, but the tuple has too many values with respect to the number of target variables. For example: this work, and prints 1, then 2, then 3  def returnATupleWithThreeValues():     return (1,2,3) a,b,c = returnATupleWithThreeValues() print a print b print c   But this raises your error  def returnATupleWithThreeValues():     return (1,2,3) a,b = returnATupleWithThreeValues() print a print b   raises  Traceback (most recent call last):   File \"c.py\", line 3, in ?     a,b = returnATupleWithThreeValues() ValueError: too many values to unpack   Now, the reason why this happens in your case, I don't know, but maybe this answer will point you in the right direction.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1479776/too-many-values-to-unpack-exception",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm working on a project in Django and I've just started trying to extend the User model in order to make user profiles.   Unfortunately, I've run into a problem: Every time I try to get the user's profile inside of a template (user.get_template.lastIP, for example), I get the following error:   Environment:  Request Method: GET Request URL: http://localhost:8000/ Django Version: 1.1 Python Version: 2.6.1  Template error: In template /path/to/base.tpl, error at line 19    Caught an exception while rendering: too many values to unpack  19 :                Hello, {{user.username}} ({{ user.get_profile.rep}}). How's it goin? Logout   Exception Type: TemplateSyntaxError at / Exception Value: Caught an exception while rendering: too many values to unpack    Any ideas as to what's going on or what I'm doing wrong?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“Too many values to unpack” Exception",
        "A_Content": "  try unpacking in one variable,  python will handle it as a list,  then unpack from the list  def returnATupleWithThreeValues():     return (1,2,3) a = returnATupleWithThreeValues() # a is a list (1,2,3) print a[0] # list[0] = 1 print a[1] # list[1] = 2 print a[2] # list[2] = 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1479776/too-many-values-to-unpack-exception",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a project in Django and I've just started trying to extend the User model in order to make user profiles.   Unfortunately, I've run into a problem: Every time I try to get the user's profile inside of a template (user.get_template.lastIP, for example), I get the following error:   Environment:  Request Method: GET Request URL: http://localhost:8000/ Django Version: 1.1 Python Version: 2.6.1  Template error: In template /path/to/base.tpl, error at line 19    Caught an exception while rendering: too many values to unpack  19 :                Hello, {{user.username}} ({{ user.get_profile.rep}}). How's it goin? Logout   Exception Type: TemplateSyntaxError at / Exception Value: Caught an exception while rendering: too many values to unpack    Any ideas as to what's going on or what I'm doing wrong?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“Too many values to unpack” Exception",
        "A_Content": "  This problem looked familiar so I thought I'd see if I could replicate from the limited amount of information.  A quick search turned up an entry in James Bennett's blog here which mentions that when working with the UserProfile to extend the User model a common mistake in settings.py can cause Django to throw this error.    To quote the blog entry:     The value of the setting is not \"appname.models.modelname\", it's just \"appname.modelname\". The reason is that Django is not using this to do a direct import; instead, it's using an internal model-loading function which only wants the name of the app and the name of the model. Trying to do things like \"appname.models.modelname\" or \"projectname.appname.models.modelname\" in the AUTH_PROFILE_MODULE setting will cause Django to blow up with the dreaded \"too many values to unpack\" error, so make sure you've put \"appname.modelname\", and nothing else, in the value of AUTH_PROFILE_MODULE.   If the OP had copied more of the traceback I would expect to see something like the one below which I was able to duplicate by adding \"models\" to my AUTH_PROFILE_MODULE setting.  TemplateSyntaxError at /  Caught an exception while rendering: too many values to unpack  Original Traceback (most recent call last):   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/template/debug.py\", line 71, in render_node     result = node.render(context)   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/template/debug.py\", line 87, in render     output = force_unicode(self.filter_expression.resolve(context))   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/template/__init__.py\", line 535, in resolve     obj = self.var.resolve(context)   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/template/__init__.py\", line 676, in resolve     value = self._resolve_lookup(context)   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/template/__init__.py\", line 711, in _resolve_lookup     current = current()   File \"/home/brandon/Development/DJANGO_VERSIONS/Django-1.0/django/contrib/auth/models.py\", line 291, in get_profile     app_label, model_name = settings.AUTH_PROFILE_MODULE.split('.') ValueError: too many values to unpack   This I think is one of the few cases where Django still has a bit of import magic that tends to cause confusion when a small error doesn't throw the expected exception.  You can see at the end of the traceback that I posted how using anything other than the form \"appname.modelname\" for the AUTH_PROFILE_MODULE would cause the line \"app_label, model_name = settings.AUTH_PROFILE_MODULE.split('.')\"  to throw the \"too many values to unpack\" error.  I'm 99% sure that this was the original problem encountered here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1479776/too-many-values-to-unpack-exception",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a project in Django and I've just started trying to extend the User model in order to make user profiles.   Unfortunately, I've run into a problem: Every time I try to get the user's profile inside of a template (user.get_template.lastIP, for example), I get the following error:   Environment:  Request Method: GET Request URL: http://localhost:8000/ Django Version: 1.1 Python Version: 2.6.1  Template error: In template /path/to/base.tpl, error at line 19    Caught an exception while rendering: too many values to unpack  19 :                Hello, {{user.username}} ({{ user.get_profile.rep}}). How's it goin? Logout   Exception Type: TemplateSyntaxError at / Exception Value: Caught an exception while rendering: too many values to unpack    Any ideas as to what's going on or what I'm doing wrong?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“Too many values to unpack” Exception",
        "A_Content": "  Most likely there is an error somewhere in the get_profile() call. In your view, before you return the request object, put this line:  request.user.get_profile()   It should raise the error, and give you a more detailed traceback, which you can then use to further debug.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1479776/too-many-values-to-unpack-exception",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a project in Django and I've just started trying to extend the User model in order to make user profiles.   Unfortunately, I've run into a problem: Every time I try to get the user's profile inside of a template (user.get_template.lastIP, for example), I get the following error:   Environment:  Request Method: GET Request URL: http://localhost:8000/ Django Version: 1.1 Python Version: 2.6.1  Template error: In template /path/to/base.tpl, error at line 19    Caught an exception while rendering: too many values to unpack  19 :                Hello, {{user.username}} ({{ user.get_profile.rep}}). How's it goin? Logout   Exception Type: TemplateSyntaxError at / Exception Value: Caught an exception while rendering: too many values to unpack    Any ideas as to what's going on or what I'm doing wrong?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "“Too many values to unpack” Exception",
        "A_Content": "  This happens to me when I'm using Jinja2 for templates. The problem can be solved by running the development server using the runserver_plus command from django_extensions.   It uses the werkzeug debugger which also happens to be a lot better and has a very nice interactive debugging console. It does some ajax magic to launch a python shell at any frame (in the call stack) so you can debug.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1479776/too-many-values-to-unpack-exception",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a project in Django and I've just started trying to extend the User model in order to make user profiles.   Unfortunately, I've run into a problem: Every time I try to get the user's profile inside of a template (user.get_template.lastIP, for example), I get the following error:   Environment:  Request Method: GET Request URL: http://localhost:8000/ Django Version: 1.1 Python Version: 2.6.1  Template error: In template /path/to/base.tpl, error at line 19    Caught an exception while rendering: too many values to unpack  19 :                Hello, {{user.username}} ({{ user.get_profile.rep}}). How's it goin? Logout   Exception Type: TemplateSyntaxError at / Exception Value: Caught an exception while rendering: too many values to unpack    Any ideas as to what's going on or what I'm doing wrong?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to surround selected text in PyCharm like with Sublime Text",
        "A_Content": "  I think you want something like  Settings | Editor | General | Smart Keys -> Surround selection on typing quote or brace     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sublimetext2",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/27152414/how-to-surround-selected-text-in-pycharm-like-with-sublime-text",
        "A_Votes": "171",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a way to configure PyCharm to be able to surround selected code with parenthesis by just typing on the parenthesis key, like when we use SublimText 2?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to surround selected text in PyCharm like with Sublime Text",
        "A_Content": "  PyCharm 4.0 has the option to Surround With..., by selecting your code snippet and pressing   ctrl + alt + T  or on Mac: ⌥ + ⌘ + T  Option 1 should provide you with the functionality you are looking for:       ",
        "Language": "Python",
        "Tags": [
            "python",
            "sublimetext2",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/27152414/how-to-surround-selected-text-in-pycharm-like-with-sublime-text",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to configure PyCharm to be able to surround selected code with parenthesis by just typing on the parenthesis key, like when we use SublimText 2?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  Are you sure you are using Python 3.x? The syntax isn't available in Python 2.x because print is still a statement.  print(\"foo\" % bar, end=\" \")   in Python 2.x is identical to  print (\"foo\" % bar, end=\" \")   or  print \"foo\" % bar, end=\" \"   i.e. as a call to print with a tuple as argument.  That's obviously bad syntax (literals don't take keyword arguments). In Python 3.x print is an actual function, so it takes keyword arguments, too.  The correct idiom in Python 2.x for end=\" \" is:  print \"foo\" % bar,   (note the final comma, this makes it end the line with a space rather than a linebreak)  If you want more control over the output, consider using sys.stdout directly. This won't do any special magic with the output.  Of course in somewhat recent versions of Python 2.x (2.5 should have it, not sure about 2.4), you can use the __future__ module to enable it in your script file:  from __future__ import print_function   The same goes with unicode_literals and some other nice things (with_statement, for example). This won't work in really old versions (i.e. created before the feature was introduced) of Python 2.x, though.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  How about this:  #Only for use in Python 2.6.0a2 and later from __future__ import print_function   This allows you to use the Python 3.0 style print function without having to hand-edit all occurrences of print :)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  In python 2.7 here is how you do it   mantra = 'Always look on the bright side of life' for c in mantra: print c,  #output A l w a y s   l o o k   o n   t h e   b r i g h t   s i d e   o f   l i f e   In python 3.x  myjob= 'hacker' for c in myjob: print (c, end='') #output  h a c k e r       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  First of all, you're missing a quote at the beginning but this is probably a copy/paste error.  In Python 3.x, the end=' ' part will place a space after the displayed string instead of a newline. To do the same thing in Python 2.x, you'd put a comma at the end:  print \"Building internam Index for %d tile(s) ...\" % len(inputTiles),      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  I think he's using Python 3.0 and you're using Python 2.6.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  It looks like you're just missing an opening double-quote.  Try:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  This is just a version thing. Since Python 3.x the print is actually a function, so it now takes arguments like any normal function.  The end=' ' is just to say that you want a space after the end of the statement instead of a new line character. In Python 2.x you would have to do this by placing a comma at the end of the print statement.  For example, when in a Python 3.x environment:  while i<5:     print(i)     i=i+1   Will give the following output:  0 1 2 3 4   Where as:  while i<5:     print(i, end = ' ')     i=i+1   Will give as output:  0 1 2 3 4      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  I think the author probably meant:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   He's missing an initial quote after print(.  Note that as of Python 3.0, print is a function as opposed to a statement, if you're using older versions of Python the equivalent would be:  print \"Building internam Index for %d tile(s) ...\" % len(inputTiles)   The end parameter means that the line gets ' ' at the end rather than a newline character. The equivalent in earlier versions of Python is:  print \"Building internam Index for %d tile(s) ...\" % len(inputTiles),   (thanks Ignacio).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  For python 2.7 I had the same issue  Just use \"from __future__ import print_function\" without quotes to resolve this issue.This Ensures Python 2.6 and later Python 2.x can use Python 3.x print function.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  Try this one if you are working with python 2.7:  from __future__ import print_function      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  Even I was getting that same error today. And I've experienced an interesting thing. If you're using python 3.x and still getting the error, it might be a reason:     You have multiple python versions installed  on same drive. And when   you're presing the f5 button the python shell window (of ver. < 3.x)   pops up   I was getting same error today, and noticed that thing. Trust me, when I execute my code from proper shell window (of ver. 3.x), I got satisfactory results     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  USE :: python3 filename.py   I had such error , this occured because i have two versions of python installed on my drive namely python2.7 and python3 . Following was my code :  #!usr/bin/python  f = open('lines.txt') for line in f.readlines():         print(line,end ='')   when i run it by the  command python lines.py I got the following error  #!usr/bin/python  f = open('lines.txt') for line in f.readlines():         print(line,end ='')   when I run it by the command python3 lines.py I executed successfully     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "python print end=' '",
        "A_Content": "  we need to import a header before using end='', as it is not included in the python's normal runtime.  from __future__ import print_function   it shall work perfectly now     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2456148/python-print-end",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this python script where I need to run gdal_retile.py  but I get an exception on this line:  if Verbose:    print(\"Building internam Index for %d tile(s) ...\" % len(inputTiles), end=' ')   The end='' is invalid syntax. I am curious as to why, and what the author probably meant to do.   I'm new to python if you haven't already guessed.    I think the root cause of the problem is that these imports are failing and therefore one must contain this import from __future__ import print_function  try:     from osgeo import gdal    from osgeo import ogr    from osgeo import osr    from osgeo.gdalconst import * except:    import gdal    import ogr    import osr    from gdalconst import *      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django import error - no module named django.conf.urls.defaults",
        "A_Content": "  django.conf.urls.defaults has been removed in Django 1.6. If the problem was in your own code, you would fix it by changing the import to  from django.conf.urls import patterns, url, include   However, in your case the problem is in a third party app, graphite. The issue has been fixed in graphite's master branch and version 0.9.14+.  In Django 1.8+ you can remove patterns from the import, and use a list of url()s instead.  from django.conf.urls import url, include      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "graphite",
            "django-1.6"
        ],
        "URL": "https://stackoverflow.com/questions/19962736/django-import-error-no-module-named-django-conf-urls-defaults",
        "A_Votes": "188",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to run statsd/graphite which uses django 1.6.  While accessing graphite URL, I get django module error     File \"/opt/graphite/webapp/graphite/urls.py\", line 15, in         from django.conf.urls.defaults import *       ImportError: No module named defaults   However, I do not find defaults django package inside /Library/Python/2.7/site-packages/django/conf/urls/  Please help fixing this issue.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Django import error - no module named django.conf.urls.defaults",
        "A_Content": "  If for some reason you don't want to downgrade to Django 1.5.x or upgrade Graphite then you can apply the fix to your older Graphite with:  find ./ -type f -exec sed -i -e 's/from\\ django\\.conf\\.urls\\.defaults\\ import\\ \\*/from\\ django\\.conf\\.urls\\ import\\ \\*/g' {} \\;   ..in your <graphite_dir>/webapp/graphite dir.  This helped me with my Graphite 0.9.12 and Django 1.7(.5).  (I also had to do:  find ./ -type f -exec sed -i -e 's/mimetype\\=/content_type\\=/g' {} \\; find ./ -type f -exec sed -i -e 's/content_type\\=mimetype/content_type\\=content_type/g' {} \\;   ..later on as after I managed to start Graphite some of its features didn't work. Now they work for me but YMMV.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "graphite",
            "django-1.6"
        ],
        "URL": "https://stackoverflow.com/questions/19962736/django-import-error-no-module-named-django-conf-urls-defaults",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run statsd/graphite which uses django 1.6.  While accessing graphite URL, I get django module error     File \"/opt/graphite/webapp/graphite/urls.py\", line 15, in         from django.conf.urls.defaults import *       ImportError: No module named defaults   However, I do not find defaults django package inside /Library/Python/2.7/site-packages/django/conf/urls/  Please help fixing this issue.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Hey, I've been looking into this problem for myself for almost a day and finally had a breakthrough. Try this:   Setting the PYTHONPATH / PYTHONHOME variables  Right click the Computer icon in the start menu, go to properties. On the left tab, go to Advanced system settings. In the window that comes up, go to the Advanced tab, then at the bottom click Environment Variables. Click in the list of user variables and start typing Python, and repeat for System variables, just to make certain that you don't have mis-set variables for PYTHONPATH or PYTHONHOME. Next, add new variables (I did in System rather than User, although it may work for User too): PYTHONPATH, set to C:\\Python27\\Lib. PYTHONHOME, set to C:\\Python27.   Hope this helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Quick solution: set PYTHONHOME and PYTHONPATH and include PYTHONHOME on PATH  For example if you installed to c:\\Python27  set PYTHONHOME=c:\\Python27 set PYTHONPATH=c:\\Python27\\Lib set PATH=%PYTHONHOME%;%PATH%   Make sure you don't have a trailing '\\' on the PYTHON* vars, this seems to break it aswel.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  I was having this issue after installing both Windows Python and Cygwin Python, and trying to run Cygwin Python from Cygwin. I solved it by exporting PYTHONHOME=/usr/ and PYTHONPATH=/usr/lib/python2.7     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Make sure your PYTHONHOME environment variable is set correctly. You will receive this error if PYTHONHOME is pointing to invalid location or to another Python installation you are trying to run.  Try this:  C:\\>set PYTHONHOME=C:\\Python27 C:\\>python   Use  setx PYTHONHOME C:\\Python27   to set this permanently for subsequent command prompts     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  For Windows 10 (follow up on @slckin answer), this can be set through the command line with:  setx PYTHONHOME \"C:\\Python27\" setx PYTHONPATH \"C:\\Python27\\Lib\" setx PATH \"%PYTHONHOME%;%PATH%\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Are you trying to run Windows Python from Cygwin? I'm having the same problem. Python in Cygwin fails to import site. Python in Cmd works.  It looks like you need to make sure you run PYTHONHOME and PYTHONPATH through cygwin -aw to make them Windows paths. Also, python seems to be using some incorrect paths.  I think I'll need to install python through cygwin to get it working.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Locate site.py and add its path in PYTHONPATH. This will solve your problem.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  For me it happened because I had 2 versions of python installed - python 27 and python 3.3. Both these folder had path variable set, and hence there was this issue. To fix, this, I moved python27 to temp folder, as I was ok with python 3.3. So do check environment variables like PATH,PYTHONHOME as it may be a issue. Thanks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  If somebody will find that it's still not working under non-admin users:  Example error:  ImportError: No module named iso8601   you need to set '--always-unzip' option for easy_install:   easy_install --always-unzip python-keystoneclient   It will unzip your egg files and will allow import to find em.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  I went through the same issue of ImportError: No module named site while installing python 2.7.11  Initially I had Python2.5 and the PYTHONHOME path was set to Python2.5. I renamed it to C:\\Python27\\ and it resolved the problem.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  You may try the Open Source Active Python Setup which is a well done Python installer for Windows. You just have to desinstall your version and install it...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  I up voted slckin's answer.  My problem was that I was thoughtful and added double quotes around the paths.  I removed the double quotes in all of the three variables: PYTHONHOME, PYTHONPATH, and PATH. Note that this was in a cmd or bat file to setup the environment for other tools.  However, the double quotes may be useful in an icon setting.  Typing      set   revealed that the quotes where in the path and not dropped as expected.  I also shorted the PATH so that it was less than 256 characters long.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  In my case, the issue was another site.py file, that was resolved earlier than the one from Python\\Lib, due to PATH setting.  Environment: Windows 10 Pro, Python27.  My desktop has pgAdmin installed, which has file C:\\Program Files (x86)\\pgAdmin\\venv\\Lib\\site.py. Because PATH environment variable had pdAdmin's home earlier than Python (apparently a bad idea in the first place), pgAdmin's site.py was found first.  All I had to do to fix the issue was to move pgAdmin's home later than Python, in PATH     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  I have an application which relies heavily on Python and have kept up-to-date with python 2.7.x as new versions are released. Everthing has been fine until 2.7.11 when I got the same \"No module named site\" error. I've set PYTHONHOME to c:\\Python27 and it's working. But the mystery remains why this is now needed when it wasn't with previous releases. And, if it is needed, why doesn't the installer set this var?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  I had the same problem. My solution was to repair the Python installation. (It was a new installation so I did not expect a problem but now it is solved.)  To repair (Windows 7):   go to Control Panel -> Programs -> Programs and Features click on the Python version installed and then press Uninstall/Change. follow the instructions to repair the installation.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python (Windows) - ImportError: No module named site",
        "A_Content": "  Install yaml from the PyYAML home pagee: http://www.pyyaml.org/wiki/PyYAML  Select the appropriate version for your OS and Python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "module",
            "installation",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/5599872/python-windows-importerror-no-module-named-site",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to install Python for the first time. I downloaded the following installer from the Python website: Python 2.7.1 Windows Installer (Windows binary -- does not include source). I then ran the installer, selected 'All Users' and all was fine. I installed Python into the default location:  C:\\Python27   Next, to test that Python was installed correctly, I navigated to my Python Directory, and ran the \"python\" command in the windows cmd prompt. It returns me the following error:     ImportError: No module named site   When I do 'python -v' I get the following:     #installing zipimport hook   import zipimport # builtin   #installed zipimport hook   #ImportError: No module named site   #clear builtin._   #clear sys.path   #clear sys.argv   #clear sys.ps1   #clear sys.ps2   #clear sys.exitfunc   #clear sys.exc_type   #clear sys.exc_value   #clear sys.exc_traceback   #clear sys.last_type   #clear sys.last_value   #clear sys.last_traceback   #clear sys.path_hooks   #clear sys.path_importer_cache   #clear sys.meta_path   #clear sys.flags   #clear sys.float_info   #restore sys.stdin   #restore sys.stdout   #restore sys.stderr   #cleanup main   #cleanup[1] zipimport   #cleanup[1] signal   #cleanup[1] exceptions   #cleanup[1] _warnings   #cleanup sys   #cleanup builtin   #cleanup ints: 6 unfreed ints   #cleanup floats     When I do dir C:\\Python27\\Lib\\site.py* I get the following:     C:\\Users\\Mimminito>dir C:\\Python27\\Lib\\site.py*   Volume in drive C has no label.   Volume Serial Number is DAB9-A863        Directory of C:\\Python27\\Lib        13/11/2010  20:08            20,389  site.py                  1 File(s)         20,389 bytes                  0 Dir(s)     694,910,976 bytes free     Any ideas?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Days between two dates in Python [duplicate]",
        "A_Content": "  Assuming you’ve literally got two date objects, you can subtract one from the other and query the resulting timedelta object for the number of days:  >>> from datetime import date >>> a = date(2011,11,24) >>> b = date(2011,11,17) >>> a-b datetime.timedelta(7) >>> (a-b).days 7   And it works with datetimes too — I think it rounds down to the nearest day:  >>> from datetime import datetime >>> a = datetime(2011,11,24,0,0,0) >>> b = datetime(2011,11,17,23,59,59) >>> a-b datetime.timedelta(6, 1) >>> (a-b).days 6      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date"
        ],
        "URL": "https://stackoverflow.com/questions/8258432/days-between-two-dates-in-python",
        "A_Votes": "162",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              How do I calculate number of days between two dates using Python?                                        10 answers                                          What's the shortest way to see how many full days have passed between two dates? Here's what I'm doing now.  math.floor((b - a).total_seconds()/float(86400))      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Days between two dates in Python [duplicate]",
        "A_Content": "  Do you mean full calendar days, or groups of 24 hours?  For simply 24 hours, assuming you're using Python's datetime, then the timedelta object already has a days property:  days = (a - b).days   For calendar days, you'll need to round a down to the nearest day, and b up to the nearest day, getting rid of the partial day on either side:  roundedA = a.replace(hour = 0, minute = 0, second = 0, microsecond = 0) roundedB = b.replace(hour = 0, minute = 0, second = 0, microsecond = 0) days = (roundedA - roundedB).days      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date"
        ],
        "URL": "https://stackoverflow.com/questions/8258432/days-between-two-dates-in-python",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How do I calculate number of days between two dates using Python?                                        10 answers                                          What's the shortest way to see how many full days have passed between two dates? Here's what I'm doing now.  math.floor((b - a).total_seconds()/float(86400))      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Days between two dates in Python [duplicate]",
        "A_Content": "  Try:  (b-a).days   I tried with b and a of type datetime.date.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "date"
        ],
        "URL": "https://stackoverflow.com/questions/8258432/days-between-two-dates-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How do I calculate number of days between two dates using Python?                                        10 answers                                          What's the shortest way to see how many full days have passed between two dates? Here's what I'm doing now.  math.floor((b - a).total_seconds()/float(86400))      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Days between two dates in Python [duplicate]",
        "A_Content": "  Referencing my comments on other answers. This is how I would work out the difference in days based on 24 hours and calender days. the days attribute works well for 24 hours and the function works best for calendar checks.  from datetime import timedelta, datetime  def cal_days_diff(a,b):      A = a.replace(hour = 0, minute = 0, second = 0, microsecond = 0)     B = b.replace(hour = 0, minute = 0, second = 0, microsecond = 0)     return (A - B).days  if __name__ == '__main__':      x = datetime(2013, 06, 18, 16, 00)     y = datetime(2013, 06, 19, 2, 00)      print (y - x).days          # 0     print cal_days_diff(y, x)   # 1       z = datetime(2013, 06, 20, 2, 00)      print (z - x).days          # 1     print cal_days_diff(z, x)   # 2       ",
        "Language": "Python",
        "Tags": [
            "python",
            "date"
        ],
        "URL": "https://stackoverflow.com/questions/8258432/days-between-two-dates-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How do I calculate number of days between two dates using Python?                                        10 answers                                          What's the shortest way to see how many full days have passed between two dates? Here's what I'm doing now.  math.floor((b - a).total_seconds()/float(86400))      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  Update:   Read the Docs for your version of Django. e.g.   https://docs.djangoproject.com/en/1.11/ref/contrib/admin/#admin-overriding-templates https://docs.djangoproject.com/en/2.0/ref/contrib/admin/#admin-overriding-templates  Original answer from 2011:  I had the same issue about a year and a half ago and I found a nice template loader on djangosnippets.org that makes this easy. It allows you to extend a template in a specific app, giving you the ability to create your own admin/index.html that extends the admin/index.html template from the admin app. Like this:  {% extends \"admin:admin/index.html\" %}  {% block sidebar %}     {{block.super}}     <div>         <h1>Extra links</h1>         <a href=\"/admin/extra/\">My extra link</a>     </div> {% endblock %}   I've given a full example on how to use this template loader in a blog post on my website.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "86",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  As for Django 1.8 being the current release, there is no need to symlink, copy the admin/templates to your project folder, or install middlewares as suggested by the answers above. Here is what to do:   create the following tree structure(recommended by the official documentation)  your_project      |-- your_project/      |-- myapp/      |-- templates/           |-- admin/               |-- myapp/                   |-- change_form.html  <- do not misspell this    Note: The location of this file is not important. You can put it inside your app and it will still work. As long as its location can be discovered by django. What's more important is the name of the HTML file has to be the same as the original HTML file name provided by django.   Add this template path to your settings.py:  TEMPLATES = [     {         'BACKEND': 'django.template.backends.django.DjangoTemplates',         'DIRS': [os.path.join(BASE_DIR, 'templates')], # <- add this line         'APP_DIRS': True,         'OPTIONS': {             'context_processors': [                 'django.template.context_processors.debug',                 'django.template.context_processors.request',                 'django.contrib.auth.context_processors.auth',                 'django.contrib.messages.context_processors.messages',             ],         },     }, ]  Identify the name and block you want to override. This is done by looking into django's admin/templates directory. I am using virtualenv, so for me, the path is here:  ~/.virtualenvs/edge/lib/python2.7/site-packages/django/contrib/admin/templates/admin    In this example, I want to modify the add new user form. The template responsiblve for this view is change_form.html. Open up the change_form.html and find the {% block %} that you want to extend.   In your change_form.html, write somethings like this:  {% extends \"admin/change_form.html\" %} {% block field_sets %}      {# your modification here #} {% endblock %}  Load up your page and you should see the changes      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  if you need to overwrite the admin/index.html, you can set the index_template parameter of the AdminSite.  e.g.  # urls.py ... from django.contrib import admin  admin.site.index_template = 'admin/my_custom_index.html' admin.autodiscover()   and place your template in <appname>/templates/admin/my_custom_index.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  With django 1.5 (at least) you can define the template you want to use for a particular modeladmin  see https://docs.djangoproject.com/en/1.5/ref/contrib/admin/#custom-template-options  You can do something like  class Myadmin(admin.ModelAdmin):     change_form_template = 'change_form.htm'   With change_form.html being a simple html template extending admin/change_form.html (or not if you want to do it from scratch)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  The best way to do it is to put the Django admin templates inside your project. So your templates would be in templates/admin while the stock Django admin templates would be in say template/django_admin. Then, you can do something like the following:  templates/admin/change_form.html  {% extends 'django_admin/change_form.html' %}  Your stuff here   If you're worried about keeping the stock templates up to date, you can include them with svn externals or similar.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  Chengs's answer is correct, howewer according to the admin docs not every admin template can be overwritten this way:  https://docs.djangoproject.com/en/1.9/ref/contrib/admin/#overriding-admin-templates     Templates which may be overridden per app or model      Not every template in contrib/admin/templates/admin may be overridden   per app or per model. The following can:  app_index.html change_form.html change_list.html delete_confirmation.html object_history.html       For those templates that cannot be overridden in this way, you may   still override them for your entire project. Just place the new   version in your templates/admin directory. This is particularly useful   to create custom 404 and 500 pages   I had to overwrite the login.html of the admin and therefore had to put the overwritten template in this folder structure:   your_project  |-- your_project/  |-- myapp/  |-- templates/       |-- admin/           |-- login.html  <- do not misspell this   (without the myapp subfolder in the admin)  I do not have enough repution for commenting on Cheng's post this is why I had to write this as new answer.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  I agree with Chris Pratt. But I think it's better to create the symlink to original Django folder where the admin templates place in:  ln -s /usr/local/lib/python2.7/dist-packages/django/contrib/admin/templates/admin/ templates/django_admin   and as you can see it depends on python version and the folder where the Django installed. So in future or on a production server you might need to change the path.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  This site had a simple solution that worked with my Django 1.7 configuration.  FIRST: Make a symlink named admin_src in your project's template/ directory to your installed Django templates. For me on Dreamhost using a virtualenv, my \"source\" Django admin templates were in:  ~/virtualenvs/mydomain/lib/python2.7/site-packages/django/contrib/admin/templates/admin   SECOND: Create an admin directory in templates/  So my project's template/ directory now looked like this:  /templates/    admin    admin_src -> [to django source]    base.html    index.html    sitemap.xml    etc...   THIRD: In your new template/admin/ directory create a base.html file with this content:  {% extends \"admin_src/base.html\" %}  {% block extrahead %} <link rel='shortcut icon' href='{{ STATIC_URL }}img/favicon-admin.ico' /> {% endblock %}   FOURTH: Add your admin favicon-admin.ico into your static root img folder.  Done. Easy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "How to override and extend basic Django admin templates?",
        "A_Content": "  You can use django-overextends, which provides circular template inheritance for Django.  It comes from the Mezzanine CMS, from where Stephen extracted it into a standalone Django extension.  More infos you find in \"Overriding vs Extending Templates\" (http:/mezzanine.jupo.org/docs/content-architecture.html#overriding-vs-extending-templates) inside the Mezzanine docs.  For deeper insides look at Stephens Blog \"Circular Template Inheritance for Django\" (http:/blog.jupo.org/2012/05/17/circular-template-inheritance-for-django).  And in Google Groups the discussion (https:/groups.google.com/forum/#!topic/mezzanine-users/sUydcf_IZkQ) which started the development of this feature.  Note:  I don't have the reputation to add more than 2 links. But I think the links provide interesting background information. So I just left out a slash after \"http(s):\". Maybe someone with better reputation can repair the links and remove this note.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/6583877/how-to-override-and-extend-basic-django-admin-templates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?  First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).  My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.  It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.  On a side note: Does anybody know if this problem will be addressed by Django itself?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  Worked for me after installing scipy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "126",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  >>> from sklearn import preprocessing, metrics, cross_validation  Traceback (most recent call last):   File \"<pyshell#6>\", line 1, in <module>     from sklearn import preprocessing, metrics, cross_validation   File \"D:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 31, in <module>     from . import __check_build ImportError: cannot import name __check_build >>> ================================ RESTART ================================ >>> from sklearn import preprocessing, metrics, cross_validation >>>    So, simply try to restart the shell!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  Restart the python shell after installing scipy! You must haven't restarted the idle after installing yet!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  After installing numpy , scipy ,sklearn  still has error  Solution:  Setting Up System Path Variable for Python & the PYTHONPATH Environment Variable  System Variables: add C:\\Python34 into path User Variables: add new: (name)PYTHONPATH (value)C:\\Python34\\Lib\\site-packages;     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  Usually when I get these kinds of errors, opening the __init__.py file and poking around helps. Go to the directory C:\\Python27\\lib\\site-packages\\sklearn and ensure that there's a sub-directory called __check_build as a first step. On my machine (with a working sklearn installation, Mac OSX, Python 2.7.3) I have __init__.py, setup.py, their associated .pyc files, and a binary _check_build.so.  Poking around the __init__.py in that directory, the next step I'd take is to go to sklearn/__init__.py and comment out the import statement---the check_build stuff just checks that things were compiled correctly, it doesn't appear to do anything but call a precompiled binary. This is, of course, at your own risk, and (to be sure) a work around. If your build failed you'll likely soon run into other, bigger problems.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  I had the same issue on Windows. Solved it by installing Numpy+MKL from http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy (there it's recommended to install numpy+mkl before other packages that depend on it) as suggested by this answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  I had problems importing SKLEARN after installing a new 64bit version of Python 3.4 from python.org.  Turns out that it was the SCIPY module that was broken, and alos failed when I tried to \"import scipy\".  Solution was to uninstall scipy and reinstall it with pip3:  C:\\> pip uninstall scipy  [lots of reporting messages deleted]  Proceed (y/n)? y   Successfully uninstalled scipy-1.0.0  C:\\Users\\>pip3 install scipy  Collecting scipy   Downloading scipy-1.0.0-cp36-none-win_amd64.whl (30.8MB)     100% |████████████████████████████████| 30.8MB 33kB/s Requirement already satisfied: numpy>=1.8.2 in c:\\users\\johnmccurdy\\appdata\\loca l\\programs\\python\\python36\\lib\\site-packages (from scipy) Installing collected packages: scipy Successfully installed scipy-1.0.0  C:\\Users>python Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)]  on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import scipy >>> >>> import sklearn >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  My solution for Python 3.6.5 64-bit Windows 10:   pip uninstall sklearn pip uninstall scikit-learn pip install sklearn   No need to restart command-line but you can do this if you want. It took me one day to fix this bug. Hope this help.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  If you use Anaconda 2.7 64 bit, try  conda upgrade scikit-learn   and restart the python shell, that works for me.  Second edit when I faced the same problem and solved it:  conda upgrade scikit-learn   also works for me     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  This is probably because you may have scikit-learn installed along with sklearn. Run the following commands   pip uninstall scikit-learn pip uninstall sklearn pip install sklearn   This solved the issue for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  I faced the same issue in my Windows machine and got it solved by installing numpy+mkl package from http://www.lfd.uci.edu/~gohlke/pythonlibs/. After installation, restart the shell.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  In windows:  I tried to delete sklearn from the shell: pip uninstall sklearn, and re install it but doesn't work ..   the solution:  1- open the cmd shell. 2- cd c:\\pythonVERSION\\scripts 3- pip uninstall sklearn 4- open in the explorer: C:\\pythonVERSION\\Lib\\site-packages 5- look for the folders that contains sklearn and delete them .. 6- back to cmd: pip install sklearn      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  i had an issue when installed sklearn and try to import datasets  the problem was cython compatibility. after creating a new env without cython it worked like a charm.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  None of the other answers worked for me. After some tinkering I unsinstalled sklearn:  pip uninstall sklearn   Then I removed sklearn folder from here: (adjust the path to your system and python version)  C:\\Users\\%USERNAME%\\AppData\\Roaming\\Python\\Python36\\site-packages   And the installed it from wheel from this site: link  The error was there probably because of a version conflict with sklearn installed somewhere else.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "ImportError in importing from sklearn: cannot import name check_build",
        "A_Content": "  Recently I met the same mistike as you.  Traceback (most recent call last): entFile \"/Users/honey/Documents/machine_learning/task1/sklearn.py\", line 8, in <module>er code here from sklearn import feature_extraction   File \"/Users/honey/Documents/machine_learning/task1/sklearn.py\", line 8, in <module> from sklearn import feature_extraction ImportError: cannot import name 'feature_extraction' [Finished in 0.8s with exit code 1] [cmd: ['python3', '-u', '/Users/honey/Documents/machine_learning/task1/sklearn.py']]   Then I found that python is confused by the name \"sklearn.py\",so the code can not be executed correctly. I notice that there is also sklearn in your path   C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py   So perhaps you can try to avoid \"sklearn\" in your path to avoid ambiguity. Hope it can help. (I am sorry that perhaps I misunderstood the problem and it may not help.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am getting the following error while trying to import from sklearn:  >>> from sklearn import svm  Traceback (most recent call last):   File \"<pyshell#17>\", line 1, in <module>    from sklearn import svm   File \"C:\\Python27\\lib\\site-packages\\sklearn\\__init__.py\", line 16, in <module>    from . import check_build ImportError: cannot import name check_build   I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11 I have a windows 7 machine  I have checked several answers for this issue but none of them gives a way out of this error.     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  I regularly \"jsonify\" np.arrays. Try using the \".tolist()\" method on the arrays first, like this:   import numpy as np import codecs, json   a = np.arange(10).reshape(2,5) # a 2 by 5 array b = a.tolist() # nested lists with same data, indices file_path = \"/path.json\" ## your path variable json.dump(b, codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4) ### this saves the array in .json format   In order to \"unjsonify\" the array use:   obj_text = codecs.open(file_path, 'r', encoding='utf-8').read() b_new = json.loads(obj_text) a_new = np.array(b_new)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "130",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  class NumpyEncoder(json.JSONEncoder):     def default(self, obj):         if isinstance(obj, np.ndarray):             return obj.tolist()         return json.JSONEncoder.default(self, obj)      a = np.array([1, 2, 3])      print(json.dumps({'aa': [2, (2, 3, 4), a], 'bb': [2]},   cls=NumpyEncoder))   {\"aa\": [2, [2, 3, 4], [1, 2, 3]], \"bb\": [2]}     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  You can use Pandas:  import pandas as pd pd.Series(your_array).to_json(orient='values')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  I found the best solution if you have nested numpy arrays in a dictionary:  import json import numpy as np  class NumpyEncoder(json.JSONEncoder):     \"\"\" Special json encoder for numpy types \"\"\"     def default(self, obj):         if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,             np.int16, np.int32, np.int64, np.uint8,             np.uint16, np.uint32, np.uint64)):             return int(obj)         elif isinstance(obj, (np.float_, np.float16, np.float32,              np.float64)):             return float(obj)         elif isinstance(obj,(np.ndarray,)): #### This is the fix             return obj.tolist()         return json.JSONEncoder.default(self, obj)  dumped = json.dumps(data, cls=NumpyEncoder)  with open(path, 'w') as f:     json.dump(dumped, f)   Thanks to this guy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  This is not supported by default, but you can make it work quite easily! There are several things you'll want to encode if you want the exact same data back:   The data itself, which you can get with obj.tolist() as @travelingbones mentioned. Sometimes this may be good enough. The data type. I feel this is important in quite some cases. The dimension (not necessarily 2D), which could be derived from the above if you assume the input is indeed always a 'rectangular' grid. The memory order (row- or column-major). This doesn't often matter, but sometimes it does (e.g. performance), so why not save everything?   Furthermore, your numpy array could part of your data structure, e.g. you have a list with some matrices inside. For that you could use a custom encoder which basically does the above.  This should be enough to implement a solution. Or you could use json-tricks which does just this (and supports various other types) (disclaimer: I made it).  pip install json-tricks   Then  data = [     arange(0, 10, 1, dtype=int).reshape((2, 5)),     datetime(year=2017, month=1, day=19, hour=23, minute=00, second=00),     1 + 2j,     Decimal(42),     Fraction(1, 3),     MyTestCls(s='ub', dct={'7': 7}),  # see later     set(range(7)), ] # Encode with metadata to preserve types when decoding print(dumps(data))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  I had a similar problem with a nested dictionary with some numpy.ndarrays in it.   def jsonify(data):     json_data = dict()     for key, value in data.iteritems():         if isinstance(value, list): # for lists             value = [ jsonify(item) if isinstance(item, dict) else item for item in value ]         if isinstance(value, dict): # for nested lists             value = jsonify(value)         if isinstance(key, int): # if key is integer: > to string             key = str(key)         if type(value).__module__=='numpy': # if value is numpy.*: > to python list             value = value.tolist()         json_data[key] = value     return json_data      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  Also, some very interesting information further on lists vs. arrays in Python ~> Python List vs. Array - when to use?  It could be noted that once I convert my arrays into a list before saving it in a JSON file, in my deployment right now anyways, once I read that JSON file for use later, I can continue to use it in a list form (as opposed to converting it back to an array).   AND actually looks nicer (in my opinion) on the screen as a list (comma seperated) vs. an array (not-comma seperated) this way.   Using @travelingbones's .tolist() method above, I've been using as such (catching a few errors I've found too):  SAVE DICTIONARY  def writeDict(values, name):     writeName = DIR+name+'.json'     with open(writeName, \"w\") as outfile:         json.dump(values, outfile)   READ DICTIONARY  def readDict(name):     readName = DIR+name+'.json'     try:         with open(readName, \"r\") as infile:             dictValues = json.load(infile)             return(dictValues)     except IOError as e:         print(e)         return('None')     except ValueError as e:         print(e)         return('None')   Hope this helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  Here is an implementation that work for me and removed all nans (assuming these are simple object (list or dict)):  from numpy import isnan  def remove_nans(my_obj, val=None):     if isinstance(my_obj, list):         for i, item in enumerate(my_obj):             if isinstance(item, list) or isinstance(item, dict):                 my_obj[i] = remove_nans(my_obj[i], val=val)              else:                 try:                     if isnan(item):                         my_obj[i] = val                 except Exception:                     pass      elif isinstance(my_obj, dict):         for key, item in my_obj.iteritems():             if isinstance(item, list) or isinstance(item, dict):                 my_obj[key] = remove_nans(my_obj[key], val=val)              else:                 try:                     if isnan(item):                         my_obj[key] = val                 except Exception:                     pass      return my_obj      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  This is a different answer, but this might help to help people who are trying to save data and then read it again. There is hickle which is faster than pickle and easier. I tried to save and read it in pickle dump but while reading there were lot of problems and wasted an hour and still didn't find solution though I was working on my own data to create a chat bot.   vec_x and vec_y are numpy arrays:  data=[vec_x,vec_y] hkl.dump( data, 'new_data_file.hkl' )   Then you just read it and perform the operations:  data2 = hkl.load( 'new_data_file.hkl' )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "NumPy array is not JSON serializable",
        "A_Content": "  You could also use default argument for example:  def myconverter(o):     if isinstance(o, np.float32):         return float(o)  json.dump(data, default=myconverter)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:  array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable   What does this mean?     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  In this example code node[k] is just the kth node. You are generating an array N points and node[k] is the kth (from 0 to N-1). If that is all that is confusing you, hopefully you can use that now.  (in other words, k is an array of size N that is defined before the code fragment starts, and which contains a list of the points).  Alternatively, building on the other answer here (and using Python):  > cat ll.py from math import asin nx = 4; ny = 5 for x in range(nx):     lon = 360 * ((x+0.5) / nx)     for y in range(ny):                                                                  midpt = (y+0.5) / ny                                                             lat = 180 * asin(2*((y+0.5)/ny-0.5))                                             print lon,lat                                                            > python2.7 ll.py                                                       45.0 -166.91313924                                                               45.0 -74.0730322921                                                              45.0 0.0                                                                         45.0 74.0730322921                                                               45.0 166.91313924                                                                135.0 -166.91313924                                                              135.0 -74.0730322921                                                             135.0 0.0                                                                        135.0 74.0730322921                                                              135.0 166.91313924                                                               225.0 -166.91313924                                                              225.0 -74.0730322921                                                             225.0 0.0                                                                        225.0 74.0730322921                                                              225.0 166.91313924 315.0 -166.91313924 315.0 -74.0730322921 315.0 0.0 315.0 74.0730322921 315.0 166.91313924   If you plot that, you'll see that the vertical spacing is larger near the poles so that each point is situated in about the same total area of space (near the poles there's less space \"horizontally\", so it gives more \"vertically\").  This isn't the same as all points having about the same distance to their neighbours (which is what I think your links are talking about), but it may be sufficient for what you want and improves on simply making a uniform lat/lon grid.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  The Fibonacci sphere algorithm is great for this. It's fast and gives results that at a glance will easily fool the human eye. You can see an example done with processing which will show the result over time as points are added. Here's another great interactive example made by @gman. And here's a quick python version with a simple randomization option:  import math, random  def fibonacci_sphere(samples=1,randomize=True):     rnd = 1.     if randomize:         rnd = random.random() * samples      points = []     offset = 2./samples     increment = math.pi * (3. - math.sqrt(5.));      for i in range(samples):         y = ((i * offset) - 1) + (offset / 2);         r = math.sqrt(1 - pow(y,2))          phi = ((i + rnd) % samples) * increment          x = math.cos(phi) * r         z = math.sin(phi) * r          points.append([x,y,z])      return points   1000 samples gives you this:       ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "89",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  This is known as packing points on a sphere, and there is no (known) general, perfect solution.  However, there are plenty of imperfect solutions.  The three most popular seem to be:   Create a simulation.  Treat each point as an electron constrained to a sphere, then run a simulation for a certain number of steps.  The electrons' repulsion will naturally tend the system to a more stable state, where the points are about as far away from each other as they can get. Hypercube rejection.  This fancy-sounding method is actually really simple:  you uniformly choose points (much more than n of them) inside of the cube surrounding the sphere, then reject the points outside of the sphere.  Treat the remaining points as vectors, and normalize them.  These are your \"samples\" - choose n of them using some method (randomly, greedy, etc). Spiral approximations.  You trace a spiral around a sphere, and evenly-distribute the points around the spiral.  Because of the mathematics involved, these are more complicated to understand than the simulation, but much faster (and probably involving less code).  The most popular seems to be by Saff, et al.   A lot more information about this problem can be found here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "73",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  The golden spiral method  You said you couldn't get the golden spiral method to work and that's a shame because it's really, really good. I would like to give you a complete understanding of it so that maybe you can understand how to keep this away from being \"bunched up.\"  So here's a fast, non-random way to create a lattice that is approximately correct; as discussed above, no lattice will be perfect, but this may be \"good enough\". It is compared to other methods e.g. at BendWavy.org but it just has a nice and pretty look as well as a guarantee about even spacing in the limit.  Primer: sunflower spirals on the unit disk  To understand this algorithm, I first invite you to look at the 2D sunflower spiral algorithm. This is based on the fact that the most irrational number is the golden ratio (1 + sqrt(5))/2 and if one emits points by the approach \"stand at the center, turn a golden ratio of whole turns, then emit another point in that direction,\" one naturally constructs a spiral which, as you get to higher and higher numbers of points, nevertheless refuses to have well-defined \"bars\" that the points line up on.(Note 1.)  The algorithm for even spacing on a disk is,    from numpy import pi, cos, sin, sqrt, arange import matplotlib.pyplot as pp  num_pts = 100 indices = arange(0, num_pts, dtype=float) + 0.5  r = sqrt(indices/num_pts) theta = pi * (1 + 5**0.5) * indices  pp.scatter(r*cos(theta), r*sin(theta)) pp.show()   and it produces results that look like (n=100 and n=1000):    Spacing the points radially  The key strange thing is the formula r = sqrt(indices / num_pts); how did I come to that one? (Note 2.)  Well, I am using the square root here because I want these to have even-area spacing around the sphere. That's the same as saying that in the limit of large N I want a little region R ∈ (r, r + dr), Θ ∈ (θ, θ + dθ) to contain a number of points proportional to its area, which is r dr dθ. Now if we pretend that we are talking about a random variable here, this has a straightforward interpretation as saying that the joint probability density for (R, Θ) is just c r for some constant c. Normalization on the unit disk then forces c = 1/π.  Now let me introduce a trick. It comes from probability theory where it's known as sampling the inverse CDF: suppose you wanted to generate a random variable with a probability density f(z) and you have a random variable U ~ Uniform(0, 1), just like comes out of random() in most programming languages. How do you do this?   First, turn your density into a cumulative distribution function F(z), which, remember, increases monotonically from 0 to 1 with derivative f(z). Then calculate the CDF's inverse function F-1(z). You will find that Z = F-1(U) is distributed according to the target density. (Note 3).   Now the golden-ratio spiral trick spaces the points out in a nicely even pattern for θ so let's integrate that out; for the unit circle we are left with F(r) = r2. So the inverse function is F-1(u) = u1/2, and therefore we would generate random points on the sphere in polar coordinates with r = sqrt(random()); theta = 2 * pi * random().   Now instead of randomly sampling this inverse function we're uniformly sampling it, and the nice thing about uniform sampling is that our results about how points are spread out in the limit of large N will behave as if we had randomly sampled it. This combination is the trick. Instead of random() we use (arange(0, num_pts, dtype=float) + 0.5)/num_pts, so that, say, if we want to sample 10 points they are r = 0.05, 0.15, 0.25, ... 0.95. We uniformly sample r to get equal-area spacing, and we use the sunflower increment to avoid awful \"bars\" of points in the output.  Now doing the sunflower on a sphere  The changes that we need to make to dot the sphere with points merely involve switching out the polar coordinates for spherical coordinates. The radial coordinate of course doesn't enter into this because we're on a unit sphere. To keep things a little more consistent here, even though I was trained as a physicist I'll use mathematicians' coordinates where 0 ≤ φ ≤ π is latitude coming down from the pole and 0 ≤ θ ≤ 2π is longitude. So the difference from above is that we are basically replacing the variable r with φ.   Our area element, which was r dr dθ, now becomes the not-much-more-complicated sin(φ) dφ dθ. So our joint density for uniform spacing is sin(φ)/4π. Integrating out θ, we find f(φ) = sin(φ)/2, thus F(φ) = (1 − cos(φ))/2. Inverting this we can see that a uniform random variable would look like acos(1 - 2 u), but we sample uniformly instead of randomly, so we instead use φk = acos(1 − 2 (k + 0.5)/N). And the rest of the algorithm is just projecting this onto the x, y, and z coordinates:  from numpy import pi, cos, sin, arccos, arange import mpl_toolkits.mplot3d import matplotlib.pyplot as pp  num_pts = 1000 indices = arange(0, num_pts, dtype=float) + 0.5  phi = arccos(1 - 2*indices/num_pts) theta = pi * (1 + 5**0.5) * indices  x, y, z = cos(theta) * sin(phi), sin(theta) * sin(phi), cos(phi);  pp.figure().add_subplot(111, projection='3d').scatter(x, y, z); pp.show()   Again for n=100 and n=1000 the results look like:    Notes   Those \"bars\" are formed by rational approximations to a number, and the best rational approximations to a number come from its continued fraction expression, z + 1/(n_1 + 1/(n_2 + 1/(n_3 + ...))) where z is an integer and n_1, n_2, n_3, ... is either a finite or infinite sequence of positive integers:  def continued_fraction(r):     while r != 0:         n = floor(r)         yield n         r = 1/(r - n)   Since the fraction part 1/(...) is always between zero and one, a large integer in the continued fraction allows for a particularly good rational approximation: \"one divided by something between 100 and 101\" is better than \"one divided by something between 1 and 2.\" The most irrational number is therefore the one which is 1 + 1/(1 + 1/(1 + ...)) and has no particularly good rational approximations; one can solve φ = 1 + 1/φ by multiplying through by φ to get the formula for the golden ratio.   For folks who are not so familiar with NumPy -- all of the functions are \"vectorized\", so that sqrt(array) is the same as what other languages might write map(sqrt, array). So this is a component-by-component sqrt application. The same also holds for division by a scalar or addition with scalars -- those apply to all components in parallel. The proof is simple once you know that this is the result. If you ask what's the probability that z < Z < z + dz, this is the same as asking what's the probability that z < F-1(U) < z + dz, apply F to all three expressions noting that it is a monotonically increasing function, hence F(z) < U < F(z + dz), expand the right hand side out to find F(z) + f(z) dz, and since U is uniform this probability is just f(z) dz as promised.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  This answer is based on the same 'theory'  that is outlined well by this answer  I'm adding this answer as:  -- None of the other options fit the 'uniformity' need 'spot-on' (or not obviously-clearly so).  (Noting to get the planet like distribution looking behavior particurally wanted in the original ask, you just reject from the finite list of the k uniformly created points at random (random wrt the index count  in the k items back).)  --The closest other impl forced you to decide the 'N' by 'angular axis', vs. just 'one value of N' across both angular axis values ( which at low counts of N is very tricky  to know what may, or may not matter  (e.g. you want '5' points -- have fun ) )   --Furthermore, it's very hard to 'grok' how to differentiate between the other options without any imagery, so here's what this option looks like (below), and the ready-to-run implementation that goes with it.   with N at 20:     and then N at 80:     here's the ready-to-run python3 code, where the emulation is that same source: \" http://web.archive.org/web/20120421191837/http://www.cgafaq.info/wiki/Evenly_distributed_points_on_sphere \" found by others.  ( The plotting I've included, that fires when run as 'main,' is taken from: http://www.scipy.org/Cookbook/Matplotlib/mplot3D )  from math import cos, sin, pi, sqrt  def GetPointsEquiAngularlyDistancedOnSphere(numberOfPoints=45):     \"\"\" each point you get will be of form 'x, y, z'; in cartesian coordinates         eg. the 'l2 distance' from the origion [0., 0., 0.] for each point will be 1.0          ------------         converted from:  http://web.archive.org/web/20120421191837/http://www.cgafaq.info/wiki/Evenly_distributed_points_on_sphere )      \"\"\"     dlong = pi*(3.0-sqrt(5.0))  # ~2.39996323      dz   =  2.0/numberOfPoints     long =  0.0     z    =  1.0 - dz/2.0     ptsOnSphere =[]     for k in range( 0, numberOfPoints):          r    = sqrt(1.0-z*z)         ptNew = (cos(long)*r, sin(long)*r, z)         ptsOnSphere.append( ptNew )         z    = z - dz         long = long + dlong     return ptsOnSphere  if __name__ == '__main__':                     ptsOnSphere = GetPointsEquiAngularlyDistancedOnSphere( 80)          #toggle True/False to print them     if( True ):             for pt in ptsOnSphere:  print( pt)      #toggle True/False to plot them     if(True):         from numpy import *         import pylab as p         import mpl_toolkits.mplot3d.axes3d as p3          fig=p.figure()         ax = p3.Axes3D(fig)          x_s=[];y_s=[]; z_s=[]          for pt in ptsOnSphere:             x_s.append( pt[0]); y_s.append( pt[1]); z_s.append( pt[2])          ax.scatter3D( array( x_s), array( y_s), array( z_s) )                         ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')         p.show()         #end   tested at low counts (N in 2, 5, 7, 13, etc) and seems to work 'nice'     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  What you are looking for is called a spherical covering. The spherical covering problem is very hard and solutions are unknown except for small numbers of points. One thing that is known for sure is that given n points on a sphere, there always exist two points of distance d = (4-csc^2(\\pi n/6(n-2)))^(1/2) or closer.  If you want a probabilistic method for generating points uniformly distributed on a sphere, it's easy: generate points in space uniformly by Gaussian distribution (it's built into Java, not hard to find the code for other languages). So in 3-dimensional space, you need something like   Random r = new Random(); double[] p = { r.nextGaussian(), r.nextGaussian(), r.nextGaussian() };   Then project the point onto the sphere by normalizing its distance from the origin   double norm = Math.sqrt( (p[0])^2 + (p[1])^2 + (p[2])^2 );  double[] sphereRandomPoint = { p[0]/norm, p[1]/norm, p[2]/norm };   The Gaussian distribution in n dimensions is spherically symmetric so the projection onto the sphere is uniform.  Of course, there's no guarantee that the distance between any two points in a collection of uniformly generated points will be bounded below, so you can use rejection to enforce any such conditions that you might have: probably it's best to generate the whole collection and then reject the whole collection if necessary. (Or use \"early rejection\" to reject the whole collection you've generated so far; just don't keep some points and drop others.) You can use the formula for d given above, minus some slack, to determine the min distance between points below which you will reject a set of points. You'll have to calculate n choose 2 distances, and the probability of rejection will depend on the slack; it's hard to say how, so run a simulation to get a feel for the relevant statistics.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  Try:  function sphere ( N:float,k:int):Vector3 {     var inc =  Mathf.PI  * (3 - Mathf.Sqrt(5));     var off = 2 / N;     var y = k * off - 1 + (off / 2);     var r = Mathf.Sqrt(1 - y*y);     var phi = k * inc;     return Vector3((Mathf.Cos(phi)*r), y, Mathf.Sin(phi)*r);  };   The above function should run in loop with N loop total and k loop current iteration.  It is based on a sunflower seeds pattern, except the sunflower seeds are curved around into a half dome, and again into a sphere.  Here is a picture, except I put the camera half way inside the sphere so it looks 2d instead of 3d because the camera is same distance from all points. http://3.bp.blogspot.com/-9lbPHLccQHA/USXf88_bvVI/AAAAAAAAADY/j7qhQsSZsA8/s640/sphere.jpg     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  with small numbers of points you could run a simulation:  from random import random,randint r = 10 n = 20 best_closest_d = 0 best_points = [] points = [(r,0,0) for i in range(n)] for simulation in range(10000):     x = random()*r     y = random()*r     z = r-(x**2+y**2)**0.5     if randint(0,1):         x = -x     if randint(0,1):         y = -y     if randint(0,1):         z = -z     closest_dist = (2*r)**2     closest_index = None     for i in range(n):         for j in range(n):             if i==j:                 continue             p1,p2 = points[i],points[j]             x1,y1,z1 = p1             x2,y2,z2 = p2             d = (x1-x2)**2+(y1-y2)**2+(z1-z2)**2             if d < closest_dist:                 closest_dist = d                 closest_index = i     if simulation % 100 == 0:         print simulation,closest_dist     if closest_dist > best_closest_d:         best_closest_d = closest_dist         best_points = points[:]     points[closest_index]=(x,y,z)   print best_points >>> best_points [(9.921692138442777, -9.930808529773849, 4.037839326088124),  (5.141893371460546, 1.7274947332807744, -4.575674650522637),  (-4.917695758662436, -1.090127967097737, -4.9629263893193745),  (3.6164803265540666, 7.004158551438312, -2.1172868271109184),  (-9.550655088997003, -9.580386054762917, 3.5277052594769422),  (-0.062238110294250415, 6.803105171979587, 3.1966101417463655),  (-9.600996012203195, 9.488067284474834, -3.498242301168819),  (-8.601522086624803, 4.519484132245867, -0.2834204048792728),  (-1.1198210500791472, -2.2916581379035694, 7.44937337008726),  (7.981831370440529, 8.539378431788634, 1.6889099589074377),  (0.513546008372332, -2.974333486904779, -6.981657873262494),  (-4.13615438946178, -6.707488383678717, 2.1197605651446807),  (2.2859494919024326, -8.14336582650039, 1.5418694699275672),  (-7.241410895247996, 9.907335206038226, 2.271647103735541),  (-9.433349952523232, -7.999106443463781, -2.3682575660694347),  (3.704772125650199, 1.0526567864085812, 6.148581714099761),  (-3.5710511242327048, 5.512552040316693, -3.4318468250897647),  (-7.483466337225052, -1.506434920354559, 2.36641535124918),  (7.73363824231576, -8.460241422163824, -1.4623228616326003),  (10, 0, 0)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  Take the two largest factors of your N, if N==20 then the two largest factors are {5,4}, or, more generally {a,b}.  Calculate   dlat  = 180/(a+1) dlong = 360/(b+1})   Put your first point at {90-dlat/2,(dlong/2)-180}, your second at {90-dlat/2,(3*dlong/2)-180}, your 3rd at {90-dlat/2,(5*dlong/2)-180}, until you've tripped round the world once, by which time you've got to about {75,150} when you go next to {90-3*dlat/2,(dlong/2)-180}.  Obviously I'm working this in degrees on the surface of the spherical earth, with the usual conventions for translating +/- to N/S or E/W.  And obviously this gives you a completely non-random distribution, but it is uniform and the points are not bunched together.  To add some degree of randomness, you could generate 2 normally-distributed (with mean 0 and std dev of {dlat/3, dlong/3} as appropriate) and add them to your uniformly distributed points.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  edit: This does not answer the question the OP meant to ask, leaving it here in case people find it useful somehow.  We use the multiplication rule of probability, combined with infinitessimals. This results in 2 lines of code to achieve your desired result:  longitude: φ = uniform([0,2pi)) azimuth:   θ = -arcsin(1 - 2*uniform([0,1]))   (defined in the following coordinate system:)    Your language typically has a uniform random number primitive. For example in python you can use random.random() to return a number in the range [0,1). You can multiply this number by k to get a random number in the range [0,k). Thus in python, uniform([0,2pi)) would mean random.random()*2*math.pi.    Proof  Now we can't assign θ uniformly, otherwise we'd get clumping at the poles. We wish to assign probabilities proportional to the surface area of the spherical wedge (the θ in this diagram is actually φ):    An angular displacement dφ at the equator will result in a displacement of dφ*r. What will that displacement be at an arbitrary azimuth θ? Well, the radius from the z-axis is r*sin(θ), so the arclength of that \"latitude\" intersecting the wedge is dφ * r*sin(θ). Thus we calculate the cumulative distribution of the area to sample from it, by integrating the area of the slice from the south pole to the north pole.   (where stuff=dφ*r)  We will now attempt to get the inverse of the CDF to sample from it: http://en.wikipedia.org/wiki/Inverse_transform_sampling  First we normalize by dividing our almost-CDF by its maximum value. This has the side-effect of cancelling out the dφ and r.  azimuthalCDF: cumProb = (sin(θ)+1)/2 from -pi/2 to pi/2  inverseCDF: θ = -sin^(-1)(1 - 2*cumProb)   Thus:  let x by a random float in range [0,1] θ = -arcsin(1-2*x)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  OR... to place 20 points, compute the centers of the icosahedronal faces. For 12 points, find the vertices of the icosahedron. For 30 points, the mid point of the edges of the icosahedron. you can do the same thing with the tetrahedron, cube, dodecahedron and octahedrons: one set of points is on the vertices, another on the center of the face and another on the center of the edges. They cannot be mixed, however.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  Healpix solves a closely related problem (pixelating the sphere with equal area pixels):  http://healpix.sourceforge.net/  It's probably overkill, but maybe after looking at it you'll realize some of it's other nice properties are interesting to you. It's way more than just a function that outputs a point cloud.  I landed here trying to find it again; the name \"healpix\" doesn't exactly evoke spheres...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  # create uniform spiral grid numOfPoints = varargin[0] vxyz = zeros((numOfPoints,3),dtype=float) sq0 = 0.00033333333**2 sq2 = 0.9999998**2 sumsq = 2*sq0 + sq2 vxyz[numOfPoints -1] = array([(sqrt(sq0/sumsq)),                                (sqrt(sq0/sumsq)),                                (-sqrt(sq2/sumsq))]) vxyz[0] = -vxyz[numOfPoints -1]  phi2 = sqrt(5)*0.5 + 2.5 rootCnt = sqrt(numOfPoints) prevLongitude = 0 for index in arange(1, (numOfPoints -1), 1, dtype=float):   zInc = (2*index)/(numOfPoints) -1   radius = sqrt(1-zInc**2)    longitude = phi2/(rootCnt*radius)   longitude = longitude + prevLongitude   while (longitude > 2*pi):      longitude = longitude - 2*pi    prevLongitude = longitude   if (longitude > pi):     longitude = longitude - 2*pi    latitude = arccos(zInc) - pi/2   vxyz[index] = array([ (cos(latitude) * cos(longitude)) ,                         (cos(latitude) * sin(longitude)),                          sin(latitude)])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Evenly distributing n points on a sphere",
        "A_Content": "  This works and it's deadly simple. As many points as you want:      private function moveTweets():void {           var newScale:Number=Scale(meshes.length,50,500,6,2);         trace(\"new scale:\"+newScale);           var l:Number=this.meshes.length;         var tweetMeshInstance:TweetMesh;         var destx:Number;         var desty:Number;         var destz:Number;         for (var i:Number=0;i<this.meshes.length;i++){              tweetMeshInstance=meshes[i];              var phi:Number = Math.acos( -1 + ( 2 * i ) / l );             var theta:Number = Math.sqrt( l * Math.PI ) * phi;              tweetMeshInstance.origX = (sphereRadius+5) * Math.cos( theta ) * Math.sin( phi );             tweetMeshInstance.origY= (sphereRadius+5) * Math.sin( theta ) * Math.sin( phi );             tweetMeshInstance.origZ = (sphereRadius+5) * Math.cos( phi );              destx=sphereRadius * Math.cos( theta ) * Math.sin( phi );             desty=sphereRadius * Math.sin( theta ) * Math.sin( phi );             destz=sphereRadius * Math.cos( phi );              tweetMeshInstance.lookAt(new Vector3D());               TweenMax.to(tweetMeshInstance, 1, {scaleX:newScale,scaleY:newScale,x:destx,y:desty,z:destz,onUpdate:onLookAtTween, onUpdateParams:[tweetMeshInstance]});          }      }     private function onLookAtTween(theMesh:TweetMesh):void {         theMesh.lookAt(new Vector3D());     }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "math",
            "geometry",
            "uniform"
        ],
        "URL": "https://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need an algorithm that can give me positions around a sphere for N points (less than 20, probably) that vaguely spreads them out. There's no need for \"perfection\", but I just need it so none of them are bunched together.   This question provided good code, but I couldn't find a way to make this uniform, as this seemed 100% randomized. This blog post recommended had two ways allowing input of number of points on the sphere, but the Saff and Kuijlaars algorithm is exactly in psuedocode I could transcribe, and the code example I found contained \"node[k]\", which I couldn't see explained and ruined that possibility. The second blog example was the Golden Section Spiral, which gave me strange, bunched up results, with no clear way to define a constant radius. This algorithm from this question seems like it could possibly work, but I can't piece together what's on that page into psuedocode or anything.   A few other question threads I came across spoke of randomized uniform distribution, which adds a level of complexity I'm not concerned about. I apologize that this is such a silly question, but I wanted to show that I've truly looked hard and still come up short.  So, what I'm looking for is simple pseudocode to evenly distribute N points around a unit sphere, that either returns in spherical or Cartesian coordinates. Even better if it can even distribute with a bit of randomization (think planets around a star, decently spread out, but with room for leeway).     ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  There's not really a huge difference between python and ruby at least at an ideological level.  For the most part, they're just different flavors of the same thing.  Thus, I would recommend seeing which one matches your programming style more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "     I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp.   Wouldn't we all.       minimal distinction between code and data, Lisp style   Sadly, the minimal distinction between code and data and \"strange\" syntax are consequences of each other.  If you want easy-to-read syntax, you have Python.  However, the code is not represented in any of the commonly-used built-in data structures.  It fails—as most languages do—in item #1 of your 'important' list.  That makes it difficult to provide useful help.  You can't have it all.  Remember, you aren't the first to have this thought.  If something like your ideal language existed, we'd all be using it.  Since the real world falls short of your ideals, you'll have to re-prioritize your wish list.  The \"important\" section has to be rearranged to identify what's really important to you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Honestly, as far as metaprogramming facilities go, Ruby and Python are a lot more similar than some of their adherent like to admit.  This review of both language offers a pretty good comparison/review:   http://regebro.wordpress.com/2009/07/12/python-vs-ruby/   So, just pick one based on some criteria.  Maybe you like Rails and want to study that code.  Maybe SciPy is your thing.  Look at the ecosystem of libraries, community, etc, and pick one.  You certainly won't lose out on some metaprogramming nirvana based on your choice of either.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Disclaimer: I only dabble in either language, but I have at least written small working programs (not just quick scripts, for which I use Perl, bash or GNU make) in both.  Ruby can be really nice for the \"multiple paradigms\" point 3, because it works hard to make it easy to create domain-specific languages. For example, browse online and look at a couple of bits of Ruby on Rails code, and a couple of bits of Rake code. They're both Ruby, and you can see the similarities, but they don't look like what you'd normally think of as the same language.  Python seems to me to be a bit more predictable (possibly correlated to 'clean' and 'sane' point 2), but I don't really know whether that's because of the language itself or just that it's typically used by people with different values. I have never attempted deep magic in Python. I would certainly say that both languages are well thought out.  Both score well in 1 and 4. [Edit: actually 1 is pretty arguable - there is \"eval\" in both, as common in interpreted languages, but they're hardly conceptually pure. You can define closures, assign methods to objects, and whatnot. Not sure whether this goes as far as you want.]  Personally I find Ruby more fun, but in part that's because it's easier to get distracted thinking of cool ways to do things. I've actually used Python more. Sometimes you don't want cool, you want to get on with it so it's done before bedtime...  Neither of them is difficult to get into, so you could just decide to do your next minor task in one, and the one after that in the other. Or pick up an introductory book on each from the library, skim-read them both and see what grabs you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Have you considered Smalltalk? It offers a very simple, clear and extensible syntax with reflectivity and introspection capabilities and a fully integrated development environment that takes advantage of those capabilities. Have a look at some of the work being done in Squeak Smalltalk for instance. A lot of researchers using Squeak hang out on the Squeak mailing list and #squeak on freenode, so you can get help on complex issues very easily.  Other indicators of its current relevance: it runs on any platform you'd care to name (including the iPhone); Gilad Bracha is basing his Newspeak work on Squeak; the V8 team cut their teeth on Smalltalk VMs; and Dan Ingalls and Randal Schwartz have recently returned to Smalltalk work after years in the wilderness.  Best of luck with your search - let us know what you decide in the end.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Lisp satisfies all your criteria, including performance, and it is the only language that doesn't have (strange) syntax. If you eschew it on such an astoundingly ill-informed/wrong-headed basis and consequently miss out on the experience of using e.g. Emacs+SLIME+CL, you'll be doing yourself a great disservice.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  You are describing Ruby.        Good metaprogramming. Ability to create classes, methods, functions,   etc. at runtime. Preferably, minimal   distinction between code and data,   Lisp style.      It's very easy to extend and modify existing primitives at runtime. In ruby everything is an object, strings, integers, even functions.  You can also construct shortcuts for syntactic sugar, for example with class_eval.        Nice, clean, sane syntax and consistent, intuitive semantics.   Basically a well thought-out, fun to   use, modern language.      Ruby follows the principle of less surprise, and when comparing Ruby code vs the equivalent in other language many people consider it more \"beautiful\".        Multiple paradigms. No one paradigm is right for every project,   or even every small subproblem within   a project.      You can follow imperative, object oriented, functional and reflective.        An interesting language that actually affects the way one thinks   about programming.      That's very subjective, but from my point of view the ability to use many paradigms at the same time allows for very interesting ideas.  I've tried Python and it doesn't fit your important points.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Your 4 \"important\" points lead to Ruby exactly, while the 2 \"somewhat important\" points ruled by Python. So be it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Compare code examples that do the same thing (join with a newline non-empty descriptions of items from a myList list) in different languages (languages are arranged in reverse-alphabetic order):  Ruby:  myList.collect { |f| f.description }.select { |d| d != \"\" }.join(\"\\n\")   Or  myList.map(&:description).reject(&:empty?).join(\"\\n\")   Python:  descriptions = (f.description() for f in mylist) \"\\n\".join(filter(len, descriptions))    Or  \"\\n\".join(f.description() for f in mylist if f.description())   Perl:  join \"\\n\", grep { $_ } map { $_->description } @myList;   Or  join \"\\n\", grep /./, map { $_->description } @myList;   Javascript:  myList.map(function(e) e.description())       .filter(function(e) e).join(\"\\n\")   Io:  myList collect(description) select(!=\"\") join(\"\\n\")   Here's an Io guide.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Ruby would be better than Lisp in terms of being \"mainstream\" (whatever that really means, but one realistic concern is how easy it would be to find answers to your questions on Lisp programming if you were to go with that.)  In any case, I found Ruby very easy to pick up.  In the same amount of time that I had spent first learning Python (or other languages for that matter), I was soon writing better code much more efficiently than I ever had before.  That's just one person's opinion, though; take it with a grain of salt, I guess.  I know much more about Ruby at this point than I do Python or Lisp, but you should know that I was a Python person for quite a while before I switched.  Lisp is definitely quite cool and worth looking into; as you said, the size of community, etc. can change quite quickly.  That being said, the size itself isn't as important as the quality of the community.  For example, the #ruby-lang channel is still filled with some incredibly smart people.  Lisp seems to attract some really smart people too.  I can't speak much about the Python community as I don't have a lot of firsthand experience, but it seems to be \"too big\" sometimes.  (I remember people being quite rude on their IRC channel, and from what I've heard from friends that are really into Python, that seems to be the rule rather than the exception.)  Anyway, some resources that you might find useful are:  1) The Pragmatic Programmers Ruby Metaprogramming series (http://www.pragprog.com/screencasts/v-dtrubyom/the-ruby-object-model-and-metaprogramming) -- not free, but the later episodes are quite intriguing.  (The code is free, if you want to download it and see what you'd be learning about.)  2) On Lisp by Paul Graham (http://www.paulgraham.com/onlisp.html).  It's a little old, but it's a classic (and downloadable for free).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  I am using Python for many projects and I think Python does provide all the features you asked for.   important:   Metaprogramming: Python supports metaclasses and runtime class/method generation etc Syntax: Well thats somehow subjective. I like Pythons syntax for its simplicity, but some People complain that Python is whitespace-sensitive. Paradigms: Python supports procedural, object-oriented and basic functional programming.  I think Python has a very practical oriented style, it was very inspiring for me.   Somewhat important:   Performance: Well its a scripting language. But writing C extensions for Python is a common optimization practice.  Documentation: I cannot complain. Its not that detailed as someone may know from Java, but its good enough.   As you are grad student you may want to read this paper claiming that Python is all a scientist needs. Unfortunately I cannot compare Python to Ruby, since I never used that language.   Regards, Dennis     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  @Jason I respectively disagree. There are differences that make Ruby superior to Python for metaprogramming - both philosophical and pragmatic. For starters, Ruby gets inheritance right with Single Inheritance and Mixins. And when it comes to metaprogramming you simply need to understand that it's all about the self. The canonical difference here is that in Ruby you have access to the self object at runtime - in Python you do not!  Unlike Python, in Ruby there is no separate compile or runtime phase. In Ruby, every line of code is executed against a particular self object. In Ruby every class inherits from both object and a hidden metaclass. This makes for some interesting dynamics:  class Ninja   def rank     puts \"Orange Clan\"   end    self.name #=> \"Ninja\" end   Using self.name accesses the Ninja classes' metaclass name method to return the class name of Ninja. Does metaprogramming flower so beautiful in Python? I sincerely doubt it!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Well, if you don't like the lisp syntax perhaps assembler is the way to go. :-)  It certainly has minimal distinction between code and data, is multi-paradigm (or maybe that is no-paradigm) and it's a mind expanding (if tedious) experience both in terms of the learning and the tricks you can do.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Io satisfies all of your \"Important\" points. I don't think there's a better language out there for doing crazy meta hackery.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "     one that supports the metaprogramming hacks that just can't be done in a statically compiled language      I would love to find a language that allows some of the cool stuff that Lisp does   Lisp can be compiled.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Did you try Rebol?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  My answer would be neither. I know both languages, took a class on Ruby and been programming in python for several years. Lisp is good at metaprogramming due to the fact that its sole purpose is to transform lists, its own source code is just a list of tokens so metaprogramming is natural. The three languages I like best for this type of thing is Rebol, Forth and Factor. Rebol is a very strong dialecting language which takes code from its input stream, runs an expression against it and transforms it using rules written in the language. Very expressive and extremely good at dialecting. Factor and Forth are more or less completely divorced from syntax and you program them by defining and calling words. They are generally mostly written in their own language. You don't write applications in traditional sense, you extend the language by writing your own words to define your particular application. Factor can be especially nice as it has many features I have only seen in smalltalk for evaluating and working with source code. A really nice workspace, interactive documents, etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  There isn't really a lot to separate Python and Ruby.  I'd say the Python community is larger and more mature than the Ruby community, and that's really important for me.  Ruby is a more flexible language, which has positive and negative repercussions.  However, I'm sure there will be plenty of people to go into detail on both these languages, so I'll throw a third option into the ring.  How about JavaScript?  JavaScript was originally designed to be Scheme for the web, and it's prototype-based, which is an advantage over Python and Ruby as far as multi-paradigm and metaprogramming is concerned.  The syntax isn't as nice as the other two, but it is probably the most widely deployed language in existence, and performance is getting better every day.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  If you like the lisp-style code-is-data concept, but don't like the Lispy syntax, maybe Prolog would be a good choice.  Whether that qualifies as a \"fun to use, modern language\", I'll leave to others to judge. ;-)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Ruby is my choice after exploring Python, Smalltalk, and Ruby.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  What about OCaml ?  OCaml features: a static type system, type inference, parametric polymorphism, tail recursion, pattern matching, first class lexical closures, functors (parametric modules), exception handling, and incremental generational automatic garbage collection.  I think that it satisfies the following:     Important:         Nice, clean, sane syntax and consistent, intuitive semantics. Basically a well thought-out, fun to use, modern language.   Multiple paradigms. No one paradigm is right for every project, or even every small subproblem within a project.   An interesting language that actually affects the way one thinks about programming.         Somewhat important:         Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead.   Well-documented.         ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  I've use Python a very bit, but much more Ruby. However I'd argue they both provide what you asked for.   If I see all your four points then you may at least check: http://www.iolanguage.com/  And Mozart/Oz may be interesting for you also: http://mozart.github.io/  Regards Friedrich     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  For python-style syntax and lisp-like macros (macros that are real code) and good DSL see converge.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  I'm not sure that Python would fulfill all things you desire (especially the point about the minimal distinction between code and data), but there is one argument in favour of python. There is a project out there which makes it easy for you to program extensions for python in D, so you can have the best of both worlds. http://pyd.dsource.org/celerid.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  if you love the rose, you have to learn to live with the thorns :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  I would recommend you go with Ruby.   When I first started to learn it, I found it really easy to pick up.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Do not to mix Ruby Programming Language with Ruby Implementations, thinking that POSIX threads are not possible in ruby.  You can simply compile with pthread support, and this was already possible at the time this thread was created, if you pardon the pun.  The answer to this question is simple. If you like lisp, you will probably prefer ruby. Or, whatever you like.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  I suggest that you try out both languages and pick the one that appeals to you. Both Python and Ruby can do what you want.  Also read this thread.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Go with JS just check out AJS (Alternative JavaScript Syntax) at my github http://github.com/visionmedia  it will give you some cleaner looking closures etc :D     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Python vs. Ruby for metaprogramming [closed]",
        "A_Content": "  Concerning your main-point (meta-programming): Version 1.6 of Groovy has AST (Abstract Syntax Tree) programming built-in as a standard and integrated feature. Ruby has RubyParser, but it's an add-on.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "lisp",
            "metaprogramming"
        ],
        "URL": "https://stackoverflow.com/questions/144661/python-vs-ruby-for-metaprogramming",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm currently primarily a D programmer and am looking to add another language to my toolbox, preferably one that supports the metaprogramming hacks that just can't be done in a statically compiled language like D.  I've read up on Lisp a little and I would love to find a language that allows some of the cool stuff that Lisp does, but without the strange syntax, etc. of Lisp. I don't want to start a language flame war, and I'm sure both Ruby and Python have their tradeoffs, so I'll list what's important to me personally. Please tell me whether Ruby, Python, or some other language would be best for me.  Important:   Good metaprogramming. Ability to create classes, methods, functions, etc. at runtime.  Preferably, minimal distinction between code and data, Lisp style. Nice, clean, sane syntax and consistent, intuitive semantics.  Basically a well thought-out, fun to use, modern language. Multiple paradigms.  No one paradigm is right for every project, or even every small subproblem within a project. An interesting language that actually affects the way one thinks about programming.   Somewhat important:   Performance. It would be nice if performance was decent, but when performance is a real priority, I'll use D instead. Well-documented.     Not important:   Community size, library availability, etc.  None of these are characteristics of the language itself, and all can change very quickly. Job availability. I am not a full-time, professional programmer. I am a grad student and programming is tangentially relevant to my research. Any features that are primarily designed with very large projects worked on by a million code monkeys in mind.      ",
        "Q_Votes": "87"
    },
    {
        "Q_Title": "Run an OLS regression with Pandas Data Frame",
        "A_Content": "  I think you can almost do exactly what you thought would be ideal, using the statsmodels package which is one of pandas' optional dependencies (it's used for a few things in pandas.stats.)  >>> import pandas as pd >>> import statsmodels.formula.api as sm >>> df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]}) >>> result = sm.ols(formula=\"A ~ B + C\", data=df).fit() >>> print result.params Intercept    14.952480 B             0.401182 C             0.000352 dtype: float64 >>> print result.summary()                             OLS Regression Results                             ============================================================================== Dep. Variable:                      A   R-squared:                       0.579 Model:                            OLS   Adj. R-squared:                  0.158 Method:                 Least Squares   F-statistic:                     1.375 Date:                Thu, 14 Nov 2013   Prob (F-statistic):              0.421 Time:                        20:04:30   Log-Likelihood:                -18.178 No. Observations:                   5   AIC:                             42.36 Df Residuals:                       2   BIC:                             41.19 Df Model:                           2                                          ==============================================================================                  coef    std err          t      P>|t|      [95.0% Conf. Int.] ------------------------------------------------------------------------------ Intercept     14.9525     17.764      0.842      0.489       -61.481    91.386 B              0.4012      0.650      0.617      0.600        -2.394     3.197 C              0.0004      0.001      0.650      0.583        -0.002     0.003 ============================================================================== Omnibus:                          nan   Durbin-Watson:                   1.061 Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.498 Skew:                          -0.123   Prob(JB):                        0.780 Kurtosis:                       1.474   Cond. No.                     5.21e+04 ==============================================================================  Warnings: [1] The condition number is large, 5.21e+04. This might indicate that there are strong multicollinearity or other numerical problems.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "scikit-learn",
            "regression",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/19991445/run-an-ols-regression-with-pandas-data-frame",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame and I would like to able to predict the values of column A from the values in columns B and C. Here is a toy example:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30,40,50],                     \"B\": [20, 30, 10, 40, 50],                     \"C\": [32, 234, 23, 23, 42523]})   Ideally, I would have something like ols(A ~ B + C, data = df) but when I look at the examples from algorithm libraries like scikit-learn it appears to feed the data to the model with a list of rows instead of columns. This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place. What is the most pythonic way to run an OLS regression (or any machine learning algorithm more generally) on data in a pandas data frame?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Run an OLS regression with Pandas Data Frame",
        "A_Content": "  Note: pandas.stats has been removed with 0.20.0    It's possible to do this with pandas.stats.ols:  >>> from pandas.stats.api import ols >>> df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]}) >>> res = ols(y=df['A'], x=df[['B','C']]) >>> res -------------------------Summary of Regression Analysis-------------------------  Formula: Y ~ <B> + <C> + <intercept>  Number of Observations:         5 Number of Degrees of Freedom:   3  R-squared:         0.5789 Adj R-squared:     0.1577  Rmse:             14.5108  F-stat (2, 2):     1.3746, p-value:     0.4211  Degrees of Freedom: model 2, resid 2  -----------------------Summary of Estimated Coefficients------------------------       Variable       Coef    Std Err     t-stat    p-value    CI 2.5%   CI 97.5% --------------------------------------------------------------------------------              B     0.4012     0.6497       0.62     0.5999    -0.8723     1.6746              C     0.0004     0.0005       0.65     0.5826    -0.0007     0.0014      intercept    14.9525    17.7643       0.84     0.4886   -19.8655    49.7705 ---------------------------------End of Summary---------------------------------   Note that you need to have statsmodels package installed, it is used internally by the pandas.stats.ols function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "scikit-learn",
            "regression",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/19991445/run-an-ols-regression-with-pandas-data-frame",
        "A_Votes": "60",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame and I would like to able to predict the values of column A from the values in columns B and C. Here is a toy example:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30,40,50],                     \"B\": [20, 30, 10, 40, 50],                     \"C\": [32, 234, 23, 23, 42523]})   Ideally, I would have something like ols(A ~ B + C, data = df) but when I look at the examples from algorithm libraries like scikit-learn it appears to feed the data to the model with a list of rows instead of columns. This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place. What is the most pythonic way to run an OLS regression (or any machine learning algorithm more generally) on data in a pandas data frame?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Run an OLS regression with Pandas Data Frame",
        "A_Content": "  I don't know if this is new in sklearn or pandas, but I'm able to pass the data frame directly to sklearn without converting the data frame to a numpy array or any other data types.  from sklearn import linear_model  reg = linear_model.LinearRegression() reg.fit(df[['B', 'C']], df['A'])  >>> reg.coef_ array([  4.01182386e-01,   3.51587361e-04])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "scikit-learn",
            "regression",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/19991445/run-an-ols-regression-with-pandas-data-frame",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame and I would like to able to predict the values of column A from the values in columns B and C. Here is a toy example:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30,40,50],                     \"B\": [20, 30, 10, 40, 50],                     \"C\": [32, 234, 23, 23, 42523]})   Ideally, I would have something like ols(A ~ B + C, data = df) but when I look at the examples from algorithm libraries like scikit-learn it appears to feed the data to the model with a list of rows instead of columns. This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place. What is the most pythonic way to run an OLS regression (or any machine learning algorithm more generally) on data in a pandas data frame?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Run an OLS regression with Pandas Data Frame",
        "A_Content": "     This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place.   No it doesn't, just convert to a NumPy array:  >>> data = np.asarray(df)   This takes constant time because it just creates a view on your data. Then feed it to scikit-learn:  >>> from sklearn.linear_model import LinearRegression >>> lr = LinearRegression() >>> X, y = data[:, 1:], data[:, 0] >>> lr.fit(X, y) LinearRegression(copy_X=True, fit_intercept=True, normalize=False) >>> lr.coef_ array([  4.01182386e-01,   3.51587361e-04]) >>> lr.intercept_ 14.952479503953672      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "scikit-learn",
            "regression",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/19991445/run-an-ols-regression-with-pandas-data-frame",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame and I would like to able to predict the values of column A from the values in columns B and C. Here is a toy example:  import pandas as pd df = pd.DataFrame({\"A\": [10,20,30,40,50],                     \"B\": [20, 30, 10, 40, 50],                     \"C\": [32, 234, 23, 23, 42523]})   Ideally, I would have something like ols(A ~ B + C, data = df) but when I look at the examples from algorithm libraries like scikit-learn it appears to feed the data to the model with a list of rows instead of columns. This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place. What is the most pythonic way to run an OLS regression (or any machine learning algorithm more generally) on data in a pandas data frame?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  Python dictionary is a built-in type that supports key-value pairs.  streetno = {\"1\":\"Sachine Tendulkar\", \"2\":\"Dravid\", \"3\":\"Sehwag\", \"4\":\"Laxman\",\"5\":\"Kohli\"}   as well as using the dict keyword:  streetno = dict({\"1\":\"Sachine Tendulkar\", \"2\":\"Dravid\"})    or:  streetno = {} streetno[\"1\"] = \"Sachine Tendulkar\"       ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "153",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  All you wanted (at the time the question was originally asked) was a hint. Here's a hint: In Python, you can use dictionaries.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  It's built-in for Python. See dictionaries.  Based on your example:  streetno = {\"1\": \"Sachine Tendulkar\",             \"2\": \"Dravid\",             \"3\": \"Sehwag\",             \"4\": \"Laxman\",             \"5\": \"Kohli\" }   You could then access it like so:  sachine = streetno[\"1\"]   Also worth mentioning: it can use any non-mutable data type as a key. That is, it can use a tuple, boolean, or string as a key.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  streetno = { 1 : \"Sachin Tendulkar\",             2 : \"Dravid\",             3 : \"Sehwag\",             4 : \"Laxman\",             5 : \"Kohli\" }   And to retrieve values:  name = streetno.get(3, \"default value\")   Or  name = streetno[3]   That's using number as keys, put quotes around the numbers to use strings as keys.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  Hash maps are built-in in Python, they're called dictionaries:  streetno = {}                        #create a dictionary called streetno streetno[\"1\"] = \"Sachin Tendulkar\"   #assign value to key \"1\"   Usage:  \"1\" in streetno                      #check if key \"1\" is in streetno streetno[\"1\"]                        #get the value from key \"1\"   See the documentation for more information, e.g. built-in methods and so on. They're great, and very common in Python programs (unsurprisingly).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  Here is the implementation of the Hash Map using python For the simplicity hash map is of a fixed size 16. This can be changed easily. Rehashing is out of scope of this code.  class Node:     def __init__(self, key, value):         self.key = key         self.value = value         self.next = None  class HashMap:     def __init__(self):         self.store = [None for _ in range(16)]     def get(self, key):         index = hash(key) & 15         if self.store[index] is None:             return None         n = self.store[index]         while True:             if n.key == key:                 return n.value             else:                 if n.next:                     n = n.next                 else:                     return None     def put(self, key, value):         nd = Node(key, value)         index = hash(key) & 15         n = self.store[index]         if n is None:             self.store[index] = nd         else:             if n.key == key:                 n.value = value             else:                 while n.next:                     if n.key == key:                         n.value = value                         return                     else:                         n = n.next                 n.next = nd  hm = HashMap() hm.put(\"1\", \"sachin\") hm.put(\"2\", \"sehwag\") hm.put(\"3\", \"ganguly\") hm.put(\"4\", \"srinath\") hm.put(\"5\", \"kumble\") hm.put(\"6\", \"dhoni\") hm.put(\"7\", \"kohli\") hm.put(\"8\", \"pandya\") hm.put(\"9\", \"rohit\") hm.put(\"10\", \"dhawan\") hm.put(\"11\", \"shastri\") hm.put(\"12\", \"manjarekar\") hm.put(\"13\", \"gupta\") hm.put(\"14\", \"agarkar\") hm.put(\"15\", \"nehra\") hm.put(\"16\", \"gawaskar\") hm.put(\"17\", \"vengsarkar\") print(hm.get(\"1\")) print(hm.get(\"2\")) print(hm.get(\"3\")) print(hm.get(\"4\")) print(hm.get(\"5\")) print(hm.get(\"6\")) print(hm.get(\"7\")) print(hm.get(\"8\")) print(hm.get(\"9\")) print(hm.get(\"10\")) print(hm.get(\"11\")) print(hm.get(\"12\")) print(hm.get(\"13\")) print(hm.get(\"14\")) print(hm.get(\"15\")) print(hm.get(\"16\")) print(hm.get(\"17\"))   Output:  sachin sehwag ganguly srinath kumble dhoni kohli pandya rohit dhawan shastri manjarekar gupta agarkar nehra gawaskar vengsarkar      ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Hash Map in Python",
        "A_Content": "  class HashMap:     def __init__(self):         self.size = 64         self.map = [None] * self.size      def _get_hash(self, key):         hash = 0          for char in str(key):             hash += ord(char)         return hash % self.size      def add(self, key, value):         key_hash = self._get_hash(key)         key_value = [key, value]          if self.map[key_hash] is None:             self.map[key_hash] = list([key_value])             return True         else:             for pair in self.map[key_hash]:                 if pair[0] == key:                     pair[1] = value                     return True                 else:                     self.map[key_hash].append(list([key_value]))                     return True      def get(self, key):         key_hash = self._get_hash(key)         if self.map[key_hash] is not None:             for pair in self.map[key_hash]:                  if pair[0] == key:                     return pair[1]         return None      def delete(self, key):         key_hash = self._get_hash(key)          if self.map[key_hash] is None :             return False         for i in range(0, len(self.map[key_hash])):             if self.map[key_hash][i][0] == key:                 self.map[key_hash].pop(i)                 return True      def print(self):          print('---Phonebook---')         for item in self.map:             if item is not None:                 print(str(item))  h = HashMap()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "hashmap"
        ],
        "URL": "https://stackoverflow.com/questions/8703496/hash-map-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to implement a HashMap in Python.  I want to ask a user for an input. depending on his input I am retrieving some information from the HashMap. If the user enters a key of the HashMap,  I would like to retrieve the corresponding value.  How do I implement this functionality in Python?  HashMap<String,String> streetno=new HashMap<String,String>();    streetno.put(\"1\", \"Sachin Tendulkar\");    streetno.put(\"2\", \"Dravid\");    streetno.put(\"3\",\"Sehwag\");    streetno.put(\"4\",\"Laxman\");    streetno.put(\"5\",\"Kohli\")      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  Just to answer this question in a little more detail, and as Pavel said, Batch Normalization is just another layer, so you can use it as such to create your desired network architecture.   The general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). There's a small discussion of it here  In your case above, this might look like:    # import BatchNormalization from keras.layers.normalization import BatchNormalization  # instantiate model model = Sequential()  # we can think of this chunk as the input layer model.add(Dense(64, input_dim=14, init='uniform')) model.add(BatchNormalization()) model.add(Activation('tanh')) model.add(Dropout(0.5))  # we can think of this chunk as the hidden layer     model.add(Dense(64, init='uniform')) model.add(BatchNormalization()) model.add(Activation('tanh')) model.add(Dropout(0.5))  # we can think of this chunk as the output layer model.add(Dense(2, init='uniform')) model.add(BatchNormalization()) model.add(Activation('softmax'))  # setting up the optimization of our weights  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd)  # running the fitting model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)     Hope this clarifies things a bit more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "121",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  This thread is misleading.  Tried commenting on Lucas Ramadan's answer, but I don't have the right privileges yet, so I'll just put this here.  Batch normalization works best after the activation function, and here or here is why: it was developed to prevent internal covariate shift. Internal covariate shift occurs when the distribution of the activations of a layer shifts significantly throughout training.  Batch normalization is used so that the distribution of the inputs (and these inputs are literally the result of an activation function) to a specific layer doesn't change over time due to parameter updates from each batch (or at least, allows it to change in an advantageous way).  It uses batch statistics to do the normalizing, and then uses the batch normalization parameters (gamma and beta in the original paper) \"to make sure that the transformation inserted in the network can represent the identity transform\" (quote from original paper).  But the point is that we're trying to normalize the inputs to a layer, so it should always go immediately before the next layer in the network.  Whether or not that's after an activation function is dependent on the architecture in question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  It's almost become a trend now to have a Conv2D followed by a ReLu followed by a BatchNormalization layer. So I made up a small function to call all of them at once. Makes the model definition look a whole lot cleaner and easier to read.   def Conv2DReluBatchNorm(n_filter, w_filter, h_filter, inputs):     return BatchNormalization()(Activation(activation='relu')(Convolution2D(n_filter, w_filter, h_filter, border_mode='same')(inputs)))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  This thread has some considerable debate about whether BN should be applied before non-linearity of current layer or to the activations of the previous layer.   Although there is no correct answer, the authors of Batch Normalization say that  It should be applied immediately before the non-linearity of the current layer. The reason ( quoted from original paper) -   \"We add the BN transform immediately before the nonlinearity, by normalizing x = Wu+b. We could have also normalized the layer inputs u, but since u is likely the output of another nonlinearity, the shape of its distribution is likely to change during training, and constraining its first and second moments would not eliminate the covariate shift. In contrast, Wu + b is more likely to have a symmetric, non-sparse distribution, that is “more Gaussian” (Hyv¨arinen & Oja, 2000); normalizing it is likely to produce activations with a stable distribution.\"     ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  Keras now supports the use_bias=False option, so we can save some computation by writing like  model.add(Dense(64, use_bias=False)) model.add(BatchNormalization(axis=bn_axis)) model.add(Activation('tanh'))   or   model.add(Convolution2D(64, 3, 3, use_bias=False)) model.add(BatchNormalization(axis=bn_axis)) model.add(Activation('relu'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Where do I call the BatchNormalization function in Keras?",
        "A_Content": "  It is another type of layer, so you should add it as a layer in an appropriate place of your model  model.add(keras.layers.normalization.BatchNormalization())   See an example here: https://github.com/fchollet/keras/blob/master/examples/kaggle_otto_nn.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "neural-network",
            "keras",
            "data-science"
        ],
        "URL": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?  I read this documentation for it: http://keras.io/layers/normalization/  I don't see where I'm supposed to call it. Below is my code attempting to use it:  model = Sequential() keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None) model.add(Dense(64, input_dim=14, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(64, init='uniform')) model.add(Activation('tanh')) model.add(Dropout(0.5)) model.add(Dense(2, init='uniform')) model.add(Activation('softmax'))  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='binary_crossentropy', optimizer=sgd) model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)   I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I get the different parts of a Flask request's url?",
        "A_Content": "  You can examine the url through several Request fields:     A user requests the following URL:      http://www.example.com/myapplication/page.html?x=y       In this case the values of the above mentioned attributes would be the following:      path             /page.html     script_root      /myapplication     base_url         http://www.example.com/myapplication/page.html     url              http://www.example.com/myapplication/page.html?x=y     url_root         http://www.example.com/myapplication/    You can easily extract the host part with the appropriate splits.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "url",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/15974730/how-do-i-get-the-different-parts-of-a-flask-requests-url",
        "A_Votes": "155",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to detect if the request came from the localhost:5000 or foo.herokuapp.com host and what path was requested.  How do I get this information about a Flask request?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I get the different parts of a Flask request's url?",
        "A_Content": "  another example:  request:  curl -XGET http://127.0.0.1:5000/alert/dingding/test?x=y   then:  request.method:              GET request.url:                 http://127.0.0.1:5000/alert/dingding/test?x=y request.base_url:            http://127.0.0.1:5000/alert/dingding/test request.url_charset:         utf-8 request.url_root:            http://127.0.0.1:5000/ str(request.url_rule):       /alert/dingding/test request.host_url:            http://127.0.0.1:5000/ request.host:                127.0.0.1:5000 request.script_root: request.path:                /alert/dingding/test request.full_path:           /alert/dingding/test?x=y  request.args:                ImmutableMultiDict([('x', 'y')]) request.args.get('x'):       y      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/15974730/how-do-i-get-the-different-parts-of-a-flask-requests-url",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to detect if the request came from the localhost:5000 or foo.herokuapp.com host and what path was requested.  How do I get this information about a Flask request?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I get the different parts of a Flask request's url?",
        "A_Content": "  you should try:  request.url    It suppose to work always, even on localhost (just did it).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "url",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/15974730/how-do-i-get-the-different-parts-of-a-flask-requests-url",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to detect if the request came from the localhost:5000 or foo.herokuapp.com host and what path was requested.  How do I get this information about a Flask request?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  The general answer is that += tries to call the __iadd__ special method, and if that isn't available it tries to use __add__ instead. So the issue is with the difference between these special methods.  The __iadd__ special method is for an in-place addition, that is it mutates the object that it acts on. The __add__ special method returns a new object and is also used for the standard + operator.  So when the += operator is used on an object which has an __iadd__ defined the object is modified in place. Otherwise it will instead try to use the plain __add__ and return a new object.  That is why for mutable types like lists += changes the object's value, whereas for immutable types like tuples, strings and integers a new object is returned instead (a += b becomes equivalent to a = a + b).  For types that support both __iadd__ and __add__ you therefore have to be careful which one you use. a += b will call __iadd__ and mutate a, whereas a = a + b will create a new object and assign it to a. They are not the same operation!  >>> a1 = a2 = [1, 2] >>> b1 = b2 = [1, 2] >>> a1 += [3]          # Uses __iadd__, modifies a1 in-place >>> b1 = b1 + [3]      # Uses __add__, creates new list, assigns it to b1 >>> a2 [1, 2, 3]              # a1 and a2 are still the same list >>> b2 [1, 2]                 # whereas only b1 was changed   For immutable types (where you don't have an __iadd__) a += b and a = a + b are equivalent. This is what lets you use += on immutable types, which might seem a strange design decision until you consider that otherwise you couldn't use += on immutable types like numbers!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "97",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  For the general case, see Scott Griffith's answer. When dealing with lists like you are, though, the += operator is a shorthand for someListObject.extend(iterableObject). See the documentation of extend().  The extend function will append all elements of the parameter to the list.  When doing foo += something you're modifying the list foo in place, thus you don't change the reference that the name foo points to, but you're changing the list object directly. With foo = foo + something, you're actually creating a new list.  This example code will explain it:  >>> l = [] >>> id(l) 13043192 >>> l += [3] >>> id(l) 13043192 >>> l = l + [3] >>> id(l) 13059216   Note how the reference changes when you reassign the new list to l.  As bar is a class variable instead of an instance variable, modifying in place will affect all instances of that class. But when redefining self.bar, the instance will have a separate instance variable self.bar without affecting the other class instances.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  The problem here is, bar is defined as a class attribute, not an instance variable.  In foo, the class attribute is modified in the init method, that's why all instances are affected.  In foo2, an instance variable is defined using the (empty) class attribute, and every instance gets its own bar.  The \"correct\" implementation would be:  class foo:     def __init__(self, x):         self.bar = [x]   Of course, class attributes are completely legal. In fact, you can access and modify them without creating an instance of the class like this:  class foo:     bar = []  foo.bar = [x]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  Although much time has passed and many correct things were said, there is no answer which bundles both effects.  You have 2 effects:   a \"special\", maybe unnoticed behaviour of lists with += (as stated by Scott Griffiths) the fact that class attributes as well as instance attributes are involved (as stated by Can Berk Büder)   In class foo, the __init__ method modifies the class attribute. It is because self.bar += [x] translates to self.bar = self.bar.__iadd__([x]). __iadd__() is for inplace modification, so it modifies the list and returns a reference to it.  Note that the instance dict is modified although this would normally not be necessary as the class dict already contains the same assignment. So this detail goes almost unnoticed - except if you do a foo.bar = [] afterwards. Here the instances's bar stays the same thanks to the said fact.  In class foo2, however, the class's bar is used, but not touched. Instead, a [x] is added to it, forming a new object, as self.bar.__add__([x]) is called here, which doesn't modify the object. The result is put into the instance dict then, giving the instance the new list as a dict, while the class's attribute stays modified.  The distinction between ... = ... + ... and ... += ... affects as well the assignments afterwards:  f = foo(1) # adds 1 to the class's bar and assigns f.bar to this as well. g = foo(2) # adds 2 to the class's bar and assigns g.bar to this as well. # Here, foo.bar, f.bar and g.bar refer to the same object. print f.bar # [1, 2] print g.bar # [1, 2]  f.bar += [3] # adds 3 to this object print f.bar # As these still refer to the same object, print g.bar # the output is the same.  f.bar = f.bar + [4] # Construct a new list with the values of the old ones, 4 appended. print f.bar # Print the new one print g.bar # Print the old one.  f = foo2(1) # Here a new list is created on every call. g = foo2(2) print f.bar # So these all obly have one element. print g.bar    You can verify the identity of the objects with print id(foo), id(f), id(g) (don't forget the additional ()s if you are on Python3).  BTW: The += operator is called \"augmented assignment\" and generally is intended to do inplace modifications as far as possible.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  The other answers would seem to pretty much have it covered, though it seems worth quoting and referring to the Augmented Assignments PEP 203:     They [the augmented assignment operators] implement the same operator   as their normal binary form, except that the operation is done   `in-place' when the left-hand side object supports it, and that the   left-hand side is only evaluated once.    ...     The idea behind augmented   assignment in Python is that it isn't just an easier way to write the   common practice of storing the result of a binary operation in its   left-hand operand, but also a way for the left-hand operand in   question to know that it should operate `on itself', rather than   creating a modified copy of itself.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  >>> elements=[[1],[2],[3]] >>> subset=[] >>> subset+=elements[0:1] >>> subset [[1]] >>> elements [[1], [2], [3]] >>> subset[0][0]='change' >>> elements [['change'], [2], [3]]  >>> a=[1,2,3,4] >>> b=a >>> a+=[5] >>> a,b ([1, 2, 3, 4, 5], [1, 2, 3, 4, 5]) >>> a=[1,2,3,4] >>> b=a >>> a=a+[5] >>> a,b ([1, 2, 3, 4, 5], [1, 2, 3, 4])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why does += behave unexpectedly on lists?",
        "A_Content": "  There are two things involved here:  1. class attributes and instance attributes 2. difference between the operators + and += for lists   + operator calls the __add__ method on a list. It takes all the elements from its operands and makes a new list containing those elements maintaining their order.    += operator calls __iadd__ method on the list. It takes an iterable and appends all the elements of the iterable to the list in place. It does not create a new list object.    In class foo the statement  self.bar += [x] is not an assignment statement but actually translates to   self.bar.__iadd__([x])  # modifies the class attribute     which modifies the list in place and acts like the list method extend.  In class foo2, on the contrary, the assignment statement in the init method  self.bar = self.bar + [x]     can be deconstructed as: The instance has no attribute bar (there is a class attribute of the same name, though) so it accesses the class attribute bar and creates a new list by appending x to it. The statement translates to:  self.bar = self.bar.__add__([x]) # bar on the lhs is the class attribute    Then it creates an instance attribute bar and assigns the newly created list to it. Note that bar on the rhs of the assignment is different from the bar on the lhs.  For instances of class foo, bar is a class attribute and not instance attribute. Hence any change to the class attribute bar will be reflected for all instances.   On the contrary, each instance of the class foo2 has its own instance attribute bar which is different from the class attribute of the same name bar.  f = foo2(4) print f.bar # accessing the instance attribute. prints [4]   print f.__class__.bar # accessing the class attribute. prints []     Hope this clears things.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "augmented-assignment"
        ],
        "URL": "https://stackoverflow.com/questions/2347265/why-does-behave-unexpectedly-on-lists",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The += operator in python seems to be operating unexpectedly on lists.  Can anyone tell me what is going on here?  class foo:        bar = []      def __init__(self,x):          self.bar += [x]   class foo2:      bar = []      def __init__(self,x):           self.bar = self.bar + [x]  f = foo(1) g = foo(2) print f.bar print g.bar   f.bar += [3] print f.bar print g.bar  f.bar = f.bar + [4] print f.bar print g.bar  f = foo2(1) g = foo2(2) print f.bar  print g.bar    OUTPUT  [1, 2] [1, 2] [1, 2, 3] [1, 2, 3] [1, 2, 3, 4] [1, 2, 3] [1] [2]   foo += bar seems to affect every instance of the class, whereas foo = foo + bar seems to behave in the way I would expect things to behave.   The += operator is called a \"compound assignment operator\".      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Parse date strings? [duplicate]",
        "A_Content": "  You can use dateutil.parser.parse to parse strings into datetime objects.  dateutil.parser.parse will attempt to guess the format of your string, if you know the exact format in advance then you can use datetime.strptime which you supply a format string to (see Brent Washburne's answer).  from dateutil.parser import parse  a = \"2012-10-09T19:00:55Z\"  b = parse(a)  print(b.weekday()) # 1 (equal to a Tuesday)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "datetime-parsing"
        ],
        "URL": "https://stackoverflow.com/questions/23277268/parse-date-strings",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to parse an ISO 8601-formatted date?                                        23 answers                                          I have a datasets where all the dates have the following format:  2012-10-09T19:00:55Z   I'd like to be able to be able to use methods like .weekday on them. How do I convert them to the proper format in Python?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Parse date strings? [duplicate]",
        "A_Content": "  This has already been answered here: How do I translate a ISO 8601 datetime string into a Python datetime object?  d = datetime.datetime.strptime( \"2012-10-09T19:00:55Z\", \"%Y-%m-%dT%H:%M:%SZ\" ) d.weekday()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "datetime-parsing"
        ],
        "URL": "https://stackoverflow.com/questions/23277268/parse-date-strings",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to parse an ISO 8601-formatted date?                                        23 answers                                          I have a datasets where all the dates have the following format:  2012-10-09T19:00:55Z   I'd like to be able to be able to use methods like .weekday on them. How do I convert them to the proper format in Python?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Parse date strings? [duplicate]",
        "A_Content": "  You should have a look at moment which is a python port of the excellent js lib momentjs.   One advantage of it is the support of ISO 8601 strings formats, as well as a generic \"% format\" :  import moment time_string='2012-10-09T19:00:55Z'  m = moment.date(time_string, '%Y-%m-%dT%H:%M:%SZ') print m.format('YYYY-M-D H:M') print m.weekday   Result:  2012-10-09 19:10 2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "datetime-parsing"
        ],
        "URL": "https://stackoverflow.com/questions/23277268/parse-date-strings",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to parse an ISO 8601-formatted date?                                        23 answers                                          I have a datasets where all the dates have the following format:  2012-10-09T19:00:55Z   I'd like to be able to be able to use methods like .weekday on them. How do I convert them to the proper format in Python?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  It's good to know that    but also know that math.log takes an optional second argument which allows you to specify the base:  In [22]: import math  In [23]: math.log? Type:       builtin_function_or_method Base Class: <type 'builtin_function_or_method'> String Form:    <built-in function log> Namespace:  Interactive Docstring:     log(x[, base]) -> the logarithm of x to the given base.     If the base not specified, returns the natural logarithm (base e) of x.   In [25]: math.log(8,2) Out[25]: 3.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "171",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  float in - float out  import math  log2 = math.log(x, 2.0) log2 = math.log2(x)   # python 3.4 or later    Thanks @akashchandrakar and @unutbu.     float in - int out  If all you need is the integer part of log base 2 of a floating point number, math.frexp() could be pretty efficient:  log2int_slow = int(math.floor(math.log(x, 2.0))) log2int_fast = math.frexp(x)[1] - 1    Python frexp() calls the C function frexp() which just grabs and tweaks the exponent. Python frexp() returns a tuple (mantissa, exponent). So [1] gets the exponent part.  For integral powers of 2 the exponent is one more than you might expect.  For example 32 is stored as 0.5x2⁶.  This explains the - 1 above.  Also works for 1/32 which is stored as 0.5x2⁻⁴.      int in - int out  If both input and output are integers, the integer method .bit_length() could be even more efficient:  log2int_faster = x.bit_length() - 1    - 1 because 2ⁿ requires n+1 bits. This is the only option that works for very large integers, e.g. 2**10000. All the int-output versions will floor the log toward negative infinity, so log₂31 is 4 not 5.        ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  If you are on python 3.4 or above then it already has a built-in function for computing log2(x)  import math 'finds log base2 of x' answer = math.log2(x)   If you are on older version of python then you can do like this  import math 'finds log base2 of x' answer = math.log(x)/math.log(2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  Using numpy:  In [1]: import numpy as np  In [2]: np.log2? Type:           function Base Class:     <type 'function'> String Form:    <function log2 at 0x03049030> Namespace:      Interactive File:           c:\\python26\\lib\\site-packages\\numpy\\lib\\ufunclike.py Definition:     np.log2(x, y=None) Docstring:     Return the base 2 logarithm of the input array, element-wise.  Parameters ---------- x : array_like   Input array. y : array_like   Optional output array with the same shape as `x`.  Returns ------- y : ndarray   The logarithm to the base 2 of `x` element-wise.   NaNs are returned where `x` is negative.  See Also -------- log, log1p, log10  Examples -------- >>> np.log2([-1, 2, 4]) array([ NaN,   1.,   2.])  In [3]: np.log2(8) Out[3]: 3.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  http://en.wikipedia.org/wiki/Binary_logarithm  def lg(x, tol=1e-13):   res = 0.0    # Integer part   while x<1:     res -= 1     x *= 2   while x>=2:     res += 1     x /= 2    # Fractional part   fp = 1.0   while fp>=tol:     fp /= 2     x *= x     if x >= 2:         x /= 2         res += fp    return res      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  >>> def log2( x ): ...     return math.log( x ) / math.log( 2 ) ...  >>> log2( 2 ) 1.0 >>> log2( 4 ) 2.0 >>> log2( 8 ) 3.0 >>> log2( 2.4 ) 1.2630344058337937 >>>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  logbase2(x) = log(x)/log(2)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  log_base_2(x) = log(x) / log(2)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  Try this ,  import math print(math.log(8,2))  # math.log(number,base)       ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Log to the base 2 in python",
        "A_Content": "  Don't forget that log[base A] x = log[base B] x / log[base B] A.  So if you only have log (for natural log) and log10 (for base-10 log), you can use  myLog2Answer = log10(myInput) / log10(2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logarithm"
        ],
        "URL": "https://stackoverflow.com/questions/3719631/log-to-the-base-2-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How should I compute log to the base two in python. Eg. I have this equation where I am using log base 2  import math e = -(t/T)* math.log((t/T)[, 2])      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  You need to install psycopg2 Python library.  Installation    Download http://initd.org/psycopg/, then install it under Python PATH  After downloading, easily extract the tarball and:  $ python setup.py install   Or if you wish, install it by either easy_install or pip.  (I prefer to use pip over easy_install for no reason.)   $ easy_install psycopg2 $ pip install psycopg2   Configuration    in settings.py  DATABASES = {     'default': {         'ENGINE': 'django.db.backends.postgresql',         'NAME': 'db_name',                               'USER': 'db_user',         'PASSWORD': 'db_user_password',         'HOST': '',         'PORT': 'db_port_number',     } }     - Other installation instructions can be found at download page and install page.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "176",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  Also make sure you have the PostgreSQL development package installed. On Ubuntu you need to do something like this:  $ sudo apt-get install libpq-dev      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  Step by step that I use:   sudo apt-get install python-dev sudo apt-get install postgresql-server-dev-9.1 sudo apt-get install python-psycopg2 - Or sudo pip install psycopg2   You may want to install a graphic tools for manager yours databases, then do: sudo apt-get install postgresql pgadmin3   After, you must change Postgre user password, then do:   sudo su su postgres -c psql postgres ALTER USER postgres WITH PASSWORD 'YourPassWordHere'; \\q   In my settings.py file I do:  DATABASES = {     'default': {         'ENGINE': 'django.db.backends.postgresql_psycopg2',         'NAME': 'dbname',         'USER': 'postgres',         'PASSWORD': 'postgres',         'HOST': '',         'PORT': '',     } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  This may seem a bit lengthy, but it worked for me without any error.  At first, Install phppgadmin from Ubuntu Software Center.  Then run these steps in terminal.  sudo apt-get install libpq-dev python-dev pip install psycopg2 sudo apt-get install postgresql postgresql-contrib phppgadmin   Start the apache server  sudo service apache2 start   Now run this too in terminal, to edit the apache file.  sudo gedit /etc/apache2/apache2.conf   Add the following line to the opened file:  Include /etc/apache2/conf.d/phppgadmin   Now reload apache. Use terminal.  sudo /etc/init.d/apache2 reload   Now you will have to create a new database. Login as 'postgres' user. Continue in terminal.  sudo su - postgres   In case you have trouble with the password of 'postgres', you can change it using the answer here https://stackoverflow.com/a/12721020/1990793 and continue with the steps.  Now create a database  createdb <db_name>   Now create a new user to login to phppgadmin later, providing a new password.  createuser -P <new_user>   Now your postgressql has been setup, and you can go to:  http://localhost/phppgadmin/   and login using the new user you've created, in order to view the database.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  You can  install \"psycopg\" with the following command:  # sudo easy_install psycopg2   Alternatively, you can use pip :  # pip install psycopg2   easy_install and pip are included with ActivePython, or manually installed from the respective project sites.  Or, simply get the pre-built Windows installer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  The immediate problem seems to be that you're missing the psycopg module.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  If you are using Fedora 20, Django 1.6.5, postgresql 9.3.* and you need the psycopg2 module, do this:  yum install postgresql-devel easy_install psycopg2   If you are like me, you may have trouble finding the well documented libpq-dev rpm... The above worked for me just now.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  I was having the same Issue on Mac.  The solution was to use only PIP to install everything, and touch some things.  First install PIP from: https://pip.pypa.io/en/latest/  Then you want to make sure if path to pg_config is in your PATH (echo $PATH), if not you can edit your bash_profile:  vi /Users/<user>/.bash_profile   and add this line:  export PATH=$PATH:/path/to/pg_config/bin   If you don't know where pg_config is you can use the \"locate\" tool, but be sure your locate.db is up to date (i was using an old locate.db and using paths that does not exists).  sudo /usr/libexec/locate.updatedb locate pg_config   Then install Django (if needed) and psycopg2.  sudo pip install Django sudo pip install psycopg2   And then in settings.py (localhost:defaultport)  DATABASES = {     'default': {         'ENGINE': 'django.db.backends.postgresql_psycopg2',         'NAME': 'dbname',         'USER': 'postgres',         'PASSWORD': 'postgres',         'HOST': '',         'PORT': '',     } }   Greets!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  $ sudo apt-get install libpq-dev   Year, this solve my problem. After execute this, do: pip install psycopg2     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  Please note that installation of psycopg2 via pip or setup.py requires to have Visual Studio  2008 (more precisely executable file vcvarsall.bat). If you don't have admin rights to install it or set the appropriate PATH variable on Windows, you can download already compiled library from here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to setup PostgreSQL Database in Django?",
        "A_Content": "  This is one of the very good and step by step process to set up PostgreSQL in ubuntu server. I have tried it with Ubuntu 16.04 and its working.  https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "django-settings"
        ],
        "URL": "https://stackoverflow.com/questions/5394331/how-to-setup-postgresql-database-in-django",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and Django.  I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:  C:\\xampp\\htdocs\\djangodir>python manage.py syncdb Traceback (most recent call last):   File \"manage.py\", line 11, in <module>     execute_manager(settings)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 438, in execute_manager     utility.execute()   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 379, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 261, in fetch_command     klass = load_command_class(app_name, subcommand)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 67, in load_command_class     module = import_module('%s.management.commands.%s' % (app_name, name))   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\commands\\syncdb.py\" , line 7, in <module>     from django.core.management.sql import custom_sql_for_model, emit_post_sync_ signal   File \"C:\\Python27\\lib\\site-packages\\django\\core\\management\\sql.py\", line 6, in  <module>     from django.db import models   File \"C:\\Python27\\lib\\site-packages\\django\\db\\__init__.py\", line 77, in <modul e>     connection = connections[DEFAULT_DB_ALIAS]   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 92, in __getitem __     backend = load_backend(db['ENGINE'])   File \"C:\\Python27\\lib\\site-packages\\django\\db\\utils.py\", line 33, in load_back end     return import_module('.base', backend_name)   File \"C:\\Python27\\lib\\site-packages\\django\\utils\\importlib.py\", line 35, in im port_module     __import__(name)   File \"C:\\Python27\\lib\\site-packages\\django\\db\\backends\\postgresql\\base.py\", li ne 23, in <module>     raise ImproperlyConfigured(\"Error loading psycopg module: %s\" % e) django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo dule named psycopg   Can someone give me a clue on what is going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  If you look at the line which is causing the error, you'll see this:  from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl   This line comment states the dependency as numpy+mkl (numpy with Intel Math Kernel Library). This means that you've installed the numpy by pip, but the scipy was installed by precompiled archive, which expects numpy+mkl.  This problem can be easy solved by installation for numpy+mkl from whl file from here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "216",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  Reinstall numpy-1.11.0_XXX.whl (for your Python) from www.lfd.uci.edu/~gohlke/pythonlibs. This file has the same name and version if compare with the variant downloaded by me earlier 29.03.2016, but its size and content differ from old variant. After re-installation error disappeared.  Second option - return back to scipy 0.17.0 from 0.17.1  P.S. I use Windows 64-bit version of Python 3.5.1, so can't guarantee that numpy for Python 2.7 is already corrected.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  I'm not sure if this is a good solution but it removed the error.  I commented out the line:   from numpy._distributor_init import NUMPY_MKL    and it worked. Not sure if this will cause other features to break though     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  I had the same problem while installing gensim on windows. Gensim is dependent on scipy and scipy on numpy. Making all three work is real pain. It took me a lot of time to make all there work on same time.  Solution: If you are using windows make sure you install numpy+mkl instead of just numpy. If you have already installed scipy and numpy, uninstall then using \"pip uninstall scipy\" and \"pip uninstall numpy\"  Then download numpy-1.13.1+mkl-cp34-cp34m-win32.whl from http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy and install using pip install numpy-1.13.1+mkl-cp34-cp34m-win32.wh Note: in cp34-cp34m 34 represent the version of python you are using, so download the relevant version.  Now download scipy from http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy (appropriate version for your python and system) and install using \"pip install  scipy‑0.19.1‑cp34‑cp34m‑win32.whl\"  Your numpy and Scipy both should work now.  These binaries by Christoph Gohlke makes it very easy to install python packages on windows. But make sure you download all the dependent packages from there.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  The reason for the error is you upgraded your numpy library of which there are some functionalities from scipy that are required by the current version for it to run which may not be found in scipy. Just upgrade your scipy library using python -m pip install scipy --upgrade. I was facing the same error and this solution worked on my python 3.5.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  From your log its clear that numpy package is missing. As mention in the PyPI package:     The SciPy library depends on NumPy, which provides convenient and fast N-dimensional array manipulation.   So, try installing numpy package for python as you did with scipy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "ImportError: cannot import name NUMPY_MKL",
        "A_Content": "  I recently got the same error when trying to load scipy in jupyter (python3.x, win10), although just having upgraded to numpy-1.13.3+mkl through pip.  The solution was to simply upgrade the scipy package (from v0.19 to v1.0.0).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "python-2.7",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/37267399/importerror-cannot-import-name-numpy-mkl",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to run the following simple code   import scipy scipy.test()   But I am getting the following error  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\Python27\\lib\\site-packages\\spyderlib\\widgets\\externalshell\\sitecustomize.py\", line 586, in runfile     execfile(filename, namespace)   File \"C:/Users/Mustafa/Documents/My Python Code/SpectralGraphAnalysis/main.py\", line 8, in <module>     import scipy   File \"C:\\Python27\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name NUMPY_MKL   I am using python 2.7 under windows 10.  I have installed scipy but that does not seem to solve the problem  Any help is appreciated.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  If you installed it through running   pip install virtualenv   What you need to do is to run:  sudo /usr/bin/easy_install virtualenv   which puts it in /usr/local/bin/.  The above directory by default should be in your PATH; otherwise, edit your .zshrc (or .bashrc) accordingly.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "177",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  I faced the same issue and this is how I solved it:   The issue occurred to me because I installed virtualenv via pip as a regular user (not root). pip installed the packages into the directory ~/.local/lib/pythonX.X/site-packages When I ran pip as root or with admin privileges (sudo), it installed packages in /usr/lib/pythonX.X/dist-packages. This path might be different for you. virtualenv command gets recognized only in the second scenario So, to solve the issue, do pip uninstall virtualenv and then reinstall it with sudo pip install virtualenv (or install as root)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  I had same problem on Mac OS X El Capitan.  When I installed virtualenv like that sudo pip3 install virtualenv I didn't have virtualenv under my command line.  I solved this problem by following those steps:   Uninstall previous installations. Switch to super user account prior to virtualenv installation by calling sudo su Install virtualenv by calling pip3 install virtualenv Finally you should be able to access virtualenv from both user and super user account.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  The simplest answer. Just:  pip uninstall virtualenv   and then:  pip install virtualenv   Or you maybe installed virtualenv with sudo, in that case:  pip install --user virtualenv      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  On Ubuntu 18.04 LTS I also faced same error. Following command worked:   sudo apt-get install python-virtualenv   For Mac OS you can try with  brew      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  You said that every time you run the pip install you get Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages. What you need to do is the following:   Change Directory (go to to the one where the virtualenv.py)  cd /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages If you do an ls you will see that the script is there virtualenv.py Run the script like this: python virtualenv.py --distribute /the/path/at/which/you/want/the/new/venv/at theNameOfTheNewVirtualEnv   Hope this helps. My advice would be to research venvs more. Here is a good resource: https://www.dabapps.com/blog/introduction-to-pip-and-virtualenv-python/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  I had troubles because used apt to install python-virtualenv package. To get it working I had to remove this package:  $sudo apt-get remove python-virtualenv  end then install it with pip:  $sudo pip install virtualenv     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  I think your problem can be solved using a simple symbolic link, but you are creating the symbolic link to the wrong file. As far as I know virtualenv is installed to /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenv, (you can change the numbers for your Python version) so the command for creating the symbolic link should be:  ln -s /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenv /usr/local/bin/virtualenv      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  Figure out the problem  Try installing with the --verbose flag  pip install virtualenv --verbose   Output will look something like this    ..   Using cached virtualenv-15.1.0-py2.py3-none-any.whl   Downloading from URL https://pypi.python.org/packages/6f/86/3dc328ee7b1a6419ebfac7896d882fba83c48e3561d22ddddf38294d3e83/virtualenv-15.1.0-py2.py3-none-any.whl#md5=aa7e5b86cc8cdb99794c4b99e8d670f3 (from https://pypi.python.org/simple/virtualenv/) Installing collected packages: virtualenv    changing mode of /home/manos/.local/bin/virtualenv to 755 Successfully installed virtualenv-15.1.0 Cleaning up...   From the output we can see that it's installed at /home/manos/.local/bin/virtualenv so let's ensure PATH includes that.  echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin   In my case we can clearly see that /home/manos/.local/bin is totally missing and that's why the shell can't find the program.  Solutions  We can solve this in many ways:   We can install directly to a specific directory by fiddling with pip options (not recomended). Create appropriate symlinks at /usr/local/bin or similar. Append /home/manos/.local/bin to PATH. Install as sudo to install directly to /usr/local/bin   The two last options are probably the most sensible. The last solution is the simplest so therefore I will just show solution 3.  Add this to ~/.profile:  PATH=\"$PATH:$HOME/.local/bin\"   Logout out and in again and it should work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  Ensure that virtualenv is executable.  If virtualenv is not found, running the full path (/usr/local/bin/virtualenv) should work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  Follow these basic steps to setup the virtual env  sudo pip install virtualenv virtualenvwrapper sudo rm -rf ~/get-pip.py ~/.cache/pip   we need to update our ~/.bashrc  export WORKON_HOME=$HOME/.virtualenvs source /usr/local/bin/virtualenvwrapper.sh   The ~/.bashrc file is simply a shell script that Bash runs whenever you launch a new terminal. You normally use this file to set various configurations. In this case, we are setting an environment variable called WORKON_HOME  to point to the directory where our Python virtual environments live. We then load any necessary configurations from virtualenvwrapper .  To update your ~/.bashrc file simply use a standard text editor, nano  is likely the easiest to operate. A more simple solution is to use the cat  command and avoid editors entirely:  echo -e \"\\n# virtualenv and virtualenvwrapper\" >> ~/.bashrc echo \"export WORKON_HOME=$HOME/.virtualenvs\" >> ~/.bashrc echo \"source /usr/local/bin/virtualenvwrapper.sh\" >> ~/.bashrc   After editing our ~/.bashrc  file, we need to reload the changes:  source ~/.bashrc   Now that we have installed virtualenv  and virtualenvwrapper , the next step is to actually create the Python virtual environment — we do this using the mkvirtualenv  command.  mkvirtualenv YOURENV      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Virtualenv Command Not Found",
        "A_Content": "  Same problem: So I just did pip uninstall virtualenv Then  pip install virtualenv  pip install virtualenv --user   Collecting virtualenv   Using cached https://files.pythonhosted.org/packages/b6/30/96a02b2287098b23b875bc8c2f58071c35d2efe84f747b64d523721dc2b5/virtualenv-16.0.0-py2.py3-none-any.whl Installing collected packages: virtualenv  Then I got this :     The script virtualenv is installed in '/Users/brahim/Library/Python/2.7/bin' which is not on PATH.     Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.   which clearly says where it is installed and what to do to get it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/31133050/virtualenv-command-not-found",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I couldn't get virtualenv to work despite various attempts. I installed virtualenv on MAC OS X using:  pip install virtualenv   and have also added the PATH into my .bash_profile. Every time I try to run the virtualenv command, it returns:  -bash: virtualenv: command not found   Every time I run pip install virtualenv, it returns:  Requirement already satisfied (use --upgrade to upgrade): virtualenv in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages   I understand that in mac, the virtualenv should be correctly installed in   /usr/local/bin   The virtualenv is indeed installed in /usr/local/bin, but whenever I try to run the virtualenv command, the command is not found. I've also tried to run the virtualenv command in the directory /usr/local/bin, and it gives me the same result:   -bash: virtualenv: command not found   These are the PATHs I added to my .bash_profile  export PATH=$PATH:/usr/local/bin export PATH=$PATH:/usr/local/bin/python export PATH=$PATH:/Library/Framework/Python.framework/Version/2.7/lib/site-packages   Any workarounds for this? Why is this the case?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  DateTime doesn't have a default key as an input. The default key should be an input to the Column function. Try this:  import datetime from sqlalchemy import Column, Integer, DateTime from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = Column(DateTime, default=datetime.datetime.utcnow)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  Calculate timestamps within your DB, not your client  For sanity, you probably want to have all datetimes calculated by your DB server, rather than the application server. Calculating the timestamp in the application can lead to problems because network latency is variable, clients experience slightly different clock drift, and different programming languages occasionally calculate time slightly differently.   SQLAlchemy allows you to do this by passing func.now() or func.current_timestamp() (they are aliases of each other) which tells the DB to calculate the timestamp itself.  Use SQLALchemy's server_default  Additionally, for a default where you're already telling the DB to calculate the value, it's generally better to use server_default instead of default. This tells SQLAlchemy to pass the default value as part of the CREATE TABLE statement.  For example, if you write an ad hoc script against this table, using server_default means you won't need to worry about manually adding a timestamp call to your script--the database will set it automatically.  Understanding SQLAlchemy's onupdate/server_onupdate  SQLAlchemy also supports onupdate so that anytime the row is updated it inserts a new timestamp. Again, best to tell the DB to calculate the timestamp itself:   from sqlalchemy.sql import func  time_created = Column(DateTime(timezone=True), server_default=func.now()) time_updated = Column(DateTime(timezone=True), onupdate=func.now())   There is a server_onupdate parameter, but unlike server_default, it doesn't actually set anything serverside. It just tells SQLalchemy that your database will change the column when an update happens (perhaps you created a trigger on the column ), so SQLAlchemy will ask for the return value so it can update the corresponding object.   One other potential gotcha:  You might be surprised to notice that if you make a bunch of changes within a single transaction, they all have the same timestamp. That's because the SQL standard specifies that CURRENT_TIMESTAMP returns values based on the start of the transaction.   PostgreSQL provides the non-SQL-standard statement_timestamp() and clock_timestamp() which do change within a transaction. Docs here: https://www.postgresql.org/docs/current/static/functions-datetime.html#FUNCTIONS-DATETIME-CURRENT  UTC timestamp  If you want to use UTC timestamps, a stub of implementation for func.utcnow() is provided in SQLAlchemy documentation. You need to provide appropriate driver-specific functions on your own though.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "185",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  You can also use sqlalchemy builtin function for default DateTime  from sqlalchemy.sql import func  DT = Column(DateTime(timezone=True), default=func.now())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  The default keyword parameter should be given to the Column object.  Example:  Column(u'timestamp', TIMESTAMP(timezone=True), primary_key=False, nullable=False, default=time_now),   The default value can be a callable, which here I defined like the following.  from pytz import timezone from datetime import datetime  UTC = timezone('UTC')  def time_now():     return datetime.now(UTC)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  [enter link description here][1]  You likely want to use onupdate=datetime.now so that UPDATEs also change the last_updated field.  [1]: SQLAlchemy has two defaults for python executed functions.   default sets the value on INSERT, only once onupdate sets the value to the callable result on UPDATE as well.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "SQLAlchemy default DateTime",
        "A_Content": "  As per PostgreSQL documentation, https://www.postgresql.org/docs/9.6/static/functions-datetime.html  now, CURRENT_TIMESTAMP, LOCALTIMESTAMP return the time of transaction.      This is considered a feature: the intent is to allow a single   transaction to have a consistent notion of the \"current\" time, so that   multiple modifications within the same transaction bear the same time   stamp.   You might want to use statement_timestamp or clock_timestamp if you don't want transaction timestamp.    statement_timestamp()      returns the start time of the current statement (more specifically,   the time of receipt of the latest command message from the client).   statement_timestamp   clock_timestamp()      returns the actual current time, and therefore its value changes even   within a single SQL command.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "date",
            "sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This is my declarative model:  import datetime from sqlalchemy import Column, Integer from sqlalchemy.ext.declarative import declarative_base  Base = declarative_base()  class Test(Base):     __tablename__ = 'test'      id = Column(Integer, primary_key=True)     created_date = DateTime(default=datetime.datetime.utcnow)   However, when I try to import this module, I get this error:  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"orm/models2.py\", line 37, in <module>     class Test(Base):   File \"orm/models2.py\", line 41, in Test     created_date = sqlalchemy.DateTime(default=datetime.datetime.utcnow) TypeError: __init__() got an unexpected keyword argument 'default'   If I use an Integer type, I can set a default value. What's going on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python, what's the difference between 'except Exception as e' and 'except Exception, e' [duplicate]",
        "A_Content": "     This PEP introduces changes intended to help eliminate ambiguities in Python's grammar, simplify exception classes, simplify garbage collection for exceptions and reduce the size of the language in Python 3.0.   PEP 3110: \"Catching Exceptions in Python 3000\"     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/5119751/in-python-whats-the-difference-between-except-exception-as-e-and-except-exc",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Python try…except comma vs 'as' in except                                        4 answers                                          In python, there are two ways to catch an exception   except Exception, e:  except Exception as e:   It seems like 'as e' is the one to use going forward.  In what version of python did this change?  Any idea why?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "In Python, what's the difference between 'except Exception as e' and 'except Exception, e' [duplicate]",
        "A_Content": "  The first proposal for using the \"as\" is here: http://mail.python.org/pipermail/python-dev/2006-March/062449.html. They thought it would be more intuitive to read the code     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/5119751/in-python-whats-the-difference-between-except-exception-as-e-and-except-exc",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python try…except comma vs 'as' in except                                        4 answers                                          In python, there are two ways to catch an exception   except Exception, e:  except Exception as e:   It seems like 'as e' is the one to use going forward.  In what version of python did this change?  Any idea why?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "In Python, what's the difference between 'except Exception as e' and 'except Exception, e' [duplicate]",
        "A_Content": "  Short answer for the why: Exception, e and Exception, TypeError are hard to tell apart. Long answer: what Ignacio said.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/5119751/in-python-whats-the-difference-between-except-exception-as-e-and-except-exc",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python try…except comma vs 'as' in except                                        4 answers                                          In python, there are two ways to catch an exception   except Exception, e:  except Exception as e:   It seems like 'as e' is the one to use going forward.  In what version of python did this change?  Any idea why?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  We use django on our appengine instances mostly when we have to serve actual websites to the user. It has a great template engine, url routing and all the request/response/error handling built in. So even while we can't use the magic orm/admin stuff it has a lot going for it.  For api services we built something very simple on top of webob. It's far more lightweight because it doesn't need everything that django offers, and therefore a little quicker in some situations.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  Django probably isn't the right choice for you, if you're sure that GAE is right for you. The strengths of the two technologies don't align very well - you completely lose a lot of Django's wonderful orm on GAE, and if you do use it, you write code that isn't really directly suitable to bigtable and the way GAE works.  The thing about GAE is that it gets the great scalability by forcing you to write code that scales easily from the ground up. You just can't do a number of things that scale poorly (of course, you can still write poorly scaling code, but you avoid some pitfalls). The tradeoff is that you really end up coding around the framework, if you use something like Django which is designed for a different environment.  If you see yourself ever leaving GAE for any reason, becoming invested in the infrastructure there is a problem for you. Coding for bigtable means that it will be harder to move to a different architecture (though the apache project is working to solve this for you with the HBase component of the Hadoop project). It would still be a lot of work to transition off of GAE.  What's the driving motivator behind using GAE, besides being a Google product, and a cool buzzword? Is there a reason that scaling using something like mediatemple's offering is unlikely to work well for you? Are you sure that the ways that GAE scales are right for your application? How does the cost compare to dedicated servers, if you're expecting to get to that performance realm? Can you solve your problem well using the tools GAE provides, as compared to a more traditional load-balanced server setup?  All this said, unless you absolutely positively need the borderline-ridiculous scaling that GAE offers, I'd personally suggest not letting that particular service structure your choice of framework. I like Django, so I'd say you should use it, but not on GAE.  Edit (June 2010): As an update to this comment sometime later: Google has announced sql-like capabilitys for GAE that aren't free, but will let you easily do things like run SQL-style commands to generate reports on your data.  Additionally, there are upcoming changes to the GAE query language which will allow complex queries in a far easier fashion. Look at the videos from Google I/O 2010.  Furthermore, there is work being done during the Summer of Code 2010 project which should bring no-sql support to django core, and by extension, make working with GAE significantly easier.  GAE is becoming more attractive as a hosting platform.  Edit (August 2011):  And Google just raised the cost to most users of the platform significantly by changing the pricing structure. The lockin problem has gotten better (if your application is big enough you can deploy the apache alternatives), but for most applications, running servers or VPS deployments is cheaper.  Very few people really have bigdata problems. \"Oh my startup might scale someday\" isn't a bigdata problem. Build stuff now and get it out the door using the standard tools.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  I've done lots of projects on GAE. Some in django, some in their normal framework.  For small things, I usually use their normal framework for simplicity and quickness. Like http://stdicon.com, http://yaml-online-parser.appspot.com/, or http://text-twist.appspot.com/.   For large things, I go with django to take advantage of all the nice middleware and plugins. Like http://metaward.com.   Basically my litmus test is Will this take me more than 2 weeks to write and be a REAL software project? If so, go with django for the addons.  It has the added benefit of, if your project is badly suited for BigTable then you quickly port off (like I did Is BigTable slow or am I dumb?)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  I think all this answers are a bit obsolete.  Now you can use Google Cloud SQL     Django is a popular third-party Python web framework. When coupled   with Google Cloud SQL, all of its functionality can be fully supported   by applications running on App Engine. Support for using Google Cloud   SQL with Django is provided by a custom Django database backend which   wraps Django's MySQL backend.   https://cloud.google.com/python/django/appengine  one more fresh news is, that there is BETA support for PostgreSQL     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  I have experience using Django and not GAE.  From my experiences with Django it was a very simplistic setup and the deployment process was incredibly easy in terms of web projects.  Granted I had to learn Python to really get a good hold on things, but at the end of the day I would use it again on a project.  This was almost 2 years ago before it reached 1.0 so I my knowledge is a bit outdated.    If you are worried about changing platforms, then this would be a better choice I suppose.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  I cannot answer the question but you may want to look into web2py. It is similar to Django in many respects but its database abstraction layer works on GAE and supports most of the GAE functionality (not all but we try to catch up). In this way if GAE works for you great, if it does not, you can move your code to a different db (SQLite, MySQL, PostgreSQL, Oracle, MSSQL, FireBird, DB2, Informix, Ingres, and - soon - Sybase and MongoDB).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  If you decide to run you app outside of GAE, you can still use Django. You won't really have that much luck with the GAE webapp     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why use Django on Google App Engine?",
        "A_Content": "  I am still very new to Google App engine development, but the interfaces Django provides do appear much nicer than the default. The benefits will depend on what you are using to run Django on the app engine. The Google App Engine Helper for Django allows you to use the full power of the Google App Engine with some Django functionality on the side.  Django non-rel attempts to provide as much of Django's power as possible, but running on the app-engine for possible extra scalability. In particular, it includes Django models (one of Django's core features), but this is a leaky abstraction due to the differences between relational databases and bigtable. There will most likely be tradeoffs in functionality and efficiency, as well as an increased number of bugs and quirks. Of course, this might be worth it in circumstances like those described in the question, but otherwise would strongly recommend using the helper at the start as then you have the option of moving towards either pure app-engine or Django non-rel later. Also, if you do switch to Django non-rel, your increased knowledge of how app engine works will be useful if the Django abstraction ever breaks - certainly much more useful than knowledge of the quirks/workarounds for Django non-rel if you swap the other way.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1934914/why-use-django-on-google-app-engine",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When researching Google App Engine (GAE), it's clear that using Django is wildly popular for developing in Python on GAE.  I've been scouring the web to find information on the costs and benefits of using Django, to find out why it's so popular.  While I've been able to find a wide variety of sources on how to run Django on GAE and the various methods of doing so, I haven't found any comparative analysis on why Django is preferable to using the webapp framework provided by Google.  To be clear, it's immediately apparent why using Django on GAE is useful for developers with an existing skillset in Django (a majority of Python web developers, no doubt) or existing code in Django (where using GAE is more of a porting exercise).  My team, however, is evaluating GAE for use on an all-new project and our existing experience is with TurboGears, not Django.  It's been quite difficult to determine why Django is beneficial to a development team when the BigTable libraries have replaced Django's ORM, sessions and authentication are necessarily changed, and Django's templating (if desirable) is available without using the entire Django stack.  Finally, it's clear that using Django does have the advantage of providing an \"exit strategy\" if we later wanted to move away from GAE and need a platform to target for the exodus.  I'd be extremely appreciative for help in pointing out why using Django is better than using webapp on GAE.  I'm also completely inexperienced with Django, so elaboration on smaller features and/or conveniences that work on GAE are also valuable to me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  \"Do child processes spawned via multiprocessing share objects created earlier in the program?\"  No.    Processes have independent memory space.  Solution 1  To make best use of a large structure with lots of workers, do this.   Write each worker as a \"filter\" -- reads intermediate results from stdin, does work, writes intermediate results on stdout. Connect all the workers as a pipeline:  process1 <source | process2 | process3 | ... | processn >result    Each process reads, does work and writes.  This is remarkably efficient since all processes are running concurrently.  The writes and reads pass directly through shared buffers between the processes.    Solution 2  In some cases, you have a more complex structure -- often a \"fan-out\" structure.  In this case you have a parent with multiple children.   Parent opens source data.  Parent forks a number of children. Parent reads source, farms parts of the source out to each concurrently running child. When parent reaches the end, close the pipe.  Child gets end of file and finishes normally.   The child parts are pleasant to write because each child simply reads sys.stdin.    The parent has a little bit of fancy footwork in spawning all the children and retaining the pipes properly, but it's not too bad.  Fan-in is the opposite structure.  A number of independently running processes need to interleave their inputs into a common process.  The collector is not as easy to write, since it has to read from many sources.    Reading from many named pipes is often done using the select module to see which pipes have pending input.    Solution 3  Shared lookup is the definition of a database.    Solution 3A -- load a database.  Let the workers process the data in the database.  Solution 3B -- create a very simple server using werkzeug (or similar) to provide WSGI applications that respond to HTTP GET so the workers can query the server.    Solution 4  Shared filesystem object.  Unix OS offers shared memory objects.  These are just files that are mapped to memory so that swapping I/O is done instead of more convention buffered reads.  You can do this from a Python context in several ways   Write a startup program that (1) breaks your original gigantic object into smaller objects, and (2) starts workers, each with a smaller object.  The smaller objects could be pickled Python objects to save a tiny bit of file reading time. Write a startup program that (1) reads your original gigantic object and writes a page-structured, byte-coded file using seek operations to assure that individual sections are easy to find with simple seeks.  This is what a database engine does -- break the data into pages, make each page easy to locate via a seek.  Spawn workers with access this this large page-structured file.  Each worker can seek to the relevant parts and do their work there.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  Do child processes spawned via multiprocessing share objects created earlier in the program?  It depends. For global read-only variables it can be often considered so (apart from the memory consumed) else it should not.   multiprocessing's documentation says:  Better to inherit than pickle/unpickle     On Windows many types from   multiprocessing need to be picklable   so that child processes can use them.   However, one should generally avoid   sending shared objects to other   processes using pipes or queues.   Instead you should arrange the program   so that a process which need access to   a shared resource created elsewhere   can inherit it from an ancestor   process.   Explicitly pass resources to child processes     On Unix a child process can make use   of a shared resource created in a   parent process using a global   resource. However, it is better to   pass the object as an argument to the   constructor for the child process.      Apart from making the code   (potentially) compatible with Windows   this also ensures that as long as the   child process is still alive the   object will not be garbage collected   in the parent process. This might be   important if some resource is freed   when the object is garbage collected   in the parent process.   Global variables     Bear in mind that if code run in a   child process tries to access a global   variable, then the value it sees (if   any) may not be the same as the value   in the parent process at the time that   Process.start() was called.   Example  On Windows (single CPU):  #!/usr/bin/env python import os, sys, time from multiprocessing import Pool  x = 23000 # replace `23` due to small integers share representation z = []    # integers are immutable, let's try mutable object  def printx(y):     global x     if y == 3:        x = -x     z.append(y)     print os.getpid(), x, id(x), z, id(z)      print y     if len(sys.argv) == 2 and sys.argv[1] == \"sleep\":        time.sleep(.1) # should make more apparant the effect  if __name__ == '__main__':     pool = Pool(processes=4)     pool.map(printx, (1,2,3,4))   With sleep:  $ python26 test_share.py sleep 2504 23000 11639492 [1] 10774408 1 2564 23000 11639492 [2] 10774408 2 2504 -23000 11639384 [1, 3] 10774408 3 4084 23000 11639492 [4] 10774408 4   Without sleep:  $ python26 test_share.py 1148 23000 11639492 [1] 10774408 1 1148 23000 11639492 [1, 2] 10774408 2 1148 -23000 11639324 [1, 2, 3] 10774408 3 1148 -23000 11639324 [1, 2, 3, 4] 10774408 4      ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  S.Lott is correct. Python's multiprocessing shortcuts effectively give you a separate, duplicated chunk of memory.  On most *nix systems, using a lower-level call to os.fork() will, in fact, give you copy-on-write memory, which might be what you're thinking. AFAIK, in theory, in the most simplistic of programs possible, you could read from that data without having it duplicated.  However, things aren't quite that simple in the Python interpreter. Object data and meta-data are stored in the same memory segment, so even if the object never changes,  something like a reference counter for that object being incremented will cause a memory write, and therefore a copy. Almost any Python program that is doing more than \"print 'hello'\" will cause reference count increments, so you will likely never realize the benefit of copy-on-write.  Even if someone did manage to hack a shared-memory solution in Python, trying to coordinate garbage collection across processes would probably be pretty painful.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  If you're running under Unix, they may share the same object, due to how fork works (i.e., the child processes have separate memory but it's copy-on-write, so it may be shared as long as nobody modifies it).  I tried the following:  import multiprocessing  x = 23  def printx(y):     print x, id(x)     print y  if __name__ == '__main__':     pool = multiprocessing.Pool(processes=4)     pool.map(printx, (1,2,3,4))   and got the following output:   $ ./mtest.py 23 22995656 1 23 22995656 2 23 22995656 3 23 22995656 4   Of course this doesn't prove that a copy hasn't been made, but you should be able to verify that in your situation by looking at the output of ps to see how much real memory each subprocess is using.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  Different processes have different address space. Like running different instances of the interpreter. That's what IPC (interprocess communication) is for.  You can use either queues or pipes for this purpose. You can also use rpc over tcp if you want to distribute the processes over a network later.  http://docs.python.org/dev/library/multiprocessing.html#exchanging-objects-between-processes     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "multiprocessing: sharing a large read-only object between processes?",
        "A_Content": "  Not directly related to multiprocessing per se, but from your example, it would seem you could just use the shelve module or something like that. Does the \"big_lookup_object\" really have to be completely in memory?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multiprocessing"
        ],
        "URL": "https://stackoverflow.com/questions/659865/multiprocessing-sharing-a-large-read-only-object-between-processes",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Do child processes spawned via multiprocessing share objects created earlier in the program?  I have the following setup:  do_some_processing(filename):     for line in file(filename):         if line.split(',')[0] in big_lookup_object:             # something here  if __name__ == '__main__':     big_lookup_object = marshal.load('file.bin')     pool = Pool(processes=4)     print pool.map(do_some_processing, glob.glob('*.data'))   I'm loading some big object into memory, then creating a pool of workers that need to make use of that big object. The big object is accessed read-only, I don't need to pass modifications of it between processes.  My question is: is the big object loaded into shared memory, as it would be if I spawned a process in unix/c, or does each process load its own copy of the big object?   Update: to clarify further - big_lookup_object is a shared lookup object. I don't need to split that up and process it separately. I need to keep a single copy of it. The work that I need to split it is reading lots of other large files and looking up the items in those large files against the lookup object.  Further update: database is a fine solution, memcached might be a better solution, and file on disk (shelve or dbm) might be even better. In this question I was particularly interested in an in memory solution. For the final solution I'll be using hadoop, but I wanted to see if I can have a local in-memory version as well.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  To set IPython Notebook to run Python 3 instead of 2 on my MAC 10.9, I did the following steps  $ sudo pip3 install ipython[all]   Then   $ ipython3 notebook        ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "90",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  For linux 16.04 Ubuntu you can use  sudo apt-get install ipython3   and then use   ipython3 notebook   to open the notebook in the browser. If you have any notebooks saved with python 2 then it will automatically convert them to Python 3 once you open the notebook.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  Is there a package from your distro? If you're using ubuntu you must to install the ipython3-notebook package. If not, maybe you must to install ipython with python3.  If you've run (because it's python2 by default)  python setup.py   you must to run instead  python3 setup.py install   to install a package with python3 instead python2. This will be a new instalation of ipython3.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  In Anaconda \"launcher.app\" there is “Environment:” pull down menu.  The default environment is called \"root\". In order to launch application using another environment, just select the desired environment from the list, to make it active.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  If you are running anaconda, then the preferred way to install notebook/jupyter is using conda:  conda install jupyter      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  If you have both version available on jupyter notebook, you can change the kernel from menu.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How To Get IPython Notebook To Run Python 3?",
        "A_Content": "  To use jupyter with python 3 instead of python 2 on my Windows 10 with Anaconda, I did the following steps on anaconda prompt:  pip3 install ipython[all]   Then,  ipython3 notebook      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "ipython",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/20360293/how-to-get-ipython-notebook-to-run-python-3",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python to bear with me.   I installed Anaconda, works great. I setup a Python 3 environment following the Anaconda cmd line instructions, works great. I setup Anaconda's Python 3 environment as Pycharm's interpreter, works great. I launched the Anaconda \"launcher.app\" and launched IPython Notebook. However, iPython Notebook is running Python 2 not 3.   Over three hours of Googling later, I cannot figure out how to set IPython Notebook to run Python 3 instead of 2.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why do you need to create a cursor when querying a sqlite database?",
        "A_Content": "  Just a misapplied abstraction it seems to me. A db cursor is an abstraction, meant for data set traversal.  From Wikipedia article on subject:     In computer science and technology, a database cursor is a control   structure that enables traversal over the records in a database.   Cursors facilitate subsequent processing in conjunction with the   traversal, such as retrieval, addition and removal of database   records. The database cursor characteristic of traversal makes cursors   akin to the programming language concept of iterator.   And:     Cursors can not only be used to fetch data from the DBMS into an   application but also to identify a row in a table to be updated or   deleted. The SQL:2003 standard defines positioned update and   positioned delete SQL statements for that purpose. Such statements do   not use a regular WHERE clause with predicates. Instead, a cursor   identifies the row. The cursor must be opened and already positioned   on a row by means of FETCH statement.   If you check the docs on Python sqlite module, you can see that a python module cursor is needed even for a CREATE TABLE statement, so it's used for cases where a mere connection object should suffice - as correctly pointed out by the OP. Such abstraction is different from what people understand a db cursor to be and hence, the confusion/frustration on the part of users. Regardless of efficiency, it's just a conceptual overhead. Would be nice if it was pointed out in the docs that the python module cursor is bit different than what a cursor is in SQL and databases.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlite",
            "sqlite3",
            "cursor"
        ],
        "URL": "https://stackoverflow.com/questions/6318126/why-do-you-need-to-create-a-cursor-when-querying-a-sqlite-database",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm completely new to Python's sqlite3 module (and SQL in general for that matter), and this just completely stumps me. The abundant lack of descriptions of cursor objects (rather, their necessity) also seems odd.   This snippet of code is the preferred way of doing things:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") c = conn.cursor() c.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit() c.close()   This one isn't, even though it works just as well and without the (seemingly pointless) cursor:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") conn.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit()   Can anyone tell me why I need a cursor? It just seems like pointless overhead. For every method in my script that accesses a database, I'm supposed to create and destroy a cursor? Why not just use the connection object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why do you need to create a cursor when querying a sqlite database?",
        "A_Content": "  You need a cursor object to fetch results. Your example works because it's an INSERT and thus you aren't trying to get any rows back from it, but if you look at the sqlite3 docs, you'll notice that there aren't any .fetchXXXX methods on connection objects, so if you tried to do a SELECT without a cursor, you'd have no way to get the resulting data.  Cursor objects allow you to keep track of which result set is which, since it's possible to run multiple queries before you're done fetching the results of the first.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlite",
            "sqlite3",
            "cursor"
        ],
        "URL": "https://stackoverflow.com/questions/6318126/why-do-you-need-to-create-a-cursor-when-querying-a-sqlite-database",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm completely new to Python's sqlite3 module (and SQL in general for that matter), and this just completely stumps me. The abundant lack of descriptions of cursor objects (rather, their necessity) also seems odd.   This snippet of code is the preferred way of doing things:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") c = conn.cursor() c.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit() c.close()   This one isn't, even though it works just as well and without the (seemingly pointless) cursor:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") conn.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit()   Can anyone tell me why I need a cursor? It just seems like pointless overhead. For every method in my script that accesses a database, I'm supposed to create and destroy a cursor? Why not just use the connection object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why do you need to create a cursor when querying a sqlite database?",
        "A_Content": "  According to the official docs connection.execute() is a nonstandard shortcut that creates an intermediate cursor object.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlite",
            "sqlite3",
            "cursor"
        ],
        "URL": "https://stackoverflow.com/questions/6318126/why-do-you-need-to-create-a-cursor-when-querying-a-sqlite-database",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm completely new to Python's sqlite3 module (and SQL in general for that matter), and this just completely stumps me. The abundant lack of descriptions of cursor objects (rather, their necessity) also seems odd.   This snippet of code is the preferred way of doing things:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") c = conn.cursor() c.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit() c.close()   This one isn't, even though it works just as well and without the (seemingly pointless) cursor:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") conn.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit()   Can anyone tell me why I need a cursor? It just seems like pointless overhead. For every method in my script that accesses a database, I'm supposed to create and destroy a cursor? Why not just use the connection object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why do you need to create a cursor when querying a sqlite database?",
        "A_Content": "     12.6.8. Using sqlite3 efficiently      12.6.8.1. Using shortcut methods      Using the nonstandard execute(), executemany() and executescript() methods of the Connection object, your code can be written more concisely because you don’t have to create the (often superfluous) Cursor objects explicitly. Instead, the Cursor objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a SELECT statement and iterate over it directly using only a single call on the Connection object.   (sqlite3 documentation; emphasis mine.)     Why not just use the connection object?   Because those methods of the connection object are nonstandard, i.e. they are not part of Python Database API Specification v2.0 (PEP 249).  As long as you use the standard methods of the Cursor object, you can be sure that if you switch to another database implementation that follows the above specification, your code will be fully portable. Perhaps you will only need to change the import line.  But if you use the connection.execute there is a chance that switching won't be that straightforward. That's the main reasons you might want to use cursor.execute instead.  However if you are certain that you're not going to switch, I'd say it's completely OK to take the connection.execute shortcut and be \"efficient\".     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlite",
            "sqlite3",
            "cursor"
        ],
        "URL": "https://stackoverflow.com/questions/6318126/why-do-you-need-to-create-a-cursor-when-querying-a-sqlite-database",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm completely new to Python's sqlite3 module (and SQL in general for that matter), and this just completely stumps me. The abundant lack of descriptions of cursor objects (rather, their necessity) also seems odd.   This snippet of code is the preferred way of doing things:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") c = conn.cursor() c.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit() c.close()   This one isn't, even though it works just as well and without the (seemingly pointless) cursor:  import sqlite3 conn = sqlite3.connect(\"db.sqlite\") conn.execute('''insert into table \"users\" values (\"Jack Bauer\", \"555-555-5555\")''') conn.commit()   Can anyone tell me why I need a cursor? It just seems like pointless overhead. For every method in my script that accesses a database, I'm supposed to create and destroy a cursor? Why not just use the connection object?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "What is the difference between a pandas Series and a single-column DataFrame?",
        "A_Content": "  Quoting the Pandas docs     pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)      Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes    (rows and columns). Arithmetic operations align on both row and column labels.    Can be thought of as a dict-like container for Series objects. The primary pandas data structure   (Emphasis mine, sentence fragment not mine)  So the Series is the datastructure for a single column of a DataFrame, not only conceptually, but literally i.e. the data in a DataFrame is actually stored in memory as a collection of Series.   Analogously: We need both lists and matrices, because matrices are built with lists. Single row matricies, while equivalent to lists in functionality still cannot exists without the list(s) they're composed of.  They both have extremely similar APIs, but you'll find that DataFrame methods always cater to the possibility that you have more than one column. And of course, you can always add another Series (or equivalent object) to a DataFrame, while adding a Series to another Series involves creating a DataFrame.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe",
        "A_Votes": "106",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Why does pandas make a distinction between a Series and a single-column DataFrame? In other words: what is the reason of existence of the Series class?   I'm mainly using time series with datetime index, maybe that helps to set the context.      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "What is the difference between a pandas Series and a single-column DataFrame?",
        "A_Content": "  from the pandas doc http://pandas.pydata.org/pandas-docs/stable/dsintro.html Series is a one-dimensional labeled array capable of holding any data type. To read data in form of panda Series:  import pandas as pd ds = pd.Series(data, index=index)   DataFrame is a 2-dimensional labeled data structure with columns of potentially different types.  import pandas as pd df = pd.DataFrame(data, index=index)   In both of the above index is list  for example: I have a csv file with following data:  ,country,popuplation,area,capital BR,Brazil,10210,12015,Brasile RU,Russia,1025,457,Moscow IN,India,10458,457787,New Delhi   To read above data as series and data frame:  import pandas as pd file_data = pd.read_csv(\"file_path\", index_col=0) d = pd.Series(file_data.country, index=['BR','RU','IN'] or index =  file_data.index)   output:  >>> d BR           Brazil RU           Russia IN            India  df = pd.DataFrame(file_data.area, index=['BR','RU','IN'] or index = file_data.index )   output:   >>> df       area BR   12015 RU     457 IN  457787      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does pandas make a distinction between a Series and a single-column DataFrame? In other words: what is the reason of existence of the Series class?   I'm mainly using time series with datetime index, maybe that helps to set the context.      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "What is the difference between a pandas Series and a single-column DataFrame?",
        "A_Content": "  Series is a one-dimensional object that can hold any data type such as integers, floats and strings e.g      import pandas as pd </i>    x = pd.Series([A,B,C])   0 A 1 B 2 C   The first column of Series is known  index i.e 0,1,2 the second column is your actual data  i.e A,B,C  DataFrames is Two-dimensional object that can hold series, list, dictionary   df=pd.DataFrame(rd(5,4),['A','B','C','D','E'],['W','X','Y','Z'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does pandas make a distinction between a Series and a single-column DataFrame? In other words: what is the reason of existence of the Series class?   I'm mainly using time series with datetime index, maybe that helps to set the context.      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "What is the difference between a pandas Series and a single-column DataFrame?",
        "A_Content": "  Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a Series is to call:  s = pd.Series(data, index=index)   DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.   d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),  two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}  df = pd.DataFrame(d)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does pandas make a distinction between a Series and a single-column DataFrame? In other words: what is the reason of existence of the Series class?   I'm mainly using time series with datetime index, maybe that helps to set the context.      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python way of printing: with 'format' or percent form? [duplicate]",
        "A_Content": "  Use the format method, especially if you're concerned about Python 3 and the future.  From the documentation:     The formatting operations described here [% substitutions] are obsolete and may go away in future versions of Python. Use the new String Formatting in new code.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/12382719/python-way-of-printing-with-format-or-percent-form",
        "A_Votes": "91",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Python string formatting: % vs. .format                                        15 answers                                          In Python there seem to be two different ways of generating formatted output:  user = \"Alex\" number = 38746 print(\"%s asked %d questions on stackoverflow.com\" % (user, number)) print(\"{0} asked {1} questions on stackoverflow.com\".format(user, number))   Is there one way to be preferred over the other? Are they equivalent, what is the difference? What form should be used, especially for Python3?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python way of printing: with 'format' or percent form? [duplicate]",
        "A_Content": "  .format was introduced in Python2.6  If you need backward compatibility with earlier Python, you should use %  For Python3 and newer you should use .format for sure  .format is more powerful than %. Porting % to .format is easy but the other way round can be non trivial     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/12382719/python-way-of-printing-with-format-or-percent-form",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python string formatting: % vs. .format                                        15 answers                                          In Python there seem to be two different ways of generating formatted output:  user = \"Alex\" number = 38746 print(\"%s asked %d questions on stackoverflow.com\" % (user, number)) print(\"{0} asked {1} questions on stackoverflow.com\".format(user, number))   Is there one way to be preferred over the other? Are they equivalent, what is the difference? What form should be used, especially for Python3?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python way of printing: with 'format' or percent form? [duplicate]",
        "A_Content": "  You can use both .No one said % formatting expression is deprecated.However,as stated before the format method call is a tad more powerful. Also note that the % expressions are bit more concise and easier to code.Try them and see what suits you best     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/12382719/python-way-of-printing-with-format-or-percent-form",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python string formatting: % vs. .format                                        15 answers                                          In Python there seem to be two different ways of generating formatted output:  user = \"Alex\" number = 38746 print(\"%s asked %d questions on stackoverflow.com\" % (user, number)) print(\"{0} asked {1} questions on stackoverflow.com\".format(user, number))   Is there one way to be preferred over the other? Are they equivalent, what is the difference? What form should be used, especially for Python3?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python way of printing: with 'format' or percent form? [duplicate]",
        "A_Content": "  The docs say that the format method is preferred for new code. There are currently no plans to remove % formatting, though.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/12382719/python-way-of-printing-with-format-or-percent-form",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python string formatting: % vs. .format                                        15 answers                                          In Python there seem to be two different ways of generating formatted output:  user = \"Alex\" number = 38746 print(\"%s asked %d questions on stackoverflow.com\" % (user, number)) print(\"{0} asked {1} questions on stackoverflow.com\".format(user, number))   Is there one way to be preferred over the other? Are they equivalent, what is the difference? What form should be used, especially for Python3?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why is copying a shuffled list much slower?",
        "A_Content": "  The interesting bit is that it depends on the order in which the integers are first created. For example instead of shuffle create a random sequence with random.randint:  from timeit import timeit import random  a = [random.randint(0, 10**6) for _ in range(10**6)] for _ in range(5):     print(timeit(lambda: list(a), number=10))   This is as fast as copying your list(range(10**6)) (first and fast example).  However when you shuffle - then your integers aren't in the order they were first created anymore, that's what makes it slow.   A quick intermezzo:   All Python objects are on the heap, so every object is a pointer. Copying a list is a shallow operation. However Python uses reference counting so when an object is put in a new container it's reference count must be incremented (Py_INCREF in list_slice), so Python really needs to go to where the object is. It can't just copy the reference.   So when you copy your list you get each item of that list and put it \"as is\" in the new list. When your next item was created shortly after the current one there is a good chance (no guarantee!) that it's saved next to it on the heap.   Let's assume that whenever your computer loads an item in the cache it also loads the x next-in-memory items (cache locality). Then your computer can perform the reference count increment for x+1 items on the same cache!  With the shuffled sequence it still loads the next-in-memory items but these aren't the ones next-in-list. So it can't perform the reference-count increment without \"really\" looking for the next item.  TL;DR: The actual speed depends on what happened before the copy: in what order were these items created and in what order are these in the list.    You can verify this by looking at the id:     CPython implementation detail: This is the address of the object in memory.   a = list(range(10**6, 10**6+100)) for item in a:     print(id(item))   Just to show a short excerpt:  1496489995888 1496489995920  # +32 1496489995952  # +32 1496489995984  # +32 1496489996016  # +32 1496489996048  # +32 1496489996080  # +32 1496489996112 1496489996144 1496489996176 1496489996208 1496489996240 1496507297840 1496507297872 1496507297904 1496507297936 1496507297968 1496507298000 1496507298032 1496507298064 1496507298096 1496507298128 1496507298160 1496507298192   So these objects are really \"next to each other on the heap\". With shuffle they aren't:  import random a = list(range(10**6, 100+10**6)) random.shuffle(a) last = None for item in a:     if last is not None:         print('diff', id(item) - id(last))     last = item   Which shows these are not really next to each other in memory:  diff 736 diff -64 diff -17291008 diff -128 diff 288 diff -224 diff 17292032 diff -1312 diff 1088 diff -17292384 diff 17291072 diff 608 diff -17290848 diff 17289856 diff 928 diff -672 diff 864 diff -17290816 diff -128 diff -96 diff 17291552 diff -192 diff 96 diff -17291904 diff 17291680 diff -1152 diff 896 diff -17290528 diff 17290816 diff -992 diff 448     Important note:  I haven't thought this up myself. Most of the informations can be found in the blogpost of Ricky Stewart.  This answer is based on the \"official\" CPython implementation of Python. The details in other implementations (Jython, PyPy, IronPython, ...) may be different. Thanks @JörgWMittag for pointing this out.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/42107442/why-is-copying-a-shuffled-list-much-slower",
        "A_Votes": "99",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Copying a shuffled range(10**6) list ten times takes me about 0.18 seconds: (these are five runs)  0.175597017661 0.173731403198 0.178601711594 0.180330912952 0.180811964451   Copying the unshuffled list ten times takes me about 0.05 seconds:  0.058402235973 0.0505464636856 0.0509734306934 0.0526022752744 0.0513324916184   Here's my testing code:  from timeit import timeit import random  a = range(10**6) random.shuffle(a)    # Remove this for the second test. a = list(a)          # Just an attempt to \"normalize\" the list. for _ in range(5):     print timeit(lambda: list(a), number=10)   I also tried copying with a[:], the results were similar (i.e., big speed difference)  Why the big speed difference? I know and understand the speed difference in the famous Why is it faster to process a sorted array than an unsorted array? example, but here my processing has no decisions. It's just blindly copying the references inside the list, no?  I'm using Python 2.7.12 on Windows 10.  Edit: Tried Python 3.5.2 as well now, the results were almost the same (shuffled consistently around 0.17 seconds, unshuffled consistently around 0.05 seconds). Here's the code for that:  a = list(range(10**6)) random.shuffle(a) a = list(a) for _ in range(5):     print(timeit(lambda: list(a), number=10))      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why is copying a shuffled list much slower?",
        "A_Content": "  When you shuffle the list items, they have worse locality of reference, leading to worse cache performance.  You might think that copying the list just copies the references, not the objects, so their locations on the heap shouldn't matter.  However, copying still involves accessing each object in order to modify the refcount.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/42107442/why-is-copying-a-shuffled-list-much-slower",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Copying a shuffled range(10**6) list ten times takes me about 0.18 seconds: (these are five runs)  0.175597017661 0.173731403198 0.178601711594 0.180330912952 0.180811964451   Copying the unshuffled list ten times takes me about 0.05 seconds:  0.058402235973 0.0505464636856 0.0509734306934 0.0526022752744 0.0513324916184   Here's my testing code:  from timeit import timeit import random  a = range(10**6) random.shuffle(a)    # Remove this for the second test. a = list(a)          # Just an attempt to \"normalize\" the list. for _ in range(5):     print timeit(lambda: list(a), number=10)   I also tried copying with a[:], the results were similar (i.e., big speed difference)  Why the big speed difference? I know and understand the speed difference in the famous Why is it faster to process a sorted array than an unsorted array? example, but here my processing has no decisions. It's just blindly copying the references inside the list, no?  I'm using Python 2.7.12 on Windows 10.  Edit: Tried Python 3.5.2 as well now, the results were almost the same (shuffled consistently around 0.17 seconds, unshuffled consistently around 0.05 seconds). Here's the code for that:  a = list(range(10**6)) random.shuffle(a) a = list(a) for _ in range(5):     print(timeit(lambda: list(a), number=10))      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why is copying a shuffled list much slower?",
        "A_Content": "  As explained by others, it's not just copying the references but also increases the reference counts inside the objects and thus the objects are accessed and the cache plays a role.  Here I just want to add more experiments. Not so much about shuffled vs unshuffled (where accessing one element might miss the cache but get the following elements into the cache so they get hit). But about repeating elements, where later accesses of the same element might hit the cache because the element is still in the cache.  Testing a normal range:  >>> from timeit import timeit >>> a = range(10**7) >>> [timeit(lambda: list(a), number=100) for _ in range(3)] [5.1915339142808925, 5.1436351868889645, 5.18055115701749]   A list of the same size but with just one element repeated over and over again is faster because it hits the cache all the time:  >>> a = [0] * 10**7 >>> [timeit(lambda: list(a), number=100) for _ in range(3)] [4.125743135926939, 4.128927210087596, 4.0941229388550795]   And it doesn't seem to matter what number it is:  >>> a = [1234567] * 10**7 >>> [timeit(lambda: list(a), number=100) for _ in range(3)] [4.124106479141709, 4.156590225249886, 4.219242600790949]   Interestingly, it gets even faster when I instead repeat the same two or four elements:  >>> a = [0, 1] * (10**7 / 2) >>> [timeit(lambda: list(a), number=100) for _ in range(3)] [3.130586101607932, 3.1001001764957294, 3.1318465707127814]  >>> a = [0, 1, 2, 3] * (10**7 / 4) >>> [timeit(lambda: list(a), number=100) for _ in range(3)] [3.096105435911994, 3.127148431279352, 3.132872673690855]   I guess something doesn't like the same single counter increased all the time. Maybe some pipeline stall because each increase has to wait for the result of the previous increase, but this is a wild guess.  Anyway, trying this for even larger numbers of repeated elements:  from timeit import timeit for e in range(26):     n = 2**e     a = range(n) * (2**25 / n)     times = [timeit(lambda: list(a), number=20) for _ in range(3)]     print '%8d ' % n, '  '.join('%.3f' % t for t in times), ' => ', sum(times) / 3   The output (first column is the number of different elements, for each I test three times and then take the average):         1  2.871  2.828  2.835  =>  2.84446732686        2  2.144  2.097  2.157  =>  2.13275338734        4  2.129  2.297  2.247  =>  2.22436720645        8  2.151  2.174  2.170  =>  2.16477771575       16  2.164  2.159  2.167  =>  2.16328197911       32  2.102  2.117  2.154  =>  2.12437970598       64  2.145  2.133  2.126  =>  2.13462250728      128  2.135  2.122  2.137  =>  2.13145065221      256  2.136  2.124  2.140  =>  2.13336283943      512  2.140  2.188  2.179  =>  2.1688431668     1024  2.162  2.158  2.167  =>  2.16208440826     2048  2.207  2.176  2.213  =>  2.19829998424     4096  2.180  2.196  2.202  =>  2.19291917834     8192  2.173  2.215  2.188  =>  2.19207065277    16384  2.258  2.232  2.249  =>  2.24609975704    32768  2.262  2.251  2.274  =>  2.26239771771    65536  2.298  2.264  2.246  =>  2.26917420394   131072  2.285  2.266  2.313  =>  2.28767871168   262144  2.351  2.333  2.366  =>  2.35030805124   524288  2.932  2.816  2.834  =>  2.86047313113  1048576  3.312  3.343  3.326  =>  3.32721167007  2097152  3.461  3.451  3.547  =>  3.48622758473  4194304  3.479  3.503  3.547  =>  3.50964316455  8388608  3.733  3.496  3.532  =>  3.58716466865 16777216  3.583  3.522  3.569  =>  3.55790996695 33554432  3.550  3.556  3.512  =>  3.53952594744   So from about 2.8 seconds for a single (repeated) element it drops to about 2.2 seconds for 2, 4, 8, 16, ... different elements and stays at about 2.2 seconds until the hundred thousands. I think this uses my L2 cache (4 × 256 KB, I have an i7-6700).  Then over a few steps, the times go up to 3.5 seconds. I think this uses a mix of my L2 cache and my L3 cache (8 MB) until that's \"exhausted\" as well.  At the end it stays at around 3.5 seconds, I guess because my caches don't help with the repeated elements anymore.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/42107442/why-is-copying-a-shuffled-list-much-slower",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Copying a shuffled range(10**6) list ten times takes me about 0.18 seconds: (these are five runs)  0.175597017661 0.173731403198 0.178601711594 0.180330912952 0.180811964451   Copying the unshuffled list ten times takes me about 0.05 seconds:  0.058402235973 0.0505464636856 0.0509734306934 0.0526022752744 0.0513324916184   Here's my testing code:  from timeit import timeit import random  a = range(10**6) random.shuffle(a)    # Remove this for the second test. a = list(a)          # Just an attempt to \"normalize\" the list. for _ in range(5):     print timeit(lambda: list(a), number=10)   I also tried copying with a[:], the results were similar (i.e., big speed difference)  Why the big speed difference? I know and understand the speed difference in the famous Why is it faster to process a sorted array than an unsorted array? example, but here my processing has no decisions. It's just blindly copying the references inside the list, no?  I'm using Python 2.7.12 on Windows 10.  Edit: Tried Python 3.5.2 as well now, the results were almost the same (shuffled consistently around 0.17 seconds, unshuffled consistently around 0.05 seconds). Here's the code for that:  a = list(range(10**6)) random.shuffle(a) a = list(a) for _ in range(5):     print(timeit(lambda: list(a), number=10))      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why is copying a shuffled list much slower?",
        "A_Content": "  Before the shuffle, when allocated in the heap, the adjacent index objects are adjacent in memory, and the memory hit rate is high when accessed; after shuffle, the object of the adjacent index of the new list is not in memory. Adjacent, the hit rate is very poor.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/42107442/why-is-copying-a-shuffled-list-much-slower",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Copying a shuffled range(10**6) list ten times takes me about 0.18 seconds: (these are five runs)  0.175597017661 0.173731403198 0.178601711594 0.180330912952 0.180811964451   Copying the unshuffled list ten times takes me about 0.05 seconds:  0.058402235973 0.0505464636856 0.0509734306934 0.0526022752744 0.0513324916184   Here's my testing code:  from timeit import timeit import random  a = range(10**6) random.shuffle(a)    # Remove this for the second test. a = list(a)          # Just an attempt to \"normalize\" the list. for _ in range(5):     print timeit(lambda: list(a), number=10)   I also tried copying with a[:], the results were similar (i.e., big speed difference)  Why the big speed difference? I know and understand the speed difference in the famous Why is it faster to process a sorted array than an unsorted array? example, but here my processing has no decisions. It's just blindly copying the references inside the list, no?  I'm using Python 2.7.12 on Windows 10.  Edit: Tried Python 3.5.2 as well now, the results were almost the same (shuffled consistently around 0.17 seconds, unshuffled consistently around 0.05 seconds). Here's the code for that:  a = list(range(10**6)) random.shuffle(a) a = list(a) for _ in range(5):     print(timeit(lambda: list(a), number=10))      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pandas read in table without headers",
        "A_Content": "  In order to read a csv in that doesn't have a header and for only certain columns you need to pass params header=None and usecols=[3,6] for the 4th and 7th columns:  df = pd.read_csv(file_path, header=None, usecols=[3,6])   See the docs     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29287224/pandas-read-in-table-without-headers",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I read in a .csv file (with no headers) and when I only want a subset of the columns (say 4th and 7th out of a total of 20 columns), using pandas? I cannot seem to be able to do usecols     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pandas read in table without headers",
        "A_Content": "  Make sure you specify pass header=None and add usecols=[3,6] for the 4th and 7th columns.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29287224/pandas-read-in-table-without-headers",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I read in a .csv file (with no headers) and when I only want a subset of the columns (say 4th and 7th out of a total of 20 columns), using pandas? I cannot seem to be able to do usecols     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pandas read in table without headers",
        "A_Content": "  Previous answers were good and correct, but in my opinion, an extra names parameter will make it perfect, especially when the csv has no headers.  df = pd.read_csv(file_path, header=None, usecols=[3,6], names=['colA', 'colB'])   So that you can retrieve your data by df['colA'], df['colB'] instead of df[0], df[1]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29287224/pandas-read-in-table-without-headers",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I read in a .csv file (with no headers) and when I only want a subset of the columns (say 4th and 7th out of a total of 20 columns), using pandas? I cannot seem to be able to do usecols     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to turn on line numbers in IDLE?",
        "A_Content": "  Unfortunately there is not an option to display line numbers in IDLE although there is an enhancement request open for this.  However, there are a couple of ways to work around this:   Under the edit menu there is a go to line option (there is a default shortcut of Alt+G for this). There is a display at the bottom right which tells you your current line number / position on the line:        ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/18805203/how-to-turn-on-line-numbers-in-idle",
        "A_Votes": "113",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In the main shell of IDLE, errors always return a line number but the development environment doesn't even have line numbers. Is there anyway to turn on line numbers?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to turn on line numbers in IDLE?",
        "A_Content": "  There's a set of useful extensions to IDLE called IDLEX that works with MacOS and Windows http://idlex.sourceforge.net/  It includes line numbering and I find it quite handy & free.   Otherwise there are a bunch of other IDEs some of which are free:  https://wiki.python.org/moin/IntegratedDevelopmentEnvironments     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/18805203/how-to-turn-on-line-numbers-in-idle",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the main shell of IDLE, errors always return a line number but the development environment doesn't even have line numbers. Is there anyway to turn on line numbers?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to turn on line numbers in IDLE?",
        "A_Content": "  If you are trying to track down which line caused an error, if you right-click in the Python shell where the line error is displayed it will come up with a \"Go to file/line\"  which takes you directly to the line in question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/18805203/how-to-turn-on-line-numbers-in-idle",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the main shell of IDLE, errors always return a line number but the development environment doesn't even have line numbers. Is there anyway to turn on line numbers?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to turn on line numbers in IDLE?",
        "A_Content": "  As it was mentioned by Davos you can use the IDLEX  It happens that I'm using Linux version and from all extensions I needed only LineNumbers. So I've downloaded IDLEX archive, took LineNumbers.py from it, copied it to Python's lib folder ( in my case its /usr/lib/python3.5/idlelib ) and added following lines to configuration file in my home folder which is  ~/.idlerc/config-extensions.cfg:  [LineNumbers] enable = 1 enable_shell = 0 visible = True  [LineNumbers_cfgBindings] linenumbers-show =       ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/18805203/how-to-turn-on-line-numbers-in-idle",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the main shell of IDLE, errors always return a line number but the development environment doesn't even have line numbers. Is there anyway to turn on line numbers?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to turn on line numbers in IDLE?",
        "A_Content": "  As @StahlRat already answered. I would like to add another method for it. There is extension pack for Python Default idle editor Python Extensions Package.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/18805203/how-to-turn-on-line-numbers-in-idle",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In the main shell of IDLE, errors always return a line number but the development environment doesn't even have line numbers. Is there anyway to turn on line numbers?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I configure a Python interpreter in IntelliJ IDEA with the PyCharm plugin?",
        "A_Content": "  With the Python plugin installed, navigate to File > Project Structure.  Under the Project menu for Project SDK, select \"New\" and select \"Python SDK\", then select \"Local\".  Provided you have a Python SDK installed, the flow should be natural from there - navigate to the location your Python installation lives.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "intellij-idea"
        ],
        "URL": "https://stackoverflow.com/questions/24769117/how-do-i-configure-a-python-interpreter-in-intellij-idea-with-the-pycharm-plugin",
        "A_Votes": "130",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    There is a tutorial in the IDEA docs on how to add a Python interpreter in PyCharm, which involves accessing the \"Project Interpreter\" page. Even after installing the Python plugin, I don't see that setting anywhere.  Am I missing something obvious?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I configure a Python interpreter in IntelliJ IDEA with the PyCharm plugin?",
        "A_Content": "  So here is a simple project, where I have used Selenium and added that using external path    Now you need to open Project Structure and go to SDK Section    Now Select your project's virtual environment. In the Classpath tab add the PYTHONPATH by clicking + button      and now the modules will be recognized       ",
        "Language": "Python",
        "Tags": [
            "python",
            "intellij-idea"
        ],
        "URL": "https://stackoverflow.com/questions/24769117/how-do-i-configure-a-python-interpreter-in-intellij-idea-with-the-pycharm-plugin",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    There is a tutorial in the IDEA docs on how to add a Python interpreter in PyCharm, which involves accessing the \"Project Interpreter\" page. Even after installing the Python plugin, I don't see that setting anywhere.  Am I missing something obvious?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I configure a Python interpreter in IntelliJ IDEA with the PyCharm plugin?",
        "A_Content": "  Follow these steps:   Open Setting (Ctrl + Alt + s) Click on plugins Find Browse Repositories and click Search for \"python\" Select Python SDK or pycharm Restart the IDE Go to project structure Select the python SDK in projects or create a new project with python SDK.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "intellij-idea"
        ],
        "URL": "https://stackoverflow.com/questions/24769117/how-do-i-configure-a-python-interpreter-in-intellij-idea-with-the-pycharm-plugin",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    There is a tutorial in the IDEA docs on how to add a Python interpreter in PyCharm, which involves accessing the \"Project Interpreter\" page. Even after installing the Python plugin, I don't see that setting anywhere.  Am I missing something obvious?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I configure a Python interpreter in IntelliJ IDEA with the PyCharm plugin?",
        "A_Content": "  For Pycharm users:  File ⟶ Settings ⟶ Project: MyProject ⟶ Project Interpreter     ",
        "Language": "Python",
        "Tags": [
            "python",
            "intellij-idea"
        ],
        "URL": "https://stackoverflow.com/questions/24769117/how-do-i-configure-a-python-interpreter-in-intellij-idea-with-the-pycharm-plugin",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    There is a tutorial in the IDEA docs on how to add a Python interpreter in PyCharm, which involves accessing the \"Project Interpreter\" page. Even after installing the Python plugin, I don't see that setting anywhere.  Am I missing something obvious?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "     I want form.data['field'] and   form.field.value to always have the   same value   This is feasible, because it involves decorated names and indexing -- i.e., completely different constructs from the barenames a and b that you're asking about, and for with your request is utterly impossible.  Why ask for something impossible and totally different from the (possible) thing you actually want?!  Maybe you don't realize how drastically different barenames and decorated names are.  When you refer to a barename a, you're getting exactly the object a was last bound to in this scope (or an exception if it wasn't bound in this scope) -- this is such a deep and fundamental aspect of Python that it can't possibly be subverted.  When you refer to a decorated name x.y, you're asking an object (the object x refers to) to please supply \"the y attribute\" -- and in response to that request, the object can perform totally arbitrary computations (and indexing is quite similar: it also allows arbitrary computations to be performed in response).  Now, your \"actual desiderata\" example is mysterious because in each case two levels of indexing or attribute-getting are involved, so the subtlety you crave could be introduced in many ways.  What other attributes is form.field suppose to have, for example, besides value?  Without that further .value computations, possibilities would include:  class Form(object):    ...    def __getattr__(self, name):        return self.data[name]   and  class Form(object):    ...    @property    def data(self):        return self.__dict__   The presence of .value suggests picking the first form, plus a kind-of-useless wrapper:  class KouWrap(object):    def __init__(self, value):        self.value = value  class Form(object):    ...    def __getattr__(self, name):        return KouWrap(self.data[name])   If assignments such form.field.value = 23 is also supposed to set the entry in form.data, then the wrapper must become more complex indeed, and not all that useless:  class MciWrap(object):    def __init__(self, data, k):        self._data = data        self._k = k    @property    def value(self):        return self._data[self._k]    @value.setter    def value(self, v)        self._data[self._k] = v  class Form(object):    ...    def __getattr__(self, name):        return MciWrap(self.data, name)   The latter example is roughly as close as it gets, in Python, to the sense of \"a pointer\" as you seem to want -- but it's crucial to understand that such subtleties can ever only work with indexing and/or decorated names, never with barenames as you originally asked!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "  There's no way you can do that changing only that line.  You can do:   a = [1] b = a a[0] = 2 b[0]   That creates a list, assigns the reference to a, then b also, uses the a reference to set the first element to 2, then accesses using the b reference variable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "  It's not a bug, it's a feature :-)  When you look at the '=' operator in Python, don't think in terms of assignment. You don't assign things, you bind them. = is a binding operator.  So in your code, you are giving the value 1 a name: a. Then, you are giving the value in 'a' a name: b. Then you are binding the value 2 to the name 'a'. The value bound to b doesn't change in this operation.  Coming from C-like languages, this can be confusing, but once you become accustomed to it, you find that it helps you to read and reason about your code more clearly: the value which has the name 'b' will not change unless you explicitly change it. And if you do an 'import this', you'll find that the Zen of Python states that Explicit is better than implicit.  Note as well that functional languages such as Haskell also use this paradigm, with great value in terms of robustness.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "  Yes! there is a way to use a variable as a pointer in python!  I am sorry to say that many of answers were partially wrong. In principle every equal(=) assignation shares the memory address (check the id(obj) function), but in practice it is not such. There are variables whose equal(\"=\") behaviour works in last term as a copy of memory space, mostly in simple objects (e.g. \"int\" object), and others in which not (e.g. \"list\",\"dict\" objects).  Here is an example of pointer assignation  dict1 = {'first':'hello', 'second':'world'} dict2 = dict1 # pointer assignation mechanism dict2['first'] = 'bye' dict1 >>> {'first':'bye', 'second':'world'}   Here is an example of copy assignation  a = 1 b = a # copy of memory mechanism. up to here id(a) == id(b) b = 2 # new address generation. therefore without pointer behaviour a >>> 1   Pointer assignation is a pretty useful tool for aliasing without the waste of extra memory, in certain situations for performing comfy code,  class cls_X():    ...    def method_1():       pd1 = self.obj_clsY.dict_vars_for_clsX['meth1'] # pointer dict 1: aliasing       pd1['var4'] = self.method2(pd1['var1'], pd1['var2'], pd1['var3'])    #enddef method_1    ... #endclass cls_X   but one have to be aware of this use in order to prevent code mistakes.  To conclude, by default some variables are barenames (simple objects like int, float, str,...), and some are pointers when assigned between them (e.g. dict1 = dict2). How to recognize them? just try this experiment with them. In IDEs with variable explorer panel usually appears to be the memory address (\"@axbbbbbb...\") in the definition of pointer-mechanism objects.  I suggest investigate in the topic. There are many people who know much more about this topic for sure. (see \"ctypes\" module). I hope it is helpful. Enjoy the good use of the objects! Regards, José Crespo     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "  From one point of view, everything is a pointer in Python.  Your example works a lot like the C++ code.  int* a = new int(1); int* b = a; a = new int(2); cout << *b << endl;   // prints 1   (A closer equivalent would use some type of shared_ptr<Object> instead of int*.)     Here's an example: I want   form.data['field'] and   form.field.value  to always have the   same value. It's not completely   necessary, but I think it would be   nice.   You can do this by overloading __getitem__ in form.data's class.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Pointers in Python?",
        "A_Content": "  id(1) 1923344848  # identity of the location in my memory     >> a = 1 >> b = a  # or equivalently b = 1, because 1 is immutable >> id(a) 1923344848 >> id(b) 1923344848   As you can see a and b are just names that reference to the same object 1. If later you write a = 2, you reassign the name a to a different object 2, but not the b which will continue referencing to 1:  >> id(2) 1923344880 >> a = 2 >> id(a) 1923344880  # same as id(2) >> id(b) 1923344848  # same as id(1)   What will happen if you had a mutable object?   >> id([1]) 328817608 >> id([1]) 328664968  # different >> a = [1] >> id(a) 328817800 >> id(a) 328817800  # same as before >> b = a  # not equivalent to b = [1] >> id(b) 328817800  # same as id(a)   Now, you are referencing to the same list object by the names a and b. You can mutate this list but it will stay the same object, and a and b will both continue referencing to it  >> a[0] = 2 >> a [2] >> b [2] >> id(a) 328817800  # same as before >> id(b) 328817800  # same as before      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pointers"
        ],
        "URL": "https://stackoverflow.com/questions/3106689/pointers-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know Python doesn't have pointers, but is there a way to have this yield 2 instead  >>> a = 1 >>> b = a # modify this line somehow so that b \"points to\" a >>> a = 2 >>> b 1   ?    Here's an example: I want form.data['field'] and form.field.value to always have the same value. It's not completely necessary, but I think it would be nice.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I use redis with Django?",
        "A_Content": "  This Python module for Redis has a clear usage example in the readme: http://github.com/andymccurdy/redis-py   Redis is designed to be a RAM cache. It supports basic GET and SET of keys plus the storing of collections such as dictionaries. You can cache RDBMS queries by storing their output in Redis. The goal would be to speed up your Django site. Don't start using Redis or any other cache until you need the speed - don't prematurely optimize.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "redis"
        ],
        "URL": "https://stackoverflow.com/questions/3801379/how-can-i-use-redis-with-django",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've heard of redis-cache but how exactly does it work? Is it used as a layer between django and my rdbms, by caching the rdbms queries somehow?   Or is it supposed to be used directly as the database? Which I doubt, since that github page doesn't cover any login details, no setup.. just tells you to set some config property.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I use redis with Django?",
        "A_Content": "  Just because Redis stores things in-memory does not mean that it is meant to be a cache. I have seen people using it as a persistent store for data.  That it can be used as a cache is a hint that it is useful as a high-performance storage. If your Redis system goes down though you might loose data that was not been written back onto the disk again. There are some ways to mitigate such dangers, e.g. a hot-standby replica. If your data is 'mission-critical', like if you run a bank or a shop, Redis might not be the best pick for you. But if you write a high-traffic game with persistent live data or some social-interaction stuff and manage the probability of data-loss to be quite acceptable, then Redis might be worth a look.  Anyway, the point remains, yes, Redis can be used as a database.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "redis"
        ],
        "URL": "https://stackoverflow.com/questions/3801379/how-can-i-use-redis-with-django",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've heard of redis-cache but how exactly does it work? Is it used as a layer between django and my rdbms, by caching the rdbms queries somehow?   Or is it supposed to be used directly as the database? Which I doubt, since that github page doesn't cover any login details, no setup.. just tells you to set some config property.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I use redis with Django?",
        "A_Content": "  Redis is basically an 'in memory' KV store with loads of bells and whistles. It is extremely flexible. You can use it as a temporary store, like a cache, or a permanent store, like a database (with caveats as mentioned in other answers).  When combined with Django the best/most common use case for Redis is probably to cache 'responses'.  There's a backend here https://github.com/sebleier/django-redis-cache/ and excellent documentation in the Django docs here: https://docs.djangoproject.com/en/1.3/topics/cache/ .  I've recently started using https://github.com/erussell/django-redis-status to monitor my cache - works a charm. (Configure maxmemory on redis or the results aren't so very useful).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "redis"
        ],
        "URL": "https://stackoverflow.com/questions/3801379/how-can-i-use-redis-with-django",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've heard of redis-cache but how exactly does it work? Is it used as a layer between django and my rdbms, by caching the rdbms queries somehow?   Or is it supposed to be used directly as the database? Which I doubt, since that github page doesn't cover any login details, no setup.. just tells you to set some config property.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How can I use redis with Django?",
        "A_Content": "  You can also use Redis as a queue for distributed tasks in your Django app. You can use it as a message broker for Celery or Python RQ.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "redis"
        ],
        "URL": "https://stackoverflow.com/questions/3801379/how-can-i-use-redis-with-django",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've heard of redis-cache but how exactly does it work? Is it used as a layer between django and my rdbms, by caching the rdbms queries somehow?   Or is it supposed to be used directly as the database? Which I doubt, since that github page doesn't cover any login details, no setup.. just tells you to set some config property.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  This is one of those subtle differences among various mapping collections that can bite you.  In Python (and apparently in Lua) the keys to a mapping (dictionary or table, respectively) are object references.  In Python they must be immutable types, or they must be objects which implement a __hash__ method.  (The Lua docs suggest that it automatically uses the object's  ID as a hash/key even for mutable objects and relies on string interning to ensure that equivalent strings map to the same objects).  In Perl, Javascript, awk and many other languages the keys for hashes, associative arrays or whatever they're called for the given language, are strings (or \"scalars\" in Perl).  In perl $foo{1}, $foo{1.0}, and $foo{\"1\"} are all references to the same mapping in %foo --- the key is evaluated as a scalar!  JSON started as a Javascript serialization technology. (JSON stands for [J]ava[S]cript [o]bject [n]otation.)  Naturally it implements semantics for its mapping notation which are consistent with its mapping semantics.  If both ends of your serialization are going to be Python then you'd be better off using pickles.  If you really need to convert these back from JSON into native Python objects I guess you have a couple of choices.  First you could try (try: ... except: ...) to convert any key to a number in the event of a dictionary look-up failure.  Alternatively, if you add  code to the other end (the serializer or generator of this JSON data) then you could have it  perform a JSON serialization on each of the key values --- providing those as a list of keys.  (Then your Python code would first iterate over the list of keys, instantiating/deserializing them into native Python objects ... and then use those for access the values out of the mapping).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  No, there is no such thing as a Number key in JavaScript. All object properties are converted to String.  var a= {1: 'a'}; for (k in a)     alert(typeof k); // 'string'   This can lead to some curious-seeming behaviours:  a[999999999999999999999]= 'a'; // this even works on Array alert(a[1000000000000000000000]); // 'a' alert(a['999999999999999999999']); // fail alert(a['1e+21']); // 'a'   JavaScript Objects aren't really proper mappings as you'd understand it in languages like Python, and using keys that aren't String results in weirdness. This is why JSON always explicitly writes keys as strings, even where it doesn't look necessary.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  Alternatively you can also try converting dictionary to a list of [(k1,v1),(k2,v2)] format while encoding it using json, and converting it back to dictionary after decoding it back.  >>>> import json >>>> json.dumps(releases.items())     '[[1, \"foo-v0.1\"]]' >>>> releases = {1: \"foo-v0.1\"} >>>> releases == dict(json.loads(json.dumps(releases.items())))      True  I believe this will need some more work like having some sort of flag to identify what all parameters to be converted to dictionary after decoding it back from json.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  I've gotten bitten by the same problem.  As others have pointed out, in JSON, the mapping keys must be strings.  You can do one of two things.  You can use a less strict JSON library, like demjson, which allows integer strings.  If no other programs (or no other in other languages) are going to read it, then you should be okay.  Or you can use a different serialization language.  I wouldn't suggest pickle.  It's hard to read, and is not designed to be secure.  Instead, I'd suggest YAML, which is (nearly) a superset of JSON, and does allow integer keys.  (At least PyYAML does.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  Answering your subquestion:  It can be accomplished by using json.loads(jsonDict, object_hook=jsonKeys2int)  def jsonKeys2int(x):     if isinstance(x, dict):             return {int(k):v for k,v in x.items()}     return x   This function will also work for nested dicts and uses a dict comprehension.  If you want to to cast the values too, use:  def jsonKV2int(x):     if isinstance(x, dict):             return {int(k):(int(v) if isinstance(v, unicode) else v) for k,v in x.items()}     return x   Which tests the instance of the values and casts them only if they are strings objects (unicode to be exact).   Both functions assumes keys (and values) to be integers.  Thanks to:  How to use if/else in a dictionary comprehension?  Convert a string key to int in a Dictionary     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  Convert the dictionary to be string by using str(dict) and then convert it back to dict by doing this:  import ast ast.literal_eval(string)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python's json module, converts int dictionary keys to strings",
        "A_Content": "  You can write your json.dumps by yourself, here is a example from djson: encoder.py. You can use it like this:  assert dumps({1: \"abc\"}) == '{1: \"abc\"}'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/1450957/pythons-json-module-converts-int-dictionary-keys-to-strings",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have found that when the following is run, python's json module (included since 2.6) converts int dictionary keys to strings.  >>> import json >>> releases = {1: \"foo-v0.1\"} >>> json.dumps(releases) '{\"1\": \"foo-v0.1\"}'   Is there any easy way to preserve the key as an int, without needing to parse the string on dump and load. I believe it would be possible using the hooks provided by the json module, but again this still requires parsing. Is there possibly an argument I have overlooked? cheers, chaz  Sub-question: Thanks for the answers. Seeing as json works as I feared, is there an easy way to convey key type by maybe parsing the output of dumps? Also I should note the code doing the dumping and the code downloading the json object from a server and loading it, are both written by me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Get Output From the logging Module in IPython Notebook",
        "A_Content": "  Try following:  import logging logger = logging.getLogger() logger.setLevel(logging.DEBUG) logging.debug(\"test\")   According to logging.basicConfig:     Does basic configuration for the logging system by creating a   StreamHandler with a default Formatter and adding it to the root   logger. The functions debug(), info(), warning(), error() and   critical() will call basicConfig() automatically if no handlers are   defined for the root logger.      This function does nothing if the root logger already has handlers   configured for it.   It seems like ipython notebook call basicConfig (or set handler) somewhere.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "logging",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook",
        "A_Votes": "74",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When I running the following inside IPython Notebook I don't see any output:  import logging logging.basicConfig(level=logging.DEBUG) logging.debug(\"test\")   Anyone know how to make it so I can see the \"test\" message inside the notebook?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Get Output From the logging Module in IPython Notebook",
        "A_Content": "  If you still want to use basicConfig, reload the logging module like this  import logging reload(logging) logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logging",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I running the following inside IPython Notebook I don't see any output:  import logging logging.basicConfig(level=logging.DEBUG) logging.debug(\"test\")   Anyone know how to make it so I can see the \"test\" message inside the notebook?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Get Output From the logging Module in IPython Notebook",
        "A_Content": "  My understanding is that the IPython session starts up logging so basicConfig doesn't work. Here is the setup that works for me (I wish this was not so gross looking since I want to use it for almost all my notebooks):  import logging logger = logging.getLogger() fhandler = logging.FileHandler(filename='mylog.log', mode='a') formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') fhandler.setFormatter(formatter) logger.addHandler(fhandler) logger.setLevel(logging.DEBUG)   Now when I run:  logging.error('hello!') logging.debug('This is a debug message') logging.info('this is an info message') logging.warning('tbllalfhldfhd, warning.')   I get a \"mylog.log\" file in the same directory as my notebook that contains:  2015-01-28 09:49:25,026 - root - ERROR - hello! 2015-01-28 09:49:25,028 - root - DEBUG - This is a debug message 2015-01-28 09:49:25,029 - root - INFO - this is an info message 2015-01-28 09:49:25,032 - root - WARNING - tbllalfhldfhd, warning.   Note that if you rerun this without restarting the IPython session it will write duplicate entries to the file since there would now be two file handlers defined     ",
        "Language": "Python",
        "Tags": [
            "python",
            "logging",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I running the following inside IPython Notebook I don't see any output:  import logging logging.basicConfig(level=logging.DEBUG) logging.debug(\"test\")   Anyone know how to make it so I can see the \"test\" message inside the notebook?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Get Output From the logging Module in IPython Notebook",
        "A_Content": "  Bear in mind that stderr is the default stream for the logging module, so in IPython and Jupyter notebooks you might not see anything unless you configure the stream to stdout:  import logging import sys  logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',                      level=logging.INFO, stream=sys.stdout)  logging.info('Hello world!')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "logging",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I running the following inside IPython Notebook I don't see any output:  import logging logging.basicConfig(level=logging.DEBUG) logging.debug(\"test\")   Anyone know how to make it so I can see the \"test\" message inside the notebook?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Get Output From the logging Module in IPython Notebook",
        "A_Content": "  You can configure logging by running %config Application.log_level=\"INFO\"  For more information, see IPython kernel options     ",
        "Language": "Python",
        "Tags": [
            "python",
            "logging",
            "ipython-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I running the following inside IPython Notebook I don't see any output:  import logging logging.basicConfig(level=logging.DEBUG) logging.debug(\"test\")   Anyone know how to make it so I can see the \"test\" message inside the notebook?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Difference between Variable and get_variable in TensorFlow",
        "A_Content": "  I'd recommend to always use tf.get_variable(...) -- it will make it way easier to refactor your code if you need to share variables at any time, e.g. in a multi-gpu setting (see the multi-gpu CIFAR example). There is no downside to it.   Pure tf.Variable is lower-level; at some point tf.get_variable() did not exist so some code still uses the low-level way.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow",
        "A_Votes": "73",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    As far as I know, Variable is the default operation for making a variable, and get_variable is mainly used for weight sharing.  On the one hand, there are some people suggesting using get_variable instead of the primitive Variable operation whenever you need a variable. On the other hand, I merely see any use of get_variable in TensorFlow's official documents and demos.  Thus I want to know some rules of thumb on how to correctly use these two mechanisms. Are there any \"standard\" principles?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Difference between Variable and get_variable in TensorFlow",
        "A_Content": "  tf.Variable is a class, and there are several ways to create tf.Variable including tf.Variable.__init__ and tf.get_variable.   tf.Variable.__init__: Creates a new variable with initial_value.  W = tf.Variable(<initial-value>, name=<optional-name>)   tf.get_variable: Gets an existing variable with these parameters or create a new one. You can also use initializer.  W = tf.get_variable(name, shape=None, dtype=tf.float32, initializer=None,        regularizer=None, trainable=True, collections=None)   It's very useful to use initializers such as xavier_initializer:  W = tf.get_variable(\"W\", shape=[784, 256],        initializer=tf.contrib.layers.xavier_initializer())   More information at https://www.tensorflow.org/versions/r0.8/api_docs/python/state_ops.html#Variable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow",
        "A_Votes": "53",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    As far as I know, Variable is the default operation for making a variable, and get_variable is mainly used for weight sharing.  On the one hand, there are some people suggesting using get_variable instead of the primitive Variable operation whenever you need a variable. On the other hand, I merely see any use of get_variable in TensorFlow's official documents and demos.  Thus I want to know some rules of thumb on how to correctly use these two mechanisms. Are there any \"standard\" principles?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Difference between Variable and get_variable in TensorFlow",
        "A_Content": "  I can find two main differences between one and the other:   First is that tf.Variable will always create a new variable, whether tf.get_variable gets from the graph an existing variable with those parameters, and if it does not exists, it creates a new one. tf.Variable requires that an initial value be specified.   It is important to clarify that the function tf.get_variable prefixes the name with the current variable scope to perform reuse checks.  For example:  with tf.variable_scope(\"one\"):     a = tf.get_variable(\"v\", [1]) #a.name == \"one/v:0\" with tf.variable_scope(\"one\"):     b = tf.get_variable(\"v\", [1]) #ValueError: Variable one/v already exists with tf.variable_scope(\"one\", reuse = True):     c = tf.get_variable(\"v\", [1]) #c.name == \"one/v:0\"  with tf.variable_scope(\"two\"):     d = tf.get_variable(\"v\", [1]) #d.name == \"two/v:0\"     e = tf.Variable(1, name = \"v\", expected_shape = [1]) #e.name == \"two/v_1:0\"  assert(a is c)  #Assertion is true, they refer to the same object. assert(a is d)  #AssertionError: they are different objects assert(d is e)  #AssertionError: they are different objects   The last assertion error is interesting: Two variables with the same name under the same scope are supposed to be the same variable.  But if you test the names of variables d and e you will realize that Tensorflow changed the name of variable e:  d.name   #d.name == \"two/v:0\" e.name   #e.name == \"two/v_1:0\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    As far as I know, Variable is the default operation for making a variable, and get_variable is mainly used for weight sharing.  On the one hand, there are some people suggesting using get_variable instead of the primitive Variable operation whenever you need a variable. On the other hand, I merely see any use of get_variable in TensorFlow's official documents and demos.  Thus I want to know some rules of thumb on how to correctly use these two mechanisms. Are there any \"standard\" principles?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  myvariable = 4 mystring = str(myvariable)  # '4'   also, alternatively try repr:  mystring = repr(myvariable) # '4'   This is called \"conversion\" in python, and is quite common.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "83",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  str is meant to produce a string representation of the object's data. If you're writing your own class and you want str to work for you, add:  def __str__(self):     return \"Some descriptive string\"   print str(myObj) will call myObj.__str__().  repr is a similar method, which generally produces information on the class info. For most core library object, repr produces the class name (and sometime some class information) between angle brackets. repr will be used, for example, by just typing your object into your interactions pane, without using print or anything else.  You can define the behavior of repr for your own objects just like you can define the behavior of str:  def __repr__(self):     return \"Some descriptive string\"   >>> myObj in your interactions pane, or repr(myObj), will result in myObj.__repr__()     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  I see all answers recommend using str(object). It might fail if your object have more than ascii characters and you will see error like ordinal not in range(128). This was the case for me while I was converting list of string in language other than English  I resolved it by using unicode(object)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  Use the str built-in:  x = str(something)   Examples:  >>> str(1) '1' >>> str(1.0) '1.0' >>> str([]) '[]' >>> str({}) '{}'  ...   From the documentation:     Return a string containing a nicely printable representation of an object. For strings, this returns the string itself. The difference with repr(object) is that str(object) does not always attempt to return a string that is acceptable to eval(); its goal is to return a printable string. If no argument is given, returns the empty string, ''.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  str(object) will do the trick.  If you want to alter the way object is stringified, define __str__(self) method for object's class. Such method has to return str or unicode object.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  With str(x). However, every data type can define its own string conversion, so this might not be what you want.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  Just use str - for example:  >>> str([]) '[]'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  Use formatting:  \"%s\" % (x)   Example:  x = time.ctime(); str = \"%s\" % (x); print str   Output:  Thu Jan 11 20:40:05 2018     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "how to change any data type into a string in python",
        "A_Content": "  You can use %s like below  >>> \"%s\" %([]) '[]'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3204614/how-to-change-any-data-type-into-a-string-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I change any data type into a string in Python?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can you list the keyword arguments a function receives?",
        "A_Content": "  A little nicer than inspecting the code object directly and working out the variables is to use the inspect module.  >>> import inspect >>> def func(a,b,c=42, *args, **kwargs): pass >>> inspect.getargspec(func) (['a', 'b', 'c'], 'args', 'kwargs', (42,))   If you want to know if its callable with a particular set of args, you need the args without a default already specified.  These can be got by:  def getRequiredArgs(func):     args, varargs, varkw, defaults = inspect.getargspec(func)     if defaults:         args = args[:-len(defaults)]     return args   # *args and **kwargs are not required, so ignore them.   Then a function to tell what you are missing from your particular dict is:  def missingArgs(func, argdict):     return set(getRequiredArgs(func)).difference(argdict)   Similarly, to check for invalid args, use:  def invalidArgs(func, argdict):     args, varargs, varkw, defaults = inspect.getargspec(func)     if varkw: return set()  # All accepted     return set(argdict) - set(args)   And so a full test if it is callable is :  def isCallableWithArgs(func, argdict):     return not missingArgs(func, argdict) and not invalidArgs(func, argdict)   (This is good only as far as python's arg parsing.  Any runtime checks for invalid values in kwargs obviously can't be detected.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arguments",
            "introspection"
        ],
        "URL": "https://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-function-receives",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a dict, which I need to pass key/values as keyword arguments.. For example..  d_args = {'kw1': 'value1', 'kw2': 'value2'} example(**d_args)   This works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):  This is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..  Ideally I would just do  parsed_kwargs = feedparser.parse(the_url) valid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2) PyRSS2Gen.RSS2(**valid_kwargs)   I will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can you list the keyword arguments a function receives?",
        "A_Content": "  This will print names of all passable arguments, keyword and non-keyword ones:  def func(one, two=\"value\"):     y = one, two     return y print func.func_code.co_varnames[:func.func_code.co_argcount]   This is because first co_varnames are always parameters (next are local variables, like y in the example above).  So now you could have a function:  def getValidArgs(func, argsDict):     '''Return dictionary without invalid function arguments.'''     validArgs = func.func_code.co_varnames[:func.func_code.co_argcount]     return dict((key, value) for key, value in argsDict.iteritems()                  if key in validArgs)   Which you then could use like this:  >>> func(**getValidArgs(func, args))     EDIT: A small addition: if you really need only keyword arguments of a function, you can use the func_defaults attribute to extract them:  def getValidKwargs(func, argsDict):     validArgs = func.func_code.co_varnames[:func.func_code.co_argcount]     kwargsLen = len(func.func_defaults) # number of keyword arguments     validKwargs = validArgs[-kwargsLen:] # because kwargs are last     return dict((key, value) for key, value in argsDict.iteritems()                  if key in validKwargs)   You could now call your function with known args, but extracted kwargs, e.g.:  func(param1, param2, **getValidKwargs(func, kwargsDict))   This assumes that func uses no *args or **kwargs magic in its signature.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arguments",
            "introspection"
        ],
        "URL": "https://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-function-receives",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dict, which I need to pass key/values as keyword arguments.. For example..  d_args = {'kw1': 'value1', 'kw2': 'value2'} example(**d_args)   This works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):  This is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..  Ideally I would just do  parsed_kwargs = feedparser.parse(the_url) valid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2) PyRSS2Gen.RSS2(**valid_kwargs)   I will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can you list the keyword arguments a function receives?",
        "A_Content": "  In Python 3.0:  >>> import inspect >>> import fileinput >>> print(inspect.getfullargspec(fileinput.input)) FullArgSpec(args=['files', 'inplace', 'backup', 'bufsize', 'mode', 'openhook'], varargs=None, varkw=None, defaults=(None, 0, '', 0, 'r', None), kwonlyargs=[],  kwdefaults=None, annotations={})      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arguments",
            "introspection"
        ],
        "URL": "https://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-function-receives",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dict, which I need to pass key/values as keyword arguments.. For example..  d_args = {'kw1': 'value1', 'kw2': 'value2'} example(**d_args)   This works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):  This is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..  Ideally I would just do  parsed_kwargs = feedparser.parse(the_url) valid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2) PyRSS2Gen.RSS2(**valid_kwargs)   I will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can you list the keyword arguments a function receives?",
        "A_Content": "  Extending DzinX's answer:  argnames = example.func_code.co_varnames[:func.func_code.co_argcount] args = dict((key, val) for key,val in d_args.iteritems() if key in argnames) example(**args)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arguments",
            "introspection"
        ],
        "URL": "https://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-function-receives",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dict, which I need to pass key/values as keyword arguments.. For example..  d_args = {'kw1': 'value1', 'kw2': 'value2'} example(**d_args)   This works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):  This is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..  Ideally I would just do  parsed_kwargs = feedparser.parse(the_url) valid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2) PyRSS2Gen.RSS2(**valid_kwargs)   I will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can you list the keyword arguments a function receives?",
        "A_Content": "  For a Python 3 solution, you can use inspect.signature and filter according to the kind of parameters you'd like to know about.   Taking a sample function with positional or keyword, keyword-only, var positional and var keyword parameters:  def spam(a, b=1, *args, c=2, **kwargs):     print(a, b, args, c, kwargs)   You can create a signature object for it:  from inspect import signature sig =  signature(spam)   and then filter with a list comprehension to find out the details you need:  >>> # positional or keyword >>> [p.name for p in sig.parameters.values() if p.kind == p.POSITIONAL_OR_KEYWORD] ['a', 'b'] >>> # keyword only >>> [p.name for p in sig.parameters.values() if p.kind == p.KEYWORD_ONLY] ['c']   and, similarly, for var positionals using p.VAR_POSITIONAL and var keyword with VAR_KEYWORD.   In addition, you can add a clause to the if to check if a default value exists by checking if p.default equals p.empty.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arguments",
            "introspection"
        ],
        "URL": "https://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-function-receives",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dict, which I need to pass key/values as keyword arguments.. For example..  d_args = {'kw1': 'value1', 'kw2': 'value2'} example(**d_args)   This works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):  This is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..  Ideally I would just do  parsed_kwargs = feedparser.parse(the_url) valid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2) PyRSS2Gen.RSS2(**valid_kwargs)   I will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  Ref: http://docs.python.org/howto/unicode  Reading Unicode from a file is therefore simple:  import codecs f = codecs.open('unicode.rst', encoding='utf-8') for line in f:     print repr(line)   It's also possible to open files in update mode, allowing both reading and writing:  f = codecs.open('test', encoding='utf-8', mode='w+') f.write(u'\\u4500 blah blah blah\\n') f.seek(0) print repr(f.readline()[:1]) f.close()   EDIT: I'm assuming that your intended goal is just to be able to read the file properly into a string in Python. If you're trying to convert to an ASCII string from Unicode, then there's really no direct way to do so, since the Unicode characters won't necessarily exist in ASCII.  If you're trying to convert to an ASCII string, try one of the following:    Replace the specific unicode chars with ASCII equivalents, if you are only looking to handle a few special cases such as this particular example Use the unicodedata module's normalize() and the string.encode() method to convert as best you can to the next closest ASCII equivalent (Ref https://web.archive.org/web/20090228203858/http://techxplorer.com/2006/07/18/converting-unicode-to-ascii-using-python):   >>> teststr u'I don\\xe2\\x80\\x98t like this' >>> unicodedata.normalize('NFKD', teststr).encode('ascii', 'ignore') 'I donat like this'       ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "134",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  There are a few points to consider.  A \\u2018 character may appear only as a fragment of representation of a unicode string in Python, e.g. if you write:  >>> text = u'‘' >>> print repr(text) u'\\u2018'   Now if you simply want to print the unicode string prettily, just use unicode's encode method:  >>> text = u'I don\\u2018t like this' >>> print text.encode('utf-8') I don‘t like this   To make sure that every line from any file would be read as unicode, you'd better use the codecs.open function instead of just open, which allows you to specify file's encoding:  >>> import codecs >>> f1 = codecs.open(file1, \"r\", \"utf-8\") >>> text = f1.read() >>> print type(text) <type 'unicode'> >>> print text.encode('utf-8') I don‘t like this      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  But it really is \"I don\\u2018t like this\" and not \"I don't like this\". The character u'\\u2018' is a completely different character than \"'\" (and, visually, should correspond more to '`').  If you're trying to convert encoded unicode into plain ASCII, you could perhaps keep a mapping of unicode punctuation that you would like to translate into ASCII.  punctuation = {   u'\\u2018': \"'\",   u'\\u2019': \"'\", } for src, dest in punctuation.iteritems():   text = text.replace(src, dest)   There are an awful lot of punctuation characters in unicode, however, but I suppose you can count on only a few of them actually being used by whatever application is creating the documents you're reading.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  Leaving aside the fact that your text file is broken (U+2018 is a left quotation mark, not an apostrophe): iconv can be used to transliterate unicode characters to ascii.  You'll have to google for \"iconvcodec\", since the module seems not to be supported anymore and I can't find a canonical home page for it.  >>> import iconvcodec >>> from locale import setlocale, LC_ALL >>> setlocale(LC_ALL, '') >>> u'\\u2018'.encode('ascii//translit') \"'\"   Alternatively you can use the iconv command line utility to clean up your file:  $ xxd foo 0000000: e280 980a                                .... $ iconv -t 'ascii//translit' foo | xxd 0000000: 270a                                     '.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  There is a possibility that somehow you have a non-unicode string with unicode escape characters, e.g.:  >>> print repr(text) 'I don\\\\u2018t like this'   This actually happened to me once before. You can use a unicode_escape codec to decode the string to unicode and then encode it to any format you want:  >>> uni = text.decode('unicode_escape') >>> print type(uni) <type 'unicode'> >>> print uni.encode('utf-8') I don‘t like this      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  Actually, U+2018 is the Unicode representation of the special character ‘ . If you want, you can convert instances of that character to U+0027 with this code:  text = text.replace (u\"\\u2018\", \"'\")   In addition, what are you using to write the file? f1.read() should return a string that looks like this:  'I don\\xe2\\x80\\x98t like this'   If it's returning this string, the file is being written incorrectly:  'I don\\u2018t like this'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Character reading from file in Python",
        "A_Content": "  This is Pythons way do show you unicode encoded strings. But i think you should be able to print the string on the screen or write it into a new file without any problems.  >>> test = u\"I don\\u2018t like this\" >>> test u'I don\\u2018t like this' >>> print test I don‘t like this      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "encoding",
            "ascii"
        ],
        "URL": "https://stackoverflow.com/questions/147741/character-reading-from-file-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In a text file, there is a string \"I don't like this\".  However, when I read it into a string, it becomes \"I don\\xe2\\x80\\x98t like this\". I understand that \\u2018 is the unicode representation of \"'\". I use   f1 = open (file1, \"r\") text = f1.read()   command to do the reading.  Now, is it possible to read the string in such a way that when it is read into the string, it is \"I don't like this\", instead of \"I don\\xe2\\x80\\x98t like this like this\"?  Second edit: I have seen some people use mapping to solve this problem, but really, is there no built-in conversion that does this kind of ANSI to unicode ( and vice versa) conversion?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  A simple recursive function can be used to convert an entity (and any referents) to a nested dictionary that can be passed to simplejson:  import datetime import time  SIMPLE_TYPES = (int, long, float, bool, dict, basestring, list)  def to_dict(model):     output = {}      for key, prop in model.properties().iteritems():         value = getattr(model, key)          if value is None or isinstance(value, SIMPLE_TYPES):             output[key] = value         elif isinstance(value, datetime.date):             # Convert date/datetime to MILLISECONDS-since-epoch (JS \"new Date()\").             ms = time.mktime(value.utctimetuple()) * 1000             ms += getattr(value, 'microseconds', 0) / 1000             output[key] = int(ms)         elif isinstance(value, db.GeoPt):             output[key] = {'lat': value.lat, 'lon': value.lon}         elif isinstance(value, db.Model):             output[key] = to_dict(value)         else:             raise ValueError('cannot encode ' + repr(prop))      return output      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "62",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  This is the simplest solution I found. It requires only 3 lines of codes.  Simply add a method to your model to return a dictionary:  class DictModel(db.Model):     def to_dict(self):        return dict([(p, unicode(getattr(self, p))) for p in self.properties()])   SimpleJSON now works properly:  class Photo(DictModel):    filename = db.StringProperty()    title = db.StringProperty()    description = db.StringProperty(multiline=True)    date_taken = db.DateTimeProperty()    date_uploaded = db.DateTimeProperty(auto_now_add=True)    album = db.ReferenceProperty(Album, collection_name='photo')  from django.utils import simplejson from google.appengine.ext import webapp  class PhotoHandler(webapp.RequestHandler):    def get(self):       photos = Photo.all()       self.response.out.write(simplejson.dumps([p.to_dict() for p in photos]))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "60",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  In the latest (1.5.2) release of the App Engine SDK, a to_dict() function that converts model instances to dictionaries was introduced in db.py.  See the release notes.   There is no reference to this function in the documentation as of yet, but I have tried it myself and it works as expected.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  To serialize models, add a custom json encoder as in the following python:  import datetime from google.appengine.api import users from google.appengine.ext import db from django.utils import simplejson  class jsonEncoder(simplejson.JSONEncoder):     def default(self, obj):         if isinstance(obj, datetime.datetime):             return obj.isoformat()          elif isinstance(obj, db.Model):             return dict((p, getattr(obj, p))                          for p in obj.properties())          elif isinstance(obj, users.User):             return obj.email()          else:             return simplejson.JSONEncoder.default(self, obj)   # use the encoder as:  simplejson.dumps(model, cls=jsonEncoder)   This will encode:   a date as as isoformat string (per this suggestion), a model as a dict of its properties,  a user as his email.   To decode the date you can use this javascript:  function decodeJsonDate(s){   return new Date( s.slice(0,19).replace('T',' ') + ' GMT' ); } // Note that this function truncates milliseconds.   Note: Thanks to user pydave who edited this code to make it more readable. I had originally had used python's if/else expressions to express jsonEncoder in fewer lines as follows: (I've added some comments and used google.appengine.ext.db.to_dict, to make it clearer than the original.)  class jsonEncoder(simplejson.JSONEncoder):   def default(self, obj):     isa=lambda x: isinstance(obj, x) # isa(<type>)==True if obj is of type <type>     return obj.isoformat() if isa(datetime.datetime) else \\            db.to_dict(obj) if isa(db.Model) else \\            obj.email()     if isa(users.User) else \\            simplejson.JSONEncoder.default(self, obj)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  You don't need to write your own \"parser\" (a parser would presumably turn JSON into a Python object), but you can still serialize your Python object yourself.  Using simplejson:  import simplejson as json serialized = json.dumps({     'filename': self.filename,     'title': self.title,     'date_taken': date_taken.isoformat(),     # etc. })      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  For simple cases, I like the approach advocated here at the end of the article:    # after obtaining a list of entities in some way, e.g.:   user = users.get_current_user().email().lower();   col = models.Entity.gql('WHERE user=:1',user).fetch(300, 0)    # ...you can make a json serialization of name/key pairs as follows:   json = simplejson.dumps(col, default=lambda o: {o.name :str(o.key())})   The article also contains, at the other end of the spectrum, a complex serializer class that enriches django's (and does require _meta -- not sure why you're getting errors about _meta missing, perhaps the bug described here) with the ability to serialize computed properties / methods.  Most of the time you serialization needs lay somewhere in between, and for those an introspective approach such as @David Wilson's may be preferable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  Even if you are not using django as a framework, those libraries are still available for you to use.    from django.core import serializers data = serializers.serialize(\"xml\", Photo.objects.all())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  If you use app-engine-patch it will automatically declare the _meta attribute for you, and then you can use django.core.serializers as you would normally do on django models (as in sledge's code).  App-engine-patch has some other cool features such has an hybrid authentication (django + google accounts), and the admin part of django works.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  Mtgred's answer above worked wonderfully for me -- I slightly modified it so I could also get the key for the entry.  Not as few lines of code, but it gives me the unique key:  class DictModel(db.Model): def to_dict(self):     tempdict1 = dict([(p, unicode(getattr(self, p))) for p in self.properties()])     tempdict2 = {'key':unicode(self.key())}     tempdict1.update(tempdict2)     return tempdict1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  I've extended the JSON Encoder class written by dpatru to support:   Query results properties (e.g. car.owner_set) ReferenceProperty - recursively turn it into JSON Filtering properties - only properties with a verbose_name will be encoded into JSON  class DBModelJSONEncoder(json.JSONEncoder):     \"\"\"Encodes a db.Model into JSON\"\"\"      def default(self, obj):         if (isinstance(obj, db.Query)):             # It's a reference query (holding several model instances)             return [self.default(item) for item in obj]          elif (isinstance(obj, db.Model)):             # Only properties with a verbose name will be displayed in the JSON output             properties = obj.properties()             filtered_properties = filter(lambda p: properties[p].verbose_name != None, properties)              # Turn each property of the DB model into a JSON-serializeable entity             json_dict = dict([(                     p,                     getattr(obj, p)                         if (not isinstance(getattr(obj, p), db.Model))                         else                     self.default(getattr(obj, p)) # A referenced model property                 ) for p in filtered_properties])              json_dict['id'] = obj.key().id() # Add the model instance's ID (optional - delete this if you do not use it)              return json_dict          else:             # Use original JSON encoding             return json.JSONEncoder.default(self, obj)       ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  As mentioned by https://stackoverflow.com/users/806432/fredva, the to_dict works great. Here is my code i'm using.  foos = query.fetch(10) prepJson = []  for f in foos:   prepJson.append(db.to_dict(f))  myJson = json.dumps(prepJson))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  There's a method, \"Model.properties()\", defined for all Model classes.  It returns the dict you seek.  from django.utils import simplejson class Photo(db.Model):   # ...  my_photo = Photo(...) simplejson.dumps(my_photo.properties())   See Model properties in the docs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "JSON serialization of Google App Engine models",
        "A_Content": "  To serialize a Datastore Model instance you can't use json.dumps (haven't tested but Lorenzo pointed it out). Maybe in the future the following will work.  http://docs.python.org/2/library/json.html  import json string = json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}]) object = json.loads(self.request.body)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/1531501/json-serialization-of-google-app-engine-models",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been searching for quite a while with no success. My project isn't using Django, is there a simple way to serialize App Engine models (google.appengine.ext.db.Model) into JSON or do I need to write my own serializer?    Model:  class Photo(db.Model):     filename = db.StringProperty()     title = db.StringProperty()     description = db.StringProperty(multiline=True)     date_taken = db.DateTimeProperty()     date_uploaded = db.DateTimeProperty(auto_now_add=True)     album = db.ReferenceProperty(Album, collection_name='photo')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Matplotlib transparent line plots",
        "A_Content": "  Plain and simple:  plt.plot(x, y, 'r-', alpha=0.7)   (I know I add nothing new, but the straightforward answer should be visible).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scientific-computing"
        ],
        "URL": "https://stackoverflow.com/questions/4320021/matplotlib-transparent-line-plots",
        "A_Votes": "139",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am plotting two similar trajectories in matplotlib and I'd like to plot each of the lines with partial transparency so that the red (plotted second) doesn't obscure the blue.    EDIT: Here's the image with transparent lines.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Matplotlib transparent line plots",
        "A_Content": "  After I plotted all the lines, I was able to set the transparency of all of them as follows:  for l in fig_field.gca().lines:     l.set_alpha(.7)   EDIT: please see Joe's answer in the comments.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scientific-computing"
        ],
        "URL": "https://stackoverflow.com/questions/4320021/matplotlib-transparent-line-plots",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting two similar trajectories in matplotlib and I'd like to plot each of the lines with partial transparency so that the red (plotted second) doesn't obscure the blue.    EDIT: Here's the image with transparent lines.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Matplotlib transparent line plots",
        "A_Content": "  It really depends on what functions you're using to plot the lines, but try see if the on you're using takes an alpha value and set it to something like 0.5. If that doesn't work, try get the line objects and set their alpha values directly.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scientific-computing"
        ],
        "URL": "https://stackoverflow.com/questions/4320021/matplotlib-transparent-line-plots",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am plotting two similar trajectories in matplotlib and I'd like to plot each of the lines with partial transparency so that the red (plotted second) doesn't obscure the blue.    EDIT: Here's the image with transparent lines.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  I'm very glad you asked! I was just working on explaining this very thing in our wikibook (which is obviously incomplete).  We're working with Python novices, and had to help a few through exactly what you're asking!    Command-line Python in Windows:    Save your python code file somewhere, using \"Save\" or \"Save as\" in your editor.  Lets call it 'first.py' in some folder, like \"pyscripts\" that you make on your Desktop. Open a prompt (a Windows 'cmd' shell that is a text interface into the computer):     start > run > \"cmd\" (in the little box).  OK.      Navigate to where your python file is, using the commands 'cd' (change directory) and 'dir' (to show files in the directory, to verify your head).  For our example something like,   > cd C:\\Documents and Settings\\Gregg\\Desktop\\pyscripts try:  > python first.py   If you get this message:       'python' is not recognized as an   internal or external command, operable   program or batch file.   then python (the interpreter program that can translate Python into 'computer instructions') isn't on your path (see Putting Python in Your Path below).  Then try calling it like this (assuming Python2.6, installed in the usual location):  > C:\\Python26\\python.exe first.py  (Advanced users:  instead of first.py, you could write out first.py's full path of C:\\Documents and Settings\\Gregg\\Desktop\\pyscripts\\first.py)  Putting Python In Your Path  Windows  In order to run programs, your operating system looks in various places, and tries to match the name of the program / command you typed with some  programs along the way.    In windows:  control panel > system >  advanced > |Environmental Variables| > system variables -> Path  this needs to include:  C:\\Python26; (or equivalent).  If you put it at the front, it will be the first place looked.  You can also add it at the end, which is possibly saner.  Then restart your prompt, and try typing 'python'.  If it all worked, you should get a \">>>\" prompt.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  You can just call  python /path/to/filename.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  In IDLE press F5  You can open your .py file with IDLE and press F5 to run it.   You can open that same file with other editor ( like Komodo as you said ) save it and press F5 again; F5 works with IDLE ( even when the editing is done with another tool ).  If you want to run it directly from Komodo according to this article: Executing Python Code Within Komodo Edit you have to:   go to Toolbox -> Add -> New Command... in the top field enter the name 'Run Python file' in the 'Command' field enter this text:  %(python) %F 3.a optionall click on the 'Key Binding' tab and assign a key command to this command click Ok.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  Python itself comes with an editor that you can access from the IDLE File > New File menu option.  Write the code in that file, save it as [filename].py and then (in that same file editor window) press F5 to execute the code you created in the IDLE Shell window.  Note: it's just been the easiest and most straightforward way for me so far.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  Navigate your file location just press Shift button and click file name. Click tab Open command window here and write in your command prompt python file_name.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  if you dont want call filename.py you can add .PY to the PATHEXT, that way you will just call filename     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  If this helps anyone, neither \"python [filename].py\" or \"python.exe [filename.py]\" worked for me, but \"start python [filename].py\" did. If anyone else is experiencing issues with the former two commands, try the latter one.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  What I just did, to open a simple python script by double clicking. I just added a batch file to the directory containing the script:  @echo off python exercise.py pause>nul   (I have the python executable on my system path. If not one would need include its complete path of course.)  Then I just can double click on the batch file to run the script. The third line keeps the cmd window from being dismissed as soon as the script ends, so you can see the results. :) When you're done just close the command window.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I run a Python program?",
        "A_Content": "  I have tried many of the commands listed above, however none worked, even after setting my path to include the directory where I installed Python.   The command py -3 file.py always works for me, and if I want to run Python 2 code, as long as Python 2 is in my path, just changing the command to py -2 file.py works perfectly.  I am using Windows, so I'm not too sure if this command will work on Linux, or Mac, but it's worth a try.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ide",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/1522564/how-do-i-run-a-python-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I'm starting like Python a bit, but I'm having trouble erm...running it. Lol  I'm using IDLE for now, but its no use whatsoever because you can only run a couple of lines at a time.  I'm also using Komodo Edit to create the actual .py files.  My question is, how can I run the .py files to test out the actual program?   I'm using Windows 7, and Komodo Edit 5 as my IDE. Pressing F5 in Komodo doesn't do anythin at all.       ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Removing first x characters from string?",
        "A_Content": "  >>> text = 'lipsum' >>> text[3:] 'sum'   See the official documentation on strings for more information and this SO answer for a concise summary of the notation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/11806559/removing-first-x-characters-from-string",
        "A_Votes": "159",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How might one remove the first x characters from a string? For example, if one had a string lipsum, how would they remove the first 3 characters and get a result of sum?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Removing first x characters from string?",
        "A_Content": "  Another way (depending on your actual needs): If you want to pop the first n characters and save both the popped characters and the modified string:  s = 'lipsum' n = 3 a, s = s[:n], s[n:] print a # lip print s # sum      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/11806559/removing-first-x-characters-from-string",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How might one remove the first x characters from a string? For example, if one had a string lipsum, how would they remove the first 3 characters and get a result of sum?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Removing first x characters from string?",
        "A_Content": "  >>> x = 'lipsum' >>> x.replace(x[:3], '') 'sum'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/11806559/removing-first-x-characters-from-string",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How might one remove the first x characters from a string? For example, if one had a string lipsum, how would they remove the first 3 characters and get a result of sum?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Removing first x characters from string?",
        "A_Content": "  Example to show last 3 digits of account number.  x = '1234567890'    x.replace(x[:7], '')  o/p: '890'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/11806559/removing-first-x-characters-from-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How might one remove the first x characters from a string? For example, if one had a string lipsum, how would they remove the first 3 characters and get a result of sum?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  When you execute a script without typing \"python\" in front, you need to know two things about how Windows invokes the program.  First is to find out what kind of file Windows thinks it is:        C:\\>assoc .py     .py=Python.File   Next, you need to know how Windows is executing things with that extension.  It's associated with the file type \"Python.File\", so this command shows what it will be doing:       C:\\>ftype Python.File     Python.File=\"c:\\python26\\python.exe\" \"%1\" %*   So on my machine, when I type \"blah.py foo\", it will execute this exact command, with no difference in results than if I had typed the full thing myself:       \"c:\\python26\\python.exe\" \"blah.py\" foo   If you type the same thing, including the quotation marks, then you'll get results identical to when you just type \"blah.py foo\".  Now you're in a position to figure out the rest of your problem for yourself.    (Or post more helpful information in your question, like actual cut-and-paste copies of what you see in the console.  Note that people who do that type of thing get their questions voted up, and they get reputation points, and more people are likely to help them with good answers.)  Brought In From Comments:  Even if assoc and ftype display the correct information, it may happen that the arguments are stripped off. What may help in that case is directly fixing the relevant registry keys for Python. Set the   HKEY_CLASSES_ROOT\\Applications\\python26.exe\\shell\\open\\command   key to:   \"C:\\Python26\\python26.exe\" \"%1\" %*   Likely, previously, %* was missing. Similarly, set    HKEY_CLASSES_ROOT\\py_auto_file\\shell\\open\\command   to the same value. See http://eli.thegreenplace.net/2010/12/14/problem-passing-arguments-to-python-scripts-on-windows/   HKEY_CLASSES_ROOT\\Applications\\python.exe\\shell\\open\\command The registry path may vary, use python26.exe or python.exe or whichever is already in the registry.   HKEY_CLASSES_ROOT\\py_auto_file\\shell\\open\\command     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  you should make the default application to handle python files be python.exe.  right click a *.py file, select \"Open With\" dialog.  In there select \"python.exe\" and check \"always use this program for this file type\" (something like that).  then your python files will always be run using python.exe     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  Additionally, if you want to be able to run your python scripts without typing the .py (or .pyw) on the end of the file name, you need to add .PY (or .PY;.PYW) to the list of extensions in the PATHEXT environment variable.  In Windows 7:  right-click on Computer left-click Properties left-click Advanced system settings left-click the Advanced tab left-click Environment Variables... under \"system variables\" scroll down until you see PATHEXT left-click on PATHEXT to highlight it left-click Edit... Edit \"Variable value\" so that it contains ;.PY  (the End key will skip to the end) left-click OK left-click OK left-click OK  Note #1: command-prompt windows won't see the change w/o being closed and reopened.  Note #2: the difference between the .py and .pyw extensions is that the former opens a command prompt when run, and the latter doesn't.  On my computer, I added ;.PY;.PYW as the last (lowest-priority) extensions, so the \"before\" and \"after\" values of PATHEXT were:  before: .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC  after .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW  Here are some instructive commands:  C:\\>echo %pathext% .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW  C:\\>assoc .py .py=Python.File  C:\\>ftype Python.File Python.File=\"C:\\Python32\\python.exe\" \"%1\" %*  C:\\>assoc .pyw .pyw=Python.NoConFile  C:\\>ftype Python.NoConFile Python.NoConFile=\"C:\\Python32\\pythonw.exe\" \"%1\" %*  C:\\>type c:\\windows\\helloworld.py print(\"Hello, world!\")  # always use a comma for direct address  C:\\>helloworld Hello, world!  C:\\>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  I encountered the same problem but in the context of needing to package my code for Windows users (coming from Linux). My package contains a number of scripts with command line options.  I need these scripts to get installed in the appropriate location on Windows users' machines so that they can invoke them from the command line. As the package is supposedly user-friendly, asking my users to change their registry to run these scripts would be impossible.  I came across a solution that the folks at Continuum use for Python scripts that come with their Anaconda package -- check out your Anaconda/Scripts directory for examples.  For a Python script test, create two files: a test.bat and a test-script.py.  test.bat looks as follows (the .bat files in Anaconda\\Scripts call python.exe with a relative path which I adapted for my purposes):  @echo off set PYFILE=%~f0 set PYFILE=%PYFILE:~0,-4%-script.py \"python.exe\" \"%PYFILE%\" %*   test-script.py is your actual Python script:  import sys print sys.argv   If you leave these two files in your local directory you can invoke your Python script through the .bat file by doing  test.bat hello world ['C:\\\\...\\\\test-scripy.py', 'hello', 'world']   If you copy both files to a location that is on your PATH (such as Anaconda\\Scripts) then you can even invoke your script by leaving out the .bat suffix  test hello world ['C:\\\\...Anaconda\\\\Scripts\\\\test-scripy.py', 'hello', 'world']   Disclaimer: I have no idea what's going on and how this works and so would appreciate any explanation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "     How to execute Python scripts in Windows?   You could install pylauncher. It is used to launch .py, .pyw, .pyc, .pyo files and supports multiple Python installations:  T\\:> blah.py argument   You can run your Python script without specifying .py extension if you have .py, .pyw in PATHEXT environment variable:  T:\\> blah argument   It adds support for shebang (#! header line) to select desired Python version on Windows if you have multiple versions installed. You could use *nix-compatible syntax #! /usr/bin/env python.  You can specify version explicitly e.g., to run using the latest installed Python 3 version:  T:\\> py -3 blah.py argument   It should also fix your sys.argv issue as a side-effect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  On Windows,   To run a python module without typing \"python\",  --> Right click any python(*.py) file  --> Set the open with property to \"python.exe\"   --> Check the \"always use this program for this file type\"  --> Append the path of python.exe to variable environment e.g. append  C:\\Python27 to PATH environment variable.  To Run a python module without typing \".py\" extension  --> Edit PATHEXT system variable and append \".PY\" extension to the list.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  Can you execute python.exe from any map? If you do not, chek if you have proper values for python.exe in PATH enviroment  Are you in same directory than blah.py. Check this by issuing command -> edit blah.py and check if you can open this file  EDIT:  In that case you can not. (python arg means that you call python.exe whit some parameters which python assume that is filename of script you want to run)  You can create bat file whit lines in your path map and run .bat file  Example: In one of Path maps create blah.py.bat Edit file and put line  python C:\\Somedir\\blah.py   You can now run blah.py from anywere, becuase you do not need to put .bat extention when running bat files     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  Found an incredibly useful answer here: How to run different python versions in cmd?     I would suggest using the Python Launcher for Windows utility that introduced was into Python 3.3 a while ago. You can also manually download and install it directly from the author's website for use with earlier versions of Python 2 and 3.      Regardless of how you obtain it, after installation it will have associated itself with all the standard Python file extensions (i.e. .py, .pyw, .pyc, and .pyo files). You'll not only be able to explicitly control which version is used at the command-prompt, but also on a script-by-script basis by adding Linux/Unix-y shebang #!/usr/bin/env pythonX comments at the beginning of your Python scripts.   As J.F. Sebastian suggests, Python Launcher for Windows is the best and default choice for launching different version of Python in Windows. It used to be a third-party tool, but now it is officially supported since Python 3.3.     New in version 3.3.      The Python launcher for Windows is a utility which aids in the location and execution of different Python versions. It allows scripts (or the command-line) to indicate a preference for a specific Python version, and will locate and execute that version.   This is a great tool just use it!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  If that's what I understood, it's like this:  C:\\Users\\(username)\\AppData\\Local\\Programs\\Python\\Python(version)   COPY (not delete) python.exe and rename to py.exe and execute:  py filename.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to execute Python scripts in Windows?",
        "A_Content": "  Simply run the command:  C:>python .\\file_name.py   Assuming the file name is within same folder and Python has already been added to environment variables.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "scripting",
            "command-line",
            "file-association"
        ],
        "URL": "https://stackoverflow.com/questions/1934675/how-to-execute-python-scripts-in-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a simple script blah.py (using Python 2):  import sys print sys.argv[1]   If I execute my script by:  python c:/..../blah.py argument   It prints argument but if I execute script by:  blah.py argument   error occurs:     IndexError...   So arguments do not pass to script.  python.exe in PATH. Folder with blah.py also in PATH. python.exe is default program to execute *.py files.  What is the problem?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  You can use datetime's strftime function to get this. The problem is that time's strftime accepts a timetuple that does not carry microsecond information.  from datetime import datetime datetime.now().strftime(\"%H:%M:%S.%f\")   Should do the trick!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  You are looking at the wrong documentation. The time module has different documentation.   You can use the datetime module strftime like this:  >>> from datetime import datetime >>> >>> now = datetime.now() >>> now.strftime(\"%H:%M:%S.%f\") '12:19:40.948000'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  You can also get microsecond precision from the time module using its time() function. (time.time() returns the time in seconds since epoch. Its fractional part is the time in microseconds, which is what you want.)  >>> from time import time >>> time() ... 1310554308.287459   # the fractional part is what you want.   # comparision with strftime - >>> from datetime import datetime >>> from time import time >>> datetime.now().strftime(\"%f\"), time() ... ('287389', 1310554310.287459)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  This should do the work  import datetime datetime.datetime.now().strftime(\"%H:%M:%S.%f\")   It will print   HH:MM:SS.microseconds like this e.g 14:38:19.425961     ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  When the \"%f\" for micro seconds isn't working please use the following method  import datetime  def getTimeStamp():     dt = datetime.datetime.now()     return dt.strftime(\"%Y%j%H%M%S\") + str(dt.microsecond)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Using %f with strftime() in Python to get microseconds",
        "A_Content": "  With python time module you can't get microseconds with %f.  For those who still want to go with time module only, here is a workaround:  now = time.time() mlsec = repr(now).split('.')[1][:3] print time.strftime(\"%Y-%m-%d %H:%M:%S.{} %Z\".format(mlsec), time.localtime(now))   You should get something like 2017-01-16 16:42:34.625 EET (yes, I use miliseconds as it's fairly enough).  To brake the code into details, paste below code into python console:  import time # get current timestamp now = time.time() # debug now now print now type(now) # debug strf time struct_now = time.localtime(now) print struct_now type(struct_now) # print nicely formatted date print time.strftime(\"%Y-%m-%d %H:%M:%S %Z\", struct_now) # get miliseconds mlsec = repr(now).split('.')[1][:3] print mlsec # get your required timestamp string timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S.{} %Z\".format(mlsec), struct_now) print timestamp   For clarification purposes, I also paste my python 2.7.12 result here:  >>> import time >>> # get current timestamp ... now = time.time() >>> # debug now ... now 1484578293.519106 >>> print now 1484578293.52 >>> type(now) <type 'float'> >>> # debug strf time ... struct_now = time.localtime(now) >>> print struct_now time.struct_time(tm_year=2017, tm_mon=1, tm_mday=16, tm_hour=16, tm_min=51, tm_sec=33, tm_wday=0, tm_yday=16, tm_isdst=0) >>> type(struct_now) <type 'time.struct_time'> >>> # print nicely formatted date ... print time.strftime(\"%Y-%m-%d %H:%M:%S %Z\", struct_now) 2017-01-16 16:51:33 EET >>> # get miliseconds ... mlsec = repr(now).split('.')[1][:3] >>> print mlsec 519 >>> # get your required timestamp string ... timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S.{} %Z\".format(mlsec), struct_now) >>> print timestamp 2017-01-16 16:51:33.519 EET >>>   Hope it helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "strftime"
        ],
        "URL": "https://stackoverflow.com/questions/6677332/using-f-with-strftime-in-python-to-get-microseconds",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use strftime() to microsecond precision, which seems possible using %f (as stated here). However when I try the following code:  import time import strftime from time  print strftime(\"%H:%M:%S.%f\")   ...I get the hour, the minutes and the seconds, but %f prints as %f, with no sign of the microseconds. I'm running Python 2.6.5 on Ubuntu, so it should be fine and %f should be supported (it's supported for 2.6 and above, as far as I know.)     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I get the user agent with Flask?",
        "A_Content": "  from flask import request request.headers.get('User-Agent')   You can also use the request.user_agent object which contains the following attributes which are created based on the useragent string:   platform (windows, linux, macos, etc.) browser (chrome, firefox, msie, etc.) version language string (== request.headers.get('User-Agent'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
        "A_Votes": "144",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to get access to the user agent with Flask, but I either can't find the documentation on it, or it doesn't tell me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I get the user agent with Flask?",
        "A_Content": "  flask.request.user_agent.string      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to get access to the user agent with Flask, but I either can't find the documentation on it, or it doesn't tell me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I get the user agent with Flask?",
        "A_Content": "  If you use  request.headers.get('User-Agent')   you may get:    Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36  If you use  request.user_agent   you may get like this:   user_agent.platform: windows user_agent.browser: chrome user_agent.version: 45.0.2454.101 user_agent.language: None user_agent.string: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to get access to the user agent with Flask, but I either can't find the documentation on it, or it doesn't tell me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I get the user agent with Flask?",
        "A_Content": "  UA usually does not contain language. If you want to get the language set in browser, you may use   request.accept_languages   It'll give you list of languages. E.g.   LanguageAccept([('en-US', 1), ('en', 0.5)])   To access the first value, you may use  request.accept_languages[0][0]   which will result in string  'en-US'   Detailed information about 'accept_language\" header: https://www.w3.org/International/questions/qa-lang-priorities     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to get access to the user agent with Flask, but I either can't find the documentation on it, or it doesn't tell me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I get the user agent with Flask?",
        "A_Content": "  The question begs for a lot more information.  This library seems to fit the bill of collecting a lot of information out of flask, and has example calls to getting this information out of the application context.  https://pythonhosted.org/Flask-Track-Usage/  Usage gets stored in this format:  [     {             'url': str,             'user_agent': {                 'browser': str,                 'language': str,                 'platform': str,                 'version': str,             },             'blueprint': str,             'view_args': dict or None             'status': int,             'remote_addr': str,             'xforwardedfor': str,             'authorization': bool             'ip_info': str or None,             'path': str,             'speed': float,             'date': datetime,     },     {         ....     } ]   Here is one of the places in the library where the data is collected:  https://github.com/ashcrow/flask-track-usage/blob/master/src/flask_track_usage/init.py around line 158      data = {         'url': ctx.request.url,         'user_agent': ctx.request.user_agent,         'server_name': ctx.app.name,         'blueprint': ctx.request.blueprint,         'view_args': ctx.request.view_args,         'status': response.status_code,         'remote_addr': ctx.request.remote_addr,         'xforwardedfor': ctx.request.headers.get(             'X-Forwarded-For', None),         'authorization': bool(ctx.request.authorization),         'ip_info': None,         'path': ctx.request.path,         'speed': float(speed),         'date': int(time.mktime(current_time.timetuple())),         'content_length': response.content_length,         'request': \"{} {} {}\".format(             ctx.request.method,             ctx.request.url,             ctx.request.environ.get('SERVER_PROTOCOL')         ),         'url_args': dict(             [(k, ctx.request.args[k]) for k in ctx.request.args]         ),         'username': None,         'track_var': g.track_var     }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to get access to the user agent with Flask, but I either can't find the documentation on it, or it doesn't tell me.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  Activate the virtualenv, and then install BeautifulSoup4:  $ pip install BeautifulSoup4   When you installed bs4 with easy_install, you installed it system-wide. So your system python can import it, but not your virtualenv python. If you do not need bs4 to be installed in your system python path, uninstall it and keep it in your virtualenv.  For more information about virtualenvs, read this      ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  For python2.x:  sudo pip install BeautifulSoup4   For python3:  sudo apt-get install python3-bs4      ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  Just tagging onto Balthazar's answer. Running  pip install BeautifulSoup4   did not work for me. Instead use   pip install beautifulsoup4      ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  If you use Pycharm, go to preferences - project interpreter - install bs4. If you try to install BeautifulSoup, it will still show that no module named bs4.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  I was facing the same problem in my Linux Ubuntu when I used the following command for installing bs4 library:     pip install bs4   I will advise you to uninstall the bs4 library by using this command:     pip uninstall bs4   and then install it using this command:     sudo apt-get install python3-bs4      ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  If you are using Anaconda for package management, following should do:  conda install -c anaconda beautifulsoup4     ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "ImportError: No Module Named bs4 (BeautifulSoup)",
        "A_Content": "  The easiest is using easy_install.  easy_install bs4    It will work if pip fails.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "beautifulsoup",
            "flask",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/11783875/importerror-no-module-named-bs4-beautifulsoup",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working in Python and using Flask. When I run my main Python file on my computer, it works perfectly, but when I activate venv and run the Flask Python file in the terminal, it says that my main Python file has \"No Module Named bs4.\" Any comments or advice is greatly appreciated.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  I had exactly the same problem, and these two lines fixed the problem:  y_formatter = matplotlib.ticker.ScalarFormatter(useOffset=False) ax.yaxis.set_major_formatter(y_formatter)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "95",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  A much easier solution is to simply customize the tick labels. Take this example:  from pylab import *  # Generate some random data... x = linspace(55478, 55486, 100) y = random(100) - 0.5 y = cumsum(y) y -= y.min() y *= 1e-8  # plot plot(x,y)  # xticks locs,labels = xticks() xticks(locs, map(lambda x: \"%g\" % x, locs))  # ytikcs locs,labels = yticks() yticks(locs, map(lambda x: \"%.1f\" % x, locs*1e9)) ylabel('microseconds (1E-9)')  show()     Notice how in the y-axis case, I multiplied the values by 1e9 then mentioned that constant in the y-label    EDIT  Another option is to fake the exponent multiplier by manually adding its text to the top of the plot:  locs,labels = yticks() yticks(locs, map(lambda x: \"%.1f\" % x, locs*1e9)) text(0.0, 1.01, '1e-9', fontsize=10, transform = gca().transAxes)     EDIT2  Also you can format the x-axis offset value in the same manner:  locs,labels = xticks() xticks(locs, map(lambda x: \"%g\" % x, locs-min(locs))) text(0.92, -0.07, \"+%g\" % min(locs), fontsize=10, transform = gca().transAxes)        ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  You have to subclass ScalarFormatter to do what you need... _set_offset just adds a constant, you want to set ScalarFormatter.orderOfMagnitude. Unfortunately, manually setting orderOfMagnitude won't do anything, as it's reset when the ScalarFormatter instance is called to format the axis tick labels.  It shouldn't be this complicated, but I can't find an easier way to do exactly what you want...  Here's an example:  import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import ScalarFormatter, FormatStrFormatter  class FixedOrderFormatter(ScalarFormatter):     \"\"\"Formats axis ticks using scientific notation with a constant order of      magnitude\"\"\"     def __init__(self, order_of_mag=0, useOffset=True, useMathText=False):         self._order_of_mag = order_of_mag         ScalarFormatter.__init__(self, useOffset=useOffset,                                   useMathText=useMathText)     def _set_orderOfMagnitude(self, range):         \"\"\"Over-riding this to avoid having orderOfMagnitude reset elsewhere\"\"\"         self.orderOfMagnitude = self._order_of_mag  # Generate some random data... x = np.linspace(55478, 55486, 100)  y = np.random.random(100) - 0.5 y = np.cumsum(y) y -= y.min() y *= 1e-8  # Plot the data... fig = plt.figure() ax = fig.add_subplot(111) ax.plot(x, y, 'b-')  # Force the y-axis ticks to use 1e-9 as a base exponent  ax.yaxis.set_major_formatter(FixedOrderFormatter(-9))  # Make the x-axis ticks formatted to 0 decimal places ax.xaxis.set_major_formatter(FormatStrFormatter('%0.0f')) plt.show()   Which yields something like:   Whereas, the default formatting would look like:   Hope that helps a bit!  Edit: For what it's worth, I don't know where the offset label resides either... It would be  slightly easier to just manually set it, but I couldn't figure out how to do so...  I get the feeling that there has to be an easier way than all of this.  It works, though!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  Similar to Amro's answer, you can use FuncFormatter  import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import FuncFormatter  # Generate some random data... x = np.linspace(55478, 55486, 100)  y = np.random.random(100) - 0.5 y = np.cumsum(y) y -= y.min() y *= 1e-8  # Plot the data... fig = plt.figure() ax = fig.add_subplot(111) ax.plot(x, y, 'b-')  # Force the y-axis ticks to use 1e-9 as a base exponent  ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: ('%.1f')%(x*1e9))) ax.set_ylabel('microseconds (1E-9)')  # Make the x-axis ticks formatted to 0 decimal places ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: '%.0f'%x)) plt.show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  I think that a more elegant way is to use the ticker formatter. Here is an example for both xaxis and yaxis:  from pylab import * from matplotlib.ticker import MultipleLocator, FormatStrFormatter  majorLocator   = MultipleLocator(20) xFormatter = FormatStrFormatter('%d') yFormatter = FormatStrFormatter('%.2f') minorLocator   = MultipleLocator(5)   t = arange(0.0, 100.0, 0.1) s = sin(0.1*pi*t)*exp(-t*0.01)  ax = subplot(111) plot(t,s)  ax.xaxis.set_major_locator(majorLocator) ax.xaxis.set_major_formatter(xFormatter) ax.yaxis.set_major_formatter(yFormatter)  #for the minor ticks, use no labels; default NullFormatter ax.xaxis.set_minor_locator(minorLocator)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  Gonzalo's solution started working for me after having added set_scientific(False):  ax=gca() fmt=matplotlib.ticker.ScalarFormatter(useOffset=False) fmt.set_scientific(False) ax.xaxis.set_major_formatter(fmt)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  As has been pointed out in the comments and in this answer, the offset may be switched off globally, by doing the following:  matplotlib.rcParams['axes.formatter.useoffset'] = False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "matplotlib: format axis offset-values to whole numbers or specific number",
        "A_Content": "  For the second part, without manually resetting all the ticks again, this was my solution:  class CustomScalarFormatter(ScalarFormatter):     def format_data(self, value):         if self._useLocale:             s = locale.format_string('%1.2g', (value,))         else:             s = '%1.2g' % value         s = self._formatSciNotation(s)         return self.fix_minus(s) xmajorformatter = CustomScalarFormatter()  # default useOffset=True axes.get_xaxis().set_major_formatter(xmajorformatter)   obviously you can set the format string to whatever you want.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/3677368/matplotlib-format-axis-offset-values-to-whole-numbers-or-specific-number",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a matplotlib figure which I am plotting data that is always referred to as nanoseconds (1e-9).  On the y-axis, if I have data that is tens of nanoseconds, ie. 44e-9, the value on the axis shows as 4.4 with a +1e-8 as an offset.  Is there anyway to force the axis to show 44 with a +1e-9 offset?  The same goes for my x-axis where the axis is showing +5.54478e4, where I would rather it show an offset of +55447 (whole number, no decimal - the value here is in days).  I've tried a couple things like this:  p = axes.plot(x,y) p.ticklabel_format(style='plain')   for the x-axis, but this doesn't work, though I'm probably using it incorrectly or misinterpreting something from the docs, can someone point me in the correct direction?  Thanks, Jonathan      I tried doing something with formatters but haven't found any solution yet...:  myyfmt = ScalarFormatter(useOffset=True) myyfmt._set_offset(1e9) axes.get_yaxis().set_major_formatter(myyfmt)   and  myxfmt = ScalarFormatter(useOffset=True) myxfmt.set_portlimits((-9,5)) axes.get_xaxis().set_major_formatter(myxfmt)   On a side note, I'm actually confused as to where the 'offset number' object actually resides...is it part of the major/minor ticks?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  Not currently, currently the only languages available to access the iPhone SDK are C/C++, Objective C and Swift.  There is no technical reason why this could not change in the future but I wouldn't hold your breath for this happening in the short term.  That said, Objective-C and Swift really are not too scary...     2016 edit      Javascript with NativeScript framework is available to use now.      ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  You can use PyObjC on the iPhone as well, due to the excellent work by Jay Freeman (saurik). See iPhone Applications in Python.  Note that this requires a jailbroken iPhone at the moment.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  Yes you can. You write your code in tinypy (which is restricted Python), then use tinypy to convert it to C++, and finally compile this with XCode into a native iPhone app. Phil Hassey has published a game called Elephants! using this approach. Here are more details,  http://www.philhassey.com/blog/2009/12/23/elephants-is-free-on-the-app-store/     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  It seems this is now something developers are allowed to do: the iOS Developer Agreement was changed yesterday and appears to have been ammended in a such a way as to make embedding a Python interpretter in your application legal:  SECTION 3.3.2 — INTERPRETERS  Old:     3.3.2 An Application may not itself install or launch other executable   code by any means, including without   limitation through the use of a   plug-in architecture, calling other   frameworks, other APIs or otherwise.   Unless otherwise approved by Apple in   writing, no interpreted code may be   downloaded or used in an Application   except for code that is interpreted   and run by Apple’s Documented APIs and   built-in interpreter(s).   Notwithstanding the foregoing, with   Apple’s prior written consent, an   Application may use embedded   interpreted code in a limited way if   such use is solely for providing minor   features or functionality that are   consistent with the intended and   advertised purpose of the Application.   New:     3.3.2 An Application may not download or install executable code.   Interpreted code may only be used in   an Application if all scripts, code   and interpreters are packaged in the   Application and not downloaded. The   only exception to the foregoing is   scripts and code downloaded and run by   Apple’s built-in WebKit framework.      ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  An update to the iOS Developer Agreement means that you can use whatever you like, as long as you meet the developer guidelines. Section 3.3.1, which restricted what developers could use for iOS development, has been entirely removed.  Source: http://daringfireball.net/2010/09/app_store_guidelines     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  Yes, nowadays you can develop apps for iOS in Python.   There are two frameworks that you may want to checkout: Kivy and PyMob.  Please consider the answers to this question too, as they are more up-to-date than this one.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  Pythonista has an Export to Xcode feature that allows you to export your Python scripts as Xcode projects that build standalone iOS apps.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  The iPhone SDK agreement is also rather vague  about whether you're even allowed to run scripting languages (outside of a WebView's Javascript). My reading is that it is OK - as long as none of the scripts you execute are downloaded from the network (so pre-installed and user-edited scripts seem to be OK).  IANAL etc etc.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  Technically, as long as the interpreted code ISN'T downloaded (excluding JavaScript), the app may be approved. Rhomobiles \"Rhodes\" framework does just that, bundling mobile Ruby, a lightweight version of Rails, and your app for distribution via the app-store. Because both the interpreter and the interpreted code are packaged into the final application - Apple doesn't find it objectionable.   http://rhomobile.com/products/rhodes/  Even after the latest apple press release - rhodes apps (mobile ruby) are still viable on the app-store. I'd find it hard to believe that tinyPy or pyObjC wouldn't find a place if there is a willing developer community.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  You can do this with PyObjC, with a jailbroken phone of course. But if you want to get it into the App Store, they will not allow it because it \"interprets code.\" However, you may be able to use Shed Skin, although I'm not aware of anyone doing this. I can't think of any good reason to do this though, as you lose dynamic typing, and might as well use ObjC.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  I think it was not possible earlier but I recently heard about PyMob, which seems interesting because the apps are written in Python and the final outputs are native source codes in various platforms (Obj-C for iOS, Java for Android etc). This is certainly quite unique. This webpage explains it in more detail.  I haven't given it a shot yet, but will take a look soon.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Can I write native iPhone apps using Python",
        "A_Content": "  The only significant \"external\" language for iPhone development that I'm aware of with semi-significant support in terms of frameworks and compatibility is MonoTouch, a C#/.NET environment for developing on the iPhone.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "cocoa-touch"
        ],
        "URL": "https://stackoverflow.com/questions/43315/can-i-write-native-iphone-apps-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using PyObjC, you can use Python to write Cocoa applications for OS X. Can I write native iPhone apps using Python and if so, how?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  The error shows that the machine does not have enough memory to read the entire CSV into a DataFrame at one time. Assuming you do not need the entire dataset in memory all at one time, one way to avoid the problem would be to process the CSV in chunks (by specifying the chunksize parameter):  chunksize = 10 ** 6 for chunk in pd.read_csv(filename, chunksize=chunksize):     process(chunk)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  I proceeded like this:  chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\\        names=['lat','long','rf','date','slno'],index_col='slno',\\        header=None,parse_dates=['date'])  df=pd.DataFrame() %time df=pd.concat(chunk.groupby(['lat','long',chunk['date'].map(lambda x: x.year)])['rf'].agg(['sum']) for chunk in chunks)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  Chunking shouldn't always be the first port of call for this problem.  1. Is the file large due to repeated non-numeric data or unwanted columns?    If so, you can sometimes see massive memory savings by reading in columns as categories and selecting required columns via pd.read_csv usecols parameter.  2. Does your workflow require slicing, manipulating, exporting?  If so, you can use dask.dataframe to slice, perform your calculations and export iteratively. Chunking is performed silently by dask, which also supports a subset of pandas API.  3. If all else fails, read line by line via chunks.  Chunk via pandas or via csv library as a last resort.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  For large data l recommend you use the library \"dask\"  e.g:   # Dataframes implement the Pandas API import dask.dataframe as dd df = dd.read_csv('s3://.../2018-*-*.csv')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  The above answer is already satisfying the topic. Anyway, if you need all the data in memory - have a look at bcolz. Its compressing the data in memory. I have had really good experience with it. But its missing a lot of pandas features  Edit: I got compression rates at around 1/10 or orig size i think, of course depending of the kind of data. Important features missing were aggregates.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  You can try sframe, that have the same syntax as pandas but allows you to manipulate files that are bigger than your RAM.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  The function read_csv and read_table is almost the same. But you must assign the delimiter “，” when you use the function read_table in your program.  def get_from_action_data(fname, chunk_size=100000):     reader = pd.read_csv(fname, header=0, iterator=True)     chunks = []     loop = True     while loop:         try:             chunk = reader.get_chunk(chunk_size)[[\"user_id\", \"type\"]]             chunks.append(chunk)         except StopIteration:             loop = False             print(\"Iteration is stopped\")      df_ac = pd.concat(chunks, ignore_index=True)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to read a 6 GB csv file with pandas",
        "A_Content": "  If you use pandas read large file into chunk and then yield row by row, here is what I have done  import pandas as pd  def chunck_generator(filename, header=False,chunk_size = 10 ** 5):    for chunk in pd.read_csv(filename,delimiter=',', iterator=True, chunksize=chunk_size, parse_dates=[1] ):          yield (chunk)  def _generator( filename, header=False,chunk_size = 10 ** 5):     chunk = chunck_generator(filename, header=False,chunk_size = 10 ** 5)     for row in chunk:         yield row  if __name__ == \"__main__\": filename = r'file.csv'         generator = generator(filename=filename)         while True:            print(next(generator))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "csv",
            "memory",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/25962114/how-to-read-a-6-gb-csv-file-with-pandas",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to read a large csv file (aprox. 6 GB) in pandas and i am getting the following memory error:  MemoryError                               Traceback (most recent call last) <ipython-input-58-67a72687871b> in <module>() ----> 1 data=pd.read_csv('aphro.csv',sep=';')  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)     450                     infer_datetime_format=infer_datetime_format)     451  --> 452         return _read(filepath_or_buffer, kwds)     453      454     parser_f.__name__ = name  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in _read(filepath_or_buffer, kwds)     242         return parser     243  --> 244     return parser.read()     245      246 _parser_defaults = {  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)     693                 raise ValueError('skip_footer not supported for iteration')     694  --> 695         ret = self._engine.read(nrows)     696      697         if self.options.get('as_recarray'):  C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.pyc in read(self, nrows)    1137     1138         try: -> 1139             data = self._reader.read(nrows)    1140         except StopIteration:    1141             if nrows is None:  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader.read (pandas\\parser.c:7145)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:7369)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._read_rows (pandas\\parser.c:8194)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:9402)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:10057)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10361)()  C:\\Python27\\lib\\site-packages\\pandas\\parser.pyd in pandas.parser._try_int64 (pandas\\parser.c:17806)()  MemoryError:    Any help on this??      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Define a lambda expression that raises an Exception",
        "A_Content": "  UPDATE 2: I was wrong! It turns out there's more than one way to skin a Python:  y = lambda: (_ for _ in ()).throw(Exception('foobar'))     No. Lambdas only accept expressions. raise ex is a statement. Of course, you could write a general purpose raiser:  def raise_(ex):     raise ex  y = lambda: raise_(Exception('foobar'))   But if your goal is to avoid a def, this obviously doesn't cut it. It does, however allow you to conditionally raise exceptions, e.g.:  y = lambda x: 2*x if x < 10 else raise_(Exception('foobar'))     UPDATE: OK, so you can raise an exception without defining a named function. All you need is a strong stomach (and 2.x for the given code):  type(lambda:0)(type((lambda:0).func_code)(   1,1,1,67,'|\\0\\0\\202\\1\\0',(),(),('x',),'','',1,''),{} )(Exception())   UPDATE 3: And a python3 strong stomach solution:  type(lambda: 0)(type((lambda: 0).__code__)(     1,0,1,1,67,b'|\\0\\202\\1\\0',(),(),('x',),'','',1,b''),{} )(Exception())   UPDATE 4: Thanks @WarrenSpencer for pointing out a very simple answer if you don't care which exception is raised: y = lambda: 1/0.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I write a lambda expression that's equivalent to:  def x():     raise Exception()   The following is not allowed:  y = lambda : raise Exception()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Define a lambda expression that raises an Exception",
        "A_Content": "  How about:  lambda x: exec('raise(Exception(x))')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I write a lambda expression that's equivalent to:  def x():     raise Exception()   The following is not allowed:  y = lambda : raise Exception()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Define a lambda expression that raises an Exception",
        "A_Content": "  Actually, there is a way, but it's very contrived.  You can create a code object using the compile() built-in function.  This allows you to use the raise statement (or any other statement, for that matter), but it raises another challenge: executing the code object.  The usual way would be to use the exec statement, but that leads you back to the original problem, namely that you can't execute statements in a lambda (or an eval(), for that matter).  The solution is a hack.  Callables like the result of a lambda statement all have an attribute __code__, which can actually be replaced.  So, if you create a callable and replace it's __code__ value with the code object from above, you get something that can be evaluated without using statements.  Achieving all this, though, results in very obscure code:  map(lambda x, y, z: x.__setattr__(y, z) or x, [lambda: 0], [\"__code__\"], [compile(\"raise Exception\", \"\", \"single\"])[0]()  The above does the following:   the compile() call creates a code object that raises the exception; the lambda: 0 returns a callable that does nothing but return the value 0 -- this is used to execute the above code object later; the lambda x, y, z creates a function that calls the __setattr__ method of the first argument with the remaining arguments, AND RETURNS THE FIRST ARGUMENT!  This is necessary, because __setattr__ itself returns None; the map() call takes the result of lambda: 0, and using the lambda x, y, z replaces it's __code__ object with the result of the compile() call.  The result of this map operation is a list with one entry, the one returned by lambda x, y, z, which is why we need this lambda: if we would use __setattr__ right away, we would lose the reference to the lambda: 0 object! finally, the first (and only) element of the list returned by the map() call is executed, resulting in the code object being called, ultimately raising the desired exception.   It works (tested in Python 2.6), but it's definitely not pretty.  One last note: if you have access to the types module (which would require to use the import statement before your eval), then you can shorten this code down a bit: using types.FunctionType() you can create a function that will execute the given code object, so you won't need the hack of creating a dummy function with lambda: 0 and replacing the value of its __code__ attribute.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I write a lambda expression that's equivalent to:  def x():     raise Exception()   The following is not allowed:  y = lambda : raise Exception()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Define a lambda expression that raises an Exception",
        "A_Content": "  Functions created with lambda forms cannot contain statements.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I write a lambda expression that's equivalent to:  def x():     raise Exception()   The following is not allowed:  y = lambda : raise Exception()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Define a lambda expression that raises an Exception",
        "A_Content": "  If all you want is a lambda expression that raises an arbitrary exception, you can accomplish this with an illegal expression. For instance, lambda x: [][0] will attempt to access the first element in an empty list, which will raise an IndexError.  PLEASE NOTE: This is a hack, not a feature. Do not use this is any (non code-golf) code that another human being might see or use.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I write a lambda expression that's equivalent to:  def x():     raise Exception()   The following is not allowed:  y = lambda : raise Exception()      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Select between two dates with Django",
        "A_Content": "  Use the __range operator:  ...filter(current_issue__isnull=True, created_at__range=(start_date, end_date))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/3963201/select-between-two-dates-with-django",
        "A_Votes": "181",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am looking to make a query that selects between dates with Django.  I know how to do this with raw SQL pretty easily, but how could this be achieved using the Django ORM?  This is where I want to add the between dates of 30 days in my query:  start_date = datetime.datetime.now() + datetime.timedelta(-30) context[self.varname] = self.model._default_manager.filter(     current_issue__isnull=True     ).live().order_by('-created_at')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Select between two dates with Django",
        "A_Content": "  __range     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/3963201/select-between-two-dates-with-django",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking to make a query that selects between dates with Django.  I know how to do this with raw SQL pretty easily, but how could this be achieved using the Django ORM?  This is where I want to add the between dates of 30 days in my query:  start_date = datetime.datetime.now() + datetime.timedelta(-30) context[self.varname] = self.model._default_manager.filter(     current_issue__isnull=True     ).live().order_by('-created_at')      ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "python getting a list of value from list of dict",
        "A_Content": "  Assuming every dict has a value key, you can write (assuming your list is named l)  [d['value'] for d in l]   If value might be missing, you can use  [d['value'] for d in l if 'value' in d]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7271482/python-getting-a-list-of-value-from-list-of-dict",
        "A_Votes": "166",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list of dict like this:  [{'value': 'apple', 'blah': 2}, {'value': 'banana', 'blah': 3} , {'value': 'cars', 'blah':4}]   I want ['apple', 'banana', 'cars']  Whats the best way to do this?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "python getting a list of value from list of dict",
        "A_Content": "  Here's another way to do it using map() and lambda functions:  >>> map(lambda d: d['value'], l)   where l is the list. I see this way \"sexiest\", but I would do it using the list comprehension.  Update: In case that 'value' might be missing as a key use:  >>> map(lambda d: d.get('value', 'default value'), l)   Update: I'm also not a big fan of lambdas, I prefer to name things... this is how I would do it with that in mind:  >>> import operator >>> map(operator.itemgetter('value'), l)   I would even go further and create a sole function that explicitly says what I want to achieve:  >>> import operator, functools >>> get_values = functools.partial(map, operator.itemgetter('value')) >>> get_values(l) ... [<list of values>]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7271482/python-getting-a-list-of-value-from-list-of-dict",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dict like this:  [{'value': 'apple', 'blah': 2}, {'value': 'banana', 'blah': 3} , {'value': 'cars', 'blah':4}]   I want ['apple', 'banana', 'cars']  Whats the best way to do this?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "python getting a list of value from list of dict",
        "A_Content": "  [x['value'] for x in list_of_dicts]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7271482/python-getting-a-list-of-value-from-list-of-dict",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dict like this:  [{'value': 'apple', 'blah': 2}, {'value': 'banana', 'blah': 3} , {'value': 'cars', 'blah':4}]   I want ['apple', 'banana', 'cars']  Whats the best way to do this?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "python getting a list of value from list of dict",
        "A_Content": "  For a very simple case like this, a comprehension, as in Ismail Badawi's answer is definitely the way to go.  But when things get more complicated, and you need to start writing multi-clause or nested comprehensions with complex expressions in them, it's worth looking into other alternatives. There are a few different (quasi-)standard ways to specify XPath-style searches on nested dict-and-list structures, such as JSONPath, DPath, and KVC. And there are nice libraries on PyPI for them.  Here's an example with the library named dpath, showing how it can simplify something just a bit more complicated:  >>> dd = { ...     'fruits': [{'value': 'apple', 'blah': 2}, {'value': 'banana', 'blah': 3}], ...     'vehicles': [{'value': 'cars', 'blah':4}]}  >>> {key: [{'value': d['value']} for d in value] for key, value in dd.items()} {'fruits': [{'value': 'apple'}, {'value': 'banana'}],  'vehicles': [{'value': 'cars'}]}  >>> dpath.util.search(dd, '*/*/value') {'fruits': [{'value': 'apple'}, {'value': 'banana'}],  'vehicles': [{'value': 'cars'}]}   Or, using jsonpath-ng:  >>> [d['value'] for key, value in dd.items() for d in value] ['apple', 'banana', 'cars'] >>> [m.value for m in jsonpath_ng.parse('*.[*].value').find(dd)] ['apple', 'banana', 'cars']   This one may not look quite as simple at first glance, because find returns match objects, which include all kinds of things besides just the matched value, such as a path directly to each item. But for more complex expressions, being able to specify a path like '*.[*].value' instead of a comprehension clause for each * can make a big difference. Plus, JSONPath is a language-agnostic specification, and there are even online testers that can be very handy for debugging.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7271482/python-getting-a-list-of-value-from-list-of-dict",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dict like this:  [{'value': 'apple', 'blah': 2}, {'value': 'banana', 'blah': 3} , {'value': 'cars', 'blah':4}]   I want ['apple', 'banana', 'cars']  Whats the best way to do this?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "gunicorn autoreload on source change",
        "A_Content": "  While this is old question, just for consistency - since version 19.0 gunicorn has --reload option. So no third party tools needed more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "reload",
            "gunicorn"
        ],
        "URL": "https://stackoverflow.com/questions/12773763/gunicorn-autoreload-on-source-change",
        "A_Votes": "169",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Finally I migrated my development env from runserver to gunicorn/nginx.  It'd be convenient to replicate the autoreload feature of runserver to gunicorn, so the server automatically restarts when source changes. Otherwise I have to restart the server manually with kill -HUP.  Any way to avoid the manual restart?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "gunicorn autoreload on source change",
        "A_Content": "  One option would be to use the --max-requests to limit each spawned process to serving only one request by adding --max-requests 1 to the startup options. Every newly spawned process should see your code changes and in a development environment the extra startup time per request should be negligible.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "reload",
            "gunicorn"
        ],
        "URL": "https://stackoverflow.com/questions/12773763/gunicorn-autoreload-on-source-change",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Finally I migrated my development env from runserver to gunicorn/nginx.  It'd be convenient to replicate the autoreload feature of runserver to gunicorn, so the server automatically restarts when source changes. Otherwise I have to restart the server manually with kill -HUP.  Any way to avoid the manual restart?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "gunicorn autoreload on source change",
        "A_Content": "  Bryan Helmig came up with this and I modified it to use run_gunicorn instead of launching gunicorn directly, to make it possible to just cut and paste these 3 commands into a shell in your django project root folder (with your virtualenv activated):  pip install watchdog -U watchmedo shell-command --patterns=\"*.py;*.html;*.css;*.js\" --recursive --command='echo \"${watch_src_path}\" && kill -HUP `cat gunicorn.pid`' . & python manage.py run_gunicorn 127.0.0.1:80 --pid=gunicorn.pid      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "reload",
            "gunicorn"
        ],
        "URL": "https://stackoverflow.com/questions/12773763/gunicorn-autoreload-on-source-change",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Finally I migrated my development env from runserver to gunicorn/nginx.  It'd be convenient to replicate the autoreload feature of runserver to gunicorn, so the server automatically restarts when source changes. Otherwise I have to restart the server manually with kill -HUP.  Any way to avoid the manual restart?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "gunicorn autoreload on source change",
        "A_Content": "  I use git push to deploy to production and set up git hooks to run a script.  The advantage of this approach is you can also do your migration and package installation at the same time.  https://mikeeverhart.net/2013/01/using-git-to-deploy-code/  mkdir -p /home/git/project_name.git cd /home/git/project_name.git git init --bare   Then create a script /home/git/project_name.git/hooks/post-receive.    #!/bin/bash GIT_WORK_TREE=/path/to/project git checkout -f source /path/to/virtualenv/activate pip install -r /path/to/project/requirements.txt python /path/to/project/manage.py migrate sudo supervisorctl restart project_name   Make sure to chmod u+x post-receive, and add user to sudoers.  Allow it to run sudo supervisorctl without password.  https://www.cyberciti.biz/faq/linux-unix-running-sudo-command-without-a-password/  From my local / development server, I set up git remote that allows me to push to the production server  git remote add production ssh://user_name@production-server/home/git/project_name.git  # initial push git push production +master:refs/heads/master  # subsequent push git push production master   As a bonus, you will get to see all the prompts as the script is running.  So you will see if there is any issue with the migration/package installation/supervisor restart.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "reload",
            "gunicorn"
        ],
        "URL": "https://stackoverflow.com/questions/12773763/gunicorn-autoreload-on-source-change",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Finally I migrated my development env from runserver to gunicorn/nginx.  It'd be convenient to replicate the autoreload feature of runserver to gunicorn, so the server automatically restarts when source changes. Otherwise I have to restart the server manually with kill -HUP.  Any way to avoid the manual restart?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why are trailing commas allowed in a list?",
        "A_Content": "  The main advantages are that it makes multi-line lists easier to edit and that it reduces clutter in diffs.  Changing:  s = ['manny',      'mo',      'jack', ]   to:  s = ['manny',      'mo',      'jack',      'roger', ]   involves only a one-line change in the diff:    s = ['manny',        'mo',        'jack', +      'roger',   ]   This beats the more confusing multi-line diff when the trailing comma was omitted:    s = ['manny',        'mo', -      'jack' +      'jack', +      'roger'   ]   The latter diff makes it harder to see that only one line was added and that the other line didn't change content.  It also reduces the risk of doing this:  s = ['manny',      'mo',      'jack'      'roger'  # Added this line, but forgot to add a comma on the previous line ]   and triggering implicit string literal concatenation, producing s = ['manny', 'mo', 'jackroger'] instead of the intended result.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "syntax",
            "comma",
            "trailing"
        ],
        "URL": "https://stackoverflow.com/questions/11597901/why-are-trailing-commas-allowed-in-a-list",
        "A_Votes": "144",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am curious why in Python a trailing comma in a list is valid syntax, and it seems that Python simply ignores it:  >>> ['a','b',] ['a', 'b']   It makes sense when its a tuple since ('a') and ('a',) are two different things, but in lists?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why are trailing commas allowed in a list?",
        "A_Content": "  It's a common syntactical convention to allow trailing commas in an array, languages like C and Java allow it, and Python seems to have adopted this convention for its list data structure. It's particularly useful when generating code for populating a list: just generate a sequence of elements and commas, no need to consider the last one as a special case that shouldn't have a comma at the end.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "syntax",
            "comma",
            "trailing"
        ],
        "URL": "https://stackoverflow.com/questions/11597901/why-are-trailing-commas-allowed-in-a-list",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am curious why in Python a trailing comma in a list is valid syntax, and it seems that Python simply ignores it:  >>> ['a','b',] ['a', 'b']   It makes sense when its a tuple since ('a') and ('a',) are two different things, but in lists?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why are trailing commas allowed in a list?",
        "A_Content": "  It helps to eliminate a certain kind of bug. It's sometimes clearer to write lists on multiple lines. But in, later maintenace you may want to rearrange the items.  l1 = [         1,         2,         3,         4,         5 ]  # Now you want to rearrange  l1 = [         1,         2,         3,         5         4, ]  # Now you have an error   But if you allow trailing commas, and use them, you can easily rearrange the lines without introducing an error.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "syntax",
            "comma",
            "trailing"
        ],
        "URL": "https://stackoverflow.com/questions/11597901/why-are-trailing-commas-allowed-in-a-list",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am curious why in Python a trailing comma in a list is valid syntax, and it seems that Python simply ignores it:  >>> ['a','b',] ['a', 'b']   It makes sense when its a tuple since ('a') and ('a',) are two different things, but in lists?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why are trailing commas allowed in a list?",
        "A_Content": "  A tuple is different because ('a') is expanded using implicit continuation and ()s as a precendence operator, whereas ('a',) refers to a length 1 tuple.  Your original example would have been tuple('a')     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "syntax",
            "comma",
            "trailing"
        ],
        "URL": "https://stackoverflow.com/questions/11597901/why-are-trailing-commas-allowed-in-a-list",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am curious why in Python a trailing comma in a list is valid syntax, and it seems that Python simply ignores it:  >>> ['a','b',] ['a', 'b']   It makes sense when its a tuple since ('a') and ('a',) are two different things, but in lists?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Why are trailing commas allowed in a list?",
        "A_Content": "  The main reason is to make diff less complicated. For example you have a list :  list = [     'a',     'b',     'c' ]   and you want to add another element to it. Then you will be end up doing this:  list = [     'a',     'b',     'c',     'd' ]   thus, diff will show that two lines have been changed, first adding ',' in line with 'c' and adding 'd' at last line.  So, python allows trailing ',' in last element of list, to prevent extra diff which can cause confusion.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "syntax",
            "comma",
            "trailing"
        ],
        "URL": "https://stackoverflow.com/questions/11597901/why-are-trailing-commas-allowed-in-a-list",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am curious why in Python a trailing comma in a list is valid syntax, and it seems that Python simply ignores it:  >>> ['a','b',] ['a', 'b']   It makes sense when its a tuple since ('a') and ('a',) are two different things, but in lists?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I detect if Python is running as a 64-bit application? [duplicate]",
        "A_Content": "  import platform platform.architecture()   From the Python docs:     Queries the given executable (defaults   to the Python interpreter binary) for   various architecture information.      Returns a tuple (bits, linkage) which   contain information about the bit   architecture and the linkage format   used for the executable. Both values   are returned as strings.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "64bit"
        ],
        "URL": "https://stackoverflow.com/questions/1842544/how-do-i-detect-if-python-is-running-as-a-64-bit-application",
        "A_Votes": "146",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "       Possible Duplicate:   How do I determine if my python shell is executing in 32bit or 64bit mode?       I'm doing some work with the windows registry. Depending on whether you're running python as 32-bit or 64-bit, the key value will be different. How do I detect if Python is running as a 64-bit application as opposed to a 32-bit application?  Note: I'm not interested in detecting 32-bit/64-bit Windows - just the Python platform.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How do I detect if Python is running as a 64-bit application? [duplicate]",
        "A_Content": "  While it may work on some platforms, be aware that platform.architecture is not always a reliable way to determine whether python is running in 32-bit or 64-bit.  In particular, on some OS X multi-architecture builds, the same executable file may be capable of running in either mode, as the example below demonstrates.  The quickest safe multi-platform approach is to test sys.maxsize on Python 2.6, 2.7, Python 3.x.  $ arch -i386 /usr/local/bin/python2.7 Python 2.7.9 (v2.7.9:648dcafa7e5f, Dec 10 2014, 10:10:46) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import platform, sys >>> platform.architecture(), sys.maxsize (('64bit', ''), 2147483647) >>> ^D $ arch -x86_64 /usr/local/bin/python2.7 Python 2.7.9 (v2.7.9:648dcafa7e5f, Dec 10 2014, 10:10:46) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import platform, sys >>> platform.architecture(), sys.maxsize (('64bit', ''), 9223372036854775807)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "64bit"
        ],
        "URL": "https://stackoverflow.com/questions/1842544/how-do-i-detect-if-python-is-running-as-a-64-bit-application",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   How do I determine if my python shell is executing in 32bit or 64bit mode?       I'm doing some work with the windows registry. Depending on whether you're running python as 32-bit or 64-bit, the key value will be different. How do I detect if Python is running as a 64-bit application as opposed to a 32-bit application?  Note: I'm not interested in detecting 32-bit/64-bit Windows - just the Python platform.     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python: Fetch first 10 results from a list [duplicate]",
        "A_Content": "  list[:10]   will give you the first 10 elements of this list using slicing.  However, note, it's best not to use list as a variable identifier as it's already used by Python: list()  To find out more about these type of operations you might find this tutorial on lists helpful and the link @DarenThomas provided Explain Python's slice notation - thanks Daren)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10897339/python-fetch-first-10-results-from-a-list",
        "A_Votes": "178",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              How to take the first N items from a generator or list in Python? [duplicate]                                        8 answers                                          Is there a way we can fetch first 10 results from a list. Something like this maybe:  list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]  list.fetch(10)   ?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python: Fetch first 10 results from a list [duplicate]",
        "A_Content": "  check this        list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]   list[0:10]   Outputs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10897339/python-fetch-first-10-results-from-a-list",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to take the first N items from a generator or list in Python? [duplicate]                                        8 answers                                          Is there a way we can fetch first 10 results from a list. Something like this maybe:  list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]  list.fetch(10)   ?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python: Fetch first 10 results from a list [duplicate]",
        "A_Content": "  The itertools module has lots of great stuff in it. So if a standard slice (as used by Levon) does not do what you want, then try the islice function:  from itertools import islice l = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] iterator = islice(l, 10) for item in iterator:     print item      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10897339/python-fetch-first-10-results-from-a-list",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to take the first N items from a generator or list in Python? [duplicate]                                        8 answers                                          Is there a way we can fetch first 10 results from a list. Something like this maybe:  list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]  list.fetch(10)   ?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Python: Fetch first 10 results from a list [duplicate]",
        "A_Content": "  Use the slicing operator:  list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] list[:10]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10897339/python-fetch-first-10-results-from-a-list",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How to take the first N items from a generator or list in Python? [duplicate]                                        8 answers                                          Is there a way we can fetch first 10 results from a list. Something like this maybe:  list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]  list.fetch(10)   ?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  If you want to write it to disk so that it will be easy to read back in as a numpy array, look into numpy.save.  Pickling it will work fine, as well, but it's less efficient for large arrays (which yours isn't, so either is perfectly fine).  If you want it to be human readable, look into numpy.savetxt.  Edit:  So, it seems like savetxt isn't quite as great an option for arrays with >2 dimensions... But just to draw everything out to it's full conclusion:  I just realized that numpy.savetxt chokes on ndarrays with more than 2 dimensions... This is probably by design, as there's no inherently defined way to indicate additional dimensions in a text file.  E.g. This (a 2D array) works fine  import numpy as np x = np.arange(20).reshape((4,5)) np.savetxt('test.txt', x)   While the same thing would fail (with a rather uninformative error: TypeError: float argument required, not numpy.ndarray) for a 3D array:  import numpy as np x = np.arange(200).reshape((4,5,10)) np.savetxt('test.txt', x)   One workaround is just to break the 3D (or greater) array into 2D slices. E.g.  x = np.arange(200).reshape((4,5,10)) with file('test.txt', 'w') as outfile:     for slice_2d in x:         np.savetxt(outfile, slice_2d)   However, our goal is to be clearly human readable, while still being easily read back in with numpy.loadtxt. Therefore, we can be a bit more verbose, and differentiate the slices using commented out lines. By default, numpy.loadtxt will ignore any lines that start with # (or whichever character is specified by the comments kwarg).  (This looks more verbose than it actually is...)  import numpy as np  # Generate some test data data = np.arange(200).reshape((4,5,10))  # Write the array to disk with file('test.txt', 'w') as outfile:     # I'm writing a header here just for the sake of readability     # Any line starting with \"#\" will be ignored by numpy.loadtxt     outfile.write('# Array shape: {0}\\n'.format(data.shape))      # Iterating through a ndimensional array produces slices along     # the last axis. This is equivalent to data[i,:,:] in this case     for data_slice in data:          # The formatting string indicates that I'm writing out         # the values in left-justified columns 7 characters in width         # with 2 decimal places.           np.savetxt(outfile, data_slice, fmt='%-7.2f')          # Writing out a break to indicate different slices...         outfile.write('# New slice\\n')   This yields:  # Array shape: (4, 5, 10) 0.00    1.00    2.00    3.00    4.00    5.00    6.00    7.00    8.00    9.00    10.00   11.00   12.00   13.00   14.00   15.00   16.00   17.00   18.00   19.00   20.00   21.00   22.00   23.00   24.00   25.00   26.00   27.00   28.00   29.00   30.00   31.00   32.00   33.00   34.00   35.00   36.00   37.00   38.00   39.00   40.00   41.00   42.00   43.00   44.00   45.00   46.00   47.00   48.00   49.00   # New slice 50.00   51.00   52.00   53.00   54.00   55.00   56.00   57.00   58.00   59.00   60.00   61.00   62.00   63.00   64.00   65.00   66.00   67.00   68.00   69.00   70.00   71.00   72.00   73.00   74.00   75.00   76.00   77.00   78.00   79.00   80.00   81.00   82.00   83.00   84.00   85.00   86.00   87.00   88.00   89.00   90.00   91.00   92.00   93.00   94.00   95.00   96.00   97.00   98.00   99.00   # New slice 100.00  101.00  102.00  103.00  104.00  105.00  106.00  107.00  108.00  109.00  110.00  111.00  112.00  113.00  114.00  115.00  116.00  117.00  118.00  119.00  120.00  121.00  122.00  123.00  124.00  125.00  126.00  127.00  128.00  129.00  130.00  131.00  132.00  133.00  134.00  135.00  136.00  137.00  138.00  139.00  140.00  141.00  142.00  143.00  144.00  145.00  146.00  147.00  148.00  149.00  # New slice 150.00  151.00  152.00  153.00  154.00  155.00  156.00  157.00  158.00  159.00  160.00  161.00  162.00  163.00  164.00  165.00  166.00  167.00  168.00  169.00  170.00  171.00  172.00  173.00  174.00  175.00  176.00  177.00  178.00  179.00  180.00  181.00  182.00  183.00  184.00  185.00  186.00  187.00  188.00  189.00  190.00  191.00  192.00  193.00  194.00  195.00  196.00  197.00  198.00  199.00  # New slice   Reading it back in is very easy, as long as we know the shape of the original array. We can just do numpy.loadtxt('test.txt').reshape((4,5,10)).  As an example (You can do this in one line, I'm just being verbose to clarify things):  # Read the array from disk new_data = np.loadtxt('test.txt')  # Note that this returned a 2D array! print new_data.shape  # However, going back to 3D is easy if we know the  # original shape of the array new_data = new_data.reshape((4,5,10))  # Just to check that they're the same... assert np.all(new_data == data)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  I'm not certain if this meets your requirements, given I think you're interested in making the file readable by people, but if that's not a primary concern, just pickle it.  To save it:  import pickle  my_data = {'a': [1, 2.0, 3, 4+6j],            'b': ('string', u'Unicode string'),            'c': None} output = open('data.pkl', 'wb') pickle.dump(data1, output) output.close()   To read it back:  import pprint, pickle  pkl_file = open('data.pkl', 'rb')  data1 = pickle.load(pkl_file) pprint.pprint(data1)  pkl_file.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  If you don't need a human-readable output, another option you could try is to save the array as a MATLAB .mat file, which is a structured array. I despise MATLAB, but the fact that I can both read and write a .mat in very few lines is convenient.   Unlike Joe Kington's answer, the benefit of this is that you don't need to know the original shape of the data in the .mat file, i.e. no need to reshape upon reading in. And, unlike using pickle, a .mat file can be read by MATLAB, and probably some other programs/languages as well.   Here is an example:  import numpy as np import scipy.io  # Some test data x = np.arange(200).reshape((4,5,10))  # Specify the filename of the .mat file matfile = 'test_mat.mat'  # Write the array to the mat file. For this to work, the array must be the value # corresponding to a key name of your choice in a dictionary scipy.io.savemat(matfile, mdict={'out': x}, oned_as='row')  # For the above line, I specified the kwarg oned_as since python (2.7 with  # numpy 1.6.1) throws a FutureWarning.  Here, this isn't really necessary  # since oned_as is a kwarg for dealing with 1-D arrays.  # Now load in the data from the .mat that was just saved matdata = scipy.io.loadmat(matfile)  # And just to check if the data is the same: assert np.all(x == matdata['out'])   If you forget the key that the array is named in the .mat file, you can always do:  print matdata.keys()   And of course you can store many arrays using many more keys.  So yes – it won't be readable with your eyes, but only takes 2 lines to write and read the data, which I think is a fair trade-off.  Take a look at the docs for scipy.io.savemat and scipy.io.loadmat and also this tutorial page: scipy.io File IO Tutorial     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  ndarray.tofile() should also work  e.g. if your array is called a:  a.tofile('yourfile.txt',sep=\" \",format=\"%s\")   Not sure how to get newline formatting though.  Edit (credit Kevin J. Black's comment here):     Since version 1.5.0, np.tofile() takes an optional parameter   newline='\\n' to allow multi-line output.   https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.savetxt.html      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  There exist special libraries to do just that. (Plus wrappers for python)   netCDF4: http://www.unidata.ucar.edu/software/netcdf/ netCDF4 Python interface: http://www.unidata.ucar.edu/software/netcdf/software.html#Python HDF5: http://www.hdfgroup.org/HDF5/   hope this helps     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  You can simply traverse the array in three nested loops and write their values to your file. For reading, you simply use the same exact loop construction. You will get the values in exactly the right order to fill your arrays correctly again.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "How to write a multidimensional array to a text file?",
        "A_Content": "  I have a way to do it using a simply filename.write() operation. It works fine for me, but I'm dealing with arrays having ~1500 data elements.   I basically just have for loops to iterate through the file and write it to the output destination line-by-line in a csv style output.   import numpy as np  trial = np.genfromtxt(\"/extension/file.txt\", dtype = str, delimiter = \",\")  with open(\"/extension/file.txt\", \"w\") as f:     for x in xrange(len(trial[:,1])):         for y in range(num_of_columns):             if y < num_of_columns-2:                 f.write(trial[x][y] + \",\")             elif y == num_of_columns-1:                 f.write(trial[x][y])         f.write(\"\\n\")   The if and elif statement are used to add commas between the data elements. For whatever reason, these get stripped out when reading the file in as an nd array. My goal was to output the file as a csv, so this method helps to handle that.  Hope this helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3685265/how-to-write-a-multidimensional-array-to-a-text-file",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In another question, other users offered some help if I could supply the array I was having trouble with. However, I even fail at a basic I/O task, such as writing an array to a file.  Can anyone explain what kind of loop I would need to write a 4x11x14 numpy array to file?  This array consist of four 11 x 14 arrays, so I should format it with a nice newline, to make the reading of the file easier on others.  Edit: So I've tried the numpy.savetxt function. Strangely, it gives the following error:  TypeError: float argument required, not numpy.ndarray   I assume that this is because the function doesn't work with multidimensional arrays? Any solutions as I would like them within one file?     ",
        "Q_Votes": "86"
    },
    {
        "Q_Title": "Instance attribute attribute_name defined outside __init__",
        "A_Content": "  The idea behind this message is for the sake of readability. We expect to find all the attributes an instance may have by reading its __init__ method.  You may still want to split initialization into other methods though. In such case, you can simply assign attributes to None (with a bit of documentation) in the __init__ then call the sub-initialization methods.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "constructor",
            "pylint"
        ],
        "URL": "https://stackoverflow.com/questions/19284857/instance-attribute-attribute-name-defined-outside-init",
        "A_Votes": "89",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I split up my class constructor by letting it call multiple functions, like this:  class Wizard:     def __init__(self, argv):         self.parse_arguments(argv)         self.wave_wand() # declaration omitted      def parse_arguments(self, argv):         if self.has_correct_argument_count(argv):             self.name = argv[0]             self.magic_ability = argv[1]         else:             raise InvalidArgumentsException() # declaration omitted  # ... irrelevant functions omitted   While my interpreter happily runs my code, Pylint has a complaint:  Instance attribute attribute_name defined outside __init__  A cursory Google search is currently fruitless. Keeping all constructor logic in __init__ seems unorganized, and turning off the Pylint warning also seems hack-ish.  What is a/the Pythonic way to resolve this problem?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Instance attribute attribute_name defined outside __init__",
        "A_Content": "  Just return a tuple from parse_arguments() and unpack into attributes inside __init__ as needed.  Also, I would recommend that you use Exceptions in lieu of using exit(1).  You get tracebacks, your code is reusable, etc.  class Wizard:     def __init__(self, argv):         self.name,self.magic_ability = self.parse_arguments(argv)      def parse_arguments(self, argv):         assert len(argv) == 2         return argv[0],argv[1]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "constructor",
            "pylint"
        ],
        "URL": "https://stackoverflow.com/questions/19284857/instance-attribute-attribute-name-defined-outside-init",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I split up my class constructor by letting it call multiple functions, like this:  class Wizard:     def __init__(self, argv):         self.parse_arguments(argv)         self.wave_wand() # declaration omitted      def parse_arguments(self, argv):         if self.has_correct_argument_count(argv):             self.name = argv[0]             self.magic_ability = argv[1]         else:             raise InvalidArgumentsException() # declaration omitted  # ... irrelevant functions omitted   While my interpreter happily runs my code, Pylint has a complaint:  Instance attribute attribute_name defined outside __init__  A cursory Google search is currently fruitless. Keeping all constructor logic in __init__ seems unorganized, and turning off the Pylint warning also seems hack-ish.  What is a/the Pythonic way to resolve this problem?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  I am assuming you mean using XSD files. Surprisingly there aren't many python XML libraries that support this. lxml does however. Check Validation with lxml. The page also lists how to use lxml to validate with other schema types.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  As for \"pure python\" solutions: the package index lists:   pyxsd, the description says it uses xml.etree.cElementTree, which is not \"pure python\" (but included in stdlib), but source code indicates that it falls back to xml.etree.ElementTree, so this would count as pure python. Haven't used it, but according to the docs, it does do schema validation. minixsv: 'a lightweight XML schema validator written in \"pure\" Python'. However, the description says \"currently a subset of the XML schema standard is supported\", so this may not be enough. XSV, which I think is used for the W3C's online xsd validator (it still seems to use the old pyxml package, which I think is no longer maintained)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  The PyXB package at http://pyxb.sourceforge.net/ generates validating bindings for Python from XML schema documents.  It handles almost every schema construct and supports multiple namespaces.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  An example of a simple validator in Python3 using the popular library lxml  Installation lxml  pip install lxml   If you get an error like \"Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?\", try to do this first:  # Debian/Ubuntu apt-get install python-dev python3-dev libxml2-dev libxslt-dev  # Fedora 23+ dnf install python-devel python3-devel libxml2-devel libxslt-devel     The simplest validator  Let's create simplest validator.py  from lxml import etree  def validate(xml_path: str, xsd_path: str) -> bool:      xmlschema_doc = etree.parse(xsd_path)     xmlschema = etree.XMLSchema(xmlschema_doc)      xml_doc = etree.parse(xml_path)     result = xmlschema.validate(xml_doc)      return result   then write and run main.py  from validator import validate  if validate(\"path/to/file.xml\", \"path/to/scheme.xsd\"):     print('Valid! :)') else:     print('Not valid! :(')     A little bit of OOP  In order to validate more than one file, there is no need to create an XMLSchema object every time, therefore:  validator.py  from lxml import etree  class Validator:      def __init__(self, xsd_path: str):         xmlschema_doc = etree.parse(xsd_path)         self.xmlschema = etree.XMLSchema(xmlschema_doc)      def validate(self, xml_path: str) -> bool:         xml_doc = etree.parse(xml_path)         result = self.xmlschema.validate(xml_doc)          return result   Now we can validate all files in the directory as follows:  main.py  import os from validator import Validator  validator = Validator(\"path/to/scheme.xsd\")  # The directory with XML files XML_DIR = \"path/to/directory\"  for file_name in os.listdir(XML_DIR):     print('{}: '.format(file_name), end='')      file_path = '{}/{}'.format(XML_DIR, file_name)      if validator.validate(file_path):         print('Valid! :)')     else:         print('Not valid! :(')     For more options read here: Validation with lxml     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  There are two ways(actually there are more) that you could do this. 1. using lxml pip install lxml      from lxml import etree, objectify from lxml.etree import XMLSyntaxError  def xml_validator(some_xml_string, xsd_file='/path/to/my_schema_file.xsd'):     try:         schema = etree.XMLSchema(file=xsd_file)         parser = objectify.makeparser(schema=schema)         objectify.fromstring(some_xml_string, parser)         print \"YEAH!, my xml file has validated\"     except XMLSyntaxError:         #handle exception here         print \"Oh NO!, my xml file does not validate\"         pass  xml_file = open('my_xml_file.xml', 'r') xml_string = xml_file.read() xml_file.close()  xml_validator(xml_string, '/path/to/my_schema_file.xsd')    Use xmllint from the commandline. xmllint comes installed in many linux distributions.   >> xmllint --format --pretty 1 --load-trace --debug --schema /path/to/my_schema_file.xsd /path/to/my_xml_file.xml     ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  lxml provides etree.DTD  from the tests on http://lxml.de/api/lxml.tests.test_dtd-pysrc.html  ... root = etree.XML(_bytes(\"<b/>\"))  dtd = etree.DTD(BytesIO(\"<!ELEMENT b EMPTY>\"))  self.assert_(dtd.validate(root))       ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Validating with an XML schema in Python",
        "A_Content": "  You can easily validate an XML file or tree against an XML Schema (XSD) with the xmlschema Python package. It's pure Python, available on PyPi and doesn't have many dependencies.  Example - validate a file:  import xmlschema xmlschema.validate('doc.xml', 'some.xsd')   The method raises an exception if the file doesn't validate against the XSD. That exception then contains some violation details.  If you want to validate many files you only have to load the XSD once:  xsd = xmlschema.XMLSchema('some.xsd') for filename in filenames:     xsd.validate(filename)   If you don't need the exception you can validate like this:  if xsd.is_valid('doc.xml'):     print('do something useful')   Alternatively, xmlschema directly works on file objects and in memory XML trees (either created with xml.etree.ElementTree or lxml). Example:  import xml.etree.ElementTree as ET t = ET.parse('doc.xml') result = xsd.is_valid(t) print('Document is valid? {}'.format(result))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "xml",
            "validation",
            "xsd"
        ],
        "URL": "https://stackoverflow.com/questions/299588/validating-with-an-xml-schema-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an XML file and an XML schema in another file and I'd like to validate that my XML file adheres to the schema.  How do I do this in Python?  I'd prefer something using the standard library, but I can install a third-party package if necessary.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  There is a feature request for this scheduled for Numpy 2.0.0: https://github.com/numpy/numpy/issues/2269     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "46",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  Although it is way too late for you, but for future reference: Using numba (1) is the easiest way until numpy implements it. If you use anaconda python distribution it should already be installed. The code will be compiled so it will be fast.  @jit(nopython=True) def find_first(item, vec):     \"\"\"return the index of the first occurence of item in vec\"\"\"     for i in xrange(len(vec)):         if item == vec[i]:             return i     return -1   and then:  >>> a = array([1,7,8,32]) >>> find_first(8,a) 2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  I've made a benchmark for several methods:   argwhere nonzero as in the question .tostring() as in @Rob Reilink's answer python loop Fortran loop   The Python and Fortran code are available. I skipped the unpromising ones like converting to a list.  The results on log scale. X-axis is the position of the needle (it takes longer to find if it's further down the array); last value is a needle that's not in the array. Y-axis is the time to find it.    The array had 1 million elements and tests were run 100 times. Results still fluctuate a bit, but the qualitative trend is clear: Python and f2py quit at the first element so they scale differently. Python gets too slow if the needle is not in the first 1%, whereas f2py is fast (but you need to compile it).  To summarize, f2py is the fastest solution, especially if the needle appears fairly early.  It's not built in which is annoying, but it's really just 2 minutes of work. Add this to a file called search.f90:  subroutine find_first(needle, haystack, haystack_length, index)     implicit none     integer, intent(in) :: needle     integer, intent(in) :: haystack_length     integer, intent(in), dimension(haystack_length) :: haystack !f2py intent(inplace) haystack     integer, intent(out) :: index     integer :: k     index = -1     do k = 1, haystack_length         if (haystack(k)==needle) then             index = k - 1             exit         endif     enddo end   If you're looking for something other than integer, just change the type. Then compile using:  f2py -c -m search search.f90   after which you can do (from Python):  import search print(search.find_first.__doc__) a = search.find_first(your_int_needle, your_int_array)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  You can convert a boolean array to a Python string using array.tostring() and then using the find() method:  (array==item).tostring().find('\\x01')   This does involve copying the data, though, since Python strings need to be immutable. An advantage is that you can also search for e.g. a rising edge by finding \\x00\\x01     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  In case of sorted arrays np.searchsorted works.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  I think you have hit a problem where a different method and some a priori knowledge of the array would really help.  The kind of thing where you have a X probability of finding your answer in the first Y percent of the data.  The splitting up the problem with the hope of getting lucky then doing this in python with a nested list comprehension or something.    Writing a C function to do this brute force isn't too hard using ctypes either.    The C code I hacked together (index.c):  long index(long val, long *data, long length){     long ans, i;     for(i=0;i<length;i++){         if (data[i] == val)             return(i);     }     return(-999); }   and the python:  # to compile (mac) # gcc -shared index.c -o index.dylib import ctypes lib = ctypes.CDLL('index.dylib') lib.index.restype = ctypes.c_long lib.index.argtypes = (ctypes.c_long, ctypes.POINTER(ctypes.c_long), ctypes.c_long)  import numpy as np np.random.seed(8675309) a = np.random.random_integers(0, 100, 10000) print lib.index(57, a.ctypes.data_as(ctypes.POINTER(ctypes.c_long)), len(a))   and I get 92.  Wrap up the python into a proper function and there you go.  The C version is a lot (~20x) faster for this seed (warning I am not good with timeit)  import timeit t = timeit.Timer('np.where(a==57)[0][0]', 'import numpy as np; np.random.seed(1); a = np.random.random_integers(0, 1000000, 10000000)') t.timeit(100)/100 # 0.09761879920959472 t2 = timeit.Timer('lib.index(57, a.ctypes.data_as(ctypes.POINTER(ctypes.c_long)), len(a))', 'import numpy as np; np.random.seed(1); a = np.random.random_integers(0, 1000000, 10000000); import ctypes; lib = ctypes.CDLL(\"index.dylib\"); lib.index.restype = ctypes.c_long; lib.index.argtypes = (ctypes.c_long, ctypes.POINTER(ctypes.c_long), ctypes.c_long) ') t2.timeit(100)/100 # 0.005288000106811523      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  If your list is sorted, you can achieve very quick search of index with the 'bisect' package. It's O(log(n)) instead of O(n).  bisect.bisect(a, x)   finds x in the array a, definitely quicker in the sorted case than any C-routine going through all the first elements (for long enough lists).  It's good to know sometimes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  @tal already presented a numba function to find the first index but that only works for 1D arrays. With np.ndenumerate you can also find the first index in an arbitarly dimensional array:  from numba import njit import numpy as np  @njit def index(array, item):     for idx, val in np.ndenumerate(array):         if val == item:             return idx     return None   Sample case:  >>> arr = np.arange(9).reshape(3,3) >>> index(arr, 3) (1, 0)   Timings show that it's similar in performance to tals solution:  arr = np.arange(100000) %timeit index(arr, 5)           # 1000000 loops, best of 3: 1.88 µs per loop %timeit find_first(5, arr)      # 1000000 loops, best of 3: 1.7 µs per loop  %timeit index(arr, 99999)       # 10000 loops, best of 3: 118 µs per loop %timeit find_first(99999, arr)  # 10000 loops, best of 3: 96 µs per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  As far as I know only np.any and np.all on boolean arrays are short-circuited.  In your case, numpy has to go through the entire array twice, once to create the boolean condition and a second time to find the indices.  My recommendation in this case would be to use cython. I think it should be easy to adjust an example for this case, especially if you don't need much flexibility for different dtypes and shapes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  I needed this for my job so I taught myself Python and Numpy's C interface and wrote my own.  http://pastebin.com/GtcXuLyd It's only for 1-D arrays, but works for most data types (int, float, or strings) and testing has shown it is again about 20 times faster than the expected approach in pure Python-numpy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  Just a note that if you are doing a sequence of searches, the performance gain from doing something clever like converting to string, might be lost in the outer loop if the search dimension isn't big enough. See how the performance of iterating find1 that uses the string conversion trick proposed above and find2 that uses argmax along the inner axis (plus an adjustment to ensure a non-match returns as -1)  import numpy,time def find1(arr,value):     return (arr==value).tostring().find('\\x01')  def find2(arr,value): #find value over inner most axis, and return array of indices to the match     b = arr==value     return b.argmax(axis=-1) - ~(b.any())   for size in [(1,100000000),(10000,10000),(1000000,100),(10000000,10)]:     print(size)     values = numpy.random.choice([0,0,0,0,0,0,0,1],size=size)     v = values>0      t=time.time()     numpy.apply_along_axis(find1,-1,v,1)     print('find1',time.time()-t)      t=time.time()     find2(v,1)     print('find2',time.time()-t)   outputs  (1, 100000000) ('find1', 0.25300002098083496) ('find2', 0.2780001163482666) (10000, 10000) ('find1', 0.46200013160705566) ('find2', 0.27300000190734863) (1000000, 100) ('find1', 20.98099994659424) ('find2', 0.3040001392364502) (10000000, 10) ('find1', 206.7590000629425) ('find2', 0.4830000400543213)   That said, a find written in C would be at least a little faster than either of these approaches     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  how about this   import numpy as np np.amin(np.where(array==item))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Numpy: find first index of value fast",
        "A_Content": "  You can covert your array into a list and use it's index() method:  i = list(array).index(item)   As far as I'm aware, this is a C compiled method.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "find"
        ],
        "URL": "https://stackoverflow.com/questions/7632963/numpy-find-first-index-of-value-fast",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I find the index of the first occurrence of a number in a Numpy array? Speed is important to me. I am not interested in the following answers because they scan the whole array and don't stop when they find the first occurrence:  itemindex = numpy.where(array==item)[0][0] nonzero(array == item)[0][0]   Note 1: none of the answers from that question seem relevant Is there a Numpy function to return the first index of something in an array?  Note 2: using a C-compiled method is preferred to a Python loop.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  From Django 1.7 onwards  Django has built in support for migrations - take a look at the documentation.  For Django 1.6 and earlier  Django doesn't support migrations out of the box. There is a pluggable app for Django that does exactly that though, and it works great. It's called South.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "100",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  Django currently does not do this automatically. Your options are:   Drop the table from the database, then recreate it in new form using syncdb. Print out SQL for the database using python manage.py sql (appname), find the added line for the field and add it manually using alter table SQL command. (This will also allow you to choose values of the field for your current records.) Use South (per Dominic's answer).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  Follow these steps:   Export your data to a fixture using the dumpdata management command Drop the table Run syncdb Reload your data from the fixture using the loaddata management command      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  As suggested in top answer, I tried using South, and after an hour of frustration with obscure migration errors decided to go with Django Evolution instead.  I think it's easier to get started with than South, and it worked perfectly the first time I typed ./manage.py evolve --hint --execute, so I'm happy with it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  Havent used django in a while, but i seem to remember that syncdb does perform alter commands on db tables. you have to drop the table then run again and it will create again.  edit: sorry does NOT perform alter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  In django 1.6   At first we have run - python manage.py sql <app name> Then we have to run - python manage.py syncdb      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "django syncdb and an updated model",
        "A_Content": "  If you run Django with Apache and MySQL, restart apache after making migration with makemigrations.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1605662/django-syncdb-and-an-updated-model",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have recently updated my model, added a BooleanField to it however when I do python manage.py syncdb, it doesn't add the new field to the database for the model. How can I fix this ?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the return value of Javascript code in Selenium",
        "A_Content": "  To return a value, simply use the return JavaScript keyword in the string passed to the execute_script() method, e.g.  >>> from selenium import webdriver >>> wd = webdriver.Firefox() >>> wd.get(\"http://localhost/foo/bar\") >>> wd.execute_script(\"return 5\") 5 >>> wd.execute_script(\"return true\") True >>> wd.execute_script(\"return {foo: 'bar'}\") {u'foo': u'bar'} >>> wd.execute_script(\"return foobar()\") u'eli'      ",
        "Language": "Python",
        "Tags": [
            "javascript",
            "python",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/5585343/getting-the-return-value-of-javascript-code-in-selenium",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using Selenium2 for some automated tests of my website, and I'd like to be able to get the return value of some Javascript code.  If I have a foobar() Javascript function in my webpage and I want to call that and get the return value into my Python code, what can I call to do that?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the return value of Javascript code in Selenium",
        "A_Content": "  You can return values even if you don't have your snipped of code written as a function like in the below example code, by just adding return var; at the end where var is the variable you want to return.   result = driver.execute_script('''cells = document.querySelectorAll('a'); URLs = [] console.log(cells); [].forEach.call(cells, function (el) {     if(el.text.indexOf(\"download\") !== -1){     //el.click();     console.log(el.href)     //window.open(el.href, '_blank');     URLs.push(el.href)     } }); return URLs''')   result will contain the array that is in URLs this case.     ",
        "Language": "Python",
        "Tags": [
            "javascript",
            "python",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/5585343/getting-the-return-value-of-javascript-code-in-selenium",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using Selenium2 for some automated tests of my website, and I'd like to be able to get the return value of some Javascript code.  If I have a foobar() Javascript function in my webpage and I want to call that and get the return value into my Python code, what can I call to do that?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  A friend and I have written a Python profile viewer called SnakeViz that runs in a web browser. If you are already successfully using RunSnakeRun SnakeViz may not add that much value, but SnakeViz is much easier to install.  Edit: SnakeViz supports Python 2 and 3 and works on all major systems.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "69",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  I'm only aware of RunSnakeRun.  There was also some talk some time ago about an integrated profiler in PyDev (Eclipse), but I don't know if that will ever see the light of day.  Update: Unfortunately it seems that RunSnakeRun is no longer maintained, and it does not support Python 3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  I use gprof2dot.py. The result looks like this. I use those commands:    python -m cProfile -o profile.dat my_program.py   gprof2dot.py -f pstats profile.dat | dot -Tpng -o profile.png   You need graphviz and gprof2dot.py installed. You might like a convenience shell script.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  Spyder also provides a pretty nice gui for cProfile:       ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  This person created a graphical profile, described here.  Maybe you could use that as a starting point for your own work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  Python Tools for Visual Studio contains a very well done graphical profiler: http://www.youtube.com/watch?v=VCx7rlPyEzE&hd=1  http://pytools.codeplex.com/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  KCacheGrind includes a version called QCacheGrind which does run on Mac OS X and on Windows.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  Python Call Graph generates pics very similar to those in maxy's answer. It also shows total time for each function, for some reason it's not reflected in the example graphs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  Try out Snakeviz. Very easy to install (via pip) and it's browser based.  https://jiffyclub.github.io/snakeviz/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  I've written a browser-based visualization tool, profile_eye, which operates on the output of gprof2dot.  gprof2dot is great at grokking many profiling-tool outputs, and does a great job at graph-element placement. The final rendering is a static graphic, which is often very cluttered.   Using d3.js it's possible to remove much of that clutter, through relative fading of unfocused elements, tooltips, and a fisheye distortion.   For comparison, see profile_eye's visualization of the canonical example used by gprof2dot. For Python in particular, see a cProfile output example.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  Consider pyflame + flamegraph  Pyflame: A Ptracing Profiler For Python + flamegraph  https://github.com/uber/pyflame  You can trace towards a running python process using pyflame.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Is there a visual profiler for Python? [closed]",
        "A_Content": "  I have used plop and found it to be very light-weight. Gives a quick insight into the perf.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "user-interface",
            "profiling",
            "profiler"
        ],
        "URL": "https://stackoverflow.com/questions/3378953/is-there-a-visual-profiler-for-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I use cProfile now but I find it tedious to write pstats code just to query the statistics data.  I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.  Some examples from the Java world are visualvm and JProfiler.   Does something like this exist? Is there an IDE that does this? Would dtrace help?   I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the caller function name inside another function in Python?",
        "A_Content": "  You can use the inspect module to get the calling stack. It returns a list of frame records. The third element in each record is the caller name. What you want is this:  >>> import inspect >>> def f(): ...     print inspect.stack()[1][3] ... >>> def g(): ...     f() ... >>> g() g   Of course, it is a good idea to check that enough frame records exist before trying to access a particular index.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/900392/getting-the-caller-function-name-inside-another-function-in-python",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    If you have 2 functions like:  def A def B   and A calls B, can you get who is calling B inside B, like:  def A () :     B ()  def B () :     this.caller.name      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the caller function name inside another function in Python?",
        "A_Content": "  There are two ways, using sys and inspect modules:   sys._getframe(1).f_code.co_name inspect.stack()[1][3]   The stack() form is less readable and is implementation dependent since it calls sys._getframe(), see extract from inspect.py:  def stack(context=1):     \"\"\"Return a list of records for the stack above the caller's frame.\"\"\"     return getouterframes(sys._getframe(1), context)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/900392/getting-the-caller-function-name-inside-another-function-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If you have 2 functions like:  def A def B   and A calls B, can you get who is calling B inside B, like:  def A () :     B ()  def B () :     this.caller.name      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the caller function name inside another function in Python?",
        "A_Content": "  Note (June 2018): today, I would probably use inspect module, see other answers  sys._getframe(1).f_code.co_name like in the example below:  >>> def foo(): ...  global x ...  x = sys._getframe(1) ... >>> def y(): foo() ... >>> y() >>> x.f_code.co_name 'y' >>>     Important note: as it's obvious from the _getframe method name (hey, it starts with an underscore), it's not an API method one should be thoughtlessly rely on.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/900392/getting-the-caller-function-name-inside-another-function-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If you have 2 functions like:  def A def B   and A calls B, can you get who is calling B inside B, like:  def A () :     B ()  def B () :     this.caller.name      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the caller function name inside another function in Python?",
        "A_Content": "  This works for me! :D  >>> def a(): ...     import sys ...     print sys._getframe(1).f_code.co_name ... >>> def b(): ...     a() ... ... >>> b() b >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/900392/getting-the-caller-function-name-inside-another-function-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If you have 2 functions like:  def A def B   and A calls B, can you get who is calling B inside B, like:  def A () :     B ()  def B () :     this.caller.name      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting the caller function name inside another function in Python?",
        "A_Content": "  you can user the logging module and specify the %(filename)s option in BaseConfig()  import logging logging.basicConfig(filename='/tmp/test.log', level=logging.DEBUG, format='%(asctime)s | %(levelname)s | %(funcName)s |%(message)s')  def A():     logging.info('info')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "debugging"
        ],
        "URL": "https://stackoverflow.com/questions/900392/getting-the-caller-function-name-inside-another-function-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    If you have 2 functions like:  def A def B   and A calls B, can you get who is calling B inside B, like:  def A () :     B ()  def B () :     this.caller.name      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  With most of these kinds of applications, you'll have to roll much of your own code for a statistical classification task. As Lucka suggested, NLTK is the perfect tool for natural language manipulation in Python, so long as your goal doesn't interfere with the non commercial nature of its license.  However, I would suggest other software packages for modeling.  I haven't found many strong advanced machine learning models available for Python, so I'm going to suggest some standalone binaries that easily cooperate with it.  You may be interested in The Toolkit for Advanced Discriminative Modeling, which can be easily interfaced with Python.  This has been used for classification tasks in various areas of natural language processing.  You also have a pick of a number of different models.  I'd suggest starting with Maximum Entropy classification so long as you're already familiar with implementing a Naive Bayes classifier.  If not, you may want to look into it and code one up to really get a decent understanding of statistical classification as a machine learning task.  The University of Texas at Austin computational linguistics groups have held classes where most of the projects coming out of them have used this great tool.  You can look at the course page for Computational Linguistics II to get an idea of how to make it work and what previous applications it has served.  Another great tool which works in the same vein is Mallet.  The difference between Mallet is that there's a bit more documentation and some more models available, such as decision trees, and it's in Java, which, in my opinion, makes it a little slower.  Weka is a whole suite of different machine learning models in one big package that includes some graphical stuff, but it's really mostly meant for pedagogical purposes, and isn't really something I'd put into production.  Good luck with your task.  The real difficult part will probably be the amount of knowledge engineering required up front for you to classify the 'seed set' off of which your model will learn.  It needs to be pretty sizeable, depending on whether you're doing binary classification (happy vs sad) or a whole range of emotions (which will require even more).  Make sure to hold out some of this engineered data for testing, or run some tenfold or remove-one tests to make sure you're actually doing a good job predicting before you put it out there. And most of all, have fun!  This is the best part of NLP and AI, in my opinion.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  Good luck with that.  Sentiment is enormously contextual, and tweeting culture makes the problem worse because you aren't given the context for most tweets.  The whole point of twitter is that you can leverage the huge amount of shared \"real world\" context to pack meaningful communication in a very short message.  If they say the video is bad, does that mean bad, or bad?     A linguistics professor was lecturing   to her class one day. \"In English,\"   she said, \"A double negative forms a   positive. In some languages, though,   such as Russian, a double negative is   still a negative. However, there is no   language wherein a double positive can   form a negative.\"      A voice from the back of the room   piped up, \"Yeah . . .right.\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "74",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  Thanks everyone for your suggestions, they were indeed very useful! I ended up using a Naive Bayesian classifier, which I borrowed from here.  I started by feeding it with a list of good/bad keywords and then added a \"learn\" feature by employing user feedback. It turned out to work pretty nice.  The full details of my work as in a blog post.  Again, your help was very useful, so thank you!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  I have constructed a word list labeled with sentiment. You can access it from here:  http://www2.compute.dtu.dk/pubdb/views/edoc_download.php/6010/zip/imm6010.zip  You will find a short Python program on my blog:   http://finnaarupnielsen.wordpress.com/2011/06/20/simplest-sentiment-analysis-in-python-with-af/  This post displays how to use the word list with single sentences as well as with Twitter.  Word lists approaches have their limitations. You will find a investigation of the limitations of my word list in the article \"A new ANEW: Evaluation of a word list for sentiment analysis in microblogs\". That article is available from my homepage.  Please note a unicode(s, 'utf-8') is missing from the code (for paedagogic reasons).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  A lot of research papers indicate that a good starting point for sentiment analysis is looking at adjectives, e.g., are they positive adjectives or negative adjectives. For a short block of text this is pretty much your only option... There are papers that look at entire documents, or sentence level analysis, but as you say tweets are quite short... There is no real magic approach to understanding the sentiment of a sentence, so I think your best bet would be hunting down one of these research papers and trying to get their data-set of positively/negatively oriented adjectives.  Now, this having been said, sentiment is domain specific, and you might find it difficult to get a high-level of accuracy with a general purpose data-set.  Good luck.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  I think you may find it difficult to find what you're after. The closest thing that I know of is LingPipe, which has some sentiment analysis functionality and is available under a limited kind of open-source licence, but is written in Java.  Also, sentiment analysis systems are usually developed by training a system on product/movie review data which is significantly different from the average tweet. They are going to be optimised for text with several sentences, all about the same topic. I suspect you would do better coming up with a rule-based system yourself, perhaps based on a lexicon of sentiment terms like the one the University of Pittsburgh provide.  Check out We Feel Fine for an implementation of similar idea with a really beautiful interface (and twitrratr).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  Take a look at Twitter sentiment analysis tool. It's written in python, and it uses Naive Bayes classifier with semi-supervised machine learning. The source can be found here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  Maybe TextBlob (based on NLTK and pattern) is the right sentiment analysis tool for you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  I came across Natural Language Toolkit a while ago. You could probably use it as a starting point. It also has a lot of modules and addons, so maybe they already have something similar.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  Somewhat wacky thought: you could try using the Twitter API to download a large set of tweets, and then classifying a subset of that set using emoticons: one positive group for  \":)\", \":]\", \":D\", etc, and another negative group with \":(\", etc.  Once you have that crude classification, you could search for more clues with frequency or ngram analysis or something along those lines.  It may seem silly, but serious research has been done on this (search for \"sentiment analysis\" and emoticon). Worth a look.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  There's a Twitter Sentiment API by TweetFeel that does advanced linguistic analysis of tweets, and can retrieve positive/negative tweets. See http://www.webservius.com/corp/docs/tweetfeel_sentiment.htm     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Sentiment analysis for Twitter in Python [closed]",
        "A_Content": "  For those interested in coding Twitter Sentiment Analyis from scratch, there is a Coursera course \"Data Science\" with python code on GitHub (as part of assignment 1 - link). The sentiments are part of the AFINN-111.  You can find working solutions, for example here. In addition to the AFINN-111 sentiment list, there is a simple implementation of builing a dynamic term list based on frequency of terms in tweets that have a pos/neg score (see here).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "open-source",
            "nlp"
        ],
        "URL": "https://stackoverflow.com/questions/573768/sentiment-analysis-for-twitter-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for an open source implementation, preferably in python, of Textual Sentiment Analysis (http://en.wikipedia.org/wiki/Sentiment_analysis). Is anyone familiar with such open source implementation I can use?  I'm writing an application that searches twitter for some search term, say \"youtube\", and counts \"happy\" tweets vs. \"sad\" tweets.  I'm using Google's appengine, so it's in python. I'd like to be able to classify the returned search results from twitter and I'd like to do that in python. I haven't been able to find such sentiment analyzer so far, specifically not in python.  Are you familiar with such open source implementation I can use? Preferably this is already in python, but if not, hopefully I can translate it to python.  Note, the texts I'm analyzing are VERY short, they are tweets. So ideally, this classifier is optimized for such short texts.  BTW, twitter does support the \":)\" and \":(\" operators in search, which aim to do just this, but unfortunately, the classification provided by them isn't that great, so I figured I might give this a try myself.  Thanks!  BTW, an early demo is here and the code I have so far is here and I'd love to opensource it with any interested developer.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Mark's iterative approach would be the usual way, I think.  Here's an alternative with string-splitting, which can often be useful for finding-related processes:  def findnth(haystack, needle, n):     parts= haystack.split(needle, n+1)     if len(parts)<=n+1:         return -1     return len(haystack)-len(parts[-1])-len(needle)   And here's a quick (and somewhat dirty, in that you have to choose some chaff that can't match the needle) one-liner:  'foo bar bar bar'.replace('bar', 'XXX', 1).find('bar')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Here's a more Pythonic version of the straightforward iterative solution:  def find_nth(haystack, needle, n):     start = haystack.find(needle)     while start >= 0 and n > 1:         start = haystack.find(needle, start+len(needle))         n -= 1     return start   Example:  >>> find_nth(\"foofoofoofoo\", \"foofoo\", 2) 6   If you want to find the nth overlapping occurrence of needle, you can increment by 1 instead of len(needle), like this:  def find_nth_overlapping(haystack, needle, n):     start = haystack.find(needle)     while start >= 0 and n > 1:         start = haystack.find(needle, start+1)         n -= 1     return start   Example:  >>> find_nth_overlapping(\"foofoofoofoo\", \"foofoo\", 2) 3   This is easier to read than Mark's version, and it doesn't require the extra memory of the splitting version or importing regular expression module.  It also adheres to a few of the rules in the Zen of python, unlike the various re approaches:   Simple is better than complex. Flat is better than nested. Readability counts.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  This will find the second occurrence of substring in string.  def find_2nd(string, substring):    return string.find(substring, string.find(substring) + 1)   Edit: I haven't thought much about the performance, but a quick recursion can help with finding the nth occurrence:  def find_nth(string, substring, n):    if (n == 1):        return string.find(substring)    else:        return string.find(substring, find_nth(string, substring, n - 1) + 1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Understanding that regex is not always the best solution, I'd probably use one here:  >>> import re >>> s = \"ababdfegtduab\" >>> [m.start() for m in re.finditer(r\"ab\",s)] [0, 2, 11] >>> [m.start() for m in re.finditer(r\"ab\",s)][2] #index 2 is third occurrence  11      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  I'm offering some benchmarking results comparing the most prominent approaches presented so far, namely @bobince's findnth() (based on str.split()) vs. @tgamblin's or @Mark Byers' find_nth() (based on str.find()). I will also compare with a C extension (_find_nth.so) to see how fast we can go. Here is find_nth.py:   def findnth(haystack, needle, n):     parts= haystack.split(needle, n+1)     if len(parts)<=n+1:         return -1     return len(haystack)-len(parts[-1])-len(needle)  def find_nth(s, x, n=0, overlap=False):     l = 1 if overlap else len(x)     i = -l     for c in xrange(n + 1):         i = s.find(x, i + l)         if i < 0:             break     return i   Of course, performance matters most if the string is large, so suppose we want to find the 1000001st newline ('\\n') in a 1.3 GB file called 'bigfile'. To save memory, we would like to work on an mmap.mmap object representation of the file:  In [1]: import _find_nth, find_nth, mmap  In [2]: f = open('bigfile', 'r')  In [3]: mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)   There is already the first problem with findnth(), since mmap.mmap objects don't support split(). So we actually have to copy the whole file into memory:  In [4]: %time s = mm[:] CPU times: user 813 ms, sys: 3.25 s, total: 4.06 s Wall time: 17.7 s   Ouch! Fortunately s still fits in the 4 GB of memory of my Macbook Air, so let's benchmark findnth():  In [5]: %timeit find_nth.findnth(s, '\\n', 1000000) 1 loops, best of 3: 29.9 s per loop   Clearly a terrible performance. Let's see how the approach based on str.find() does:  In [6]: %timeit find_nth.find_nth(s, '\\n', 1000000) 1 loops, best of 3: 774 ms per loop   Much better! Clearly, findnth()'s problem is that it is forced to copy the string during split(), which is already the second time we copied the 1.3 GB of data around after s = mm[:]. Here comes in the second advantage of find_nth(): We can use it on mm directly, such that zero copies of the file are required:  In [7]: %timeit find_nth.find_nth(mm, '\\n', 1000000) 1 loops, best of 3: 1.21 s per loop   There appears to be a small performance penalty operating on mm vs. s, but this illustrates that find_nth() can get us an answer in 1.2 s compared to findnth's total of 47 s.  I found no cases where the str.find() based approach was significantly worse than the str.split() based approach, so at this point, I would argue that @tgamblin's or @Mark Byers' answer should be accepted instead of @bobince's.  In my testing, the version of find_nth() above was the fastest pure Python solution I could come up with (very similar to @Mark Byers' version). Let's see how much better we can do with a C extension module. Here is _find_nthmodule.c:  #include <Python.h> #include <string.h>  off_t _find_nth(const char *buf, size_t l, char c, int n) {     off_t i;     for (i = 0; i < l; ++i) {         if (buf[i] == c && n-- == 0) {             return i;         }     }     return -1; }  off_t _find_nth2(const char *buf, size_t l, char c, int n) {     const char *b = buf - 1;     do {         b = memchr(b + 1, c, l);         if (!b) return -1;     } while (n--);     return b - buf; }  /* mmap_object is private in mmapmodule.c - replicate beginning here */ typedef struct {     PyObject_HEAD     char *data;     size_t size; } mmap_object;  typedef struct {     const char *s;     size_t l;     char c;     int n; } params;  int parse_args(PyObject *args, params *P) {     PyObject *obj;     const char *x;      if (!PyArg_ParseTuple(args, \"Osi\", &obj, &x, &P->n)) {         return 1;     }     PyTypeObject *type = Py_TYPE(obj);      if (type == &PyString_Type) {         P->s = PyString_AS_STRING(obj);         P->l = PyString_GET_SIZE(obj);     } else if (!strcmp(type->tp_name, \"mmap.mmap\")) {         mmap_object *m_obj = (mmap_object*) obj;         P->s = m_obj->data;         P->l = m_obj->size;     } else {         PyErr_SetString(PyExc_TypeError, \"Cannot obtain char * from argument 0\");         return 1;     }     P->c = x[0];     return 0; }  static PyObject* py_find_nth(PyObject *self, PyObject *args) {     params P;     if (!parse_args(args, &P)) {         return Py_BuildValue(\"i\", _find_nth(P.s, P.l, P.c, P.n));     } else {         return NULL;         } }  static PyObject* py_find_nth2(PyObject *self, PyObject *args) {     params P;     if (!parse_args(args, &P)) {         return Py_BuildValue(\"i\", _find_nth2(P.s, P.l, P.c, P.n));     } else {         return NULL;         } }  static PyMethodDef methods[] = {     {\"find_nth\", py_find_nth, METH_VARARGS, \"\"},     {\"find_nth2\", py_find_nth2, METH_VARARGS, \"\"},     {0} };  PyMODINIT_FUNC init_find_nth(void) {     Py_InitModule(\"_find_nth\", methods); }   Here is the setup.py file:  from distutils.core import setup, Extension module = Extension('_find_nth', sources=['_find_nthmodule.c']) setup(ext_modules=[module])   Install as usual with python setup.py install. The C code plays at an advantage here since it is limited to finding single characters, but let's see how fast this is:  In [8]: %timeit _find_nth.find_nth(mm, '\\n', 1000000) 1 loops, best of 3: 218 ms per loop  In [9]: %timeit _find_nth.find_nth(s, '\\n', 1000000) 1 loops, best of 3: 216 ms per loop  In [10]: %timeit _find_nth.find_nth2(mm, '\\n', 1000000) 1 loops, best of 3: 307 ms per loop  In [11]: %timeit _find_nth.find_nth2(s, '\\n', 1000000) 1 loops, best of 3: 304 ms per loop   Clearly quite a bit faster still. Interestingly, there is no difference on the C level between the in-memory and mmapped cases. It is also interesting to see that _find_nth2(), which is based on string.h's memchr() library function, loses out against the straightforward implementation in _find_nth(): The additional \"optimizations\" in memchr() are apparently backfiring...  In conclusion, the implementation in findnth() (based on str.split()) is really a bad idea, since (a) it performs terribly for larger strings due to the required copying, and (b)  it doesn't work on mmap.mmap objects at all. The implementation in find_nth() (based on str.find()) should be preferred in all circumstances (and therefore be the accepted answer to this question).  There is still quite a bit of room for improvement, since the C extension ran almost a factor of 4 faster than the pure Python code, indicating that there might be a case for a dedicated Python library function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  I'd probably do something like this, using the find function that takes an index parameter:  def find_nth(s, x, n):     i = -1     for _ in range(n):         i = s.find(x, i + len(x))         if i == -1:             break     return i  print find_nth('bananabanana', 'an', 3)   It's not particularly Pythonic I guess, but it's simple. You could do it using recursion instead:  def find_nth(s, x, n, i = 0):     i = s.find(x, i)     if n == 1 or i == -1:         return i      else:         return find_nth(s, x, n - 1, i + len(x))  print find_nth('bananabanana', 'an', 3)   It's a functional way to solve it, but I don't know if that makes it more Pythonic.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Simplest way?  text = \"This is a test from a test ok\"   firstTest = text.find('test')  print text.find('test', firstTest + 1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Here's another re + itertools version that should work when searching for either a str or a RegexpObject. I will freely admit that this is likely over-engineered, but for some reason it entertained me.  import itertools import re  def find_nth(haystack, needle, n = 1):     \"\"\"     Find the starting index of the nth occurrence of ``needle`` in \\     ``haystack``.      If ``needle`` is a ``str``, this will perform an exact substring     match; if it is a ``RegexpObject``, this will perform a regex     search.      If ``needle`` doesn't appear in ``haystack``, return ``-1``. If     ``needle`` doesn't appear in ``haystack`` ``n`` times,     return ``-1``.      Arguments     ---------     * ``needle`` the substring (or a ``RegexpObject``) to find     * ``haystack`` is a ``str``     * an ``int`` indicating which occurrence to find; defaults to ``1``      >>> find_nth(\"foo\", \"o\", 1)     1     >>> find_nth(\"foo\", \"o\", 2)     2     >>> find_nth(\"foo\", \"o\", 3)     -1     >>> find_nth(\"foo\", \"b\")     -1     >>> import re     >>> either_o = re.compile(\"[oO]\")     >>> find_nth(\"foo\", either_o, 1)     1     >>> find_nth(\"FOO\", either_o, 1)     1     \"\"\"     if (hasattr(needle, 'finditer')):         matches = needle.finditer(haystack)     else:         matches = re.finditer(re.escape(needle), haystack)     start_here = itertools.dropwhile(lambda x: x[0] < n, enumerate(matches, 1))     try:         return next(start_here)[1].start()     except StopIteration:         return -1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Here is another approach using re.finditer. The difference is that this only looks into the haystack as far as necessary  from re import finditer from itertools import dropwhile needle='an' haystack='bananabanana' n=2 next(dropwhile(lambda x: x[0]<n, enumerate(re.finditer(needle,haystack))))[1].start()       ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  >>> s=\"abcdefabcdefababcdef\" >>> j=0 >>> for n,i in enumerate(s): ...   if s[n:n+2] ==\"ab\": ...     print n,i ...     j=j+1 ...     if j==2: print \"2nd occurence at index position: \",n ... 0 a 6 a 2nd occurence at index position:  6 12 a 14 a      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  This will give you an array of the starting indices for matches to yourstring:  import re indices = [s.start() for s in re.finditer(':', yourstring)]   Then your nth entry would be:  n = 2 nth_entry = indices[n-1]   Of course you have to be careful with the index bounds. You can get the number of instances of yourstring like this:  num_instances = len(indices)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Building on modle13's answer, but without the re module dependency.  def iter_find(haystack, needle):     return [i for i in range(0, len(haystack)) if haystack[i:].startswith(needle)]   I kinda wish this was a builtin string method.  >>> iter_find(\"http://stackoverflow.com/questions/1883980/\", '/') [5, 6, 24, 34, 42]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  The replace one liner is great but only works because XX and bar have the same lentgh  A good and general def would be:  def findN(s,sub,N,replaceString=\"XXX\"):     return s.replace(sub,replaceString,N-1).find(sub) - (len(replaceString)-len(sub))*(N-1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  Providing another \"tricky\" solution, which use split and join.  In your example, we can use  len(\"substring\".join([s for s in ori.split(\"substring\")[:2]]))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  How about:  c = os.getcwd().split('\\\\') print '\\\\'.join(c[0:-2])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  This is the answer you really want:  def Find(String,ToFind,Occurence = 1): index = 0  count = 0 while index <= len(String):     try:         if String[index:index + len(ToFind)] == ToFind:             count += 1         if count == Occurence:                return index                break         index += 1     except IndexError:         return False         break return False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Find the nth occurrence of substring in a string",
        "A_Content": "  # return -1 if nth substr (0-indexed) d.n.e, else return index def find_nth(s, substr, n):     i = 0     while n >= 0:         n -= 1         i = s.find(substr, i + 1)     return i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "substring"
        ],
        "URL": "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.  I want to find the n'th occurrence of a substring in a string.  There's got to be something equivalent to what I WANT to do which is   mystring.find(\"substring\", 2nd)  How can you achieve this in Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Read and overwrite a file in Python",
        "A_Content": "  If you don't want to close and reopen the file, to avoid race conditions, you could truncate it:  f = open(filename, 'r+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.write(text) f.truncate() f.close()   The functionality may also be cleaner and safer using with open as per  mVChr's comment, which is will close the handler, even if an error occurs.  with open(filename, 'r+') as f:     text = f.read()     text = re.sub('foobar', 'bar', text)     f.seek(0)     f.write(text)     f.truncate()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "overwrite"
        ],
        "URL": "https://stackoverflow.com/questions/2424000/read-and-overwrite-a-file-in-python",
        "A_Votes": "149",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Currently I'm using this:  f = open(filename, 'r+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.write(text) f.close()   But the problem is that the old file is larger than the new file. So I end up with a new file that has a part of the old file on the end of it.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Read and overwrite a file in Python",
        "A_Content": "  Probably it would be easier and neater to close the file after text = re.sub('foobar', 'bar', text), re-open it for writing (thus clearing old contents), and write your updated text to it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "overwrite"
        ],
        "URL": "https://stackoverflow.com/questions/2424000/read-and-overwrite-a-file-in-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I'm using this:  f = open(filename, 'r+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.write(text) f.close()   But the problem is that the old file is larger than the new file. So I end up with a new file that has a part of the old file on the end of it.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Read and overwrite a file in Python",
        "A_Content": "  The fileinput module has an inline mode for writing changes to the file you are processing without using temporary files etc.  The module nicely encapsulates the common operation of looping over the lines in a list of files, via an object which transparently keeps track of the file name, line number etc if you should want to inspect them inside the loop.  import fileinput for line in fileinput.FileInput(\"file\",inplace=1):     if \"foobar\" in line:          line=line.replace(\"foobar\",\"bar\")     print line      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "overwrite"
        ],
        "URL": "https://stackoverflow.com/questions/2424000/read-and-overwrite-a-file-in-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I'm using this:  f = open(filename, 'r+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.write(text) f.close()   But the problem is that the old file is larger than the new file. So I end up with a new file that has a part of the old file on the end of it.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Read and overwrite a file in Python",
        "A_Content": "  Try writing it in a new file..  f = open(filename, 'r+') f2= open(filename2,'a+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.close() f2.write(text) fw.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "overwrite"
        ],
        "URL": "https://stackoverflow.com/questions/2424000/read-and-overwrite-a-file-in-python",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I'm using this:  f = open(filename, 'r+') text = f.read() text = re.sub('foobar', 'bar', text) f.seek(0) f.write(text) f.close()   But the problem is that the old file is larger than the new file. So I end up with a new file that has a part of the old file on the end of it.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "TensorFlow, why was python the chosen language?",
        "A_Content": "  The most important thing to realize about TensorFlow is that, for the most part, the core is not written in Python:  It's written in a combination of highly-optimized C++ and CUDA (Nvidia's language for programming GPUs).  Much of that happens, in turn, by using Eigen (a high-performance C++ and CUDA numerical library) and NVidia's cuDNN (a very optimized DNN library for NVidia GPUs, for functions such as convolutions).  The model for TensorFlow is that the programmer uses \"some language\" (most likely Python!) to express the model.  This model, written in the TensorFlow constructs such as:  h1 = tf.nn.relu(tf.matmul(l1, W1) + b1) h2 = ...   is not actually executed when the Python is run.  Instead, what's actually created is a dataflow graph that says to take particular inputs, apply particular operations, supply the results as the inputs to other operations, and so on.  This model is executed by fast C++ code, and for the most part, the data going between operations is never copied back to the Python code.  Then the programmer \"drives\" the execution of this model by pulling on nodes -- for training, usually in Python, and for serving, sometimes in Python and sometimes in raw C++:  sess.run(eval_results)   This one Python (or C++ function call) uses either an in-process call to C++ or an RPC for the distributed version to call into the C++ TensorFlow server to tell it to execute, and then copies back the results.  So, with that said, let's re-phrase the question:  Why did TensorFlow choose  Python as the first well-supported language for expressing and controlling the training of models?  The answer to that is simple:  Python is probably the most comfortable language for a large range of data scientists and machine learning experts that's also that easy to integrate and have control a C++ backend, while also being general, widely-used both inside and outside of Google, and open source.  Given that with the basic model of TensorFlow, the performance of Python isn't that important, it was a natural fit.  It's also a huge plus that NumPy makes it easy to do pre-processing in Python -- also with high performance -- before feeding it in to TensorFlow for the truly CPU-heavy things.  There's also a bunch of complexity in expressing the model that isn't used when executing it -- shape inference (e.g., if you do matmul(A, B), what is the shape of the resulting data?) and automatic gradient computation.  It turns out to have been nice to be able to express those in Python, though I think in the long term they'll probably move to the C++ backend to make adding other languages easier.  (The hope, of course, is to support other languages in the future for creating and expressing models.  It's already quite straightforward to run inference using several other languages -- C++ works now, someone from Facebook contributed Go bindings that we're reviewing now, etc.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "c++",
            "machine-learning",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/35677724/tensorflow-why-was-python-the-chosen-language",
        "A_Votes": "158",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I recently started studying deep learning and other ML techniques, and I started searching for frameworks that simplify the process of build a net and training it, then I found TensorFlow, having little experience in the field, for me, it seems that speed is a big factor for making a big ML system even more if working with deep learning, so why python was chosen by Google to make TensorFlow? Wouldn't it be better to make it over an language that can be compiled and not interpreted?  What are the advantages of using Python over a language like C++ for machine learning?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "TensorFlow, why was python the chosen language?",
        "A_Content": "  TF is not written in python. It is written in C++ (and uses high-performant numerical libraries and CUDA code) and you can check this by looking at their github. So the core is written not in python but TF provide an interface to many other languages (python, C++, Java, Go)    If you come from a data analysis world, you can think about it like numpy (not written in python, but provides an interface to Python) or if you are a web-developer - think about it as a database (PostgreSQL, MySQL, which can be invoked from Java, Python, PHP)    Python frontend (the language in which people write models in TF) is the most popular due to many reasons. In my opinion the main reason is historical: majority of ML users already use it (another popular choice is R) so if you will not provide an interface to python, your library is most probably doomed to obscurity.    But being written in python does not mean that your model is executed in python. On the contrary, if you written your model in the right way Python is never executed during the evaluation of the TF graph (except of tf.py_func(), which exists for debugging and should be avoided in real model exactly because it is executed on Python's side).  This is different from for example numpy. For example if you do np.linalg.eig(np.matmul(A, np.transpose(A)) (which is eig(AA')), the operation will compute transpose in some fast language (C++ or fortran), return it to python, take it from python together with A, and compute a multiplication in some fast language and return it to python, then compute eigenvalues and return it to python. So nonetheless expensive operations like matmul and eig are calculated efficiently, you still lose time by moving the results to python back and force. TF does not do it, once you defined the graph your tensors flow not in python but in C++/CUDA/something else.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "c++",
            "machine-learning",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/35677724/tensorflow-why-was-python-the-chosen-language",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently started studying deep learning and other ML techniques, and I started searching for frameworks that simplify the process of build a net and training it, then I found TensorFlow, having little experience in the field, for me, it seems that speed is a big factor for making a big ML system even more if working with deep learning, so why python was chosen by Google to make TensorFlow? Wouldn't it be better to make it over an language that can be compiled and not interpreted?  What are the advantages of using Python over a language like C++ for machine learning?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "TensorFlow, why was python the chosen language?",
        "A_Content": "  Python allows you to create extension modules using C and C++, interfacing with native code, and still getting the advantages that Python gives you.  TensorFlow uses Python, yes, but it also contains large amounts of C++.  This allows a simpler interface for experimentation with less human-thought overhead with Python, and add performance by programming the most important parts in C++.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "c++",
            "machine-learning",
            "tensorflow"
        ],
        "URL": "https://stackoverflow.com/questions/35677724/tensorflow-why-was-python-the-chosen-language",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently started studying deep learning and other ML techniques, and I started searching for frameworks that simplify the process of build a net and training it, then I found TensorFlow, having little experience in the field, for me, it seems that speed is a big factor for making a big ML system even more if working with deep learning, so why python was chosen by Google to make TensorFlow? Wouldn't it be better to make it over an language that can be compiled and not interpreted?  What are the advantages of using Python over a language like C++ for machine learning?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  First Option - Online Installation (i.e. remaining connected to the Internet during the entire installation process):   Download setuptools-0.6c9.tar.gz Use 7-zip to extract it to a folder(directory) outside your Windows Python installation folder Go the folder (refer step 2) and run ez_setup.py from the corresponding dos (command) prompt Ensure that your PATH includes the appropriate C:\\Python2X\\Scripts directory   Second Option:   Download setuptools-0.6c9.tar.gz Download setuptools-0.6c9-py2.6.egg to a folder(directory) outside your Windows Python installation folder Use 7-zip to extract ez_setup.py in the same folder as setuptools-0.6c9-py2.6.egg Go to the corresponding dos prompt and run python ez_setup.py setuptools-0.6c9-py2.6.egg from the command prompt Ensure that your PATH includes the appropriate C:\\Python2X\\Scripts directory   Third Option (assuming that you have Visual Studio 2005 or MinGW on your machine)   Download setuptools-0.6c9.tar.gz Use 7-zip to extract it to a folder(directory) outside your Windows Python installation folder Go the folder (refer step 2) and run python setup.py install from the corresponding dos (command) prompt   Please provide feedback.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  You could download and run http://peak.telecommunity.com/dist/ez_setup.py. This will download and install setuptools.  [update]  This script no longer works - the version of setuptools the it downloads is not at the URI specified in ez_setup.py -navigate to http://pypi.python.org/packages/2.7/s/setuptools/ for the latest version - the script also does some md5 checking, I haven't looked into it any further.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  The Nov. 21 answer didn't work for me.  I got it working on my 64 bit Vista machine by following the Method 1 instructions, except for Step 3 I typed:  setup.py install  So, in summary, I did:   Download setuptools-0.6c9.tar.gz Use 7-zip to extract it to a folder (directory) outside your Windows Python installation folder At a DOS (command) prompt, cd to your the newly created setuptools-0.6c9 folder and type \"setup.py install\" (without the quotes). Ensure that your PATH includes the appropriate C:\\Python2X\\Scripts directory      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  I'm able to find the EXE doing google,  you can simply download it from following URL, and double click and install....  http://pypi.python.org/packages/2.6/s/setuptools/setuptools-0.6c11.win32-py2.6.exe#md5=1509752c3c2e64b5d0f9589aafe053dc     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  I got it working quickly by downloading the source and then running (from the extracted directory):  python.exe setup.py bdist_wininst   That builds dist\\setuptools-0.6c9.win32.exe, which is exactly the installer you're looking for.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  Just installed setuptools as follows:   Downloaded http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c9.tar.gz#md5=3864c01d9c719c8924c455714492295e , and extracted to a folder outside of my Python installation. command prompt, then cd into that folder. enter python setup.py install   That will install from the source into your python's site-packages folder and any other steps needed. This was on Windows XP SP2.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  The \"first option\" (4 steps: download, extract, run, verify PATH) didn't work on my Windows Server 2008 x64 machine with Python 2.6 32 bit installed, nor did it work on my Vista x64 machine with Python 2.6 32 bit installed.  The \"second option (5 steps: download, extract, extract, run, verify PATH) worked on both Windows Server 2008 x64 and on Windows Vista x64.  Thanks a bunch for providing the instructions!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  OP option 1 did not work for me.  However doing setup.py install as mentioned by NathanD did do the trick.  Maybe that should become option 1?  Werner     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  The easiest setuptools installation option is to use the pre-packaged Windows Installer.  for 32-bit Python on Windows, the official setuptools page has been updated and has windows installers for Python 2.6 and 2.7:   http://pypi.python.org/pypi/setuptools   for 64-bit Python on Windows, setuptools Windows installers are available here:   http://www.lfd.uci.edu/~gohlke/pythonlibs/      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  setuptools has been updated in version 0.6c11.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  My advice is to wait until Python 2.6.2 to use Python 2.6 on Windows.  There are still some bugs that make it less than ideal (this one is particularly nasty).  Personally, I wasn't able to get setuptools working totally well on Vista x64 even after installing from source.  Under Python 2.5.4, I haven't had any problems though.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  Second option worked for me.  Two notes:  a. After installing, when you using easy_install in vista, do so as administrator. (Right click on your command line shortcut and click \"run as administrator\"). I had trouble trying to run easy_install without doing that.  b. He means use ez_setup from setuptools-0.6c9.tar.gz     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  Python has everything on board to do this.  from https://pypi.python.org/pypi/setuptools#installing-and-using-setuptools I got the URL to the ez_setup.py: https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py  instead downloading it and fiddling with the file we can do this from the console:  import urllib url = 'https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py' ezcode = urllib.urlopen(url).read() exec(ezcode)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to setup setuptools for python 2.6 on Windows?",
        "A_Content": "  ActivePython already includes setuptools (Distribute actually), along with pip and virtualenv.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "setuptools"
        ],
        "URL": "https://stackoverflow.com/questions/309412/how-to-setup-setuptools-for-python-2-6-on-windows",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer?   There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it.   Does anyone know of a way to install it anyway?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  Using list comprehension:  >>> lst = [['a','b','c'], [1,2,3], ['x','y','z']] >>> lst2 = [item[0] for item in lst] >>> lst2 ['a', 1, 'x']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  You could use zip:  >>> lst=[[1,2,3],[11,12,13],[21,22,23]] >>> zip(*lst)[0] (1, 11, 21)   Or, Python 3 where zip does not produce a list:  >>> list(zip(*lst))[0] (1, 11, 21)   Or,   >>> next(zip(*lst)) (1, 11, 21)   Or, (my favorite) use numpy:  >>> import numpy as np >>> a=np.array([[1,2,3],[11,12,13],[21,22,23]]) >>> a array([[ 1,  2,  3],        [11, 12, 13],        [21, 22, 23]]) >>> a[:,0] array([ 1, 11, 21])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "53",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  Python includes a function called itemgetter to return the item at a specific index in a list:  from operator import itemgetter   Pass the itemgetter() function the index of the item you want to retrieve.  To retrieve the first item, you would use itemgetter(0).  The important thing to understand is that itemgetter(0) itself returns a function.  If you pass a list to that function, you get the specific item:  itemgetter(0)([10, 20, 30]) # Returns 10   This is useful when you combine it with map(), which takes a function as its first argument, and a list (or any other iterable) as the second argument.  It returns the result of calling the function on each object in the iterable:  my_list = [['a', 'b', 'c'], [1, 2, 3], ['x', 'y', 'z']] list(map(itemgetter(0), my_list)) # Returns ['a', 1, 'x']   Note that map() returns a generator, so the result is passed to list() to get an actual list.  In summary, your task could be done like this:  lst2.append(list(map(itemgetter(0), lst)))   This is an alternative method to using a list comprehension, and which method to choose highly depends on context, readability, and preference.  More info: https://docs.python.org/3/library/operator.html#operator.itemgetter     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  Had the same issue and got curious about the performance of each solution.  Here's is the %timeit:  import numpy as np lst = [['a','b','c'], [1,2,3], ['x','y','z']]   The first numpy-way, transforming the array:  %timeit list(np.array(lst).T[0]) 4.9 µs ± 163 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)   Fully native using list comprehension (as explained by @alecxe):  %timeit [item[0] for item in lst] 379 ns ± 23.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)   Another native way using zip (as explained by @dawg):  %timeit list(zip(*lst))[0] 585 ns ± 7.26 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)   Second numpy-way. Also explained by @dawg:  %timeit list(np.array(lst)[:,0]) 4.95 µs ± 179 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)   Surprisingly (well, at least for me) the native way using list comprehension is the fastest and about 10x faster than the numpy-way. Running the two numpy-ways without the final list saves about one µs which is still in the 10x difference.  Note that, when I surrounded each code snippet with a call to len, to ensure that Generators run till the end, the timing stayed the same.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  Your code is almost correct. The only issue is the usage of list comprehension.  If you use like: (x[0] for x in lst), it returns a generator object. If you use like: [x[0] for x in lst], it return a list.  When you append the list comprehension output to a list, the output of list comprehension is the single element of the list.  lst = [[\"a\",\"b\",\"c\"], [1,2,3], [\"x\",\"y\",\"z\"]] lst2 = [] lst2.append([x[0] for x in lst]) print lst2[0]   lst2    = [['a', 1, 'x']]  lst2[0] = ['a', 1, 'x']  Please let me know if I am incorrect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  lst = [['a','b','c'], [1,2,3], ['x','y','z']] outputlist = [] for values in lst:     outputlist.append(values[0])  print(outputlist)    Output:  ['a', 1, 'x']     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Extract first item of each sublist in python",
        "A_Content": "  You said that you have an existing list. So I'll go with that.  >>> lst1 = [['a','b','c'], [1,2,3], ['x','y','z']] >>> lst2 = [1, 2, 3]   Right now you are appending the generator object to your second list.  >>> lst2.append(item[0] for item in lst) >>> lst2 [1, 2, 3, <generator object <genexpr> at 0xb74b3554>]   But you probably want it to be a list of first items  >>> lst2.append([item[0] for item in lst]) >>> lst2 [1, 2, 3, ['a', 1, 'x']]   Now we appended the list of first items to the existing list. If you'd like to add the items themeselves, not a list of them, to the existing ones, you'd use list.extend. In that case we don't have to worry about adding a generator, because extend will use that generator to add each item it gets from there, to extend the current list.  >>> lst2.extend(item[0] for item in lst) >>> lst2 [1, 2, 3, 'a', 1, 'x']   or  >>> lst2 + [x[0] for x in lst] [1, 2, 3, 'a', 1, 'x'] >>> lst2 [1, 2, 3]   https://docs.python.org/3.4/tutorial/datastructures.html#more-on-lists https://docs.python.org/3.4/tutorial/datastructures.html#list-comprehensions     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/25050311/extract-first-item-of-each-sublist-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering what is the best way to extract a first item of each sublist in a list of lists and append it to a new list. So if i have:   lst = [[a,b,c], [1,2,3], [x,y,z]]   and i want to pull out a, 1 and x and create a seperate list from those.  I tried:  lst2.append(x[0] for x in lst)      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How can I split and parse a string in Python?",
        "A_Content": "  \"2.7.0_bf4fda703454\".split(\"_\") gives a list of strings:  In [1]: \"2.7.0_bf4fda703454\".split(\"_\") Out[1]: ['2.7.0', 'bf4fda703454']   This splits the string at every underscore. If you want it to stop after the first split, use \"2.7.0_bf4fda703454\".split(\"_\", 1).  If you know for a fact that the string contains an underscore, you can even unpack the LHS and RHS into separate variables:  In [8]: lhs, rhs = \"2.7.0_bf4fda703454\".split(\"_\", 1)  In [9]: lhs Out[9]: '2.7.0'  In [10]: rhs Out[10]: 'bf4fda703454'   An alternative pointed out by @S.Lott is to use partition. The usage is similar to the last example, except that it returns three components instead of two. The principal advantage is that this method doesn't fail if the string doesn't contain the separator. This method, however, requires Python 2.5.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "parsing",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/5749195/how-can-i-split-and-parse-a-string-in-python",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to split this string in python: 2.7.0_bf4fda703454  I want to split that string on the underscore _ so that I can use the value on the left side.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How can I split and parse a string in Python?",
        "A_Content": "  Python string parsing walkthrough  Split a string on space, get a list, show its type, print it out:  el@apollo:~/foo$ python >>> mystring = \"What does the fox say?\"  >>> mylist = mystring.split(\" \")  >>> print type(mylist) <type 'list'>  >>> print mylist ['What', 'does', 'the', 'fox', 'say?']   If you have two delimiters next to each other, empty string is assumed:  el@apollo:~/foo$ python >>> mystring = \"its  so   fluffy   im gonna    DIE!!!\"  >>> print mystring.split(\" \") ['its', '', 'so', '', '', 'fluffy', '', '', 'im', 'gonna', '', '', '', 'DIE!!!']   Split a string on underscore and grab the 5th item in the list:  el@apollo:~/foo$ python >>> mystring = \"Time_to_fire_up_Kowalski's_Nuclear_reactor.\"  >>> mystring.split(\"_\")[4] \"Kowalski's\"   Collapse multiple spaces into one  el@apollo:~/foo$ python >>> mystring = 'collapse    these       spaces'  >>> mycollapsedstring = ' '.join(mystring.split())  >>> print mycollapsedstring.split(' ') ['collapse', 'these', 'spaces']   When you pass no parameter to Python's split method, the documentation states: \"runs of consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace\".  Hold onto your hats boys, parse on a regular expression:  el@apollo:~/foo$ python >>> mystring = 'zzzzzzabczzzzzzdefzzzzzzzzzghizzzzzzzzzzzz' >>> import re >>> mylist = re.split(\"[a-m]+\", mystring) >>> print mylist ['zzzzzz', 'zzzzzz', 'zzzzzzzzz', 'zzzzzzzzzzzz']   The regular expression \"[a-m]+\" means the lowercase letters a through m that occur one or more times are matched as a delimiter. re is a library to be imported.  Or if you want to chomp the items one at a time:  el@apollo:~/foo$ python >>> mystring = \"theres coffee in that nebula\"  >>> mytuple = mystring.partition(\" \")  >>> print type(mytuple) <type 'tuple'>  >>> print mytuple ('theres', ' ', 'coffee in that nebula')  >>> print mytuple[0] theres  >>> print mytuple[2] coffee in that nebula      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "parsing",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/5749195/how-can-i-split-and-parse-a-string-in-python",
        "A_Votes": "61",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to split this string in python: 2.7.0_bf4fda703454  I want to split that string on the underscore _ so that I can use the value on the left side.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How can I split and parse a string in Python?",
        "A_Content": "  If it's always going to be an even LHS/RHS split, you can also use the partition method that's built into strings. It returns a 3-tuple as (LHS, separator, RHS) if the separator is found, and (original_string, '', '') if the separator wasn't present:  >>> \"2.7.0_bf4fda703454\".partition('_') ('2.7.0', '_', 'bf4fda703454')  >>> \"shazam\".partition(\"_\") ('shazam', '', '')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "parsing",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/5749195/how-can-i-split-and-parse-a-string-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to split this string in python: 2.7.0_bf4fda703454  I want to split that string on the underscore _ so that I can use the value on the left side.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I convert hex to decimal in Python? [duplicate]",
        "A_Content": "  If by \"hex data\" you mean a string of the form  s = \"6a48f82d8e828ce82b82\"   you can use  i = int(s, 16)   to convert it to an integer and  str(i)   to convert it to a decimal string.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hex",
            "decimal"
        ],
        "URL": "https://stackoverflow.com/questions/9210525/how-do-i-convert-hex-to-decimal-in-python",
        "A_Votes": "160",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Convert hex string to int in Python                                        9 answers                                          I have some Perl code where the hex() function converts hex data to decimal. How can I do it on Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I convert hex to decimal in Python? [duplicate]",
        "A_Content": "  >>> int(\"0xff\", 16) 255   or  >>> int(\"FFFF\", 16) 65535   Read the docs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "hex",
            "decimal"
        ],
        "URL": "https://stackoverflow.com/questions/9210525/how-do-i-convert-hex-to-decimal-in-python",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Convert hex string to int in Python                                        9 answers                                          I have some Perl code where the hex() function converts hex data to decimal. How can I do it on Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I convert hex to decimal in Python? [duplicate]",
        "A_Content": "  You could use a literal eval:  >>> ast.literal_eval('0xdeadbeef') 3735928559   Or just specify the base as argument to int:  >>> int('deadbeef', 16) 3735928559      ",
        "Language": "Python",
        "Tags": [
            "python",
            "hex",
            "decimal"
        ],
        "URL": "https://stackoverflow.com/questions/9210525/how-do-i-convert-hex-to-decimal-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Convert hex string to int in Python                                        9 answers                                          I have some Perl code where the hex() function converts hex data to decimal. How can I do it on Python?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  You could also use the EPEL-repository, and then do sudo yum install python26 to install python 2.6     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "78",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  Try epel  wget http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm sudo rpm -ivh epel-release-5-4.noarch.rpm sudo yum install python26   The python executable will be available at /usr/bin/python26  mkdir -p ~/bin ln -s /usr/bin/python26 ~/bin/python export PATH=~/bin:$PATH # Append this to your ~/.bash_profile for persistence   Now, python command will execute python 2.6     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  When I've run into similar situations, I generally avoid the package manager, especially if it would be embarrassing to break something, i.e. a production server. Instead, I would go to Activestate and download their binary package:  https://www.activestate.com/activepython/downloads/  This is installed by running a script which places everything into a folder and does not touch any system files. In fact, you don't even need root permissions to set it up. Then I change the name of the binary to something like apy26, add that folder to the end of the PATH and start coding. If you install packages with apy26 setup.py installor if you use virtualenv and easyinstall, then you have just as flexible a python environment as you need without touching the system standard python.  Edits... Recently I've done some work to build a portable Python binary for Linux that should run on any distro with no external dependencies. This means that any binary shared libraries needed by the portable Python module are part of the build, included in the tarball and installed in Python's private directory structure. This way you can install Python for your application without interfering with the system installed Python.  My github site has a build script which has been thoroughly tested on Ubuntu Lucid 10.04 LTS both 32 and 64 bit installs. I've also built it on Debian Etch but that was a while ago and I can't guarantee that I haven't changed something. The easiest way to do this is you just put your choice of Ubuntu Lucid in a virtual machine, checkout the script with git clone git://github.com/wavetossed/pybuild.git and then run the script.   Once you have it built, use the tarball on any recent Linux distro. There is one little wrinkle with moving it to a directory other than /data1/packages/python272 which is that you have to run the included patchelf to set the interpreter path BEFORE you move the directory. This affects any binaries in /data1/packages/python272/bin  All of this is based on building with RUNPATH and copying the dependent shared libraries. Even though the script is in several files, it is effectively one long shell script arranged in the style of /etc/rc.d directories.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  No need to do yum or make your own RPM. Build python26 from source.  wget https://www.python.org/ftp/python/2.6.6/Python-2.6.6.tgz tar -zxvf Python-2.6.6.tgz cd Python-2.6.6 ./configure && make && make install   There can be a dependency error use   yum install gcc cc   Add the install path (/usr/local/bin/python by default) to ~/.bash_profile.  It will not break yum or any other things which are dependent on python24.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  No, that's it. You might want to make sure you have all optional library headers installed too so you don't have to recompile it later. They are listed in the documentation I think.  Also, you can install it even in the standard path if you do make altinstall. That way it won't override your current default \"python\".     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  Chris Lea provides a YUM repository for python26 RPMs that can co-exist with the 'native' 2.4 that is needed for quite a few admin tools on CentOS.  Quick instructions that worked at least for me:  $ sudo rpm -Uvh http://yum.chrislea.com/centos/5/i386/chl-release-5-3.noarch.rpm $ sudo rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CHL $ sudo yum install python26 $ python26      ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  If you want to make it easier on yourself, there are CentOS RPMs for new Python versions floating around the net. E.g. see:  http://www.geekymedia.com/python_26_centos.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  When you install your python version (in this case it is python2.6) then issue this command to create your virtualenv:  virtualenv -p /usr/bin/python2.6 /your/virtualenv/path/here/      ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  Late to the party, but the OP should have gone with Buildout or Virtualenv, and sidestepped the problem completely.  I am currently working on a Centos server, well, toiling away would be the proper term and I can assure everyone that the only way I am able to blink back the tears whilst using the software equivalents of fire hardened spears, is  buildout.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  you can always make your own RPM:  http://www.grenadepod.com/2009/12/26/building-python-2-6-4-rpm-for-centos-5-4/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  Missing Dependency: libffi.so.5  is here :   ftp://ftp.pbone.net/mirror/centos.karan.org/el5/extras/testing/i386/RPMS/libffi-3.0.5-1.el5.kb.i386.rpm     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  rpm -Uvh http://yum.chrislea.com/centos/5/i386/chl-release-5-3.noarch.rpm rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CHL rpm -Uvh ftp://ftp.pbone.net/mirror/centos.karan.org/el5/extras/testing/i386/RPMS/libffi-3.0.5-1.el5.kb.i386.rpm yum install python26 python26   for dos that just dont know :=)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  # yum groupinstall \"Development tools\" # yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel   Download and install Python 3.3.0  # wget http://python.org/ftp/python/3.3.0/Python-3.3.0.tar.bz2 # tar xf Python-3.3.0.tar.bz2 # cd Python-3.3.0 # ./configure --prefix=/usr/local # make && make altinstall   Download and install Distribute for Python 3.3  # wget http://pypi.python.org/packages/source/d/distribute/distribute-0.6.35.tar.gz # tar xf distribute-0.6.35.tar.gz # cd distribute-0.6.35 # python3.3 setup.py install   Install and use virtualenv for Python 3.3  # easy_install-3.3 virtualenv # virtualenv-3.3 --distribute otherproject  New python executable in otherproject/bin/python3.3 Also creating executable in otherproject/bin/python Installing distribute...................done. Installing pip................done.  # source otherproject/bin/activate # python --version Python 3.3.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  I unistalled the original version of python (2.6.6) and install 2.7(with option make && make altinstall) but when I tried install something with yum didn't work.  So I solved this issue as follow:   # ln -s /usr/local/bin/python /usr/bin/python Download the RPM package python-2.6.6-36.el6.i686.rpm from http://rpm.pbone.net/index.php3/stat/4/idpl/20270470/dir/centos_6/com/python-2.6.6-36.el6.i686.rpm.html Execute as root rpm -Uvh python-2.6.6-36.el6.i686.rpm   Done     ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Install python 2.6 in CentOS",
        "A_Content": "  Type the following commands on the terminal to install Python 3.6 on CentOS 7:  $ sudo yum install https://centos7.iuscommunity.org/ius-release.rpm   Then do :  $ sudo yum install python36u    You can also install any version instead of 3.6 (if you want to) by just replacing 36 by your version number.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "centos",
            "rpath"
        ],
        "URL": "https://stackoverflow.com/questions/1465036/install-python-2-6-in-centos",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a shell that runs CentOS.  For a project I'm doing, I need python 2.5+, but centOS is pretty dependent on 2.4.  From what I've read, a number of things will break if you upgrade to 2.5.  I want to install 2.5 separately from 2.4, but I'm not sure how to do it. So far I've downloaded the source tarball, untarred it, and did a ./configure --prefix=/opt which is where I want it to end up. Can I now just make, make install ? Or is there more?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do we determine the number of days for a given month in python [duplicate]",
        "A_Content": "  Use calendar.monthrange:  >>> from calendar import monthrange >>> monthrange(2011, 2) (1, 28)   Just to be clear, monthrange supports leap years as well:  >>> from calendar import monthrange >>> monthrange(2012, 2) (2, 29)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4938429/how-do-we-determine-the-number-of-days-for-a-given-month-in-python",
        "A_Votes": "189",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Get Last Day of the Month in Python                                        24 answers                                          I need to calculate the number of days for a given month in python. If a user inputs Feb 2011 the program should be able to tell me that Feb 2011 has 28 days. Could any one tell me which library I should use to determine the length of a given month.       ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do we determine the number of days for a given month in python [duplicate]",
        "A_Content": "  Alternative solution:  >>> from datetime import date >>> (date(2012, 3, 1) - date(2012, 2, 1)).days 29      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4938429/how-do-we-determine-the-number-of-days-for-a-given-month-in-python",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Get Last Day of the Month in Python                                        24 answers                                          I need to calculate the number of days for a given month in python. If a user inputs Feb 2011 the program should be able to tell me that Feb 2011 has 28 days. Could any one tell me which library I should use to determine the length of a given month.       ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do we determine the number of days for a given month in python [duplicate]",
        "A_Content": "  Just for the sake of academic interest, I did it this way...  (dt.replace(month = dt.month % 12 +1, day = 1)-timedelta(days=1)).day      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4938429/how-do-we-determine-the-number-of-days-for-a-given-month-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Get Last Day of the Month in Python                                        24 answers                                          I need to calculate the number of days for a given month in python. If a user inputs Feb 2011 the program should be able to tell me that Feb 2011 has 28 days. Could any one tell me which library I should use to determine the length of a given month.       ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Convert Pandas Column to DateTime",
        "A_Content": "  Use the to_datetime function, specifying a format to match your data.  raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26763344/convert-pandas-column-to-datetime",
        "A_Votes": "183",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have one field in a pandas DataFrame that was imported as string format.  It should be a datetime variable. How do I convert it to a datetime column and then filter based on date.  Example:   DataFrame Name: raw_data     Column Name: Mycol     Value Format in Column: '05SEP2014:00:00:00.000'      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Convert Pandas Column to DateTime",
        "A_Content": "  You can use the DataFrame method .apply() to operate on the values in Mycol:  >>> df = pd.DataFrame(['05SEP2014:00:00:00.000'],columns=['Mycol']) >>> df                     Mycol 0  05SEP2014:00:00:00.000 >>> import datetime as dt >>> df['Mycol'] = df['Mycol'].apply(lambda x:                                      dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f')) >>> df        Mycol 0 2014-09-05      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26763344/convert-pandas-column-to-datetime",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have one field in a pandas DataFrame that was imported as string format.  It should be a datetime variable. How do I convert it to a datetime column and then filter based on date.  Example:   DataFrame Name: raw_data     Column Name: Mycol     Value Format in Column: '05SEP2014:00:00:00.000'      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Convert Pandas Column to DateTime",
        "A_Content": "  raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')   works, however it results in a Python warning of  A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead  I would guess this is due to some chaining indexing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/26763344/convert-pandas-column-to-datetime",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have one field in a pandas DataFrame that was imported as string format.  It should be a datetime variable. How do I convert it to a datetime column and then filter based on date.  Example:   DataFrame Name: raw_data     Column Name: Mycol     Value Format in Column: '05SEP2014:00:00:00.000'      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  Distribution Fitting with Sum of Square Error (SSE)  This is an update and modification to Saullo's answer, that uses the full list of the current scipy.stats distributions and returns the distribution with the least SSE between the distribution's histogram and the data's histogram.  Example Fitting  Using the El Niño dataset from statsmodels, the distributions are fit and error is determined. The distribution with the least error is returned.    All Distributions    Best Fit Distribution    Example Code  %matplotlib inline  import warnings import numpy as np import pandas as pd import scipy.stats as st import statsmodels as sm import matplotlib import matplotlib.pyplot as plt  matplotlib.rcParams['figure.figsize'] = (16.0, 12.0) matplotlib.style.use('ggplot')  # Create models from data def best_fit_distribution(data, bins=200, ax=None):     \"\"\"Model data by finding best fit distribution to data\"\"\"     # Get histogram of original data     y, x = np.histogram(data, bins=bins, density=True)     x = (x + np.roll(x, -1))[:-1] / 2.0      # Distributions to check     DISTRIBUTIONS = [                 st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,         st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,         st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,         st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,         st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,         st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,         st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,         st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,         st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,         st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy     ]      # Best holders     best_distribution = st.norm     best_params = (0.0, 1.0)     best_sse = np.inf      # Estimate distribution parameters from data     for distribution in DISTRIBUTIONS:          # Try to fit the distribution         try:             # Ignore warnings from data that can't be fit             with warnings.catch_warnings():                 warnings.filterwarnings('ignore')                  # fit dist to data                 params = distribution.fit(data)                  # Separate parts of parameters                 arg = params[:-2]                 loc = params[-2]                 scale = params[-1]                  # Calculate fitted PDF and error with fit in distribution                 pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)                 sse = np.sum(np.power(y - pdf, 2.0))                  # if axis pass in add to plot                 try:                     if ax:                         pd.Series(pdf, x).plot(ax=ax)                     end                 except Exception:                     pass                  # identify if this distribution is better                 if best_sse > sse > 0:                     best_distribution = distribution                     best_params = params                     best_sse = sse          except Exception:             pass      return (best_distribution.name, best_params)  def make_pdf(dist, params, size=10000):     \"\"\"Generate distributions's Probability Distribution Function \"\"\"      # Separate parts of parameters     arg = params[:-2]     loc = params[-2]     scale = params[-1]      # Get sane start and end points of distribution     start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)     end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)      # Build PDF and turn into pandas Series     x = np.linspace(start, end, size)     y = dist.pdf(x, loc=loc, scale=scale, *arg)     pdf = pd.Series(y, x)      return pdf  # Load data from statsmodels datasets data = pd.Series(sm.datasets.elnino.load_pandas().data.set_index('YEAR').values.ravel())  # Plot for comparison plt.figure(figsize=(12,8)) ax = data.plot(kind='hist', bins=50, normed=True, alpha=0.5, color=plt.rcParams['axes.color_cycle'][1]) # Save plot limits dataYLim = ax.get_ylim()  # Find best fit distribution best_fit_name, best_fit_params = best_fit_distribution(data, 200, ax) best_dist = getattr(st, best_fit_name)  # Update plots ax.set_ylim(dataYLim) ax.set_title(u'El Niño sea temp.\\n All Fitted Distributions') ax.set_xlabel(u'Temp (°C)') ax.set_ylabel('Frequency')  # Make PDF pdf = make_pdf(best_dist, best_fir_paramms)  # Display plt.figure(figsize=(12,8)) ax = pdf.plot(lw=2, label='PDF', legend=True) data.plot(kind='hist', bins=50, normed=True, alpha=0.5, label='Data', legend=True, ax=ax)  param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale'] param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)]) dist_str = '{}({})'.format(best_fit_name, param_str)  ax.set_title(u'El Niño sea temp. with best fit distribution \\n' + dist_str) ax.set_xlabel(u'Temp. (°C)') ax.set_ylabel('Frequency')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  There are 82 implemented distribution functions in SciPy 0.12.0. You can test how some of them fit to your data using their fit() method. Check the code below for more details:    import matplotlib.pyplot as plt import scipy import scipy.stats size = 30000 x = scipy.arange(size) y = scipy.int_(scipy.round_(scipy.stats.vonmises.rvs(5,size=size)*47)) h = plt.hist(y, bins=range(48), color='w')  dist_names = ['gamma', 'beta', 'rayleigh', 'norm', 'pareto']  for dist_name in dist_names:     dist = getattr(scipy.stats, dist_name)     param = dist.fit(y)     pdf_fitted = dist.pdf(x, *param[:-2], loc=param[-2], scale=param[-1]) * size     plt.plot(pdf_fitted, label=dist_name)     plt.xlim(0,47) plt.legend(loc='upper right') plt.show()   References:  - Fitting distributions, goodness of fit, p-value. Is it possible to do this with Scipy (Python)?  - Distribution fitting with Scipy  And here a list with the names of all distribution functions available in Scipy 0.12.0 (VI):  dist_names = [ 'alpha', 'anglit', 'arcsine', 'beta', 'betaprime', 'bradford', 'burr', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'ksone', 'kstwobign', 'laplace', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'wald', 'weibull_min', 'weibull_max', 'wrapcauchy']       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  fit() method mentioned by @Saullo Castro provides maximum likelihood estimates (MLE).  The best distribution for your data is the one give you the highest can be determined by several different ways: such as  1, the one that gives you the highest log likelihood.  2, the one that gives you the smallest AIC, BIC or BICc values (see wiki: http://en.wikipedia.org/wiki/Akaike_information_criterion, basically can be viewed as log likelihood adjusted for number of parameters, as distribution with more parameters are expected to fit better)  3, the one that maximize the Bayesian posterior probability. (see wiki: http://en.wikipedia.org/wiki/Posterior_probability)  Of course, if you already have a distribution that should describe you data (based on the theories in your particular field) and want to stick to that, you will skip the step of identifying the best fit distribution.  scipy does not come with a function to calculate log likelihood (although MLE method is provided), but hard code one is easy: see Is the build-in probability density functions of `scipy.stat.distributions` slower than a user provided one?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  AFAICU, your distribution is discrete (and nothing but discrete). Therefore just counting the frequencies of different values and normalizing them should be enough for your purposes. So, an example to demonstrate this:  In []: values= [0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4] In []: counts= asarray(bincount(values), dtype= float) In []: cdf= counts.cumsum()/ counts.sum()   Thus, probability of seeing values higher than 1 is simply (according to the complementary cumulative distribution function (ccdf):  In []: 1- cdf[1] Out[]: 0.40000000000000002   Please note that ccdf is closely related to survival function (sf), but it's also defined with discrete distributions, whereas sf is defined only for contiguous distributions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  It sounds like probability density estimation problem to me.  from scipy.stats import gaussian_kde occurences = [0,0,0,0,..,1,1,1,1,...,2,2,2,2,...,47] values = range(0,48) kde = gaussian_kde(map(float, occurences)) p = kde(values) p = p/sum(p) print \"P(x>=1) = %f\" % sum(p[1:])   Also see http://jpktd.blogspot.com/2009/03/using-gaussian-kernel-density.html.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Fitting empirical distribution to theoretical ones with Scipy (Python)?",
        "A_Content": "  Forgive me if I don't understand your need but what about storing your data in a dictionary where keys would be the numbers between 0 and 47 and values the number of occurrences of their related keys in your original list? Thus your likelihood p(x) will be the sum of all the values for keys greater than x divided by 30000.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "statistics",
            "scipy",
            "distribution"
        ],
        "URL": "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    INTRODUCTION: I have a list of more than 30 000 values ranging from 0 to 47 e.g.[0,0,0,0,..,1,1,1,1,...,2,2,2,2,..., 47 etc.] which is the continuous distribution.   PROBLEM: Based on my distribution I would like to calculate p-value (the probability of seeing greater values) for any given value. For example, as you can see p-value for 0 would be approaching 1 and p-value for higher numbers would be tending to 0.  I don't know if I am right, but to determine probabilities I think I need to fit my data to a theoretical distribution that is the most suitable to describe my data. I assume that some kind of goodness of fit test is needed to determine the best model.  Is there a way to implement such an analysis in Python (Scipy or Numpy)? Could you present any examples?  Thank you!     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Does Flask support regular expressions in its URL routing?",
        "A_Content": "  Even though Armin beat me to the punch with an accepted answer I thought I'd show an abbreviated example of how I implemented a regex matcher in Flask just in case anyone wants a working example of how this could be done.  from flask import Flask from werkzeug.routing import BaseConverter  app = Flask(__name__)  class RegexConverter(BaseConverter):     def __init__(self, url_map, *items):         super(RegexConverter, self).__init__(url_map)         self.regex = items[0]   app.url_map.converters['regex'] = RegexConverter  @app.route('/<regex(\"[abcABC0-9]{4,6}\"):uid>-<slug>/') def example(uid, slug):     return \"uid: %s, slug: %s\" % (uid, slug)   if __name__ == '__main__':     app.run(debug=True, host='0.0.0.0', port=5000)   this URL should return with 200: http://localhost:5000/abc0-foo/  this URL should will return with 404: http://localhost:5000/abcd-foo/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/5870188/does-flask-support-regular-expressions-in-its-url-routing",
        "A_Votes": "165",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I understand that Flask has the int, float and path converters, but the application we're developing has more complex patterns in its URLs.  Is there a way we can use regular expressions, as in Django?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Does Flask support regular expressions in its URL routing?",
        "A_Content": "  You can hook in custom converters that match for arbitrary expressions: Custom Converter  from random import randrange from werkzeug.routing import Rule, Map, BaseConverter, ValidationError  class BooleanConverter(BaseConverter):      def __init__(self, url_map, randomify=False):         super(BooleanConverter, self).__init__(url_map)         self.randomify = randomify         self.regex = '(?:yes|no|maybe)'      def to_python(self, value):         if value == 'maybe':             if self.randomify:                 return not randrange(2)             raise ValidationError()         return value == 'yes'      def to_url(self, value):         return value and 'yes' or 'no'  url_map = Map([     Rule('/vote/<bool:werkzeug_rocks>', endpoint='vote'),     Rule('/vote/<bool(randomify=True):foo>', endpoint='foo') ], converters={'bool': BooleanConverter})      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/5870188/does-flask-support-regular-expressions-in-its-url-routing",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I understand that Flask has the int, float and path converters, but the application we're developing has more complex patterns in its URLs.  Is there a way we can use regular expressions, as in Django?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Does Flask support regular expressions in its URL routing?",
        "A_Content": "  You could also write a catch all type of route and do complex routing within the method:  from flask import Flask app = Flask(__name__)  @app.route('/', methods=['GET', 'POST'], defaults={'path': ''}) @app.route('/<path:path>', methods=['GET', 'POST']) def catch_all(path):     return 'You want path: %s' % path  if __name__ == '__main__':     app.run()   This will match any request. See more details here: Catch-All URL.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/5870188/does-flask-support-regular-expressions-in-its-url-routing",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I understand that Flask has the int, float and path converters, but the application we're developing has more complex patterns in its URLs.  Is there a way we can use regular expressions, as in Django?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  I use this context manager to capture output. It ultimately uses the same technique as some of the other answers by temporarily replacing sys.stdout. I prefer the context manager because it wraps all the bookkeeping into a single function, so I don't have to re-write any try-finally code, and I don't have to write setup and teardown functions just for this.  import sys from contextlib import contextmanager from StringIO import StringIO  @contextmanager def captured_output():     new_out, new_err = StringIO(), StringIO()     old_out, old_err = sys.stdout, sys.stderr     try:         sys.stdout, sys.stderr = new_out, new_err         yield sys.stdout, sys.stderr     finally:         sys.stdout, sys.stderr = old_out, old_err   Use it like this:  with captured_output() as (out, err):     foo() # This can go inside or outside the `with` block output = out.getvalue().strip() self.assertEqual(output, 'hello world!')   Furthermore, since the original output state is restored upon exiting the with block, we can set up a second capture block in the same function as the first one, which isn't possible using setup and teardown functions, and gets wordy when writing try-finally blocks manually. That ability came in handy when the goal of a test was to compare the results of two functions relative to each other rather than to some precomputed value.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "82",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  If you really want to do this, you can reassign sys.stdout for the duration of the test.  def test_foo():     import sys     from foomodule import foo     from StringIO import StringIO      saved_stdout = sys.stdout     try:         out = StringIO()         sys.stdout = out         foo()         output = out.getvalue().strip()         assert output == 'hello world!'     finally:         sys.stdout = saved_stdout   If I were writing this code, however, I would prefer to pass an optional out parameter to the foo function.  def foo(out=sys.stdout):     out.write(\"hello, world!\")   Then the test is much simpler:  def test_foo():     from foomodule import foo     from StringIO import StringIO      out = StringIO()     foo(out=out)     output = out.getvalue().strip()     assert output == 'hello world!'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  Since version 2.7, you do not need anymore to reassign sys.stdout, this is provided through buffer flag. Moreover, it is the default behavior of nosetest.  Here is a sample failing in non buffered context:  import sys import unittest  def foo():     print 'hello world!'  class Case(unittest.TestCase):     def test_foo(self):         foo()         if not hasattr(sys.stdout, \"getvalue\"):             self.fail(\"need to run in buffered mode\")         output = sys.stdout.getvalue().strip() # because stdout is an StringIO instance         self.assertEquals(output,'hello world!')   You can set buffer through unit2 command line flag -b, --buffer or in unittest.main options. The opposite is achieved through nosetest flag --nocapture.  if __name__==\"__main__\":        assert not hasattr(sys.stdout, \"getvalue\")     unittest.main(module=__name__, buffer=True, exit=False)     #.     #----------------------------------------------------------------------     #Ran 1 test in 0.000s     #     #OK     assert not hasattr(sys.stdout, \"getvalue\")      unittest.main(module=__name__, buffer=False)     #hello world!     #F     #======================================================================     #FAIL: test_foo (__main__.Case)     #----------------------------------------------------------------------     #Traceback (most recent call last):     #  File \"test_stdout.py\", line 15, in test_foo     #    self.fail(\"need to run in buffered mode\")     #AssertionError: need to run in buffered mode     #     #----------------------------------------------------------------------     #Ran 1 test in 0.002s     #     #FAILED (failures=1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  A lot of these answers failed for me because you can't from StringIO import StringIO in Python 3. Here's a minimum working snippet based on @naxa's comment and the Python Cookbook.  from io import StringIO from unittest.mock import patch  with patch('sys.stdout', new=StringIO()) as fakeOutput:     print('hello world')     self.assertEqual(fakeOutput.getvalue().strip(), 'hello world')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  I'm only just learning Python and found myself struggling with a similar problem to the one above with unit tests for methods with output. My passing unit test for foo module above has ended up looking like this:  import sys import unittest from foo import foo from StringIO import StringIO  class FooTest (unittest.TestCase):     def setUp(self):         self.held, sys.stdout = sys.stdout, StringIO()      def test_foo(self):         foo()         self.assertEqual(sys.stdout.getvalue(),'hello world!\\n')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  In python 3.5 you can use contextlib.redirect_stdout() and StringIO(). Here's the modification to your code  import contextlib from io import StringIO from foomodule import foo  def test_foo():     temp_stdout = StringIO()     with contextlib.redirect_stdout(temp_stdout):         foo()     output = temp_stdout.getvalue().strip()     assert output == 'hello world!'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  Writing tests often shows us a better way to write our code. Similar to Shane's answer, I'd like to suggest yet another way of looking at this. Do you really want to assert that your program outputted a certain string, or just that it constructed a certain string for output? This becomes easier to test, since we can probably assume that the Python print statement does its job correctly.  def foo_msg():     return 'hello world'  def foo():     print foo_msg()   Then your test is very simple:  def test_foo_msg():     assert 'hello world' == foo_msg()   Of course, if you really have a need to test your program's actual output, then feel free to disregard. :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  Based on Rob Kennedy's answer, I wrote a class-based version of the context manager to buffer the output.  Usage is like:  with OutputBuffer() as bf:     print('hello world') assert bf.out == 'hello world\\n'   Here's the implementation:  from io import StringIO import sys   class OutputBuffer(object):      def __init__(self):         self.stdout = StringIO()         self.stderr = StringIO()      def __enter__(self):         self.original_stdout, self.original_stderr = sys.stdout, sys.stderr         sys.stdout, sys.stderr = self.stdout, self.stderr         return self      def __exit__(self, exception_type, exception, traceback):         sys.stdout, sys.stderr = self.original_stdout, self.original_stderr      @property     def out(self):         return self.stdout.getvalue()      @property     def err(self):         return self.stderr.getvalue()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How to assert output with nosetest/unittest in python?",
        "A_Content": "  Or consider using pytest, it has built-in support for asserting stdout and stderr. See docs  def test_myoutput(capsys): # or use \"capfd\" for fd-level     print(\"hello\")     captured = capsys.readouterr()     assert captured.out == \"hello\\n\"     print(\"next\")     captured = capsys.readouterr()     assert captured.out == \"next\\n\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "nosetests",
            "python-nose"
        ],
        "URL": "https://stackoverflow.com/questions/4219717/how-to-assert-output-with-nosetest-unittest-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing tests for a function like next one:  def foo():     print 'hello world!'   So when I want to test this function the code will be like this:  import sys from foomodule import foo def test_foo():     foo()     output = sys.stdout.getline().strip() # because stdout is an StringIO instance     assert output == 'hello world!'   But if I run nosetests with -s parameter the test crashes. How can I catch the output with unittest or nose module?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  The answer by Ber - storing it in threadlocals - is a very bad idea. There's absolutely no reason to do it this way.  A much better way is to override the form's __init__ method to take an extra keyword argument, request. This stores the request in the form, where it's required, and from where you can access it in your clean method.  class MyForm(forms.Form):      def __init__(self, *args, **kwargs):         self.request = kwargs.pop('request', None)         super(MyForm, self).__init__(*args, **kwargs)       def clean(self):         ... access the request object via self.request ...   and in your view:  myform = MyForm(request.POST, request=request)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  UPDATED 10/25/2011: I'm now using this with a metaclass instead of method, as Django 1.3 displays some weirdness otherwise.  class MyModelAdmin(admin.ModelAdmin):     form = MyCustomForm     def get_form(self, request, obj=None, **kwargs):         ModelForm = super(MyModelAdmin, self).get_form(request, obj, **kwargs)         class ModelFormMetaClass(ModelForm):             def __new__(cls, *args, **kwargs):                 kwargs['request'] = request                 return ModelForm(*args, **kwargs)         return ModelFormMetaClass   Then override MyCustomForm.__init__ as follows:  class MyCustomForm(forms.ModelForm):     def __init__(self, *args, **kwargs):         self.request = kwargs.pop('request', None)         super(MyCustomForm, self).__init__(*args, **kwargs)   You can then access the request object from any method of ModelForm with self.request.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  For what it's worth, if you're using Class Based Views, instead of function based views, override get_form_kwargs in your editing view. Example code for a custom CreateView:  from braces.views import LoginRequiredMixin  class MyModelCreateView(LoginRequiredMixin, CreateView):     template_name = 'example/create.html'     model = MyModel     form_class = MyModelForm     success_message = \"%(my_object)s added to your site.\"      def get_form_kwargs(self):         kw = super(MyModelCreateView, self).get_form_kwargs()         kw['request'] = self.request # the trick!         return kw      def form_valid(self):         # do something   The above view code will make request available as one of the keyword arguments to the form's __init__ constructor function. Therefore in your ModelForm do:  class MyModelForm(forms.ModelForm):     class Meta:         model = MyModel      def __init__(self, *args, **kwargs):         # important to \"pop\" added kwarg before call to parent's constructor         self.request = kwargs.pop('request')         super(MyModelForm, self).__init__(*args, **kwargs)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  The usual aproach is to store the request object in a thread-local reference using a middleware. Then you can access this from anywhere in you app, including the Form.clean() method.  Changing the signature of the Form.clean() method means you have you own, modified version of Django, which may not be what you want.  Thank middleware count look something like this:  import threading _thread_locals = threading.local()  def get_current_request():     return getattr(_thread_locals, 'request', None)  class ThreadLocals(object):     \"\"\"     Middleware that gets various objects from the     request object and saves them in thread local storage.     \"\"\"     def process_request(self, request):         _thread_locals.request = request   Register this middleware as described in the Django docs     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  For Django admin, in Django 1.8  class MyModelAdmin(admin.ModelAdmin):     ...     form = RedirectForm      def get_form(self, request, obj=None, **kwargs):         form = super(MyModelAdmin, self).get_form(request, obj=obj, **kwargs)         form.request = request         return form      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  I ran into this particular problem when customizing the admin. I wanted a certain field to be validated based on the particular admin's credentials.  Since I did not want to modify the view to pass the request as an argument to the form, the following is what I did:  class MyCustomForm(forms.ModelForm):     class Meta:         model = MyModel      def clean(self):         # make use of self.request here  class MyModelAdmin(admin.ModelAdmin):     form = MyCustomForm     def get_form(self, request, obj=None, **kwargs):         ModelForm = super(MyModelAdmin, self).get_form(request, obj=obj, **kwargs)         def form_wrapper(*args, **kwargs):             a = ModelForm(*args, **kwargs)             a.request = request             return a     return form_wrapper      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  You can't always use this method (and its probably bad practice), but if you are only using the form in one view you could scope it inside the view method itself.  def my_view(request):      class ResetForm(forms.Form):         password = forms.CharField(required=True, widget=forms.PasswordInput())          def clean_password(self):             data = self.cleaned_data['password']             if not request.user.check_password(data):                 raise forms.ValidationError(\"The password entered does not match your account password.\")             return data      if request.method == 'POST':         form = ResetForm(request.POST, request.FILES)         if form.is_valid():              return HttpResponseRedirect(\"/\")     else:         form = ResetForm()      return render_to_response(request, \"reset.html\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  The answer by Daniel Roseman is still the best. However, I would use the first positional argument for the request instead of the keyword argument for a few reasons:   You don't run the risk of overriding a kwarg with the same name The request is optional which is not right. The request attribute should never be None in this context. You can cleanly pass the args and kwargs to the parent class without having to modify them.   Lastly, I would use a more unique name to avoid overriding an existing variable. Thus, My modified answer looks like:  class MyForm(forms.Form):    def __init__(self, request, *args, **kwargs):       self._my_request = request       super(MyForm, self).__init__(*args, **kwargs)     def clean(self):       ... access the request object via self._my_request ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  fresh cheese from cheesebaker@pypi: django-requestprovider     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "How do I access the request object or any other variable in a form's clean() method?",
        "A_Content": "  I have another answer to this question as per your requirement you want to access the user into the clean method of the form. You can Try this. View.py  person=User.objects.get(id=person_id) form=MyForm(request.POST,instance=person)   forms.py  def __init__(self,*arg,**kwargs):     self.instance=kwargs.get('instance',None)     if kwargs['instance'] is not None:         del kwargs['instance']     super(Myform, self).__init__(*args, **kwargs)   Now you can access the self.instance in any clean method in form.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1057252/how-do-i-access-the-request-object-or-any-other-variable-in-a-forms-clean-met",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  Use the enumerate built-in function: http://docs.python.org/library/functions.html#enumerate     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "60",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  Use enumerate():  >>> S = [1,30,20,30,2] >>> for index, elem in enumerate(S):         print(index, elem)  (0, 1) (1, 30) (2, 20) (3, 30) (4, 2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  Like everyone else:  for i, val in enumerate(data):     print i, val   but also  for i, val in enumerate(data, 1):     print i, val   In other words, you can specify as starting value for the index/count generated by enumerate() which comes in handy if you don't want your index to start with the default value of zero.  I was printing out lines in a file the other day and specified the starting value as 1 for enumerate(), which made more sense than 0 when displaying information about a specific line to the user.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  enumerate is what you want:  for i, s in enumerate(S):     print s, i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  >>> for i, s in enumerate(S):      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Loop through list with both content and index [duplicate]",
        "A_Content": "  enumerate() makes this prettier:  for index, value in enumerate(S):     print index, value   See here for more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "loops"
        ],
        "URL": "https://stackoverflow.com/questions/11475748/loop-through-list-with-both-content-and-index",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Accessing the index in 'for' loops?                                        21 answers                                          It is very common for me to loop through a python list to get both the contents and their indexes. What I usually do is the following:  S = [1,30,20,30,2] # My list for s, i in zip(S, range(len(S))):     # Do stuff with the content s and the index i   I find this syntax a bit ugly, especially the part inside the zip function. Are there any more elegant/Pythonic ways of doing this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  Such renaming is quite easy, for example with os and glob modules:  import glob, os  def rename(dir, pattern, titlePattern):     for pathAndFilename in glob.iglob(os.path.join(dir, pattern)):         title, ext = os.path.splitext(os.path.basename(pathAndFilename))         os.rename(pathAndFilename,                    os.path.join(dir, titlePattern % title + ext))   You could then use it in your example like this:  rename(r'c:\\temp\\xx', r'*.doc', r'new(%s)')   The above example will convert all *.doc files in c:\\temp\\xx dir to new(%s).doc, where %s is the previous base name of the file (without extension).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "94",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  I prefer writing small one liners for each replace I have to do instead of making a more generic and complex code. E.g.:  This replaces all underscores with hyphens in any non-hidden file in the current directory  import os [os.rename(f, f.replace('_', '-')) for f in os.listdir('.') if not f.startswith('.')]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  If you don't mind using regular expressions, then this function would give you much power in renaming files:  import re, glob, os  def renamer(files, pattern, replacement):     for pathname in glob.glob(files):         basename= os.path.basename(pathname)         new_filename= re.sub(pattern, replacement, basename)         if new_filename != basename:             os.rename(               pathname,               os.path.join(os.path.dirname(pathname), new_filename))   So in your example, you could do (assuming it's the current directory where the files are):  renamer(\"*.doc\", r\"^(.*)\\.doc$\", r\"new(\\1).doc\")   but you could also roll back to the initial filenames:  renamer(\"*.doc\", r\"^new\\((.*)\\)\\.doc\", r\"\\1.doc\")   and more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  I have this to simply rename all files in subfolders of folder  import os  def replace(fpath, old_str, new_str):     for path, subdirs, files in os.walk(fpath):         for name in files:             if(old_str.lower() in name.lower()):                 os.rename(os.path.join(path,name), os.path.join(path,                                             name.lower().replace(old_str,new_str)))   I am replacing all occurences of old_str with any case by new_str.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  Try: http://www.mattweber.org/2007/03/04/python-script-renamepy/     I like to have my music, movie, and   picture files named a certain way.   When I download files from the   internet, they usually don’t follow my   naming convention. I found myself   manually renaming each file to fit my   style. This got old realy fast, so I   decided to write a program to do it   for me.      This program can convert the filename   to all lowercase, replace strings in   the filename with whatever you want,   and trim any number of characters from   the front or back of the filename.   The program's source code is also available.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  I've written a python script on my own. It takes as arguments the path of the directory in which the files are present and the naming pattern that you want to use. However, it renames by attaching an incremental number (1, 2, 3 and so on) to the naming pattern you give.  import os import sys  # checking whether path and filename are given. if len(sys.argv) != 3:     print \"Usage : python rename.py <path> <new_name.extension>\"     sys.exit()  # splitting name and extension. name = sys.argv[2].split('.') if len(name) < 2:     name.append('') else:     name[1] = \".%s\" %name[1]  # to name starting from 1 to number_of_files. count = 1  # creating a new folder in which the renamed files will be stored. s = \"%s/pic_folder\" % sys.argv[1] try:     os.mkdir(s) except OSError:     # if pic_folder is already present, use it.     pass  try:     for x in os.walk(sys.argv[1]):         for y in x[2]:             # creating the rename pattern.             s = \"%spic_folder/%s%s%s\" %(x[0], name[0], count, name[1])             # getting the original path of the file to be renamed.             z = os.path.join(x[0],y)             # renaming.             os.rename(z, s)             # incrementing the count.             count = count + 1 except OSError:     pass   Hope this works for you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  directoryName = \"Photographs\" filePath = os.path.abspath(directoryName) filePathWithSlash = filePath + \"\\\\\"  for counter, filename in enumerate(os.listdir(directoryName)):      filenameWithPath = os.path.join(filePathWithSlash, filename)      os.rename(filenameWithPath, filenameWithPath.replace(filename,\"DSC_\" + \\           str(counter).zfill(4) + \".jpg\" ))  # e.g. filename = \"photo1.jpg\", directory = \"c:\\users\\Photographs\"         # The string.replace call swaps in the new filename into  # the current filename within the filenameWitPath string. Which     # is then used by os.rename to rename the file in place, using the   # current (unmodified) filenameWithPath.  # os.listdir delivers the filename(s) from the directory # however in attempting to \"rename\" the file using os  # a specific location of the file to be renamed is required.  # this code is from Windows       ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  I had a similar problem, but I wanted to append text to the beginning of the file name of all files in a directory and used a similar method. See example below:  folder = r\"R:\\mystuff\\GIS_Projects\\Website\\2017\\PDF\"  import os   for root, dirs, filenames in os.walk(folder):   for filename in filenames:       fullpath = os.path.join(root, filename)       filename_split = os.path.splitext(filename) # filename will be filename_split[0] and extension will be filename_split[1])     print fullpath     print filename_split[0]     print filename_split[1]     os.rename(os.path.join(root, filename), os.path.join(root, \"NewText_2017_\" + filename_split[0] + filename_split[1]))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  #  another regex version #  usage example: #  replacing an underscore in the filename with today's date #  rename_files('..\\\\output', '(.*)(_)(.*\\.CSV)', '\\g<1>_20180402_\\g<3>') def rename_files(path, pattern, replacement):     for filename in os.listdir(path):         if re.search(pattern, filename):             new_filename = re.sub(pattern, replacement, filename)             new_fullname = os.path.join(path, new_filename)             old_fullname = os.path.join(path, filename)             os.rename(old_fullname, new_fullname)             print('Renamed: ' + old_fullname + ' to ' + new_fullname      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "  as to me in my directory I have multiple subdir, each subdir has lots of images I want to change all the subdir images to 1.jpg ~ n.jpg  def batch_rename():     base_dir = 'F:/ad_samples/test_samples/'     sub_dir_list = glob.glob(base_dir + '*')     # print sub_dir_list # like that ['F:/dir1', 'F:/dir2']     for dir_item in sub_dir_list:         files = glob.glob(dir_item + '/*.jpg')         i = 0         for f in files:             os.rename(f, os.path.join(dir_item, str(i) + '.jpg'))             i += 1   (mys own answer)https://stackoverflow.com/a/45734381/6329006     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Batch Renaming of Files in a Directory",
        "A_Content": "     Be in the directory where you need to perform the renaming.   import os # get the file name list to nameList nameList = os.listdir()  #loop through the name and rename for fileName in nameList:     rename=fileName[15:28]     os.rename(fileName,rename) #example: #input fileName bulk like :20180707131932_IMG_4304.JPG #output renamed bulk like :IMG_4304.JPG      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-io",
            "rename",
            "batch-rename"
        ],
        "URL": "https://stackoverflow.com/questions/225735/batch-renaming-of-files-in-a-directory",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an easy way to rename a group of files already contained in a directory, using Python?  Example:   I have a directory full of *.doc files and I want to rename them in a consistent way.     X.doc -> \"new(X).doc\"      Y.doc -> \"new(Y).doc\"      ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  There are a couple of quirks with the urllib and urlparse modules. Here's a working example:  try:     import urlparse     from urllib import urlencode except: # For Python 3     import urllib.parse as urlparse     from urllib.parse import urlencode  url = \"http://stackoverflow.com/search?q=question\" params = {'lang':'en','tag':'python'}  url_parts = list(urlparse.urlparse(url)) query = dict(urlparse.parse_qsl(url_parts[4])) query.update(params)  url_parts[4] = urlencode(query)  print(urlparse.urlunparse(url_parts))   ParseResult, the result of urlparse(), is read-only and we need to convert it to a list before we can attempt to modify its data.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "141",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Why  I've been not satisfied with all the solutions on this page (come on, where is our favorite copy-paste thing?) so I wrote my own based on answers here. It tries to be complete and more Pythonic. I've added a handler for dict and bool values in arguments to be more consumer-side (JS) friendly, but they are yet optional, you can drop them.  How it works  Test 1: Adding new arguments, handling Arrays and Bool values:  url = 'http://stackoverflow.com/test' new_params = {'answers': False, 'data': ['some','values']}  add_url_params(url, new_params) == \\     'http://stackoverflow.com/test?data=some&data=values&answers=false'   Test 2: Rewriting existing args, handling DICT values:  url = 'http://stackoverflow.com/test/?question=false' new_params = {'question': {'__X__':'__Y__'}}  add_url_params(url, new_params) == \\     'http://stackoverflow.com/test/?question=%7B%22__X__%22%3A+%22__Y__%22%7D'   Talk is cheap. Show me the code.  Code itself. I've tried to describe it in details:  from json import dumps  try:     from urllib import urlencode, unquote     from urlparse import urlparse, parse_qsl, ParseResult except ImportError:     # Python 3 fallback     from urllib.parse import (         urlencode, unquote, urlparse, parse_qsl, ParseResult     )   def add_url_params(url, params):     \"\"\" Add GET params to provided URL being aware of existing.      :param url: string of target URL     :param params: dict containing requested params to be added     :return: string with updated URL      >> url = 'http://stackoverflow.com/test?answers=true'     >> new_params = {'answers': False, 'data': ['some','values']}     >> add_url_params(url, new_params)     'http://stackoverflow.com/test?data=some&data=values&answers=false'     \"\"\"     # Unquoting URL first so we don't loose existing args     url = unquote(url)     # Extracting url info     parsed_url = urlparse(url)     # Extracting URL arguments from parsed URL     get_args = parsed_url.query     # Converting URL arguments to dict     parsed_get_args = dict(parse_qsl(get_args))     # Merging URL arguments dict with new params     parsed_get_args.update(params)      # Bool and Dict values should be converted to json-friendly values     # you may throw this part away if you don't like it :)     parsed_get_args.update(         {k: dumps(v) for k, v in parsed_get_args.items()          if isinstance(v, (bool, dict))}     )      # Converting URL argument to proper query string     encoded_get_args = urlencode(parsed_get_args, doseq=True)     # Creating new parsed result object based on provided with new     # URL arguments. Same thing happens inside of urlparse.     new_url = ParseResult(         parsed_url.scheme, parsed_url.netloc, parsed_url.path,         parsed_url.params, encoded_get_args, parsed_url.fragment     ).geturl()      return new_url   Please be aware that there may be some issues, if you'll find one please let me know and we will make this thing better     ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  You want to use URL encoding if the strings can have arbitrary data (for example, characters such as ampersands, slashes, etc. will need to be encoded).  Check out urllib.urlencode:  >>> import urllib >>> urllib.urlencode({'lang':'en','tag':'python'}) 'lang=en&tag=python'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  You can also use the furl module https://github.com/gruns/furl  >>> from furl import furl >>> print furl('http://example.com/search?q=question').add({'lang':'en','tag':'python'}).url http://example.com/search?q=question&lang=en&tag=python      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Yes: use urllib.  From the examples in the documentation:  >>> import urllib >>> params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0}) >>> f = urllib.urlopen(\"http://www.musi-cal.com/cgi-bin/query?%s\" % params) >>> print f.geturl() # Prints the final URL with parameters. >>> print f.read() # Prints the contents      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  I liked Łukasz version, but since urllib and urllparse functions are somewhat awkward to use in this case, I think it's more straightforward to do something like this:  params = urllib.urlencode(params)  if urlparse.urlparse(url)[4]:     print url + '&' + params else:     print url + '?' + params      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Based on this answer, one-liner for simple cases (Python 3 code):  from urllib.parse import urlparse, urlencode   url = \"https://stackoverflow.com/search?q=question\" params = {'lang':'en','tag':'python'}  url += ('&' if urlparse(url).query else '?') + urlencode(params)   or:  url += ('&', '?')[urlparse(url).query == ''] + urlencode(params)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Use the various urlparse functions to tear apart the existing URL, urllib.urlencode() on the combined dictionary, then urlparse.urlunparse() to put it all back together again.  Or just take the result of urllib.urlencode() and concatenate it to the URL appropriately.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Yet another answer:  def addGetParameters(url, newParams):     (scheme, netloc, path, params, query, fragment) = urlparse.urlparse(url)     queryList = urlparse.parse_qsl(query, keep_blank_values=True)     for key in newParams:         queryList.append((key, newParams[key]))     return urlparse.urlunparse((scheme, netloc, path, params, urllib.urlencode(queryList), fragment))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  If you are using the requests lib:  import requests ... params = {'tag': 'python'} requests.get(url, params=params)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Outsource it to the battle tested requests library.  This is how I will do it:  from requests.models import PreparedRequest url = 'http://example.com/search?q=question' params = {'lang':'en','tag':'python'} req = PreparedRequest() req.prepare_url(url, params) print(req.url)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  In python 2.5  import cgi import urllib import urlparse  def add_url_param(url, **params):     n=3     parts = list(urlparse.urlsplit(url))     d = dict(cgi.parse_qsl(parts[n])) # use cgi.parse_qs for list values     d.update(params)     parts[n]=urllib.urlencode(d)     return urlparse.urlunsplit(parts)  url = \"http://stackoverflow.com/search?q=question\" add_url_param(url, lang='en') == \"http://stackoverflow.com/search?q=question&lang=en\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Add params to given URL in Python",
        "A_Content": "  Here is how I implemented it.  import urllib  params = urllib.urlencode({'lang':'en','tag':'python'}) url = '' if request.GET:    url = request.url + '&' + params else:    url = request.url + '?' + params       Worked like a charm. However, I would have liked a more cleaner way to implement this.  Another way of implementing the above is put it in a method.  import urllib  def add_url_param(request, **params):    new_url = ''    _params = dict(**params)    _params = urllib.urlencode(_params)     if _params:       if request.GET:          new_url = request.url + '&' + _params       else:          new_url = request.url + '?' + _params    else:       new_url = request.url     return new_ur      ",
        "Language": "Python",
        "Tags": [
            "python",
            "url"
        ],
        "URL": "https://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I was given a URL. It might already have GET parameters (e.g. http://example.com/search?q=question) or it might not (e.g. http://example.com/).  And now I need to add some parameters to it like {'lang':'en','tag':'python'}. In the first case I'm going to have http://example.com/search?q=question&lang=en&tag=python and in the second — http://example.com/search?lang=en&tag=python.  Is there any standard way to do this?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Auto reloading python Flask app upon code changes",
        "A_Content": "  The current recommended way (Flask >= 0.11) is with the flask command line utility.  http://flask.pocoo.org/docs/0.11/server/  Example:   $ export FLASK_APP=main.py $ export FLASK_DEBUG=1 $ python -m flask run   or in one command:  $ FLASK_APP=main.py FLASK_DEBUG=1 python -m flask run   I prefer python -m flask run rather than flask run because the former also works with virtualenv.  If you want different port than the default (5000) add --port option.  Example:  $ python -m flask run --port 8080   More options are available with:   $ python -m flask run --help      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache",
            "web",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/16344756/auto-reloading-python-flask-app-upon-code-changes",
        "A_Votes": "74",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm investigating how to develop a decent web app with Python. Since I don't want some high-order structures to get in my way, my choice fell on the lightweight Flask framework. Time will tell if this was the right choice.  So, now I've set up an Apache server with mod_wsgi, and my test site is running fine. However, I'd like to speed up the development routine by making the site automatically reload upon any changes in py or template files I make. I see that any changes in site's .wsgi file causes reloading (even without WSGIScriptReloading On in the apache config file), but I still have to prod it manually (ie, insert extra linebreak, save). Is there some way how to cause reload when I edit some of the app's py files? Or, I am expected to use IDE that refreshes the .wsgi file for me?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Auto reloading python Flask app upon code changes",
        "A_Content": "  If you are talking about test/dev environments, then just use the debug option. It will auto-reload the flask app when a code change happens.  app.run(debug=True)   Or, from the shell:  $ export FLASK_DEBUG=1 $ flask run   http://flask.pocoo.org/docs/quickstart/#debug-mode     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache",
            "web",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/16344756/auto-reloading-python-flask-app-upon-code-changes",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm investigating how to develop a decent web app with Python. Since I don't want some high-order structures to get in my way, my choice fell on the lightweight Flask framework. Time will tell if this was the right choice.  So, now I've set up an Apache server with mod_wsgi, and my test site is running fine. However, I'd like to speed up the development routine by making the site automatically reload upon any changes in py or template files I make. I see that any changes in site's .wsgi file causes reloading (even without WSGIScriptReloading On in the apache config file), but I still have to prod it manually (ie, insert extra linebreak, save). Is there some way how to cause reload when I edit some of the app's py files? Or, I am expected to use IDE that refreshes the .wsgi file for me?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Auto reloading python Flask app upon code changes",
        "A_Content": "  In test/development environments  The werkzeug debugger already has an 'auto reload' function available that can be enabled by doing one of the following:  app.run(debug=True)   or  app.debug = True   You can also use a separate configuration file to manage all your setup if you need be. For example I use 'settings.py' with a 'DEBUG = True' option. Importing this file is easy too;  app.config.from_object('application.settings')   However this is not suitable for a production environment.  Production environment  Personally I chose Nginx + uWSGI over Apache + mod_wsgi for a few performance reasons but also the configuration options. The touch-reload option allows you to specify a file/folder that will cause the uWSGI application to reload your newly deployed flask app.  For example, your update script pulls your newest changes down and touches 'reload_me.txt' file. Your uWSGI ini script (which is kept up by Supervisord - obviously) has this line in it somewhere:  touch-reload = '/opt/virtual_environments/application/reload_me.txt'   I hope this helps!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache",
            "web",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/16344756/auto-reloading-python-flask-app-upon-code-changes",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm investigating how to develop a decent web app with Python. Since I don't want some high-order structures to get in my way, my choice fell on the lightweight Flask framework. Time will tell if this was the right choice.  So, now I've set up an Apache server with mod_wsgi, and my test site is running fine. However, I'd like to speed up the development routine by making the site automatically reload upon any changes in py or template files I make. I see that any changes in site's .wsgi file causes reloading (even without WSGIScriptReloading On in the apache config file), but I still have to prod it manually (ie, insert extra linebreak, save). Is there some way how to cause reload when I edit some of the app's py files? Or, I am expected to use IDE that refreshes the .wsgi file for me?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Auto reloading python Flask app upon code changes",
        "A_Content": "  If you're running using uwsgi look at the python auto reload option:  uwsgi --py-autoreload 1   Example uwsgi-dev-example.ini:  [uwsgi] socket = 127.0.0.1:5000 master = true virtualenv = /Users/xxxx/.virtualenvs/sites_env chdir = /Users/xxx/site_root module = site_module:register_debug_server() callable = app uid = myuser chmod-socket = 660 log-date = true workers = 1 py-autoreload = 1   site_root/__init__.py  def register_debug_server():     from werkzeug.debug import DebuggedApplication      app = Flask(__name__)     app.debug = True     app = DebuggedApplication(app, evalex=True)     return app   Then run:  uwsgi --ini uwsgi-dev-example.ini   Note: This example also enables the debugger.  I went this route to mimic production as close as possible with my nginx setup.  Simply running the flask app with it's built in web server behind nginx it would result in a bad gateway error.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache",
            "web",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/16344756/auto-reloading-python-flask-app-upon-code-changes",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm investigating how to develop a decent web app with Python. Since I don't want some high-order structures to get in my way, my choice fell on the lightweight Flask framework. Time will tell if this was the right choice.  So, now I've set up an Apache server with mod_wsgi, and my test site is running fine. However, I'd like to speed up the development routine by making the site automatically reload upon any changes in py or template files I make. I see that any changes in site's .wsgi file causes reloading (even without WSGIScriptReloading On in the apache config file), but I still have to prod it manually (ie, insert extra linebreak, save). Is there some way how to cause reload when I edit some of the app's py files? Or, I am expected to use IDE that refreshes the .wsgi file for me?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Auto reloading python Flask app upon code changes",
        "A_Content": "  To achieve this in PyCharm set 'Environment Variables' section to :   PYTHONUNBUFFERED=1;FLASK_DEBUG=1  For Flask 'run / debug configurations'     ",
        "Language": "Python",
        "Tags": [
            "python",
            "apache",
            "web",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/16344756/auto-reloading-python-flask-app-upon-code-changes",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm investigating how to develop a decent web app with Python. Since I don't want some high-order structures to get in my way, my choice fell on the lightweight Flask framework. Time will tell if this was the right choice.  So, now I've set up an Apache server with mod_wsgi, and my test site is running fine. However, I'd like to speed up the development routine by making the site automatically reload upon any changes in py or template files I make. I see that any changes in site's .wsgi file causes reloading (even without WSGIScriptReloading On in the apache config file), but I still have to prod it manually (ie, insert extra linebreak, save). Is there some way how to cause reload when I edit some of the app's py files? Or, I am expected to use IDE that refreshes the .wsgi file for me?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  If you are looking for all entries in the 1d array a smaller than their neighbors, you can try  numpy.r_[True, a[1:] < a[:-1]] & numpy.r_[a[:-1] < a[1:], True]   You could also smooth your array before this step using numpy.convolve().  I don't think there is a dedicated function for this.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  In SciPy >= 0.11  import numpy as np from scipy.signal import argrelextrema  x = np.random.random(12)  # for local maxima argrelextrema(x, np.greater)  # for local minima argrelextrema(x, np.less)   Produces   >>> x array([ 0.56660112,  0.76309473,  0.69597908,  0.38260156,  0.24346445,     0.56021785,  0.24109326,  0.41884061,  0.35461957,  0.54398472,     0.59572658,  0.92377974]) >>> argrelextrema(x, np.greater) (array([1, 5, 7]),) >>> argrelextrema(x, np.less) (array([4, 6, 8]),)   Note, these are the indices of x that are local max/min. To get the values, try:  >>> x[argrelextrema(x, np.greater)[0]]   scipy.signal also provides argrelmax and argrelmin for finding maxima and minima respectively.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "169",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  For curves with not too much noise, I recommend the following small code snippet:  from numpy import *  # example data with some peaks: x = linspace(0,4,1e3) data = .2*sin(10*x)+ exp(-abs(2-x)**2)  # that's the line, you need: a = diff(sign(diff(data))).nonzero()[0] + 1 # local min+max b = (diff(sign(diff(data))) > 0).nonzero()[0] + 1 # local min c = (diff(sign(diff(data))) < 0).nonzero()[0] + 1 # local max   # graphical output... from pylab import * plot(x,data) plot(x[b], data[b], \"o\", label=\"min\") plot(x[c], data[c], \"o\", label=\"max\") legend() show()   The +1 is important, because diff reduces the original index number.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  Another approach (more words, less code) that may help:  The locations of local maxima and minima are also the locations of the zero crossings of the first derivative.  It is generally much easier to find zero crossings than it is to directly find local maxima and minima.  Unfortunately, the first derivative tends to \"amplify\" noise, so when significant noise is present in the original data, the first derivative is best used only after the original data has had some degree of smoothing applied.  Since smoothing is, in the simplest sense, a low pass filter, the smoothing is often best (well, most easily) done by using a convolution kernel, and \"shaping\" that kernel can provide a surprising amount of feature-preserving/enhancing capability.  The process of finding an optimal kernel can be automated using a variety of means, but the best may be simple brute force (plenty fast for finding small kernels).  A good kernel will (as intended) massively distort the original data, but it will NOT affect the location of the peaks/valleys of interest.  Fortunately, quite often a suitable kernel can be created via a simple SWAG (\"educated guess\"). The width of the smoothing kernel should be a little wider than the widest expected \"interesting\" peak in the original data, and its shape will resemble that peak (a single-scaled wavelet).  For mean-preserving kernels (what any good smoothing filter should be) the sum of the kernel elements should be precisely equal to 1.00, and the kernel should be symmetric about its center (meaning it will have an odd number of elements.  Given an optimal smoothing kernel (or a small number of kernels optimized for different data content), the degree of smoothing becomes a scaling factor for (the \"gain\" of) the convolution kernel.  Determining the \"correct\" (optimal) degree of smoothing (convolution kernel gain) can even be automated: Compare the standard deviation of the first derivative data with the standard deviation of the smoothed data.  How the ratio of the two standard deviations changes with changes in the degree of smoothing cam be used to predict effective smoothing values.  A few manual data runs (that are truly representative) should be all that's needed.  All the prior solutions posted above compute the first derivative, but they don't treat it as a statistical measure, nor do the above solutions attempt to performing feature preserving/enhancing smoothing (to help subtle peaks \"leap above\" the noise).  Finally, the bad news: Finding \"real\" peaks becomes a royal pain when the noise also has features that look like real peaks (overlapping bandwidth).  The next more-complex solution is generally to use a longer convolution kernel (a \"wider kernel aperture\") that takes into account the relationship between adjacent \"real\" peaks (such as minimum or maximum rates for peak occurrence), or to use multiple convolution passes using kernels having different widths (but only if it is faster: it is a fundamental mathematical truth that linear convolutions performed in sequence can always be convolved together into a single convolution).  But it is often far easier to first find a sequence of useful kernels (of varying widths) and convolve them together than it is to directly find the final kernel in a single step.  Hopefully this provides enough info to let Google (and perhaps a good stats text) fill in the gaps.  I really wish I had the time to provide a worked example, or a link to one.  If anyone comes across one online, please post it here!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  Update:  I wasn't happy with gradient so I found it more reliable to use numpy.diff. Please let me know if it does what you want.  Regarding the issue of noise, the mathematical problem is to locate maxima/minima if we want to look at noise we can use something like convolve which was mentioned earlier.  import numpy as np from matplotlib import pyplot  a=np.array([10.3,2,0.9,4,5,6,7,34,2,5,25,3,-26,-20,-29],dtype=np.float)  gradients=np.diff(a) print gradients   maxima_num=0 minima_num=0 max_locations=[] min_locations=[] count=0 for i in gradients[:-1]:         count+=1      if ((cmp(i,0)>0) & (cmp(gradients[count],0)<0) & (i != gradients[count])):         maxima_num+=1         max_locations.append(count)           if ((cmp(i,0)<0) & (cmp(gradients[count],0)>0) & (i != gradients[count])):         minima_num+=1         min_locations.append(count)   turning_points = {'maxima_number':maxima_num,'minima_number':minima_num,'maxima_locations':max_locations,'minima_locations':min_locations}    print turning_points  pyplot.plot(a) pyplot.show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  Why not use Scipy built-in function signal.find_peaks_cwt to do the job ?  from scipy import signal import numpy as np  #generate junk data (numpy 1D arr) xs = np.arange(0, np.pi, 0.05) data = np.sin(xs)  # maxima : use builtin function to find (max) peaks max_peakind = signal.find_peaks_cwt(data, np.arange(1,10))  #generate an inverse numpy 1D arr (in order to find minima) inv_data = 1./data # minima : use builtin function fo find (min) peaks (use inversed data) min_peakind = signal.find_peaks_cwt(inv_data, np.arange(1,10))  #show results print \"maxima\",  data[max_peakind] print \"minima\",  data[min_peakind]   results:  maxima [ 0.9995736] minima [ 0.09146464]   Regards     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  None of these solutions worked for me since I wanted to find peaks in the center of repeating values as well. for example, in   ar = np.array([0,1,2,2,2,1,3,3,3,2,5,0])  the answer should be  array([ 3,  7, 10], dtype=int64)   I did this using a loop. I know it's not super clean, but it gets the job done.  def findLocalMaxima(ar): # find local maxima of array, including centers of repeating elements     maxInd = np.zeros_like(ar) peakVar = -np.inf i = -1 while i < len(ar)-1: #for i in range(len(ar)):     i += 1     if peakVar < ar[i]:         peakVar = ar[i]         for j in range(i,len(ar)):             if peakVar < ar[j]:                 break             elif peakVar == ar[j]:                 continue             elif peakVar > ar[j]:                 peakInd = i + np.floor(abs(i-j)/2)                 maxInd[peakInd.astype(int)] = 1                 i = j                 break     peakVar = ar[i] maxInd = np.where(maxInd)[0] return maxInd       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  While this question is really old. I believe there is a much simpler approach in numpy (a one liner).  import numpy as np  list = [1,3,9,5,2,5,6,9,7]  np.diff(np.sign(np.diff(list))) #the one liner  #output array([ 0, -2,  0,  2,  0,  0, -2])   To find a local max or min we essentially want to find when the difference between the values in the list (3-1, 9-3...) changes from positive to negative (max) or negative to positive (min). Therefore, first we find the difference. Then we find the sign, and then we find the changes in sign by taking the difference again. (Sort of like a first and second derivative in calculus, only we have discrete data and don't have a continuous function.)  The output in my example does not contain the extrema (the first and last values in the list). Also, just like calculus, if the second derivative is negative, you have max, and if it is positive you have a min.  Thus we have the following matchup:  [1,  3,  9,  5,  2,  5,  6,  9,  7]     [0, -2,  0,  2,  0,  0, -2]         Max     Min         Max      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Finding local maxima/minima with Numpy in a 1D numpy array",
        "A_Content": "  import numpy as np x=np.array([6,3,5,2,1,4,9,7,8]) y=np.array([2,1,3,5,3,9,8,10,7]) sortId=np.argsort(x) x=x[sortId] y=y[sortId] minm = np.array([]) maxm = np.array([]) i = 0 while i < length-1:     if i < length - 1:         while i < length-1 and y[i+1] >= y[i]:             i+=1          if i != 0 and i < length-1:             maxm = np.append(maxm,i)          i+=1      if i < length - 1:         while i < length-1 and y[i+1] <= y[i]:             i+=1          if i < length-1:             minm = np.append(minm,i)         i+=1   print minm print maxm   minm and maxm contain indices of minima and maxima, respectively. For a huge data set, it will give lots of maximas/minimas so in that case smooth the curve first and then apply this algorithm.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4624970/finding-local-maxima-minima-with-numpy-in-a-1d-numpy-array",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can you suggest a module function from numpy/scipy that can find local maxima/minima in a 1D numpy array? Obviously the simplest approach ever is to have a look at the nearest neighbours, but I would like to have an accepted solution that is part of the numpy distro.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  First, the function, for those who just want some copy-and-paste code:  def truncate(f, n):     '''Truncates/pads a float f to n decimal places without rounding'''     s = '{}'.format(f)     if 'e' in s or 'E' in s:         return '{0:.{1}f}'.format(f, n)     i, p, d = s.partition('.')     return '.'.join([i, (d+'0'*n)[:n]])   This is valid in Python 2.7 and 3.1+. For older versions, it's not possible to get the same \"intelligent rounding\" effect (at least, not without a lot of complicated code), but rounding to 12 decimal places before truncation will work much of the time:  def truncate(f, n):     '''Truncates/pads a float f to n decimal places without rounding'''     s = '%.12f' % f     i, p, d = s.partition('.')     return '.'.join([i, (d+'0'*n)[:n]])   Explanation  The core of the underlying method is to convert the value to a string at full precision and then just chop off everything beyond the desired number of characters. The latter step is easy; it can be done either with string manipulation  i, p, d = s.partition('.') '.'.join([i, (d+'0'*n)[:n]])   or the decimal module  str(Decimal(s).quantize(Decimal((0, (1,), -n)), rounding=ROUND_DOWN))   The first step, converting to a string, is quite difficult because there are some pairs of floating point literals (i.e. what you write in the source code) which both produce the same binary representation and yet should be truncated differently. For example, consider 0.3 and 0.29999999999999998. If you write 0.3 in a Python program, the compiler encodes it using the IEEE floating-point format into the sequence of bits (assuming a 64-bit float)  0011111111010011001100110011001100110011001100110011001100110011   This is the closest value to 0.3 that can accurately be represented as an IEEE float. But if you write 0.29999999999999998 in a Python program, the compiler translates it into exactly the same value. In one case, you meant it to be truncated (to one digit) as 0.3, whereas in the other case you meant it to be truncated as 0.2, but Python can only give one answer. This is a fundamental limitation of Python, or indeed any programming language without lazy evaluation. The truncation function only has access to the binary value stored in the computer's memory, not the string you actually typed into the source code.1  If you decode the sequence of bits back into a decimal number, again using the IEEE 64-bit floating-point format, you get  0.2999999999999999888977697537484345957637...   so a naive implementation would come up with 0.2 even though that's probably not what you want. For more on floating-point representation error, see the Python tutorial.  It's very rare to be working with a floating-point value that is so close to a round number and yet is intentionally not equal to that round number. So when truncating, it probably makes sense to choose the \"nicest\" decimal representation out of all that could correspond to the value in memory. Python 2.7 and up (but not 3.0) includes a sophisticated algorithm to do just that, which we can access through the default string formatting operation.  '{}'.format(f)   The only caveat is that this acts like a g format specification, in the sense that it uses exponential notation (1.23e+4) if the number is large or small enough. So the method has to catch this case and handle it differently. There are a few cases where using an f format specification instead causes a problem, such as trying to truncate 3e-10 to 28 digits of precision (it produces 0.0000000002999999999999999980), and I'm not yet sure how best to handle those.  If you actually are working with floats that are very close to round numbers but intentionally not equal to them (like 0.29999999999999998 or 99.959999999999994), this will produce some false positives, i.e. it'll round numbers that you didn't want rounded. In that case the solution is to specify a fixed precision.  '{0:.{1}f}'.format(f, sys.float_info.dig + n + 2)   The number of digits of precision to use here doesn't really matter, it only needs to be large enough to ensure that any rounding performed in the string conversion doesn't \"bump up\" the value to its nice decimal representation. I think sys.float_info.dig + n + 2 may be enough in all cases, but if not that 2 might have to be increased, and it doesn't hurt to do so.  In earlier versions of Python (up to 2.6, or 3.0), the floating point number formatting was a lot more crude, and would regularly produce things like  >>> 1.1 1.1000000000000001   If this is your situation, if you do want to use \"nice\" decimal representations for truncation, all you can do (as far as I know) is pick some number of digits, less than the full precision representable by a float, and round the number to that many digits before truncating it. A typical choice is 12,  '%.12f' % f   but you can adjust this to suit the numbers you're using.    1Well... I lied. Technically, you can instruct Python to re-parse its own source code and extract the part corresponding to the first argument you pass to the truncation function. If that argument is a floating-point literal, you can just cut it off a certain number of places after the decimal point and return that. However this strategy doesn't work if the argument is a variable, which makes it fairly useless. The following is presented for entertainment value only:  def trunc_introspect(f, n):     '''Truncates/pads the float f to n decimal places by looking at the caller's source code'''     current_frame = None     caller_frame = None     s = inspect.stack()     try:         current_frame = s[0]         caller_frame = s[1]         gen = tokenize.tokenize(io.BytesIO(caller_frame[4][caller_frame[5]].encode('utf-8')).readline)         for token_type, token_string, _, _, _ in gen:             if token_type == tokenize.NAME and token_string == current_frame[3]:                 next(gen) # left parenthesis                 token_type, token_string, _, _, _ = next(gen) # float literal                 if token_type == tokenize.NUMBER:                     try:                         cut_point = token_string.index('.') + n + 1                     except ValueError: # no decimal in string                         return token_string + '.' + '0' * n                     else:                         if len(token_string) < cut_point:                             token_string += '0' * (cut_point - len(token_string))                         return token_string[:cut_point]                 else:                     raise ValueError('Unable to find floating-point literal (this probably means you called {} with a variable)'.format(current_frame[3]))                 break     finally:         del s, current_frame, caller_frame   Generalizing this to handle the case where you pass in a variable seems like a lost cause, since you'd have to trace backwards through the program's execution until you find the floating-point literal which gave the variable its value. If there even is one. Most variables will be initialized from user input or mathematical expressions, in which case the binary representation is all there is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "92",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  round(1.923328437452, 3)   See Python's documentation on the standard types. You'll need to scroll down a bit to get to the round function. Essentially the second number says how many decimal places to round it to.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  The result of round is a float, so watch out (example is from Python 2.6):  >>> round(1.923328437452, 3) 1.923 >>> round(1.23456, 3) 1.2350000000000001   You will be better off when using a formatted string:  >>> \"%.3f\" % 1.923328437452 '1.923' >>> \"%.3f\" % 1.23456 '1.235'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  n = 1.923328437452 str(n)[:4]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  At my Python 2.7 prompt:  >>> int(1.923328437452 * 1000)/1000.0 1.923     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  The truely pythonic way of doing it is  from decimal import *  with localcontext() as ctx:     ctx.rounding = ROUND_DOWN     print Decimal('1.923328437452').quantize(Decimal('0.001'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  def trunc(num, digits):    sp = str(num).split('.')    return '.'.join([sp[0], sp[1][:digits]])   This should work.  It should give you the truncation you are looking for.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  So many of the answers given for this question are just completely wrong. They either round up floats (rather than truncate) or do not work for all cases.  This is the top Google result when I search for 'Python truncate float', a concept which is really straightforward, and which deserves better answers. I agree with Hatchkins that using the decimal module is the pythonic way of doing this, so I give here a function which I think answers the question correctly, and which works as expected for all cases.  As a side-note, fractional values, in general, cannot be represented exactly by binary floating point variables (see here for a discussion of this), which is why my function returns a string.   from decimal import Decimal, localcontext, ROUND_DOWN  def truncate(number, places):     if not isinstance(places, int):         raise ValueError(\"Decimal places must be an integer.\")     if places < 1:         raise ValueError(\"Decimal places must be at least 1.\")     # If you want to truncate to 0 decimal places, just do int(number).      with localcontext() as context:         context.rounding = ROUND_DOWN         exponent = Decimal(str(10 ** - places))         return Decimal(str(number)).quantize(exponent).to_eng_string()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  Simple python script -  n = 1.923328437452 n = float(int(n * 1000)) n /=1000      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  I did something like this:  from math import trunc   def truncate(number, decimals=0):     if decimals < 0:         raise ValueError('truncate received an invalid value of decimals ({})'.format(decimals))     elif decimals == 0:         return trunc(number)     else:         factor = float(10**decimals)         return trunc(number*factor)/factor      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  You can do:  def truncate(f, n):     return math.floor(f * 10 ** n) / 10 ** n   testing:  >>> f=1.923328437452 >>> [truncate(f, n) for n in range(5)] [1.0, 1.9, 1.92, 1.923, 1.9233]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  If you fancy some mathemagic, this works for +ve numbers:  >>> v = 1.923328437452 >>> v - v % 1e-3 1.923      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  Just wanted to mention that the old \"make round() with floor()\" trick of  round(f) = floor(f+0.5)   can be turned around to make floor() from round()  floor(f) = round(f-0.5)   Although both these rules break around negative numbers, so using it is less than ideal:  def trunc(f, n):     if f > 0:         return \"%.*f\" % (n, (f - 0.5*10**-n))     elif f == 0:         return \"%.*f\" % (n, f)     elif f < 0:         return \"%.*f\" % (n, (f + 0.5*10**-n))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  int(16.5); this will give an integer value of 16, i.e. trunc, won't be able to specify decimals, but guess you can do that by   import math;  def trunc(invalue, digits):     return int(invalue*math.pow(10,digits))/math.pow(10,digits);      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  use numpy.round  import numpy as np precision = 3 floats = [1.123123123, 2.321321321321] new_float = np.round(floats, precision)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  def trunc(f,n):   return ('%.16f' % f)[:(n-16)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  A general and simple function to use:  def truncate_float(number, length):     \"\"\"Truncate float numbers, up to the number specified     in length that must be an integer\"\"\"      number = number * pow(10, length)     number = int(number)     number = float(number)     number /= pow(10, length)     return number      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  Here is an easy way:  def truncate(num, res=3):     return (floor(num*pow(10, res)+0.5))/pow(10, res)   for num = 1.923328437452, this outputs 1.923     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  >>>floor((1.23658945) * 10**4) / 10**4 1.2365  # divide and multiply by 10**number of desired digits     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  There is an easy workaround in python 3. Where to cut I defined with an help variable decPlace to make it easy to adapt.  f = 1.12345 decPlace= 4 f_cut = int(f * 10**decPlace) /10**decPlace   Output:  f = 1.1234   Hope it helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  def precision(value, precision):     \"\"\"     param: value: takes a float     param: precision: int, number of decimal places     returns a float     \"\"\"     x = 10.0**precision     num = int(value * x)/ x     return num precision(1.923328437452, 3)           1.923         ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  Something simple enough to fit in a list-comprehension, with no libraries or other external dependencies. For Python >=3.6, it's very simple to write with f-strings.  The idea is to let the string-conversion do the rounding to one more place than you need and then chop off the last digit.  >>> nout = 3  # desired number of digits in output >>> [f'{x:.{nout+1}f}'[:-1] for x in [2/3, 4/5, 8/9, 9/8, 5/4, 3/2]] ['0.666', '0.800', '0.888', '1.125', '1.250', '1.500']   Of course, there is rounding happening here (namely for the fourth digit), but rounding at some point is unvoidable. In case the transition between truncation and rounding is relevant, here's a slightly better example:  >>> nacc = 6  # desired accuracy (maximum 15!) >>> nout = 3  # desired number of digits in output >>> [f'{x:.{nacc}f}'[:-(nacc-nout)] for x in [2.9999, 2.99999, 2.999999, 2.9999999]] >>> ['2.999', '2.999', '2.999', '3.000']   Bonus: removing zeros on the right  >>> nout = 3  # desired number of digits in output >>> [f'{x:.{nout+1}f}'[:-1].rstrip('0') for x in [2/3, 4/5, 8/9, 9/8, 5/4, 3/2]] ['0.666', '0.8', '0.888', '1.125', '1.25', '1.5']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  Am also a python newbie and after making use of some bits and pieces here, I offer my two cents  print str(int(time.time()))+str(datetime.now().microsecond)[:3]   str(int(time.time())) will take the time epoch as int and convert it to string and join with... str(datetime.now().microsecond)[:3] which returns the microseconds only, convert to string and truncate to first 3 chars     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Truncating floats in Python",
        "A_Content": "  # value  value to be truncated # n  number of values after decimal  value = 0.999782 n = 3 float(int(value*1en))*1e-n      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/783897/truncating-floats-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to remove digits from a float to have a fixed number of digits after the dot, like:  1.923328437452 -> 1.923   I need to output as a string to another function, not print.  Also I want to ignore the lost digits, not round them.     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  No. It's not possible.  Example:  import random  def gen(n):     for i in xrange(n):         if random.randint(0, 1) == 0:             yield i  iterator = gen(10)   Length of iterator is unknown until you iterate through it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  This code should work:  >>> iter = (i for i in range(50)) >>> sum(1 for _ in iter) 50   Although it does iterate through each item and count them, it is the fastest way to do so.  It also works for when the iterator has no item:  >>> sum(1 for _ in range(0)) 0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "150",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  No, any method will require you to resolve every result. You can do   iter_length = len(list(iterable))   but running that on an infinite iterator will of course never return. It also will consume the iterator and it will need to be reset if you want to use the contents.  Telling us what real problem you're trying to solve might help us find you a better way to accomplish your actual goal.  Edit: Using list() will read the whole iterable into memory at once, which may be undesirable. Another way is to do  sum(1 for _ in iterable)   as another person posted. That will avoid keeping it in memory.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  You cannot (except the type of a particular iterator implements some specific methods that make it possible).  Generally, you may count iterator items only by consuming the iterator. One of probably the most efficient ways:  import itertools from collections import deque  def count_iter_items(iterable):     \"\"\"     Consume an iterable not reading it into memory; return the number of items.     \"\"\"     counter = itertools.count()     deque(itertools.izip(iterable, counter), maxlen=0)  # (consume at C speed)     return next(counter)   (For Python 3.x replace itertools.izip with zip).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  Kinda. You could check the __length_hint__ method, but be warned that (at least up to Python 3.4, as gsnedders helpfully points out) it's a undocumented implementation detail (following message in thread), that could very well vanish or summon nasal demons instead.  Otherwise, no. Iterators are just an object that only expose the next() method. You can call it as many times as required and they may or may not eventually raise StopIteration. Luckily, this behaviour is most of the time transparent to the coder. :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  An iterator is just an object which has a pointer to the next object to be read by some kind of buffer or stream, it's like a LinkedList where you don't know how many things you have until you iterate through them. Iterators are meant to be efficient because all they do is tell you what is next by references instead of using indexing (but as you saw you lose the ability to see how many entries are next).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  Regarding your original question, the answer is still that there is no way in general to know the length of an iterator in Python.  Given that you question is motivated by an application of the pysam library, I can give a more specific answer: I'm a contributer to PySAM and the definitive answer is that SAM/BAM files do not provide an exact count of aligned reads.  Nor is this information easily available from a BAM index file.  The best one can do is to estimate the approximate number of alignments by using the location of the file pointer after reading a number of alignments and extrapolating based on the total size of the file.  This is enough to implement a progress bar, but not a method of counting alignments in constant time.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  I like the cardinality package for this, it is very lightweight and tries to use the fastest possible implementation available depending on the iterable.  Usage:  >>> import cardinality >>> cardinality.count([1, 2, 3]) 3 >>> cardinality.count(i for i in range(500)) 500 >>> def gen(): ...     yield 'hello' ...     yield 'world' >>> cardinality.count(gen()) 2   The actual count() implementation is as follows:  def count(iterable):     if hasattr(iterable, '__len__'):         return len(iterable)      d = collections.deque(enumerate(iterable, 1), maxlen=1)     return d[0][0] if d else 0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  There are two ways to get the length of \"something\" on a computer.  The first way is to store a count - this requires anything that touches the file/data to modify it (or a class that only exposes interfaces -- but it boils down to the same thing).  The other way is to iterate over it and count how big it is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  A quick benchmark:  import collections import itertools  def count_iter_items(iterable):     counter = itertools.count()     collections.deque(itertools.izip(iterable, counter), maxlen=0)     return next(counter)  def count_lencheck(iterable):     if hasattr(iterable, '__len__'):         return len(iterable)      d = collections.deque(enumerate(iterable, 1), maxlen=1)     return d[0][0] if d else 0  def count_sum(iterable):                return sum(1 for _ in iterable)  iter = lambda y: (x for x in xrange(y))  %timeit count_iter_items(iter(1000)) %timeit count_lencheck(iter(1000)) %timeit count_sum(iter(1000))   The results:  10000 loops, best of 3: 35.4 µs per loop 10000 loops, best of 3: 40.2 µs per loop 10000 loops, best of 3: 50.7 µs per loop   I.e. the simple count_iter_items is the way to go.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  It's common practice to put this type of information in the file header, and for pysam to give you access to this.  I don't know the format, but have you checked the API?  As others have said, you can't know the length from the iterator.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  This is against the very definition of an iterator, which is a pointer to an object, plus information about how to get to the next object.  An iterator does not know how many more times it will be able to iterate until terminating.  This could be infinite, so infinity might be your answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  def count_iter(iter):     sum = 0     for _ in iter: sum += 1     return sum      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  Although it's not possible in general to do what's been asked, it's still often useful to have a count of how many items were iterated over after having iterated over them. For that, you can use jaraco.itertools.Counter or similar. Here's an example using Python 3 and rwt to load the package.  $ rwt -q jaraco.itertools -- -q >>> import jaraco.itertools >>> items = jaraco.itertools.Counter(range(100)) >>> _ = list(counted) >>> items.count 100 >>> import random >>> def gen(n): ...     for i in range(n): ...         if random.randint(0, 1) == 0: ...             yield i ...  >>> items = jaraco.itertools.Counter(gen(100)) >>> _ = list(counted) >>> items.count 48      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Getting number of elements in an iterator in Python",
        "A_Content": "  So, for those who would like to know the summary of that discussion. The final top scores for counting a 50 million-lengthed generator expression using:    len(list(gen)),  len([_ for _ in gen]),  sum(1 for _ in gen),  ilen(gen) (from more_itertool),  reduce(lambda c, i: c + 1, gen, 0),    sorted by performance of execution (including memory consumption), will make you surprised:  ```  1: test_list.py:8: 0.492 KiB  gen = (i for i in data*1000); t0 = monotonic(); len(list(gen))   ('list, sec', 1.9684218849870376)  2: test_list_compr.py:8: 0.867 KiB  gen = (i for i in data*1000); t0 = monotonic(); len([i for i in gen])   ('list_compr, sec', 2.5885991149989422)  3: test_sum.py:8: 0.859 KiB  gen = (i for i in data*1000); t0 = monotonic(); sum(1 for i in gen); t1 = monotonic()   ('sum, sec', 3.441088170016883)  4: more_itertools/more.py:413: 1.266 KiB  d = deque(enumerate(iterable, 1), maxlen=1)  test_ilen.py:10: 0.875 KiB gen = (i for i in data*1000); t0 = monotonic(); ilen(gen)   ('ilen, sec', 9.812256851990242)  5: test_reduce.py:8: 0.859 KiB  gen = (i for i in data*1000); t0 = monotonic(); reduce(lambda counter, i: counter + 1, gen, 0)   ('reduce, sec', 13.436614598002052) ```  So, len(list(gen)) is the most frequent and less memory consumable     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3345785/getting-number-of-elements-in-an-iterator-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there an efficient way to know how many elements are in an iterator in Python, in general, without iterating through each and counting?     ",
        "Q_Votes": "84"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  As a guess, Python strings are reference counted immutable strings, so that no strings are copied around in the Python code, while C++ std::string is a mutable value type, and is copied at the smallest opportunity.  If the goal is fast splitting, then one would use constant time substring operations, which means only referring to parts of the original string, as in Python (and Java, and C#…).  The C++ std::string class has one redeeming feature, though: it is standard, so that it can be used to pass strings safely and portably around where efficiency is not a main consideration. But enough chat. Code -- and on my machine this is of course faster than Python, since Python's string handling is implemented in C which is a subset of C++ (he he):  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  class StringRef { private:     char const*     begin_;     int             size_;  public:     int size() const { return size_; }     char const* begin() const { return begin_; }     char const* end() const { return begin_ + size_; }      StringRef( char const* const begin, int const size )         : begin_( begin )         , size_( size )     {} };  vector<StringRef> split3( string const& str, char delimiter = ' ' ) {     vector<StringRef>   result;      enum State { inSpace, inToken };      State state = inSpace;     char const*     pTokenBegin = 0;    // Init to satisfy compiler.     for( auto it = str.begin(); it != str.end(); ++it )     {         State const newState = (*it == delimiter? inSpace : inToken);         if( newState != state )         {             switch( newState )             {             case inSpace:                 result.push_back( StringRef( pTokenBegin, &*it - pTokenBegin ) );                 break;             case inToken:                 pTokenBegin = &*it;             }         }         state = newState;     }     if( state == inToken )     {         result.push_back( StringRef( pTokenBegin, &*str.end() - pTokenBegin ) );     }     return result; }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         //spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           //split2(spline, input_line);          vector<StringRef> const v = split3( input_line );         count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0; }  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp -std=c++0x   Disclaimer: I hope there aren't any bugs. I haven't tested the functionality, but only checked the speed. But I think, even if there is a bug or two, correcting that won't significantly affect the speed.     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  I'm not providing any better solutions (at least performance-wise), but some additional data that could be interesting.  Using strtok_r (reentrant variant of strtok):  void splitc1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     char *saveptr;     char *cpy, *token;      cpy = (char*)malloc(str.size() + 1);     strcpy(cpy, str.c_str());      for(token = strtok_r(cpy, delimiters.c_str(), &saveptr);         token != NULL;         token = strtok_r(NULL, delimiters.c_str(), &saveptr)) {         tokens.push_back(string(token));     }      free(cpy); }   Additionally using character strings for parameters, and fgets for input:  void splitc2(vector<string> &tokens, const char *str,         const char *delimiters) {     char *saveptr;     char *cpy, *token;      cpy = (char*)malloc(strlen(str) + 1);     strcpy(cpy, str);      for(token = strtok_r(cpy, delimiters, &saveptr);         token != NULL;         token = strtok_r(NULL, delimiters, &saveptr)) {         tokens.push_back(string(token));     }      free(cpy); }   And, in some cases, where destroying the input string is acceptable:  void splitc3(vector<string> &tokens, char *str,         const char *delimiters) {     char *saveptr;     char *token;      for(token = strtok_r(str, delimiters, &saveptr);         token != NULL;         token = strtok_r(NULL, delimiters, &saveptr)) {         tokens.push_back(string(token));     } }   The timings for these are as follows (including my results for the other variants from the question and the accepted answer):  split1.cpp:  C++   : Saw 20000000 lines in 31 seconds.  Crunch speed: 645161 split2.cpp:  C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444 split.py:    Python: Saw 20000000 lines in 33 seconds.  Crunch Speed: 606060 split5.py:   Python: Saw 20000000 lines in 35 seconds.  Crunch Speed: 571428 split6.cpp:  C++   : Saw 20000000 lines in 18 seconds.  Crunch speed: 1111111  splitc1.cpp: C++   : Saw 20000000 lines in 27 seconds.  Crunch speed: 740740 splitc2.cpp: C++   : Saw 20000000 lines in 22 seconds.  Crunch speed: 909090 splitc3.cpp: C++   : Saw 20000000 lines in 20 seconds.  Crunch speed: 1000000   As we can see, the solution from the accepted answer is still fastest.  For anyone who would want to do further tests, I also put up a Github repo with all the programs from the question, the accepted answer, this answer, and additionally a Makefile and a script to generate test data: https://github.com/tobbez/string-splitting.     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  I suspect that this is because of the way std::vector gets resized during the process of a push_back() function call. If you try using std::list or std::vector::reserve() to reserve enough space for the sentences, you should get a much better performance. Or you could use a combination of both like below for split1():  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);     list<string> token_list;      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the list         token_list.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     }     tokens.assign(token_list.begin(), token_list.end()); }   EDIT: The other obvious thing I see is that Python variable dummy gets assigned each time but not modified. So it's not a fair comparison against C++. You should try modifying your Python code to be dummy = [] to initialize it and then do dummy += line.split(). Can you report the runtime after this?  EDIT2: To make it even more fair can you modify the while loop in C++ code to be:      while(cin) {         getline(cin, input_line);         std::vector<string> spline; // create a new vector          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  I think the following code is better, using some C++17 and C++14 features:  // These codes are un-tested when I write this post, but I'll test it // When I'm free, and I sincerely welcome others to test and modify this // code.  // C++17 #include <istream>     // For std::istream. #include <string_view> // new feature in C++17, sizeof(std::string_view) == 16 in libc++ on my x86-64 debian 9.4 computer. #include <string> #include <utility>     // C++14 feature std::move.  template <template <class...> class Container, class Allocator> void split1(Container<std::string_view, Allocator> &tokens,              std::string_view str,             std::string_view delimiter = \" \")  {     /*       * The model of the input string:      *      * (optional) delimiter | content | delimiter | content | delimiter|       * ... | delimiter | content       *      * Using std::string::find_first_not_of or       * std::string_view::find_first_not_of is a bad idea, because it       * actually does the following thing:      *       *     Finds the first character not equal to any of the characters       *     in the given character sequence.      *       * Which means it does not treeat your delimiters as a whole, but as      * a group of characters.      *       * This has 2 effects:      *      *  1. When your delimiters is not a single character, this function      *  won't behave as you predicted.      *      *  2. When your delimiters is just a single character, the function      *  may have an additional overhead due to the fact that it has to       *  check every character with a range of characters, although       * there's only one, but in order to assure the correctness, it still       * has an inner loop, which adds to the overhead.      *      * So, as a solution, I wrote the following code.      *      * The code below will skip the first delimiter prefix.      * However, if there's nothing between 2 delimiter, this code'll       * still treat as if there's sth. there.      *      * Note:       * Here I use C++ std version of substring search algorithm, but u      * can change it to Boyer-Moore, KMP(takes additional memory),       * Rabin-Karp and other algorithm to speed your code.      *       */      // Establish the loop invariant 1.     typename std::string_view::size_type          next,          delimiter_size = delimiter.size(),           pos = str.find(delimiter) ? 0 : delimiter_size;      // The loop invariant:     //  1. At pos, it is the content that should be saved.     //  2. The next pos of delimiter is stored in next, which could be 0     //  or std::string_view::npos.      do {         // Find the next delimiter, maintain loop invariant 2.         next = str.find(delimiter, pos);          // Found a token, add it to the vector         tokens.push_back(str.substr(pos, next));          // Skip delimiters, maintain the loop invariant 1.         //         // @ next is the size of the just pushed token.         // Because when next == std::string_view::npos, the loop will         // terminate, so it doesn't matter even if the following          // expression have undefined behavior due to the overflow of          // argument.         pos = next + delimiter_size;     } while(next != std::string_view::npos); }     template <template <class...> class Container, class traits, class Allocator2, class Allocator> void split2(Container<std::basic_string<char, traits, Allocator2>, Allocator> &tokens,              std::istream &stream,             char delimiter = ' ') {     std::string<char, traits, Allocator2> item;      // Unfortunately, std::getline can only accept a single-character      // delimiter.     while(std::getline(stream, item, delimiter))         // Move item into token. I haven't checked whether item can be          // reused after being moved.         tokens.push_back(std::move(item)); }   The choice of container:   std::vector.  Assuming the initial size of allocated internal array is 1, and the ultimate size is N, you will allocate and deallocate for log2(N) times, and you will copy the (2 ^ (log2(N) + 1) - 1) = (2N - 1) times. As pointed out in Is the poor performance of std::vector due to not calling realloc a logarithmic number of times?, this can have a poor performance when the size of vector is unpredictable and could be very large. But, if you can estimate the size of it, this'll be less a problem. std::list.   For every push_back, the time it consumed is a constant, but it'll probably takes more time than std::vector on individual push_back. Using a per-thread memory pool and a custom allocator can ease this problem. std::forward_list.   Same as std::list, but occupy less memory per element. Require a wrapper class to work due to the lack of API push_back. std::array.   If you can know the limit of growth, then you can use std::array. Of cause, you can't use it directly, since it doesn't have the API push_back. But you can define a wrapper, and I think it's the fastest way here and can save some memory if your estimation is quite accurate. std::deque.   This option allows you to trade memory for performance. There'll be no (2 ^ (N + 1) - 1) times copy of element, just N times allocation, and no deallocation. Also, you'll has constant random access time, and the ability to add new elements at both ends.   According to std::deque-cppreference     On the other hand, deques typically have large minimal memory cost; a    deque holding just one element has to allocate its full internal array    (e.g. 8 times the object size on 64-bit libstdc++; 16 times the object size    or 4096 bytes, whichever is larger, on 64-bit libc++)   or you can use combo of these:   std::vector< std::array<T, 2 ^ M> >  This is similar to std::deque, the difference is just this container doesn't support to add element at the front. But it is still faster in performance, due to the fact that it won't copy the underlying std::array for (2 ^ (N + 1) - 1) times, it'll just copy the pointer array for (2 ^ (N - M + 1) - 1) times, and allocating new array only when the current is full and doesn't need to deallocate anything. By the way, you can get constant random access time. std::list< std::array<T, ...> >   Greatly ease the pressure of memory framentation. It will only allocate new array when the current is full, and does not need to copy anything. You will still have to pay the price for an additional pointer conpared to combo 1. std::forward_list< std::array<T, ...> >  Same as 2, but cost the same memory as combo 1.      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  You're making the mistaken assumption that your chosen C++ implementation is necessarily faster than Python's. String handling in Python is highly optimized. See this question for more: Why do std::string operations perform poorly?     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  If you take the split1 implementaion and change the signature to more closely match that of split2, by changing this:  void split1(vector<string> &tokens, const string &str, const string &delimiters = \" \")   to this:  void split1(vector<string> &tokens, const string &str, const char delimiters = ' ')   You get a more dramatic difference between split1 and split2, and a fairer comparison:  split1  C++   : Saw 10000000 lines in 41 seconds.  Crunch speed: 243902 split2  C++   : Saw 10000000 lines in 144 seconds.  Crunch speed: 69444 split1' C++   : Saw 10000000 lines in 33 seconds.  Crunch speed: 303030      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  void split5(vector<string> &tokens, const string &str, char delim=' ') {      enum { do_token, do_delim } state = do_delim;     int idx = 0, tok_start = 0;     for (string::const_iterator it = str.begin() ; ; ++it, ++idx) {         switch (state) {             case do_token:                 if (it == str.end()) {                     tokens.push_back (str.substr(tok_start, idx-tok_start));                     return;                 }                 else if (*it == delim) {                     state = do_delim;                     tokens.push_back (str.substr(tok_start, idx-tok_start));                 }                 break;              case do_delim:                 if (it == str.end()) {                     return;                 }                 if (*it != delim) {                     state = do_token;                     tok_start = idx;                 }                 break;         }     } }      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Why is splitting a string slower in C++ than Python?",
        "A_Content": "  I suspect that this is related to buffering on sys.stdin in Python, but no buffering in the C++ implementation.  See this post for details on how to change the buffer size, then try the comparison again: Setting smaller buffer size for sys.stdin?     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "string",
            "split",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to convert some code from Python to C++ in an effort to gain a little bit of speed and sharpen my rusty C++ skills.  Yesterday I was shocked when a naive implementation of reading lines from stdin was much faster in Python than C++ (see this).  Today, I finally figured out how to split a string in C++ with merging delimiters (similar semantics to python's split()), and am now experiencing deja vu!  My C++ code takes much longer to do the work (though not an order of magnitude more, as was the case for yesterday's lesson).  Python Code:  #!/usr/bin/env python from __future__ import print_function                                             import time import sys  count = 0 start_time = time.time() dummy = None  for line in sys.stdin:     dummy = line.split()     count += 1  delta_sec = int(time.time() - start_time) print(\"Python: Saw {0} lines in {1} seconds. \".format(count, delta_sec), end='') if delta_sec > 0:     lps = int(count/delta_sec)     print(\"  Crunch Speed: {0}\".format(lps)) else:     print('')   C++ Code:  #include <iostream>                                                               #include <string> #include <sstream> #include <time.h> #include <vector>  using namespace std;  void split1(vector<string> &tokens, const string &str,         const string &delimiters = \" \") {     // Skip delimiters at beginning     string::size_type lastPos = str.find_first_not_of(delimiters, 0);      // Find first non-delimiter     string::size_type pos = str.find_first_of(delimiters, lastPos);      while (string::npos != pos || string::npos != lastPos) {         // Found a token, add it to the vector         tokens.push_back(str.substr(lastPos, pos - lastPos));         // Skip delimiters         lastPos = str.find_first_not_of(delimiters, pos);         // Find next non-delimiter         pos = str.find_first_of(delimiters, lastPos);     } }  void split2(vector<string> &tokens, const string &str, char delim=' ') {     stringstream ss(str); //convert string to stream     string item;     while(getline(ss, item, delim)) {         tokens.push_back(item); //add token to vector     } }  int main() {     string input_line;     vector<string> spline;     long count = 0;     int sec, lps;     time_t start = time(NULL);      cin.sync_with_stdio(false); //disable synchronous IO      while(cin) {         getline(cin, input_line);         spline.clear(); //empty the vector for the next line to parse          //I'm trying one of the two implementations, per compilation, obviously: //        split1(spline, input_line);           split2(spline, input_line);          count++;     };      count--; //subtract for final over-read     sec = (int) time(NULL) - start;     cerr << \"C++   : Saw \" << count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     } else         cerr << endl;     return 0;  //compiled with: g++ -Wall -O3 -o split1 split_1.cpp   Note that I tried two different split implementations.  One (split1) uses string methods to search for tokens and is able to merge multiple tokens as well as handle numerous tokens (it comes from here).  The second (split2) uses getline to read the string as a stream, doesn't merge delimiters, and only supports a single delimeter character (that one was posted by several StackOverflow users in answers to string splitting questions).  I ran this multiple times in various orders.  My test machine is a Macbook Pro (2011, 8GB, Quad Core), not that it matters much.  I'm testing with a 20M line text file with three space-separated columns that each look similar to this: \"foo.bar 127.0.0.1   home.foo.bar\"  Results:  $ /usr/bin/time cat test_lines_double | ./split.py        15.61 real         0.01 user         0.38 sys Python: Saw 20000000 lines in 15 seconds.   Crunch Speed: 1333333 $ /usr/bin/time cat test_lines_double | ./split1        23.50 real         0.01 user         0.46 sys C++   : Saw 20000000 lines in 23 seconds.  Crunch speed: 869565 $ /usr/bin/time cat test_lines_double | ./split2        44.69 real         0.02 user         0.62 sys C++   : Saw 20000000 lines in 45 seconds.  Crunch speed: 444444   What am I doing wrong?  Is there a better way to do string splitting in C++ that does not rely on external libraries (i.e. no boost), supports merging sequences of delimiters (like python's split), is thread safe (so no strtok), and whose performance is at least on par with python?  Edit 1 / Partial Solution?:  I tried making it a more fair comparison by having python reset the dummy list and append to it each time, as C++ does. This still isn't exactly what the C++ code is doing, but it's a bit closer. Basically, the loop is now:  for line in sys.stdin:     dummy = []     dummy += line.split()     count += 1   The performance of python is now about the same as the split1 C++ implementation.   /usr/bin/time cat test_lines_double | ./split5.py        22.61 real         0.01 user         0.40 sys Python: Saw 20000000 lines in 22 seconds.   Crunch Speed: 909090   I still am surprised that, even if Python is so optimized for string processing (as Matt Joiner suggested), that these C++ implementations would not be faster.  If anyone has ideas about how to do this in a more optimal way using C++, please share your code.  (I think my next step will be trying to implement this in pure C, although I'm not going to trade off programmer productivity to re-implement my overall project in C, so this will just be an experiment for string splitting speed.)     Thanks to all for your help.  Final Edit/Solution:  Please see Alf's accepted answer.  Since python deals with strings strictly by reference and STL strings are often copied, performance is better with vanilla python implementations.  For comparison, I compiled and ran my data through Alf's code, and here is the performance on the same machine as all the other runs, essentially identical to the naive python implementation (though faster than the python implementation that resets/appends the list, as shown in the above edit):  $ /usr/bin/time cat test_lines_double | ./split6        15.09 real         0.01 user         0.45 sys C++   : Saw 20000000 lines in 15 seconds.  Crunch speed: 1333333   My only small remaining gripe is regarding the amount of code necessary to get C++ to perform in this case.    One of the lessons here from this issue and yesterday's stdin line reading issue (linked above) are that one should always benchmark instead of making naive assumptions about languages' relative \"default\" performance.  I appreciate the education.     Thanks again to all for your suggestions!     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the purpose of the -m switch?",
        "A_Content": "  The first line of the Rationale section of PEP 338 says:     Python 2.4 adds the command line switch -m to allow modules to be located using the Python module namespace for execution as scripts. The motivating examples were standard library modules such as pdb and profile, and the Python 2.4 implementation is fine for this limited purpose.   So you can specify any module in Python's search path this way, not just files in the current directory. You're correct that python mymod1.py mymod2.py args has exactly the same effect. The first line of the Scope of this proposal section states:     In Python 2.4, a module located using -m is executed just as if its filename had been provided on the command line.   With -m more is possible, like working with modules which are part of a package, etc. That's what the rest of PEP 338 is about. Read it for more info.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7610001/what-is-the-purpose-of-the-m-switch",
        "A_Votes": "86",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Could you explain to me what the difference is between calling  python -m mymod1 mymod2.py args   and  python mymod1.py mymod2.py args   It seems in both cases mymod1.py is called and sys.argv is   ['mymod1.py', 'mymod2.py', 'args']   So what is the -m switch for?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to create Python egg file",
        "A_Content": "  You are reading the wrong documentation. You want this: https://setuptools.readthedocs.io/en/latest/setuptools.html#develop-deploy-the-project-source-in-development-mode   Creating setup.py is covered in the distutils documentation in Python's standard library documentation here. The main difference (for python eggs) is you import setup from setuptools, not distutils. Yep. That should be right. I don't think so. pyc files can be version and platform dependent. You might be able to open the egg (they should just be zip files) and delete .py files leaving .pyc files, but it wouldn't be recommended. I'm not sure. That might be “Development Mode”. Or are you looking for some “py2exe” or “py2app” mode?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "packaging",
            "egg"
        ],
        "URL": "https://stackoverflow.com/questions/2026395/how-to-create-python-egg-file",
        "A_Votes": "71",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have questions about egg files in Python.  I have much Python code organized by package and I'm trying to create egg files. I'm following instructions, but they are very common.  According to that, it seems I need to have a setup.py file.   Would you please tell me what I need to put into setup.py file and where it should reside? I suppose it's enough to create setup.py and then start \"setup.py bdist_egg\" for getting egg file. Could you please confirm? Is it possible to include only .pyc files into egg file? Having .egg file how I can just start the code from it without unpacking like java -jar <jar file> does?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to create Python egg file",
        "A_Content": "  For #4, the closest thing to starting java with a jar file for your app is a new feature in Python 2.6, executable zip files and directories.  python myapp.zip   Where myapp.zip is a zip containing a __main__.py file which is executed as the script file to be executed. Your package dependencies can also be included in the file:  __main__.py mypackage/__init__.py mypackage/someliblibfile.py   You can also execute an egg, but the incantation is not as nice:   # Bourn Shell and derivatives (Linux/OSX/Unix) PYTHONPATH=myapp.egg python -m myapp   rem Windows  set PYTHONPATH=myapp.egg python -m myapp   This puts the myapp.egg on the Python path and uses the -m argument to run a module. Your myapp.egg will likely look something like:  myapp/__init__.py myapp/somelibfile.py   And python will run __init__.py (you should check that __file__=='__main__' in your app for command line use).  Egg files are just zip files so you might be able to add __main__.py to your egg with a zip tool and make it executable in python 2.6 and run it like python myapp.egg instead of the above incantation where the PYTHONPATH environment variable is set.  More information on executable zip files including how to make them directly executable with a shebang can be found on Michael Foord's blog post on the subject.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "packaging",
            "egg"
        ],
        "URL": "https://stackoverflow.com/questions/2026395/how-to-create-python-egg-file",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have questions about egg files in Python.  I have much Python code organized by package and I'm trying to create egg files. I'm following instructions, but they are very common.  According to that, it seems I need to have a setup.py file.   Would you please tell me what I need to put into setup.py file and where it should reside? I suppose it's enough to create setup.py and then start \"setup.py bdist_egg\" for getting egg file. Could you please confirm? Is it possible to include only .pyc files into egg file? Having .egg file how I can just start the code from it without unpacking like java -jar <jar file> does?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to create Python egg file",
        "A_Content": "  I think you should use python wheels for distribution instead of egg now.     Wheels are the new standard of python distribution and are intended to   replace eggs. Support is offered in pip >= 1.4 and setuptools >= 0.8.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "packaging",
            "egg"
        ],
        "URL": "https://stackoverflow.com/questions/2026395/how-to-create-python-egg-file",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have questions about egg files in Python.  I have much Python code organized by package and I'm trying to create egg files. I'm following instructions, but they are very common.  According to that, it seems I need to have a setup.py file.   Would you please tell me what I need to put into setup.py file and where it should reside? I suppose it's enough to create setup.py and then start \"setup.py bdist_egg\" for getting egg file. Could you please confirm? Is it possible to include only .pyc files into egg file? Having .egg file how I can just start the code from it without unpacking like java -jar <jar file> does?      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  You can find information about Python audio here: http://wiki.python.org/moin/Audio/  It doesn't look like it can play .mp3 files without external libraries. You could either convert your .mp3 file to a .wav or other format, or use a library like PyMedia.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Your best bet is probably to use pygame/SDL. It's an external library, but it has great support across platforms.  pygame.mixer.init() pygame.mixer.music.load(\"file.mp3\") pygame.mixer.music.play()   You can find more specific documentation about the audio mixer support in the pygame.mixer.music documentation     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  In pydub we've recently opted to use ffplay (via subprocess) from the ffmpeg suite of tools, which internally uses SDL.  It works for our purposes – mainly just making it easier to test the results of pydub code in interactive mode – but it has it's downsides, like causing a new program to appear in the dock on mac.  I've linked the implementation above, but a simplified version follows:  import subprocess  def play(audio_file_path):     subprocess.call([\"ffplay\", \"-nodisp\", \"-autoexit\", audio_file_path])   The -nodisp flag stops ffplay from showing a new window, and the -autoexit flag causes ffplay to exit and return a status code when the audio file is done playing.  edit: pydub now uses pyaudio for playback when it's installed and falls back to ffplay to avoid the downsides I mentioned. The link above shows that implementation as well.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Take a look at Simpleaudio, which is a relatively recent and lightweight library for this purpose:  > pip install simpleaudio   Then:  import simpleaudio as sa  wave_obj = sa.WaveObject.from_wave_file(\"path/to/file.wav\") play_obj = wave_obj.play() play_obj.wait_done()   Make sure to use uncompressed 16 bit PCM files.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Sorry for the late reply, but I think this is a good place to advertise my library ...  AFAIK, the standard library has only one module for playing audio: ossaudiodev. Sadly, this only works on Linux and FreeBSD.  UPDATE: There is also winsound, but obviously this is also platform-specific.  For something more platform-independent, you'll need to use an external library.  My recommendation is the sounddevice module (but beware, I'm the author).  The package includes the pre-compiled PortAudio library for Mac OS X and Windows, and can be easily installed with:  pip install sounddevice --user   It can play back sound from NumPy arrays, but it can also use plain Python buffers (if NumPy is not available).  To play back a NumPy array, that's all you need (assuming that the audio data has a sampling frequency of 44100 Hz):  import sounddevice as sd sd.play(myarray, 44100)   For more details, have a look at the documentation.  It cannot read/write sound files, you'll need a separate library for that.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  If you need portable Python audio library try PyAudio. It certainly has a mac port.  As for mp3 files: it's certainly doable in \"raw\" Python, only I'm afraid you'd have to code everything yourself :). If you can afford some external library I've found some PyAudio - PyLame sample here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Pyglet has the ability to play back audio through an external library called AVbin. Pyglet is a ctypes wrapper around native system calls on each platform it supports. Unfortunately, I don't think anything in the standard library will play audio back.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  You can see this: http://www.speech.kth.se/snack/  s = Sound()  s.read('sound.wav')  s.play()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Aaron's answer appears to be about 10x more complicated than necessary. Just do this if you only need an answer that works on OS X:  from AppKit import NSSound  sound = NSSound.alloc() sound.initWithContentsOfFile_byReference_('/path/to/file.wav', True) sound.play()   One thing... this returns immediately. So you might want to also do this, if you want the call to block until the sound finishes playing.  from time import sleep  sleep(sound.duration())   Edit: I took this function and combined it with variants for Windows and Linux. The result is a pure python, cross platform module with no dependencies called playsound. I've uploaded it to pypi.  pip install playsound   Then run it like this:  from playsound import playsound playsound('/path/to/file.wav', block = False)   MP3 files also work on OS X. WAV should work on all platforms. I don't know what other combinations of platform/file format do or don't work - I haven't tried them yet.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  It is possible to play audio in OS X without any 3rd party libraries using an analogue of the following code. The raw audio data can be input with wave_wave.writeframes. This code extracts 4 seconds of audio from the input file.  import wave import io from AppKit import NSSound   wave_output = io.BytesIO() wave_shell = wave.open(wave_output, mode=\"wb\") file_path = 'SINE.WAV' input_audio = wave.open(file_path) input_audio_frames = input_audio.readframes(input_audio.getnframes())  wave_shell.setnchannels(input_audio.getnchannels()) wave_shell.setsampwidth(input_audio.getsampwidth()) wave_shell.setframerate(input_audio.getframerate())  seconds_multiplier = input_audio.getnchannels() * input_audio.getsampwidth() * input_audio.getframerate()  wave_shell.writeframes(input_audio_frames[second_multiplier:second_multiplier*5])  wave_shell.close()  wave_output.seek(0) wave_data = wave_output.read() audio_stream = NSSound.alloc() audio_stream.initWithData_(wave_data) audio_stream.play()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Try playsound which is a Pure Python, cross platform, single function module with no dependencies for playing sounds.  Install via pip:  $ pip install playsound   Once you've installed, you can use it like this:  from playsound import playsound playsound('/path/to/a/sound/file/you/want/to/play.mp3')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  You can't do this without a nonstandard library.  for windows users who end up in this thread, try pythonwin.  PyGame has some sound support.  For hardware accelerated game audio, you'll probably need to call OpenAL or similar through ctypes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  VLC has some nice python bindings here, for me this worked better than pyglet, at least on Mac OS:  https://wiki.videolan.org/Python_bindings  But it does rely on the VLC application, unfortunately     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Try PySoundCard which uses PortAudio for playback which is available on many platforms. In addition, it recognizes \"professional\" sound devices with lots of channels.  Here a small example from the Readme:  from pysoundcard import Stream  \"\"\"Loop back five seconds of audio data.\"\"\"  fs = 44100 blocksize = 16 s = Stream(samplerate=fs, blocksize=blocksize) s.start() for n in range(int(fs*5/blocksize)):     s.write(s.read(blocksize)) s.stop()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Pypi has a list of modules for python in music. My favorite would be jython because it has more resources and libraries for music. As example of of code to play a single note from the textbook:  # playNote.py  # Demonstrates how to play a single note.  from music import *   # import music library note = Note(C4, HN)   # create a middle C half note  Play.midi(note)       # and play it!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Also on OSX - from SO, using OSX's afplay command:  import subprocess subprocess.call([\"afplay\", \"path/to/audio/file\"])   UPDATE: All this does is specify how to do what the OP wanted to avoid doing in the first place. I guess I posted this here because what OP wanted to avoid was the info I was looking for. Whoops.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  If you're on OSX, you can use the \"os\" module or \"subprocess\" etc. to call the OSX \"play\" command.  From the OSX shell, it looks like   play \"bah.wav\"  It starts to play in about a half-second on my machine.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Simply You can do it with the help of cvlc- I did it in this way:  import os os.popen2(\"cvlc /home/maulo/selfProject/task.mp3 --play-and-exit\")   /home/maulo/selfProject/task.mp3. This is the location of my mp3 file. with the help of \"--play-and-exit\" you will be  able to play again the sound without ending the vlc process.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  Put this at the top of your python script you are writing:  import subprocess   If the wav file IS in the directory of the python script:  f = './mySound.wav' subprocess.Popen(['aplay','-q',f)   If the wav file IS NOT in the directory of the python script:  f = 'mySound.wav' subprocess.Popen(['aplay','-q', 'wav/' + f)   If you want to learn more about aplay:  man aplay      ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  This is the easiest & best iv'e found. It supports Linux/pulseaudio, Mac/coreaudio, and Windows/WASAPI.  import soundfile as sf import soundcard as sc  default_speaker = sc.default_speaker() samples, samplerate = sf.read('bell.wav')  default_speaker.play(samples, samplerate=samplerate)   See https://github.com/bastibe/PySoundFile and https://github.com/bastibe/SoundCard for tons of other super-useful features.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Play audio with Python",
        "A_Content": "  To play a notification sound using python, call a music player, such as vlc. VLC prompted me to use its commandline version, cvlc, instead.  from subprocess import call call([\"cvlc\", \"--play-and-exit\", \"myNotificationTone.mp3\"])   It requires vlc to be preinstalled on the device. Tested on Linux(Ubuntu 16.04 LTS); Running Python 3.5.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "audio"
        ],
        "URL": "https://stackoverflow.com/questions/260738/play-audio-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I play audio (it would be like a 1 second sound) from a Python script?  It would be best if it was platform independent, but firstly it needs to work on a Mac.  I know I could just execute the afplay file.mp3 command from within Python, but is it possible to do it in raw Python? I would also be better if it didn't rely on external libraries.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  Instead of modifying the XML document itself, it's best to parse it and then modify the tags in the result. This way you can handle multiple namespaces and namespace aliases:  from StringIO import StringIO import xml.etree.ElementTree as ET  # instead of ET.fromstring(xml) it = ET.iterparse(StringIO(xml)) for _, el in it:     if '}' in el.tag:         el.tag = el.tag.split('}', 1)[1]  # strip all namespaces root = it.root   This is based on the discussion here: http://bugs.python.org/issue18304     ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  If you remove the xmlns attribute from the xml before parsing it then there won't be a namespace prepended to each tag in the tree.  import re  xmlstring = re.sub(' xmlns=\"[^\"]+\"', '', xmlstring, count=1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "39",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  The answers so far explicitely put the namespace value in the script. For a more generic solution, I would rather extract the namespace from the xml:  import re def get_namespace(element):   m = re.match('\\{.*\\}', element.tag)   return m.group(0) if m else ''   And use it in find method:  namespace = get_namespace(tree.getroot()) print tree.find('./{0}parent/{0}version'.format(namespace)).text      ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  Here's an extension to nonagon's answer, which also strips namespaces off attributes:  from StringIO import StringIO import xml.etree.ElementTree as ET  # instead of ET.fromstring(xml) it = ET.iterparse(StringIO(xml)) for _, el in it:     if '}' in el.tag:         el.tag = el.tag.split('}', 1)[1]  # strip all namespaces     for at in el.attrib.keys(): # strip namespaces of attributes too         if '}' in at:             newat = at.split('}', 1)[1]             el.attrib[newat] = el.attrib[at]             del el.attrib[at] root = it.root      ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  You can use the elegant string formatting construct as well:  ns='http://www.test.com' el2 = tree.findall(\"{%s}DEAL_LEVEL/{%s}PAID_OFF\" %(ns,ns))   or, if you're sure that PAID_OFF only appears in one level in tree:  el2 = tree.findall(\".//{%s}PAID_OFF\" % ns)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python ElementTree module: How to ignore the namespace of XML files to locate matching element when using the method “find”, “findall”",
        "A_Content": "  If you're using ElementTree and not cElementTree you can force Expat to ignore namespace processing by replacing ParserCreate():  from xml.parsers import expat oldcreate = expat.ParserCreate expat.ParserCreate = lambda encoding, sep: oldcreate(encoding, None)   ElementTree tries to use Expat by calling ParserCreate() but provides no option to not provide a namespace separator string, the above code will cause it to be ignore but be warned this could break other things.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "namespaces",
            "find",
            "elementtree",
            "findall"
        ],
        "URL": "https://stackoverflow.com/questions/13412496/python-elementtree-module-how-to-ignore-the-namespace-of-xml-files-to-locate-ma",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to use the method of \"findall\" to locate some elements of the source xml file in the ElementTree module.  However, the source xml file (test.xml) has namespace. I truncate part of xml file as sample:  <?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <XML_HEADER xmlns=\"http://www.test.com\">     <TYPE>Updates</TYPE>     <DATE>9/26/2012 10:30:34 AM</DATE>     <COPYRIGHT_NOTICE>All Rights Reserved.</COPYRIGHT_NOTICE>     <LICENSE>newlicense.htm</LICENSE>     <DEAL_LEVEL>         <PAID_OFF>N</PAID_OFF>         </DEAL_LEVEL> </XML_HEADER>   The sample python code is below:  from xml.etree import ElementTree as ET tree = ET.parse(r\"test.xml\") el1 = tree.findall(\"DEAL_LEVEL/PAID_OFF\") # Return None el2 = tree.findall(\"{http://www.test.com}DEAL_LEVEL/{http://www.test.com}PAID_OFF\") # Return <Element '{http://www.test.com}DEAL_LEVEL/PAID_OFF' at 0xb78b90>   Although it can works, because there is a namespace \"{http://www.test.com}\", it's very inconvenient to add a namespace in front of each tag.  How can I ignore the namespace when using the method of \"find\", \"findall\" and so on?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  Update: See @GwynBleidD's comment below for the problems this solution can cause, and see @Rockallite's answer below for an approach that's more durable to future model changes.    Assuming you have a fixture file in <yourapp>/fixtures/initial_data.json   Create your empty migration:  In Django 1.7:  python manage.py makemigrations --empty <yourapp>   In Django 1.8+, you can provide a name:  python manage.py makemigrations --empty <yourapp> --name load_intial_data  Edit your migration file <yourapp>/migrations/0002_auto_xxx.py  2.1. Custom implementation, inspired by Django' loaddata (initial answer):  import os from sys import path from django.core import serializers  fixture_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../fixtures')) fixture_filename = 'initial_data.json'  def load_fixture(apps, schema_editor):     fixture_file = os.path.join(fixture_dir, fixture_filename)      fixture = open(fixture_file, 'rb')     objects = serializers.deserialize('json', fixture, ignorenonexistent=True)     for obj in objects:         obj.save()     fixture.close()  def unload_fixture(apps, schema_editor):     \"Brutally deleting all entries for this model...\"      MyModel = apps.get_model(\"yourapp\", \"ModelName\")     MyModel.objects.all().delete()  class Migration(migrations.Migration):        dependencies = [         ('yourapp', '0001_initial'),     ]      operations = [         migrations.RunPython(load_fixture, reverse_code=unload_fixture),     ]   2.2. A simpler solution for load_fixture (per @juliocesar's suggestion):  from django.core.management import call_command  fixture_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../fixtures')) fixture_filename = 'initial_data.json'  def load_fixture(apps, schema_editor):     fixture_file = os.path.join(fixture_dir, fixture_filename)     call_command('loaddata', fixture_file)    Useful if you want to use a custom directory.  2.3. Simplest: calling loaddata with app_label will load fixtures from the <yourapp>'s fixtures dir automatically :              from django.core.management import call_command  fixture = 'initial_data'  def load_fixture(apps, schema_editor):     call_command('loaddata', fixture, app_label='yourapp')    If you don't specify app_label, loaddata will try to load fixture filename from all apps fixtures directories (which you probably don't want).  Run it  python manage.py migrate <yourapp>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  Short version  You should NOT use loaddata management command directly in a data migration.  # Bad example for a data migration from django.db import migrations from django.core.management import call_command   def load_fixture(apps, schema_editor):     # No, it's wrong. DON'T DO THIS!     call_command('loaddata', 'your_data.json', app_label='yourapp')   class Migration(migrations.Migration):     dependencies = [         # Dependencies to other migrations     ]      operations = [         migrations.RunPython(load_fixture),     ]   Long version  loaddata utilizes django.core.serializers.python.Deserializer which uses the most up-to-date models to deserialize historical data in a migration. That's incorrect behavior.  For example, supposed that there is a data migration which utilizes loaddata management command to load data from a fixture, and it's already applied on your development environment.  Later, you decide to add a new required field to the corresponding model, so you do it and make a new migration against your updated model (and possibly provide a one-off value to the new field when ./manage.py makemigrations prompts you).  You run the next migration, and all is well.  Finally, you're done developing your Django application, and you deploy it on the production server. Now it's time for you to run the whole migrations from scratch on the production environment.  However, the data migration fails. That's because the deserialized model from loaddata command, which represents the current code, can't be saved with empty data for the new required field you added. The original fixture lacks necessary data for it!  But even if you update the fixture with required data for the new field, the data migration still fails. When the data migration is running, the next migration which adds the corresponding column to the database, is not applied yet. You can't save data to a column which does not exist!  Conclusion: in a data migration, the loaddata command introduces potential inconsistency between the model and the database. You should definitely NOT use it directly in a data migration.  The Solution  loaddata command relies on django.core.serializers.python._get_model function to get the corresponding model from a fixture, which will return the most up-to-date version of a model. We need to monkey-patch it so it gets the historical model.  (The following code works for Django 1.8.x)  # Good example for a data migration from django.db import migrations from django.core.serializers import base, python from django.core.management import call_command   def load_fixture(apps, schema_editor):     # Save the old _get_model() function     old_get_model = python._get_model      # Define new _get_model() function here, which utilizes the apps argument to     # get the historical version of a model. This piece of code is directly stolen     # from django.core.serializers.python._get_model, unchanged. However, here it     # has a different context, specifically, the apps variable.     def _get_model(model_identifier):         try:             return apps.get_model(model_identifier)         except (LookupError, TypeError):             raise base.DeserializationError(\"Invalid model identifier: '%s'\" % model_identifier)      # Replace the _get_model() function on the module, so loaddata can utilize it.     python._get_model = _get_model      try:         # Call loaddata command         call_command('loaddata', 'your_data.json', app_label='yourapp')     finally:         # Restore old _get_model() function         python._get_model = old_get_model   class Migration(migrations.Migration):     dependencies = [         # Dependencies to other migrations     ]      operations = [         migrations.RunPython(load_fixture),     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  Inspired by some of the comments (namely n__o's) and the fact that I have a lot of initial_data.* files spread out over multiple apps I decided to create a Django app that would facilitate the creation of these data migrations.  Using django-migration-fixture you can simply run the following management command and it will search through all your INSTALLED_APPS for initial_data.* files and turn them into data migrations.  ./manage.py create_initial_data_fixtures Migrations for 'eggs':   0002_auto_20150107_0817.py: Migrations for 'sausage':   Ignoring 'initial_data.yaml' - migration already exists. Migrations for 'foo':   Ignoring 'initial_data.yaml' - not migrated.   See django-migration-fixture for install/usage instructions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  The best way to load initial data in migrated apps is through data migrations (as also recommended in the docs). The advantage is that the fixture is thus loaded in both during the tests as well as production.  @n__o suggested reimplementing loaddata command in the migration. In my tests, however, calling loaddata command directly also works fine. The whole process is thus:   Create a fixture file in <yourapp>/fixtures/initial_data.json Create your empty migration:  python manage.py makemigrations --empty <yourapp>  Edit your migration file /migrations/0002_auto_xxx.py  from django.db import migrations from django.core.management import call_command   def loadfixture(apps, schema_editor):     call_command('loaddata', 'initial_data.json')   class Migration(migrations.Migration):      dependencies = [         ('<yourapp>', '0001_initial'),     ]      operations = [         migrations.RunPython(loadfixture),     ]       ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  In order to give your database some initial data, write a data migration. In the data migration, use the RunPython function to load your data.  Don't write any loaddata command as this way is deprecated.  Your data migrations will be run only once. The migrations are an ordered sequence of migrations. When the 003_xxxx.py migrations is run, django migrations writes in the database that this app is migrated until this one (003), and will run the following migrations only.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  The solutions presented above didn't work for me unfortunately. I found that every time I change my models I have to update my fixtures. Ideally I would instead write data migrations to modify created data and fixture-loaded data similarly.  To facilitate this I wrote a quick function which will look in the fixtures directory of the current app and load a fixture. Put this function into a migration in the point of the model history that matches the fields in the migration.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Loading initial data with Django 1.7 and data migrations",
        "A_Content": "  In my opinion fixtures are a bit bad. If your database changes frequently, keeping them up-to-date will came a nightmare soon. Actually, it's not only my opinion, in the book \"Two Scoops of Django\" it's explained much better.  Instead I'll write a Python file to provide initial setup. If you need something more I'll suggest you look at Factory boy.  If you need to migrate some data you should use data migrations.  There's also \"Burn Your Fixtures, Use Model Factories\" about using fixtures.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json",
            "django",
            "migration",
            "data-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25960850/loading-initial-data-with-django-1-7-and-data-migrations",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I recently switched from Django 1.6 to 1.7, and I began using migrations (I never used South).  Before 1.7, I used to load initial data with a fixture/initial_data.json file, which was loaded with the python manage.py syncdb command (when creating the database).  Now, I started using migrations, and this behavior is deprecated :     If an application uses migrations, there is no automatic loading of fixtures.   Since migrations will be required for applications in Django 2.0, this behavior is considered deprecated. If you want to load initial data for an app, consider doing it in a data migration.    (https://docs.djangoproject.com/en/1.7/howto/initial-data/#automatically-loading-initial-data-fixtures)   The official documentation does not have a clear example on how to do it, so my question is :  What is the best way to import such initial data using data migrations :   Write Python code with multiple calls to mymodel.create(...), Use or write a Django function (like calling loaddata) to load data from a JSON fixture file.   I prefer the second option.  I don't want to use South, as Django seems to be able to do it natively now.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Mocking a class: Mock() or patch()?",
        "A_Content": "  mock.patch is a very very different critter than mock.Mock.  patch replaces the class with a mock object and lets you work with the mock instance.  Take a look at this snippet:  >>> class MyClass(object): ...   def __init__(self): ...     print 'Created MyClass@{0}'.format(id(self)) ...  >>> def create_instance(): ...   return MyClass() ...  >>> x = create_instance() Created MyClass@4299548304 >>>  >>> @mock.patch('__main__.MyClass') ... def create_instance2(MyClass): ...   MyClass.return_value = 'foo' ...   return create_instance() ...  >>> i = create_instance2() >>> i 'foo' >>> def create_instance(): ...   print MyClass ...   return MyClass() ... >>> create_instance2() <mock.Mock object at 0x100505d90> 'foo' >>> create_instance() <class '__main__.MyClass'> Created MyClass@4300234128 <__main__.MyClass object at 0x100505d90>   patch replaces MyClass in a way that allows you to control the usage of the class in functions that you call.  Once you patch a class, references to the class are completely replaced by the mock instance.  mock.patch is usually used when you are testing something that creates a new instance of a class inside of the test.  mock.Mock instances are clearer and are preferred.  If your self.sut.something method created an instance of MyClass instead of receiving an instance as a parameter, then mock.patch would be appropriate here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/8180769/mocking-a-class-mock-or-patch",
        "A_Votes": "118",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am using mock with Python and was wondering which of those two approaches is better (read: more pythonic).   Method one:  Just create a mock object and use that. The code looks like:  def test_one (self):     mock = Mock()     mock.method.return_value = True      self.sut.something(mock) # This should called mock.method and checks the result.      self.assertTrue(mock.method.called)   Method two:  Use patch to create a mock.  The code looks like:  @patch(\"MyClass\") def test_two (self, mock):     instance = mock.return_value     instance.method.return_value = True     self.sut.something(instance) # This should called mock.method and checks the result.      self.assertTrue(instance.method.called)   Both methods do the same thing.  I am unsure of the differences.   Could anyone enlighten me?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Mocking a class: Mock() or patch()?",
        "A_Content": "  I've got a YouTube video on this.  Short answer: Use mock when you're passing in the thing that you want mocked, and patch if you're not.  Of the two, mock is strongly preferred because it means you're writing code with proper dependency injection.  Silly example:  # Use a mock to test this. my_custom_tweeter(twitter_api, sentence):     sentence.replace('cks','x')   # We're cool and hip.     twitter_api.send(sentence)  # Use a patch to mock out twitter_api. You have to patch the Twitter() module/class  # and have it return a mock. Much uglier, but sometimes necessary. my_badly_written_tweeter(sentence):     twitter_api = Twitter(user=\"XXX\", password=\"YYY\")     sentence.replace('cks','x')      twitter_api.send(sentence)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/8180769/mocking-a-class-mock-or-patch",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using mock with Python and was wondering which of those two approaches is better (read: more pythonic).   Method one:  Just create a mock object and use that. The code looks like:  def test_one (self):     mock = Mock()     mock.method.return_value = True      self.sut.something(mock) # This should called mock.method and checks the result.      self.assertTrue(mock.method.called)   Method two:  Use patch to create a mock.  The code looks like:  @patch(\"MyClass\") def test_two (self, mock):     instance = mock.return_value     instance.method.return_value = True     self.sut.something(instance) # This should called mock.method and checks the result.      self.assertTrue(instance.method.called)   Both methods do the same thing.  I am unsure of the differences.   Could anyone enlighten me?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to remove specific element in an array using python",
        "A_Content": "  You don't need to iterate the array. Just:  >>> x = ['ala@ala.com', 'bala@bala.com'] >>> x ['ala@ala.com', 'bala@bala.com'] >>> x.remove('ala@ala.com') >>> x ['bala@bala.com']   This will remove the first occurence that matches the string.  EDIT: After your edit, you still don't need to iterate over. Just do:  index = initial_list.index(item1) del initial_list[index] del other_list[index]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays"
        ],
        "URL": "https://stackoverflow.com/questions/7118276/how-to-remove-specific-element-in-an-array-using-python",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to Python and want to write something that removes a specific element in an array. I know that I have to for loop through the array to find the element that matches the content, but Python for loops are a bit funny.   lets say that I have an array of emails and I want to get rid of the element that matches some email string.  I'd actually like to use the for loop structure because I need to use the same index for other arrays as well.   Here is the code that I have:  for index, item in emails:     if emails[index] == 'something@something.com':          emails.pop(index)          otherarray.pop(index)      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to remove specific element in an array using python",
        "A_Content": "  Using filter() and lambda would provide a neat and terse method of removing unwanted values:  newEmails = list(filter(lambda x : x != 'something@something.com', emails))   This does not modify emails. It creates the new list newEmails containing only elements for which the anonymous function returned True.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays"
        ],
        "URL": "https://stackoverflow.com/questions/7118276/how-to-remove-specific-element-in-an-array-using-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and want to write something that removes a specific element in an array. I know that I have to for loop through the array to find the element that matches the content, but Python for loops are a bit funny.   lets say that I have an array of emails and I want to get rid of the element that matches some email string.  I'd actually like to use the for loop structure because I need to use the same index for other arrays as well.   Here is the code that I have:  for index, item in emails:     if emails[index] == 'something@something.com':          emails.pop(index)          otherarray.pop(index)      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to remove specific element in an array using python",
        "A_Content": "  The sane way to do this is to use zip() and a List Comprehension / Generator Expression:  filtered = (     (email, other)          for email, other in zip(emails, other_list)              if email == 'something@something.com')  new_emails, new_other_list = zip(*filtered)   Also, if your'e not using array.array() or numpy.array(), then most likely you are using [] or list(), which give you Lists, not Arrays. Not the same thing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays"
        ],
        "URL": "https://stackoverflow.com/questions/7118276/how-to-remove-specific-element-in-an-array-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and want to write something that removes a specific element in an array. I know that I have to for loop through the array to find the element that matches the content, but Python for loops are a bit funny.   lets say that I have an array of emails and I want to get rid of the element that matches some email string.  I'd actually like to use the for loop structure because I need to use the same index for other arrays as well.   Here is the code that I have:  for index, item in emails:     if emails[index] == 'something@something.com':          emails.pop(index)          otherarray.pop(index)      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to remove specific element in an array using python",
        "A_Content": "  Your for loop is not right, if you need the index in the for loop use:  for index, item in enumerate(emails):     # whatever (but you can't remove element while iterating)   In your case, Bogdan solution is ok, but your data structure choice is not so good. Having to maintain these two lists with data from one related to data from the other at same index is clumsy.  A list of tupple (email, otherdata) may be better, or a dict with email as key.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays"
        ],
        "URL": "https://stackoverflow.com/questions/7118276/how-to-remove-specific-element-in-an-array-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and want to write something that removes a specific element in an array. I know that I have to for loop through the array to find the element that matches the content, but Python for loops are a bit funny.   lets say that I have an array of emails and I want to get rid of the element that matches some email string.  I'd actually like to use the for loop structure because I need to use the same index for other arrays as well.   Here is the code that I have:  for index, item in emails:     if emails[index] == 'something@something.com':          emails.pop(index)          otherarray.pop(index)      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How to remove specific element in an array using python",
        "A_Content": "  There is an alternative solution to this problem which also deals with duplicate matches.  We start with 2 lists of equal length: emails, otherarray. The objective is to remove items from both lists for each index i where emails[i] == 'something@something.com'.  This can be achieved using a list comprehension and then splitting via zip:  emails = ['abc@def.com', 'something@something.com', 'ghi@jkl.com'] otherarray = ['some', 'other', 'details']  from operator import itemgetter  res = [(i, j) for i, j in zip(emails, otherarray) if i!= 'something@something.com'] emails, otherarray = map(list, map(itemgetter(0, 1), zip(*res)))  print(emails)      # ['abc@def.com', 'ghi@jkl.com'] print(otherarray)  # ['some', 'details']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays"
        ],
        "URL": "https://stackoverflow.com/questions/7118276/how-to-remove-specific-element-in-an-array-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python and want to write something that removes a specific element in an array. I know that I have to for loop through the array to find the element that matches the content, but Python for loops are a bit funny.   lets say that I have an array of emails and I want to get rid of the element that matches some email string.  I'd actually like to use the for loop structure because I need to use the same index for other arrays as well.   Here is the code that I have:  for index, item in emails:     if emails[index] == 'something@something.com':          emails.pop(index)          otherarray.pop(index)      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None) # 1   If you need to fetch repeatedly from name, you should index them by name (using a dictionary), this way get operations would be O(1) time. An idea:  def build_dict(seq, key):     return dict((d[key], dict(d, index=index)) for (index, d) in enumerate(seq))  info_by_name = build_dict(lst, key=\"name\") tom_info = info_by_name.get(\"Tom\") # {'index': 1, 'id': '2345', 'name': 'Tom'}      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "101",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  A simple readable version is  def find(lst, key, value):     for i, dic in enumerate(lst):         if dic[key] == value:             return i     return -1      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  It won't be efficient, as you need to walk the list checking every item in it (O(n)). If you want efficiency, you can use dict of dicts.  On the question, here's one possible way to find it (though, if you want to stick to this data structure, it's actually more efficient to use a generator as Brent Newey has written in the comments; see also tokland's answer):  >>> L = [{'id':'1234','name':'Jason'}, ...         {'id':'2345','name':'Tom'}, ...         {'id':'3456','name':'Art'}] >>> [i for i,_ in enumerate(L) if _['name'] == 'Tom'][0] 1      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  Here's a function that finds the dictionary's index position if it exists.  dicts = [{'id':'1234','name':'Jason'},          {'id':'2345','name':'Tom'},          {'id':'3456','name':'Art'}]  def find_index(dicts, key, value):     class Null: pass     for i, d in enumerate(dicts):         if d.get(key, Null) == value:             return i     else:         raise ValueError('no dict with the key and value combination found')  print find_index(dicts, 'name', 'Tom') # 1 find_index(dicts, 'name', 'Ensnare') # ValueError: no dict with the key and value combination found      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  For a given iterable, more_itertools.locate yields positions of items that satisfy a predicate.  import more_itertools as mit   iterable = [     {\"id\": \"1234\", \"name\": \"Jason\"},     {\"id\": \"2345\", \"name\": \"Tom\"},     {\"id\": \"3456\", \"name\": \"Art\"} ]  list(mit.locate(iterable, pred=lambda d: d[\"name\"] == \"Tom\")) # [1]   more_itertools is a third-party library that implements itertools recipes among other useful tools.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Find the index of a dict within a list, by matching the dict's value",
        "A_Content": "  Seems most logical to use a filter/index combo:  names=[{}, {'name': 'Tom'},{'name': 'Tony'}] names.index(filter(lambda n: n.get('name') == 'Tom', names)[0]) 1   And if you think there could be multiple matches:  [names.index(n) for item in filter(lambda n: n.get('name') == 'Tom', names)] [1]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of dicts:  list = [{'id':'1234','name':'Jason'},         {'id':'2345','name':'Tom'},         {'id':'3456','name':'Art'}]   How can I efficiently find the index position [0],[1], or [2] by matching on name = 'Tom'?  If this were a one-dimensional list I could do list.index() but I'm not sure how to proceed by searching the values of the dicts within the list.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I create a datetime in Python from milliseconds?",
        "A_Content": "  Just convert it to timestamp  datetime.datetime.fromtimestamp(ms/1000.0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/748491/how-do-i-create-a-datetime-in-python-from-milliseconds",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I can create a similar Date object in Java by java.util.Date(milliseconds). How do I create the comparable in Python?     Allocates a Date object and initializes it to represent the specified number of milliseconds since the standard base time known as \"the epoch\", namely January 1, 1970, 00:00:00 GMT.      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I create a datetime in Python from milliseconds?",
        "A_Content": "  What about this?  I presume it can be counted on to handle dates before 1970 and after 2038.             target_date_time_ms = 200000 # or whatever    base_datetime = datetime.datetime( 1970, 1, 1 )    delta = datetime.timedelta( 0, 0, 0, target_date_time_ms )    target_date = base_datetime + delta   as mentioned in the Python standard lib:     fromtimestamp() may raise ValueError, if the timestamp is out of the   range of values supported by the platform C localtime() or gmtime()   functions. It’s common for this to be restricted to years in 1970   through 2038.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime"
        ],
        "URL": "https://stackoverflow.com/questions/748491/how-do-i-create-a-datetime-in-python-from-milliseconds",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I can create a similar Date object in Java by java.util.Date(milliseconds). How do I create the comparable in Python?     Allocates a Date object and initializes it to represent the specified number of milliseconds since the standard base time known as \"the epoch\", namely January 1, 1970, 00:00:00 GMT.      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Open the file in universal-newline mode using the CSV Django module",
        "A_Content": "  I finally found the solution:  mypath = customerbulk.objects.get(pk=1).fileup.path o = open(mypath,'rU') mydata = csv.reader(o)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "macos",
            "csv",
            "newline"
        ],
        "URL": "https://stackoverflow.com/questions/6726953/open-the-file-in-universal-newline-mode-using-the-csv-django-module",
        "A_Votes": "146",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to access a model.filefield in Django to parse a CSV file in Python using the csv module. It's working on Windows, but on Mac it gave me this:  Exception Type: Error  Exception Value: new-line character seen in unquoted field - do you need to open the file in universal-newline mode?   This is the code:  myfile = customerbulk.objects.all()[0].fileup  mydata = csv.reader(myfile)     for email,mobile,name,civilid in mydata:         print email,mobile,name,civilid      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  You can just construct a list from the range object:  my_list = list(range(1, 1001))   This is how you do it with generators in python2.x as well.  Typically speaking, you probably don't need a list though since you can come by the value of my_list[i] more efficiently (i + 1), and if you just need to iterate over it, you can just fall back on range.  Also note that on python2.x, xrange is still indexable1.  This means that range on python3.x also has the same property2  1print xrange(30)[12] works for python2.x  2The analogous statement to 1 in python3.x is print(range(30)[12]) and that works also.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  in Python 3.x, the range() function got its own type. so in this case you must use iterator  list(range(1000))     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  In Pythons <= 3.4 you can, as others suggested, use list(range(10)) in order to make a list out of a range (In general, any iterable).  Another alternative, introduced in Python 3.5 with its unpacking generalizations, is by using * in a list literal []:  >>> r = range(10) >>> l = [*r] >>> print(l) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   Though this is equivalent to list(r), it's literal syntax and the fact that no function call is involved does let it execute faster. It's also less characters, if you need to code golf :-)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  You really shouldn't need to use the numbers 1-1000 in a list. But if for some reason you really do need these numbers, then you could do:  [i for i in range(1, 1001)]   List Comprehension in a nutshell:  The above list comprehension translates to:  nums = [] for i in range(1, 1001):     nums.append(i)   This is just the list comprehension syntax, though from 2.x. I know that this will work in python 3, but am not sure if there is an upgraded syntax as well  Range starts inclusive of the first parameter; but ends Up To, Not Including the second Parameter (when supplied 2 parameters; if the first parameter is left off, it'll start at '0')    range(start, end+1) [start, start+1, .., end]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  Actually, if you want 1-1000 (inclusive), use the range(...) function with parameters 1 and 1001: range(1, 1001), because the range(start, end) function goes from start to (end-1), inclusive.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  In fact, this is a retro-gradation of Python3 as compared to Python2. Certainly, Python2 which uses range() and xrange() is more convenient than Python3 which uses list(range()) and range() respectively. The reason is because the original designer of Python3 is not very experienced, they only considered the use of the range function by many beginners to iterate over a large number of elements where it is both memory and CPU inefficient; but they neglected the use of the range function to produce a number list. Now, it is too late for them to change back already.  If I was to be the designer of Python3, I will:   use irange to return a sequence iterator use lrange to return a sequence list use range to return either a sequence iterator (if the number of elements is large, e.g., range(9999999) or a sequence list (if the number of elements is small, e.g., range(10))   That should be optimal.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  Use Range in Python 3.  Here is a example function that return in between numbers from two numbers  def get_between_numbers(a, b):     \"\"\"     This function will return in between numbers from two numbers.     :param a:     :param b:     :return:     \"\"\"     x = []     if b < a:         x.extend(range(b, a))         x.append(a)     else:         x.extend(range(a, b))         x.append(b)      return x      Result   print(get_between_numbers(5, 9)) print(get_between_numbers(9, 5))  [5, 6, 7, 8, 9]   [5, 6, 7, 8, 9]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Python 3 turn range to a list",
        "A_Content": "  The reason why Python3 lacks a function for directly getting a ranged list is because the original Python3 designer was quite novice in Python2. He only considered the use of range() function in a for loop, thus, the list should never need to be expanded. In fact, very often we do need to use the range() function to produce a list and pass into a function.  Therefore, in this case, Python3 is less convenient as compared to Python2 because:   In Python2, we have xrange() and range();  In Python3, we have range() and list(range())   Nonetheless, you can still use list expansion in this way:  [*range(N)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "list",
            "range"
        ],
        "URL": "https://stackoverflow.com/questions/11480042/python-3-turn-range-to-a-list",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to make a list with numbers 1-1000 in it. Obviously this would be annoying to write/read, so I'm attempting to make a list with a range in it. In Python 2 it seems that:  some_list = range(1,1000)   would have worked, but in Python 3 the range is similar to the xrange of Python 2?  Can anyone provide some insight into this?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  If you can install the latest Python (2.7.9 and up) Pip is now bundled with it.  See: https://docs.python.org/2.7//installing/index.html If not : Update (from the release notes):     Beginning with v1.5.1, pip does not require setuptools prior to running get-pip.py. Additionally, if setuptools (or distribute) is not already installed, get-pip.py will install setuptools for you.   I now run the regular:  curl --silent --show-error --retry 5 https://bootstrap.pypa.io/get-pip.py | sudo python   Here are the official installation instructions: http://pip.readthedocs.org/en/latest/installing.html#install-pip  EDIT 25-Jul-2013: Changed URL for setuptools install.    EDIT 10-Feb-2014: Removed setuptools install (thanks @Ciantic)  EDIT 26-Jun-2014: Updated URL again (thanks @LarsH)  EDIT 1-Mar-2015: Pip is now bundled with Python      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "87",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  http://www.pip-installer.org/en/latest/installing.html is really the canonical answer to this question.  Specifically, the systemwide instructions are:  $ curl -O http://python-distribute.org/distribute_setup.py $ python distribute_setup.py $ curl -O https://raw.github.com/pypa/pip/master/contrib/get-pip.py $ python get-pip.py   The section quoted in the question is the virtualenv instructions rather than the systemwide ones. The easy_install instructions have been around for longer, but it isn't necessary to do it that way any more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  This answer comes from @webology on Twitter:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install --upgrade pip virtualenv virtualenvwrapper   My added notes:    On Mac/Windows (and Linux if the apt repo is outdated) you'd replace the first step with downloading setuptools from http://pypi.python.org/pypi/setuptools On Windows you'd have to omit virtualenvwrapper from the last step and install it manually somehow. I don't know if there's a way to do this without Cygwin, but I hope so.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  On Ubuntu 12.04 I've had good luck just using the package manager:  sudo apt-get install python-pip virtualenvwrapper      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  There is no preferred method - everything depends on your needs. Often you need to have different Python interpreters on the system for whatever reason. In this case you need to install the stuff individually for each interpreter. Apart from that: I prefer installing stuff myself instead of depending of pre-packaged stuff sometimes causing issues - but that's only one possible opionion.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  There really isn't a single \"answer\" to this question, but there are definitely some helpful concepts that can help you to come to a decision.   The first question that needs to be answered in your use case is \"Do I want to use the system Python?\" If you want to use the Python distributed with your operating system, then using the apt-get install method may be just fine. Depending on the operating system distribution method though, you still have to ask some more questions, such as \"Do I want to install multiple versions of this package?\" If the answer is yes, then it is probably not a good idea to use something like apt. Dpkg pretty much will just untar an archive at the root of the filesystem, so it is up to the package maintainer to make sure the package installs safely under very little assumptions. In the case of most debian packages, I would assume (someone can feel free to correct me here) that they simply untar and provide a top level package.   For example, say the package is \"virtualenv\", you'd end up with /usr/lib/python2.x/site-packages/virtualenv. If you install it with easy_install you'd get something like /usr/lib/python2.x/site-packages/virtualenv.egg-link that might point to /usr/lib/python2.x/site-packages/virtualenv-1.2-2.x.egg which may be a directory or zipped egg. Pip does something similar although it doesn't use eggs and instead will place the top level package directly in the lib directory.   I might be off on the paths, but the point is that each method takes into account different needs. This is why tools like virtualenv are helpful as they allow you to sandbox your Python libraries such that you can have any combination you need of libraries and versions.   Setuptools also allows installing packages as multiversion which means there is not a singular module_name.egg-link created. To import those packages you need to use pkg_resources and the __import__ function.  Going back to your original question, if you are happy with the system python and plan on using virtualenv and pip to build environments for different applications, then installing virtualenv and / or pip at the system level using apt-get seems totally appropriate. One word of caution though is that if you plan on upgrading your distributions Python, that may have a ripple effect through your virtualenvs if you linked back to your system site packages.   I should also mention that none of these options is inherently better than the others. They simply take different approaches. Using the system version is an excellent way to install Python applications, yet it can be a very difficult way to develop with Python. Easy install and setuptools is very convenient in a world without virtualenv, but if you need to use different versions of the same library, then it also become rather unwieldy. Pip and virtualenv really act more like a virtual machine. Instead of taking care to install things side by side, you just create an whole new environment. The downside here is that 30+ virtualenvs later you might have used up quite bit of diskspace and cluttered up your filesystem.   As you can see, with the many options it is difficult to say which method to use, but with a little investigation into your use cases, you should be able to find a method that works.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  Since virtualenvs contain pip by default, I almost never install pip globally.  What I do ends up looking more like:  $ sudo apt-get install python-setuptools $ curl -O http://python-distribute.org/distribute_setup.py $ sudo python distribute_setup.py $ sudo easy_install virtualenv   I then proceed to install and set up virtualenvwrapper to my liking and off I go.  it might also be worthwhile to take a look at Jeremy Avnet's virtualenv-burrito:  https://github.com/brainsik/virtualenv-burrito     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  @ericholscher says on Twitter, \"The one in the official docs..\"  It's a great point, you should do what the docs say.  Quoted from the official pip installation instructions at http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  Starting from distro packages, you can either use:  sudo apt-get install python-virtualenv   which lets you create virtualenvs, or  sudo apt-get install python{,3}-pip   which lets you install arbitrary packages to your home directory.  If you're used to virtualenv, the first command gives you everything you need (remember, pip is bundled and will be installed in any virtualenv you create).  If you just want to install packages, the second command gives you what you need.  Use pip like this:  pip install --user something   and put something like  PATH=~/.local/bin:$PATH   in your ~/.bashrc.    If your distro is ancient and you don't want to use its packages at all (except for Python itself, probably), you can download virtualenv, either as a tarball or as a standalone script:  wget -O ~/bin/virtualenv https://raw.github.com/pypa/virtualenv/master/virtualenv.py chmod +x ~/bin/virtualenv     If your distro is more of the bleeding edge kind, Python3.3 has built-in virtualenv-like abilities:  python3 -m venv ./venv   This runs way faster, but setuptools and pip aren't included.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  To install pip on a mac (osx), the following one liner worked great for me:  sudo easy_install pip      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  Do this:  curl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\" python get-pip.py pip install virtualenv   See    https://pip.pypa.io/en/latest/installing.html http://docs.python-guide.org/en/latest/dev/virtualenvs/      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  In Raspbian, there is even no need to mention python2.7. Indeed this is best way to install pip if python version in less then 2.7.9.  curl --silent --show-error --retry 5 https://bootstrap.pypa.io/get-pip.py | sudo python   Thanks to @tal-weiss     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  https://github.com/pypa/pip/raw/master/contrib/get-pip.py is probably the right way now.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  I use get-pip and virtualenv-burrito to install all this. Not sure if python-setuptools is required.  # might be optional. I install as part of my standard ubuntu setup script sudo apt-get -y install python-setuptools  # install pip (using get-pip.py from pip contrib) curl -O https://raw.github.com/pypa/pip/develop/contrib/get-pip.py && sudo python get-pip.py  # one-line virtualenv and virtualenvwrapper using virtualenv-burrito curl -s https://raw.github.com/brainsik/virtualenv-burrito/master/virtualenv-burrito.sh | bash      ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  On Debian the best way to do it would be   sudo apt-get install python-pip     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What is the official “preferred” way to install pip and virtualenv systemwide?",
        "A_Content": "  The former method is fine. The only problem I can see is that you might end up with an old version of setuptools (if the apt repository hasn't been kept up-to-date..     ",
        "Language": "Python",
        "Tags": [
            "python",
            "virtualenv",
            "setuptools",
            "pip",
            "easy-install"
        ],
        "URL": "https://stackoverflow.com/questions/5585875/what-is-the-official-preferred-way-to-install-pip-and-virtualenv-systemwide",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it this, which people seem to recommend most often:  $ sudo apt-get install python-setuptools $ sudo easy_install pip $ sudo pip install virtualenv   Or this, which I got from http://www.pip-installer.org/en/latest/installing.html:  $ curl -O https://github.com/pypa/virtualenv/raw/master/virtualenv.py $ python virtualenv.py my_new_env $ . my_new_env/bin/activate (my_new_env)$ pip install ...   Or something entirely different?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  You could serialise the function bytecode and then reconstruct it on the caller.  The marshal module can be used to serialise code objects, which can then be reassembled into a function.  ie:  import marshal def foo(x): return x*x code_string = marshal.dumps(foo.func_code)   Then in the remote process (after transferring code_string):  import marshal, types  code = marshal.loads(code_string) func = types.FunctionType(code, globals(), \"some_func_name\")  func(10)  # gives 100   A few caveats:   marshal's format (any python bytecode for that matter) may not be compatable between major python versions. Will only work for cpython implementation. If the function references globals (including imported modules, other functions etc) that you need to pick up, you'll need to serialise these too, or recreate them on the remote side.  My example just gives it the remote process's global namespace. You'll probably need to do a bit more to support more complex cases, like closures or generator functions.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "109",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  Check out Dill, which extends Python's pickle library to support a greater variety of types, including functions:  >>> import dill as pickle >>> def f(x): return x + 1 ... >>> g = pickle.dumps(f) >>> f(1) 2 >>> pickle.loads(g)(1) 2   It also supports references to objects in the function's closure:  >>> def plusTwo(x): return f(f(x)) ... >>> pickle.loads(pickle.dumps(plusTwo))(1) 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  Pyro is able to do this for you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  The most simple way is probably inspect.getsource(object) (see the inspect module) which returns a String with the source code for a function or a method.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  It all depends on whether you generate the function at runtime or not:  If you do - inspect.getsource(object) won't work for dynamically generated functions as it gets object's source from .py file, so only functions defined before execution can be retrieved as source.  And if your functions are placed in files anyway, why not give receiver access to them and only pass around module and function names.  The only solution for dynamically created functions that I can think of is to construct function as a string before transmission, transmit source, and then eval() it on the receiver side.  Edit: the marshal solution looks also pretty smart, didn't know you can serialize something other thatn built-ins     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  The cloud package (pip install cloud) can pickle arbitrary code, including dependencies.  See https://stackoverflow.com/a/16891169/1264797.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  The basic functions used for this module covers your query, plus you get the best compression over the wire; see the instructive source code:  y_serial.py module :: warehouse Python objects with SQLite  \"Serialization + persistance :: in a few lines of code, compress and annotate Python objects into SQLite; then later retrieve them chronologically by keywords without any SQL. Most useful \"standard\" module for a database to store schema-less data.\"  http://yserial.sourceforge.net     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Is there an easy way to pickle a python function (or otherwise serialize its code)?",
        "A_Content": "  code_string = ''' def foo(x):     return x * 2 def bar(x):     return x ** 2 '''  obj = pickle.dumps(code_string)    Now   exec(pickle.loads(obj))  foo(1) > 2 bar(3) > 9      ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "pickle"
        ],
        "URL": "https://stackoverflow.com/questions/1253528/is-there-an-easy-way-to-pickle-a-python-function-or-otherwise-serialize-its-cod",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to transfer a function across a network connection (using asyncore). Is there an easy way to serialize a python function (one that, in this case at least, will have no side affects) for transfer like this?  I would ideally like to have a pair of functions similar to these:  def transmit(func):     obj = pickle.dumps(func)     [send obj across the network]  def receive():     [receive obj from the network]     func = pickle.loads(s)     func()      ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  I have a class that handles non-interactive plotting, as a frontend to Matplotlib.  However, on occasion one wants to do interactive plotting.  With only a couple functions I found that I was able to increment the figure count, call draw manually, etc, but I needed to do these before and after every plotting call.  So to create both an interactive plotting wrapper and an offscreen plotting wrapper, I found it was more efficient to do this via metaclasses, wrapping the appropriate methods, than to do something like:  class PlottingInteractive:     add_slice = wrap_pylab_newplot(add_slice)   This method doesn't keep up with API changes and so on, but one that iterates over the class attributes in __init__ before re-setting the class attributes is more efficient and keeps things up to date:  class _Interactify(type):     def __init__(cls, name, bases, d):         super(_Interactify, cls).__init__(name, bases, d)         for base in bases:             for attrname in dir(base):                 if attrname in d: continue # If overridden, don't reset                 attr = getattr(cls, attrname)                 if type(attr) == types.MethodType:                     if attrname.startswith(\"add_\"):                         setattr(cls, attrname, wrap_pylab_newplot(attr))                     elif attrname.startswith(\"set_\"):                         setattr(cls, attrname, wrap_pylab_show(attr))   Of course, there might be better ways to do this, but I've found this to be effective.  Of course, this could also be done in __new__ or __init__, but this was the solution I found the most straightforward.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  I was asked the same question recently, and came up with several answers. I hope it's OK to revive this thread, as I wanted to elaborate on a few of the use cases mentioned, and add a few new ones.  Most metaclasses I've seen do one of two things:   Registration (adding a class to a data structure):  models = {}  class ModelMetaclass(type):     def __new__(meta, name, bases, attrs):         models[name] = cls = type.__new__(meta, name, bases, attrs)         return cls  class Model(object):     __metaclass__ = ModelMetaclass   Whenever you subclass Model, your class is registered in the models dictionary:  >>> class A(Model): ...     pass ... >>> class B(A): ...     pass ... >>> models {'A': <__main__.A class at 0x...>,  'B': <__main__.B class at 0x...>}   This can also be done with class decorators:  models = {}  def model(cls):     models[cls.__name__] = cls     return cls  @model class A(object):     pass   Or with an explicit registration function:  models = {}  def register_model(cls):     models[cls.__name__] = cls  class A(object):     pass  register_model(A)   Actually, this is pretty much the same: you mention class decorators unfavorably, but it's really nothing more than syntactic sugar for a function invocation on a class, so there's no magic about it.  Anyway, the advantage of metaclasses in this case is inheritance, as they work for any subclasses, whereas the other solutions only work for subclasses explicitly decorated or registered.  >>> class B(A): ...     pass ... >>> models {'A': <__main__.A class at 0x...> # No B :(  Refactoring (modifying class attributes or adding new ones):  class ModelMetaclass(type):     def __new__(meta, name, bases, attrs):         fields = {}         for key, value in attrs.items():             if isinstance(value, Field):                 value.name = '%s.%s' % (name, key)                 fields[key] = value         for base in bases:             if hasattr(base, '_fields'):                 fields.update(base._fields)         attrs['_fields'] = fields         return type.__new__(meta, name, bases, attrs)  class Model(object):     __metaclass__ = ModelMetaclass   Whenever you subclass Model and define some Field attributes, they are injected with their names (for more informative error messages, for example), and grouped into a _fields dictionary (for easy iteration, without having to look through all the class attributes and all its base classes' attributes every time):  >>> class A(Model): ...     foo = Integer() ... >>> class B(A): ...     bar = String() ... >>> B._fields {'foo': Integer('A.foo'), 'bar': String('B.bar')}   Again, this can be done (without inheritance) with a class decorator:  def model(cls):     fields = {}     for key, value in vars(cls).items():         if isinstance(value, Field):             value.name = '%s.%s' % (cls.__name__, key)             fields[key] = value     for base in cls.__bases__:         if hasattr(base, '_fields'):             fields.update(base._fields)     cls._fields = fields     return cls  @model class A(object):     foo = Integer()  class B(A):     bar = String()  # B.bar has no name :( # B._fields is {'foo': Integer('A.foo')} :(   Or explicitly:  class A(object):     foo = Integer('A.foo')     _fields = {'foo': foo} # Don't forget all the base classes' fields, too!   Although, on the contrary to your advocacy for readable and maintainable non-meta programming, this is much more cumbersome, redundant and error prone:  class B(A):     bar = String()  # vs.  class B(A):     bar = String('bar')     _fields = {'B.bar': bar, 'A.foo': A.foo}    Having considered the most common and concrete use cases, the only cases where you absolutely HAVE to use metaclasses are when you want to modify the class name or list of base classes, because once defined, these parameters are baked into the class, and no decorator or function can unbake them.  class Metaclass(type):     def __new__(meta, name, bases, attrs):         return type.__new__(meta, 'foo', (int,), attrs)  class Baseclass(object):     __metaclass__ = Metaclass  class A(Baseclass):     pass  class B(A):     pass  print A.__name__ # foo print B.__name__ # foo print issubclass(B, A)   # False print issubclass(B, int) # True   This may be useful in frameworks for issuing warnings whenever classes with similar names or incomplete inheritance trees are defined, but I can't think of a reason beside trolling to actually change these values. Maybe David Beazley can.  Anyway, in Python 3, metaclasses also have the __prepare__ method, which lets you evaluate the class body into a mapping other than a dict, thus supporting ordered attributes, overloaded attributes, and other wicked cool stuff:  import collections  class Metaclass(type):      @classmethod     def __prepare__(meta, name, bases, **kwds):         return collections.OrderedDict()      def __new__(meta, name, bases, attrs, **kwds):         print(list(attrs))         # Do more stuff...  class A(metaclass=Metaclass):     x = 1     y = 2  # prints ['x', 'y'] rather than ['y', 'x']      class ListDict(dict):     def __setitem__(self, key, value):         self.setdefault(key, []).append(value)  class Metaclass(type):      @classmethod     def __prepare__(meta, name, bases, **kwds):         return ListDict()      def __new__(meta, name, bases, attrs, **kwds):         print(attrs['foo'])         # Do more stuff...  class A(metaclass=Metaclass):      def foo(self):         pass      def foo(self, x):         pass  # prints [<function foo at 0x...>, <function foo at 0x...>] rather than <function foo at 0x...>   You might argue ordered attributes can be achieved with creation counters, and overloading can be simulated with default arguments:  import itertools  class Attribute(object):     _counter = itertools.count()     def __init__(self):         self._count = Attribute._counter.next()  class A(object):     x = Attribute()     y = Attribute()  A._order = sorted([(k, v) for k, v in vars(A).items() if isinstance(v, Attribute)],                   key = lambda (k, v): v._count)      class A(object):      def _foo0(self):         pass      def _foo1(self, x):         pass      def foo(self, x=None):         if x is None:             return self._foo0()         else:             return self._foo1(x)   Besides being much more ugly, it's also less flexible: what if you want ordered literal attributes, like integers and strings? What if None is a valid value for x?  Here's a creative way to solve the first problem:  import sys  class Builder(object):     def __call__(self, cls):         cls._order = self.frame.f_code.co_names         return cls  def ordered():     builder = Builder()     def trace(frame, event, arg):         builder.frame = frame         sys.settrace(None)     sys.settrace(trace)     return builder  @ordered() class A(object):     x = 1     y = 'foo'  print A._order # ['x', 'y']   And here's a creative way to solve the second one:  _undefined = object()  class A(object):      def _foo0(self):         pass      def _foo1(self, x):         pass      def foo(self, x=_undefined):         if x is _undefined:             return self._foo0()         else:             return self._foo1(x)   But this is much, MUCH voodoo-er than a simple metaclass (especially the first one, which really melts your brain). My point is, you look at metaclasses as unfamiliar and counter-intuitive, but you can also look at them as the next step of evolution in programming languages: you just have to adjust your mindset. After all, you could probably do everything in C, including defining a struct with function pointers and passing it as the first argument to its functions. A person seeing C++ for the first time might say, \"what is this magic? Why is the compiler implicitly passing this to methods, but not to regular and static functions? It's better to be explicit and verbose about your arguments\". But then, object-oriented programming is much more powerful once you get it; and so is this, uh... quasi-aspect-oriented programming, I guess. And once you understand metaclasses, they're actually very simple, so why not use them when  convenient?  And finally, metaclasses are rad, and programming should be fun. Using standard programming constructs and design patterns all the time is boring and uninspiring, and hinders your imagination. Live a little! Here's a metametaclass, just for you.  class MetaMetaclass(type):     def __new__(meta, name, bases, attrs):         def __new__(meta, name, bases, attrs):             cls = type.__new__(meta, name, bases, attrs)             cls._label = 'Made in %s' % meta.__name__             return cls          attrs['__new__'] = __new__         return type.__new__(meta, name, bases, attrs)  class China(type):     __metaclass__ = MetaMetaclass  class Taiwan(type):     __metaclass__ = MetaMetaclass  class A(object):     __metaclass__ = China  class B(object):     __metaclass__ = Taiwan  print A._label # Made in China print B._label # Made in Taiwan      ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  The purpose of metaclasses isn't to replace the class/object distinction with metaclass/class - it's to change the behaviour of class definitions (and thus their instances) in some way.  Effectively it's to alter the behaviour of the class statement in ways that may be more useful for your particular domain than the default.  The things I have used them for are:   Tracking subclasses, usually to register handlers.  This is handy when using a plugin style setup, where you wish to register a handler for a particular thing simply by subclassing and setting up a few class attributes.  eg.  suppose you write a handler for various music formats, where each class implements appropriate methods (play / get tags etc) for its type.  Adding a handler for a new type becomes:  class Mp3File(MusicFile):     extensions = ['.mp3']  # Register this type as a handler for mp3 files     ...     # Implementation of mp3 methods go here   The metaclass then maintains a dictionary of {'.mp3' : MP3File, ... } etc, and constructs an object of the appropriate type when you request a handler through a factory function. Changing behaviour.  You may want to attach a special meaning to certain attributes, resulting in altered behaviour when they are present.  For example, you may want to look for methods with the name _get_foo and _set_foo and transparently convert them to properties.  As a real-world example, here's a recipe I wrote to give more C-like struct definitions.  The metaclass is used to convert the declared items into a struct format string, handling inheritance etc, and produce a class capable of dealing with it.  For other real-world examples, take a look at various ORMs, like sqlalchemy's ORM or sqlobject.  Again, the purpose is to interpret defintions (here SQL column definitions) with a particular meaning.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  Let's start with Tim Peter's classic quote:     Metaclasses are deeper magic than 99%   of users should ever worry about. If   you wonder whether you need them, you   don't (the people who actually need   them know with certainty that they   need them, and don't need an   explanation about why). Tim Peters   (c.l.p post 2002-12-22)   Having said that, I have (periodically) run across true uses of metaclasses. The one that comes to mind is in Django where all of your models inherit from models.Model. models.Model, in turn, does some serious magic to wrap your DB models with Django's ORM goodness. That magic happens by way of metaclasses. It creates all manner of exception classes, manager classes, etc. etc.  See django/db/models/base.py, class ModelBase() for the beginning of the story.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  Metaclasses can be handy for construction of Domain Specific Languages in Python. Concrete examples are Django, SQLObject 's declarative syntax of database schemata.   A basic example from A Conservative Metaclass by Ian Bicking:     The metaclasses I've used have been   primarily to support a sort of   declarative style of programming. For   instance, consider a validation   schema:   class Registration(schema.Schema):     first_name = validators.String(notEmpty=True)     last_name = validators.String(notEmpty=True)     mi = validators.MaxLength(1)     class Numbers(foreach.ForEach):         class Number(schema.Schema):             type = validators.OneOf(['home', 'work'])             phone_number = validators.PhoneNumber()   Some other techniques: Ingredients for Building a DSL in Python (pdf).   Edit (by Ali): An example of doing this using collections and instances is what I would prefer. The important fact is the instances, which give you more power, and eliminate reason to use metaclasses. Further worth noting that your example uses a mixture of classes and instances, which is surely an indication that you can't just do it all with metaclasses. And creates a truly non-uniform way of doing it.  number_validator = [     v.OneOf('type', ['home', 'work']),     v.PhoneNumber('phone_number'), ]  validators = [     v.String('first_name', notEmpty=True),     v.String('last_name', notEmpty=True),     v.MaxLength('mi', 1),     v.ForEach([number_validator,]) ]   It's not perfect, but already there is almost zero magic, no need for metaclasses, and improved uniformity.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  I was thinking the same thing just yesterday and completely agree.  The complications in the code caused by attempts to make it more declarative generally make the codebase harder to maintain, harder to read and less pythonic in my opinion.  It  also normally requires a lot of copy.copy()ing (to maintain inheritance and to copy from class to instance) and means you have to look in many places to see whats going on (always looking from metaclass up) which goes against the python grain also. I have been picking through formencode and sqlalchemy code to see if such a declarative style was worth it and its clearly not. Such style should be left to descriptors (such as property and methods) and immutable data. Ruby has better support for such declarative styles and I am glad the core python  language is not going down that route.  I can see their use for debugging, add a metaclass to all your base classes to get richer info.  I also see their use only in (very) large projects to get rid of some boilerplate code (but at the loss of clarity).  sqlalchemy for example does use them elsewhere, to add a particular custom method to all subclasses based on an attribute value in their class definition e.g a toy example  class test(baseclass_with_metaclass):     method_maker_value = \"hello\"   could have a metaclass that generated a method in that class with special properties based on \"hello\" (say a method that added \"hello\" to the end of a string). It could be good for maintainability to make sure you did not have to write a method in every subclass you make instead all you have to define is method_maker_value.   The need for this is so rare though and only cuts down on a bit of typing that its not really worth considering unless you have a large enough codebase.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  A reasonable pattern of metaclass use is doing something once when a class is defined rather than repeatedly whenever the same class is instantiated.  When multiple classes share the same special behaviour, repeating __metaclass__=X is obviously better than repeating the special purpose code and/or introducing ad-hoc shared superclasses.  But even with only one special class and no foreseeable extension,  __new__ and __init__ of a metaclass are a cleaner way to initialize class variables or other global data than intermixing special-purpose code and normal def and class statements in the class definition body.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  You never absolutely need to use a metaclass, since you can always construct a class that does what you want using inheritance or aggregation of the class you want to modify.  That said, it can be very handy in Smalltalk and Ruby to be able to modify an existing class, but Python doesn't like to do that directly.  There's an excellent DeveloperWorks article on metaclassing in Python that might help.  The Wikipedia article is also pretty good.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  The only time I used metaclasses in Python was when writing a wrapper for the Flickr API.   My goal was to scrape flickr's api site and dynamically generate a complete class hierarchy to allow API access using Python objects:  # Both the photo type and the flickr.photos.search API method  # are generated at \"run-time\" for photo in flickr.photos.search(text=balloons):     print photo.description   So in that example, because I generated the entire Python Flickr API from the website, I really don't know the class definitions at runtime. Being able to dynamically generate types was very useful.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  Metaclasses aren't replacing programming! They're just a trick which can automate or make more elegant some tasks. A good example of this is Pygments syntax highlighting library. It has a class called RegexLexer which lets the user define a set of lexing rules as regular expressions on a class. A metaclass is used to turn the definitions into a useful parser.  They're like salt; it's easy to use too much.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  The way I used metaclasses was to provide some attributes to classes. Take for example:  class NameClass(type):     def __init__(cls, *args, **kwargs):        type.__init__(cls, *args, **kwargs)        cls.name = cls.__name__   will put the name attribute on every class that will have the metaclass set to point to NameClass.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  Some GUI libraries have trouble when multiple threads try to interact with them. tkinter is one such example; and while one can explicitly handle the problem with events and queues, it can be far simpler to use the library in a manner that ignores the problem altogether. Behold -- the magic of metaclasses.  Being able to dynamically rewrite an entire library seamlessly so that it works properly as expected in a multithreaded application can be extremely helpful in some circumstances. The safetkinter module does that with the help of a metaclass provided by the threadbox module -- events and queues not needed.  One neat aspect of threadbox is that it does not care what class it clones. It provides an example of how all base classes can be touched by a metaclass if needed. A further benefit that comes with metaclasses is that they run on  inheriting classes as well. Programs that write themselves -- why not?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  The only legitimate use-case of a metaclass is to keep other nosy developers from touching your code. Once a nosy developer masters metaclasses and starts poking around with yours, throw in another level or two to keep them out. If that doesn't work, start using type.__new__ or perhaps some scheme using a recursive metaclass.  (written tongue in cheek, but I've seen this kind of obfuscation done. Django is a perfect example)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  This is a minor use, but... one  thing I've found metaclasses useful for is to invoke a function whenever a subclass is created. I codified this into a metaclass which looks for an __initsubclass__ attribute: whenever a subclass is created, all parent classes which define that method are invoked with __initsubclass__(cls, subcls). This allows creation of a parent class which then registers all subclasses with some global registry, runs invariant checks on subclasses whenever they are defined, perform late-binding operations, etc... all without have to manually call functions or to create custom metaclasses that perform each of these separate duties.   Mind you, I've slowly come to realize the implicit magicalness of this behavior is somewhat undesirable, since it's unexpected if looking at a class definition out of context... and so I've moved away from using that solution for anything serious besides initializing a __super attribute for each class and instance.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  I recently had to use a metaclass to help declaratively define an SQLAlchemy model around a database table populated with U.S. Census data from http://census.ire.org/data/bulkdata.html  IRE provides database shells for the census data tables, which create integer columns following a naming convention from the Census Bureau of p012015, p012016, p012017, etc.  I wanted to a) be able to access these columns using a model_instance.p012017 syntax, b) be fairly explicit about what I was doing and c) not have to explicitly define dozens of fields on the model, so I subclassed SQLAlchemy's DeclarativeMeta to iterate through a range of the columns and automatically create model fields corresponding to the columns:  from sqlalchemy.ext.declarative.api import DeclarativeMeta  class CensusTableMeta(DeclarativeMeta):     def __init__(cls, classname, bases, dict_):         table = 'p012'         for i in range(1, 49):             fname = \"%s%03d\" % (table, i)             dict_[fname] = Column(Integer)             setattr(cls, fname, dict_[fname])          super(CensusTableMeta, cls).__init__(classname, bases, dict_)   I could then use this metaclass for my model definition and access the automatically enumerated fields on the model:  CensusTableBase = declarative_base(metaclass=CensusTableMeta)  class P12Tract(CensusTableBase):     __tablename__ = 'ire_p12'      geoid = Column(String(12), primary_key=True)      @property     def male_under_5(self):         return self.p012003      ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  There seems to be a legitimate use described here - Rewriting Python Docstrings with a Metaclass.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "What are some (concrete) use-cases for metaclasses?",
        "A_Content": "  I had to use them once for a binary parser to make it easier to use. You define a message class with attributes of the fields present on the wire. They needed to be ordered in the way they were declared to construct the final wire format from it. You can do that with metaclasses, if you use an ordered namespace dict. In fact, its in the examples for Metaclasses:  https://docs.python.org/3/reference/datamodel.html#metaclass-example  But in general: Very carefully evaluate, if you really really need the added complexity of metaclasses.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "metaclass"
        ],
        "URL": "https://stackoverflow.com/questions/392160/what-are-some-concrete-use-cases-for-metaclasses",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a friend who likes to use metaclasses, and regularly offers them as a solution.  I am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.  Being able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.  So please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.  I will start:     Sometimes when using a third-party   library it is useful to be able to   mutate the class in a certain way.   (This is the only case I can think of, and it's not concrete)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  Ray's solution is good. However, on my machine it is about 2.5x faster to use numpy.sum in place of numpy.min:  In [13]: %timeit np.isnan(np.min(x)) 1000 loops, best of 3: 244 us per loop  In [14]: %timeit np.isnan(np.sum(x)) 10000 loops, best of 3: 97.3 us per loop   Unlike min, sum doesn't require branching, which on modern hardware tends to be pretty expensive. This is probably the reason why sum is faster.  edit The above test was performed with a single NaN right in the middle of the array.  It is interesting to note that min is slower in the presence of NaNs than in their absence. It also seems to get slower as NaNs get closer to the start of the array. On the other hand, sum's throughput seems constant regardless of whether there are NaNs and where they're located:  In [40]: x = np.random.rand(100000)  In [41]: %timeit np.isnan(np.min(x)) 10000 loops, best of 3: 153 us per loop  In [42]: %timeit np.isnan(np.sum(x)) 10000 loops, best of 3: 95.9 us per loop  In [43]: x[50000] = np.nan  In [44]: %timeit np.isnan(np.min(x)) 1000 loops, best of 3: 239 us per loop  In [45]: %timeit np.isnan(np.sum(x)) 10000 loops, best of 3: 95.8 us per loop  In [46]: x[0] = np.nan  In [47]: %timeit np.isnan(np.min(x)) 1000 loops, best of 3: 326 us per loop  In [48]: %timeit np.isnan(np.sum(x)) 10000 loops, best of 3: 95.9 us per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "126",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  I think np.isnan(np.min(X)) should do what you want.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  Even there exist an accepted answer, I'll like to demonstrate the following (with Python 2.7.2 and Numpy 1.6.0 on Vista):  In []: x= rand(1e5) In []: %timeit isnan(x.min()) 10000 loops, best of 3: 200 us per loop In []: %timeit isnan(x.sum()) 10000 loops, best of 3: 169 us per loop In []: %timeit isnan(dot(x, x)) 10000 loops, best of 3: 134 us per loop  In []: x[5e4]= NaN In []: %timeit isnan(x.min()) 100 loops, best of 3: 4.47 ms per loop In []: %timeit isnan(x.sum()) 100 loops, best of 3: 6.44 ms per loop In []: %timeit isnan(dot(x, x)) 10000 loops, best of 3: 138 us per loop   Thus, the really efficient way might be heavily dependent on the operating system. Anyway dot(.) based seems to be the most stable one.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  There are two general approaches here:   Check each array item for nan and take any. Apply some cumulative operation that preserves nans (like sum) and check its result.   While the first approach is certainly the cleanest, the heavy optimization of some of the cumulative operations (particularly the ones that are executed in BLAS, like dot) can make those quite fast. Note that dot, like some other BLAS operations, are multithreaded under certain conditions. This explains the difference in speed between different machines.      import numpy import perfplot   def min(a):     return numpy.isnan(numpy.min(a))   def sum(a):     return numpy.isnan(numpy.sum(a))   def dot(a):     return numpy.isnan(numpy.dot(a, a))   def any(a):     return numpy.any(numpy.isnan(a))   def einsum(a):     return numpy.isnan(numpy.einsum('i->', a))   perfplot.show(     setup=lambda n: numpy.random.rand(n),     kernels=[min, sum, dot, any, einsum],     n_range=[2**k for k in range(20)],     logx=True,     logy=True,     xlabel='len(a)'     )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  If you're comfortable with numba it allows to create a fast short-circuit (stops as soon as a NaN is found) function:  import numba as nb import math  @nb.njit def anynan(array):     array = array.ravel()     for i in range(array.size):         if math.isnan(array[i]):             return True     return False   If there is no NaN the function might actually be slower than np.min, I think that's because np.min uses multiprocessing for large arrays:  import numpy as np array = np.random.random(2000000)  %timeit anynan(array)          # 100 loops, best of 3: 2.21 ms per loop %timeit np.isnan(array.sum())  # 100 loops, best of 3: 4.45 ms per loop %timeit np.isnan(array.min())  # 1000 loops, best of 3: 1.64 ms per loop   But in case there is a NaN in the array, especially if it's position is at low indices, then it's much faster:  array = np.random.random(2000000) array[100] = np.nan  %timeit anynan(array)          # 1000000 loops, best of 3: 1.93 µs per loop %timeit np.isnan(array.sum())  # 100 loops, best of 3: 4.57 ms per loop %timeit np.isnan(array.min())  # 1000 loops, best of 3: 1.65 ms per loop   Similar results may be achieved with Cython or a C extension, these are a bit more complicated (or easily avaiable as bottleneck.anynan) but ultimatly do the same as my anynan function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  Related to this is the question of how to find the first occurrence of NaN. This is the fastest way to handle that that I know of:  index = next((i for (i,n) in enumerate(iterable) if n!=n), None)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Fast check for NaN in NumPy",
        "A_Content": "  enter code here    use .any()   if numpy.isnan(myarray).any()   numpy.isfinite maybe better than isnan for checking   if not np.isfinite(prop).all()     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "nan"
        ],
        "URL": "https://stackoverflow.com/questions/6736590/fast-check-for-nan-in-numpy",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for the fastest way to check for the occurrence of NaN (np.nan) in a NumPy array X. np.isnan(X) is out of the question, since it builds a boolean array of shape X.shape, which is potentially gigantic.  I tried np.nan in X, but that seems not to work because np.nan != np.nan. Is there a fast and memory-efficient way to do this at all?  (To those who would ask \"how gigantic\": I can't tell. This is input validation for library code.)     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  You don't set PYTHONPATH, you add entries to sys.path. It's a list of directories that should be searched for Python packages, so you can just append your directories to that list.  sys.path.append('/path/to/whatever')   In fact, sys.path is initialized by splitting the value of PYTHONPATH on the path separator character (: on Linux-like systems, ; on Windows).  You can also add directories using site.addsitedir, and that method will also take into account .pth files existing within the directories you pass. (That would not be the case with directories you specify in PYTHONPATH.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "141",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  You can get and set environment variables via os.environ:  import os user_home = os.environ[\"HOME\"]  os.environ[\"PYTHONPATH\"] = \"...\"   But since your interpreter is already running, this will have no effect. You're better off using  import sys sys.path.append(\"...\")   which is the array that your PYTHONPATH will be transformed into on interpreter startup.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  Sorry for reopen the question, but I think that it can help someone:  If you put sys.path.append('dir/to/path') without check it is already added, you could generate a long list in sys.path. For that, I recommend this:  import sys import os # if you want this directory  try:     sys.path.index('/dir/path') # Or os.getcwd() for this directory except ValueError:     sys.path.append('/dir/path') # Or os.getcwd() for this directory   I'm sorry if I annoyed someone reopening the question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  PYTHONPATH ends up in sys.path, which you can modify at runtime.  import sys sys.path += [\"whatever\"]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  you can set PYTHONPATH, by os.environ['PATHPYTHON']=/some/path, then you need to call os.system('python') to restart the python shell to make the newly added path effective.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "In Python script, how do I set PYTHONPATH?",
        "A_Content": "  This works too:  import sys sys.path.extend([\"/path/to/dotpy/file/\"])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "unix",
            "environment-variables"
        ],
        "URL": "https://stackoverflow.com/questions/3108285/in-python-script-how-do-i-set-pythonpath",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know how to set it in my /etc/profile and in my environment variables.  But what if I want to set it during a script? Is it import os, sys? How do I do it?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Edit:  According to https://www.jetbrains.com/pycharm/whatsnew/#v2016-3-venv-in-terminal, PyCharm 2016.3 (released Nov 2016) has virutalenv support for terminals out of the box     Auto virtualenv is supported for bash, zsh, fish, and Windows cmd. You   can customize your shell preference in Settings (Preferences) | Tools   | Terminal.    Old Method:  Create a file .pycharmrc in your home folder with the following contents  source ~/.bashrc source ~/pycharmvenv/bin/activate   Using your virtualenv path as the last parameter.  Then set the shell Preferences->Project Settings->Shell path to  /bin/bash --rcfile ~/.pycharmrc      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "81",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  For Windows users when using PyCharm and a virtual environment under Windows, you can use the /k parameter to cmd.exe to set the virtual environment automatically.  Go to Settings, Terminal, Default shell and add /K <path-to-your-activate.bat>.  I don't have the reputation to comment on the earlier response so posting this corrected version. This really saves a LOT of time.   Update:  Note: Pycharm now supports virtual environments directly and it seems to work well for me - so my workaround not needed anymore.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  For Windows users: when using PyCharm with a virtual environment, you can use the /K parameter to cmd.exe to set the virtual environment automatically.  PyCharm 3 or 4: Settings, Terminal, Default shell and add /K <path-to-your-activate.bat>.  PyCharm 5: Settings, Tools, Terminal, and add /K <path-to-your-activate.bat> to Shell path.  PyCharm 2016.1 or 2016.2: Settings, Tools, Terminal, and add \"\"/K <path-to-your-activate.bat>\"\" to Shell path and add (mind the quotes). Also add quotes around cmd.exe, resulting in:  \"cmd.exe\" /k \"\"C:\\mypath\\my-venv\\Scripts\\activate.bat\"\"     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Based on answers from Peter and experimentation, I've come up with a good \"general solution\", which solves the following:   Restores the behaviour of a login shell. PyCharm normally runs a login shell, but --rcfile stopped this happening. Script still uses --rcfile, but attempts to emulate the INVOCATION behaviour of a login shell. Removes the need to create an rcfile for each environment Removes the need to update the project settings if you change the environment.   Drop this script into a bin directory somewhere. E.g. ~/bin/pycharmactivate  if [ -r \"/etc/profile\" ] ; then . /etc/profile ; fi if [ -r \"~/.bash_profile\" ] ; then     . ~/.bash_profile elif [ -r \"~/.bash_login\" ] ; then     . ~/.bash_login elif [ -r \"~/.profile\" ] ; then     . ~/.profile fi ACTIVATERC=`cat .idea/workspace.xml | perl -n -e 'print \"\\$1/bin/activate\" if m:option name=\"SDK_HOME\" value=\"\\\\\\$USER_HOME\\\\\\$(.*)/bin/python\":'` if [ -n \"$ACTIVATERC\" ] ; then . \"$HOME/$ACTIVATERC\" ; else echo \"Could not find virtualenv from PyCharm\" ; fi   Then set PyCharm's Shell path to:  /bin/bash --rcfile ~/bin/pycharmactivate      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Thanks Chris, your script worked for some projects but not all on my machine. Here is a script that I wrote and I hope anyone finds it useful.   #Stored in ~/.pycharmrc   ACTIVATERC=$(python -c 'import re import os from glob import glob  try:   #sets Current Working Directory to _the_projects .idea folder   os.chdir(os.getcwd()+\"/.idea\")     #gets every file in the cwd and sets _the_projects iml file   for file in glob(\"*\"):      if re.match(\"(.*).iml\", file):       project_iml_file = file    #gets _the_virtual_env for _the_project   for line in open(project_iml_file):     env_name = re.findall(\"~/(.*)\\\" jdkType\", line.strip())     # created or changed a virtual_env after project creation? this will be true     if env_name:       print env_name[0] + \"/bin/activate\"       break      inherited = re.findall(\"type=\\\"inheritedJdk\\\"\", line.strip())     # set a virtual_env during project creation? this will be true     if inherited:       break    # find _the_virtual_env in misc.xml   if inherited:     for line in open(\"misc.xml\").readlines():       env_at_project_creation = re.findall(\"\\~/(.*)\\\" project-jdk\", line.strip())       if env_at_project_creation:         print env_at_project_creation[0] + \"/bin/activate\"         break finally:   pass ')  if [ \"$ACTIVATERC\" ] ; then . \"$HOME/$ACTIVATERC\" ; fi      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  PyCharm 4 now has virtualenvs integrated in the IDE.  When selecting your project interpreter, you can create, add, or select a virtualenv.  They've added a \"Python Console\" that runs in the configured project interpreter.  More info here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  If You are using windows version it is quite easy. If you already have the virtual environment just navigate to its folder, find activate.bat inside Scripts folder. copy it's full path and paste it in pycharm's terminal then press Enter and you're done!  If you need to create new virtual environment :  Go to files > settings then search for project interpreter, open it, click on gear button and create the environment wherever you want and then follow first paragraph.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  I just added a script named pycharmactivate to my home directory. Set value of PyCharm (4.0.1) File > Settings > Tools > Terminal > Shell path  to /bin/bash --rcfile ~/pycharmactivate. Maybe not the best solution incase you have different project and virtualenv directories/names but it works for me. This script contains the following 3 lines and assumes your virtualenv has the same name as your project dir.  source ~/.bashrc projectdir=${PWD##*/} source ~/.virtualenvs/$projectdir/bin/activate      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Following up on Peter's answer, here the Mac version of the .pycharmrc file:  source /etc/profile source ~/.bash_profile source  <venv_dir>/bin/activate   Hen     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  I have a solution that worked on my Windows 7 machine.  I believe PyCharm's terminal is a result of it running cmd.exe, which will load the Windows PATH variable, and use the version of Python that it finds first within that PATH. To edit this variable, right click My Computer --> Properties --> Advanced System Settings --> Advanced tab --> Environment Variables... button. Within the System variables section, select and edit the PATH variable.  Here is the relevant part of my PATH before editing:     C:\\Python27\\;   C:\\Python27\\Lib\\site-packages\\pip\\;   C:\\Python27\\Scripts;   C:\\Python27\\Lib\\site-packages\\django\\bin;   ...and after editing PATH (only 3 lines now):     C:[project_path]\\virtualenv-Py2.7_Dj1.7\\Lib\\site-packages\\pip;   C:[project_path]\\virtualenvs\\virtualenv-Py2.7_Dj1.7\\Scripts;   C:[project_path]\\virtualenvs\\virtualenv-Py2.7_Dj1.7\\Lib\\site-packages\\django\\bin;   To test this, open a new windows terminal (Start --> type in cmd and hit Enter) and see if it's using your virtual environment. If that works, restart PyCharm and then test it out in PyCharm's terminal.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  this is what i am doing: create a activate_env.bat(windows,maybe  .sh in linux) file in the source code folde:  /env_yourenvlocate/scripts/activate.bat   and another file deactivate_env.bat:  /env_yourenvlocate/scripts/deactivate.bat   everytime  open the terminal window, just execute the bat file to activate/deactivate the virtualenv, you will stay in source code path, no need to change path to and back.  E:\\Projects\\django_study\\src>active_env.bat  E:\\Projects\\django_study\\src>../env_django_study/scripts/activate.bat (env_django_study) E:\\Projects\\django_study\\src>    (env_django_study) E:\\Projects\\django_study\\src>deactive_env.bat  (env_django_study)E:\\Projects\\django_study\\src>../env_django_study/scripts/deactivate.bat E:\\Projects\\django_study\\src>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  If your Pycharm 2016.1.4v and higher you should use \"default path\" /K \"<path-to-your-activate.bat>\" don't forget quotes     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  I have viewed all of the answers above but none of them is elegant enough for me. In Pycharm 2017.1.3(in my computer), the easiest way is to open Settings->Tools->Terminal and check Shell integration and Activate virtualenv options.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Another alternative is to use virtualenvwrapper to manage your virtual environments. It appears that once the virtualenvwrapper script is activated, pycharm can use that and then the simple workon command will be available from the pycharm console and present you with the available virtual environments:  kevin@debian:~/Development/django-tutorial$ workon django-tutorial FlaskHF SQLAlchemy themarkdownapp kevin@debian:~/Development/django-tutorial$ workon django-tutorial (django-tutorial)kevin@debian:~/Development/django-tutorial$       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  This method should work with arbitrary virtual environments per project and it doesn't make assumptions on your environment as it is using hooks you create.  You write:   A global script that invokes the hook A hook script per PyCharm project (not mandatory)   Given that the current latest PyCharm (Community 2016.1) does not allow for Terminal settings per project start with the script that invokes the project specific hook. This is my ~/.pycharmrc:  if [ -r \".pycharm/term-activate\" ]; then    echo \"Terminal activation hook detected.\"    echo \"Loading Bash profile...\"    source ~/.bash_profile    echo \"Activating terminal hook...\"    source \".pycharm/term-activate\"    source activate $PYCHARM_VENV fi   If you are using something other than Bash, invoke your own .bash_profile equivalent should you wish to.  Now set your PyCharm \"Tools -> Terminal -> Shell Path\" to invoke this script, e.g.: /bin/bash --rcfile ~/.pycharmrc  Finally, for every PyCharm project you need a specific virtual environment activated, create a file within the PyCharm project root .pycharm/term-activate. This is your hook and it will simply define the name of the desired virtual environment for your PyCharm project:  export PYCHARM_VENV=<your-virtual-env-name>   You can of course extend your hooks with anything you find useful in the terminal environment of your particular PyCharm project.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  For conda virtual environments on Windows, make sure your batch file is NOT named activate.bat as this will cause a conflict with the conda activate command, resulting in a recursive calling of the batch file.  What works for me is the following Shell path:   \"cmd.exe\" /k \"\"C:\\FullPathToYourProject\\activate-env.bat\"\"   And in the activate-env.bat file:  call activate myenvname      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  I wanted a separate virtual environment for each project, and didn't care much for having additional files to facilitate this. A solution which you only need to do once and works for all projects is then adding the following to your .bashrc or .bash_profile:  if [ -d \"./venv\" ]; then     source ./venv/bin/activate fi   This checks if there is a virtual environment where the terminal is being opened, and if so activates it (and of course other relative paths could be used). PyCharm's terminal settings can be left as their default.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  PyCharm 4.5.4      Create a file .pycharmrc in your home folder with the following   contents  source ~/.bashrc source ~/pycharmvenv/bin/activate       Using your virtualenv path as the last parameter.      Then set the shell Preferences->Project Settings->Shell path to  /bin/bash --rcfile ~/.pycharmrc    I don't why, but it doesn't work for me. PyCharm prints an error.  cmd.exe /K \"<path-to-your-activate.bat>\"  It works, but it creates the same virtualenv for each project, and even if this is not necessary.  This receipt is working! But the string /env_yourenvlocate/scripts/activate.bat must contain quotes, like this \"Full_path_to_your_env_locate\\scripts\\activate.bat\"!  Deactivate the virtualenv is very easy - type in the terminal 'deactivate'  (virt_env) D:\\Projects\\src>deactivate D:\\Projects\\src>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  Solution for WSL (Ubuntu on Windows)  If you're using WSL (Ubuntu on Windows), you can also open bash as terminal in pycharm and activate a linux virtualenv.  Use a .pycharmrc file like described in Peter Gibson's answer; Add the .pycharmrc file to your home directory with following content:  source ~/.bashrc source ~/path_to_virtualenv/bin/activate   In Pycharm File > Settings > Tools > Terminal add the following 'Shell path':  \"C:/Windows/system32/bash.exe\" -c \"bash --rcfile ~/.pycharmrc\"   Project specific virtualenv  The path to your virtualenv in .pycharmrc does not have to be absolute. You can set a project specific virtualenv by setting a relative path from your project directory. My virtualenv is always located in a 'venv' folder under my project directory, so my .pycharmrc file looks like this:   source ~/.bashrc source ~/pycharmvenv/bin/activate #absolute path source ./venv/bin/activate #relative path     BONUS: automatically open ssh tunnel to connect virtualenv as project interpreter  Add the following to your .pycharmrc file:  if [ $(ps -aux | grep -c 'ssh') -lt 2 ]; then     sudo service ssh start  fi   This checks if a ssh tunnel is already opened, and opens one otherwise. In File -> Settings -> Project -> Project Interpreter in Pycharm, add a new remote interpreter with following configuration:  +--------------------------+---------------------------------+-------+----+ | Name:                    | <Interpreter name>              |       |    | | Select                   | 'SSH Credentials'               |       |    | | Host:                    | 127.0.0.1                       | Port: | 22 | | User:                    | <Linux username>                |       |    | | Auth type:               | 'Password'                      |       |    | | Password:                | <Linux password>                |       |    | | Python interpreter path: | <Linux path to your virtualenv> |       |    | | Python helpers path:     | <Set automatically>             |       |    | +--------------------------+---------------------------------+-------+----+  Now when you open your project, your bash automatically starts in your virtualenv, opens a ssh tunnel, and pycharm connects the virtualenv as remote interpreter.  warning: the last update in Windows automatically starts a SshBroker and SshProxy service on startup. These block the ssh tunnel from linux to windows. You can stop these services in Task Manager -> Services, after which everything will work again.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How do I activate a virtualenv inside PyCharm's terminal?",
        "A_Content": "  One option you have when you enter the terminal > Run > Debug > Edit Configurations     select the appropriate conda environmnent.. Also when you create a new project - it asks to configure this location.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "shell",
            "virtualenv",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/22288569/how-do-i-activate-a-virtualenv-inside-pycharms-terminal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.  However, if I open a terminal using \"Tools, Open Terminal\", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.  Another method is to activate the environment in a shell, and run PyCharm from that environment. This is \"workable\" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.  Is there some other, much-easier way to have \"Tools, Open Terminal\" automatically activate the virtual environment?     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  When you use the extends template tag, you're saying that the current template extends another -- that it is a child template, dependent on a parent template.  Django will look at your child template and use its content to populate the parent.  Everything that you want to use in a child template should be within blocks, which Django uses to populate the parent.  If you want use an include statement in that child template, you have to put it within a block, for Django to make sense of it.  Otherwise it just doesn't make sense and Django doesn't know what to do with it.  The Django documentation has a few really good examples of using blocks to replace blocks in the parent template.  https://docs.djangoproject.com/en/dev/ref/templates/language/#template-inheritance     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "90",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  From Django docs:     The include tag should be considered as an implementation of \"render this subtemplate and include the HTML\", not as \"parse this subtemplate and include its contents as if it were part of the parent\". This means that there is no shared state between included templates -- each include is a completely independent rendering process.   So Django doesn't grab any blocks from your commondata.html and it doesn't know what to do with rendered html outside blocks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "69",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  More info about why it wasn't working for me in case it helps future people:  The reason why it wasn't working is that {% include %} in django doesn't like special characters like fancy apostrophe.  The template data I was trying to include was pasted from word.  I had to manually remove all of these special characters and then it included successfully.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  This should do the trick for you: put include tag inside of a block section.   page1.html:  {% extends \"base1.html\" %}  {% block foo %}    {% include \"commondata.html\" %} {% endblock %}   page2.html:  {% extends \"base2.html\" %}  {% block bar %}    {% include \"commondata.html\" %} {% endblock %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  You can't pull in blocks from an included file into a child template to override the parent template's blocks.  However, you can specify a parent in a variable and have the base template specified in the context.  From the documentation:     {% extends variable %} uses the value of variable. If the variable evaluates to a string, Django will use that string as the name of the parent template. If the variable evaluates to a Template object, Django will use that object as the parent template.   Instead of separate \"page1.html\" and \"page2.html\", put {% extends base_template %} at the top of \"commondata.html\".  And then in your view, define base_template to be either \"base1.html\" or \"base2.html\".     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  Added for reference to future people who find this via google:  You might want to look at the {% overextend %} tag provided by the mezzanine library for cases like this.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "django templates: include and extends",
        "A_Content": "  Edit 10th Dec 2015: As pointed out in the comments, ssi is deprecated since version 1.8. According to the documentation:      This tag has been deprecated and will be removed in Django 1.10. Use the include tag instead.     In my opinion, the right (best) answer to this question is the one from podshumok, as it explains why the behaviour of include when used along with inheritance.  However, I was somewhat surprised that nobody mentioned the ssi tag provided by the Django templating system, which is specifically designed for inline including an external piece of text. Here, inline means the external text will not be interpreted, parsed or interpolated, but simply \"copied\" inside the calling template.  Please, refer to the documentation for further details (be sure to check your appropriate version of Django in the selector at the lower right part of the page).  https://docs.djangoproject.com/en/dev/ref/templates/builtins/#ssi  From the documentation:   ssi Outputs the contents of a given file into the page. Like a simple include tag, {% ssi %} includes the contents of another file – which must be specified using an absolute path – in the current page    Beware also of the security implications of this technique and also of the required ALLOWED_INCLUDE_ROOTS define, which must be added to your settings files.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-templates"
        ],
        "URL": "https://stackoverflow.com/questions/1408925/django-templates-include-and-extends",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to provide the same content inside 2 different base files.   So I'm trying to do this:  page1.html:  {% extends \"base1.html\" %} {% include \"commondata.html\" %}   page2.html:  {% extends \"base2.html\" %}  {% include \"commondata.html\" %}   The problem is that I can't seem to use both extends and include.  Is there some way to do that?  And if not, how can I accomplish the above?  commondata.html overrides a block that is specified in both base1.html and base2.html  The purpose of this is to provide the same page in both pdf and html format, where the formatting is slightly different.  The above question though simplifies what I'm trying to do so if I can get an answer to that it will solve my problem.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  You can't copy to IPython directly. This are the steps:   Copy the lines you want to copy into IPython into the clipboard Enter %paste into IPython Press enter Profit!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "126",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  A clarification on the steps:   First, copy target lines into your clipboard. Type into the iPython prompt:   If on Tkinter: enter %paste  Otherwise: enter %cpaste   Paste (Ctrl-V) and hit enter. Then type -- and hit enter.   For example:  In [1]: %cpaste Pasting code; enter '--' alone on the line to stop or use Ctrl-D. :for l in \"Hello World\": :    print l, :-- H e l l o   W o r l d      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  As of Ipython 5 you don't need any magic command, just paste it       Thanks to prompt_toolkit, IPython now supports:         Syntax highlighting as you type   Real multi-line editing (up and down arrow keys move between lines)   Multi-line paste without breaking indentation or immediately executing code   Better code completion interface (we plan to improve that more) Optional mouse support      More on this here  To upgrade ipython to the latest version  pip install ipython --upgrade       ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  %paste  requires Tkinter. If you  are in  ubuntu, you can  install it by   sudo apt-get install python-tk   If you are on Python3  sudo apt-get install python3-tk   Then  restart ipython and use %paste to paste  from your  clipboard.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  For ubuntu users who are on Python 3.  The python-tk is for Python 2.  To make %paste work on Python 3, install the python3-tk package:  sudo apt-get install python3-tk      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "How does IPython's magic %paste work?",
        "A_Content": "  One of the useful answers was lost in the comments, so wanted to restate it along with adding a reference for another useful IPython magic function.  First to restate what @EOL said, one way to solve OP's problem is to turn off auto-indentation by first running %autoindent and doing the paste (not needed if you are using %paste, of course).  Now to add more information to what is already there here, one more useful mode in IPython is %doctest_mode which allows you to copy paste example and test snippets from doc strings. This is also useful to execute interactive python session output that you could find in documentation and online forums, without having to first strip out the prompt strings.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/10886946/how-does-ipythons-magic-paste-work",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to copy already indented Python code / whole functions and classes into IPython. Everytime I try the indentation is screwed up and I get following error message:  IndentationError: unindent does not match any outer indentation level (<ipython-input-23-354f8c8be51b>, line 12)  If you want to paste code into IPython, try the %paste and %cpaste magic functions.     ",
        "Q_Votes": "85"
    },
    {
        "Q_Title": "Unpickling a python 2 object with python 3",
        "A_Content": "  You'll have to tell pickle.load() how to convert Python bytestring data to Python 3 strings, or you can tell pickle to leave them as bytes.  The default is to try and decode all string data as ASCII, and that decoding fails. See the pickle.load() documentation:     Optional keyword arguments are fix_imports, encoding and errors, which are used to control compatibility support for pickle stream generated by Python 2. If fix_imports is true, pickle will try to map the old Python 2 names to the new names used in Python 3. The encoding and errors tell pickle how to decode 8-bit string instances pickled by Python 2; these default to ‘ASCII’ and ‘strict’, respectively. The encoding can be ‘bytes’ to read these 8-bit string instances as bytes objects.   Setting the encoding to latin1 allows you to import the data directly:  with open(mshelffile, 'rb') as f:     d = pickle.load(f, encoding='latin1')    but you'll need to verify that none of your strings are decoded using the wrong codec; Latin-1 works for any input as it maps the byte values 0-255 to the first 256 Unicode codepoints directly.  The alternative would be to load the data with encoding='bytes', and decode all bytes keys and values afterwards.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "pickle",
            "python-2.4",
            "python-2to3"
        ],
        "URL": "https://stackoverflow.com/questions/28218466/unpickling-a-python-2-object-with-python-3",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm wondering if there is a way to load an object that was pickled in Python 2.4, with Python 3.4.  I've been running 2to3 on a large amount of company legacy code to get it up to date.  Having done this, when running the file I get the following error:    File \"H:\\fixers - 3.4\\addressfixer - 3.4\\trunk\\lib\\address\\address_generic.py\" , line 382, in read_ref_files     d = pickle.load(open(mshelffile, 'rb')) UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 1: ordinal not in range(128)   looking at the pickled object in contention, it's a dict in a dict, containing keys and values of type str.  So my question is: Is there a way to load an object, originally pickled in python 2.4, with python 3.4?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Unpickling a python 2 object with python 3",
        "A_Content": "  Using encoding = 'latin1' causes some issues when your object contains numpy arrays in it.  Using encoding = bytes will be better.  Please see this answer for complete explanation of using encoding=bytes     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "pickle",
            "python-2.4",
            "python-2to3"
        ],
        "URL": "https://stackoverflow.com/questions/28218466/unpickling-a-python-2-object-with-python-3",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm wondering if there is a way to load an object that was pickled in Python 2.4, with Python 3.4.  I've been running 2to3 on a large amount of company legacy code to get it up to date.  Having done this, when running the file I get the following error:    File \"H:\\fixers - 3.4\\addressfixer - 3.4\\trunk\\lib\\address\\address_generic.py\" , line 382, in read_ref_files     d = pickle.load(open(mshelffile, 'rb')) UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 1: ordinal not in range(128)   looking at the pickled object in contention, it's a dict in a dict, containing keys and values of type str.  So my question is: Is there a way to load an object, originally pickled in python 2.4, with python 3.4?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  Calling string on a python list calls the __repr__ method on each element inside.  For some items, __str__ and __repr__ are the same.  If you want that behavior, do:  def __str__(self):     ... def __repr__(self):     return self.__str__()      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "111",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  You can use a list comprehension to generate a new list with each item str()'d automatically:  print([str(item) for item in mylist])      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  Two easy things you can do, use the map function or use a comprehension.  But that gets you a list of strings, not a string.  So you also have to join the strings together.  s= \",\".join( map( str, myList ) )   or  s= \",\".join( [ str(element) for element in myList ] )   Then you can print this composite string object.  print 'my list is %s'%( s )      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  Depending on what you want to use that output for, perhaps __repr__ might be more appropriate:  import unittest  class A(object):     def __init__(self, val):         self.val = val      def __repr__(self):         return repr(self.val)  class Test(unittest.TestCase):     def testMain(self):         l = [A('a'), A('b')]         self.assertEqual(repr(l), \"['a', 'b']\")  if __name__ == '__main__':     unittest.main()      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  I agree with the previous answer about using list comprehensions to do this, but you could certainly hide that behind a function, if that's what floats your boat.  def is_list(value):     if type(value) in (list, tuple): return True     return False  def list_str(value):     if not is_list(value): return str(value)     return [list_str(v) for v in value]   Just for fun, I made list_str() recursively str() everything contained in the list.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  You can use format.      def __str__(self):        return(\"my list is\".format(self.list1))      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python __str__ and lists",
        "A_Content": "  Something like this?  a = [1, 2 ,3] [str(x) for x in a] # ['1', '2', '3']      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/727761/python-str-and-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Java, if I call List.toString(), it will automatically call the toString() method on each object inside the List. For example, if my list contains objects o1, o2, and o3, list.toString() would look something like this:  \"[\" + o1.toString() + \", \" + o2.toString() + \", \" + o3.toString() + \"]\"   Is there a way to get similar behavior in Python? I implemented a __str__() method in my class, but when I print out a list of objects, using:  print 'my list is %s'%(list)   it looks something like this:  [<__main__.cell instance at 0x2a955e95f0>, <__main__.cell instance at 0x2a955e9638>, <__main__.cell instance at 0x2a955e9680>]   how can I get python to call my __str__ automatically for each element inside the list (or dict for that matter)?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  PyCharm \"thinks\" that you might have wanted to have a static method, but you forgot to declare it to be static.   PyCharm proposes this because the method does not use self in its body and hence does not actually change the class instance. Hence the method could be static, i.e. callable without having created a class instance before.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "95",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  Agreed with @jolvi, @ArundasR, and others, the warning happens on a member function that doesn't use self.  If you're sure PyCharm is wrong, that the function should not be a @staticmethod, and if you value zero warnings, you can make this one go away two different ways:  Workaround #1  def bar(self):     self.is_not_used()     doing_something_without_self()  def is_not_used(self):     pass   Workaround #2 [Thanks @DavidPärsson]  # noinspection PyMethodMayBeStatic def bar(self):     doing_something_without_self()   The application I had for this (the reason I could not use @staticmethod) was in making a table of handler functions for responding to a protocol subtype field.  All handlers had to be the same form of course (static or nonstatic).  But some didn't happen to do anything with the instance.  If I made those static I'd get \"TypeError: 'staticmethod' object is not callable\".  In support of the OP's consternation, suggesting you add staticmethod whenever you can, goes against the principle that it's easier to make code less restrictive later, than to make it more -- making a method static makes it less restrictive now, in that you can call class.f() instead of instance.f().    Guesses as to why this warning exists:   It advertises staticmethod.  It makes developers aware of something they may well have intended. As @JohnWorrall's points out, it gets your attention when self was inadvertently left out of the function.   It's a cue to rethink the object model; maybe the function does not belong in this class at all.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  I think that the reason for this warning is config in Pycharm. You can uncheck the selection Method may be static in Editor->Inspection     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  I can imagine following advantages of having a class method defined as static one:   you can call the method just using class name, no need to instantiate it.   remaining advantages are probably marginal if present at all:   might run a bit faster save a bit of memory      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  This error message just helped me a bunch, as I hadn't realized that I'd accidentally written my function using my testing example player  my_player.attributes[item]    instead of the correct way  self.attributes[item]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  Since you didn't refer to self in the bar method body, PyCharm is asking if you might have wanted to make bar static. In other programming languages, like Java, there are obvious reasons for declaring a static method. In Python, the only real benefit to a static method (AFIK) is being able to call it without an instance of the class. However, if that's your only reason, you're probably better off going with a top-level function - as note here.  In short, I'm not one hundred percent sure why it's there. I'm guessing they'll probably remove it in an upcoming release.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Why does pycharm propose to change method to static",
        "A_Content": "  I agree with the answers given here (method does not use self and therefore could be decorated with @staticmethod).  I'd like to add that you maybe want to move the method to a top-level function instead of a static method inside a class. For details see this question and the accepted answer: python - should I use static methods or top-level functions  Moving the method to a top-level function will fix the PyCharm warning, too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pycharm"
        ],
        "URL": "https://stackoverflow.com/questions/23554872/why-does-pycharm-propose-to-change-method-to-static",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The new pycharm release (3.1.3 community edition) proposes to convert the methods that don't work with the current object's state to static.    What is the practical reason for that? Some kind of micro-performance(-or-memory)-optimization?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Jython: Python for the Java Platform - http://www.jython.org/index.html  You can easily call python functions from Java code with Jython. That is as long as your python code itself runs under jython, i.e. doesn't use some c-extensions that aren't supported.  If that works for you, it's certainly the simplest solution you can get. Otherwise you can use org.python.util.PythonInterpreter from the new Java6 interpreter support.  A simple example from the top of my head - but should work I hope: (no error checking done for brevity)  PythonInterpreter interpreter = new PythonInterpreter(); interpreter.exec(\"import sys\\nsys.path.append('pathToModules if they are not there by default')\\nimport yourModule\"); // execute a function that takes a string and returns a string PyObject someFunc = interpreter.get(\"funcName\"); PyObject result = someFunc.__call__(new PyString(\"Test!\")); String realResult = (String) result.__tojava__(String.class);      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "79",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Hey I thought I would enter my answer to this even though its late. I think there are some important things to consider first with how strong you wish to have the linking between java and python.  Firstly  Do you only want to call functions or do you actually want python code to change the data in your java objects? This is very important. If you only want to call some python code with or without arguments, then that is not very difficult. If your arguments are primitives it makes it even more easy. However if you want to have java class implement member functions in python, which change the data of the java object, then this is not so easy or straight forward.  Secondly are we talking cpython or will jython do? I would say cpython is where its at! I would advocate this is why python is so kool! Having such high abstractions however access to c,c++ when needed. Imagine if you could have that in java. This question is not even worth asking if jython is ok because then it is easy anyway.  So I have played with the following methods, and listed them from easy to difficult:  Java to Jython   Advantages: Trivially easy. Have actual references to java objects  Disadvantages: No CPython, Extremely Slow!  Jython from java is so easy, and if this is really enough then great. However it is very slow and no cpython! Is life worth living without cpython I don't think so! You can easily have python code implementing your member functions for you java objects.  Java to Jython to CPython via Pyro  Pyro is the remote object module for python. You have some object on a cpython interpreter, and you can send it objects which are transferred via serialization and it can also return objects via this method. Note that if you send a serialized python object from jython and then call some functions which change the data in its members, then you will not see those changes in java. You just need to remember to send back the data which you want from pyro. This I believe is the easiest way to get to cpython! You do not need any jni or jna or swig or .... You don't need to know any c, or c++. kool huh?  Advantages: Access to cpython, not as difficult as following methods  Disadvantages: Cannot change the member data of java objects directly from python. Is somewhat indirect, (jython is middle man).  Java to C/C++ via JNI/JNA/SWIG to Python via Embedded interpreter (maybe using BOOST Libraries?)  OMG this method is not for the faint of heart. And I can tell you it has taken me very long to achieve this in with a decent method. Main reason you would want to do this is so that you can run cpython code which as full rein over you java object. There are major major things to consider before deciding to try and bread java (which is like a chimp) with python (which is like a horse). Firstly if you crash the interpreter that's lights out for you program! And don't get me started on concurrency issues! In addition, there is allot allot of boiler, I believe I have found the best configuration to minimize this boiler but still it is allot! So how to go about this: Consider that C++ is your middle man, your objects are actually c++ objects! Good that you know that now. Just write your object as if your program as in cpp not java, with the data you want to access from both worlds. Then you can use the wrapper generator called swig (http://www.swig.org/Doc1.3/Java.html) to make this accessible to java and compile a dll which you call System.load(dll name here) in java. Get this working first, then move on to the hard part! To get to python you need to embed an interpreter. Firstly I suggest doing some hello interpreter programs or this tutorial Embedding python in C/C. Once you have that working, its time to make the horse and the monkey dance! You can send you c++ object to python via [boost][3] . I know I have not given you the fish, merely told you where to find the fish. Some pointers to note for this when compiling.  When you compile boost you will need to compile a shared library. And you need to include and link to the stuff you need from jdk, ie jawt.lib, jvm.lib, (you will also need the client jvm.dll in your path when launching the application) As well as the python27.lib or whatever and the boost_python-vc100-mt-1_55.lib. Then include Python/include, jdk/include, boost and only use shared libraries (dlls) otherwise boost has a teary. And yeah full on I know. There are so many ways in which this can go sour. So make sure you get each thing done block by block. Then put them together.      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Several of the answers mention that you can use JNI or JNA to access cpython but I would not recommend starting from scratch because there are already open source libraries for accessing cpython from java. For example:   JEP JPY      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  It depends on what do you mean by python functions? if they were written in cpython you can not directly call them you will have to use JNI, but if they were written in Jython you can easily call them from java, as jython ultimately generates java byte code.  Now when I say written in cpython or jython it doesn't make much sense because python is python and most code will run on both implementations unless you are using specific libraries which relies on cpython or java.  see here how to use Python interpreter in Java.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Here a library that lets you write your python scripts once and decide which integration method (Jython, CPython/PyPy via Jep and Py4j) to use at runtime:   https://github.com/subes/invesdwin-context-python   Since each method has its own benefits/drawbacks as explained in the link.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  You can call any language from java using Java Native Interface     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Depending on your requirements, options like XML-RPC could be useful, which can be used to remotely call functions virtually in any language supporting the protocol.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  Jython has some limitations:     There are a number of differences. First, Jython programs cannot use CPython    extension modules written in C. These modules usually have files with the   extension .so, .pyd or .dll. If you want to use such a module, you should look    for an equivalent written in pure Python or Java. Although it is technically    feasible to support such extensions - IronPython does so - there are no plans    to do so in Jython.   Distributing my Python scripts as JAR files with Jython?  you can simply call python scripts (or bash or Perl scripts) from Java using Runtime or ProcessBuilder and pass output back to Java:  Running a bash shell script in java   Running Command Line in Java  java runtime.getruntime() getting output from executing a command line program     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Calling Python in Java?",
        "A_Content": "  It's not smart to have python code inside java. Wrap your python code with flask or other web framework to make it as a microservice. Make your java program able to call this microservice (e.g. via REST).  Beleive me, this is much simple and will save you tons of issues. And the codes are loosely coupled so they are scalable.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python",
            "jython"
        ],
        "URL": "https://stackoverflow.com/questions/8898765/calling-python-in-java",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  As a temporary workaround you can try dumping in JSON format. You lose some type information, but it looks nice and keeps the order.  import json  pprint(data, indent=4) # ^ugly  print(json.dumps(data, indent=4)) # ^nice      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "111",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  The following will work if the order of your OrderedDict is an alpha sort, since pprint will sort a dict before print.  pprint(dict(o.items()))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  Here's another answer that works by overriding and using the stock pprint() function internally. Unlike my earlier one it will handle OrderedDict's inside another container such as a list and should also be able to handle any optional keyword arguments given — however it does not have the same degree of control over the output that the other one afforded.  It operates by redirecting the stock function's output into a temporary buffer and then word wraps that before sending it on to the output stream. While the final output produced isn't exceptionalily pretty, it's decent and may be \"good enough\" to use as a workaround.  Update 2.0  Simplified by using standard library textwrap module, and modified to work in both Python 2 & 3.  from collections import OrderedDict try:     from cStringIO import StringIO except ImportError:  # Python 3     from io import StringIO from pprint import pprint as pp_pprint import sys import textwrap  def pprint(object, **kwrds):     try:         width = kwrds['width']     except KeyError: # unlimited, use stock function         pp_pprint(object, **kwrds)         return     buffer = StringIO()     stream = kwrds.get('stream', sys.stdout)     kwrds.update({'stream': buffer})     pp_pprint(object, **kwrds)     words = buffer.getvalue().split()     buffer.close()      # word wrap output onto multiple lines <= width characters     try:         print >> stream, textwrap.fill(' '.join(words), width=width)     except TypeError:  # Python 3         print(textwrap.fill(' '.join(words), width=width), file=stream)  d = dict((('john',1), ('paul',2), ('mary',3))) od = OrderedDict((('john',1), ('paul',2), ('mary',3))) lod = [OrderedDict((('john',1), ('paul',2), ('mary',3))),        OrderedDict((('moe',1), ('curly',2), ('larry',3))),        OrderedDict((('weapons',1), ('mass',2), ('destruction',3)))]   Sample output:  pprint(d, width=40)   »   {'john': 1, 'mary': 3, 'paul': 2}  pprint(od, width=40)   » OrderedDict([('john', 1), ('paul', 2),    ('mary', 3)])  pprint(lod, width=40)   » [OrderedDict([('john', 1), ('paul', 2),    ('mary', 3)]), OrderedDict([('moe', 1),    ('curly', 2), ('larry', 3)]),    OrderedDict([('weapons', 1), ('mass',    2), ('destruction', 3)])]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  To print an ordered dict, e.g.  from collections import OrderedDict  d=OrderedDict([     ('a', OrderedDict([         ('a1',1),         ('a2','sss')     ])),     ('b', OrderedDict([         ('b1', OrderedDict([             ('bb1',1),             ('bb2',4.5)])),         ('b2',4.5)     ])), ])   I do  def dict_or_OrdDict_to_formatted_str(OD, mode='dict', s=\"\", indent=' '*4, level=0):     def is_number(s):         try:             float(s)             return True         except ValueError:             return False     def fstr(s):         return s if is_number(s) else '\"%s\"'%s     if mode != 'dict':         kv_tpl = '(\"%s\", %s)'         ST = 'OrderedDict([\\n'; END = '])'     else:         kv_tpl = '\"%s\": %s'         ST = '{\\n'; END = '}'     for i,k in enumerate(OD.keys()):         if type(OD[k]) in [dict, OrderedDict]:             level += 1             s += (level-1)*indent+kv_tpl%(k,ST+dict_or_OrdDict_to_formatted_str(OD[k], mode=mode, indent=indent, level=level)+(level-1)*indent+END)             level -= 1         else:             s += level*indent+kv_tpl%(k,fstr(OD[k]))         if i!=len(OD)-1:             s += \",\"         s += \"\\n\"     return s  print dict_or_OrdDict_to_formatted_str(d)   Which yields  \"a\": {     \"a1\": 1,     \"a2\": \"sss\" }, \"b\": {     \"b1\": {         \"bb1\": 1,         \"bb2\": 4.5     },     \"b2\": 4.5 }   or  print dict_or_OrdDict_to_formatted_str(d, mode='OD')   which yields  (\"a\", OrderedDict([     (\"a1\", 1),     (\"a2\", \"sss\") ])), (\"b\", OrderedDict([     (\"b1\", OrderedDict([         (\"bb1\", 1),         (\"bb2\", 4.5)     ])),     (\"b2\", 4.5) ]))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  Here’s a way that hacks the implementation of pprint. pprint sorts the keys before printing, so to preserve order, we just have to make the keys sort in the way we want.  Note that this impacts the items() function. So you might want to preserve and restore the overridden functions after doing the pprint.  from collections import OrderedDict import pprint  class ItemKey(object):   def __init__(self, name, position):     self.name = name     self.position = position   def __cmp__(self, b):     assert isinstance(b, ItemKey)     return cmp(self.position, b.position)   def __repr__(self):     return repr(self.name)  OrderedDict.items = lambda self: [     (ItemKey(name, i), value)     for i, (name, value) in enumerate(self.iteritems())] OrderedDict.__repr__ = dict.__repr__  a = OrderedDict() a[4] = '4' a[1] = '1' a[2] = '2' print pprint.pformat(a) # {4: '4', 1: '1', 2: '2'}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  This is pretty crude, but I just needed a way to visualize a data structure made up of any arbitrary Mappings and Iterables and this is what I came up with before giving up.  It's recursive, so it will fall through nested structures and lists just fine.  I used the Mapping and Iterable abstract base classes from collections to handle just about anything.  I was aiming for almost yaml like output with concise python code, but didn't quite make it.  def format_structure(d, level=0):     x = \"\"     if isinstance(d, Mapping):         lenk = max(map(lambda x: len(str(x)), d.keys()))         for k, v in d.items():             key_text = \"\\n\" + \" \"*level + \" \"*(lenk - len(str(k))) + str(k)             x += key_text + \": \" + format_structure(v, level=level+lenk)     elif isinstance(d, Iterable) and not isinstance(d, basestring):         for e in d:             x += \"\\n\" + \" \"*level + \"- \" + format_structure(e, level=level+4)     else:         x = str(d)     return x   and some test data using OrderedDict and lists of OrderedDicts... (sheesh Python needs OrderedDict literals sooo badly...)  d = OrderedDict([(\"main\",                   OrderedDict([(\"window\",                                 OrderedDict([(\"size\", [500, 500]),                                              (\"position\", [100, 900])])),                                (\"splash_enabled\", True),                                (\"theme\", \"Dark\")])),                  (\"updates\",                   OrderedDict([(\"automatic\", True),                                (\"servers\",                                 [OrderedDict([(\"url\", \"http://server1.com\"),                                               (\"name\", \"Stable\")]),                                  OrderedDict([(\"url\", \"http://server2.com\"),                                               (\"name\", \"Beta\")]),                                  OrderedDict([(\"url\", \"http://server3.com\"),                                               (\"name\", \"Dev\")])]),                                (\"prompt_restart\", True)])),                  (\"logging\",                   OrderedDict([(\"enabled\", True),                                (\"rotate\", True)]))])  print format_structure(d)   yields the following output:     main:                 window:                           size:                               - 500                              - 500                      position:                               - 100                              - 900        splash_enabled: True                 theme: Dark updates:              automatic: True               servers:                       -                            url: http://server1.com                          name: Stable                      -                            url: http://server2.com                          name: Beta                      -                            url: http://server3.com                          name: Dev        prompt_restart: True logging:         enabled: True         rotate: True   I had some thoughts along the way of using str.format() for better alignment, but didn't feel like digging into it.  You'd need to dynamically specify the field widths depending on the type of alignment you want, which would get either tricky or cumbersome.  Anyway, this shows me my data in readable hierarchical fashion, so that works for me!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  def pprint_od(od):     print \"{\"     for key in od:         print \"%s:%s,\\n\" % (key, od[key]) # Fixed syntax     print \"}\"   There you go ^^  for item in li:     pprint_od(item)   or  (pprint_od(item) for item in li)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  The pprint() method is just invoking the __repr__() method of things in it, and OrderedDict doesn't appear to do much in it's method (or doesn't have one or something).   Here's a cheap solution that should work IF YOU DON'T CARE ABOUT THE ORDER BEING VISIBLE IN THE PPRINT OUTPUT, which may be a big if:  class PrintableOrderedDict(OrderedDict):     def __repr__(self):         return dict.__repr__(self)   I'm actually surprised that the order isn't preserved... ah well.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  You could redefine pprint() and intercept calls for OrderedDict's. Here's a simple illustration. As written, the OrderedDict override code ignores any optional stream, indent, width, or depth keywords that may have been passed, but could be enhanced to implement them. Unfortunately this technique doesn't handle them inside another container, such as a list of OrderDict's   from collections import OrderedDict from pprint import pprint as pp_pprint  def pprint(obj, *args, **kwrds):     if not isinstance(obj, OrderedDict):         # use stock function         return pp_pprint(obj, *args, **kwrds)     else:         # very simple sample custom implementation...         print \"{\"         for key in obj:             print \"    %r:%r\" % (key, obj[key])         print \"}\"  l = [10, 2, 4] d = dict((('john',1), ('paul',2), ('mary',3))) od = OrderedDict((('john',1), ('paul',2), ('mary',3))) pprint(l, width=4) # [10, #  2, #  4] pprint(d) # {'john': 1, 'mary': 3, 'paul': 2}  pprint(od) # { #     'john':1 #     'paul':2 #     'mary':3 # }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  If the dictionary items are all of one type, you could use the amazing data-handling library pandas:  >>> import pandas as pd >>> x = {'foo':1, 'bar':2} >>> pd.Series(x) bar    2 foo    1 dtype: int64   or  >>> import pandas as pd >>> x = {'foo':'bar', 'baz':'bam'} >>> pd.Series(x) baz    bam foo    bar dtype: object      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  You can also use this simplification of the kzh answer:  pprint(data.items(), indent=4)   It preserves the order and will output almost the same than the webwurst answer (print through json dump).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Any way to properly pretty-print ordered dictionaries?",
        "A_Content": "  Here is my approach to pretty print an OrderedDict  from collections import OrderedDict import json d = OrderedDict() d['duck'] = 'alive' d['parrot'] = 'dead' d['penguin'] = 'exploded' d['Falcon'] = 'discharged' print d print json.dumps(d,indent=4)  OutPut:  OrderedDict([('duck', 'alive'), ('parrot', 'dead'), ('penguin', 'exploded'), ('Falcon', 'discharged')])  {     \"duck\": \"alive\",     \"parrot\": \"dead\",     \"penguin\": \"exploded\",     \"Falcon\": \"discharged\" }   If you want to pretty print dictionary with keys in sorted order  print json.dumps(indent=4,sort_keys=True) {     \"Falcon\": \"discharged\",     \"duck\": \"alive\",     \"parrot\": \"dead\",     \"penguin\": \"exploded\" }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pretty-print",
            "ordereddictionary",
            "pprint"
        ],
        "URL": "https://stackoverflow.com/questions/4301069/any-way-to-properly-pretty-print-ordered-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.  It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.  Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.  UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How to add a new row to an empty numpy array",
        "A_Content": "  The way to \"start\" the array that you want is:  arr = np.empty((0,3), int)   Which is an empty array but it has the proper dimensionality.  >>> arr array([], shape=(0, 3), dtype=int64)   Then be sure to append along axis 0:  arr = np.append(arr, np.array([[1,2,3]]), axis=0) arr = np.append(arr, np.array([[4,5,6]]), axis=0)   But, @jonrsharpe is right.  In fact, if you're going to be appending in a loop, it would be much faster to append to a list as in your first example, then convert to a numpy array at the end, since you're really not using numpy as intended during the loop:  In [210]: %%timeit    .....: l = []    .....: for i in xrange(1000):    .....:     l.append([3*i+1,3*i+2,3*i+3])    .....: l = np.asarray(l)    .....:  1000 loops, best of 3: 1.18 ms per loop  In [211]: %%timeit    .....: a = np.empty((0,3), int)    .....: for i in xrange(1000):    .....:     a = np.append(a, 3*i+np.array([[1,2,3]]), 0)    .....:  100 loops, best of 3: 18.5 ms per loop  In [214]: np.allclose(a, l) Out[214]: True   The numpythonic way to do it depends on your application, but it would be more like:  In [220]: timeit n = np.arange(1,3001).reshape(1000,3) 100000 loops, best of 3: 5.93 µs per loop  In [221]: np.allclose(a, n) Out[221]: True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/22392497/how-to-add-a-new-row-to-an-empty-numpy-array",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Using standard Python arrays, I can do the following:  arr = [] arr.append([1,2,3]) arr.append([4,5,6]) # arr is now [[1,2,3],[4,5,6]]   However, I cannot do the same thing in numpy. For example:  arr = np.array([]) arr = np.append(arr, np.array([1,2,3])) arr = np.append(arr, np.array([4,5,6])) # arr is now [1,2,3,4,5,6]   I also looked into vstack, but when I use vstack on an empty array, I get:  ValueError: all the input array dimensions except for the concatenation axis must match exactly   So how do I do append a new row to an empty array in numpy?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How to add a new row to an empty numpy array",
        "A_Content": "  In this case you might want to use the functions np.hstack and np.vstack  arr = np.array([]) arr = np.hstack((arr, np.array([1,2,3]))) # arr is now [1,2,3]  arr = np.vstack((arr, np.array([4,5,6]))) # arr is now [[1,2,3],[4,5,6]]   You also can use the np.concatenate function.  Cheers     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/22392497/how-to-add-a-new-row-to-an-empty-numpy-array",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using standard Python arrays, I can do the following:  arr = [] arr.append([1,2,3]) arr.append([4,5,6]) # arr is now [[1,2,3],[4,5,6]]   However, I cannot do the same thing in numpy. For example:  arr = np.array([]) arr = np.append(arr, np.array([1,2,3])) arr = np.append(arr, np.array([4,5,6])) # arr is now [1,2,3,4,5,6]   I also looked into vstack, but when I use vstack on an empty array, I get:  ValueError: all the input array dimensions except for the concatenation axis must match exactly   So how do I do append a new row to an empty array in numpy?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How to add a new row to an empty numpy array",
        "A_Content": "  Here is my solution:  arr = [] arr.append([1,2,3]) arr.append([4,5,6]) np_arr = np.array(arr)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/22392497/how-to-add-a-new-row-to-an-empty-numpy-array",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using standard Python arrays, I can do the following:  arr = [] arr.append([1,2,3]) arr.append([4,5,6]) # arr is now [[1,2,3],[4,5,6]]   However, I cannot do the same thing in numpy. For example:  arr = np.array([]) arr = np.append(arr, np.array([1,2,3])) arr = np.append(arr, np.array([4,5,6])) # arr is now [1,2,3,4,5,6]   I also looked into vstack, but when I use vstack on an empty array, I get:  ValueError: all the input array dimensions except for the concatenation axis must match exactly   So how do I do append a new row to an empty array in numpy?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How to add a new row to an empty numpy array",
        "A_Content": "  using an custom dtype definition, what worked for me was:  import numpy  # define custom dtype type1 = numpy.dtype([('freq', numpy.float64, 1), ('amplitude', numpy.float64, 1)]) # declare empty array, zero rows but one column arr = numpy.empty([0,1],dtype=type1) # store row data, maybe inside a loop row = numpy.array([(0.0001, 0.002)], dtype=type1) # append row to the main array arr = numpy.row_stack((arr, row)) # print values stored in the row 0 print float(arr[0]['freq']) print float(arr[0]['amplitude'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/22392497/how-to-add-a-new-row-to-an-empty-numpy-array",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using standard Python arrays, I can do the following:  arr = [] arr.append([1,2,3]) arr.append([4,5,6]) # arr is now [[1,2,3],[4,5,6]]   However, I cannot do the same thing in numpy. For example:  arr = np.array([]) arr = np.append(arr, np.array([1,2,3])) arr = np.append(arr, np.array([4,5,6])) # arr is now [1,2,3,4,5,6]   I also looked into vstack, but when I use vstack on an empty array, I get:  ValueError: all the input array dimensions except for the concatenation axis must match exactly   So how do I do append a new row to an empty array in numpy?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings",
        "A_Content": "  If you want to use 8-bit strings instead of unicode string in sqlite3, set approptiate text_factory for sqlite connection:  connection = sqlite3.connect(...) connection.text_factory = str      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "sqlite3",
            "zlib"
        ],
        "URL": "https://stackoverflow.com/questions/3425320/sqlite3-programmingerror-you-must-not-use-8-bit-bytestrings-unless-you-use-a-te",
        "A_Votes": "84",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using SQLite3 in Python, I am trying to store a compressed version of a snippet of UTF-8 HTML code.  Code looks like this:  ... c = connection.cursor() c.execute('create table blah (cid integer primary key,html blob)') ... c.execute('insert or ignore into blah values (?, ?)',(cid, zlib.compress(html)))   At which point at get the error:  sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.   If I use 'text' rather than 'blob' and don't compress the HTML snippet, it works all fine (db is to large though). When I use 'blob' and compress via Python zlib library, I get the above error message. I looked around but couldn't find a simple answer for this one.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings",
        "A_Content": "  Found the solution, I should have spent just a little more time searching.  Solution is to 'cast' the value as a Python 'buffer', like so:  c.execute('insert or ignore into blah values (?, ?)',(cid, buffer(zlib.compress(html))))   Hopefully this will help somebody else.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "sqlite3",
            "zlib"
        ],
        "URL": "https://stackoverflow.com/questions/3425320/sqlite3-programmingerror-you-must-not-use-8-bit-bytestrings-unless-you-use-a-te",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using SQLite3 in Python, I am trying to store a compressed version of a snippet of UTF-8 HTML code.  Code looks like this:  ... c = connection.cursor() c.execute('create table blah (cid integer primary key,html blob)') ... c.execute('insert or ignore into blah values (?, ?)',(cid, zlib.compress(html)))   At which point at get the error:  sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.   If I use 'text' rather than 'blob' and don't compress the HTML snippet, it works all fine (db is to large though). When I use 'blob' and compress via Python zlib library, I get the above error message. I looked around but couldn't find a simple answer for this one.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings",
        "A_Content": "  In order to work with the BLOB type, you must first convert your zlib compressed string into binary data - otherwise sqlite will try to process it as a text string. This is done with sqlite3.Binary(). For example:  c.execute('insert or ignore into blah values (?, ?)',(cid,  sqlite3.Binary(zlib.compress(html))))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "sqlite3",
            "zlib"
        ],
        "URL": "https://stackoverflow.com/questions/3425320/sqlite3-programmingerror-you-must-not-use-8-bit-bytestrings-unless-you-use-a-te",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using SQLite3 in Python, I am trying to store a compressed version of a snippet of UTF-8 HTML code.  Code looks like this:  ... c = connection.cursor() c.execute('create table blah (cid integer primary key,html blob)') ... c.execute('insert or ignore into blah values (?, ?)',(cid, zlib.compress(html)))   At which point at get the error:  sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.   If I use 'text' rather than 'blob' and don't compress the HTML snippet, it works all fine (db is to large though). When I use 'blob' and compress via Python zlib library, I get the above error message. I looked around but couldn't find a simple answer for this one.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings",
        "A_Content": "  You could store the value using repr(html) instead of the raw output and then use eval(html) when retrieving the value for use.  c.execute('insert or ignore into blah values (?, ?)',(1, repr(zlib.compress(html))))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "sqlite3",
            "zlib"
        ],
        "URL": "https://stackoverflow.com/questions/3425320/sqlite3-programmingerror-you-must-not-use-8-bit-bytestrings-unless-you-use-a-te",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Using SQLite3 in Python, I am trying to store a compressed version of a snippet of UTF-8 HTML code.  Code looks like this:  ... c = connection.cursor() c.execute('create table blah (cid integer primary key,html blob)') ... c.execute('insert or ignore into blah values (?, ?)',(cid, zlib.compress(html)))   At which point at get the error:  sqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.   If I use 'text' rather than 'blob' and don't compress the HTML snippet, it works all fine (db is to large though). When I use 'blob' and compress via Python zlib library, I get the above error message. I looked around but couldn't find a simple answer for this one.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How can I find the first occurrence of a sub-string in a python string?",
        "A_Content": "  find()  >>> s = \"the dude is a cool dude\" >>> s.find('dude') 4      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/3221891/how-can-i-find-the-first-occurrence-of-a-sub-string-in-a-python-string",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    So if my string is \"the dude is a cool dude\". I'd like to find the first index of 'dude':  mystring.findfirstindex('dude') # should return 4   What is the python command for this? Thanks.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How can I find the first occurrence of a sub-string in a python string?",
        "A_Content": "  Quick Overview: index and find  Next to the find method there is as well index. find and index both yield the same result: returning the position of the first occurrence, but if nothing is found index will raise a ValueError whereas find returns -1. Speedwise, both have the same benchmark results.  s.find(t)    #returns: -1, or index where t starts in s s.index(t)   #returns: Same as find, but raises ValueError if t is not in s   Additional knowledge:  rfind and rindex:     In general, find and index return the smallest index where the passed-in string starts, and rfind and rindex return the largest index where it starts   Most of the string searching algorithms search from left to right, so functions starting with r indicate that the search happens from right to left.    So in case that the likelihood of the element you are searching is close to the end than to the start of the list, rfind or rindex would be faster.   s.rfind(t)   #returns: Same as find, but searched right to left s.rindex(t)  #returns: Same as index, but searches right to left   Source: Python: Visual QuickStart Guide, Toby Donaldson     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/3221891/how-can-i-find-the-first-occurrence-of-a-sub-string-in-a-python-string",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So if my string is \"the dude is a cool dude\". I'd like to find the first index of 'dude':  mystring.findfirstindex('dude') # should return 4   What is the python command for this? Thanks.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "  Use a virtual environment:  $ virtualenv myenv .. some output .. $ source myenv/bin/activate (myenv) $ pip install what-i-want   You only use sudo or elevated permissions when you want to install stuff for the global, system-wide Python installation.  It is best to use a virtual environment which isolates packages for you.  That way you can play around without polluting the global python install.  As a bonus, virtualenv does not need elevated permissions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "84",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "     Is it acceptable & safe to run pip install under sudo?   It's not safe and it's being frowned upon – see What are the risks of running 'sudo pip'? To install Python package in your home directory you don't need root privileges. See description of --user option to pip.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "  Your original problem is that pip cannot write the logs to the folder.  IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   You need to cd into a folder in which the process invoked can write like /tmp so a cd /tmp and re invoking the command will probably work but is not what you want.  BUT actually for this particular case (you not wanting to use sudo for installing python packages) and no need for global package installs you can use the --user flag like this :  pip install --user <packagename>   and it will work just fine.  I assume you have a one user python python installation and do not want to bother with reading about virtualenv (which is not very userfriendly) or pipenv.  As some people in the comments section have pointed out the next approach is not a very good idea unless you do not know what to do and got stuck:  Another approach for global packages like in your case you want to do something like :  chown -R $USER /Library/Python/2.7/site-packages/   or more generally    chown -R $USER <path to your global pip packages>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "  Because I had the same problem, I want to stress that actually the first comment by Brian Cain is the solution to the \"IOError: [Errno 13]\"-problem:  If executed in the temp directory (cd /tmp), the IOError does not occur anymore if I run sudo pip install foo.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "  It looks like your permissions are messed up. Type chown -R markwalker ~ in the Terminal and try pip again? Let me know if you're sorted.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Is it acceptable and safe to run pip install under sudo?",
        "A_Content": "  I had a problem installing virtualenvwrapper after successfully installing virtualenv.  My terminal complained after I did this:  pip install virtualenvwrapper   So, I unsuccessfully tried this (NOT RECOMMENDED):  sudo pip install virtualenvwrapper   Then, I successfully installed it with this:  pip install --user virtualenvwrapper      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "pip",
            "sudo"
        ],
        "URL": "https://stackoverflow.com/questions/15028648/is-it-acceptable-and-safe-to-run-pip-install-under-sudo",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've started to use my Mac to install Python packages in the same way I do with my Windows PC at work; however on my Mac I've come across frequent permission denied errors while writing to log files or site-packages.  Therefore I thought about running pip install <package> under sudo but is that a safe/acceptable use of sudo considering I'm just wanting this to be installed under my current user account?  Example traceback from a logfile I/O error:  Command /usr/bin/python -c \"import setuptools;__file__='/Users/markwalker/build/pycrypto/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/tq/hy1fz_4j27v6rstzzw4vymnr0000gp/T/pip-k6f2FU-record/install-record.txt failed with error code 1 in /Users/markwalker/build/pycrypto Storing complete log in /Users/markwalker/Library/Logs/pip.log Traceback (most recent call last):   File \"/usr/local/bin/pip\", line 8, in <module>     load_entry_point('pip==1.1', 'console_scripts', 'pip')()   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/__init__.py\", line 116, in main     return command.main(args[1:], options)   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 141, in main     log_fp = open_logfile(log_fn, 'w')   File \"/Library/Python/2.7/site-packages/pip-1.1-py2.7.egg/pip/basecommand.py\", line 168, in open_logfile     log_fp = open(filename, mode) IOError: [Errno 13] Permission denied: '/Users/markwalker/Library/Logs/pip.log'   Update This was likely down to permissions, however the best approach is to use virtual environments for your python projects. Running sudo pip should be avoided unless absolutely necessary.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can a dictionary be passed to django models on create?",
        "A_Content": "  If title and body are fields in your model, then you can deliver the keyword arguments in your dictionary using the ** operator.  Assuming your model is called MyModel:  # create instance of model m = MyModel(**data_dict) # don't forget to save to database! m.save()   As for your second question, the dictionary has to be the final argument. Again, extra and extra2 should be fields in the model.  m2 =MyModel(extra='hello', extra2='world', **data_dict) m2.save()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/1571570/can-a-dictionary-be-passed-to-django-models-on-create",
        "A_Votes": "155",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is is possible to do something similar to this with a list, dictionary or something else even?  data_dict = {     'title' : 'awesome title',     'body' : 'great body of text', } Model.objects.create(data_dict)   Even better if I can extend it  Model.objects.create(data_dict, extra='hello', extra2='world)      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Can a dictionary be passed to django models on create?",
        "A_Content": "  Not directly an answer to the question, but I find this code helped me create the dicts that save nicely into the correct answer.  The type conversions made are required if this data will be exported to json.  I hope this helps:    #mod is a django database model instance def toDict( mod ):   import datetime   from decimal import Decimal   import re      #Go through the object, load in the objects we want   obj = {}   for key in mod.__dict__:     if re.search('^_', key):       continue        #Copy my data     if isinstance( mod.__dict__[key], datetime.datetime ):       obj[key] = int(calendar.timegm( ts.utctimetuple(mod.__dict__[key])))     elif isinstance( mod.__dict__[key], Decimal ):       obj[key] = float( mod.__dict__[key] )     else:       obj[key] = mod.__dict__[key]    return obj   def toCsv( mod, fields, delim=',' ):   import datetime   from decimal import Decimal      #Dump the items   raw = []   for key in fields:     if key not in mod.__dict__:       continue        #Copy my data     if isinstance( mod.__dict__[key], datetime.datetime ):       raw.append( str(calendar.timegm( ts.utctimetuple(mod.__dict__[key]))) )     elif isinstance( mod.__dict__[key], Decimal ):       raw.append( str(float( mod.__dict__[key] )))     else:       raw.append( str(mod.__dict__[key]) )    return delim.join( raw )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/1571570/can-a-dictionary-be-passed-to-django-models-on-create",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is is possible to do something similar to this with a list, dictionary or something else even?  data_dict = {     'title' : 'awesome title',     'body' : 'great body of text', } Model.objects.create(data_dict)   Even better if I can extend it  Model.objects.create(data_dict, extra='hello', extra2='world)      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Importing variables from another file?",
        "A_Content": "  from file1 import *     will import all objects and methods in file1     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "variables",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/17255737/importing-variables-from-another-file",
        "A_Votes": "90",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I import variables from one file to another?  example: file1 has the variables x1 and x2 how to pass them to file2?  How can I import all of the variables from one to another?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Importing variables from another file?",
        "A_Content": "  Import file1 inside file2:  To import all variables from file1 without flooding file2's namespace, use:  import file1  #now use file1.x1, file2.x2, ... to access those variables   To import all variables from file1 to file2's namespace( not recommended):  from file1 import * #now use x1, x2..   From the docs:     While it is valid to use from module import * at module level it is   usually a bad idea. For one, this loses an important property Python   otherwise has — you can know where each toplevel name is defined by a   simple “search” function in your favourite editor. You also open   yourself to trouble in the future, if some module grows additional   functions or classes.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "variables",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/17255737/importing-variables-from-another-file",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I import variables from one file to another?  example: file1 has the variables x1 and x2 how to pass them to file2?  How can I import all of the variables from one to another?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Importing variables from another file?",
        "A_Content": "  Best to import x1 and x2 explicitly:  from file1 import x1, x2   This allows you to avoid unnecessary namespace conflicts with variables and functions from file1 while working in file2.  But if you really want, you can import all the variables:  from file1 import *       ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "variables",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/17255737/importing-variables-from-another-file",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I import variables from one file to another?  example: file1 has the variables x1 and x2 how to pass them to file2?  How can I import all of the variables from one to another?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Importing variables from another file?",
        "A_Content": "  Actually this is not really the same to import a variable with:  from file1 import x1 print(x1)   and  import file1 print(file1.x1)   Altough at import time x1 and file1.x1 have the same value, they are not the same variables. For instance, call a function in file1 that modifies x1 and then try to print the variable from the main file: you will not see the modified value.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "variables",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/17255737/importing-variables-from-another-file",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I import variables from one file to another?  example: file1 has the variables x1 and x2 how to pass them to file2?  How can I import all of the variables from one to another?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  Do as seen here. Then you can use a word that represents the proper integer.  Like so:  LOW = 0 NORMAL = 1 HIGH = 2 STATUS_CHOICES = (     (LOW, 'Low'),     (NORMAL, 'Normal'),     (HIGH, 'High'), )   Then they are still integers in the DB.  Usage would be thing.priority = Thing.NORMAL     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "139",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  I'd probably set up the reverse-lookup dict once and for all, but if I hadn't I'd just use:  thing.priority = next(value for value, name in Thing.PRIORITIES                       if name=='Normal')   which seems simpler than building the dict on the fly just to toss it away again;-).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  Here's a field type I wrote a few minutes ago that I think does what you want. Its constructor requires an argument 'choices', which may be either a tuple of 2-tuples in the same format as the choices option to IntegerField, or instead a simple list of names (ie ChoiceField(('Low', 'Normal', 'High'), default='Low') ). The class takes care of the mapping from string to int for you, you never see the int.    class ChoiceField(models.IntegerField):     def __init__(self, choices, **kwargs):         if not hasattr(choices[0],'__iter__'):             choices = zip(range(len(choices)), choices)          self.val2choice = dict(choices)         self.choice2val = dict((v,k) for k,v in choices)          kwargs['choices'] = choices         super(models.IntegerField, self).__init__(**kwargs)      def to_python(self, value):         return self.val2choice[value]      def get_db_prep_value(self, choice):         return self.choice2val[choice]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  class Sequence(object):     def __init__(self, func, *opts):         keys = func(len(opts))         self.attrs = dict(zip([t[0] for t in opts], keys))         self.choices = zip(keys, [t[1] for t in opts])         self.labels = dict(self.choices)     def __getattr__(self, a):         return self.attrs[a]     def __getitem__(self, k):         return self.labels[k]     def __len__(self):         return len(self.choices)     def __iter__(self):         return iter(self.choices)     def __deepcopy__(self, memo):         return self  class Enum(Sequence):     def __init__(self, *opts):         return super(Enum, self).__init__(range, *opts)  class Flags(Sequence):     def __init__(self, *opts):         return super(Flags, self).__init__(lambda l: [1<<i for i in xrange(l)], *opts)   Use it like this:  Priorities = Enum(     ('LOW', 'Low'),     ('NORMAL', 'Normal'),     ('HIGH', 'High') )  priority = models.IntegerField(default=Priorities.LOW, choices=Priorities)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  I appreciate the constant defining way but I believe Enum type is far best for this task. They can represent integer and a string for an item in the same time, while keeping your code more readable.  Enums were introduced to Python in version 3.4. If you are using any lower (such as v2.x) you can still have it by installing the backported package: pip install enum34.  # myapp/fields.py from enum import Enum       class ChoiceEnum(Enum):      @classmethod     def choices(cls):         choices = list()          # Loop thru defined enums         for item in cls:             choices.append((item.value, item.name))          # return as tuple         return tuple(choices)      def __str__(self):         return self.name      def __int__(self):         return self.value   class Language(ChoiceEnum):     Python = 1     Ruby = 2     Java = 3     PHP = 4     Cpp = 5  # Uh oh Language.Cpp._name_ = 'C++'   This is pretty much all. You can inherit the ChoiceEnum to create your own definitions and use them in a model definition like:  from django.db import models from myapp.fields import Language  class MyModel(models.Model):     language = models.IntegerField(choices=Language.choices(), default=int(Language.Python))     # ...   Querying is icing on the cake as you may guess:  MyModel.objects.filter(language=int(Language.Ruby)) # or if you don't prefer `__int__` method.. MyModel.objects.filter(language=Language.Ruby.value)   Representing them in string is also made easy:  # Get the enum item lang = Language(some_instance.language)  print(str(lang)) # or if you don't prefer `__str__` method.. print(lang.name)  # Same as get_FOO_display lang.name == some_instance.get_language_display()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  Simply replace your numbers with the human readable values you would like. As such:  PRIORITIES = ( ('LOW', 'Low'), ('NORMAL', 'Normal'), ('HIGH', 'High'), )   This makes it human readable, however, you'd have to define your own ordering.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Set Django IntegerField by choices=… name",
        "A_Content": "  My answer is very late and might seem obvious to nowadays-Django experts, but to whoever lands here, i recently discovered a very elegant solution brought by django-model-utils: https://django-model-utils.readthedocs.io/en/latest/utilities.html#choices  This package allows you to define Choices with three-tuples where:   The first item is the database value The second item is a code-readable value The third item is a human-readable value   So here's what you can do:  from model_utils import Choices  class Thing(models.Model):     PRIORITIES = Choices(         (0, 'low', 'Low'),         (1, 'normal', 'Normal'),         (2, 'high', 'High'),       )      priority = models.IntegerField(default=PRIORITIES.normal, choices=PRIORITIES)  thing.priority = getattr(Thing.PRIORITIES.Normal)   This way:   You can use your human-readable value to actually choose the value of your field (in my case, it's useful because i'm scraping wild content and storing it in a normalized way) A clean value is stored in your database You have nothing non-DRY to do ;)   Enjoy :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models"
        ],
        "URL": "https://stackoverflow.com/questions/1117564/set-django-integerfield-by-choices-name",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When you have a model field with a choices option you tend to have some magic values associated with human readable names. Is there in Django a convenient way to set these fields by the human readable name instead of the value?  Consider this model:  class Thing(models.Model):   PRIORITIES = (     (0, 'Low'),     (1, 'Normal'),     (2, 'High'),   )    priority = models.IntegerField(default=0, choices=PRIORITIES)   At some point we have a Thing instance and we want to set its priority. Obviously you could do,  thing.priority = 1   But that forces you to memorize the Value-Name mapping of PRIORITIES. This doesn't work:  thing.priority = 'Normal' # Throws ValueError on .save()   Currently I have this silly workaround:  thing.priority = dict((key,value) for (value,key) in Thing.PRIORITIES)['Normal']   but that's clunky. Given how common this scenario could be I was wondering if anyone had a better solution. Is there some field method for setting fields by choice name which I totally overlooked?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Most efficient way of making an if-elif-elif-else statement when the else is done the most?",
        "A_Content": "  The code...  options.get(something, doThisMostOfTheTime)()   ...looks like it ought to be faster, but it's actually slower than the if ... elif ... else construct, because it has to call a function, which can be a significant performance overhead in a tight loop.  Consider these examples...  1.py  something = 'something'  for i in xrange(1000000):     if something == 'this':         the_thing = 1     elif something == 'that':         the_thing = 2     elif something == 'there':         the_thing = 3     else:         the_thing = 4   2.py  something = 'something' options = {'this': 1, 'that': 2, 'there': 3}  for i in xrange(1000000):     the_thing = options.get(something, 4)   3.py  something = 'something' options = {'this': 1, 'that': 2, 'there': 3}  for i in xrange(1000000):     if something in options:         the_thing = options[something]     else:         the_thing = 4   4.py  from collections import defaultdict  something = 'something' options = defaultdict(lambda: 4, {'this': 1, 'that': 2, 'there': 3})  for i in xrange(1000000):     the_thing = options[something]   ...and note the amount of CPU time they use...  1.py: 160ms 2.py: 170ms 3.py: 110ms 4.py: 100ms   ...using the user time from time(1).  Option #4 does have the additional memory overhead of adding a new item for every distinct key miss, so if you're expecting an unbounded number of distinct key misses, I'd go with option #3, which is still a significant improvement on the original construct.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/17166074/most-efficient-way-of-making-an-if-elif-elif-else-statement-when-the-else-is-don",
        "A_Votes": "83",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've got a in if-elif-elif-else statement in which 99% of the time, the else statement is executed:  if something == 'this':     doThis() elif something == 'that':     doThat() elif something == 'there':     doThere() else:     doThisMostOfTheTime()   This construct is done a lot, but since it goes over every condition before it hits the else I have the feeling this is not very efficient, let alone Pythonic. On the other hand, it does need to know if any of those conditions are met, so it should test it anyway.  Does anybody know if and how this could be done more efficiently or is this simply the best possible way to do it?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Most efficient way of making an if-elif-elif-else statement when the else is done the most?",
        "A_Content": "  I'd create a dictionary :  options = {'this': doThis,'that' :doThat, 'there':doThere}   Now use just:   options.get(something, doThisMostOfTheTime)()   If something is not found in the options dict then dict.get will return the default value doThisMostOfTheTime  Some timing comparisons:  Script:  from random import shuffle def doThis():pass def doThat():pass def doThere():pass def doSomethingElse():pass options = {'this':doThis, 'that':doThat, 'there':doThere} lis = range(10**4) + options.keys()*100 shuffle(lis)  def get():     for x in lis:         options.get(x, doSomethingElse)()  def key_in_dic():     for x in lis:         if x in options:             options[x]()         else:             doSomethingElse()  def if_else():     for x in lis:         if x == 'this':             doThis()         elif x == 'that':             doThat()         elif x == 'there':             doThere()         else:             doSomethingElse()   Results:  >>> from so import * >>> %timeit get() 100 loops, best of 3: 5.06 ms per loop >>> %timeit key_in_dic() 100 loops, best of 3: 3.55 ms per loop >>> %timeit if_else() 100 loops, best of 3: 6.42 ms per loop   For 10**5 non-existent keys and 100 valid keys::  >>> %timeit get() 10 loops, best of 3: 84.4 ms per loop >>> %timeit key_in_dic() 10 loops, best of 3: 50.4 ms per loop >>> %timeit if_else() 10 loops, best of 3: 104 ms per loop   So, for a normal dictionary checking for the key using key in options is the most efficient way here:  if key in options:    options[key]() else:    doSomethingElse()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/17166074/most-efficient-way-of-making-an-if-elif-elif-else-statement-when-the-else-is-don",
        "A_Votes": "71",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got a in if-elif-elif-else statement in which 99% of the time, the else statement is executed:  if something == 'this':     doThis() elif something == 'that':     doThat() elif something == 'there':     doThere() else:     doThisMostOfTheTime()   This construct is done a lot, but since it goes over every condition before it hits the else I have the feeling this is not very efficient, let alone Pythonic. On the other hand, it does need to know if any of those conditions are met, so it should test it anyway.  Does anybody know if and how this could be done more efficiently or is this simply the best possible way to do it?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Most efficient way of making an if-elif-elif-else statement when the else is done the most?",
        "A_Content": "  Are you able to use pypy?  Keeping your original code but running it on pypy gives a 50x speed-up for me.  CPython:  matt$ python Python 2.6.8 (unknown, Nov 26 2012, 10:25:03) [GCC 4.2.1 Compatible Apple Clang 3.0 (tags/Apple/clang-211.12)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> >>> from timeit import timeit >>> timeit(\"\"\" ... if something == 'this': pass ... elif something == 'that': pass ... elif something == 'there': pass ... else: pass ... \"\"\", \"something='foo'\", number=10000000) 1.728302001953125   Pypy:  matt$ pypy Python 2.7.3 (daf4a1b651e0, Dec 07 2012, 23:00:16) [PyPy 2.0.0-beta1 with GCC 4.2.1] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. And now for something completely different: ``a 10th of forever is 1h45'' >>>> >>>> from timeit import timeit >>>> timeit(\"\"\" .... if something == 'this': pass .... elif something == 'that': pass .... elif something == 'there': pass .... else: pass .... \"\"\", \"something='foo'\", number=10000000) 0.03306388854980469      ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/17166074/most-efficient-way-of-making-an-if-elif-elif-else-statement-when-the-else-is-don",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got a in if-elif-elif-else statement in which 99% of the time, the else statement is executed:  if something == 'this':     doThis() elif something == 'that':     doThat() elif something == 'there':     doThere() else:     doThisMostOfTheTime()   This construct is done a lot, but since it goes over every condition before it hits the else I have the feeling this is not very efficient, let alone Pythonic. On the other hand, it does need to know if any of those conditions are met, so it should test it anyway.  Does anybody know if and how this could be done more efficiently or is this simply the best possible way to do it?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Most efficient way of making an if-elif-elif-else statement when the else is done the most?",
        "A_Content": "  That's an example of a if with dynamic conditions translated to a dictionary.  selector = {lambda d: datetime(2014, 12, 31) >= d : 'before2015',             lambda d: datetime(2015, 1, 1) <= d < datetime(2016, 1, 1): 'year2015',             lambda d: datetime(2016, 1, 1) <= d < datetime(2016, 12, 31): 'year2016'}  def select_by_date(date, selector=selector):     selected = [selector[x] for x in selector if x(date)] or ['after2016']     return selected[0]   It is a way, but may not be the most pythonic way to do it because is less readable for whom is not fluent in Python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "performance",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/17166074/most-efficient-way-of-making-an-if-elif-elif-else-statement-when-the-else-is-don",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got a in if-elif-elif-else statement in which 99% of the time, the else statement is executed:  if something == 'this':     doThis() elif something == 'that':     doThat() elif something == 'there':     doThere() else:     doThisMostOfTheTime()   This construct is done a lot, but since it goes over every condition before it hits the else I have the feeling this is not very efficient, let alone Pythonic. On the other hand, it does need to know if any of those conditions are met, so it should test it anyway.  Does anybody know if and how this could be done more efficiently or is this simply the best possible way to do it?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What is the difference between join and merge in Pandas?",
        "A_Content": "  I always use join on indices:  import pandas as pd left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key') right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key') left.join(right, lsuffix='_l', rsuffix='_r')       val_l  val_r key             foo      1      4 bar      2      5   The same functionality can be had by using merge on the columns follows:  left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}) right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}) left.merge(right, on=('key'), suffixes=('_l', '_r'))     key  val_l  val_r 0  foo      1      4 1  bar      2      5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I have two DataFrames like so:  left = pd.DataFrame({'key1': ['foo', 'bar'], 'lval': [1, 2]})  right = pd.DataFrame({'key2': ['foo', 'bar'], 'rval': [4, 5]})   I want to merge them, so I try something like this:  pd.merge(left, right, left_on='key1', right_on='key2')   And I'm happy      key1    lval    key2    rval 0   foo     1       foo     4 1   bar     2       bar     5   But I'm trying to use the join method, which I've been lead to believe is pretty similar.   left.join(right, on=['key1', 'key2'])   And I get this:  //anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc in _validate_specification(self)     406             if self.right_index:     407                 if not ((len(self.left_on) == self.right.index.nlevels)): --> 408                     raise AssertionError()     409                 self.right_on = [None] * n     410         elif self.right_on is not None:  AssertionError:    What am I missing?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What is the difference between join and merge in Pandas?",
        "A_Content": "  pandas.merge() is the underlying function used for all merge/join behavior.   DataFrames provide the pandas.DataFrame.merge() and pandas.DataFrame.join() methods as a convenient way to access the capabilities of pandas.merge(). For example, df1.merge(right=df2, ...) is equivalent to pandas.merge(left=df1, right=df2, ...).   These are the main differences between df.join() and df.merge():   lookup on right table: df1.join(df2) always joins via the index of df2, but df1.merge(df2) can join to one or more columns of df2 (default) or to the index of df2 (with right_index=True).  lookup on left table: by default, df1.join(df2) uses the index of df1 and df1.merge(df2) uses column(s) of df1. That can be overridden by specifying df1.join(df2, on=key_or_keys) or df1.merge(df2, left_index=True).  left vs inner join: df1.join(df2) does a left join by default (keeps all rows of df1), but df.merge does an inner join by default (returns only matching rows of df1 and df2).   So, the generic approach is to use pandas.merge(df1, df2) or df1.merge(df2). But for a number of common situations (keeping all rows of df1 and joining to  an index in df2), you can save some typing by using df1.join(df2) instead.  Some notes on these issues from the documentation at http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging:     merge is a function in the pandas namespace, and it is also   available as a DataFrame instance method, with the calling DataFrame   being implicitly considered the left object in the join.      The related DataFrame.join method, uses merge internally for the   index-on-index and index-on-column(s) joins, but joins on indexes by   default rather than trying to join on common columns (the default   behavior for merge). If you are joining on index, you may wish to   use DataFrame.join to save yourself some typing.   ...     These two function calls are completely equivalent:  left.join(right, on=key_or_keys) pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)       ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have two DataFrames like so:  left = pd.DataFrame({'key1': ['foo', 'bar'], 'lval': [1, 2]})  right = pd.DataFrame({'key2': ['foo', 'bar'], 'rval': [4, 5]})   I want to merge them, so I try something like this:  pd.merge(left, right, left_on='key1', right_on='key2')   And I'm happy      key1    lval    key2    rval 0   foo     1       foo     4 1   bar     2       bar     5   But I'm trying to use the join method, which I've been lead to believe is pretty similar.   left.join(right, on=['key1', 'key2'])   And I get this:  //anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc in _validate_specification(self)     406             if self.right_index:     407                 if not ((len(self.left_on) == self.right.index.nlevels)): --> 408                     raise AssertionError()     409                 self.right_on = [None] * n     410         elif self.right_on is not None:  AssertionError:    What am I missing?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What is the difference between join and merge in Pandas?",
        "A_Content": "  I believe that join() is just a convenience method. Try df1.merge(df2) instead, which allows you to specify left_on and right_on:  In [30]: left.merge(right, left_on=\"key1\", right_on=\"key2\") Out[30]:    key1  lval key2  rval 0  foo     1  foo     4 1  bar     2  bar     5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have two DataFrames like so:  left = pd.DataFrame({'key1': ['foo', 'bar'], 'lval': [1, 2]})  right = pd.DataFrame({'key2': ['foo', 'bar'], 'rval': [4, 5]})   I want to merge them, so I try something like this:  pd.merge(left, right, left_on='key1', right_on='key2')   And I'm happy      key1    lval    key2    rval 0   foo     1       foo     4 1   bar     2       bar     5   But I'm trying to use the join method, which I've been lead to believe is pretty similar.   left.join(right, on=['key1', 'key2'])   And I get this:  //anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc in _validate_specification(self)     406             if self.right_index:     407                 if not ((len(self.left_on) == self.right.index.nlevels)): --> 408                     raise AssertionError()     409                 self.right_on = [None] * n     410         elif self.right_on is not None:  AssertionError:    What am I missing?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What is the difference between join and merge in Pandas?",
        "A_Content": "  http://pandas.pydata.org/pandas-docs/stable/merging.html#brief-primer-on-merge-methods-relational-algebra     pandas provides a single function, merge, as the entry point for all   standard database join operations between DataFrame objects:      merge(left, right, how='inner', on=None, left_on=None, right_on=None,         left_index=False, right_index=False, sort=True,         suffixes=('_x', '_y'), copy=True, indicator=False)   And :     DataFrame.join is a convenient method for combining the columns of two   potentially differently-indexed DataFrames into a single result   DataFrame. Here is a very basic example: The data alignment here is on   the indexes (row labels). This same behavior can be achieved using   merge plus additional arguments instructing it to use the indexes:   result = pd.merge(left, right, left_index=True, right_index=True,   how='outer')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have two DataFrames like so:  left = pd.DataFrame({'key1': ['foo', 'bar'], 'lval': [1, 2]})  right = pd.DataFrame({'key2': ['foo', 'bar'], 'rval': [4, 5]})   I want to merge them, so I try something like this:  pd.merge(left, right, left_on='key1', right_on='key2')   And I'm happy      key1    lval    key2    rval 0   foo     1       foo     4 1   bar     2       bar     5   But I'm trying to use the join method, which I've been lead to believe is pretty similar.   left.join(right, on=['key1', 'key2'])   And I get this:  //anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc in _validate_specification(self)     406             if self.right_index:     407                 if not ((len(self.left_on) == self.right.index.nlevels)): --> 408                     raise AssertionError()     409                 self.right_on = [None] * n     410         elif self.right_on is not None:  AssertionError:    What am I missing?     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python str vs unicode types",
        "A_Content": "  unicode is meant to handle text. Text is a sequence of code points which may be bigger than a single byte. Text can be encoded in a specific encoding to represent the text as raw bytes(e.g. utf-8, latin-1...).  Note that unicode is not encoded! The internal representation used by python is an implementation detail, and you shouldn't care about it as long as it is able to represent the code points you want.  On the contrary str in Python 2 is a plain sequence of bytes. It does not represent text!  You can think of unicode as a general representation of some text, which can be encoded in many different ways into a sequence of binary data represented via str.  Note: In Python 3, unicode was renamed to str and there is a new bytes type for a plain sequence of bytes.  Some differences that you can see:  >>> len(u'à')  # a single code point 1 >>> len('à')   # by default utf-8 -> takes two bytes 2 >>> len(u'à'.encode('utf-8')) 2 >>> len(u'à'.encode('latin1'))  # in latin1 it takes one byte 1 >>> print u'à'.encode('utf-8')  # terminal encoding is utf-8 à >>> print u'à'.encode('latin1') # it cannot understand the latin1 byte �   Note that using str you have a lower-level control on the single bytes of a specific encoding representation, while using unicode you can only control at the code-point level. For example you can do:  >>> 'àèìòù' '\\xc3\\xa0\\xc3\\xa8\\xc3\\xac\\xc3\\xb2\\xc3\\xb9' >>> print 'àèìòù'.replace('\\xa8', '') à�ìòù   What before was valid UTF-8, isn't anymore. Using a unicode string you cannot operate in such a way that the resulting string isn't valid unicode text. You can remove a code point, replace a code point with a different code point etc. but you cannot mess with the internal representation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/18034272/python-str-vs-unicode-types",
        "A_Votes": "148",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Working with Python 2.7, I'm wondering what real advantage there is in using the type unicode instead of str, as both of them seem to be able to hold Unicode strings. Is there any special reason apart from being able to set Unicode codes in unicode strings using the escape char \\?:  Executing a module with:  # -*- coding: utf-8 -*-  a = 'á' ua = u'á' print a, ua   Results in: á, á  EDIT:  More testing using Python shell:  >>> a = 'á' >>> a '\\xc3\\xa1' >>> ua = u'á' >>> ua u'\\xe1' >>> ua.encode('utf8') '\\xc3\\xa1' >>> ua.encode('latin1') '\\xe1' >>> ua u'\\xe1'   So, the unicode string seems to be encoded using latin1 instead of utf-8 and the raw string is encoded using utf-8? I'm even more confused now! :S     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python str vs unicode types",
        "A_Content": "  Your terminal happens to be configured to UTF-8.  The fact that printing a works is a coincidence; you are writing raw UTF-8 bytes to the terminal. a is a value of length two, containing two bytes, hex values C3 and A1, while ua is a unicode value of length one, containing a codepoint U+00E1.  This difference in length is one major reason to use Unicode values; you cannot easily measure the number of text characters in a byte string; the len() of a byte string tells you how many bytes were used, not how many characters were encoded.  You can see the difference when you encode the unicode value to different output encodings:  >>> a = 'á' >>> ua = u'á' >>> ua.encode('utf8') '\\xc3\\xa1' >>> ua.encode('latin1') '\\xe1' >>> a '\\xc3\\xa1'   Note that the first 256 codepoints of the Unicode standard match the Latin 1 standard, so the U+00E1 codepoint is encoded to Latin 1 as a byte with hex value E1.  Furthermore, Python uses escape codes in representations of unicode and byte strings alike, and low code points that are not printable ASCII are represented using \\x.. escape values as well. This is why a Unicode string with a code point between 128 and 255 looks just like the Latin 1 encoding. If you have a unicode string with codepoints beyond U+00FF a different escape sequence, \\u.... is used instead, with a four-digit hex value.  It looks like you don't yet fully understand what the difference is between Unicode and an encoding. Please do read the following articles before you continue:   The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) by Joel Spolsky The Python Unicode HOWTO Pragmatic Unicode by Ned Batchelder      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/18034272/python-str-vs-unicode-types",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Working with Python 2.7, I'm wondering what real advantage there is in using the type unicode instead of str, as both of them seem to be able to hold Unicode strings. Is there any special reason apart from being able to set Unicode codes in unicode strings using the escape char \\?:  Executing a module with:  # -*- coding: utf-8 -*-  a = 'á' ua = u'á' print a, ua   Results in: á, á  EDIT:  More testing using Python shell:  >>> a = 'á' >>> a '\\xc3\\xa1' >>> ua = u'á' >>> ua u'\\xe1' >>> ua.encode('utf8') '\\xc3\\xa1' >>> ua.encode('latin1') '\\xe1' >>> ua u'\\xe1'   So, the unicode string seems to be encoded using latin1 instead of utf-8 and the raw string is encoded using utf-8? I'm even more confused now! :S     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python str vs unicode types",
        "A_Content": "  Unicode and encodings are completely different, unrelated things.  Unicode  Assigns a numeric ID to each character:   0x41 → A 0xE1 → á 0x414 → Д   So, Unicode assigns the number 0x41 to A, 0xE1 to á, and 0x414 to Д.  Even the little arrow → I used has its Unicode number, it's 0x2192. And even emojis have their Unicode numbers, \uD83D\uDE02 is 0x1F602.  You can look up the Unicode numbers of all characters in this table. In particular, you can find the first three characters above here, the arrow here, and the emoji here.  These numbers assigned to all characters by Unicode are called code points.  The purpose of all this is to provide a means to unambiguously refer to a each character. For example, if I'm talking about \uD83D\uDE02, instead of saying \"you know, this laughing emoji with tears\", I can just say, Unicode code point 0x1F602. Easier, right?  Note that Unicode code points are usually formatted with a leading U+, then the hexadecimal numeric value padded to at least 4 digits. So, the above examples would be U+0041, U+00E1, U+0414, U+2192, U+1F602.  Unicode code points range from U+0000 to U+10FFFF. That is 1,114,112 numbers. 2048 of these numbers are used for surrogates, thus, there remain 1,112,064. This means, Unicode can assign a unique ID (code point) to 1,112,064 distinct characters. Not all of these code points are assigned to a character yet, and Unicode is extended continuously (for example, when new emojis are introduced).  The important thing to remember is that all Unicode does is to assign a numerical ID, called code point, to each character for easy and unambiguous reference.  Encodings  Map characters to bit patterns.  These bit patterns are used to represent the characters in computer memory or on disk.  There are many different encodings that cover different subsets of characters. In the English-speaking world, the most common encodings are the following:  ASCII  Maps 128 characters (code points U+0000 to U+007F) to bit patterns of length 7.  Example:   a → 1100001 (0x61)   You can see all the mappings in this table.  ISO 8859-1 (aka Latin-1)  Maps 191 characters (code points U+0020 to U+007E and U+00A0 to U+00FF) to bit patterns of length 8.  Example:   a → 01100001 (0x61) á → 11100001 (0xE1)   You can see all the mappings in this table.  UTF-8  Maps 1,112,064 characters (all existing Unicode code points) to bit patterns of either length 8, 16, 24, or 32 bits (that is, 1, 2, 3, or 4 bytes).  Example:   a → 01100001 (0x61) á → 11000011 10100001 (0xC3 0xA1) ≠ → 11100010 10001001 10100000 (0xE2 0x89 0xA0) \uD83D\uDE02 → 11110000 10011111 10011000 10000010 (0xF0 0x9F 0x98 0x82)   The way UTF-8 encodes characters to bit strings is very well described here.  Unicode and Encodings  Looking at the above examples, it becomes clear how Unicode is useful.  For example, if I'm Latin-1 and I want to explain my encoding of á, I don't need to say:     \"I encode that a with an aigu (or however you call that rising bar) as 11100001\"   But I can just say:     \"I encode U+00E1 as 11100001\"   And if I'm UTF-8, I can say:     \"Me, in turn, I encode U+00E1 as 11000011 10100001\"   And it's unambiguously clear to everybody which character we mean.  Now to the often arising confusion  It's true that sometimes the bit pattern of an encoding, if you interpret it as a binary number, is the same as the Unicode code point of this character.  For example:   ASCII encodes a as 1100001, which you can interpret as the hexadecimal number 0x61, and the Unicode code point of a is U+0061. Latin-1 encodes á as 11100001, which you can interpret as the hexadecimal number 0xE1, and the Unicode code point of á is U+00E1.   Of course, this has been arranged like this on purpose for convenience. But you should look at it as a pure coincidence. The bit pattern used to represent a character in memory is not tied in any way to the Unicode code point of this character.  Nobody even says that you have to interpret a bit string like 11100001 as a binary number. Just look at it as the sequence of bits that Latin-1 uses to encode the character á.  Back to your question  The encoding used by your Python interpreter is UTF-8.  Here's what's going on in your examples:  Example 1  The following encodes the character á in UTF-8. This results in the bit string 11000011 10100001, which is saved in the variable a.  >>> a = 'á'   When you look at the value of a, its content 11000011 10100001 is formatted as the hex number 0xC3 0xA1 and output as '\\xc3\\xa1':  >>> a '\\xc3\\xa1'   Example 2  The following saves the Unicode code point of á, which is U+00E1, in the variable ua (we don't know which data format Python uses internally to represent the code point U+00E1 in memory, and it's unimportant to us):  >>> ua = u'á'   When you look at the value of ua, Python tells you that it contains the code point U+00E1:  >>> ua u'\\xe1'   Example 3  The following encodes Unicode code point U+00E1 (representing character á) with UTF-8, which results in the bit pattern 11000011 10100001. Again, for output this bit pattern is represented as the hex number 0xC3 0xA1:  >>> ua.encode('utf-8') '\\xc3\\xa1'   Example 4  The following encodes Unicode code point U+00E1 (representing character á) with Latin-1, which results in the bit pattern 11100001. For output, this bit pattern is represented as the hex number 0xE1, which by coincidence is the same as the initial code point U+00E1:  >>> ua.encode('latin1') '\\xe1'   There's no relation between the Unicode object ua and the Latin-1 encoding. That the code point of á is U+00E1 and the Latin-1 encoding of á is 0xE1 (if you interpret the bit pattern of the encoding as a binary number) is a pure coincidence.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/18034272/python-str-vs-unicode-types",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Working with Python 2.7, I'm wondering what real advantage there is in using the type unicode instead of str, as both of them seem to be able to hold Unicode strings. Is there any special reason apart from being able to set Unicode codes in unicode strings using the escape char \\?:  Executing a module with:  # -*- coding: utf-8 -*-  a = 'á' ua = u'á' print a, ua   Results in: á, á  EDIT:  More testing using Python shell:  >>> a = 'á' >>> a '\\xc3\\xa1' >>> ua = u'á' >>> ua u'\\xe1' >>> ua.encode('utf8') '\\xc3\\xa1' >>> ua.encode('latin1') '\\xe1' >>> ua u'\\xe1'   So, the unicode string seems to be encoded using latin1 instead of utf-8 and the raw string is encoded using utf-8? I'm even more confused now! :S     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python str vs unicode types",
        "A_Content": "  When you define a as unicode, the chars a and á are equal. Otherwise á counts as two chars. Try len(a) and len(au). In addition to that, you may need to have the encoding when you work with other environments. For example if you use md5, you get different values for a and ua     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/18034272/python-str-vs-unicode-types",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Working with Python 2.7, I'm wondering what real advantage there is in using the type unicode instead of str, as both of them seem to be able to hold Unicode strings. Is there any special reason apart from being able to set Unicode codes in unicode strings using the escape char \\?:  Executing a module with:  # -*- coding: utf-8 -*-  a = 'á' ua = u'á' print a, ua   Results in: á, á  EDIT:  More testing using Python shell:  >>> a = 'á' >>> a '\\xc3\\xa1' >>> ua = u'á' >>> ua u'\\xe1' >>> ua.encode('utf8') '\\xc3\\xa1' >>> ua.encode('latin1') '\\xe1' >>> ua u'\\xe1'   So, the unicode string seems to be encoded using latin1 instead of utf-8 and the raw string is encoded using utf-8? I'm even more confused now! :S     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  How do you enter line breaks with raw_input? But, once you have a string with some characters in it you want to get rid of, just replace them.  >>> mystr = raw_input('please enter string: ') please enter string: hello world, how do i enter line breaks? >>> # pressing enter didn't work... ... >>> mystr 'hello world, how do i enter line breaks?' >>> mystr.replace(' ', '') 'helloworld,howdoienterlinebreaks?' >>>   In the example above, I replaced all spaces. The string '\\n' represents newlines. And \\r represents carriage returns (if you're on windows, you might be getting these and a second replace will handle them for you!).  basically:  # you probably want to use a space ' ' to replace `\\n` mystring = mystring.replace('\\n', ' ').replace('\\r', '')   Note also, that it is a bad idea to call your variable string, as this shadows the module string. Another name I'd avoid but would love to use sometimes: file. For the same reason.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "136",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  You can try using string replace:  string = string.replace('\\r', '').replace('\\n', '')      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  updated based on Xbello comment:  string = my_string.rstrip('\\r\\n')   read more here     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  You can split the string with no separator arg, which will treat consecutive whitespace as a single separator (including newlines and tabs). Then join using a space:  In : \" \".join(\"\\n\\nsome    text \\r\\n with multiple whitespace\".split()) Out: 'some text with multiple whitespace'   https://docs.python.org/2/library/stdtypes.html#str.split     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  A method taking into consideration   additional white characters at the beginning/end of string  additional white characters at the beginning/end of every line various end-line characters   it takes such a multi-line string which may be messy e.g.  test_str = '\\nhej ho \\n aaa\\r\\n   a\\n '   and produces nice one-line string  >>> ' '.join([line.strip() for line in test_str.strip().splitlines()]) 'hej ho aaa a'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Remove all line breaks from a long string of text",
        "A_Content": "  Another option is regex:  >>> import re >>> re.sub(\"\\n|\\r\", \"\", \"Foo\\n\\rbar\\n\\rbaz\\n\\r\") 'Foobarbaz'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/16566268/remove-all-line-breaks-from-a-long-string-of-text",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I'm asking the user to input a string of text into the console, but the string is very long and includes many line breaks.  How would I take the user's string and delete all line breaks to make it a single line of text.  My method for acquiring the string is very simple.  string = raw_input(\"Please enter string: \")   Is there a different way I should be grabbing the string from the user?  I'm running Python 2.7.4 on a Mac.  P.S. Clearly I'm a noob, so even if a solution isn't the most efficient, the one that uses the most simple syntax would be appreciated.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What does x[x < 2] = 0 mean in Python?",
        "A_Content": "  This only makes sense with NumPy arrays. The behavior with lists is useless, and specific to Python 2 (not Python 3). You may want to double-check if the original object was indeed a NumPy array (see further below) and not a list.  But in your code here, x is a simple list.  Since  x < 2   is False i.e 0, therefore  x[x<2] is x[0]  x[0] gets changed.  Conversely, x[x>2] is x[True] or x[1]  So, x[1] gets changed.  Why does this happen?  The rules for comparison are:   When you order two strings or two numeric types the ordering is done in the expected way (lexicographic ordering for string, numeric ordering for integers). When you order a numeric and a non-numeric type, the numeric type comes first. When you order two incompatible types where neither is numeric, they are ordered by the alphabetical order of their typenames:   So, we have the following order  numeric < list < string < tuple  See the accepted answer for How does Python compare string and int?.  If x is a NumPy array, then the syntax makes more sense because of boolean array indexing. In that case, x < 2 isn't a boolean at all; it's an array of booleans representing whether each element of x was less than 2. x[x < 2] = 0 then selects the elements of x that were less than 2 and sets those cells to 0. See Indexing.  >>> x = np.array([1., -1., -2., 3]) >>> x < 0 array([False,  True,  True, False], dtype=bool) >>> x[x < 0] += 20   # All elements < 0 get increased by 20 >>> x array([  1.,  19.,  18.,   3.]) # Only elements < 0 are affected      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/36603042/what-does-xx-2-0-mean-in-python",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I came across some code with a line similar to  x[x<2]=0   Playing around with variations, I am still stuck on what this syntax does.  Examples:  >>> x = [1,2,3,4,5] >>> x[x<2] 1 >>> x[x<3] 1 >>> x[x>2] 2 >>> x[x<2]=0 >>> x [0, 2, 3, 4, 5]      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What does x[x < 2] = 0 mean in Python?",
        "A_Content": "  >>> x = [1,2,3,4,5] >>> x<2 False >>> x[False] 1 >>> x[True] 2   The bool is simply converted to an integer. The index is either 0 or 1.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/36603042/what-does-xx-2-0-mean-in-python",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I came across some code with a line similar to  x[x<2]=0   Playing around with variations, I am still stuck on what this syntax does.  Examples:  >>> x = [1,2,3,4,5] >>> x[x<2] 1 >>> x[x<3] 1 >>> x[x>2] 2 >>> x[x<2]=0 >>> x [0, 2, 3, 4, 5]      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What does x[x < 2] = 0 mean in Python?",
        "A_Content": "  The original code in your question works only in Python 2. If x is a list in Python 2, the comparison x < y is False if y is an integer. This is because it does not make sense to compare a list with an integer. However in Python 2, if the operands are not comparable, the comparison is based in CPython on the alphabetical ordering of the names of the types; additionally all numbers come first in mixed-type comparisons. This is not even spelled out in the documentation of CPython 2, and different Python 2 implementations could give different results. That is [1, 2, 3, 4, 5] < 2 evaluates to False because 2 is a number and thus \"smaller\" than a list in CPython. This mixed comparison was eventually deemed to be too obscure a feature, and was removed in Python 3.0.    Now, the result of < is a bool; and bool is a subclass of int:  >>> isinstance(False, int) True >>> isinstance(True, int) True >>> False == 0 True >>> True == 1 True >>> False + 5 5 >>> True + 5 6   So basically you're taking the element 0 or 1 depending on whether the comparison is true or false.    If you try the code above in Python 3, you will get TypeError: unorderable types: list() < int() due to a change in Python 3.0:     Ordering Comparisons      Python 3.0 has simplified the rules for ordering comparisons:      The ordering comparison operators (<, <=, >=, >) raise a TypeError exception when the operands don’t have a meaningful natural ordering. Thus, expressions like 1 < '', 0 > None or len <= len are no longer valid, and e.g. None < None raises TypeError instead of returning False. A corollary is that sorting a heterogeneous list no longer makes sense – all the elements must be comparable to each other. Note that this does not apply to the == and != operators: objects of different incomparable types always compare unequal to each other.     There are many datatypes that overload the comparison operators to do something different (dataframes from pandas, numpy's arrays). If the code that you were using did something else, it was because x was not a list, but an instance of some other class with operator < overridden to return a value that is not a bool; and this value was then handled specially by x[] (aka __getitem__/__setitem__)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/36603042/what-does-xx-2-0-mean-in-python",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I came across some code with a line similar to  x[x<2]=0   Playing around with variations, I am still stuck on what this syntax does.  Examples:  >>> x = [1,2,3,4,5] >>> x[x<2] 1 >>> x[x<3] 1 >>> x[x>2] 2 >>> x[x<2]=0 >>> x [0, 2, 3, 4, 5]      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What does x[x < 2] = 0 mean in Python?",
        "A_Content": "  This has one more use: code golf. Code golf is the art of writing programs that solve some problem in as few source code bytes as possible.   return(a,b)[c<d]   is roughly equivalent to  if c < d:     return b else:     return a   except that both a and b are evaluated in the first version, but not in the second version.  c<d evaluates to True or False. (a, b) is a tuple. Indexing on a tuple works like indexing on a list: (3,5)[1] == 5. True is equal to 1 and False is equal to 0.     (a,b)[c<d] (a,b)[True] (a,b)[1] b   or for False:   (a,b)[c<d] (a,b)[False] (a,b)[0] a   There's a good list on the stack exchange network of many nasty things you can do to python in order to save a few bytes. https://codegolf.stackexchange.com/questions/54/tips-for-golfing-in-python  Although in normal code this should never be used, and in your case it would mean that x acts both as something that can be compared to an integer and as a container that supports slicing, which is a very unusual combination. It's probably Numpy code, as others have pointed out.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/36603042/what-does-xx-2-0-mean-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I came across some code with a line similar to  x[x<2]=0   Playing around with variations, I am still stuck on what this syntax does.  Examples:  >>> x = [1,2,3,4,5] >>> x[x<2] 1 >>> x[x<3] 1 >>> x[x>2] 2 >>> x[x<2]=0 >>> x [0, 2, 3, 4, 5]      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What does x[x < 2] = 0 mean in Python?",
        "A_Content": "  In general it could mean anything. It was already explained what it means if x is a list or numpy.ndarray but in general it only depends on how the comparison operators (<, >, ...) and also how the get/set-item ([...]-syntax) are implemented.  x.__getitem__(x.__lt__(2))      # this is what x[x < 2] means! x.__setitem__(x.__lt__(2), 0)   # this is what x[x < 2] = 0 means!   Because:   x < value is equivalent to x.__lt__(value) x[value] is (roughly) equivalent to x.__getitem__(value)  x[value] = othervalue is (also roughly) equivalent to x.__setitem__(value, othervalue).     This can be customized to do anything you want. Just as an example (mimics a bit numpys-boolean indexing):  class Test:     def __init__(self, value):         self.value = value      def __lt__(self, other):         # You could do anything in here. For example create a new list indicating if that          # element is less than the other value         res = [item < other for item in self.value]         return self.__class__(res)      def __repr__(self):         return '{0} ({1})'.format(self.__class__.__name__, self.value)      def __getitem__(self, item):         # If you index with an instance of this class use \"boolean-indexing\"         if isinstance(item, Test):             res = self.__class__([i for i, index in zip(self.value, item) if index])             return res         # Something else was given just try to use it on the value         return self.value[item]      def __setitem__(self, item, value):         if isinstance(item, Test):             self.value = [i if not index else value for i, index in zip(self.value, item)]         else:             self.value[item] = value   So now let's see what happens if you use it:  >>> a = Test([1,2,3]) >>> a Test ([1, 2, 3]) >>> a < 2  # calls __lt__ Test ([True, False, False]) >>> a[Test([True, False, False])] # calls __getitem__ Test ([1]) >>> a[a < 2] # or short form Test ([1])  >>> a[a < 2] = 0  # calls __setitem__ >>> a Test ([0, 2, 3])   Notice this is just one possibility. You are free to implement almost everything you want.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/36603042/what-does-xx-2-0-mean-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I came across some code with a line similar to  x[x<2]=0   Playing around with variations, I am still stuck on what this syntax does.  Examples:  >>> x = [1,2,3,4,5] >>> x[x<2] 1 >>> x[x<3] 1 >>> x[x>2] 2 >>> x[x<2]=0 >>> x [0, 2, 3, 4, 5]      ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  They are used for formatting strings. %s acts a placeholder for a string while %d acts as a placeholder for a number. Their associated values are passed in via a tuple using the % operator.   name = 'marcog' number = 42 print '%s %d' % (name, number)   will print marcog 42. Note that name is a string (%s) and number is an integer (%d for decimal).  See https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting for details.  In Python 3 the example would be:  print('%s %d' % (name, number))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  %s is used as a placeholder for string values you want to inject into a formatted string.  %d is used as a placeholder for numeric or decimal values.  For example  '%s is %d years old' % ('Joe', 42)   Would output  'Joe is 42 years old'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  These are placeholders:  For example: 'Hi %s I have %d donuts' %('Alice', 42)  This line of code will substitute %s with Alice (str) and %d with 42.  Output: 'Hi Alice I have 42 donuts'  This could be achieved with a \"+\" most of the time. To gain a deeper understanding to your question, you may want to check {} / .format() as well. Here is one example: Python string formatting: % vs. .format  also see here a google python tutorial video @ 40', it has some explanations https://www.youtube.com/watch?v=tKTZoB2Vjuk     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  %d and %s are placeholders, they work as a replaceable variable. For example, if you create 2 variables  variable_one = \"Stackoverflow\" variable_two = 45   you can assign those variables to a sentence in a string using a tuple of the variables.  variable_3 = \"I was searching for an answer in %s and found more than %d answers to my question\"   Note that %s works for String and %d work for numerical or decimal variables.  if you print variable_3 it would look like this  print(variable_3 % (variable_one, variable_two))   I was searching for an answer in StackOverflow and found more than 45 answers to my question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  They are format specifiers. They are used when you want to include the value of your Python expressions into strings, with a specific format enforced.  See Dive into Python for a relatively detailed introduction.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  from python 3 doc  %d is for decimal integer  %s is for generic string or object and in case of object, it will be converted to string  Consider the following code  name ='giacomo' number = 4.3 print('%s %s %d %f %g' % (name, number, number, number, number))   the out put will be     giacomo 4.3 4 4.300000 4.3   as you can see %d will truncate to integer, %s will maintain formatting, %f will print as float and %g is used for generic number  obviously  print('%d' % (name))   will generate an exception; you cannot convert string to number     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  The %d and %s string formatting \"commands\" are used to format strings. The %d is for numbers, and %s is for strings.  For an example:  print(\"%s\" % \"hi\")   and  print(\"%d\" % 34.6)   To pass multiple arguments:  print(\"%s %s %s%d\" % (\"hi\", \"there\", \"user\", 123456)) will return hi there user123456     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  In case you would like to avoid %s or %d then..  name = 'marcog' number = 42 print ('my name is',name,'and my age is:', number)   Output:  my name is marcog and my name is 42      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "What's the difference between %s and %d in Python string formatting?",
        "A_Content": "  speaking of which ...  python3.6 comes with f-strings which  makes things much easier in formatting!  now if your python version is greater than 3.6 you can format your strings with these available methods:  name = \"python\"  print (\"i code with %s\" %name)          # with help of older method print (\"i code with {0}\".format(name))  # with help of format print (f\"i code with {name}\")           # with help of f-strings      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/4288973/whats-the-difference-between-s-and-d-in-python-string-formatting",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I don't understand what %s and %d do and how they work.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python pandas Filtering out nan from a data selection of a column of strings",
        "A_Content": "  Just drop them:  nms.dropna(thresh=2)   this will drop all rows where there are at least two non-NaN  then you could then drop where name is NaN:  In [87]:  nms Out[87]:   movie    name  rating 0   thg    John       3 1   thg     NaN       4 3   mol  Graham     NaN 4   lob     NaN     NaN 5   lob     NaN     NaN  [5 rows x 3 columns] In [89]:  nms = nms.dropna(thresh=2) In [90]:  nms[nms.name.notnull()] Out[90]:   movie    name  rating 0   thg    John       3 3   mol  Graham     NaN  [2 rows x 3 columns]   EDIT  Actually looking at what you originally want you can do just this without the dropna call:  nms[nms.name.notnull()]   UPDATE  Looking at this question 3 years later, there is a mistake, firstly thresh arg looks for at leas n non-NaN values so in fact the output should be:  In [4]: nms.dropna(thresh=2)  Out[4]:   movie    name  rating 0   thg    John     3.0 1   thg     NaN     4.0 3   mol  Graham     NaN   It's possible that I was either mistaken 3 years ago or that the version of pandas I was running had a bug, both scenarios entirely possible     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/22551403/python-pandas-filtering-out-nan-from-a-data-selection-of-a-column-of-strings",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Without using groupby how would I filter out data without NaN?  Let say I have a matrix where customers will fill in 'N/A','n/a' or any of its variations and others leave it blank:  import pandas as pd import numpy as np   df = pd.DataFrame({'movie': ['thg', 'thg', 'mol', 'mol', 'lob', 'lob'],                   'rating': [3., 4., 5., np.nan, np.nan, np.nan],                   'name': ['John', np.nan, 'N/A', 'Graham', np.nan, np.nan]})  nbs = df['name'].str.extract('^(N/A|NA|na|n/a)') nms=df[(df['name'] != nbs) ]   output:  >>> nms   movie    name  rating 0   thg    John       3 1   thg     NaN       4 3   mol  Graham     NaN 4   lob     NaN     NaN 5   lob     NaN     NaN   How would I filter out NaN values so I can get results to work with like this:    movie    name  rating 0   thg    John       3 3   mol  Graham     NaN   I am guessing I need something like ~np.isnan but the tilda does not work with strings.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Python pandas Filtering out nan from a data selection of a column of strings",
        "A_Content": "  Simplest of all solutions:  filtered_df = df[df['name'].notnull()]   Thus, it filters out only rows that doesn't have NaN values in 'name' column.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/22551403/python-pandas-filtering-out-nan-from-a-data-selection-of-a-column-of-strings",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Without using groupby how would I filter out data without NaN?  Let say I have a matrix where customers will fill in 'N/A','n/a' or any of its variations and others leave it blank:  import pandas as pd import numpy as np   df = pd.DataFrame({'movie': ['thg', 'thg', 'mol', 'mol', 'lob', 'lob'],                   'rating': [3., 4., 5., np.nan, np.nan, np.nan],                   'name': ['John', np.nan, 'N/A', 'Graham', np.nan, np.nan]})  nbs = df['name'].str.extract('^(N/A|NA|na|n/a)') nms=df[(df['name'] != nbs) ]   output:  >>> nms   movie    name  rating 0   thg    John       3 1   thg     NaN       4 3   mol  Graham     NaN 4   lob     NaN     NaN 5   lob     NaN     NaN   How would I filter out NaN values so I can get results to work with like this:    movie    name  rating 0   thg    John       3 3   mol  Graham     NaN   I am guessing I need something like ~np.isnan but the tilda does not work with strings.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  I think you don't have the python-opencv package.  I had the exact same problem and   sudo apt-get install python-opencv   solved the issue for me.  you can install opencv from the following link  https://www.learnopencv.com/install-opencv3-on-ubuntu/ It works for me .  apt-get install doesnt contain many packages of opencv     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  I also had this issue. Tried different things. But finally  conda install opencv   worked for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  If you want as simple as possible, install from the repository:  sudo apt-get install python-opencv libopencv-dev python-numpy python-dev      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  Use pip:     https://pypi.python.org/pypi/pip   $ pip install SomePackage   [...]   Successfully installed SomePackage   And when you add a path to PYTHONPATH with sys, PYTHONPATH it's always restarted to default values when you close your Python shell. Check this thread:     Permanently add a directory to PYTHONPATH   First add openCV to your path (Quick guide):     https://help.ubuntu.com/community/OpenCV   after that, install the non-python packages pyopencv depends on:  sudo apt-get build-dep python-opencv   finally, use pip:  pip install pyopencv   Also, you can check this tutorial to install openCV in ubuntu 14.04 LTS     http://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  Try conda install -c conda-forge opencv if you are using anaconda, it works!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  Find where the cv2.so is, for example /usr/local/lib/python2.7/dist-packages, then add this into your ~/.bashrc by doing:  sudo gedit ~/.bashrc   and add   export PYTHONPATH=/usr/local/lib/python2.7/dist-packages:$PYTHONPATH   In the last line  And then remember to open another terminal, this can be work, and I have solve my problem. Hope it can help you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  Verify if cv2.so did compile, should be placed in: /usr/local/lib/python2.7/site-packages Then export that path like this  export PYTHONPATH=/usr/local/lib/python2.7/site-packages:$PYTHONPATH   Same as in the answer here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  My environment:    Ubuntu 15.10 Python 3.5   Since none of the previous answers worked for me, I downloaded OpenCV 3.0 from http://opencv.org/downloads.html and followed the installation manual. I used the following cmake command:  $ ~/Programs/opencv-3.0.0$ cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D PYTHON3_EXECUTABLE=/usr/bin/python3.5 -D PYTHON_INCLUDE_DIR=/usr/include/python3.5 -D PYTHON_INCLUDE_DIR2=/usr/include/x86_64-linux-gnu/python3.5m -D PYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so -D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/lib/python3/dist-packages/numpy/core/include/ -D PYTHON3_PACKAGES_PATH=/usr/lib/python3/dist-packages ..   Each step of the tutorial is important. Particularly, don't forget to call sudo make install.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  I found a solution in the guide here:  http://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/  I resorted to compiling and installing from source. The process was very smooth, had I known, I would have started with that instead of trying to find a more simple way to install. Hopefully this information is helpful to someone.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  Create a symbolic link to OpenCV. Eg:  cd ~/.virtualenvs/cv/lib/python2.7/site-packages/ ln -s /usr/local/lib/python2.7/dist-packages/cv2.so cv2.so ln -s /usr/local/lib/python2.7/dist-packages/cv.py cv.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  If you really sure that you installed cv2 but it gives no module error. There is a solution for this. Probably you have cv2.so file in your directory  /usr/local/lib/python2.7/site-packages/cv2.so   move this cv2.so file to  /usr/lib/python2.7/site-packages   copy the file into site-packages directory     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  if you are using pycharm platform it's very simple go into view=>tool windows==>python console after that you will see in the bottom the console with [1] : type this !pip install opencv-python     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  This seemed to work for me on Max OSX: https://anaconda.org/menpo/opencv3  conda install -c menpo opencv3=3.1.0   I confirmed that you can import cv2 in python using python2.7 and python3     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  For me, this problem was due to the fact that I had not appropriately sym-linked the cv2.so file in the~/.virtualenvs/cv/lib/python3.5/site-packages folder (the name of your virualenv may not be \"cv\", your version of python may not be 3.5--adjust accordingly).   If you go to the ~/.virtualenvs/cv/lib/python3.5/site-packages folder and ls, the cv2.so file should appear in light blue (Ubuntu 16.04) showing that it is linked. You can check the link location by typing: readlink cv2.so   If cv2.so appears in red (as mine did), rm the file and type: (for my install of python 3.5)  ln -s /usr/local/lib/python3.5/dist-packages/cv2.cpython-35m-x86_64-linux-gnu.so cv2.so   OR (if you have python 3.6)  ln -s /usr/local/lib/python3.6/dist-packages/cv2.cpython-36m-x86_64-linux-gnu.so cv2.so   If you are working in python 2.6 or python 2.7, you instead type:  ln -s /usr/local/lib/python2.7/dist-packages/cv2.so cv2.so   If the cv2.so or cv2.cpython-36m-x86_64-linux-gnu.so files do not exist in your /usr/local/lib/python***/dist-packages location, check to see if they're in a /usr/local/lib/python***/sites-packages folder. If so, adjust the path accordingly. If not, something has gone wrong with your opencv installation.  This answer was inspired by information here: https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "Installing OpenCV for Python on Ubuntu, getting ImportError: No module named cv2.cv",
        "A_Content": "  For those who are trying to use 3.1.0 but after installing python says \"cv2 module not found\".  You likely have python but not python-dev.  sudo apt-get install python-dev   then reinstall 3.1.0 and it'll work.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "ubuntu",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/25215102/installing-opencv-for-python-on-ubuntu-getting-importerror-no-module-named-cv2",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an Ubuntu 14.04 system, on which I want to install OpenCV and use it with Python 2.x.  I installed OpenCV using the instructions here: https://help.ubuntu.com/community/OpenCV  The install seemed to run properly, no errors, the script ended with output   OpenCV 2.4.9 ready to be used   When I try to run the sample Python script, I get the following:  $ python opencv.py Traceback (most recent call last):   File \"opencv.py\", line 1, in <module>     from cv2.cv import * ImportError: No module named cv2.cv   I suspect I know why, I just don't know how to fix it. OpenCV installed to the current directory I was in when I ran the install script, it's a subdirectory of my home folder.   Others who get this import error after install seem to be having a path issue, and have luck adding this to their code:  import sys sys.path.append('/usr/local/lib/python2.7/site-packages')   or updating their PYTHONPATH with that same directory. I tried adding that code, it doesn't make a difference. I don't see any files in the \"site-packages\" directory. Should I have done the install in that directory? I imagine the installation instructions would have spelled that out. I suspect that my problem has to do with Python not finding the OpenCV install, but I'm not sure how to proceed.  Please help me get a usable install of OpenCV as simply as possible.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  You can use the .update() method if you don't need the original d2 any more:     Update the dictionary with the key/value pairs from other, overwriting existing keys. Return None.   E.g.:  >>> d1 = {'a': 1, 'b': 2}  >>> d2 = {'b': 1, 'c': 3} >>> d2.update(d1) >>> d2 {'a': 1, 'c': 3, 'b': 2}   Update:  Of course you can copy the dictionary first in order to create a new merged one. This might or might not be necessary. In case you have compound objects (objects that contain other objects, like lists or class instances) in your dictionary, copy.deepcopy should also be considered.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "145",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  In Python2,  d1={'a':1,'b':2} d2={'a':10,'c':3}   d1 overrides d2:   dict(d2,**d1) # {'a': 1, 'c': 3, 'b': 2}   d2 overrides d1:  dict(d1,**d2) # {'a': 10, 'c': 3, 'b': 2}   This behavior is not just a fluke of implementation; it is guaranteed in the documentation:     If a key is specified both in the   positional argument and as a keyword   argument, the value associated with   the keyword is retained in the   dictionary.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "39",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  If you want d1 to have priority in the conflicts, do:  d3 = d2.copy() d3.update(d1)   Otherwise, reverse d2 and d1.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  My solution is to define a merge function. It's not sophisticated and just cost one line. Here's the code in Python 3.  from functools import reduce from operator import or_  def merge(*dicts):     return { k: reduce(lambda d, x: x.get(k, d), dicts, None) for k in reduce(or_, map(lambda x: x.keys(), dicts), set()) }   Tests  >>> d = {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} >>> d_letters = {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'} >>> merge(d, d_letters) {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'} >>> merge(d_letters, d) {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'} >>> merge(d) {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} >>> merge(d_letters) {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'} >>> merge() {}   It works for arbitrary number of dictionary arguments. Were there any duplicate keys in those dictionary, the key from the rightmost dictionary in the argument list wins.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  Trey Hunner has a nice blog post outlining several options for merging multiple dictionaries, including (for python3.3+) ChainMap and dictionary unpacking.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    },
    {
        "Q_Title": "How do I merge dictionaries together in Python?",
        "A_Content": "  I believe that, as stated above, using d2.update(d1) is the best approach and that you can also copy d2 first if you still need it.  Although, I want to point out that dict(d1, **d2) is actually a bad way to merge dictionnaries in general since keyword arguments need to be strings, thus it will fail if you have a dict such as:  {   1: 'foo',   2: 'bar' }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/2799064/how-do-i-merge-dictionaries-together-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    d3 = dict(d1, **d2)   I understand that this merges the dictionary. But, is it unique? What if d1 has the same key as d2 but different value?  I would like d1 and d2 to be merged, but d1 has priority if there is duplicate key.     ",
        "Q_Votes": "83"
    }
]