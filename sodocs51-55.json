[
    {
        "Q_Title": "How to select all columns, except one column in pandas?",
        "A_Content": "  When you don't have a MultiIndex, df.columns is just an array of column names so you can do:  df.loc[:, df.columns != 'b']            a         c         d 0  0.561196  0.013768  0.772827 1  0.882641  0.615396  0.075381 2  0.368824  0.651378  0.397203 3  0.788730  0.568099  0.869127      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas",
        "A_Votes": "152",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a dataframe look like this:  import pandas import numpy as np df = DataFrame(np.random.rand(4,4), columns = list('abcd')) df       a         b         c         d 0  0.418762  0.042369  0.869203  0.972314 1  0.991058  0.510228  0.594784  0.534366 2  0.407472  0.259811  0.396664  0.894202 3  0.726168  0.139531  0.324932  0.906575   How I can get all columns except column b?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to select all columns, except one column in pandas?",
        "A_Content": "  Don't use ix. It's deprecated. The most readable and idiomatic way of doing this is df.drop():  >>> df            a         b         c         d 0  0.175127  0.191051  0.382122  0.869242 1  0.414376  0.300502  0.554819  0.497524 2  0.142878  0.406830  0.314240  0.093132 3  0.337368  0.851783  0.933441  0.949598  >>> df.drop('b', axis=1)            a         c         d 0  0.175127  0.382122  0.869242 1  0.414376  0.554819  0.497524 2  0.142878  0.314240  0.093132 3  0.337368  0.933441  0.949598   Note that by default, .drop() does not operate inplace; despite the ominous name, df is unharmed by this process. If you want to permanently remove b from df, do df.drop('b', inplace=True).  df.drop() also accepts a list of labels, e.g. df.drop(['a', 'b'], axis=1) will drop column a and b.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas",
        "A_Votes": "99",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dataframe look like this:  import pandas import numpy as np df = DataFrame(np.random.rand(4,4), columns = list('abcd')) df       a         b         c         d 0  0.418762  0.042369  0.869203  0.972314 1  0.991058  0.510228  0.594784  0.534366 2  0.407472  0.259811  0.396664  0.894202 3  0.726168  0.139531  0.324932  0.906575   How I can get all columns except column b?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to select all columns, except one column in pandas?",
        "A_Content": "  df[df.columns.difference(['b'])]  Out:            a         c         d 0  0.427809  0.459807  0.333869 1  0.678031  0.668346  0.645951 2  0.996573  0.673730  0.314911 3  0.786942  0.719665  0.330833      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dataframe look like this:  import pandas import numpy as np df = DataFrame(np.random.rand(4,4), columns = list('abcd')) df       a         b         c         d 0  0.418762  0.042369  0.869203  0.972314 1  0.991058  0.510228  0.594784  0.534366 2  0.407472  0.259811  0.396664  0.894202 3  0.726168  0.139531  0.324932  0.906575   How I can get all columns except column b?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to select all columns, except one column in pandas?",
        "A_Content": "  Here is another way:  df[[i for i in list(df.columns) if i != '<your column>']]   You just pass all columns to be shown except of the one you do not want.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dataframe look like this:  import pandas import numpy as np df = DataFrame(np.random.rand(4,4), columns = list('abcd')) df       a         b         c         d 0  0.418762  0.042369  0.869203  0.972314 1  0.991058  0.510228  0.594784  0.534366 2  0.407472  0.259811  0.396664  0.894202 3  0.726168  0.139531  0.324932  0.906575   How I can get all columns except column b?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to select all columns, except one column in pandas?",
        "A_Content": "  I think the best way to do is the way mentioned by @Salvador Dali. Not that the others are wrong.   Because when you have a data set where you just want to select one column and put it into one variable and the rest of the columns into another for comparison or computational purposes. Then dropping the column of the data set might not help. Of course there are use cases for that as well.   x_cols = [x for x in data.columns if x != 'name of column to be excluded']   Then you can put those collection of columns in variable x_cols into another variable like x_cols1 for other computation.  ex: x_cols1 = data[x_cols]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dataframe look like this:  import pandas import numpy as np df = DataFrame(np.random.rand(4,4), columns = list('abcd')) df       a         b         c         d 0  0.418762  0.042369  0.869203  0.972314 1  0.991058  0.510228  0.594784  0.534366 2  0.407472  0.259811  0.396664  0.894202 3  0.726168  0.139531  0.324932  0.906575   How I can get all columns except column b?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  The file is being read as a bunch of strs, but it should be unicodes. Python tries to implicitly convert, but fails. Change:  job_titles = [line.strip() for line in title_file.readlines()]   to explicitly decode the strs to unicode (here assuming UTF-8):  job_titles = [line.decode('utf-8').strip() for line in title_file.readlines()]   It could also be solved by importing the codecs module and using codecs.open rather than the built-in open.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  You can try this also:  import sys reload(sys) sys.setdefaultencoding('utf8')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  This works fine for me.  f = open(file_path, 'r+', encoding=\"utf-8\")   You can add a third parameter encoding to ensure the encoding type is 'utf-8'  Note: this method works fine in Python3, I did not try it in Python2.7.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  For me there was a problem with the terminal encoding. Adding UTF-8 to .bashrc solved the problem:  export LC_CTYPE=en_US.UTF-8   Don't forget to reload .bashrc afterwards:  source ~/.bashrc      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  You can try this before using job_titles string:  source = unicode(job_titles, 'utf-8')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  For python 3, the default encoding would be \"utf-8\". Following steps are suggested in the base documentation:https://docs.python.org/2/library/csv.html#csv-examples in case of any problem    Create a function  def utf_8_encoder(unicode_csv_data):     for line in unicode_csv_data:         yield line.encode('utf-8')  Then use the function inside the reader, for e.g.  csv_reader = csv.reader(utf_8_encoder(unicode_csv_data))       ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)",
        "A_Content": "  To find ANY and ALL unicode error related... Using the following command:  grep -r -P '[^\\x00-\\x7f]' /etc/apache2 /etc/letsencrypt /etc/nginx   Found mine in  /etc/letsencrypt/options-ssl-nginx.conf:        # The following CSP directives don't use default-src as    Using shed, I found the offending sequence.  It turned out to be an editor mistake.  00008099:     C2  194 302 11000010 00008100:     A0  160 240 10100000 00008101:  d  64  100 144 01100100 00008102:  e  65  101 145 01100101 00008103:  f  66  102 146 01100110 00008104:  a  61  097 141 01100001 00008105:  u  75  117 165 01110101 00008106:  l  6C  108 154 01101100 00008107:  t  74  116 164 01110100 00008108:  -  2D  045 055 00101101 00008109:  s  73  115 163 01110011 00008110:  r  72  114 162 01110010 00008111:  c  63  099 143 01100011 00008112:     C2  194 302 11000010 00008113:     A0  160 240 10100000      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/18649512/unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-13-ordinal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using NLTK to perform kmeans clustering on my text file in which each line is considered as a document. So for example, my text file is something like this:  belong finger death punch  hasty  mike hasty walls jericho  jägermeister rules  rules bands follow performing jägermeister stage  approach   Now the demo code I'm trying to run is this: https://gist.github.com/xim/1279283  The error I receive is this:  Traceback (most recent call last): File \"cluster_example.py\", line 40, in words = get_words(job_titles) File \"cluster_example.py\", line 20, in get_words words.add(normalize_word(word)) File \"\", line 1, in File \"/usr/local/lib/python2.7/dist-packages/nltk/decorators.py\", line 183, in memoize result = func(*args) File \"cluster_example.py\", line 14, in normalize_word return stemmer_func(word.lower()) File \"/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.py\", line 694, in stem word = (word.replace(u\"\\u2019\", u\"\\x27\") UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 13: ordinal not in range(128)   What is happening here?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to filter rows in pandas by regex",
        "A_Content": "  Use contains instead:  In [10]: df.b.str.contains('^f') Out[10]:  0    False 1     True 2     True 3    False Name: b, dtype: bool      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to cleanly filter a dataframe using regex on one of the columns.  For a contrived example:  In [210]: foo = pd.DataFrame({'a' : [1,2,3,4], 'b' : ['hi', 'foo', 'fat', 'cat']}) In [211]: foo Out[211]:     a    b 0  1   hi 1  2  foo 2  3  fat 3  4  cat   I want to filter the rows to those that start with f using a regex. First go:  In [213]: foo.b.str.match('f.*') Out[213]:  0    [] 1    () 2    () 3    []   That's not too terribly useful. However this will get me my boolean index:  In [226]: foo.b.str.match('(f.*)').str.len() > 0 Out[226]:  0    False 1     True 2     True 3    False Name: b   So I could then do my restriction by:  In [229]: foo[foo.b.str.match('(f.*)').str.len() > 0] Out[229]:     a    b 1  2  foo 2  3  fat   That makes me artificially put a group into the regex though, and seems like maybe not the clean way to go. Is there a better way to do this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to filter rows in pandas by regex",
        "A_Content": "  Multiple column search with dataframe:  frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\\test\\test.txt')]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to cleanly filter a dataframe using regex on one of the columns.  For a contrived example:  In [210]: foo = pd.DataFrame({'a' : [1,2,3,4], 'b' : ['hi', 'foo', 'fat', 'cat']}) In [211]: foo Out[211]:     a    b 0  1   hi 1  2  foo 2  3  fat 3  4  cat   I want to filter the rows to those that start with f using a regex. First go:  In [213]: foo.b.str.match('f.*') Out[213]:  0    [] 1    () 2    () 3    []   That's not too terribly useful. However this will get me my boolean index:  In [226]: foo.b.str.match('(f.*)').str.len() > 0 Out[226]:  0    False 1     True 2     True 3    False Name: b   So I could then do my restriction by:  In [229]: foo[foo.b.str.match('(f.*)').str.len() > 0] Out[229]:     a    b 1  2  foo 2  3  fat   That makes me artificially put a group into the regex though, and seems like maybe not the clean way to go. Is there a better way to do this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to filter rows in pandas by regex",
        "A_Content": "  This may be a bit late, but this is now easier to do in Pandas. You can call match with as_indexer=True to get boolean results. This is documented (along with the difference between match and contains) here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to cleanly filter a dataframe using regex on one of the columns.  For a contrived example:  In [210]: foo = pd.DataFrame({'a' : [1,2,3,4], 'b' : ['hi', 'foo', 'fat', 'cat']}) In [211]: foo Out[211]:     a    b 0  1   hi 1  2  foo 2  3  fat 3  4  cat   I want to filter the rows to those that start with f using a regex. First go:  In [213]: foo.b.str.match('f.*') Out[213]:  0    [] 1    () 2    () 3    []   That's not too terribly useful. However this will get me my boolean index:  In [226]: foo.b.str.match('(f.*)').str.len() > 0 Out[226]:  0    False 1     True 2     True 3    False Name: b   So I could then do my restriction by:  In [229]: foo[foo.b.str.match('(f.*)').str.len() > 0] Out[229]:     a    b 1  2  foo 2  3  fat   That makes me artificially put a group into the regex though, and seems like maybe not the clean way to go. Is there a better way to do this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to filter rows in pandas by regex",
        "A_Content": "  There is already a string handling function Series.str.startwith().   You should try foo[foo.b.str.startswith('f')].   Result:   a   b 1   2   foo 2   3   fat   I think what you expect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to cleanly filter a dataframe using regex on one of the columns.  For a contrived example:  In [210]: foo = pd.DataFrame({'a' : [1,2,3,4], 'b' : ['hi', 'foo', 'fat', 'cat']}) In [211]: foo Out[211]:     a    b 0  1   hi 1  2  foo 2  3  fat 3  4  cat   I want to filter the rows to those that start with f using a regex. First go:  In [213]: foo.b.str.match('f.*') Out[213]:  0    [] 1    () 2    () 3    []   That's not too terribly useful. However this will get me my boolean index:  In [226]: foo.b.str.match('(f.*)').str.len() > 0 Out[226]:  0    False 1     True 2     True 3    False Name: b   So I could then do my restriction by:  In [229]: foo[foo.b.str.match('(f.*)').str.len() > 0] Out[229]:     a    b 1  2  foo 2  3  fat   That makes me artificially put a group into the regex though, and seems like maybe not the clean way to go. Is there a better way to do this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to filter rows in pandas by regex",
        "A_Content": "  Write a Boolean function that checks the regex and use apply on the column  foo[foo['b'].apply(regex_function)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to cleanly filter a dataframe using regex on one of the columns.  For a contrived example:  In [210]: foo = pd.DataFrame({'a' : [1,2,3,4], 'b' : ['hi', 'foo', 'fat', 'cat']}) In [211]: foo Out[211]:     a    b 0  1   hi 1  2  foo 2  3  fat 3  4  cat   I want to filter the rows to those that start with f using a regex. First go:  In [213]: foo.b.str.match('f.*') Out[213]:  0    [] 1    () 2    () 3    []   That's not too terribly useful. However this will get me my boolean index:  In [226]: foo.b.str.match('(f.*)').str.len() > 0 Out[226]:  0    False 1     True 2     True 3    False Name: b   So I could then do my restriction by:  In [229]: foo[foo.b.str.match('(f.*)').str.len() > 0] Out[229]:     a    b 1  2  foo 2  3  fat   That makes me artificially put a group into the regex though, and seems like maybe not the clean way to go. Is there a better way to do this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  '%f' % (x/y)   but you need to manage precision yourself. e.g.,  '%f' % (1/10**8)   will display zeros only. details are in the docs  Or for Python 3 the equivalent old formatting or the newer style formatting     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  With newer versions of Python (2.6 and later), you can use ''.format() to accomplish what @SilentGhost suggested:  '{0:f}'.format(x/y)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  Using the newer version ''.format (also remember to specify how many digit after the . you wish to display, this depends on how small is the floating number). See this example:  >>> a = -7.1855143557448603e-17 >>> '{:f}'.format(a) '-0.000000'   as shown above, default is 6 digits! This is not helpful for our case example, so instead we could use something like this:  >>> '{:.20f}'.format(a) '-0.00000000000000007186'   Update  Starting in Python 3.6, this can be simplified with the new formatted string literal, as follows:  >>> f'{a:.20f}' '-0.00000000000000007186'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  This will work for any exponent:  def getExpandedScientificNotation(flt):     str_vals = str(flt).split('e')     coef = float(str_vals[0])     exp = int(str_vals[1])     return_val = ''     if int(exp) > 0:         return_val += str(coef).replace('.', '')         return_val += ''.join(['0' for _ in range(0, abs(exp - len(str(coef).split('.')[1])))])     elif int(exp) < 0:         return_val += '0.'         return_val += ''.join(['0' for _ in range(0, abs(exp) - 1)])         return_val += str(coef).replace('.', '')     return return_val      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  This is using Captain Cucumber's answer, but with 2 additions.  1) allowing the function to get non scientific notation numbers and just return them as is (so you can throw a lot of input that some of the numbers are 0.00003123 vs  3.123e-05 and still have function work.  2) added support for negative numbers. (in original function,  a negative number would end up like 0.0000-108904 from -1.08904e-05)  def getExpandedScientificNotation(flt):     was_neg = False     if not (\"e\" in flt):         return flt     if flt.startswith('-'):         flt = flt[1:]         was_neg = True      str_vals = str(flt).split('e')     coef = float(str_vals[0])     exp = int(str_vals[1])     return_val = ''     if int(exp) > 0:         return_val += str(coef).replace('.', '')         return_val += ''.join(['0' for _ in range(0, abs(exp - len(str(coef).split('.')[1])))])     elif int(exp) < 0:         return_val += '0.'         return_val += ''.join(['0' for _ in range(0, abs(exp) - 1)])         return_val += str(coef).replace('.', '')     if was_neg:         return_val='-'+return_val     return return_val      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  In addition to SG's answer, you can also use the Decimal module:  from decimal import Decimal x = str(Decimal(1) / Decimal(10000))  # x is a string '0.0001'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  If it is a string then use the built in float on it to do the conversion for instance: print( \"%.5f\" % float(\"1.43572e-03\")) answer:0.00143572     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  Using 3.6.4, I was having a similar problem that randomly, a number in the output file would be formatted with scientific notation when using this:  fout.write('someFloats: {0:0.8},{1:0.8},{2:0.8}'.format(someFloat[0], someFloat[1], someFloat[2]))   All that I had to do to fix it was to add 'f':  fout.write('someFloats: {0:0.8f},{1:0.8f},{2:0.8f}'.format(someFloat[0], someFloat[1], someFloat[2]))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I suppress scientific notation in Python?",
        "A_Content": "  Since this is the top result on Google, I will post here after failing to find a solution for my problem. If you are looking to format the display value of a float object and have it remain a float - not a string, you can use this solution:  Create a new class that modifies the way that float values are displayed.  from builtins import float class FormattedFloat(float):      def __str__(self):         return \"{:.10f}\".format(self).rstrip('0')   You can modify the precision yourself by changing the integer values in {:f}     ",
        "Language": "Python",
        "Tags": [
            "python",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/658763/how-do-i-suppress-scientific-notation-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here's my code:  x = 1.0 y = 100000.0     print x/y   My quotient displays as 1.00000e-05  Is there any way to suppress scientific notation and make it display as 0.00001? How to convert the scientific notation into float.   Thanks in advance. This feels somewhat ridiculous to ask but I haven't figured out a way to do it yet.  I'm going to use the result as a string.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  Python does not add the current directory to sys.path, but rather the directory that the script is in. Add /home/bodacydo/work/project to either sys.path or $PYTHONPATH.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "93",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  Do you have a file called __init__.py in the foo directory?  If not then python won't recognise foo as a python package.  See the section on packages in the python tutorial for more information.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  Here is a step-by-step solution:   Add a script called run.py in /home/bodacydo/work/project and edit it like this:   import programs.my_python_program programs.my_python_program.main()    (replace main() with your equivalent method in my_python_program.) Go to /home/bodacydo/work/project Run run.py   Explanation: Since python appends to PYTHONPATH the path of the script from which it runs, running run.py will append /home/bodacydo/work/project. And voilà, import foo.tasks will be found.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  Example solution for adding the library to your PYTHONPATH.   Add the following line into your ~/.bashrc or just run it directly:  export PYTHONPATH=\"$PYTHONPATH:$HOME/.python\"  Then link your required library into your ~/.python folder, e.g.  ln -s /home/user/work/project/foo ~/.python/       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  In my mind I have to consider that the foo folder is a stand-alone library.  I might want to consider moving it to the Lib\\site-packages folder within a python installation.  I might want to consider adding a foo.pth file there.  I know it's a library since the ./programs/my_python_program.py contains the following line:     from foo.tasks import my_function   So it doesn't matter that ./programs is a sibling folder to ./foo. It's the fact that my_python_program.py is run as a script like this:       python ./programs/my_python_program.py      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to fix “ImportError: No module named …” error in Python?",
        "A_Content": "  A better fix than setting PYTHONPATH is to use python -m module.path  This will correctly set sys.path[0] and is a more reliable way to execute modules.  I have a quick writeup about this problem, as other answerers have mentioned  the reason for this is python path/to/file.py puts path/to on the beginning of the PYTHONPATH (sys.path).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2325923/how-to-fix-importerror-no-module-named-error-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the correct way to fix this ImportError error?  I have the following directory structure:  /home/bodacydo /home/bodacydo/work /home/bodacydo/work/project /home/bodacydo/work/project/programs /home/bodacydo/work/project/foo   And I am in the directory  /home/bodacydo/work/project   Now if I type  python ./programs/my_python_program.py   I instantly get  ImportError: No module named foo.tasks   The ./programs/my_python_program.py contains the following line:  from foo.tasks import my_function   I can't understand why python won't find ./foo/tasks.py - it's there.  If I do it from the Python shell, then it works:  python >>> from foo.tasks import my_function   It only doesn't work if I call it via python ./programs/my_python_program.py script.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  If you take a look at the sources for django.contrib.auth.views.password_reset you'll see that it uses RequestContext. The upshot is, you can use Context Processors to modify the context which may allow you to inject the information that you need.  The b-list has a good introduction to context processors.  Edit (I seem to have been confused about what the actual question was):  You'll notice that password_reset takes a named parameter called template_name:  def password_reset(request, is_admin_site=False,              template_name='registration/password_reset_form.html',             email_template_name='registration/password_reset_email.html',             password_reset_form=PasswordResetForm,              token_generator=default_token_generator,             post_reset_redirect=None):   Check password_reset for more information.  ... thus, with a urls.py like:  from django.conf.urls.defaults import * from django.contrib.auth.views import password_reset  urlpatterns = patterns('',      (r'^/accounts/password/reset/$', password_reset, {'template_name': 'my_templates/password_reset.html'}),      ... )   django.contrib.auth.views.password_reset will be called for URLs matching '/accounts/password/reset' with the keyword argument template_name = 'my_templates/password_reset.html'.  Otherwise, you don't need to provide any context as the password_reset view takes care of itself. If you want to see what context you have available, you can trigger a TemplateSyntax error and look through the stack trace find the frame with a local variable named context. If you want to modify the context then what I said above about context processors is probably the way to go.  In summary: what do you need to do to use your own template? Provide a template_name keyword argument to the view when it is called. You can supply keyword arguments to views by including a dictionary as the third member of a URL pattern tuple.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  Strongly recommend this article.  I just plugged it in and it worked  http://garmoncheg.blogspot.com.au/2012/07/django-resetting-passwords-with.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  You just need to wrap the existing functions and pass in the template you want. For example:  from django.contrib.auth.views import password_reset  def my_password_reset(request, template_name='path/to/my/template'):     return password_reset(request, template_name)   To see this just have a look at the function declartion of the built in views:  http://code.djangoproject.com/browser/django/trunk/django/contrib/auth/views.py#L74     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  You can do the following:   add to your urlpatterns (r'^/accounts/password/reset/$', password_reset) put your template in '/templates/registration/password_reset_form.html' make your app come before 'django.contrib.auth' in INSTALLED_APPS   Explanation:  When the templates are loaded, they are searched in your INSTALLED_APPS variable in settings.py . The order is dictated by the definition's rank in INSTALLED_APPS, so since your app come before 'django.contrib.auth' your template were loaded (reference: https://docs.djangoproject.com/en/dev/ref/templates/api/#django.template.loaders.app_directories.Loader).  Motivation of approach:   I want be more dry and don't repeat for any view(defined by django) the template name (they are already defined in django) I want a smallest url.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  The documentation says that there only one context variable, form.  If you're having trouble with login (which is common), the documentation says there are three context variables:   form: A Form object representing the login form. See the forms documentation for more on Form objects. next: The URL to redirect to after successful login. This may contain a query string, too. site_name: The name of the current Site, according to the SITE_ID setting.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  I was using this two lines in the url and the template from the admin what i was changing to my need  url(r'^change-password/$', 'django.contrib.auth.views.password_change', {     'template_name': 'password_change_form.html'}, name=\"password-change\"), url(r'^change-password-done/$', 'django.contrib.auth.views.password_change_done', {     'template_name': 'password_change_done.html'     }, name=\"password-change-done\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I use the built in password reset/change views with my own templates",
        "A_Content": "  Another, perhaps simpler, solution is to add your override template directory to the DIRS entry of the TEMPLATES setting in settings.py.  (I think this setting is new in Django 1.8.  It may have been called TEMPLATE_DIRS in previous Django versions.)  Like so:  TEMPLATES = [    {         'BACKEND': 'django.template.backends.django.DjangoTemplates',         # allow overriding templates from other installed apps                                                                                                         'DIRS': ['my_app/templates'],         'APP_DIRS': True, }]   Then put your override template files under my_app/templates.  So the overridden password reset template would be my_app/templates/registration/password_reset_form.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "passwords"
        ],
        "URL": "https://stackoverflow.com/questions/388800/how-do-i-use-the-built-in-password-reset-change-views-with-my-own-templates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.  I need to  know exactly what context to add for each of the password reset and change views.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  staticmethod objects apparently have a __func__ attribute storing the original raw function (makes sense that they had to). So this will work:  class Klass(object):      @staticmethod  # use as decorator     def stat_func():         return 42      _ANS = stat_func.__func__()  # call the staticmethod      def method(self):         ret = Klass.stat_func()         return ret     As an aside, though I suspected that a staticmethod object had some sort of attribute storing the original function, I had no idea of the specifics. In the spirit of teaching someone to fish rather than giving them a fish, this is what I did to investigate and find that out (literally a C&P from my Python session):  >>> class Foo(object):     @staticmethod     def foo():         return 3     global z     z = foo  >>> z <staticmethod object at 0x0000000002E40558> >>> Foo.foo <function foo at 0x0000000002E3CBA8> >>> dir(z) ['__class__', '__delattr__', '__doc__', '__format__', '__func__', '__get__', '__getattribute__', '__hash__', '__init__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] >>> z.__func__ <function foo at 0x0000000002E3CBA8>   Similar sorts of digging in an interactive session (dir is very helpful) can often solve these sorts of question very quickly.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "112",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  This is the way I prefer:  class Klass(object):      @staticmethod     def stat_func():         return 42      _ANS = stat_func.__func__()      def method(self):         return self.__class__.stat_func() + self.__class__._ANS   I prefer this solution to Klass.stat_func, because of the DRY principle. Reminds me of the reason why there is a new super() in Python 3 :)  But I agree with the others, usually the best choice is to define a module level function.  For instance with @staticmethod function, the recursion might not look very good (You would need to break DRY principle by calling Klass.stat_func inside Klass.stat_func). That's because you don't have reference to self inside static method. With module level function, everything will look OK.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  This is due to staticmethod being a descriptor and requires a class-level attribute fetch to exercise the descriptor protocol and get the true callable.  From the source code:     It can be called either on the class (e.g. C.f()) or on an instance   (e.g. C().f()); the instance is ignored except for its class.   But not directly from inside the class while it is being defined.   But as one commenter mentioned, this is not really a \"Pythonic\" design at all. Just use a module level function instead.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  What about this solution? It does not rely on knowledge of @staticmethod decorator implementation. Inner class StaticMethod plays as a container of static initialization functions.  class Klass(object):      class StaticMethod:         @staticmethod  # use as decorator         def _stat_func():             return 42      _ANS = StaticMethod._stat_func()  # call the staticmethod      def method(self):         ret = self.StaticMethod._stat_func() + Klass._ANS         return ret      ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  What about injecting the class attribute after the class definition?  class Klass(object):      @staticmethod  # use as decorator     def stat_func():         return 42      def method(self):         ret = Klass.stat_func()         return ret  Klass._ANS = Klass.stat_func()  # inject the class attribute with static method value      ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Calling class staticmethod within the class body?",
        "A_Content": "  According to the blog below, when calling a static method within a class, the caller function must be a class method, so adding @classmethod to your method definition may solve the problem.  The definitive guide on how to use static, class or abstract methods in Python     ",
        "Language": "Python",
        "Tags": [
            "python",
            "decorator",
            "static-methods"
        ],
        "URL": "https://stackoverflow.com/questions/12718187/calling-class-staticmethod-within-the-class-body",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempt to use a static method from within the body of the class, and define the static method using the built-in staticmethod function as a decorator, like this:  class Klass(object):      @staticmethod  # use as decorator     def _stat_func():         return 42      _ANS = _stat_func()  # call the staticmethod      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   I get the following error:  Traceback (most recent call last):<br>   File \"call_staticmethod.py\", line 1, in <module>     class Klass(object):    File \"call_staticmethod.py\", line 7, in Klass     _ANS = _stat_func()    TypeError: 'staticmethod' object is not callable   I understand why this is happening (descriptor binding), and can work around it by manually converting _stat_func() into a staticmethod after its last use, like so:  class Klass(object):      def _stat_func():         return 42      _ANS = _stat_func()  # use the non-staticmethod version      _stat_func = staticmethod(_stat_func)  # convert function to a static method      def method(self):         ret = Klass._stat_func() + Klass._ANS         return ret   So my question is:  Are there better, as in cleaner or more \"Pythonic\", ways to accomplish this?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "rreplace - How to replace the last occurrence of an expression in a string?",
        "A_Content": "  >>> def rreplace(s, old, new, occurrence): ...  li = s.rsplit(old, occurrence) ...  return new.join(li) ...  >>> s '1232425' >>> rreplace(s, '2', ' ', 2) '123 4 5' >>> rreplace(s, '2', ' ', 3) '1 3 4 5' >>> rreplace(s, '2', ' ', 4) '1 3 4 5' >>> rreplace(s, '2', ' ', 0) '1232425'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/2556108/rreplace-how-to-replace-the-last-occurrence-of-an-expression-in-a-string",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a quick way in Python to replace strings but, instead of starting from the beginning as replace does, starting from the end? For example:  >>> def rreplace(old, new, occurrence) >>>     ... # Code to replace the last occurrences of old by new  >>> '<div><div>Hello</div></div>'.rreplace('</div>','</bad>',1) >>> '<div><div>Hello</div></bad>'      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "rreplace - How to replace the last occurrence of an expression in a string?",
        "A_Content": "  I'm not going to pretend that this is the most efficient way of doing it, but it's a simple way. It reverses all the strings in question, performs an ordinary replacement using str.replace on the reversed strings, then reverses the result back the right way round:  >>> def rreplace(s, old, new, count): ...     return (s[::-1].replace(old[::-1], new[::-1], count))[::-1] ... >>> rreplace('<div><div>Hello</div></div>', '</div>', '</bad>', 1) '<div><div>Hello</div></bad>'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/2556108/rreplace-how-to-replace-the-last-occurrence-of-an-expression-in-a-string",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a quick way in Python to replace strings but, instead of starting from the beginning as replace does, starting from the end? For example:  >>> def rreplace(old, new, occurrence) >>>     ... # Code to replace the last occurrences of old by new  >>> '<div><div>Hello</div></div>'.rreplace('</div>','</bad>',1) >>> '<div><div>Hello</div></bad>'      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "rreplace - How to replace the last occurrence of an expression in a string?",
        "A_Content": "  If you know that the 'old' string does not contain any special characters you can do it with a regex:  In [44]: s = '<div><div>Hello</div></div>'  In [45]: import re  In [46]: re.sub(r'(.*)</div>', r'\\1</bad>', s) Out[46]: '<div><div>Hello</div></bad>'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/2556108/rreplace-how-to-replace-the-last-occurrence-of-an-expression-in-a-string",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a quick way in Python to replace strings but, instead of starting from the beginning as replace does, starting from the end? For example:  >>> def rreplace(old, new, occurrence) >>>     ... # Code to replace the last occurrences of old by new  >>> '<div><div>Hello</div></div>'.rreplace('</div>','</bad>',1) >>> '<div><div>Hello</div></bad>'      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "rreplace - How to replace the last occurrence of an expression in a string?",
        "A_Content": "  Here is a recursive solution to the problem:  def rreplace(s, old, new, occurence = 1):      if occurence == 0:         return s      left, found, right = s.rpartition(old)      if found == \"\":         return right     else:         return rreplace(left, old, new, occurence - 1) + new + right      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/2556108/rreplace-how-to-replace-the-last-occurrence-of-an-expression-in-a-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a quick way in Python to replace strings but, instead of starting from the beginning as replace does, starting from the end? For example:  >>> def rreplace(old, new, occurrence) >>>     ... # Code to replace the last occurrences of old by new  >>> '<div><div>Hello</div></div>'.rreplace('</div>','</bad>',1) >>> '<div><div>Hello</div></bad>'      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  I normally would use a generator function. Each time you use a yield statement, it will add an item to the sequence.  The following will create an iterator that returns five, and then every item in some_list.  def __iter__(self):    yield 5    for x in some_list:       yield x      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  Another option is to inherit from the appropriate abstract base class from the `collections module as documented here.  In case the container is its own iterator, you can inherit from  collections.Iterator. You only need to implement the next method then.  An example is:  >>> from collections import Iterator >>> class MyContainer(Iterator): ...     def __init__(self, *data): ...         self.data = list(data) ...     def next(self): ...         if not self.data: ...             raise StopIteration ...         return self.data.pop() ...          ...      ...  >>> c = MyContainer(1, \"two\", 3, 4.0) >>> for i in c: ...     print i ...      ...  4.0 3 two 1   While you are looking at the collections module, consider inheriting from Sequence, Mapping or another abstract base class if that is more appropriate. Here is an example for a Sequence subclass:  >>> from collections import Sequence >>> class MyContainer(Sequence): ...     def __init__(self, *data): ...         self.data = list(data) ...     def __getitem__(self, index): ...         return self.data[index] ...     def __len__(self): ...         return len(self.data) ...          ...      ...  >>> c = MyContainer(1, \"two\", 3, 4.0) >>> for i in c: ...     print i ...      ...  1 two 3 4.0   NB: Thanks to Glenn Maynard for drawing my attention to the need to clarify the difference between iterators on the one hand and containers that are iterables rather than iterators on the other.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  usually __iter__() just return self if you have already define the next() method (generator object):  here is a Dummy example of a generator :  class Test(object):      def __init__(self, data):        self.data = data      def next(self):         if not self.data:            raise StopIteration         return self.data.pop()      def __iter__(self):         return self   but __iter__() can also be used like this:     http://mail.python.org/pipermail/tutor/2006-January/044455.html     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  If your object contains a set of data you want to bind your object's iter to, you can cheat and do this:  >>> class foo:     def __init__(self, *params):            self.data = params     def __iter__(self):         if hasattr(self.data[0], \"__iter__\"):             return self.data[0].__iter__()         return self.data.__iter__() >>> d=foo(6,7,3,8, \"ads\", 6) >>> for i in d:     print i 6 7 3 8 ads 6      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  To answer the question about mappings: your provided __iter__ should iterate over the keys of the mapping. The following is a simple example that creates a mapping x -> x * x and works on Python3 extending the ABC mapping.  import collections.abc  class MyMap(collections.abc.Mapping):     def __init__(self, n):         self.n = n      def __getitem__(self, key): # given a key, return it's value         if 0 <= key < self.n:             return key * key         else:             raise KeyError('Invalid key')      def __iter__(self): # iterate over all keys         for x in range(self.n):             yield x      def __len__(self):         return self.n  m = MyMap(5) for k, v in m.items():     print(k, '->', v) # 0 -> 0 # 1 -> 1 # 2 -> 4 # 3 -> 9 # 4 -> 16      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  In case you don't want to inherit from dict as others have suggested, here is direct answer to the question on how to implement __iter__ for a crude example of a custom dict:  class Attribute:     def __init__(self, key, value):         self.key = key         self.value = value  class Node(collections.Mapping):     def __init__(self):         self.type  = \"\"         self.attrs = [] # List of Attributes      def __iter__(self):         for attr in self.attrs:             yield attr.key   That uses a generator, which is well described here.  Since we're inheriting from Mapping, you need to also implement __getitem__ and __len__:      def __getitem__(self, key):         for attr in self.attrs:             if key == attr.key:                 return attr.value         raise KeyError      def __len__(self):         return len(self.attrs)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  The \"iterable interface\" in python consists of two methods __next__() and __iter__(). The __next__ function is the most important, as it defines the iterator behavior - that is, the function determines what value should be returned next. The __iter__() method is used to reset the starting point of the iteration. Often, you will find that  __iter__() can just return self when __init__() is used to set the starting point.  See the following code for defining a Class Reverse which implements the \"iterable interface\" and defines an iterator over any instance from any sequence class. The __next__() method starts at the end of the sequence and returns values in reverse order of the sequence. Note that instances from a class implementing the \"sequence interface\" must define a __len__() and a __getitem__() method.   class Reverse:     \"\"\"Iterator for looping over a sequence backwards.\"\"\"     def __init__(self, seq):         self.data = seq         self.index = len(seq)      def __iter__(self):         return self      def __next__(self):         if self.index == 0:             raise StopIteration         self.index = self.index - 1         return self.data[self.index]  >>> rev = Reverse('spam') >>> next(rev)   # note no need to call iter() 'm' >>> nums = Reverse(range(1,10)) >>> next(nums) 9      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  One option that might work for some cases is to make your custom class inherit from dict. This seems like a logical choice if it acts like a dict; maybe it should be a dict. This way, you get dict-like iteration for free.  class MyDict(dict):     def __init__(self, custom_attribute):         self.bar = custom_attribute  mydict = MyDict('Some name') mydict['a'] = 1 mydict['b'] = 2  print mydict.bar for k, v in mydict.items():     print k, '=>', v   Output:  Some name a => 1 b => 2      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to implement __iter__(self) for a container object (Python)",
        "A_Content": "  example for inhert from dict, modify its iter, for example, skip key 2 when in for loop  # method 1 class Dict(dict):     def __iter__(self):         keys = self.keys()         for i in keys:             if i == 2:                 continue             yield i  # method 2 class Dict(dict):     def __iter__(self):         for i in super(Dict, self).__iter__():             if i == 2:                 continue             yield i      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/4019971/how-to-implement-iter-self-for-a-container-object-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have written a custom container object.  According to this page, I need to implement this method on my object:  __iter__(self)   However, upon following up the link to Iterator Types in the Python reference manual, there are no examples given of how to implement your own.  Can someone post a snippet (or link to a resource), that shows how to do this?  The container I am writing, is a map (i.e. stores values by unique keys). dicts can be iterated like this:  for k, v in mydict.items()   In this case I need to be able to return two elements (a tuple?) in the iterator.  It is still not clear how to implement such an iterator (despite the several answers that have been kindly provided). Could someone please shed some more light on how to implement an iterator for a map-like container object? (i.e. a custom class that acts like a dict)?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What are the comprehensive lint checkers for Python? [closed]",
        "A_Content": "  There are several lint-type programs for Python:   pyflakes - parses, great for finding NameErrors, obsolete imports pylint - parses, very comprehensive (on the excessive-compulsive side). pep8 - parses, a style checker. flake8 - parser, combines pep8 and pyflakes, with added complexity support, extensible. pychecker - executes (be careful)   All have helped me find small issues and have their pros and cons.  There is also a lot of discussion here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "lint"
        ],
        "URL": "https://stackoverflow.com/questions/5611776/what-are-the-comprehensive-lint-checkers-for-python",
        "A_Votes": "134",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hear that there are several tools that let you check the code for common Python mistakes, like pylint and pyflakes. I'm looking for one that is comprehensive, correct and simple to integrate into a build (setup.py preferably or buildbot if good reasons).  Which one do you recommend and why ?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What are the comprehensive lint checkers for Python? [closed]",
        "A_Content": "  This question is too broad so I will just list my tool chain FWIW.  Editing  emacs + python-mode + flymake + ropemacs.   flymake runs a process as you are editing a file, the process can be anything. I have flymake configured to fire off pyflakes and pep8. So I get indications in the file of pep8 violations, syntax errors, unused imports, variables declared but not used, etc...  rope is handy for jumping around declarations and a little bit of auto complete. It will also show you the docs and function signatures, etc...  I'm sure there's similar stuff for vim. And though my one colleague has not managed to get it running, I've been told wingide can use pyflakes and pep8.  Testing  nose + various plugins. In my emacs I bind F7(compile) to run nose, that way I get a buffer where I can jump to the errors and then jump to that line in the source code.  version control  I use mercurial.  dependencies  buildout or virtualenv or both. Depending on the project. Use what's best for your project. I put up with buildout because I develop for appengine right now, and I prefer the recipes in buildout for the appengine application structure to the appengine monkey approach, but that's just me.  If I weren't developing for appengine I would probably stick with virtualenv.  continuous integration  jenkins is the easiest I have ever setup. basically it runs the same testsuite that I use on my compile command but also generates a coverage report.  I think being aware of what's out there and being able to morph it all to your needs of the project you are working on is better than looking for a \"best of breed\" solution, mainly because the best of breed solution just doesn't exist.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "lint"
        ],
        "URL": "https://stackoverflow.com/questions/5611776/what-are-the-comprehensive-lint-checkers-for-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hear that there are several tools that let you check the code for common Python mistakes, like pylint and pyflakes. I'm looking for one that is comprehensive, correct and simple to integrate into a build (setup.py preferably or buildbot if good reasons).  Which one do you recommend and why ?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python group by",
        "A_Content": "  Do it in 2 steps. First, create a dictionary.  >>> input = [('11013331', 'KAT'), ('9085267', 'NOT'), ('5238761', 'ETH'), ('5349618', 'ETH'), ('11788544', 'NOT'), ('962142', 'ETH'), ('7795297', 'ETH'), ('7341464', 'ETH'), ('9843236', 'KAT'), ('5594916', 'ETH'), ('1550003', 'ETH')] >>> from collections import defaultdict >>> res = defaultdict(list) >>> for v, k in input: res[k].append(v) ...   Then, convert that dictionary into the expected format.  >>> [{'type':k, 'items':v} for k,v in res.items()] [{'items': ['9085267', '11788544'], 'type': 'NOT'}, {'items': ['5238761', '5349618', '962142', '7795297', '7341464', '5594916', '1550003'], 'type': 'ETH'}, {'items': ['11013331', '9843236'], 'type': 'KAT'}]     It is also possible with itertools.groupby but it requires the input to be sorted first.  >>> sorted_input = sorted(input, key=itemgetter(1)) >>> groups = groupby(sorted_input, key=itemgetter(1)) >>> [{'type':k, 'items':[x[0] for x in v]} for k, v in groups] [{'items': ['5238761', '5349618', '962142', '7795297', '7341464', '5594916', '1550003'], 'type': 'ETH'}, {'items': ['11013331', '9843236'], 'type': 'KAT'}, {'items': ['9085267', '11788544'], 'type': 'NOT'}]     Note both of these do not respect the original order of the keys. You need an OrderedDict if you need to keep the order.  >>> from collections import OrderedDict >>> res = OrderedDict() >>> for v, k in input: ...   if k in res: res[k].append(v) ...   else: res[k] = [v] ...  >>> [{'type':k, 'items':v} for k,v in res.items()] [{'items': ['11013331', '9843236'], 'type': 'KAT'}, {'items': ['9085267', '11788544'], 'type': 'NOT'}, {'items': ['5238761', '5349618', '962142', '7795297', '7341464', '5594916', '1550003'], 'type': 'ETH'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "group-by"
        ],
        "URL": "https://stackoverflow.com/questions/3749512/python-group-by",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Assume that I have a such set of pair datas where index 0 is the value and the index 1 is the type:  input = [           ('11013331', 'KAT'),            ('9085267',  'NOT'),            ('5238761',  'ETH'),            ('5349618',  'ETH'),            ('11788544', 'NOT'),            ('962142',   'ETH'),            ('7795297',  'ETH'),            ('7341464',  'ETH'),            ('9843236',  'KAT'),            ('5594916',  'ETH'),            ('1550003',  'ETH')         ]   I want to group them by their type(by the 1st indexed string) as such:  result = [             {               type:'KAT',               items: ['11013331', '9843236']             },            {              type:'NOT',               items: ['9085267', '11788544']             },            {              type:'ETH',               items: ['5238761', '962142', '7795297', '7341464', '5594916', '1550003']             }          ]    How can I achieve this in an efficient way?  Thanks     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python group by",
        "A_Content": "  Python's built-in itertools module actually has a groupby function , but for that the elements to be grouped must first be sorted such that the elements to be grouped are contiguous in the list:  from operator import itemgetter sortkeyfn = itemgetter(1) input = [('11013331', 'KAT'), ('9085267', 'NOT'), ('5238761', 'ETH'),   ('5349618', 'ETH'), ('11788544', 'NOT'), ('962142', 'ETH'), ('7795297', 'ETH'),   ('7341464', 'ETH'), ('9843236', 'KAT'), ('5594916', 'ETH'), ('1550003', 'ETH')]  input.sort(key=sortkeyfn)   Now input looks like:  [('5238761', 'ETH'), ('5349618', 'ETH'), ('962142', 'ETH'), ('7795297', 'ETH'),  ('7341464', 'ETH'), ('5594916', 'ETH'), ('1550003', 'ETH'), ('11013331', 'KAT'),  ('9843236', 'KAT'), ('9085267', 'NOT'), ('11788544', 'NOT')]   groupby returns a sequence of 2-tuples, of the form (key, values_iterator).  What we want is to turn this into a list of dicts where the 'type' is the key, and 'items' is a list of the 0'th elements of the tuples returned by the values_iterator.  Like this:  from itertools import groupby result = [] for key,valuesiter in groupby(input, key=sortkeyfn):     result.append(dict(type=key, items=list(v[0] for v in valuesiter)))   Now result contains your desired dict, as stated in your question.  You might consider, though, just making a single dict out of this, keyed by type, and each value containing the list of values.  In your current form, to find the values for a particular type, you'll have to iterate over the list to find the dict containing the matching 'type' key, and then get the 'items' element from it.  If you use a single dict instead of a list of 1-item dicts, you can find the items for a particular type with a single keyed lookup into the master dict.  Using groupby, this would look like:  result = {} for key,valuesiter in groupby(input, key=sortkeyfn):     result[key] = list(v[0] for v in valuesiter)   result now contains this dict (this is similar to the intermediate res defaultdict in @KennyTM's answer):  {'NOT': ['9085267', '11788544'],   'ETH': ['5238761', '5349618', '962142', '7795297', '7341464', '5594916', '1550003'],   'KAT': ['11013331', '9843236']}   (If you want to reduce this to a one-liner, you can:  result = dict((key,list(v[0] for v in valuesiter)               for key,valuesiter in groupby(input, key=sortkeyfn))   or using the newfangled dict-comprehension form:  result = {key:list(v[0] for v in valuesiter)               for key,valuesiter in groupby(input, key=sortkeyfn)}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "group-by"
        ],
        "URL": "https://stackoverflow.com/questions/3749512/python-group-by",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume that I have a such set of pair datas where index 0 is the value and the index 1 is the type:  input = [           ('11013331', 'KAT'),            ('9085267',  'NOT'),            ('5238761',  'ETH'),            ('5349618',  'ETH'),            ('11788544', 'NOT'),            ('962142',   'ETH'),            ('7795297',  'ETH'),            ('7341464',  'ETH'),            ('9843236',  'KAT'),            ('5594916',  'ETH'),            ('1550003',  'ETH')         ]   I want to group them by their type(by the 1st indexed string) as such:  result = [             {               type:'KAT',               items: ['11013331', '9843236']             },            {              type:'NOT',               items: ['9085267', '11788544']             },            {              type:'ETH',               items: ['5238761', '962142', '7795297', '7341464', '5594916', '1550003']             }          ]    How can I achieve this in an efficient way?  Thanks     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python group by",
        "A_Content": "  The following function will quickly (no sorting required) group tuples of any length by a key having any index:  # given a sequence of tuples like [(3,'c',6),(7,'a',2),(88,'c',4),(45,'a',0)], # returns a dict grouping tuples by idx-th element - with idx=1 we have: # if merge is True {'c':(3,6,88,4),     'a':(7,2,45,0)} # if merge is False {'c':((3,6),(88,4)), 'a':((7,2),(45,0))} def group_by(seqs,idx=0,merge=True):     d = dict()     for seq in seqs:         k = seq[idx]         v = d.get(k,tuple()) + (seq[:idx]+seq[idx+1:] if merge else (seq[:idx]+seq[idx+1:],))         d.update({k:v})     return d   In the case of your question, the index of key you want to group by is 1, therefore:  group_by(input,1)   gives  {'ETH': ('5238761','5349618','962142','7795297','7341464','5594916','1550003'),  'KAT': ('11013331', '9843236'),  'NOT': ('9085267', '11788544')}   which is not exactly the output you asked for, but might as well suit your needs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "group-by"
        ],
        "URL": "https://stackoverflow.com/questions/3749512/python-group-by",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume that I have a such set of pair datas where index 0 is the value and the index 1 is the type:  input = [           ('11013331', 'KAT'),            ('9085267',  'NOT'),            ('5238761',  'ETH'),            ('5349618',  'ETH'),            ('11788544', 'NOT'),            ('962142',   'ETH'),            ('7795297',  'ETH'),            ('7341464',  'ETH'),            ('9843236',  'KAT'),            ('5594916',  'ETH'),            ('1550003',  'ETH')         ]   I want to group them by their type(by the 1st indexed string) as such:  result = [             {               type:'KAT',               items: ['11013331', '9843236']             },            {              type:'NOT',               items: ['9085267', '11788544']             },            {              type:'ETH',               items: ['5238761', '962142', '7795297', '7341464', '5594916', '1550003']             }          ]    How can I achieve this in an efficient way?  Thanks     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python group by",
        "A_Content": "  I also liked pandas simple grouping. it's powerful, simple and most adequate for large data set  result = pandas.DataFrame(input).groupby(1).groups     ",
        "Language": "Python",
        "Tags": [
            "python",
            "group-by"
        ],
        "URL": "https://stackoverflow.com/questions/3749512/python-group-by",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume that I have a such set of pair datas where index 0 is the value and the index 1 is the type:  input = [           ('11013331', 'KAT'),            ('9085267',  'NOT'),            ('5238761',  'ETH'),            ('5349618',  'ETH'),            ('11788544', 'NOT'),            ('962142',   'ETH'),            ('7795297',  'ETH'),            ('7341464',  'ETH'),            ('9843236',  'KAT'),            ('5594916',  'ETH'),            ('1550003',  'ETH')         ]   I want to group them by their type(by the 1st indexed string) as such:  result = [             {               type:'KAT',               items: ['11013331', '9843236']             },            {              type:'NOT',               items: ['9085267', '11788544']             },            {              type:'ETH',               items: ['5238761', '962142', '7795297', '7341464', '5594916', '1550003']             }          ]    How can I achieve this in an efficient way?  Thanks     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python group by",
        "A_Content": "  result = [] # Make a set of your \"types\": input_set = set([tpl[1] for tpl in input]) >>> set(['ETH', 'KAT', 'NOT']) # Iterate over the input_set for type_ in input_set:     # a dict to gather things:     D = {}     # filter all tuples from your input with the same type as type_     tuples = filter(lambda tpl: tpl[1] == type_, input)     # write them in the D:     D[\"type\"] = type_     D[\"itmes\"] = [tpl[0] for tpl in tuples]     # append D to results:     result.append(D)  result >>> [{'itmes': ['9085267', '11788544'], 'type': 'NOT'}, {'itmes': ['5238761', '5349618', '962142', '7795297', '7341464', '5594916', '1550003'], 'type': 'ETH'}, {'itmes': ['11013331', '9843236'], 'type': 'KAT'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "group-by"
        ],
        "URL": "https://stackoverflow.com/questions/3749512/python-group-by",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume that I have a such set of pair datas where index 0 is the value and the index 1 is the type:  input = [           ('11013331', 'KAT'),            ('9085267',  'NOT'),            ('5238761',  'ETH'),            ('5349618',  'ETH'),            ('11788544', 'NOT'),            ('962142',   'ETH'),            ('7795297',  'ETH'),            ('7341464',  'ETH'),            ('9843236',  'KAT'),            ('5594916',  'ETH'),            ('1550003',  'ETH')         ]   I want to group them by their type(by the 1st indexed string) as such:  result = [             {               type:'KAT',               items: ['11013331', '9843236']             },            {              type:'NOT',               items: ['9085267', '11788544']             },            {              type:'ETH',               items: ['5238761', '962142', '7795297', '7341464', '5594916', '1550003']             }          ]    How can I achieve this in an efficient way?  Thanks     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Importing from builtin library when module with same name exists",
        "A_Content": "  Actually, solving this is rather easy, but the implementation will always be a bit fragile, because it depends python import mechanism's internals and they are subject to change in future versions.  (the following code shows how to load both local and non-local modules and how they may coexist)  def import_non_local(name, custom_name=None):     import imp, sys      custom_name = custom_name or name      f, pathname, desc = imp.find_module(name, sys.path[1:])     module = imp.load_module(custom_name, f, pathname, desc)     f.close()      return module  # Import non-local module, use a custom name to differentiate it from local # This name is only used internally for identifying the module. We decide # the name in the local scope by assigning it to the variable calendar. calendar = import_non_local('calendar','std_calendar')  # import local module normally, as calendar_local import calendar as calendar_local  print calendar.Calendar print calendar_local   The best solution, if possible, is to avoid naming your modules with the same name as standard-library or built-in module names.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/6031584/importing-from-builtin-library-when-module-with-same-name-exists",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Situation: - There is a module in my project_folder called calendar - I would like to use the built-in Calendar class from the Python libraries - When I use from calendar import Calendar it complains because it's trying to load from my module.  I've done a few searches and I can't seem to find a solution to my problem.   How to access a standard-library module in Python when there is a local module with the same name? http://docs.python.org/whatsnew/2.5.html How to avoid writing the name of the module all the time when importing a module in python?   Any ideas without having to rename my module?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Importing from builtin library when module with same name exists",
        "A_Content": "  Changing the name of your module is not necessary. Rather, you can use absolute_import to change the importing behavior. For example with stem/socket.py I import the socket module as follows:  from __future__ import absolute_import import socket   This only works with Python 2.5 and above; it's enabling behavior that is the default in Python 3.0 and higher. Pylint will complain about the code but it's perfectly valid.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/6031584/importing-from-builtin-library-when-module-with-same-name-exists",
        "A_Votes": "121",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Situation: - There is a module in my project_folder called calendar - I would like to use the built-in Calendar class from the Python libraries - When I use from calendar import Calendar it complains because it's trying to load from my module.  I've done a few searches and I can't seem to find a solution to my problem.   How to access a standard-library module in Python when there is a local module with the same name? http://docs.python.org/whatsnew/2.5.html How to avoid writing the name of the module all the time when importing a module in python?   Any ideas without having to rename my module?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Importing from builtin library when module with same name exists",
        "A_Content": "  The only way to solve this problem is to hijack the internal import machinery yourself. This is not easy, and fraught with peril. You should avoid the grail shaped beacon at all costs because the peril is too perilous.  Rename your module instead.  If you want to learn how to hijack the internal import machinery, here is where you would go about finding out how to do this:   The Importing Modules section of the Python 2.7 documentation The Importing Modules section of the Python 3.2 documentation PEP 302 - New Import Hooks   There are sometimes good reasons to get into this peril. The reason you give is not among them. Rename your module.  If you take the perilous path, one problem you will encounter is that when you load a module it ends up with an 'official name' so that Python can avoid ever having to parse the contents of that module ever again. A mapping of the 'official name' of a module to the module object itself can be found in sys.modules.  This means that if you import calendar in one place, whatever module is imported will be thought of as the module with the official name calendar and all other attempts to import calendar anywhere else, including in other code that's part of the main Python library, will get that calendar.  It might be possible to design a customer importer using the imputil module in Python 2.x that caused modules loaded from certain paths to look up the modules they were importing in something other than sys.modules first or something like that. But that's an extremely hairy thing to be doing, and it won't work in Python 3.x anyway.  There is an extremely ugly and horrible thing you can do that does not involve hooking the import mechanism. This is something you should probably not do, but it will likely work. It turns your calendar module into a hybrid of the system calendar module and your calendar module. Thanks to Boaz Yaniv for the skeleton of the function I use. Put this at the beginning of your calendar.py file:  import sys  def copy_in_standard_module_symbols(name, local_module):     import imp      for i in range(0, 100):         random_name = 'random_name_%d' % (i,)         if random_name not in sys.modules:             break         else:             random_name = None     if random_name is None:         raise RuntimeError(\"Couldn't manufacture an unused module name.\")     f, pathname, desc = imp.find_module(name, sys.path[1:])     module = imp.load_module(random_name, f, pathname, desc)     f.close()     del sys.modules[random_name]     for key in module.__dict__:         if not hasattr(local_module, key):             setattr(local_module, key, getattr(module, key))  copy_in_standard_module_symbols('calendar', sys.modules[copy_in_standard_module_symbols.__module__])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/6031584/importing-from-builtin-library-when-module-with-same-name-exists",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Situation: - There is a module in my project_folder called calendar - I would like to use the built-in Calendar class from the Python libraries - When I use from calendar import Calendar it complains because it's trying to load from my module.  I've done a few searches and I can't seem to find a solution to my problem.   How to access a standard-library module in Python when there is a local module with the same name? http://docs.python.org/whatsnew/2.5.html How to avoid writing the name of the module all the time when importing a module in python?   Any ideas without having to rename my module?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Importing from builtin library when module with same name exists",
        "A_Content": "  I'd like to offer my version, which is a combination of Boaz Yaniv's and Omnifarious's solution. It will import the system version of a module, with two main differences from the previous answers:   Supports the 'dot' notation, eg. package.module Is a drop-in replacement for the import statement on system modules, meaning you just have to replace that one line and if there are already calls being made to the module they will work as-is   Put this somewhere accessible so you can call it (I have mine in my __init__.py file):  class SysModule(object):     pass  def import_non_local(name, local_module=None, path=None, full_name=None, accessor=SysModule()):     import imp, sys, os      path = path or sys.path[1:]     if isinstance(path, basestring):         path = [path]      if '.' in name:         package_name = name.split('.')[0]         f, pathname, desc = imp.find_module(package_name, path)         if pathname not in __path__:             __path__.insert(0, pathname)         imp.load_module(package_name, f, pathname, desc)         v = import_non_local('.'.join(name.split('.')[1:]), None, pathname, name, SysModule())         setattr(accessor, package_name, v)         if local_module:             for key in accessor.__dict__.keys():                 setattr(local_module, key, getattr(accessor, key))         return accessor     try:         f, pathname, desc = imp.find_module(name, path)         if pathname not in __path__:             __path__.insert(0, pathname)         module = imp.load_module(name, f, pathname, desc)         setattr(accessor, name, module)         if local_module:             for key in accessor.__dict__.keys():                 setattr(local_module, key, getattr(accessor, key))             return module         return accessor     finally:         try:             if f:                 f.close()         except:             pass   Example  I wanted to import mysql.connection, but I had a local package already called mysql (the official mysql utilities). So to get the connector from the system mysql package, I replaced this:  import mysql.connector   With this:  import sys from mysql.utilities import import_non_local         # where I put the above function (mysql/utilities/__init__.py) import_non_local('mysql.connector', sys.modules[__name__])   Result  # This unmodified line further down in the file now works just fine because mysql.connector has actually become part of the namespace self.db_conn = mysql.connector.connect(**parameters)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/6031584/importing-from-builtin-library-when-module-with-same-name-exists",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Situation: - There is a module in my project_folder called calendar - I would like to use the built-in Calendar class from the Python libraries - When I use from calendar import Calendar it complains because it's trying to load from my module.  I've done a few searches and I can't seem to find a solution to my problem.   How to access a standard-library module in Python when there is a local module with the same name? http://docs.python.org/whatsnew/2.5.html How to avoid writing the name of the module all the time when importing a module in python?   Any ideas without having to rename my module?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Importing from builtin library when module with same name exists",
        "A_Content": "  Change the import path:  import sys save_path = sys.path[:] sys.path.remove('') import calendar sys.path = save_path      ",
        "Language": "Python",
        "Tags": [
            "python",
            "import"
        ],
        "URL": "https://stackoverflow.com/questions/6031584/importing-from-builtin-library-when-module-with-same-name-exists",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Situation: - There is a module in my project_folder called calendar - I would like to use the built-in Calendar class from the Python libraries - When I use from calendar import Calendar it complains because it's trying to load from my module.  I've done a few searches and I can't seem to find a solution to my problem.   How to access a standard-library module in Python when there is a local module with the same name? http://docs.python.org/whatsnew/2.5.html How to avoid writing the name of the module all the time when importing a module in python?   Any ideas without having to rename my module?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  You are looking for continue.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "243",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  for i in iterator:     try:         # Do something.         pass     except:         # Continue to next iteration.         continue      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  Something like this?  for i in xrange( someBigNumber ):     try:         doSomethingThatMightFail()     except SomeException, e:         continue     doSomethingWhenNothingFailed()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  I think you're looking for continue     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  Example for Continue:  number = 0  for number in range(10):    number = number + 1     if number == 5:       continue    # continue here     print('Number is ' + str(number))  print('Out of loop')   Output:  Number is 1 Number is 2 Number is 3 Number is 4 Number is 6 # Note: 5 is skipped!! Number is 7 Number is 8 Number is 9 Number is 10 Out of loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Skipping Iterations in Python",
        "A_Content": "  For this specific use-case using try..except..else is the cleanest solution, the else clause will be executed if no exception was raised.   NOTE: The else clause must follow all except clauses  for i in iterator:     try:         # Do something.     except:         # Handle exception     else:         # Continue doing something      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iteration",
            "skip"
        ],
        "URL": "https://stackoverflow.com/questions/549674/skipping-iterations-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a loop going, but there is the possibility for exceptions to be raised inside the loop. This of course would stop my program all together. To prevent that I catch the exceptions and handle them. But then the rest of the iteration runs even though an exception occurred. Is there a keyword to use in my except: clause to just skip the rest of the current iteration?     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  Install lxml from http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml for your python version. It's a precompiled WHL with required modules/dependencies.   The site lists several packages, when e.g. using Win32 Python 2.7, use lxml-3.6.1-cp27-cp27m-win32.whl.  Download the file, and then install with   pip install C:\\path\\to\\downloaded\\file\\lxml-3.6.1-cp27-cp27m-win32.whl      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "92",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  I had this issue and realised that whilst I did have libxml2 installed, I didn't have the necessary development libraries required by the python package. Installing them solved the problem:  sudo apt-get install libxml2-dev libxslt1-dev sudo pip install lxml      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "139",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  Try to use: easy_install lxml That works for me, win10, python 2.7.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  On Mac OS X El Capitan I had to run these two commands to fix this error:  xcode-select --install pip install lxml   Which ended up installing lxml-3.5.0  When you run the xcode-select command you may have to sign a EULA (so have an X-Term handy for the UI if you're doing this on a headless machine).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  In case anyone else has the same issue as this on      Centos, try:   yum install python-lxml      Ubuntu   sudo apt-get install -y python-lxml   worked for me.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  set STATICBUILD=true && pip install lxml   run this command instead, must have VS C++ compiler installed first  https://blogs.msdn.microsoft.com/pythonengineering/2016/04/11/unable-to-find-vcvarsall-bat/  It works for me with Python 3.5.2 and Windows 7     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Getting “Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?” when installing lxml through pip",
        "A_Content": "  I tried install a lib that depends lxml and nothing works. I see a message when build was started: \"Building without Cython\", so after install cython with apt-get install cython, lxml was installed.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/33785755/getting-could-not-find-function-xmlcheckversion-in-library-libxml2-is-libxml2",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting an error Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed? when trying to install lxml through pip.    c:\\users\\f\\appdata\\local\\temp\\xmlXPathInitqjzysz.c(1) : fatal error C1083: Cannot open include file: 'libxml/xpath.h': No such file or directory   *********************************************************************************   Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?   *********************************************************************************   error: command 'C:\\\\Users\\\\f\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\cl.exe' failed with exit status 2   I don't find any libxml2 dev packages to install via pip.  Using Python 2.7.10 on x86 in a virtualenv under Windows 10.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do I find the length (or dimensions, size) of a numpy matrix in python? [duplicate]",
        "A_Content": "  shape is a property of both numpy ndarray's and matrices.  A.shape   will return a tuple (m, n), where m is the number of rows, and n is the number of columns.  In fact, the numpy matrix object is built on top of the ndarray object, one of numpy's two fundamental objects (along with a universal function object), so it inherits from ndarray     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matrix",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14847457/how-do-i-find-the-length-or-dimensions-size-of-a-numpy-matrix-in-python",
        "A_Votes": "177",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Numpy array dimensions                                        6 answers                                          For a numpy matrix in python  from numpy import matrix A = matrix([[1,2],[3,4]])   How can I find the length of a row (or column) of this matrix? Equivalently, how can I know the number of rows or columns?  So far, the only solution I've found is:  len(A) len(A[:,1]) len(A[1,:])   Which returns 2, 2, and 1, respectively. From this I've gathered that len() will return the number of rows, so I can always us the transpose, len(A.T), for the number of columns. However, this feels unsatisfying and arbitrary, as when reading the line len(A), it isn't immediately obvious that this should return the number of rows. It actually works differently than len([1,2]) would for a 2D python array, as this would return 2.  So, is there a more intuitive way to find the size of a matrix, or is this the best I have?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I find the length (or dimensions, size) of a numpy matrix in python? [duplicate]",
        "A_Content": "  matrix.size according to the numpy docs returns the Number of elements in the array. Hope that helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matrix",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14847457/how-do-i-find-the-length-or-dimensions-size-of-a-numpy-matrix-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Numpy array dimensions                                        6 answers                                          For a numpy matrix in python  from numpy import matrix A = matrix([[1,2],[3,4]])   How can I find the length of a row (or column) of this matrix? Equivalently, how can I know the number of rows or columns?  So far, the only solution I've found is:  len(A) len(A[:,1]) len(A[1,:])   Which returns 2, 2, and 1, respectively. From this I've gathered that len() will return the number of rows, so I can always us the transpose, len(A.T), for the number of columns. However, this feels unsatisfying and arbitrary, as when reading the line len(A), it isn't immediately obvious that this should return the number of rows. It actually works differently than len([1,2]) would for a 2D python array, as this would return 2.  So, is there a more intuitive way to find the size of a matrix, or is this the best I have?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  Middleware may be your best bet.  I've used this piece of code in the past, modified from a snippet found elsewhere:  import re  from django.conf import settings from django.contrib.auth.decorators import login_required   class RequireLoginMiddleware(object):     \"\"\"     Middleware component that wraps the login_required decorator around     matching URL patterns. To use, add the class to MIDDLEWARE_CLASSES and     define LOGIN_REQUIRED_URLS and LOGIN_REQUIRED_URLS_EXCEPTIONS in your     settings.py. For example:     ------     LOGIN_REQUIRED_URLS = (         r'/topsecret/(.*)$',     )     LOGIN_REQUIRED_URLS_EXCEPTIONS = (         r'/topsecret/login(.*)$',         r'/topsecret/logout(.*)$',     )     ------     LOGIN_REQUIRED_URLS is where you define URL patterns; each pattern must     be a valid regex.      LOGIN_REQUIRED_URLS_EXCEPTIONS is, conversely, where you explicitly     define any exceptions (like login and logout URLs).     \"\"\"     def __init__(self):         self.required = tuple(re.compile(url) for url in settings.LOGIN_REQUIRED_URLS)         self.exceptions = tuple(re.compile(url) for url in settings.LOGIN_REQUIRED_URLS_EXCEPTIONS)      def process_view(self, request, view_func, view_args, view_kwargs):         # No need to process URLs if user already logged in         if request.user.is_authenticated():             return None          # An exception match should immediately return None         for url in self.exceptions:             if url.match(request.path):                 return None          # Requests matching a restricted URL pattern are returned         # wrapped with the login_required decorator         for url in self.required:             if url.match(request.path):                 return login_required(view_func)(request, *view_args, **view_kwargs)          # Explicitly return None for all non-matching requests         return None   Then in settings.py, list the base URLs you want to protect:  LOGIN_REQUIRED_URLS = (     r'/private_stuff/(.*)$',     r'/login_required/(.*)$', )   As long as your site follows URL conventions for the pages requiring authentication, this model will work.  If this isn't a one-to-one fit, you may choose to modify the middleware to suit your circumstances more closely.  What I like about this approach - besides removing the necessity of littering the codebase with @login_required decorators - is that if the authentication scheme changes, you have one place to go to make global changes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "93",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  There is an alternative to putting a decorator on each view function. You can also put the login_required() decorator in the urls.py file. While this is still a manual task, at least you have it all in one place, which makes it easier to audit.  e.g.,       from my_views import home_view      urlpatterns = patterns('',         # \"Home\":         (r'^$', login_required(home_view), dict(template_name='my_site/home.html', items_per_page=20)),     )   Note that view functions are named and imported directly, not as strings.  Also note that this works with any callable view object, including classes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  It's hard to change the built-in assumptions in Django without reworking the way url's are handed off to view functions.  Instead of mucking about in Django internals, here's an audit you can use.  Simply check each view function.  import os import re  def view_modules( root ):     for path, dirs, files in os.walk( root ):         for d in dirs[:]:             if d.startswith(\".\"):                 dirs.remove(d)         for f in files:             name, ext = os.path.splitext(f)             if ext == \".py\":                 if name == \"views\":                     yield os.path.join( path, f )  def def_lines( root ):     def_pat= re.compile( \"\\n(\\S.*)\\n+(^def\\s+.*:$)\", re.MULTILINE )     for v in view_modules( root ):         with open(v,\"r\") as source:             text= source.read()             for p in def_pat.findall( text ):                 yield p  def report( root ):     for decorator, definition in def_lines( root ):         print decorator, definition   Run this and examine the output for defs without appropriate decorators.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  Inspired by Ber's answer I wrote a little snippet that replaces the patterns function, by wrapping all of the URL callbacks with the login_required decorator. This works in Django 1.6.  def login_required_patterns(*args, **kw):     for pattern in patterns(*args, **kw):         # This is a property that should return a callable, even if a string view name is given.         callback = pattern.callback          # No property setter is provided, so this will have to do.         pattern._callback = login_required(callback)          yield pattern   Using it works like this (the call to list is required because of the yield).  urlpatterns = list(login_required_patterns('', url(r'^$', home_view)))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  Here is a middleware solution for django 1.10+  The middlewares in have to be written in a new way in django 1.10+.  Code  import re  from django.conf import settings from django.contrib.auth.decorators import login_required   class RequireLoginMiddleware(object):      def __init__(self, get_response):          # One-time configuration and initialization.         self.get_response = get_response          self.required = tuple(re.compile(url)                               for url in settings.LOGIN_REQUIRED_URLS)         self.exceptions = tuple(re.compile(url)                                 for url in settings.LOGIN_REQUIRED_URLS_EXCEPTIONS)      def __call__(self, request):          response = self.get_response(request)         return response      def process_view(self, request, view_func, view_args, view_kwargs):          # No need to process URLs if user already logged in         if request.user.is_authenticated:             return None          # An exception match should immediately return None         for url in self.exceptions:             if url.match(request.path):                 return None          # Requests matching a restricted URL pattern are returned         # wrapped with the login_required decorator         for url in self.required:             if url.match(request.path):                 return login_required(view_func)(request, *view_args, **view_kwargs)          # Explicitly return None for all non-matching requests         return None   Installation   Copy the code into your project folder, and save as middleware.py Add to MIDDLEWARE  MIDDLEWARE = [     ...     '.middleware.RequireLoginMiddleware',  # Require login ] Add to your settings.py:   LOGIN_REQUIRED_URLS = (     r'(.*)', ) LOGIN_REQUIRED_URLS_EXCEPTIONS = (     r'/admin(.*)$', ) LOGIN_URL = '/admin'   Sources:   This answer by Daniel Naab Django Middleware tutorial by Max Goodridge Django Middleware Docs      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  You can't really win this.  You simply must make a declaration of the authorization requirements.   Where else would you put this declaration except right by the view function?  Consider replacing your view functions with callable objects.  class LoginViewFunction( object ):     def __call__( self, request, *args, **kw ):         p1 = self.login( request, *args, **kw )         if p1 is not None:             return p1         return self.view( request, *args, **kw )     def login( self, request )         if not request.user.is_authenticated():             return HttpResponseRedirect('/login/?next=%s' % request.path)     def view( self, request, *args, **kw ):         raise NotImplementedError   You then make your view functions subclasses of LoginViewFunction.  class MyRealView( LoginViewFunction ):     def view( self, request, *args, **kw ):         .... the real work ...  my_real_view = MyRealView()     It doesn't save any lines of code.  And it doesn't help the \"we forgot\" problem.  All you can do is examine the code to be sure that the view functions are objects.  Of the right class.  But even then, you'll never really know that every view function is correct without a unit test suite.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  Would be possible to have a single starting point for all the urls in a sort of include and that decorate it using this packages https://github.com/vorujack/decorate_url.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Best way to make Django's login_required the default",
        "A_Content": "  In Django 2.1, we can decorate all methods in a class with:  from django.contrib.auth.decorators import login_required from django.utils.decorators import method_decorator from django.views.generic import TemplateView  @method_decorator(login_required, name='dispatch') class ProtectedView(TemplateView):     template_name = 'secret.html'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/2164069/best-way-to-make-djangos-login-required-the-default",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a large Django app, the vast majority of which requires a login to access.  This means that all throughout our app we've sprinkled:  @login_required def view(...):   That's fine, and it works great as long as we remember to add it everywhere!  Sadly sometimes we forget, and the failure often isn't terribly evident.  If the only link to a view is on a @login_required page then you're not likely to notice that you can actually reach that view without logging in.  But the bad guys might notice, which is a problem.  My idea was to reverse the system.  Instead of having to type @login_required everywhere, instead I'd have something like:  @public def public_view(...):   Just for the public stuff.  I tried to implement this with some middleware and I couldn't seem to get it to work.  Everything I tried interacted badly with other middleware we're using, I think.  Next up I tried writing something to traverse the URL patterns to check that everything that's not @public was marked @login_required - at least then we'd get a quick error if we forgot something.  But then I couldn't figure out how to tell if @login_required had been applied to a view...  So, what's the right way to do this?  Thanks for the help!     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  I have a suspicion that this is related to the parser that BS will use to read the HTML.  They document is here, but if you're like me (on OSX) you might be stuck with something that requires a bit of work:  You'll notice that in the BS4 documentation page above, they point out that by default BS4 will use the Python built-in HTML parser.  Assuming you are in OSX, the Apple-bundled version of Python is 2.7.2 which is not lenient for character formatting.  I hit this same problem, so I upgraded my version of Python to work around it. Doing this in a virtualenv will minimize disruption to other projects.  If doing that sounds like a pain, you can switch over to the LXML parser:  pip install lxml   And then try:  soup = BeautifulSoup(html, \"lxml\")   Depending on your scenario, that might be good enough.  I found this annoying enough to warrant upgrading my version of Python.  Using virtualenv, you can migrate your packages fairly easily.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  For basic out of the box python with bs4 installed then you can process your xml with  soup = BeautifulSoup(html, \"html5lib\")   If however you want to use formatter='xml' then you need to   pip3 install lxml  soup = BeautifulSoup(html, features=\"xml\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  I preferred built in python html parser, no install no dependencies soup = BeautifulSoup(s,  \"html.parser\")     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  I am using Python 3.6 and I had the same original error in this post. After I ran the command:  python3 -m pip install lxml   it resolved my problem     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  I encountered the same issue. I found the reason is that I had a slightly-outdated python six package.  >>> import html5lib Traceback (most recent call last): File \"<stdin>\", line 1, in <module>   File \"/usr/local/lib/python2.7/site-packages/html5lib/__init__.py\", line 16, in <module>     from .html5parser import HTMLParser, parse, parseFragment   File \"/usr/local/lib/python2.7/site-packages/html5lib/html5parser.py\", line 2, in <module>     from six import with_metaclass, viewkeys, PY3 ImportError: cannot import name viewkeys   Upgrading your six package will solve the issue:  sudo pip install six=1.10.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  Parser library is not install on your machine or not found.   Try this command from cmd:  pip install lxml     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  Instead of using lxml use html.parser, you can use this piece of code:  soup = BeautifulSoup(html, 'html.parser')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  I resolved this error by upgrading my lxml distribution:  pip install -U lxml     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  Although BeautifulSoup supports the HTML parser by default If you want to use any other third-party Python parsers you need to install that external parser like(lxml).  soup_object= BeautifulSoup(markup,\"html.parser\") #Python HTML parser   But if you don't specified any parser as parameter  you will get an warning that no parser specified.  soup_object= BeautifulSoup(markup) #Warnning   To use any other external parser you need to install it and then need to specify it. like  pip install lxml  soup_object= BeautifulSoup(markup,'lxml') # C dependent parser    External parser have c and python dependency which may have some advantage and disadvantage.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
        "A_Content": "  In some references, use the second instead of the first:  soup_object= BeautifulSoup(markup,'html-parser') soup_object= BeautifulSoup(markup,'html.parser')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "beautifulsoup",
            "lxml"
        ],
        "URL": "https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    ... soup = BeautifulSoup(html, \"lxml\") File \"/Library/Python/2.7/site-packages/bs4/__init__.py\", line 152, in __init__ % \",\".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?   The above outputs on my Terminal. I am on Mac OS 10.7.x. I have Python 2.7.1, and followed this tutorial to get Beautiful Soup and lxml, which both installed successfully and work with a separate test file located here. In the Python script that causes this error, I have included this line:     from pageCrawler import comparePages And in the pageCrawler file I have included the following two lines:     from bs4 import BeautifulSoup     from urllib2 import urlopen  Any help in figuring out what the problem is and how it can be solved would much be appreciated.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Where does this come from: -*- coding: utf-8 -*-",
        "A_Content": "  This way of specifying the encoding of a Python file comes from PEP 0263 - Defining Python Source Code Encodings.  It is also recognized by GNU Emacs (see Python Language Reference, 2.1.4 Encoding declarations), though I don't know if it was the first program to use that syntax.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "text",
            "encoding",
            "emacs"
        ],
        "URL": "https://stackoverflow.com/questions/4872007/where-does-this-come-from-coding-utf-8",
        "A_Votes": "64",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Python recognizes the following as instruction which defines file's encoding:  # -*- coding: utf-8 -*-   I definitely saw this kind of instructions before (-*- var: value -*-). Where does it come from? What is the full specification, e.g. can the value include spaces, special symbols, newlines, even -*- itself?  My program will be writing plain text files and I'd like to include some metadata in them using this format.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Where does this come from: -*- coding: utf-8 -*-",
        "A_Content": "  This is so called file local variables, that are understood by Emacs and set correspondingly.  See corresponding section in Emacs manual - you can define them either in header or in footer of file     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "text",
            "encoding",
            "emacs"
        ],
        "URL": "https://stackoverflow.com/questions/4872007/where-does-this-come-from-coding-utf-8",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python recognizes the following as instruction which defines file's encoding:  # -*- coding: utf-8 -*-   I definitely saw this kind of instructions before (-*- var: value -*-). Where does it come from? What is the full specification, e.g. can the value include spaces, special symbols, newlines, even -*- itself?  My program will be writing plain text files and I'd like to include some metadata in them using this format.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Where does this come from: -*- coding: utf-8 -*-",
        "A_Content": "  In PyCharm, I'd leave it out. It turns off the UTF-8 indicator at the bottom with a warning that the encoding is hard-coded. Don't think you need the PyCharm comment mentioned above.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "text",
            "encoding",
            "emacs"
        ],
        "URL": "https://stackoverflow.com/questions/4872007/where-does-this-come-from-coding-utf-8",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python recognizes the following as instruction which defines file's encoding:  # -*- coding: utf-8 -*-   I definitely saw this kind of instructions before (-*- var: value -*-). Where does it come from? What is the full specification, e.g. can the value include spaces, special symbols, newlines, even -*- itself?  My program will be writing plain text files and I'd like to include some metadata in them using this format.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  I see many answers suggesting itertools.tee, but that's ignoring one crucial warning in the docs for it:     This itertool may require significant   auxiliary storage (depending on how   much temporary data needs to be   stored). In general, if one iterator   uses most or all of the data before   another iterator starts, it is faster   to use list() instead of tee().   Basically, tee is designed for those situation where two (or more) clones of one iterator, while \"getting out of sync\" with each other, don't do so by much -- rather, they say in the same \"vicinity\" (a few items behind or ahead of each other).  Not suitable for the OP's problem of \"redo from the start\".  L = list(DictReader(...)) on the other hand is perfectly suitable, as long as the list of dicts can fit comfortably in memory.  A new \"iterator from the start\" (very lightweight and low-overhead) can be made at any time with iter(L), and used in part or in whole without affecting new or existing ones; other access patterns are also easily available.  As several answers rightly remarked, in the specific case of csv you can also .seek(0) the underlying file object (a rather special case).  I'm not sure that's documented and guaranteed, though it does currently work;  it would probably be worth considering only for truly huge csv files, in which the list I recommmend as the general approach would have too large a memory footprint.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  If you have a csv file named 'blah.csv' That looks like  a,b,c,d 1,2,3,4 2,3,4,5 3,4,5,6   you know that you can open the file for reading, and create a DictReader with  blah = open('blah.csv', 'r') reader= csv.DictReader(blah)   Then, you will be able to get the next line with reader.next(), which should output  {'a':1,'b':2,'c':3,'d':4}   using it again will produce  {'a':2,'b':3,'c':4,'d':5}   However, at this point if you use blah.seek(0), the next time you call reader.next() you will get  {'a':1,'b':2,'c':3,'d':4}   again.  This seems to be the functionality you're looking for. I'm sure there are some tricks associated with this approach that I'm not aware of however. @Brian suggested simply creating another DictReader. This won't work if you're first reader is half way through reading the file, as your new reader will have unexpected keys and values from wherever you are in the file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  No. Python's iterator protocol is very simple, and only provides one single method (.next() or __next__()), and no method to reset an iterator in general.  The common pattern is to instead create a new iterator using the same procedure again.  If you want to \"save off\" an iterator so that you can go back to its beginning, you may also fork the iterator by using itertools.tee     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  There's a bug in using .seek(0) as advocated by Alex Martelli and Wilduck above, namely that the next call to .next() will give you a dictionary of your header row in the form of {key1:key1, key2:key2, ...}.  The work around is to follow file.seek(0) with a call to reader.next() to get rid of the header row.  So your code would look something like this:  f_in = open('myfile.csv','r') reader = csv.DictReader(f_in)  for record in reader:     if some_condition:         # reset reader to first row of data on 2nd line of file         f_in.seek(0)         reader.next()         continue     do_something(record)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  Yes, if you use numpy.nditer to build your iterator.    >>> lst = [1,2,3,4,5] >>> itr = numpy.nditer([lst]) >>> itr.next() 1 >>> itr.next() 2 >>> itr.finished False >>> itr.reset() >>> itr.next() 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  While there is no iterator reset, the \"itertools\" module from python 2.6 (and later) has some utilities that can help there. One of then is the \"tee\" which can make multiple copies of an iterator, and cache the results of the one running ahead, so that these results are used on the copies. I will seve your purposes:  >>> def printiter(n): ...   for i in xrange(n): ...     print \"iterating value %d\" % i ...     yield i  >>> from itertools import tee >>> a, b = tee(printiter(5), 2) >>> list(a) iterating value 0 iterating value 1 iterating value 2 iterating value 3 iterating value 4 [0, 1, 2, 3, 4] >>> list(b) [0, 1, 2, 3, 4]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  This is perhaps orthogonal to the original question, but one could wrap the iterator in a function that returns the iterator.  def get_iter():     return iterator   To reset  the iterator just call the function again.  This is of course trivial if the function when the said function takes no arguments.  In the case that the function requires some arguments, use functools.partial to create a closure that can be passed instead of the original iterator.  def get_iter(arg1, arg2):    return iterator from functools import partial iter_clos = partial(get_iter, a1, a2)   This seems to avoid the caching that tee (n copies) or list (1 copy) would need to do     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  For small files, you may consider using more_itertools.seekable - a third-party tool that offers resetting iterables.  Demo  import csv  import more_itertools as mit   filename = \"data/iris.csv\" with open(filename, \"r\") as f:     reader = csv.DictReader(f)     iterable = mit.seekable(reader)                    # 1     print(next(iterable))                              # 2     print(next(iterable))     print(next(iterable))      print(\"\\nReset iterable\\n--------------\")     iterable.seek(0)                                   # 3     print(next(iterable))     print(next(iterable))     print(next(iterable))   Output  {'Sepal width': '3.5', 'Petal width': '0.2', 'Petal length': '1.4', 'Sepal length': '5.1', 'Species': 'Iris-setosa'} {'Sepal width': '3', 'Petal width': '0.2', 'Petal length': '1.4', 'Sepal length': '4.9', 'Species': 'Iris-setosa'} {'Sepal width': '3.2', 'Petal width': '0.2', 'Petal length': '1.3', 'Sepal length': '4.7', 'Species': 'Iris-setosa'}  Reset iterable -------------- {'Sepal width': '3.5', 'Petal width': '0.2', 'Petal length': '1.4', 'Sepal length': '5.1', 'Species': 'Iris-setosa'} {'Sepal width': '3', 'Petal width': '0.2', 'Petal length': '1.4', 'Sepal length': '4.9', 'Species': 'Iris-setosa'} {'Sepal width': '3.2', 'Petal width': '0.2', 'Petal length': '1.3', 'Sepal length': '4.7', 'Species': 'Iris-setosa'}   Here a DictReader is wrapped in a seekable object (1) and advanced (2).  The seek() method is used to reset/rewind the iterator to the 0th position (3).  Note: memory consumption grows with iteration, so be wary applying this tool to  large files, as indicated in the docs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  Only if the underlying type provides a mechanism for doing so (e.g. fp.seek(0)).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  For DictReader:  f = open(filename, \"rb\") d = csv.DictReader(f, delimiter=\",\")  f.seek(0) d.__init__(f, delimiter=\",\")   For DictWriter:  f = open(filename, \"rb+\") d = csv.DictWriter(f, fieldnames=fields, delimiter=\",\")  f.seek(0) f.truncate(0) d.__init__(f, fieldnames=fields, delimiter=\",\") d.writeheader() f.flush()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  list(generator()) returns all remaining values for a generator and effectively resets it if it is not looped.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Can iterators be reset in Python?",
        "A_Content": "  Problem  I've had the same issue before. After analyzing my code, I realized that attempting to reset the iterator inside of loops slightly increases the time complexity and it also makes the code a bit ugly.  Solution  Open the file and save the rows to a variable in memory.  # initialize list of rows rows = []  # open the file and temporarily name it as 'my_file' with open('myfile.csv', 'rb') as my_file:      # set up the reader using the opened file     myfilereader = csv.DictReader(my_file)      # loop through each row of the reader     for row in myfilereader:         # add the row to the list of rows         rows.append(row)   Now you can loop through rows anywhere in your scope without dealing with an iterator.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "iterator",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3266180/can-iterators-be-reset-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Heatmap in matplotlib with pcolor?",
        "A_Content": "  This is late, but here is my python implementation of the flowingdata NBA heatmap.  updated:1/4/2014: thanks everyone  # -*- coding: utf-8 -*- # <nbformat>3.0</nbformat>  # ------------------------------------------------------------------------ # Filename   : heatmap.py # Date       : 2013-04-19 # Updated    : 2014-01-04 # Author     : @LotzJoe >> Joe Lotz # Description: My attempt at reproducing the FlowingData graphic in Python # Source     : http://flowingdata.com/2010/01/21/how-to-make-a-heatmap-a-quick-and-easy-solution/ # # Other Links: #     http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor # # ------------------------------------------------------------------------  import matplotlib.pyplot as plt import pandas as pd from urllib2 import urlopen import numpy as np %pylab inline  page = urlopen(\"http://datasets.flowingdata.com/ppg2008.csv\") nba = pd.read_csv(page, index_col=0)  # Normalize data columns nba_norm = (nba - nba.mean()) / (nba.max() - nba.min())  # Sort data according to Points, lowest to highest # This was just a design choice made by Yau # inplace=False (default) ->thanks SO user d1337 nba_sort = nba_norm.sort('PTS', ascending=True)  nba_sort['PTS'].head(10)  # Plot it out fig, ax = plt.subplots() heatmap = ax.pcolor(nba_sort, cmap=plt.cm.Blues, alpha=0.8)  # Format fig = plt.gcf() fig.set_size_inches(8, 11)  # turn off the frame ax.set_frame_on(False)  # put the major ticks at the middle of each cell ax.set_yticks(np.arange(nba_sort.shape[0]) + 0.5, minor=False) ax.set_xticks(np.arange(nba_sort.shape[1]) + 0.5, minor=False)  # want a more natural, table-like display ax.invert_yaxis() ax.xaxis.tick_top()  # Set the labels  # label source:https://en.wikipedia.org/wiki/Basketball_statistics labels = [     'Games', 'Minutes', 'Points', 'Field goals made', 'Field goal attempts', 'Field goal percentage', 'Free throws made', 'Free throws attempts', 'Free throws percentage',     'Three-pointers made', 'Three-point attempt', 'Three-point percentage', 'Offensive rebounds', 'Defensive rebounds', 'Total rebounds', 'Assists', 'Steals', 'Blocks', 'Turnover', 'Personal foul']  # note I could have used nba_sort.columns but made \"labels\" instead ax.set_xticklabels(labels, minor=False) ax.set_yticklabels(nba_sort.index, minor=False)  # rotate the plt.xticks(rotation=90)  ax.grid(False)  # Turn off all the ticks ax = plt.gca()  for t in ax.xaxis.get_major_ticks():     t.tick1On = False     t.tick2On = False for t in ax.yaxis.get_major_ticks():     t.tick1On = False     t.tick2On = False   The output looks like this:   There's an ipython notebook with all this code here. I've learned a lot from 'overflow so hopefully someone will find this useful.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "data-visualization",
            "heatmap"
        ],
        "URL": "https://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor",
        "A_Votes": "119",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'd like to make a heatmap like this (shown on FlowingData):   The source data is here, but random data and labels would be fine to use, i.e.  import numpy column_labels = list('ABCD') row_labels = list('WXYZ') data = numpy.random.rand(4,4)   Making the heatmap is easy enough in matplotlib:  from matplotlib import pyplot as plt heatmap = plt.pcolor(data)   And I even found a colormap arguments that look about right: heatmap = plt.pcolor(data, cmap=matplotlib.cm.Blues)  But beyond that, I can't figure out how to display labels for the columns and rows and display the data in the proper orientation (origin at the top left instead of bottom left).  Attempts to manipulate heatmap.axes (e.g. heatmap.axes.set_xticklabels = column_labels) have all failed. What am I missing here?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Heatmap in matplotlib with pcolor?",
        "A_Content": "  Main issue is that you first need to set the location of your x and y ticks. Also, it helps to use the more object-oriented interface to matplotlib. Namely, interact with the axes object directly.  import matplotlib.pyplot as plt import numpy as np column_labels = list('ABCD') row_labels = list('WXYZ') data = np.random.rand(4,4) fig, ax = plt.subplots() heatmap = ax.pcolor(data)  # put the major ticks at the middle of each cell, notice \"reverse\" use of dimension ax.set_yticks(np.arange(data.shape[0])+0.5, minor=False) ax.set_xticks(np.arange(data.shape[1])+0.5, minor=False)   ax.set_xticklabels(row_labels, minor=False) ax.set_yticklabels(column_labels, minor=False) plt.show()   Hope that helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "data-visualization",
            "heatmap"
        ],
        "URL": "https://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'd like to make a heatmap like this (shown on FlowingData):   The source data is here, but random data and labels would be fine to use, i.e.  import numpy column_labels = list('ABCD') row_labels = list('WXYZ') data = numpy.random.rand(4,4)   Making the heatmap is easy enough in matplotlib:  from matplotlib import pyplot as plt heatmap = plt.pcolor(data)   And I even found a colormap arguments that look about right: heatmap = plt.pcolor(data, cmap=matplotlib.cm.Blues)  But beyond that, I can't figure out how to display labels for the columns and rows and display the data in the proper orientation (origin at the top left instead of bottom left).  Attempts to manipulate heatmap.axes (e.g. heatmap.axes.set_xticklabels = column_labels) have all failed. What am I missing here?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Heatmap in matplotlib with pcolor?",
        "A_Content": "  The python seaborn module is based on matplotlib, and produces a very nice heatmap.  Below is an implementation with seaborn, designed for the ipython/jupyter notebook.  import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline # import the data directly into a pandas dataframe nba = pd.read_csv(\"http://datasets.flowingdata.com/ppg2008.csv\", index_col='Name  ') # remove index title nba.index.name = \"\" # normalize data columns nba_norm = (nba - nba.mean()) / (nba.max() - nba.min()) # relabel columns labels = ['Games', 'Minutes', 'Points', 'Field goals made', 'Field goal attempts', 'Field goal percentage', 'Free throws made',            'Free throws attempts', 'Free throws percentage','Three-pointers made', 'Three-point attempt', 'Three-point percentage',            'Offensive rebounds', 'Defensive rebounds', 'Total rebounds', 'Assists', 'Steals', 'Blocks', 'Turnover', 'Personal foul'] nba_norm.columns = labels # set appropriate font and dpi sns.set(font_scale=1.2) sns.set_style({\"savefig.dpi\": 100}) # plot it out ax = sns.heatmap(nba_norm, cmap=plt.cm.Blues, linewidths=.1) # set the x-axis labels on the top ax.xaxis.tick_top() # rotate the x-axis labels plt.xticks(rotation=90) # get figure (usually obtained via \"fig,ax=plt.subplots()\" with matplotlib) fig = ax.get_figure() # specify dimensions and save fig.set_size_inches(15, 20) fig.savefig(\"nba.png\")   The output looks like this:  I used the matplotlib Blues color map, but personally find the default colors quite beautiful. I used matplotlib to rotate the x-axis labels, as I couldn't find the seaborn syntax. As noted by grexor, it was necessary to specify the dimensions (fig.set_size_inches) by trial and error, which I found a bit frustrating.  As noted by Paul H, you can easily add the values to heat maps (annot=True), but in this case I didn't think it improved the figure. Several code snippets were taken from the excellent answer by joelotz.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "data-visualization",
            "heatmap"
        ],
        "URL": "https://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'd like to make a heatmap like this (shown on FlowingData):   The source data is here, but random data and labels would be fine to use, i.e.  import numpy column_labels = list('ABCD') row_labels = list('WXYZ') data = numpy.random.rand(4,4)   Making the heatmap is easy enough in matplotlib:  from matplotlib import pyplot as plt heatmap = plt.pcolor(data)   And I even found a colormap arguments that look about right: heatmap = plt.pcolor(data, cmap=matplotlib.cm.Blues)  But beyond that, I can't figure out how to display labels for the columns and rows and display the data in the proper orientation (origin at the top left instead of bottom left).  Attempts to manipulate heatmap.axes (e.g. heatmap.axes.set_xticklabels = column_labels) have all failed. What am I missing here?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Heatmap in matplotlib with pcolor?",
        "A_Content": "  Someone edited this question to remove the code I used, so I was forced to add it as an answer. Thanks to all who participated in answering this question! I think most of the other answers are better than this code, I'm just leaving this here for reference purposes.  With thanks to Paul H, and unutbu (who answered this question), I have some pretty nice-looking output:  import matplotlib.pyplot as plt import numpy as np column_labels = list('ABCD') row_labels = list('WXYZ') data = np.random.rand(4,4) fig, ax = plt.subplots() heatmap = ax.pcolor(data, cmap=plt.cm.Blues)  # put the major ticks at the middle of each cell ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False) ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)  # want a more natural, table-like display ax.invert_yaxis() ax.xaxis.tick_top()  ax.set_xticklabels(row_labels, minor=False) ax.set_yticklabels(column_labels, minor=False) plt.show()   And here's the output:       ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "data-visualization",
            "heatmap"
        ],
        "URL": "https://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'd like to make a heatmap like this (shown on FlowingData):   The source data is here, but random data and labels would be fine to use, i.e.  import numpy column_labels = list('ABCD') row_labels = list('WXYZ') data = numpy.random.rand(4,4)   Making the heatmap is easy enough in matplotlib:  from matplotlib import pyplot as plt heatmap = plt.pcolor(data)   And I even found a colormap arguments that look about right: heatmap = plt.pcolor(data, cmap=matplotlib.cm.Blues)  But beyond that, I can't figure out how to display labels for the columns and rows and display the data in the proper orientation (origin at the top left instead of bottom left).  Attempts to manipulate heatmap.axes (e.g. heatmap.axes.set_xticklabels = column_labels) have all failed. What am I missing here?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Union of 2 sets does not contain all items",
        "A_Content": "  Why the union() doesn't contain all items  The 1 and True are equivalent and considered to be duplicates.  Likewise the 0 and False are equivalent as well:  >>> 1 == True True >>> 0 == False True   Which equivalent value is used  When multiple equivalent values are encountered, sets keep the first one seen:  >>> {0, False} {0} >>> {False, 0} {False}   Ways to make the values be distinct  To get them to be treated as distinct, just store them in a (value, type) pair:  >>> set1 = {(1, int), (2, int), (3, int)} >>> set2 = {(True, bool), (False, bool)} >>> set1 | set2 {(3, <class 'int'>), (1, <class 'int'>), (2, <class 'int'>),  (True, <class 'bool'>), (False, <class 'bool'>)} >>> set1 & set2 set()   Another way to make the values distinct is to store them as strings:  >>> set1 = {'1', '2', '3'} >>> set2 = {'True', 'False'} >>> set1 | set2 {'2', '3', 'False', 'True', '1'} >>> set1 & set2 set()   Hope this clears up the mystery and shows the way forward :-)    Rescued from the comments:  This is the standard technique for breaking cross-type equivalence (i.e. 0.0 == 0, True == 1, and Decimal(8.5) == 8.5). The technique is used in Python 2.7's regular expression module to force unicode regexes to be cached distinctly from otherwise equivalent str regexes. The technique is also used in Python 3 for functools.lru_cache() when the typed parameter is true.  If the OP needs something other than the default equivalence relation, then some new relation needs to be defined. Depending the use case, that could be case-insensitivity for strings, normalization for unicode, visual appearance (things that look different are considered different), identity (no two distinct objects are considered equal), a value/type pair, or some other function that defines an equivalence relation. Given the OPs specific example, it would seem that he/she expected either distinction by type or visual distinction.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "set",
            "equivalence-classes"
        ],
        "URL": "https://stackoverflow.com/questions/44489658/union-of-2-sets-does-not-contain-all-items",
        "A_Votes": "112",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How come when I change the order of the two sets in the unions below, I get different results?  set1 = {1, 2, 3} set2 = {True, False}  print(set1 | set2) # {False, 1, 2, 3}  print(set2 | set1) #{False, True, 2, 3}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Union of 2 sets does not contain all items",
        "A_Content": "  In Python, False and 0 are considered equivalent, as are True and 1. Because True and 1 are considered the same value, only one of them can be present in a set a the same time. Which one depends on the order they are added to the set in. In the first line, set1 is used as the first set, so we get 1 in the resulting set. In the second set, True is in the first set, so True is included in the result.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "set",
            "equivalence-classes"
        ],
        "URL": "https://stackoverflow.com/questions/44489658/union-of-2-sets-does-not-contain-all-items",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How come when I change the order of the two sets in the unions below, I get different results?  set1 = {1, 2, 3} set2 = {True, False}  print(set1 | set2) # {False, 1, 2, 3}  print(set2 | set1) #{False, True, 2, 3}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Union of 2 sets does not contain all items",
        "A_Content": "  If you look at https://docs.python.org/3/library/stdtypes.html#boolean-values section 4.12.10. Boolean Values:     Boolean values are the two constant objects False and True. They are used to represent truth values (although other values can also be considered false or true). In numeric contexts (for example when used as the argument to an arithmetic operator), they behave like the integers 0 and 1, respectively.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "set",
            "equivalence-classes"
        ],
        "URL": "https://stackoverflow.com/questions/44489658/union-of-2-sets-does-not-contain-all-items",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How come when I change the order of the two sets in the unions below, I get different results?  set1 = {1, 2, 3} set2 = {True, False}  print(set1 | set2) # {False, 1, 2, 3}  print(set2 | set1) #{False, True, 2, 3}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Union of 2 sets does not contain all items",
        "A_Content": "  The comparison operator (==, !=) is defined for boolean True and False to match 1 and 0.  That's why, in the set union, when it checks whether True is in the new set already, it gets a truthy answer:  >>> True in {1} True >>> 1 in {True} True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "set",
            "equivalence-classes"
        ],
        "URL": "https://stackoverflow.com/questions/44489658/union-of-2-sets-does-not-contain-all-items",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How come when I change the order of the two sets in the unions below, I get different results?  set1 = {1, 2, 3} set2 = {True, False}  print(set1 | set2) # {False, 1, 2, 3}  print(set2 | set1) #{False, True, 2, 3}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What does the 'u' symbol mean in front of string values? [duplicate]",
        "A_Content": "  The 'u' in front of the string values means the string has been represented as unicode.  Letters before strings here are called \"String Encoding declarations\".  Unicode is a way to represent more characters than normal ascii can manage.  You can convert a string to unicode multiple ways:  >>> u'foo' u'foo' >>> unicode('foo') u'foo'   But the real reason is to represent something like this (translation here):  >>> val = u'Ознакомьтесь с документацией' >>> val u'\\u041e\\u0437\\u043d\\u0430\\u043a\\u043e\\u043c\\u044c\\u0442\\u0435\\u0441\\u044c \\u0441 \\u0434\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\\u0430\\u0446\\u0438\\u0435\\u0439' >>> print val Ознакомьтесь с документацией   For the most part, you shouldn't have any errors in treating them different than ascii strings in this code.  There are other symbols you will see, such as the \"raw\" symbol for telling a string not to interpret any special characters. This is extremely useful when doing regular expression in python.  >>> 'foo\\\"' 'foo\"' >>> r'foo\\\"' 'foo\\\\\"'   ASCII and Unicode strings can be logically equivalent:  >>> bird1 = unicode('unladen swallow') >>> bird2 = 'unladen swallow' >>> bird1 == bird2 True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/11279331/what-does-the-u-symbol-mean-in-front-of-string-values",
        "A_Votes": "137",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              What's the u prefix in a Python string?                                        7 answers                                          Yes in short i would like to know why am I seeing a u in front of my keys and values.  I am rendering a form. The form has  check-box for the particular label and one text field for the ip address. I am creating a dictionary with keys being the label which are hardcoded in the list_key and values for the dictionary are taken from the form input (list_value). The dictionary is created but it is preceded by u for some values. here is the sample output for the dictionary:  {u'1': {'broadcast': u'on', 'arp': '', 'webserver': '', 'ipaddr': u'', 'dns': ''}}   can someone please explain what I am doing wrong. I am not getting the error when i simulate similar method in pyscripter. Any suggestions to improve the code are welcome. Thank you  #!/usr/bin/env python  import webapp2 import itertools import cgi  form =\"\"\"     <form method=\"post\">     FIREWALL      <br><br>     <select name=\"profiles\">         <option value=\"1\">profile 1</option>         <option value=\"2\">profile 2</option>         <option value=\"3\">profile 3</option>     </select>     <br><br>     Check the box to implement the particular policy     <br><br>      <label> Allow Broadcast         <input type=\"checkbox\" name=\"broadcast\">     </label>     <br><br>      <label> Allow ARP         <input type=\"checkbox\" name=\"arp\">     </label><br><br>      <label> Allow Web traffic from external address to internal webserver         <input type=\"checkbox\" name=\"webserver\">     </label><br><br>      <label> Allow DNS         <input type=\"checkbox\" name=\"dns\">     </label><br><br>      <label> Block particular Internet Protocol  address         <input type=\"text\" name=\"ipaddr\">     </label><br><br>      <input type=\"submit\">        </form> \"\"\" dictionarymain={}  class MainHandler(webapp2.RequestHandler):       def get(self):         self.response.out.write(form)      def post(self):         # get the parameters from the form          profile = self.request.get('profiles')          broadcast = self.request.get('broadcast')         arp = self.request.get('arp')         webserver = self.request.get('webserver')         dns =self.request.get('dns')         ipaddr = self.request.get('ipaddr')           # Create a dictionary for the above parameters         list_value =[ broadcast , arp , webserver , dns, ipaddr ]         list_key =['broadcast' , 'arp' , 'webserver' , 'dns' , 'ipaddr' ]          #self.response.headers['Content-Type'] ='text/plain'         #self.response.out.write(profile)          # map two list to a dictionary using itertools         adict = dict(zip(list_key,list_value))         self.response.headers['Content-Type'] ='text/plain'         self.response.out.write(adict)          if profile not in dictionarymain:             dictionarymain[profile]= {}         dictionarymain[profile]= adict          #self.response.headers['Content-Type'] ='text/plain'         #self.response.out.write(dictionarymain)          def escape_html(s):             return cgi.escape(s, quote =True)    app = webapp2.WSGIApplication([('/', MainHandler)],                               debug=True)      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What does the 'u' symbol mean in front of string values? [duplicate]",
        "A_Content": "  This is a feature, not a bug.  See http://docs.python.org/howto/unicode.html, specifically the 'unicode type' section.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "google-app-engine"
        ],
        "URL": "https://stackoverflow.com/questions/11279331/what-does-the-u-symbol-mean-in-front-of-string-values",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              What's the u prefix in a Python string?                                        7 answers                                          Yes in short i would like to know why am I seeing a u in front of my keys and values.  I am rendering a form. The form has  check-box for the particular label and one text field for the ip address. I am creating a dictionary with keys being the label which are hardcoded in the list_key and values for the dictionary are taken from the form input (list_value). The dictionary is created but it is preceded by u for some values. here is the sample output for the dictionary:  {u'1': {'broadcast': u'on', 'arp': '', 'webserver': '', 'ipaddr': u'', 'dns': ''}}   can someone please explain what I am doing wrong. I am not getting the error when i simulate similar method in pyscripter. Any suggestions to improve the code are welcome. Thank you  #!/usr/bin/env python  import webapp2 import itertools import cgi  form =\"\"\"     <form method=\"post\">     FIREWALL      <br><br>     <select name=\"profiles\">         <option value=\"1\">profile 1</option>         <option value=\"2\">profile 2</option>         <option value=\"3\">profile 3</option>     </select>     <br><br>     Check the box to implement the particular policy     <br><br>      <label> Allow Broadcast         <input type=\"checkbox\" name=\"broadcast\">     </label>     <br><br>      <label> Allow ARP         <input type=\"checkbox\" name=\"arp\">     </label><br><br>      <label> Allow Web traffic from external address to internal webserver         <input type=\"checkbox\" name=\"webserver\">     </label><br><br>      <label> Allow DNS         <input type=\"checkbox\" name=\"dns\">     </label><br><br>      <label> Block particular Internet Protocol  address         <input type=\"text\" name=\"ipaddr\">     </label><br><br>      <input type=\"submit\">        </form> \"\"\" dictionarymain={}  class MainHandler(webapp2.RequestHandler):       def get(self):         self.response.out.write(form)      def post(self):         # get the parameters from the form          profile = self.request.get('profiles')          broadcast = self.request.get('broadcast')         arp = self.request.get('arp')         webserver = self.request.get('webserver')         dns =self.request.get('dns')         ipaddr = self.request.get('ipaddr')           # Create a dictionary for the above parameters         list_value =[ broadcast , arp , webserver , dns, ipaddr ]         list_key =['broadcast' , 'arp' , 'webserver' , 'dns' , 'ipaddr' ]          #self.response.headers['Content-Type'] ='text/plain'         #self.response.out.write(profile)          # map two list to a dictionary using itertools         adict = dict(zip(list_key,list_value))         self.response.headers['Content-Type'] ='text/plain'         self.response.out.write(adict)          if profile not in dictionarymain:             dictionarymain[profile]= {}         dictionarymain[profile]= adict          #self.response.headers['Content-Type'] ='text/plain'         #self.response.out.write(dictionarymain)          def escape_html(s):             return cgi.escape(s, quote =True)    app = webapp2.WSGIApplication([('/', MainHandler)],                               debug=True)      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  Personally I can't convince myself to litter my code with the markers. I've become pretty used to (and efficient) at using indent-folding. Together with my mapping of space bar (see below) to open/close folds and the zR and zM commands, I'm right at home. Perfect for Python!     nnoremap <space> za      vnoremap <space> zf      ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "97",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  I use this syntax file for Python. It sets the folding method to syntax and folds all classes and functions, but nothing else.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  Python is well suited for folding on indent, bit for writing my own code I use markers as they can crunch a document down the way you want it and can serve as a kind of a table of contents. I have this in my vimrc to flip between the two when I'm viewing someone elses code.   #Toggle fold methods \\fo let g:FoldMethod = 0 map <leader>fo :call ToggleFold()<cr> fun! ToggleFold()     if g:FoldMethod == 0         exe 'set foldmethod=indent'         let g:FoldMethod = 1     else         exe 'set foldmethod=marker'         let g:FoldMethod = 0     endif endfun #Add markers (trigger on class Foo line) nnoremap ,f2 ^wywO#<c-r>0 {{{2<esc> nnoremap ,f3 ^wywO#<c-r>0 {{{3<esc>  nnoremap ,f4 ^wywO#<c-r>0 {{{4<esc> nnoremap ,f1 ^wywO#<c-r>0 {{{1<esc>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  I think that indent folding is fine for python.  I'm making a multi-branched git repo for vim-config python/django IDE ideas.  Fork away!  http://github.com/skyl/vim-config-python-ide     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  I really like the python_ifold plugin.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  Try this plugin:  http://vim.sourceforge.net/scripts/script.php?script_id=515     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  Yet another plugin for folding Python code. Rather simple, handling docstrings, and on the GitHub:  SimpylFold  Enjoy!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  The Python source comes with a vim syntax plugin along with a custom vimrc file. Check the python FAQ on vim     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "What is the recommended way to use Vim folding for Python code",
        "A_Content": "  For me the ideal folding is to fold just the class and def blocks, indent folding is too much for my taste. I think one elegant solution is to use the syntax system like this one mentioned by Tomas. However, this one is meant to replace the original syntax file and it may end being older than the original (i.e. that script doesn't mention Python 3 syntax).   My solution is to place in the ~/.vim/syntax folder a file named python.vim with just the important lines (taken from the above script):  syn match   pythonDefStatement  /^\\s*\\%(def\\|class\\)/        \\ nextgroup=pythonFunction skipwhite syn region  pythonFunctionFold  start=\"^\\z(\\s*\\)\\%(def\\|class\\)\\>\"        \\ end=\"\\ze\\%(\\s*\\n\\)\\+\\%(\\z1\\s\\)\\@!.\" fold transparent  hi link pythonDefStatement Statement   Then simply activate the folding with :set foldmethod=syntax.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "vim",
            "folding"
        ],
        "URL": "https://stackoverflow.com/questions/357785/what-is-the-recommended-way-to-use-vim-folding-for-python-code",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am interested in enabling code folding in Vim for Python code. I have noticed multiple ways to do so.  Does anyone have a preferred way to do Python code folding in Vim? I.e,    Do you have a particular Vim plugin that you use and like? Do you use manual folding or do you place markers in comments? Any other recommended ways to do code folding for Python in Vim?      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  With the following program  #! /usr/bin/env python  import foo  def fullname(o):   return o.__module__ + \".\" + o.__class__.__qualname__  bar = foo.Bar() print fullname(bar)   and Bar defined as  class Bar(object):   def __init__(self, v=42):     self.val = v   the output is  $ ./prog.py foo.Bar      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "99",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  The provided answers don't deal with nested classes. Though it's not available until Python 3.3 (PEP 3155), you really want to use __qualname__ of the class. Eventually (3.4? PEP 395), __qualname__ will also exist for modules to deal with cases where the module is renamed (i.e. when it is renamed to __main__).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  Consider using the inspect module which has functions like getmodule which might be what are looking for:  >>>import inspect >>>import xml.etree.ElementTree >>>et = xml.etree.ElementTree.ElementTree() >>>inspect.getmodule(et) <module 'xml.etree.ElementTree' from          'D:\\tools\\python2.5.2\\lib\\xml\\etree\\ElementTree.pyc'>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  Here's one based on Greg Bacon's excellent answer, but with a couple of extra checks:  __module__ can be None (according to the docs), and also for a type like str it can be __builtin__ (which you might not want appearing in logs or whatever).  The following checks for both those possibilities:  def fullname(o):     module = o.__class__.__module__     if module is None or module == str.__class__.__module__:         return o.__class__.__name__     return module + '.' + o.__class__.__name__   (There might be a better way to check for __builtin__.  The above just relies on the fact that str is always available, and its module is always __builtin__)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  __module__ would do the trick.  Try:  >>> import re >>> print re.compile.__module__ re   This site suggests that __package__ might work for Python 3.0; However, the examples given there won't work under my Python 2.5.2 console.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  This is a hack but I'm supporting 2.6 and just need something simple:  >>> from logging.handlers import MemoryHandler as MH >>> str(MH).split(\"'\")[1]  'logging.handlers.MemoryHandler'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  Since the interest of this topic is to get fully qualified names, here is a pitfall that occurs when using relative imports along with the main module existing in the same package. E.g., with the below module setup:  $ cat /tmp/fqname/foo/__init__.py $ cat /tmp/fqname/foo/bar.py from baz import Baz print Baz.__module__ $ cat /tmp/fqname/foo/baz.py class Baz: pass $ cat /tmp/fqname/main.py import foo.bar from foo.baz import Baz print Baz.__module__ $ cat /tmp/fqname/foo/hum.py import bar import foo.bar   Here is the output showing the result of importing the same module differently:  $ export PYTHONPATH=/tmp/fqname $ python /tmp/fqname/main.py foo.baz foo.baz $ python /tmp/fqname/foo/bar.py baz $ python /tmp/fqname/foo/hum.py baz foo.baz   When hum imports bar using relative path, bar sees Baz.__module__ as just \"baz\", but in the second import that uses full name, bar sees the same as \"foo.baz\".  If you are persisting the fully-qualified names somewhere, it is better to avoid relative imports for those classes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  None of the answers here worked for me. In my case, I was using Python 2.7 and knew that I would only be working with newstyle object classes.   def get_qualified_python_name_from_class(model):     c = model.__class__.__mro__[0]     name = c.__module__ + \".\" + c.__name__     return name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get fully qualified class name of an object in Python",
        "A_Content": "  Some people (e.g. https://stackoverflow.com/a/16763814/5766934) arguing that __qualname__ is better than __name__. Here is an example that shows the difference:  $ cat dummy.py  class One:     class Two:         pass  $ python3.6 >>> import dummy >>> print(dummy.One) <class 'dummy.One'> >>> print(dummy.One.Two) <class 'dummy.One.Two'> >>> def full_name_with_name(klass): ...     return f'{klass.__module__}.{klass.__name__}' >>> def full_name_with_qualname(klass): ...     return f'{klass.__module__}.{klass.__qualname__}' >>> print(full_name_with_name(dummy.One))  # Correct dummy.One >>> print(full_name_with_name(dummy.One.Two))  # Wrong dummy.Two >>> print(full_name_with_qualname(dummy.One))  # Correct dummy.One >>> print(full_name_with_qualname(dummy.One.Two))  # Correct dummy.One.Two   Note, it also works correctly for buildins:  >>> print(full_name_with_qualname(print)) builtins.print >>> import builtins >>> builtins.print <built-in function print>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-datamodel"
        ],
        "URL": "https://stackoverflow.com/questions/2020014/get-fully-qualified-class-name-of-an-object-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For logging purposes I want to retrieve the fully qualified class name of a Python object. (With fully qualified I mean the class name including the package and module name.)  I know about x.__class__.__name__, but is there a simple method to get the package and module?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  This really isn't too hard to implement with ModelForms. So lets say you have Forms A, B, and C. You print out each of the forms and the page and now you need to handle the POST.  if request.POST():     a_valid = formA.is_valid()     b_valid = formB.is_valid()     c_valid = formC.is_valid()     # we do this since 'and' short circuits and we want to check to whole page for form errors     if a_valid and b_valid and c_valid:         a = formA.save()         b = formB.save(commit=False)         c = formC.save(commit=False)         b.foreignkeytoA = a         b.save()         c.foreignkeytoB = b         c.save()   Here are the docs for custom validation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "71",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  I just was in about the same situation a day ago, and here are my 2 cents:  1) I found arguably the shortest and most concise demonstration of multiple model entry in single form here: http://collingrady.wordpress.com/2008/02/18/editing-multiple-objects-in-django-with-newforms/ .   In a nutshell: Make a form for each model, submit them both to template in a single <form>, using prefix keyarg and have the view handle validation. If there is dependency, just make sure you save the \"parent\"  model before dependant, and use parent's ID for foreign key before commiting save of \"child\" model. The link has the demo.  2) Maybe formsets can be beaten into doing this, but as far as I delved in, formsets are primarily for entering multiples of the same model, which may be optionally tied to another model/models by foreign keys. However, there seem to be no default option for entering more than one model's data and that's not what formset seems to be meant for.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  I very recently had the some problem and just figured out how to do this. Assuming you have three classes, Primary, B, C and that B,C have a foreign key to primary      class PrimaryForm(ModelForm):         class Meta:             model = Primary      class BForm(ModelForm):         class Meta:             model = B             exclude = ('primary',)      class CForm(ModelForm):          class Meta:             model = C             exclude = ('primary',)      def generateView(request):         if request.method == 'POST': # If the form has been submitted...             primary_form = PrimaryForm(request.POST, prefix = \"primary\")             b_form = BForm(request.POST, prefix = \"b\")             c_form = CForm(request.POST, prefix = \"c\")             if primary_form.is_valid() and b_form.is_valid() and c_form.is_valid(): # All validation rules pass                     print \"all validation passed\"                     primary = primary_form.save()                     b_form.cleaned_data[\"primary\"] = primary                     b = b_form.save()                     c_form.cleaned_data[\"primary\"] = primary                     c = c_form.save()                     return HttpResponseRedirect(\"/viewer/%s/\" % (primary.name))             else:                     print \"failed\"          else:             primary_form = PrimaryForm(prefix = \"primary\")             b_form = BForm(prefix = \"b\")             c_form = Form(prefix = \"c\")      return render_to_response('multi_model.html', {      'primary_form': primary_form,      'b_form': b_form,      'c_form': c_form,       })   This method should allow you to do whatever validation you require, as well as generating all three objects on the same page. I have also used javascript and hidden fields to allow the generation of multiple B,C objects on the same page.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  The MultiModelForm from django-betterforms is a convenient wrapper to do what is described in Gnudiff's answer. It wraps regular ModelForms in a single class which is transparently (at least for basic usage) used as a single form. I've copied an example from their docs below.  # forms.py from django import forms from django.contrib.auth import get_user_model from betterforms.multiform import MultiModelForm from .models import UserProfile  User = get_user_model()  class UserEditForm(forms.ModelForm):     class Meta:         fields = ('email',)  class UserProfileForm(forms.ModelForm):     class Meta:         fields = ('favorite_color',)  class UserEditMultiForm(MultiModelForm):     form_classes = {         'user': UserEditForm,         'profile': UserProfileForm,     }  # views.py from django.views.generic import UpdateView from django.core.urlresolvers import reverse_lazy from django.shortcuts import redirect from django.contrib.auth import get_user_model from .forms import UserEditMultiForm  User = get_user_model()  class UserSignupView(UpdateView):     model = User     form_class = UserEditMultiForm     success_url = reverse_lazy('home')      def get_form_kwargs(self):         kwargs = super(UserSignupView, self).get_form_kwargs()         kwargs.update(instance={             'user': self.object,             'profile': self.object.profile,         })         return kwargs      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  I currently have a workaround functional (it passes my unit tests). It is a good solution to my opinion when you only want to add a limited number of fields from other models.  Am I missing something here ?  class UserProfileForm(ModelForm):     def __init__(self, instance=None, *args, **kwargs):         # Add these fields from the user object         _fields = ('first_name', 'last_name', 'email',)         # Retrieve initial (current) data from the user object         _initial = model_to_dict(instance.user, _fields) if instance is not None else {}         # Pass the initial data to the base         super(UserProfileForm, self).__init__(initial=_initial, instance=instance, *args, **kwargs)         # Retrieve the fields from the user model and update the fields with it         self.fields.update(fields_for_model(User, _fields))      class Meta:         model = UserProfile         exclude = ('user',)      def save(self, *args, **kwargs):         u = self.instance.user         u.first_name = self.cleaned_data['first_name']         u.last_name = self.cleaned_data['last_name']         u.email = self.cleaned_data['email']         u.save()         profile = super(UserProfileForm, self).save(*args,**kwargs)         return profile      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  \"I want to hide some of the fields and do some complex validation.\"  I start with the built-in admin interface.   Build the ModelForm to show the desired fields. Extend the Form with the validation rules within the form.  Usually this is a clean method.  Be sure this part works reasonably well.   Once this is done, you can move away from the built-in admin interface.  Then you can fool around with multiple, partially related forms on a single web page.  This is a bunch of template stuff to present all the forms on a single page.  Then you have to write the view function to read and validated the various form things and do the various object saves().  \"Is it a design issue if I break down and hand-code everything?\"  No, it's just a lot of time for not much benefit.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Django: multiple models in one template using forms",
        "A_Content": "  According to Django documentation, inline formsets are for this purpose: \"Inline formsets is a small abstraction layer on top of model formsets. These simplify the case of working with related objects via a foreign key\".  See https://docs.djangoproject.com/en/dev/topics/forms/modelforms/#inline-formsets     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "design",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/569468/django-multiple-models-in-one-template-using-forms",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm building a support ticket tracking app and have a few models I'd like to create from one page. Tickets belong to a Customer via a ForeignKey. Notes belong to Tickets via a ForeignKey as well. I'd like to have the option of selecting a Customer (that's a whole separate project) OR creating a new Customer, then creating a Ticket and finally creating a Note assigned to the new ticket.  Since I'm fairly new to Django, I tend to work iteratively, trying out new features each time. I've played with ModelForms but I want to hide some of the fields and do some complex validation. It seems like the level of control I'm looking for either requires formsets or doing everything by hand, complete with a tedious, hand-coded template page, which I'm trying to avoid.  Is there some lovely feature I'm missing? Does someone have a good reference or example for using formsets? I spent a whole weekend on the API docs for them and I'm still clueless. Is it a design issue if I break down and hand-code everything?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  With Python < 3 (e.g. 2.6 [see comments] or 2.7), there are two ways to do so.  # Option one older_method_string = \"%.9f\" % numvar  # Option two newer_method_string = \"{:.9f}\".format(numvar)   But note that for Python versions above 3 (e.g. 3.2 or 3.3), option two is preferred.  For more information on option two, I suggest this link on string formatting from the Python documentation.  And for more information on option one, this link will suffice and has info on the various flags.  Python 3.6 (official release in December of 2016), will add the f string literal, see more information here, which extends the str.format method (use of curly braces such that f\"{numvar:.9f}\" solves the original problem).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  Python 3.6 | 2017  Just to make it clear, you can use f-string formatting. This has almost the same syntax as the format method, but make it a bit nicer.  Example:  print(f'{numvar:.9f}')   More reading about the new f string:   What's new in Python 3.6 (same link as above) PEP official documentation Python official documentation Really good blog post - talks about performance too        ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  Using round:  >>> numvar = 135.12345678910 >>> str(round(numvar,9)) '135.123456789' >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  It's not print that does the formatting, It's a property of strings, so you can just use  newstring = \"%.9f\" % numvar      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  In case the precision is not known until runtime, this other formatting option is useful:  >>> n = 9 >>> '%.*f' % (n, numvar) '135.123456789'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  To set precision with 9 digits, get:  print \"%.9f\" % numvar   Return precision with 2 digits:  print \"%.2f\" % numvar    Return precision with 2 digits and float converted value:  numvar = 4.2345 print float(\"%.2f\" % numvar)       ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Convert floating point number to a certain precision, and then copy to string",
        "A_Content": "  The str function has a bug. Please try the following. You will see '0,196553' but the right output is '0,196554'. Because the str function's default value is ROUND_HALF_UP.  >>> value=0.196553500000  >>> str(\"%f\" % value).replace(\".\", \",\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "floating-point"
        ],
        "URL": "https://stackoverflow.com/questions/15263597/convert-floating-point-number-to-a-certain-precision-and-then-copy-to-string",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a floating point number, say 135.12345678910. I want to concatenate that value to a string, but only want 135.123456789. With print, I can easily do this by doing something like:  print \"%.9f\" % numvar   with numvar being my original number. Is there an easy way to do this?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do you run your own code alongside Tkinter's event loop?",
        "A_Content": "  Use the after method on the Tk object:  from tkinter import *  root = Tk()  def task():     print(\"hello\")     root.after(2000, task)  # reschedule event in 2 seconds  root.after(2000, task) root.mainloop()   Here's the declaration and documentation for the after method:  def after(self, ms, func=None, *args):     \"\"\"Call function once after given time.      MS specifies the time in milliseconds. FUNC gives the     function which shall be called. Additional parameters     are given as parameters to the function call.  Return     identifier to cancel scheduling with after_cancel.\"\"\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "events",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop",
        "A_Votes": "115",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    My little brother is just getting into programming, and for his Science Fair project, he's doing a simulation of a flock of birds in the sky. He's gotten most of his code written, and it works nicely, but the birds need to move every moment.  Tkinter, however, hogs the time for its own event loop, and so his code won't run. Doing root.mainloop() runs, runs, and keeps running, and the only thing it runs is the event handlers.  Is there a way to have his code run alongside the mainloop (without multithreading, it's confusing and this should be kept simple), and if so, what is it?  Right now, he came up with an ugly hack, tying his move() function to <b1-motion>, so that as long as he holds the button down and wiggles the mouse, it works. But there's got to be a better way.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do you run your own code alongside Tkinter's event loop?",
        "A_Content": "  The solution posted by Bjorn results in a \"RuntimeError: Calling Tcl from different appartment\" message on my computer (RedHat Enterprise 5, python 2.6.1).  Bjorn might not have gotten this message, since, according to one place I checked, mishandling threading with Tkinter is unpredictable and platform-dependent.  The problem seems to be that app.start() counts as a reference to Tk, since app contains Tk elements. I fixed this by replacing app.start() with a self.start() inside __init__. I also made it so that all Tk references are either inside the function that calls mainloop() or are inside functions that are called by the function that calls mainloop() (this is apparently critical to avoid the \"different apartment\" error).  Finally, I added a protocol handler with a callback, since without this the program exits with an error when the Tk window is closed by the user.  The revised code is as follows:  # Run tkinter code in another thread  import tkinter as tk import threading  class App(threading.Thread):      def __init__(self):         threading.Thread.__init__(self)         self.start()      def callback(self):         self.root.quit()      def run(self):         self.root = tk.Tk()         self.root.protocol(\"WM_DELETE_WINDOW\", self.callback)          label = tk.Label(self.root, text=\"Hello World\")         label.pack()          self.root.mainloop()   app = App() print('Now we can continue running code while mainloop runs!')  for i in range(100000):     print(i)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "events",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My little brother is just getting into programming, and for his Science Fair project, he's doing a simulation of a flock of birds in the sky. He's gotten most of his code written, and it works nicely, but the birds need to move every moment.  Tkinter, however, hogs the time for its own event loop, and so his code won't run. Doing root.mainloop() runs, runs, and keeps running, and the only thing it runs is the event handlers.  Is there a way to have his code run alongside the mainloop (without multithreading, it's confusing and this should be kept simple), and if so, what is it?  Right now, he came up with an ugly hack, tying his move() function to <b1-motion>, so that as long as he holds the button down and wiggles the mouse, it works. But there's got to be a better way.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do you run your own code alongside Tkinter's event loop?",
        "A_Content": "  When writing your own loop, as in the simulation (I assume), you need to call the update function which does what the mainloop does: updates the window with your changes, but you do it in your loop.  def task():    # do something    root.update()  while 1:    task()        ",
        "Language": "Python",
        "Tags": [
            "python",
            "events",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My little brother is just getting into programming, and for his Science Fair project, he's doing a simulation of a flock of birds in the sky. He's gotten most of his code written, and it works nicely, but the birds need to move every moment.  Tkinter, however, hogs the time for its own event loop, and so his code won't run. Doing root.mainloop() runs, runs, and keeps running, and the only thing it runs is the event handlers.  Is there a way to have his code run alongside the mainloop (without multithreading, it's confusing and this should be kept simple), and if so, what is it?  Right now, he came up with an ugly hack, tying his move() function to <b1-motion>, so that as long as he holds the button down and wiggles the mouse, it works. But there's got to be a better way.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do you run your own code alongside Tkinter's event loop?",
        "A_Content": "  Another option is to let tkinter execute on a separate thread. One way of doing it is like this:  import Tkinter import threading  class MyTkApp(threading.Thread):     def __init__(self):         self.root=Tkinter.Tk()         self.s = Tkinter.StringVar()         self.s.set('Foo')         l = Tkinter.Label(self.root,textvariable=self.s)         l.pack()         threading.Thread.__init__(self)      def run(self):         self.root.mainloop()   app = MyTkApp() app.start()  # Now the app should be running and the value shown on the label # can be changed by changing the member variable s. # Like this: # app.s.set('Bar')   Be careful though, multithreaded programming is hard and it is really easy to shoot your self in the foot. For example you have to be careful when you change member variables of the sample class above so you don't interrupt with the event loop of Tkinter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "events",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My little brother is just getting into programming, and for his Science Fair project, he's doing a simulation of a flock of birds in the sky. He's gotten most of his code written, and it works nicely, but the birds need to move every moment.  Tkinter, however, hogs the time for its own event loop, and so his code won't run. Doing root.mainloop() runs, runs, and keeps running, and the only thing it runs is the event handlers.  Is there a way to have his code run alongside the mainloop (without multithreading, it's confusing and this should be kept simple), and if so, what is it?  Right now, he came up with an ugly hack, tying his move() function to <b1-motion>, so that as long as he holds the button down and wiggles the mouse, it works. But there's got to be a better way.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do you run your own code alongside Tkinter's event loop?",
        "A_Content": "  This is the first working version of what will be a GPS reader and data presenter.  tkinter is a very fragile thing with way too few error messages.  It does not put stuff up and does not tell why much of the time.  Very difficult coming from a good WYSIWYG form developer.  Anyway, this runs a small routine 10 times a second and presents the information on a form.  Took a while to make it happen.  When I tried a timer value of 0, the form never came up.  My head now hurts!  10 or more times per second is good enough for me.  I hope it helps someone else.  Mike Morrow  import tkinter as tk import time  def GetDateTime():   # Get current date and time in ISO8601   # https://en.wikipedia.org/wiki/ISO_8601    # https://xkcd.com/1179/   return (time.strftime(\"%Y%m%d\", time.gmtime()),           time.strftime(\"%H%M%S\", time.gmtime()),           time.strftime(\"%Y%m%d\", time.localtime()),           time.strftime(\"%H%M%S\", time.localtime()))  class Application(tk.Frame):    def __init__(self, master):      fontsize = 12     textwidth = 9      tk.Frame.__init__(self, master)     self.pack()      tk.Label(self, font=('Helvetica', fontsize), bg = '#be004e', fg = 'white', width = textwidth,              text='Local Time').grid(row=0, column=0)     self.LocalDate = tk.StringVar()     self.LocalDate.set('waiting...')     tk.Label(self, font=('Helvetica', fontsize), bg = '#be004e', fg = 'white', width = textwidth,              textvariable=self.LocalDate).grid(row=0, column=1)      tk.Label(self, font=('Helvetica', fontsize), bg = '#be004e', fg = 'white', width = textwidth,              text='Local Date').grid(row=1, column=0)     self.LocalTime = tk.StringVar()     self.LocalTime.set('waiting...')     tk.Label(self, font=('Helvetica', fontsize), bg = '#be004e', fg = 'white', width = textwidth,              textvariable=self.LocalTime).grid(row=1, column=1)      tk.Label(self, font=('Helvetica', fontsize), bg = '#40CCC0', fg = 'white', width = textwidth,              text='GMT Time').grid(row=2, column=0)     self.nowGdate = tk.StringVar()     self.nowGdate.set('waiting...')     tk.Label(self, font=('Helvetica', fontsize), bg = '#40CCC0', fg = 'white', width = textwidth,              textvariable=self.nowGdate).grid(row=2, column=1)      tk.Label(self, font=('Helvetica', fontsize), bg = '#40CCC0', fg = 'white', width = textwidth,              text='GMT Date').grid(row=3, column=0)     self.nowGtime = tk.StringVar()     self.nowGtime.set('waiting...')     tk.Label(self, font=('Helvetica', fontsize), bg = '#40CCC0', fg = 'white', width = textwidth,              textvariable=self.nowGtime).grid(row=3, column=1)      tk.Button(self, text='Exit', width = 10, bg = '#FF8080', command=root.destroy).grid(row=4, columnspan=2)      self.gettime()   pass    def gettime(self):     gdt, gtm, ldt, ltm = GetDateTime()     gdt = gdt[0:4] + '/' + gdt[4:6] + '/' + gdt[6:8]     gtm = gtm[0:2] + ':' + gtm[2:4] + ':' + gtm[4:6] + ' Z'       ldt = ldt[0:4] + '/' + ldt[4:6] + '/' + ldt[6:8]     ltm = ltm[0:2] + ':' + ltm[2:4] + ':' + ltm[4:6]       self.nowGtime.set(gdt)     self.nowGdate.set(gtm)     self.LocalTime.set(ldt)     self.LocalDate.set(ltm)      self.after(100, self.gettime)    #print (ltm)  # Prove it is running this and the external code, too.   pass  root = tk.Tk() root.wm_title('Temp Converter') app = Application(master=root)  w = 200 # width for the Tk root h = 125 # height for the Tk root  # get display screen width and height ws = root.winfo_screenwidth()  # width of the screen hs = root.winfo_screenheight() # height of the screen  # calculate x and y coordinates for positioning the Tk root window  #centered #x = (ws/2) - (w/2) #y = (hs/2) - (h/2)  #right bottom corner (misfires in Win10 putting it too low. OK in Ubuntu) x = ws - w y = hs - h - 35  # -35 fixes it, more or less, for Win10  #set the dimensions of the screen and where it is placed root.geometry('%dx%d+%d+%d' % (w, h, x, y))  root.mainloop()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "events",
            "tkinter"
        ],
        "URL": "https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My little brother is just getting into programming, and for his Science Fair project, he's doing a simulation of a flock of birds in the sky. He's gotten most of his code written, and it works nicely, but the birds need to move every moment.  Tkinter, however, hogs the time for its own event loop, and so his code won't run. Doing root.mainloop() runs, runs, and keeps running, and the only thing it runs is the event handlers.  Is there a way to have his code run alongside the mainloop (without multithreading, it's confusing and this should be kept simple), and if so, what is it?  Right now, he came up with an ugly hack, tying his move() function to <b1-motion>, so that as long as he holds the button down and wiggles the mouse, it works. But there's got to be a better way.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  os.path.isdir() and os.path.isfile() should give you what you want.  See:  http://docs.python.org/library/os.path.html     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  As other answers have said, os.path.isdir() and os.path.isfile() are what you want.  However, you need to keep in mind that these are not the only two cases.  Use os.path.islink() for symlinks for instance.  Furthermore, these all return False if the file does not exist, so you'll probably want to check with os.path.exists() as well.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  import os  if os.path.isdir(d):     print \"dir\" else:     print \"file\"      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  try this:  import os.path if os.path.isdir(\"path/to/your/file\"):     print \"it's a directory\" else:     print \"it's a file\"      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  os.path.isdir('string') os.path.isfile('string')     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  Python 3.4 introduced the pathlib module into the standard library, which provides an object oriented approach to handle filesystem paths. The relavant methods would be .is_file() and .is_dir():  In [1]: from pathlib import Path  In [2]: p = Path('/usr')  In [3]: p.is_file() Out[3]: False  In [4]: p.is_dir() Out[4]: True  In [5]: q = p / 'bin' / 'vim'  In [6]: q.is_file() Out[6]: True  In [7]: q.is_dir() Out[7]: False   Pathlib is also available on Python 2.7 via the pathlib2 module on PyPi.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to identify whether a file is normal file or directory using python",
        "A_Content": "  If you're just stepping through a set of directories you might be better just to try os.chdir and give an error/warning if it fails:  import os,sys for DirName in sys.argv[1:]:     SaveDir = os.getcwd()     try:         os.chdir(DirName)         print \"Changed to \"+DirName         # Do some stuff here in the directory         os.chdir(SaveDir)     except:         sys.stderr.write(\"%s: WARNING: Cannot change to %s\\n\" % (sys.argv[0],DirName))      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/955941/how-to-identify-whether-a-file-is-normal-file-or-directory-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you check whether a file is a normal file or a directory using python?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do I access the command history from IDLE?",
        "A_Content": "  I think you are looking for the history-previous action, which is bound to alt+p by default.  You can remap it in Options->Configure IDLE->Keys  Incidentally, why don't you try a better (less ugly, for starters) shell like bpython or ipython?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/3132265/how-do-i-access-the-command-history-from-idle",
        "A_Votes": "125",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    On bash or Window's Command Prompt, we can press the up arrow on keyboard to get the last command, and edit it, and press ENTER again to see the result.  But in Python's IDLE 2.6.5 or 3.1.2, it seems if our statement prints out 25 lines, we need to press the up arrow 25 times to that last command, and press ENTER for it to be copied?  Or use the mouse to pinpoint that line and click there, and press ENTER to copy?  Is there a faster way?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do I access the command history from IDLE?",
        "A_Content": "  just use Alt+P to go up. Similarly, Alt+N could be used to go down.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/3132265/how-do-i-access-the-command-history-from-idle",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    On bash or Window's Command Prompt, we can press the up arrow on keyboard to get the last command, and edit it, and press ENTER again to see the result.  But in Python's IDLE 2.6.5 or 3.1.2, it seems if our statement prints out 25 lines, we need to press the up arrow 25 times to that last command, and press ENTER for it to be copied?  Or use the mouse to pinpoint that line and click there, and press ENTER to copy?  Is there a faster way?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do I access the command history from IDLE?",
        "A_Content": "  If you're on mac, it's ctrl+p.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/3132265/how-do-i-access-the-command-history-from-idle",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    On bash or Window's Command Prompt, we can press the up arrow on keyboard to get the last command, and edit it, and press ENTER again to see the result.  But in Python's IDLE 2.6.5 or 3.1.2, it seems if our statement prints out 25 lines, we need to press the up arrow 25 times to that last command, and press ENTER for it to be copied?  Or use the mouse to pinpoint that line and click there, and press ENTER to copy?  Is there a faster way?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do I access the command history from IDLE?",
        "A_Content": "  You can always edit the file config-keys.cfg found under ~/.idlerc by default; look for the entry \"history-previous\" and set it to as below...   history-previous = <Key-Up>   Done.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/3132265/how-do-i-access-the-command-history-from-idle",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    On bash or Window's Command Prompt, we can press the up arrow on keyboard to get the last command, and edit it, and press ENTER again to see the result.  But in Python's IDLE 2.6.5 or 3.1.2, it seems if our statement prints out 25 lines, we need to press the up arrow 25 times to that last command, and press ENTER for it to be copied?  Or use the mouse to pinpoint that line and click there, and press ENTER to copy?  Is there a faster way?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How do I access the command history from IDLE?",
        "A_Content": "  Go into Preferences > Keys. Find the 'history-previous' selection in the list and edit it to Up Arrow.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/3132265/how-do-i-access-the-command-history-from-idle",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    On bash or Window's Command Prompt, we can press the up arrow on keyboard to get the last command, and edit it, and press ENTER again to see the result.  But in Python's IDLE 2.6.5 or 3.1.2, it seems if our statement prints out 25 lines, we need to press the up arrow 25 times to that last command, and press ENTER for it to be copied?  Or use the mouse to pinpoint that line and click there, and press ENTER to copy?  Is there a faster way?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Assert a function/method was not called using Mock",
        "A_Content": "  This should work for your case;  assert not my_var.called, 'method should not have been called'   Sample;  >>> mock=Mock() >>> mock.a() <Mock name='mock.a()' id='4349129872'> >>> assert not mock.b.called, 'b was called and should not have been' >>> assert not mock.a.called, 'a was called and should not have been' Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AssertionError: a was called and should not have been      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking",
            "python-mock"
        ],
        "URL": "https://stackoverflow.com/questions/12187122/assert-a-function-method-was-not-called-using-mock",
        "A_Votes": "113",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using the Mock library to test my application, but I want to assert that some function was not called. Mock docs talk about methods like mock.assert_called_with and mock.assert_called_once_with, but I didn't find anything like mock.assert_not_called or something related to verify mock was NOT called.  I could go with something like the following, though it doesn't seem cool nor pythonic:  def test_something:     # some actions     with patch('something') as my_var:         try:             # args are not important. func should never be called in this test             my_var.assert_called_with(some, args)         except AssertionError:             pass  # this error being raised means it's ok     # other stuff   Any ideas how to accomplish this?  Thanks for any help :)     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Assert a function/method was not called using Mock",
        "A_Content": "  Though an old question, I would like to add that currently mock library (backport of unittest.mock) supports assert_not_called method.  Just upgrade yours;  pip install mock --upgrade     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking",
            "python-mock"
        ],
        "URL": "https://stackoverflow.com/questions/12187122/assert-a-function-method-was-not-called-using-mock",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Mock library to test my application, but I want to assert that some function was not called. Mock docs talk about methods like mock.assert_called_with and mock.assert_called_once_with, but I didn't find anything like mock.assert_not_called or something related to verify mock was NOT called.  I could go with something like the following, though it doesn't seem cool nor pythonic:  def test_something:     # some actions     with patch('something') as my_var:         try:             # args are not important. func should never be called in this test             my_var.assert_called_with(some, args)         except AssertionError:             pass  # this error being raised means it's ok     # other stuff   Any ideas how to accomplish this?  Thanks for any help :)     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Assert a function/method was not called using Mock",
        "A_Content": "  You can check the called attribute, but if your assertion fails, the next thing you'll want to know is something about the unexpected call, so you may as well arrange for that information to be displayed from the start. Using unittest, you can check the contents of call_args_list instead:  self.assertItemsEqual(my_var.call_args_list, [])   When it fails, it gives a message like this:   AssertionError: Element counts were not equal: First has 0, Second has 1:  call('first argument', 4)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking",
            "python-mock"
        ],
        "URL": "https://stackoverflow.com/questions/12187122/assert-a-function-method-was-not-called-using-mock",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Mock library to test my application, but I want to assert that some function was not called. Mock docs talk about methods like mock.assert_called_with and mock.assert_called_once_with, but I didn't find anything like mock.assert_not_called or something related to verify mock was NOT called.  I could go with something like the following, though it doesn't seem cool nor pythonic:  def test_something:     # some actions     with patch('something') as my_var:         try:             # args are not important. func should never be called in this test             my_var.assert_called_with(some, args)         except AssertionError:             pass  # this error being raised means it's ok     # other stuff   Any ideas how to accomplish this?  Thanks for any help :)     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Assert a function/method was not called using Mock",
        "A_Content": "  When you test using class inherits unittest.TestCase you can simply use methods like:   assertTrue assertFalse assertEqual   and similar (in python documentation you find the rest).  In your example we can simply assert if mock_method.called property is False, which means that method was not called.  import unittest from unittest import mock  import my_module  class A(unittest.TestCase):     def setUp(self):         self.message = \"Method should not be called. Called {times} times!\"      @mock.patch(\"my_module.method_to_mock\")     def test(self, mock_method):         my_module.method_to_mock()          self.assertFalse(mock_method.called,                          self.message.format(times=mock_method.call_count))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking",
            "python-mock"
        ],
        "URL": "https://stackoverflow.com/questions/12187122/assert-a-function-method-was-not-called-using-mock",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Mock library to test my application, but I want to assert that some function was not called. Mock docs talk about methods like mock.assert_called_with and mock.assert_called_once_with, but I didn't find anything like mock.assert_not_called or something related to verify mock was NOT called.  I could go with something like the following, though it doesn't seem cool nor pythonic:  def test_something:     # some actions     with patch('something') as my_var:         try:             # args are not important. func should never be called in this test             my_var.assert_called_with(some, args)         except AssertionError:             pass  # this error being raised means it's ok     # other stuff   Any ideas how to accomplish this?  Thanks for any help :)     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Assert a function/method was not called using Mock",
        "A_Content": "  Judging from other answers, no one except @rob-kennedy talked about the call_args_list.  It's a powerful tool for that you can implement the exact contrary of MagicMock.assert_called_with()  call_args_list is a list of call objects. Each call object represents a call made on a mocked callable.  >>> from unittest.mock import MagicMock >>> m = MagicMock() >>> m.call_args_list [] >>> m(42) <MagicMock name='mock()' id='139675158423872'> >>> m.call_args_list [call(42)] >>> m(42, 30) <MagicMock name='mock()' id='139675158423872'> >>> m.call_args_list [call(42), call(42, 30)]   Consuming a call object is easy, since you can compare it with a tuple of length 2 where the first component is a tuple containing all the positional arguments of the related call, while the second component is a dictionary of the keyword arguments.  >>> ((42,),) in m.call_args_list True >>> m(42, foo='bar') <MagicMock name='mock()' id='139675158423872'> >>> ((42,), {'foo': 'bar'}) in m.call_args_list True >>> m(foo='bar') <MagicMock name='mock()' id='139675158423872'> >>> ((), {'foo': 'bar'}) in m.call_args_list True   So, a way to address the specific problem of the OP is  def test_something():     with patch('something') as my_var:         assert ((some, args),) not in my_var.call_args_list   Note that this way, instead of just checking if a mocked callable has been called, via MagicMock.called, you can now check if it has been called with a specific set of arguments.  That's useful. Say you want to test a function that takes a list and call another function, compute(), for each of the value of the list only if they satisfy a specific condition.  You can now mock compute, and test if it has been called on some value but not on others.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "mocking",
            "python-mock"
        ],
        "URL": "https://stackoverflow.com/questions/12187122/assert-a-function-method-was-not-called-using-mock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using the Mock library to test my application, but I want to assert that some function was not called. Mock docs talk about methods like mock.assert_called_with and mock.assert_called_once_with, but I didn't find anything like mock.assert_not_called or something related to verify mock was NOT called.  I could go with something like the following, though it doesn't seem cool nor pythonic:  def test_something:     # some actions     with patch('something') as my_var:         try:             # args are not important. func should never be called in this test             my_var.assert_called_with(some, args)         except AssertionError:             pass  # this error being raised means it's ok     # other stuff   Any ideas how to accomplish this?  Thanks for any help :)     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  The following works in Python 2:  sorted_list = sorted(unsorted_list, key=lambda s: s.lower())   It works for both normal and unicode strings, since they both have a lower method.  In Python 2 it works for a mix of normal and unicode strings, since values of the two types can be compared with each other. Python 3 doesn't work like that, though: you can't compare a byte string and a unicode string, so in Python 3 you should do the sane thing and only sort lists of one type of string.  >>> lst = ['Aden', u'abe1'] >>> sorted(lst) ['Aden', u'abe1'] >>> sorted(lst, key=lambda s: s.lower()) [u'abe1', 'Aden']   Since python 3.3, there is also the str.casefold method that's specifically designed for caseless matching and can be used in place of str.lower:  sorted_list = sorted(unsorted_list, key=lambda s: s.casefold())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "134",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  >>> x = ['Aden', 'abel'] >>> sorted(x, key=str.lower) # Or unicode.lower if all items are unicode ['abel', 'Aden']   In Python 3 str is unicode but in Python 2 you can use this more general approach which works for both str and unicode:  >>> sorted(x, key=lambda s: s.lower()) ['abel', 'Aden']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  You can also try this:  >>> x = ['Aden', 'abel'] >>> x.sort(key=lambda y: y.lower()) >>> x ['abel', 'Aden']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  In python3 you can use  list1.sort(key=lambda x: x.lower()) #Case In-sensitive              list1.sort() #Case Sensitive      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  I did it this way for Python 3.3:   def sortCaseIns(lst):     lst2 = [[x for x in range(0, 2)] for y in range(0, len(lst))]     for i in range(0, len(lst)):         lst2[i][0] = lst[i].lower()         lst2[i][1] = lst[i]     lst2.sort()     for i in range(0, len(lst)):         lst[i] = lst2[i][1]   Then you just can call this function:  sortCaseIns(yourListToSort)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "case-insensitive list sorting, without lowercasing the result?",
        "A_Content": "  Try this  def cSort(inlist, minisort=True):     sortlist = []     newlist = []     sortdict = {}     for entry in inlist:         try:             lentry = entry.lower()         except AttributeError:             sortlist.append(lentry)         else:             try:                 sortdict[lentry].append(entry)             except KeyError:                 sortdict[lentry] = [entry]                 sortlist.append(lentry)      sortlist.sort()     for entry in sortlist:         try:             thislist = sortdict[entry]             if minisort: thislist.sort()             newlist = newlist + thislist         except KeyError:             newlist.append(entry)     return newlist     lst = ['Aden', 'abel'] print cSort(lst)   Output  ['abel', 'Aden']     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "sorting",
            "case-insensitive"
        ],
        "URL": "https://stackoverflow.com/questions/10269701/case-insensitive-list-sorting-without-lowercasing-the-result",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list of strings like this:  ['Aden', 'abel']   I want to sort the items, case-insensitive. So I want to get:  ['abel', 'Aden']   But I get the opposite with sorted() or list.sort(), because uppercase appears before lowercase.  How can I ignore the case? I've seen solutions which involves lowercasing all list items, but I don't want to change the case of the list items.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python - json without whitespaces",
        "A_Content": "  json.dumps(separators=(',', ':'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/16311562/python-json-without-whitespaces",
        "A_Votes": "157",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I just realized that json.dumps() adds spaces in the JSON object  e.g.  {'duration': '02:55', 'name': 'flower', 'chg': 0}   how can remove the spaces in order to make the JSON more compact and save bytes to be sent via HTTP?  such as:  {'duration':'02:55','name':'flower','chg':0}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python - json without whitespaces",
        "A_Content": "  In some cases you may want to get rid of the trailing whitespaces only. You can then use  json.dumps(separators=(',', ': '))   There is a space after : but not after ,.  This is useful for diff'ing your JSON files (in version control such as git diff), where some editors will get rid of the trailing whitespace but python json.dump will add it back.  Note: This does not exactly answers the question on top, but I came here looking for this answer specifically. I don't think that it deserves its own QA, so I'm adding it here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "json"
        ],
        "URL": "https://stackoverflow.com/questions/16311562/python-json-without-whitespaces",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just realized that json.dumps() adds spaces in the JSON object  e.g.  {'duration': '02:55', 'name': 'flower', 'chg': 0}   how can remove the spaces in order to make the JSON more compact and save bytes to be sent via HTTP?  such as:  {'duration':'02:55','name':'flower','chg':0}      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  This works in Python 2.x.  For Python 3 look here:  http://docs.python.org/py3k/library/urllib.request.html?highlight=urllib#urllib.request.urlopen  import urllib.request with urllib.request.urlopen(\"http://www.python.org\") as url:     s = url.read() #I'm guessing this would output the html source code? print(s)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "154",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  A Python 2+3 compatible solution is:  import sys  if sys.version_info[0] == 3:     from urllib.request import urlopen else:     # Not Python 3 - today, it is most likely to be Python 2     # But note that this might need an update when Python 4     # might be around one day     from urllib import urlopen   # Your code where you can use urlopen with urlopen(\"http://www.python.org\") as url:     s = url.read()  print(s)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  import urllib.request as ur s = ur.urlopen(\"http://www.google.com\") sl = s.read() print(sl)   In Python v3 the \"urllib.request\" is a module by itself, therefore \"urllib\" cannot be used here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  import urllib.request as ur  filehandler = ur.urlopen ('http://www.google.com') for line in filehandler:     print(line.strip())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  To get 'dataX = urllib.urlopen(url).read()' working in python3 (this would have been correct for python2) you must just change 2 little things.   1: The urllib statement itself (add the .request in the middle):  dataX = urllib.request.urlopen(url).read()   2: The import statement preceding it (change from 'import urlib' to:  import urllib.request   And it should work in python3 :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  For python 3, try something like this:  import urllib.request urllib.request.urlretrieve('http://crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_YoYo_g19_c02.avi', \"video_name.avi\")   It will download the video to the current working directory   I got help from HERE     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  Solution for python3:  from urllib.request import urlopen  url = 'http://www.python.org' file = urlopen(url) html = file.read() print(html)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "AttributeError: 'module' object has no attribute 'urlopen'",
        "A_Content": "  your code used in python2.x, you can use like this:  from urllib.request import urlopen urlopen(url)   by the way , suggest another model called requests is more friendly to use, you can use pip install it, and use like this:  import requests requests.get(url) requests.post(url)   I thought it is easily to use, i am beginner too....hahah     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "urllib"
        ],
        "URL": "https://stackoverflow.com/questions/3969726/attributeerror-module-object-has-no-attribute-urlopen",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to use Python to download the HTML source code of a website but I'm receiving this error.      Traceback (most recent call last):   File   \"C:\\Users\\Sergio.Tapia\\Documents\\NetBeansProjects\\DICParser\\src\\WebDownload.py\",   line 3, in        file = urllib.urlopen(\"http://www.python.org\")   AttributeError: 'module' object has no   attribute 'urlopen'   I'm following the guide here: http://www.boddie.org.uk/python/HTML.html  import urllib  file = urllib.urlopen(\"http://www.python.org\") s = file.read() f.close()  #I'm guessing this would output the html source code? print(s)   I'm using Python 3, thanks for the help!     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  CTRL - ML toggles line numbers in the CodeMirror area.  See the QuickHelp for other keyboard shortcuts.  In more details CTRL - M (or ESC) bring you to command mode, then pressing the L keys should toggle the visibility of current cell line numbers. In more recent notebook versions Shift-L should toggle for all cells.  If you can't remember the shortcut, bring up the command palette Ctrl-Shift+P (Cmd+Shift+P on Mac), and search for \"line numbers\"), it should allow to toggle and show you the shortcut.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "114",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  On IPython 2.2.0, just typing l (lowercase L) on command mode (activated by typing Esc) works.  See [Help] - [Keyboard Shortcuts] for other shortcuts.  Also, you can set default behavior to display line numbers by editing custom.js.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  For me, ctrl + m is used to save webpage as png, so it does not work properly. But I find another way.  On the toolbar, there is a bottom named \"open the command paletee\", you can click it and type in line, and you can see the toggle cell line number here.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  Select the Toggle Line Number Option from the View -> Toggle Line Number.  enter image description here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  Here is how to know active shortcut (depending on your OS and notebook version, it might change)  Help > Keyboard Shortcuts > toggle line numbers  On OSX running ipython3 it was ESC L     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  To turn line numbers on by default in all cells at startup I recommend this link:  https://www.webucator.com/blog/2015/11/show-line-numbers-by-default-in-ipython-notebook/  I quote ...  Navigate to your jupyter config directory, which you can find by typing the following at the command line:  jupyter --config-dir  From there, open or create the   custom   folder.   In that folder, you should find a custom.js file. If there isn’t one, you should be able to create one. Open it in a text editor and add this code:   define([     'base/js/namespace',     'base/js/events'     ],     function(IPython, events) {         events.on(\"app_initialized.NotebookApp\",             function () {                 IPython.Cell.options_default.cm_config.lineNumbers = true;             }         );     } );      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  You can also find [Toggle Line Numbers] under [View] on the top toolbar of the Jupyter notebook in your browser. This adds/removes the lines numbers in all notebook cells.  For me, [Esc] [l] only added/removed the line numbers of the active cell.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Showing line numbers in IPython/Jupyter Notebooks",
        "A_Content": "  1.press esc to enter the command mode 2.perss l(it L in lowcase) to show the line number     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter"
        ],
        "URL": "https://stackoverflow.com/questions/10979667/showing-line-numbers-in-ipython-jupyter-notebooks",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Error reports from most language kernels running in IPython/Jupyter Notebooks indicate the line on which the error occurred; but (at least by default) no line numbers are indicated in Notebooks.  Is it possibile to add the line numbers to IPython/Jupyter Notebooks?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  You can use:  >>> lst = [None] * 5 >>> lst [None, None, None, None, None]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  Why don't these questions get answered with the obvious answer?  a = numpy.empty(n, dtype=object)   This creates an array of length n that can store objects.  It can't be resized or appended to.  In particular, it doesn't waste space by padding its length. This is the Java equivalent of   Object[] a = new Object[n];   If you're really interested in performance and space and know that your array will only store certain numeric types then you can change the dtype argument to some other value like int. Then numpy will pack these elements directly into the array rather than making the array reference int objects.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "46",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  Do this:  >>> d = [ [ None for y in range( 2 ) ] for x in range( 2 ) ] >>> d [[None, None], [None, None]] >>> d[0][0] = 1 >>> d [[1, None], [None, None]]   The other solutions will lead to this kind of problem:  >>> d = [ [ None ] * 2 ] * 2 >>> d [[None, None], [None, None]] >>> d[0][0] = 1 >>> d [[1, None], [1, None]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  The best bet is to use the numpy library.  from numpy import ndarray  a = ndarray((5,),int)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  >>> import numpy >>> x = numpy.zeros((3,4)) >>> x array([[ 0.,  0.,  0.,  0.],        [ 0.,  0.,  0.,  0.],        [ 0.,  0.,  0.,  0.]]) >>> y = numpy.zeros(5)    >>> y array([ 0.,  0.,  0.,  0.,  0.])   x is a 2-d array, and y is a 1-d array. They are both initialized with zeros.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  An easy solution is x = [None]*length, but note that it initializes all list elements to None. If the size is really fixed, you can do x=[None,None,None,None,None] as well. But strictly speaking, you won't get undefined elements either way because this plague doesn't exist in Python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  Well I would like to help you by posting a sample program and its output  Program:  t = input(\"\") x = [None]*t y = [[None]*t]*t  for i in range(1, t+1):     x[i-1] = i;      for j in range(1, t+1):         y[i-1][j-1] = j;  print x print y   Output :-  2 [1, 2] [[1, 2], [1, 2]]   I hope this clears some very basic concept of yours regarding their declaration. To initialize them with some other specific values, like initializing them with 0.. you can declare them as:  x = [0]*10   Hope it helps..!! ;)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  >>> n = 5                     #length of list >>> list = [None] * n         #populate list, length n with n entries \"None\" >>> print(list) [None, None, None, None, None]  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [None, None, None, None, 1]  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [None, None, None, 1, 1]  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [None, None, 1, 1, 1]   or with really nothing in the list to begin with:  >>> n = 5                     #length of list >>> list = []                 # create list >>> print(list) []  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [1]   on the 4th iteration of append:  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [1,1,1,1]   5 and all subsequent:  >>> list.append(1)            #append 1 to right side of list >>> list = list[-n:]          #redefine list as the last n elements of list >>> print(list) [1,1,1,1,1]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  You can try using Descriptor, to limit the size  class fixedSizeArray(object):     def __init__(self, arraySize=5):         self.arraySize = arraySize         self.array = [None] * self.arraySize      def __repr__(self):         return str(self.array)      def __get__(self, instance, owner):         return self.array      def append(self, index=None, value=None):         print \"Append Operation cannot be performed on fixed size array\"         return      def insert(self, index=None, value=None):         if not index and index - 1 not in xrange(self.arraySize):             print 'invalid Index or Array Size Exceeded'             return         try:             self.array[index] = value         except:             print 'This is Fixed Size Array: Please Use the available Indices'   arr = fixedSizeArray(5) print arr arr.append(100) print arr arr.insert(1, 200) print arr arr.insert(5, 300) print arr   OUTPUT:  [None, None, None, None, None] Append Operation cannot be performed on fixed size array [None, None, None, None, None] [None, 200, None, None, None] This is Fixed Size Array: Please Use the available Indices [None, 200, None, None, None]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  One thing I find easy to do is i set an array of empty strings for the size I prefer, for example  Code:  import numpy as np  x= np.zeros(5,str) print x   Output:  ['' '' '' '' '']   Hope this is helpful :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Initialising an array of fixed size in python [duplicate]",
        "A_Content": "  If you are working with bytes you could use the builtin bytearray. If you are working with other integral types look at the builtin array.  Specifically understand that a list is not an array.  If, for example, you are trying to create a buffer for reading file contents into you could use bytearray as follows (there are better ways to do this but the example is valid):  with open(FILENAME, 'rb') as f:     data = bytearray(os.path.getsize(FILENAME))     f.readinto(data)   In this snippet the bytearray memory is preallocated with the fixed length of FILENAMEs size in bytes. This preallocation allows the use of the buffer protocol to more efficiently read the file into a mutable buffer without an array copy. There are yet better ways to do this but I believe this provides one answer to your question.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/6142689/initialising-an-array-of-fixed-size-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Create an empty list in python with certain size                                        13 answers                                          I would like to know how i can initialise an array(or list), yet to be populated with values, to have a defined size.  for example in C:  int x[5]; /* declared without adding elements*/   How do i do that in python?  Thanks.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  It should just be  name[0].firstChild.nodeValue      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "130",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  Probably something like this if it's the text part you want...  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name')  print \" \".join(t.nodeValue for t in name[0].childNodes if t.nodeType == t.TEXT_NODE)   The text part of a node is considered a node in itself placed as a child-node of the one you asked for. Thus you will want to go through all its children and find all child nodes that are text nodes. A node can have several text nodes; eg.  <name>   blabla   <somestuff>asdf</somestuff>   znylpx </name>   You want both 'blabla' and 'znylpx'; hence the \" \".join(). You might want to replace the space with a newline or so, or perhaps by nothing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  you can use something like this.It worked out for me  doc = parse('C:\\\\eve.xml') my_node_list = doc.getElementsByTagName(\"name\") my_n_node = my_node_list[0] my_child = my_n_node.firstChild my_text = my_child.data  print my_text      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  I know this question is pretty old now, but I thought you might have an easier time with ElementTree  from xml.etree import ElementTree as ET import datetime  f = ET.XML(data)  for element in f:     if element.tag == \"currentTime\":         # Handle time data was pulled         currentTime = datetime.datetime.strptime(element.text, \"%Y-%m-%d %H:%M:%S\")     if element.tag == \"cachedUntil\":         # Handle time until next allowed update         cachedUntil = datetime.datetime.strptime(element.text, \"%Y-%m-%d %H:%M:%S\")     if element.tag == \"result\":         # Process list of skills         pass   I know that's not super specific, but I just discovered it, and so far it's a lot easier to get my head around than the minidom (since so many nodes are essentially white space).  For instance, you have the tag name and the actual text together, just as you'd probably expect:  >>> element[0] <Element currentTime at 40984d0> >>> element[0].tag 'currentTime' >>> element[0].text '2010-04-12 02:45:45'e      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  The above answer is correct, namely:  name[0].firstChild.nodeValue   However for me, like others, my value was further down the tree:  name[0].firstChild.firstChild.nodeValue   To find this I used the following:  def scandown( elements, indent ):     for el in elements:         print(\"   \" * indent + \"nodeName: \" + str(el.nodeName) )         print(\"   \" * indent + \"nodeValue: \" + str(el.nodeValue) )         print(\"   \" * indent + \"childNodes: \" + str(el.childNodes) )         scandown(el.childNodes, indent + 1)  scandown( doc.getElementsByTagName('text'), 0 )   Running this for my simple SVG file created with Inkscape this gave me:  nodeName: text nodeValue: None childNodes: [<DOM Element: tspan at 0x10392c6d0>]    nodeName: tspan    nodeValue: None    childNodes: [<DOM Text node \"'MY STRING'\">]       nodeName: #text       nodeValue: MY STRING       childNodes: () nodeName: text nodeValue: None childNodes: [<DOM Element: tspan at 0x10392c800>]    nodeName: tspan    nodeValue: None    childNodes: [<DOM Text node \"'MY WORDS'\">]       nodeName: #text       nodeValue: MY WORDS       childNodes: ()   I used xml.dom.minidom, the various fields are explained on this page, MiniDom Python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  I had a similar case, what worked for me was:  name.firstChild.childNodes[0].data  XML is supposed to be simple and it really is and I don't know why python's minidom did it so complicated... but it's how it's made     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  Here is a slightly modified answer of Henrik's for multiple nodes (ie. when getElementsByTagName returns more than one instance)  images = xml.getElementsByTagName(\"imageUrl\") for i in images:     print \" \".join(t.nodeValue for t in i.childNodes if t.nodeType == t.TEXT_NODE)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get Element value with minidom with Python",
        "A_Content": "  The question has been answered, my contribution consists in clarifying one thing that may confuse beginners:  Some of the suggested and correct answers used firstChild.data and others used firstChild.nodeValue instead. In case you are wondering what is the different between them, you should remember they do the same thing because nodeValue is just an alias for data.  The reference to my statement can be found as a comment on the source code of minidom:     #nodeValue is an alias for data      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dom",
            "minidom"
        ],
        "URL": "https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am creating a GUI frontend for the Eve Online API in Python.  I have successfully pulled the XML data from their server.  I am trying to grab the value from a node called \"name\":  from xml.dom.minidom import parse dom = parse(\"C:\\\\eve.xml\") name = dom.getElementsByTagName('name') print name   This seems to find the node, but the output is below:  [<DOM Element: name at 0x11e6d28>]   How could I get it to print the value of the node?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Asserting successive calls to a mock method",
        "A_Content": "  You can use the Mock.call_args_list attribute to compare parameters to previous method calls. That in conjunction with Mock.call_count attribute should give you full control.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/7242433/asserting-successive-calls-to-a-mock-method",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Mock has a helpful assert_called_with() method. However, as far as I understand this only checks the last call to a method. If I have code that calls the mocked method 3 times successively, each time with different parameters, how can I assert these 3 calls with their specific parameters?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Asserting successive calls to a mock method",
        "A_Content": "  assert_has_calls is another approach to this problem.  From the docs:     assert_has_calls (calls, any_order=False)      assert the mock has been   called with the specified calls. The mock_calls list is checked for   the calls.      If any_order is False (the default) then the calls must be sequential.   There can be extra calls before or after the specified calls.      If any_order is True then the calls can be in any order, but they must   all appear in mock_calls.   Example:  >>> from mock import call, Mock >>> mock = Mock(return_value=None) >>> mock(1) >>> mock(2) >>> mock(3) >>> mock(4) >>> calls = [call(2), call(3)] >>> mock.assert_has_calls(calls) >>> calls = [call(4), call(2), call(3)] >>> mock.assert_has_calls(calls, any_order=True)   Source: http://www.voidspace.org.uk/python/mock/mock.html#mock.Mock.assert_has_calls     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/7242433/asserting-successive-calls-to-a-mock-method",
        "A_Votes": "106",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Mock has a helpful assert_called_with() method. However, as far as I understand this only checks the last call to a method. If I have code that calls the mocked method 3 times successively, each time with different parameters, how can I assert these 3 calls with their specific parameters?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Asserting successive calls to a mock method",
        "A_Content": "  Usually, I don't care about the order of the calls, only that they happened. In that case, I  combine assert_any_call with an assertion about call_count.  >>> import mock >>> m = mock.Mock() >>> m(1) <Mock name='mock()' id='37578160'> >>> m(2) <Mock name='mock()' id='37578160'> >>> m(3) <Mock name='mock()' id='37578160'> >>> m.assert_any_call(1) >>> m.assert_any_call(2) >>> m.assert_any_call(3) >>> assert 3 == m.call_count >>> m.assert_any_call(4) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"[python path]\\lib\\site-packages\\mock.py\", line 891, in assert_any_call     '%s call not found' % expected_string AssertionError: mock(4) call not found   I find doing it this way to be easier to read and understand than a large list of calls passed into a single method.  If you do care about order or you expect multiple identical calls, assert_has_calls might be more appropriate.  Edit  Since I posted this answer, I've rethought my approach to testing in general. I think it's worth mentioning that if your test is getting this complicated, you may be testing inappropriately or have a design problem. Mocks are designed for testing inter-object communication in an object oriented design. If your design is not objected oriented (as in more procedural or functional), the mock may be totally inappropriate. You may also have too much going on inside the method, or you might be testing internal details that are best left unmocked. I developed the strategy mentioned in this method when my code was not very object oriented, and I believe I was also testing internal details that would have been best left unmocked.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/7242433/asserting-successive-calls-to-a-mock-method",
        "A_Votes": "69",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Mock has a helpful assert_called_with() method. However, as far as I understand this only checks the last call to a method. If I have code that calls the mocked method 3 times successively, each time with different parameters, how can I assert these 3 calls with their specific parameters?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Asserting successive calls to a mock method",
        "A_Content": "  I always have to look this one up time and time again, so here is my answer.      Asserting multiple method calls on different objects of the same class  Suppose we have a heavy duty class (which we want to mock):   In [1]: class HeavyDuty(object):    ...:     def __init__(self):    ...:         import time    ...:         time.sleep(2)  # <- Spends a lot of time here    ...:         ...:     def do_work(self, arg1, arg2):    ...:         print(\"Called with %r and %r\" % (arg1, arg2))    ...:     here is some code that uses two instances of the  HeavyDuty class:  In [2]: def heavy_work():    ...:     hd1 = HeavyDuty()    ...:     hd1.do_work(13, 17)    ...:     hd2 = HeavyDuty()    ...:     hd2.do_work(23, 29)    ...:          Now, here is a test case for the heavy_work function:  In [3]: from unittest.mock import patch, call    ...: def test_heavy_work():    ...:     expected_calls = [call.do_work(13, 17),call.do_work(23, 29)]    ...:         ...:     with patch('__main__.HeavyDuty') as MockHeavyDuty:    ...:         heavy_work()    ...:         MockHeavyDuty.return_value.assert_has_calls(expected_calls)    ...:     We are mocking the HeavyDuty class with MockHeavyDuty. To assert method calls coming from every HeavyDuty instance we have to refer to MockHeavyDuty.return_value.assert_has_calls,  instead of MockHeavyDuty.assert_has_calls.   In addition, in the list of expected_calls we have to specify which method name we are interested in asserting calls for.  So our list is made of calls to call.do_work, as opposed to simply call.   Exercising the test case shows us it is successful:  In [4]: print(test_heavy_work()) None     If we modify the heavy_work function, the test fails and produces a helpful error message:  In [5]: def heavy_work():    ...:     hd1 = HeavyDuty()    ...:     hd1.do_work(113, 117)  # <- call args are different    ...:     hd2 = HeavyDuty()    ...:     hd2.do_work(123, 129)  # <- call args are different    ...:       In [6]: print(test_heavy_work()) --------------------------------------------------------------------------- (traceback omitted for clarity)  AssertionError: Calls not found. Expected: [call.do_work(13, 17), call.do_work(23, 29)] Actual: [call.do_work(113, 117), call.do_work(123, 129)]     Asserting multiple calls to a function  To contrast with the above, here is an example that shows how to mock multiple calls to a function:  In [7]: def work_function(arg1, arg2):    ...:     print(\"Called with args %r and %r\" % (arg1, arg2))  In [8]: from unittest.mock import patch, call    ...: def test_work_function():    ...:     expected_calls = [call(13, 17), call(23, 29)]        ...:     with patch('__main__.work_function') as mock_work_function:    ...:         work_function(13, 17)    ...:         work_function(23, 29)    ...:         mock_work_function.assert_has_calls(expected_calls)    ...:      In [9]: print(test_work_function()) None     There are two main differences.  The first one is that when mocking a function we setup our expected calls using call,  instead of using call.some_method.  The second one is that we call assert_has_calls on mock_work_function, instead of on mock_work_function.return_value.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/7242433/asserting-successive-calls-to-a-mock-method",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Mock has a helpful assert_called_with() method. However, as far as I understand this only checks the last call to a method. If I have code that calls the mocked method 3 times successively, each time with different parameters, how can I assert these 3 calls with their specific parameters?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How can I time a code segment for testing performance with Pythons timeit?",
        "A_Content": "  You can use time.time() or time.clock() before and after the block you want to time.  import time  t0 = time.time() code_block t1 = time.time()  total = t1-t0   This method is not as exact as timeit (it does not average several runs) but it is straightforward.   time.time() (in Windows and Linux) and time.clock() (in Linux) are not precise enough for fast functions (you get total = 0). In this case or if you want to average the time elapsed by several runs, you have to manually call the function multiple times (As I think you already do in you example code and timeit does automatically when you set its number argument)  import time  def myfast():    code  n = 10000 t0 = time.time() for i in range(n): myfast() t1 = time.time()  total_n = t1-t0   In Windows, as Corey stated in the comment, time.clock() has much higher precision (microsecond instead of second) and is preferred over time.time().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "testing",
            "timeit",
            "database-tuning"
        ],
        "URL": "https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit",
        "A_Votes": "175",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use timeit but I can't seem to get it to work.  My Python script looks like this:  import sys import getopt import timeit import random import os import re import ibm_db import time from string import maketrans myfile = open(\"results_update.txt\", \"a\")  for r in range(100):     rannumber = random.randint(0, 100)      update = \"update TABLE set val = %i where MyCount >= '2010' and MyCount < '2012' and number = '250'\" % rannumber     #print rannumber      conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")  for r in range(5):     print \"Run %s\\n\" % r             ibm_db.execute(query_stmt)  query_stmt = ibm_db.prepare(conn, update)  myfile.close() ibm_db.close(conn)   What I need is the time it takes to execute the query and write it to the file results_update.txt. The purpose is to test an update statement for my database with different indexes and tuning mechanisms.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How can I time a code segment for testing performance with Pythons timeit?",
        "A_Content": "  If you are profiling your code and can use IPython, it has the magic function %timeit.  %%timeit operates on cells.  In [2]: %timeit cos(3.14) 10000000 loops, best of 3: 160 ns per loop  In [3]: %%timeit    ...: cos(3.14)    ...: x = 2 + 3    ...:  10000000 loops, best of 3: 196 ns per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "testing",
            "timeit",
            "database-tuning"
        ],
        "URL": "https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use timeit but I can't seem to get it to work.  My Python script looks like this:  import sys import getopt import timeit import random import os import re import ibm_db import time from string import maketrans myfile = open(\"results_update.txt\", \"a\")  for r in range(100):     rannumber = random.randint(0, 100)      update = \"update TABLE set val = %i where MyCount >= '2010' and MyCount < '2012' and number = '250'\" % rannumber     #print rannumber      conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")  for r in range(5):     print \"Run %s\\n\" % r             ibm_db.execute(query_stmt)  query_stmt = ibm_db.prepare(conn, update)  myfile.close() ibm_db.close(conn)   What I need is the time it takes to execute the query and write it to the file results_update.txt. The purpose is to test an update statement for my database with different indexes and tuning mechanisms.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How can I time a code segment for testing performance with Pythons timeit?",
        "A_Content": "  Quite apart from the timing, this code you show is simply incorrect: you execute 100 connections (completely ignoring all but the last one), and then when you do the first execute call you pass it a local variable query_stmt which you only initialize after the execute call.  First, make your code correct, without worrying about timing yet: i.e. a function that makes or receives a connection and performs 100 or 500 or whatever number of updates on that connection, then closes the connection. Once you have your code working correctly is the correct point at which to think about using timeit on it!  Specifically, if the function you want to time is a parameter-less one called foobar you can use timeit.timeit (2.6 or later -- it's more complicated in 2.5 and before):  timeit.timeit('foobar()', number=1000)   You'd better specify the number of runs because the default, a million, may be high for your use case (leading to spending a lot of time in this code;-).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "testing",
            "timeit",
            "database-tuning"
        ],
        "URL": "https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use timeit but I can't seem to get it to work.  My Python script looks like this:  import sys import getopt import timeit import random import os import re import ibm_db import time from string import maketrans myfile = open(\"results_update.txt\", \"a\")  for r in range(100):     rannumber = random.randint(0, 100)      update = \"update TABLE set val = %i where MyCount >= '2010' and MyCount < '2012' and number = '250'\" % rannumber     #print rannumber      conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")  for r in range(5):     print \"Run %s\\n\" % r             ibm_db.execute(query_stmt)  query_stmt = ibm_db.prepare(conn, update)  myfile.close() ibm_db.close(conn)   What I need is the time it takes to execute the query and write it to the file results_update.txt. The purpose is to test an update statement for my database with different indexes and tuning mechanisms.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How can I time a code segment for testing performance with Pythons timeit?",
        "A_Content": "  Focus on one specific thing. Disk I/O is slow, so I'd take that out of the test if all you are going to tweak is the database query.  And if you need to time your database execution, look for database tools instead, like asking for the query plan, and note that performance varies not only with the exact query and what indexes you have, but also with the data load (how much data you have stored).  That said, you can simply put your code in a function and run that function with timeit.timeit():  def function_to_repeat():     # ...  duration = timeit.timeit(function_to_repeat, number=1000)   This would disable the garbage collection, repeatedly call the function_to_repeat() function, and time the total duration of those calls using timeit.default_timer(), which is the most accurate available clock for your specific platform.  You should move setup code out of the repeated function; for example, you should connect to the database first, then time only the queries. Use the setup argument to either import or create those dependencies, and pass them into your function:  def function_to_repeat(var1, var2):     # ...  duration = timeit.timeit(     'function_to_repeat(var1, var2)',     'from __main__ import function_to_repeat, var1, var2',      number=1000)   would grab the globals function_to_repeat, var1 and var2 from your script and pass those to the function each repetition.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "testing",
            "timeit",
            "database-tuning"
        ],
        "URL": "https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use timeit but I can't seem to get it to work.  My Python script looks like this:  import sys import getopt import timeit import random import os import re import ibm_db import time from string import maketrans myfile = open(\"results_update.txt\", \"a\")  for r in range(100):     rannumber = random.randint(0, 100)      update = \"update TABLE set val = %i where MyCount >= '2010' and MyCount < '2012' and number = '250'\" % rannumber     #print rannumber      conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")  for r in range(5):     print \"Run %s\\n\" % r             ibm_db.execute(query_stmt)  query_stmt = ibm_db.prepare(conn, update)  myfile.close() ibm_db.close(conn)   What I need is the time it takes to execute the query and write it to the file results_update.txt. The purpose is to test an update statement for my database with different indexes and tuning mechanisms.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How can I time a code segment for testing performance with Pythons timeit?",
        "A_Content": "  I see the question has already been answered, but still want to add my 2 cents for the same.  I have also faced similar scenario in which I have to test the execution times for several approaches and hence written a small script, which calls timeit on all functions written in it.  The script is also available as github gist here.  Hope it will help you and others.  from random import random import types  def list_without_comprehension():     l = []     for i in xrange(1000):         l.append(int(random()*100 % 100))     return l  def list_with_comprehension():     # 1K random numbers between 0 to 100     l = [int(random()*100 % 100) for _ in xrange(1000)]     return l   # operations on list_without_comprehension def sort_list_without_comprehension():     list_without_comprehension().sort()  def reverse_sort_list_without_comprehension():     list_without_comprehension().sort(reverse=True)  def sorted_list_without_comprehension():     sorted(list_without_comprehension())   # operations on list_with_comprehension def sort_list_with_comprehension():     list_with_comprehension().sort()  def reverse_sort_list_with_comprehension():     list_with_comprehension().sort(reverse=True)  def sorted_list_with_comprehension():     sorted(list_with_comprehension())   def main():     objs = globals()     funcs = []     f = open(\"timeit_demo.sh\", \"w+\")      for objname in objs:         if objname != 'main' and type(objs[objname]) == types.FunctionType:             funcs.append(objname)     funcs.sort()     for func in funcs:         f.write('''echo \"Timing: %(funcname)s\" python -m timeit \"import timeit_demo; timeit_demo.%(funcname)s();\"\\n\\n echo \"------------------------------------------------------------\" ''' % dict(                 funcname = func,                 )             )      f.close()  if __name__ == \"__main__\":     main()      from os import system      #Works only for *nix platforms     system(\"/bin/bash timeit_demo.sh\")      #un-comment below for windows     #system(\"cmd timeit_demo.sh\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "testing",
            "timeit",
            "database-tuning"
        ],
        "URL": "https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use timeit but I can't seem to get it to work.  My Python script looks like this:  import sys import getopt import timeit import random import os import re import ibm_db import time from string import maketrans myfile = open(\"results_update.txt\", \"a\")  for r in range(100):     rannumber = random.randint(0, 100)      update = \"update TABLE set val = %i where MyCount >= '2010' and MyCount < '2012' and number = '250'\" % rannumber     #print rannumber      conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")  for r in range(5):     print \"Run %s\\n\" % r             ibm_db.execute(query_stmt)  query_stmt = ibm_db.prepare(conn, update)  myfile.close() ibm_db.close(conn)   What I need is the time it takes to execute the query and write it to the file results_update.txt. The purpose is to test an update statement for my database with different indexes and tuning mechanisms.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Histogram Matplotlib",
        "A_Content": "  import matplotlib.pyplot as plt import numpy as np  mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000) hist, bins = np.histogram(x, bins=50) width = 0.7 * (bins[1] - bins[0]) center = (bins[:-1] + bins[1:]) / 2 plt.bar(center, hist, align='center', width=width) plt.show()     The object-oriented interface is also straightforward:  fig, ax = plt.subplots() ax.bar(center, hist, align='center', width=width) fig.savefig(\"1.png\")     If you are using custom (non-constant) bins, you can pass compute the widths using np.diff, pass the widths to ax.bar and use ax.set_xticks to label the bin edges:  import matplotlib.pyplot as plt import numpy as np  mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000) bins = [0, 40, 60, 75, 90, 110, 125, 140, 160, 200] hist, bins = np.histogram(x, bins=bins) width = np.diff(bins) center = (bins[:-1] + bins[1:]) / 2  fig, ax = plt.subplots(figsize=(8,3)) ax.bar(center, hist, align='center', width=width) ax.set_xticks(bins) fig.savefig(\"/tmp/out.png\")  plt.show()        ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/5328556/histogram-matplotlib",
        "A_Votes": "212",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    So I have a little problem. I have a data set in scipy that is already in the histogram format, so I have the center of the bins and the number of events per bin. How can I now plot is as a histogram. I tried just doing   bins, n=hist()   but it didn't like that. Any recommendations?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Histogram Matplotlib",
        "A_Content": "  If you don't want bars you can plot it like this:  import numpy as np import matplotlib.pyplot as plt  mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000)  bins, edges = np.histogram(x, 50, normed=1) left,right = edges[:-1],edges[1:] X = np.array([left,right]).T.flatten() Y = np.array([bins,bins]).T.flatten()  plt.plot(X,Y) plt.show()        ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/5328556/histogram-matplotlib",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I have a little problem. I have a data set in scipy that is already in the histogram format, so I have the center of the bins and the number of events per bin. How can I now plot is as a histogram. I tried just doing   bins, n=hist()   but it didn't like that. Any recommendations?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Histogram Matplotlib",
        "A_Content": "  I know this does not answer your question, but I always end up on this page, when I search for the matplotlib solution to histograms, because the simple histogram_demo was removed from the matplotlib example gallery page.  Here is a solution, which doesn't require numpy to be imported. I only import numpy to generate the data x to be plotted. It relies on the function hist instead of the function bar as in the answer by @unutbu.  import numpy as np mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000)  import matplotlib.pyplot as plt plt.hist(x, bins=50) plt.savefig('hist.png')     Also check out the matplotlib gallery and the matplotlib examples.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/5328556/histogram-matplotlib",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I have a little problem. I have a data set in scipy that is already in the histogram format, so I have the center of the bins and the number of events per bin. How can I now plot is as a histogram. I tried just doing   bins, n=hist()   but it didn't like that. Any recommendations?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Histogram Matplotlib",
        "A_Content": "  If you're willing to use pandas:  pandas.DataFrame({'x':hist[1][1:],'y':hist[0]}).plot(x='x',kind='bar')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/5328556/histogram-matplotlib",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I have a little problem. I have a data set in scipy that is already in the histogram format, so I have the center of the bins and the number of events per bin. How can I now plot is as a histogram. I tried just doing   bins, n=hist()   but it didn't like that. Any recommendations?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Histogram Matplotlib",
        "A_Content": "  I think this might be useful for someone.  Numpy's histogram function, to my annoyance (although, I appreciate there is a good reason for it), returns back the edges of each bin, rather than the value of the bin. While, this makes sense for floating-point numbers, which can lie within an interval (i.e. the center value is not super meaningful), this is not the desired output when dealing with discrete values or integers (0, 1, 2, etc). In particular, the length of bins returned from np.histogram is not equal to the length of the counts / density.  To get around this, I used np.digitize to quantize the input, and return a discrete number of bins, along with fraction of counts for each bin. You could easily edit to get the integer number of counts.  def compute_PMF(data)     import numpy as np     from collections import Counter     _, bins = np.histogram(data, bins='auto', range=(data.min(), data.max()), density=False)     h = Counter(np.digitize(data,bins) - 1)     weights = np.asarray(list(h.values()))      weights = weights / weights.sum()     values = np.asarray(list(h.keys()))     return weights, values ####   Refs:  [1] https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html  [2] https://docs.scipy.org/doc/numpy/reference/generated/numpy.digitize.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/5328556/histogram-matplotlib",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So I have a little problem. I have a data set in scipy that is already in the histogram format, so I have the center of the bins and the number of events per bin. How can I now plot is as a histogram. I tried just doing   bins, n=hist()   but it didn't like that. Any recommendations?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "UnicodeDecodeError when redirecting to file",
        "A_Content": "  The whole key to such encoding problems is to understand that there are in principle two distinct concepts of \"string\": (1) string of characters, and (2) string/array of bytes. This distinction has been mostly ignored for a long time because of the historic ubiquity of encodings with no more than 256 characters (ASCII, Latin-1, Windows-1252, Mac OS Roman,…): these encodings map a set of common characters to numbers between 0 and 255 (i.e. bytes); the relatively limited exchange of files before the advent of the web made this situation of incompatible encodings tolerable, as most programs could ignore the fact that there were multiple encodings as long as they produced text that remained on the same operating system: such programs would simply treat text as bytes (through the encoding used by the operating system). The correct, modern view properly separates these two string concepts, based on the following two points:   Characters are mostly unrelated to computers: one can draw them on a chalk board, etc., like for instance بايثون, 中蟒 and \uD83D\uDC0D.  \"Characters\" for machines also include \"drawing instructions\" like for example spaces, carriage return, instructions to set the writing direction (for Arabic, etc.), accents, etc. A very large character list is included in the Unicode standard; it covers most of the known characters. On the other hand, computers do need to represent abstract characters in some way: for this, they use arrays of bytes (numbers between 0 and 255 included), because their memory comes in byte chunks. The necessary process that converts characters to bytes is called encoding.  Thus, a computer requires an encoding in order to represent characters.  Any text present on your computer is encoded (until it is displayed), whether it be sent to a terminal (which expects characters encoded in a specific way), or saved in a file.  In order to be displayed or properly \"understood\" (by, say, the Python interpreter), streams of bytes are decoded into characters. A few encodings (UTF-8, UTF-16,…) are defined by Unicode for its list of characters (Unicode thus defines both a list of characters and encodings for these characters—there are still places where one sees the expression \"Unicode encoding\" as a way to refer to the ubiquitous UTF-8, but this is incorrect terminology, as Unicode provides multiple encodings).   In summary, computers need to internally represent characters with bytes, and they do so through two operations:     Encoding: characters → bytes      Decoding: bytes → characters   Some encodings cannot encode all characters (e.g., ASCII), while (some) Unicode encodings allow you to encode all Unicode characters. The encoding is also not necessarily unique, because some characters can be represented either directly or as a combination (e.g. of a base character and of accents).  Note that the concept of newline adds a layer of complication, since it can be represented by different (control) characters that depend on the operating system (this is the reason for Python's universal newline file reading mode).  Now, what I have called \"character\" above is what Unicode calls a \"user-perceived character\". A single user-perceived character can sometimes be represented in Unicode by combining character parts (base character, accents,…) found at different indexes in the Unicode list, which are called \"code points\"—these codes points can be combined together to form a \"grapheme cluster\".  Unicode thus leads to a third concept of string, made of a sequence of Unicode code points, that sits between byte and character strings, and which is closer to the latter. I will call them \"Unicode strings\" (like in Python 2).  While Python can print strings of (user-perceived) characters, Python non-byte strings are essentially sequences of Unicode code points, not of user-perceived characters. The code point values are the ones used in Python's \\u and \\U Unicode string syntax.  They should not be confused with the encoding of a character (and do not have to bear any relationship with it: Unicode code points can be encoded in various ways).   This has an important consequence: the length of a Python (Unicode) string is its number of code points, which is not always its number of user-perceived characters: thus s = \"\\u1100\\u1161\\u11a8\"; print(s, \"len\", len(s)) (Python 3) gives 각 len 3 despite s having a single user-perceived (Korean) character (because it is represented with 3 code points—even if it does not have to, as print(\"\\uac01\") shows). However, in many practical circumstances, the length of a string is its number of user-perceived characters, because many characters are typically stored by Python as a single Unicode code point.  In Python 2, Unicode strings are called… \"Unicode strings\" (unicode type, literal form u\"…\"), while byte arrays are \"strings\" (str type, where the array of bytes can for instance be constructed with string literals \"…\").  In Python 3, Unicode strings are simply called \"strings\" (str type, literal form \"…\"), while byte arrays are \"bytes\" (bytes type, literal form b\"…\").  With these few key points, you should be able to understand most encoding related questions!    Normally, when you print u\"…\" to a terminal, you should not get garbage: Python knows the encoding of your terminal.  In fact, you can check what encoding the terminal expects:  % python Python 2.7.6 (default, Nov 15 2013, 15:20:37)  [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.2.79)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sys >>> print sys.stdout.encoding UTF-8   If your input characters can be encoded with the terminal's encoding, Python will do so and will send the corresponding bytes to your terminal without complaining. The terminal will then do its best to display the characters after decoding the input bytes (at worst the terminal font does not have some of the characters and will print some kind of blank instead).  If your input characters cannot be encoded with the terminal's encoding, then it means that the terminal is not configured for displaying these characters. Python will complain (in Python with a UnicodeEncodeError since the character string cannot be encoded in a way that suits your terminal). The only possible solution is to use a terminal that can display the characters (either by configuring the terminal so that it accepts an encoding that can represent your characters, or by using a different terminal program). This is important when you distribute programs that can be used in different environments: messages that you print should be representable in the user's terminal. Sometimes it is thus best to stick to strings that only contain ASCII characters.  However, when you redirect or pipe the output of your program, then it is generally not possible to know what the input encoding of the receiving program is, and the above code returns some default encoding: None (Python 2.7) or UTF-8 (Python 3):  % python2.7 -c \"import sys; print sys.stdout.encoding\" | cat None % python3.4 -c \"import sys; print(sys.stdout.encoding)\" | cat UTF-8   The encoding of stdin, stdout and stderr can however be set through the PYTHONIOENCODING environment variable, if needed:  % PYTHONIOENCODING=UTF-8 python2.7 -c \"import sys; print sys.stdout.encoding\" | cat UTF-8     If the printing to a terminal does not produce what you expect, you can check the UTF-8 encoding that you put manually in is correct; for instance, your first character (\\u001A) is not printable, if I'm not mistaken.  At http://wiki.python.org/moin/PrintFails, you can find a solution like the following, for Python 2.x:  import codecs import locale import sys  # Wrap sys.stdout into a StreamWriter to allow writing unicode. sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout)   uni = u\"\\u001A\\u0BC3\\u1451\\U0001D10C\" print uni   For Python 3, you can check one of the questions asked previously on StackOverflow.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/4545661/unicodedecodeerror-when-redirecting-to-file",
        "A_Votes": "236",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I run this snippet twice, in the Ubuntu terminal (encoding set to utf-8), once with ./test.py and then with ./test.py >out.txt:  uni = u\"\\u001A\\u0BC3\\u1451\\U0001D10C\" print uni   Without redirection it prints garbage. With redirection I get a UnicodeDecodeError. Can someone explain why I get the error only in the second case, or even better give a detailed explanation of what's going on behind the curtain in both cases?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "UnicodeDecodeError when redirecting to file",
        "A_Content": "  Python always encodes Unicode strings when writing to a terminal, file, pipe, etc.  When writing to a terminal Python can usually determine the encoding of the terminal and use it correctly.  When writing to a file or pipe Python defaults to the 'ascii' encoding unless explicitly told otherwise.  Python can be told what to do when piping output through the PYTHONIOENCODING environment variable.  A shell can set this variable before redirecting Python output to a file or pipe so the correct encoding is known.  In your case you've printed 4 uncommon characters that your terminal didn't support in its font.  Here's some examples to help explain the behavior, with characters that are actually supported by my terminal (which uses cp437, not UTF-8).  Example 1  Note that the #coding comment indicates the encoding in which the source file is saved.  I chose utf8 so I could support characters in source that my terminal could not.  Encoding redirected to stderr so it can be seen when redirected to a file.  #coding: utf8 import sys uni = u'αßΓπΣσµτΦΘΩδ∞φ' print >>sys.stderr,sys.stdout.encoding print uni   Output (run directly from terminal)  cp437 αßΓπΣσµτΦΘΩδ∞φ   Python correctly determined the encoding of the terminal.  Output (redirected to file)  None Traceback (most recent call last):   File \"C:\\ex.py\", line 5, in <module>     print uni UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-13: ordinal not in range(128)   Python could not determine encoding (None) so used 'ascii' default.  ASCII only supports converting the first 128 characters of Unicode.  Output (redirected to file, PYTHONIOENCODING=cp437)  cp437   and my output file was correct:  C:\\>type out.txt αßΓπΣσµτΦΘΩδ∞φ   Example 2  Now I'll throw in a character in the source that isn't supported by my terminal:  #coding: utf8 import sys uni = u'αßΓπΣσµτΦΘΩδ∞φ马' # added Chinese character at end. print >>sys.stderr,sys.stdout.encoding print uni   Output (run directly from terminal)  cp437 Traceback (most recent call last):   File \"C:\\ex.py\", line 5, in <module>     print uni   File \"C:\\Python26\\lib\\encodings\\cp437.py\", line 12, in encode     return codecs.charmap_encode(input,errors,encoding_map) UnicodeEncodeError: 'charmap' codec can't encode character u'\\u9a6c' in position 14: character maps to <undefined>   My terminal didn't understand that last Chinese character.  Output (run directly, PYTHONIOENCODING=437:replace)  cp437 αßΓπΣσµτΦΘΩδ∞φ?   Error handlers can be specified with the encoding.  In this case unknown characters were replaced with ?.  ignore and xmlcharrefreplace are some other options.  When using UTF8 (which supports encoding all Unicode characters) replacements will never be made, but the font used to display the characters must still support them.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/4545661/unicodedecodeerror-when-redirecting-to-file",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I run this snippet twice, in the Ubuntu terminal (encoding set to utf-8), once with ./test.py and then with ./test.py >out.txt:  uni = u\"\\u001A\\u0BC3\\u1451\\U0001D10C\" print uni   Without redirection it prints garbage. With redirection I get a UnicodeDecodeError. Can someone explain why I get the error only in the second case, or even better give a detailed explanation of what's going on behind the curtain in both cases?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "UnicodeDecodeError when redirecting to file",
        "A_Content": "  Encode it while printing  uni = u\"\\u001A\\u0BC3\\u1451\\U0001D10C\" print uni.encode(\"utf-8\")   This is because when you run the script manually python encodes it before outputting it to terminal, when you pipe it python does not encode it itself so you have to encode manually when doing I/O.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/4545661/unicodedecodeerror-when-redirecting-to-file",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I run this snippet twice, in the Ubuntu terminal (encoding set to utf-8), once with ./test.py and then with ./test.py >out.txt:  uni = u\"\\u001A\\u0BC3\\u1451\\U0001D10C\" print uni   Without redirection it prints garbage. With redirection I get a UnicodeDecodeError. Can someone explain why I get the error only in the second case, or even better give a detailed explanation of what's going on behind the curtain in both cases?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  In [1]: df Out[1]:     Sp  Mt Value  count 0  MM1  S1     a      3 1  MM1  S1     n      2 2  MM1  S3    cb      5 3  MM2  S3    mk      8 4  MM2  S4    bg     10 5  MM2  S4   dgd      1 6  MM4  S2    rd      2 7  MM4  S2    cb      2 8  MM4  S2   uyi      7  In [2]: df.groupby(['Mt'], sort=False)['count'].max() Out[2]: Mt S1     3 S3     8 S4    10 S2     7 Name: count   To get the indices of the original DF you can do:  In [3]: idx = df.groupby(['Mt'])['count'].transform(max) == df['count']  In [4]: df[idx] Out[4]:     Sp  Mt Value  count 0  MM1  S1     a      3 3  MM2  S3    mk      8 4  MM2  S4    bg     10 8  MM4  S2   uyi      7   Note that if you have multiple max values per group, all will be returned.  Update  On a hail mary chance that this is what the OP is requesting:  In [5]: df['count_max'] = df.groupby(['Mt'])['count'].transform(max)  In [6]: df Out[6]:     Sp  Mt Value  count  count_max 0  MM1  S1     a      3          3 1  MM1  S1     n      2          3 2  MM1  S3    cb      5          8 3  MM2  S3    mk      8          8 4  MM2  S4    bg     10         10 5  MM2  S4   dgd      1         10 6  MM4  S2    rd      2          7 7  MM4  S2    cb      2          7 8  MM4  S2   uyi      7          7      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "147",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  You can sort the dataFrame by count and then remove duplicates. I think it's easier:  df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  Having tried the solution suggested by Zelazny on a relatively large DataFrame (~400k rows) I found it to be very slow.  Here is an alternative that I found to run orders of magnitude faster on my data set.  df = pd.DataFrame({     'sp' : ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],     'mt' : ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],     'val' : ['a', 'n', 'cb', 'mk', 'bg', 'dgb', 'rd', 'cb', 'uyi'],     'count' : [3,2,5,8,10,1,2,2,7]     })  df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})  df_grouped = df_grouped.reset_index()  df_grouped = df_grouped.rename(columns={'count':'count_max'})  df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])  df = df[df['count'] == df['count_max']]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  Easy solution would be to apply : idxmax() function to get indices of rows with max values.  This would filter out all the rows with max value in the group.  In [365]: import pandas as pd  In [366]: df = pd.DataFrame({ 'sp' : ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4','MM4'], 'mt' : ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'], 'val' : ['a', 'n', 'cb', 'mk', 'bg', 'dgb', 'rd', 'cb', 'uyi'], 'count' : [3,2,5,8,10,1,2,2,7] })  In [367]: df                                                                                                        Out[367]:     count  mt   sp  val 0      3  S1  MM1    a 1      2  S1  MM1    n 2      5  S3  MM1   cb 3      8  S3  MM2   mk 4     10  S4  MM2   bg 5      1  S4  MM2  dgb 6      2  S2  MM4   rd 7      2  S2  MM4   cb 8      7  S2  MM4  uyi   ### Apply idxmax() and use .loc() on dataframe to filter the rows with max values: In [368]: df.loc[df.groupby([\"sp\", \"mt\"])[\"count\"].idxmax()]                                                        Out[368]:     count  mt   sp  val 0      3  S1  MM1    a 2      5  S3  MM1   cb 3      8  S3  MM2   mk 4     10  S4  MM2   bg 8      7  S2  MM4  uyi  ### Just to show what values are returned by .idxmax() above: In [369]: df.groupby([\"sp\", \"mt\"])[\"count\"].idxmax().values                                                         Out[369]: array([0, 2, 3, 4, 8])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  For me, the easiest solution would be keep value when count is equal to the maximum. Therefore, the following one line command is enough :   df[df['count'] == df.groupby(['Mt'])['count'].transform(max)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  Use groupby and idxmax methods:   transfer col date to datetime:  df['date']=pd.to_datetime(df['date'])  get the index of max of column date, after groupyby ad_id:  idx=df.groupby(by='ad_id')['date'].idxmax()  get the wanted data:  df_max=df.loc[idx,]    Out[54]:  ad_id  price       date 7     22      2 2018-06-11 6     23      2 2018-06-22 2     24      2 2018-06-30 3     28      5 2018-06-22      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Python : Getting the Row which has the max value in groups using groupby",
        "A_Content": "  df = pd.DataFrame({ 'sp' : ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4','MM4'], 'mt' : ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'], 'val' : ['a', 'n', 'cb', 'mk', 'bg', 'dgb', 'rd', 'cb', 'uyi'], 'count' : [3,2,5,8,10,1,2,2,7] })  df.groupby(['sp', 'mt']).apply(lambda grp: grp.nlargest(1, 'count'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I hope I can find help for my question. I am searching for a solution for the following problem:  I have a dataFrame like:   Sp  Mt Value  count 0  MM1  S1   a      **3** 1  MM1  S1   n      2 2  MM1  S3   cb     5 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10** 5  MM2  S4   dgd      1 6  MM4  S2  rd     2 7  MM4  S2   cb      2 8  MM4  S2   uyi      **7**   My objective is to get the result rows whose count is max between the groups, like :  0  MM1  S1   a      **3** 1 3  MM2  S3   mk      **8** 4  MM2  S4   bg     **10**  8  MM4  S2   uyi      **7**   Somebody knows how can I do it in pandas or in python?  UPDATE  I didn't give more details for my question. For my problem, I want to group by ['Sp','Mt'].  Let take a second example like this :     Sp   Mt   Value  count 4  MM2  S4   bg     10 5  MM2  S4   dgd    1 6  MM4  S2   rd     2 7  MM4  S2   cb     8 8  MM4  S2   uyi    8   For the above example, I want to get ALL the rows where count equals max in each group e.g :  MM2  S4   bg     10 MM4  S2   cb     8 MM4  S2   uyi    8      ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  Assuming m is a string, you can use endswith:  if m.endswith('.mp3'): ... elif m.endswith('.flac'): ...   To be case-insensitive, and to eliminate a potentially large else-if chain:  m.lower().endswith(('.png', '.jpg', '.jpeg'))   (Thanks to Wilhem Murdoch for the list of args to endswith)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "215",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  os.path provides many functions for manipulating paths/filenames. (docs)  os.path.splitext takes a path and splits the file extension from the end of it.  import os  filepaths = [\"/folder/soundfile.mp3\", \"folder1/folder/soundfile.flac\"]  for fp in filepaths:     # Split the extension from the path and normalise it to lowercase.     ext = os.path.splitext(fp)[-1].lower()      # Now we can simply use == to check for equality, no need for wildcards.     if ext == \".mp3\":         print fp, \"is an mp3!\"     elif ext == \".flac\":         print fp, \"is a flac file!\"     else:         print fp, \"is an unknown file format.\"   Gives:   /folder/soundfile.mp3 is an mp3! folder1/folder/soundfile.flac is a flac file!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  Look at module fnmatch.  That will do what you're trying to do.  import fnmatch import os  for file in os.listdir('.'):     if fnmatch.fnmatch(file, '*.txt'):         print file      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  or perhaps:   from glob import glob ... for files in glob('path/*.mp3'):    do something for files in glob('path/*.flac'):    do something else      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  one easy way could be:  import os  if os.path.splitext(file)[1] == \".mp3\":     # do something   os.path.splitext(file) will return a tuple with two values (the filename without extension + just the extension). The second index ([1]) will therefor give you just the extension. The cool thing is, that this way you can also access the filename pretty easily, if needed!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  import os source = ['test_sound.flac','ts.mp3']  for files in source:    fileName,fileExtension = os.path.splitext(files)    print fileExtension   # Print File Extensions    print fileName   # It print file name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  if (file.split(\".\")[1] == \"mp3\"):     print \"its mp3\" elif (file.split(\".\")[1] == \"flac\"):     print \"its flac\" else:     print \"not compat\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  #!/usr/bin/python  import shutil, os  source = ['test_sound.flac','ts.mp3']  for files in source:   fileName,fileExtension = os.path.splitext(files)    if fileExtension==\".flac\" :     print 'This file is flac file %s' %files   elif  fileExtension==\".mp3\":     print 'This file is mp3 file %s' %files   else:     print 'Format is not valid'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  An old thread, but may help future readers...  I would avoid using .lower() on filenames if for no other reason than to make your code more platform independent. (linux is case sensistive, .lower() on a filename will surely corrupt your logic eventually ...or worse, an important file!)  Why not use re?  (Although to be even more robust, you should check the magic file header of each file... How to check type of files without extensions in python? )  import re  def checkext(fname):        if re.search('\\.mp3$',fname,flags=re.IGNORECASE):         return('mp3')     if re.search('\\.flac$',fname,flags=re.IGNORECASE):         return('flac')     return('skip')  flist = ['myfile.mp3', 'myfile.MP3','myfile.mP3','myfile.mp4','myfile.flack','myfile.FLAC',      'myfile.Mov','myfile.fLaC']  for f in flist:     print \"{} ==> {}\".format(f,checkext(f))    Output:  myfile.mp3 ==> mp3 myfile.MP3 ==> mp3 myfile.mP3 ==> mp3 myfile.mp4 ==> skip myfile.flack ==> skip myfile.FLAC ==> flac myfile.Mov ==> skip myfile.fLaC ==> flac      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Checking file extension",
        "A_Content": "  Use pathlib From Python3.4 onwards.  from pathlib import Path Path('my_file.mp3').suffix == '.mp3'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-extension"
        ],
        "URL": "https://stackoverflow.com/questions/5899497/checking-file-extension",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on a certain program and I need to have it do different things if the file in question is a flac file, or an mp3 file. Could I just use this?   if m == *.mp3    .... elif m == *.flac    ....   I'm not sure whether it will work.  EDIT: When I use that, it tells me invalid syntax. So what do I do?     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  import os def get_immediate_subdirectories(a_dir):     return [name for name in os.listdir(a_dir)             if os.path.isdir(os.path.join(a_dir, name))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "173",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  Why has no one mentioned glob? glob lets you use Unix-style pathname expansion, and is my go to function for almost everything that needs to find more than one path name. It makes it very easy:  from glob import glob paths = glob('*/')   Note that glob will return the directory with the final slash (as unix would) while most path based solutions will omit the final slash.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "51",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  import os, os.path   To get (full-path) immediate sub-directories in a directory:  def SubDirPath (d):     return filter(os.path.isdir, [os.path.join(d,f) for f in os.listdir(d)])   To get the latest (newest) sub-directory:  def LatestDirectory (d):     return max(SubDirPath(d), key=os.path.getmtime)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  Check \"Getting a list of all subdirectories in the current directory\".  Here's a Python 3 version:  import os  dir_list = next(os.walk('.'))[1]  print(dir_list)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  os.walk is your friend in this situation.  Straight from the documentation:     walk() generates the file names in a directory tree, by walking the tree either top down or bottom up. For each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).       ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  Using Twisted's FilePath module:  from twisted.python.filepath import FilePath  def subdirs(pathObj):     for subpath in pathObj.walk():         if subpath.isdir():             yield subpath  if __name__ == '__main__':     for subdir in subdirs(FilePath(\".\")):         print \"Subdirectory:\", subdir   Since some commenters have asked what the advantages of using Twisted's libraries for this is, I'll go a bit beyond the original question here.    There's some improved documentation in a branch that explains the advantages of FilePath; you might want to read that.  More specifically in this example: unlike the standard library version, this function can be implemented with no imports.  The \"subdirs\" function is totally generic, in that it operates on nothing but its argument.  In order to copy and move the files using the standard library, you need to depend on the \"open\" builtin, \"listdir\", perhaps \"isdir\" or \"os.walk\" or \"shutil.copy\".  Maybe \"os.path.join\" too.  Not to mention the fact that you need a string passed an argument to identify the actual file.  Let's take a look at the full implementation which will copy each directory's \"index.tpl\" to \"index.html\":  def copyTemplates(topdir):     for subdir in subdirs(topdir):         tpl = subdir.child(\"index.tpl\")         if tpl.exists():             tpl.copyTo(subdir.child(\"index.html\"))   The \"subdirs\" function above can work on any FilePath-like object.  Which means, among other things, ZipPath objects.  Unfortunately ZipPath is read-only right now, but it could be extended to support writing.  You can also pass your own objects for testing purposes.  In order to test the os.path-using APIs suggested here, you have to monkey with imported names and implicit dependencies and generally perform black magic to get your tests to work.  With FilePath, you do something like this:  class MyFakePath:     def child(self, name):         \"Return an appropriate child object\"      def walk(self):         \"Return an iterable of MyFakePath objects\"      def exists(self):         \"Return true or false, as appropriate to the test\"      def isdir(self):         \"Return true or false, as appropriate to the test\" ... subdirs(MyFakePath(...))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  This method nicely does it all in one go.  from glob import glob subd = [s.rstrip(\"/\") for s in glob(parent_dir+\"*/\")]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  I just wrote some code to move vmware virtual machines around, and ended up using os.path and shutil to accomplish file copying between sub-directories.  def copy_client_files (file_src, file_dst):     for file in os.listdir(file_src):             print \"Copying file: %s\" % file             shutil.copy(os.path.join(file_src, file), os.path.join(file_dst, file))   It's not terribly elegant, but it does work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  Here's one way:  import os import shutil  def copy_over(path, from_name, to_name):   for path, dirname, fnames in os.walk(path):     for fname in fnames:       if fname == from_name:         shutil.copy(os.path.join(path, from_name), os.path.join(path, to_name))   copy_over('.', 'index.tpl', 'index.html')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "How to get all of the immediate subdirectories in Python",
        "A_Content": "  def get_folders_in_directories_recursively(self, directory, index=0):     folder_list = list()     parent_directory = directory      for path, subdirs, _ in os.walk(directory):         if not index:             for sdirs in subdirs:                 folder_path = \"{}/{}\".format(path, sdirs)                 folder_list.append(folder_path)         elif path[len(parent_directory):].count('/') + 1 == index:             for sdirs in subdirs:                 folder_path = \"{}/{}\".format(path, sdirs)                 folder_list.append(folder_path)      return folder_list   The following function can be called as:  get_folders_in_directories_recursively(directory, index=1) -> gives the list of folders in first level  get_folders_in_directories_recursively(directory) -> gives all the sub folders     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file"
        ],
        "URL": "https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to write a simple Python script that will copy a index.tpl to index.html in all of the subdirectories (with a few exceptions).   I'm getting bogged down by trying to get the list of subdirectories.     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  __repr__ should return a printable representation of the object, most likely one of the ways possible to create this object. See official documentation here. __repr__ is more for developers while __str__ is for end users.  A simple example:  >>> class Point: ...   def __init__(self, x, y): ...     self.x, self.y = x, y ...   def __repr__(self): ...     return 'Point(x=%s, y=%s)' % (self.x, self.y) >>> p = Point(1, 2) >>> p Point(x=1, y=2)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "130",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  This is explained quite well in the Python documentation:     repr(object): Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse quotes). It is sometimes useful to be able to access this operation as an ordinary function. For many types, this function makes an attempt to return a string that would yield an object with the same value when passed to eval(), otherwise the representation is a string enclosed in angle brackets that contains the name of the type of the object together with additional information often including the name and address of the object. A class can control what this function returns for its instances by defining a __repr__() method.   So what you're seeing here is the default implementation of __repr__, which is useful for serialization and debugging.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  __repr__ is used by the standalone Python interpreter to display a class in printable format. Example:    ~> python3.5 Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44)  [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> class StackOverflowDemo: ...     def __init__(self): ...         pass ...     def __repr__(self): ...         return '<StackOverflow demo object __repr__>' ...  >>> demo = StackOverflowDemo() >>> demo <StackOverflow demo object>   In cases where a __str__ method is not defined in the class, it will call the __repr__ function in an attempt to create a printable representation.  >>> str(demo) '<StackOverflow demo object __repr__>'   Additionally, print()ing the class will call __str__ by default.    Documentation, if you please     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  The __repr__ method simply tells Python how to print objects of a class     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  An example to see the differences between them (I copied from this source),  >>> x=4 >>> repr(x) '4' >>> str(x) '4' >>> y='stringy' >>> repr(y) \"'stringy'\" >>> str(y) 'stringy'   The returns of repr() and str() are identical for int x, but there's a difference between the return values for str  y -- one is formal and the other is informal. One of the most important differences between the formal and informal representations is that the default implementation of __repr__ for a str value can be called as an argument to eval, and the return value would be a valid string object, like this:  >>> repr(y) \"'a string'\" >>> y2=eval(repr(y)) >>> y==y2 True   If you try to call the return value of __str__ as an argument to eval, the result won't be valid.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Purpose of Python's __repr__",
        "A_Content": "  When we create new types by defining classes, we can take advantage of certain features of Python to make the new classes convenient to use. One of these features is \"special methods\", also referred to as \"magic methods\".  Special methods have names that begin and end with two underscores. We define them, but do not usually call them directly by name. Instead, they execute automatically under under specific circumstances.  It is convenient to be able to output the value of an instance of an object by using a print statement. When we do this, we would like the value to be represented in the output in some understandable unambiguous format. The repr special method can be used to arrange for this to happen. If we define this method, it can get called automatically when we print the value of an instance of a class for which we defined this method. It should be mentioned, though, that there is also a str special method, used for a similar, but not identical purpose, that may get precedence, if we have also defined it.  If we have not defined, the repr method for the Point3D class, and have instantiated my_point as an instance of Point3D, and then we do this ...  print my_point ... we may see this as the output ...   Not very nice, eh?  So, we define the repr or str special method, or both, to get better output.  **class Point3D(object):     def __init__(self,a,b,c):         self.x = a         self.y = b         self.z = c     def __repr__(self):         return \"Point3D(%d, %d, %d)\" % (self.x, self.y, self.z)     def __str__(self):         return \"(%d, %d, %d)\" % (self.x, self.y, self.z) my_point = Point3D(1, 2, 3) print my_point # __repr__ gets called automatically print my_point # __str__ gets called automatically**   Output ...  (1, 2, 3) (1, 2, 3)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1984162/purpose-of-pythons-repr",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def __repr__(self):   return '<%s %s (%s:%s) %s>' % (     self.__class__.__name__, self.urlconf_name, self.app_name,     self.namespace, self.regex.pattern)   What is the significance/purpose of this method?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "TypeError: module.__init__() takes at most 2 arguments (3 given)",
        "A_Content": "  Your error is happening because Object is a module, not a class. So your inheritance is screwy.  Change your import statement to:  from Object import ClassName   and your class definition to:  class Visitor(ClassName):   or   change your class definition to:  class Visitor(Object.ClassName):    etc      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/14583761/typeerror-module-init-takes-at-most-2-arguments-3-given",
        "A_Votes": "159",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have defined a class in a file named Object.py. When I try to inherit from this class in another file, calling the constructor throws an exception:  TypeError: module.__init__() takes at most 2 arguments (3 given)   This is my code:  import Object  class Visitor(Object):     pass  instance = Visitor()  # this line throws the exception   What am I doing wrong?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "TypeError: module.__init__() takes at most 2 arguments (3 given)",
        "A_Content": "  You may also do the following in Python 3.6.1  from Object import Object as Parent   and your class definition to:  class Visitor(Parent):      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/14583761/typeerror-module-init-takes-at-most-2-arguments-3-given",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have defined a class in a file named Object.py. When I try to inherit from this class in another file, calling the constructor throws an exception:  TypeError: module.__init__() takes at most 2 arguments (3 given)   This is my code:  import Object  class Visitor(Object):     pass  instance = Visitor()  # this line throws the exception   What am I doing wrong?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  This was discussed not too long ago in PyQt mailing list. Quoting Giovanni Bajo's comments on the subject:     It's mostly the same. The main difference is that QThreads are better   integrated with Qt (asynchrnous signals/slots, event loop, etc.).   Also, you can't use Qt from a Python thread (you can't for instance   post event to the main thread through QApplication.postEvent): you   need a QThread for that to work.      A general rule of thumb might be to use QThreads if you're going to interact somehow with Qt, and use Python threads otherwise.   And some earlier comment on this subject from PyQt's author: \"they are both wrappers around the same native thread implementations\". And both implementations use GIL in the same way.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "89",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  Python's threads will be simpler and safer, and since it is for an I/O-based application, they are able to bypass the GIL. That said, have you considered non-blocking I/O using Twisted or non-blocking sockets/select?  EDIT: more on threads  Python threads  Python's threads are system threads. However, Python uses a global interpreter lock (GIL) to ensure that the interpreter is only ever executing a certain size block of byte-code instructions at a time. Luckily, Python releases the GIL during input/output operations, making threads useful for simulating non-blocking I/O.  Important caveat: This can be misleading, since the number of byte-code instructions does not correspond to the number of lines in a program. Even a single assignment may not be atomic in Python, so a mutex lock is necessary for any block of code that must be executed atomically, even with the GIL.  QT threads  When Python hands off control to a 3rd party compiled module, it releases the GIL. It becomes the responsibility of the module to ensure atomicity where required. When control is passed back, Python will use the GIL. This can make using 3rd party libraries in conjunction with threads confusing. It is even more difficult to use an external threading library because it adds uncertainty as to where and when control is in the hands of the module vs the interpreter.  QT threads operate with the GIL released. QT threads are able to execute QT library code (and other compiled module code that does not acquire the GIL) concurrently. However, the Python code executed within the context of a QT thread still acquires the GIL, and now you have to manage two sets of logic for locking your code.  In the end, both QT threads and Python threads are wrappers around system threads. Python threads are marginally safer to use, since those parts that are not written in Python (implicitly using the GIL) use the GIL in any case (although the caveat above still applies.)  Non-blocking I/O  Threads add extraordinarily complexity to your application. Especially when dealing with the already complex interaction between the Python interpreter and compiled module code. While many find event-based programming difficult to follow, event-based, non-blocking I/O is often much less difficult to reason about than threads.  With asynchronous I/O, you can always be sure that, for each open descriptor, the path of execution is consistent and orderly. There are, obviously, issues that must be addressed, such as what to do when code depending on one open channel further depends on the results of code to be called when another open channel returns data.  One nice solution for event-based, non-blocking I/O is the new Diesel library. It is restricted to Linux at the moment, but it is extraordinarily fast and quite elegant.  It is also worth your time to learn pyevent, a wrapper around the wonderful libevent library, which provides a basic framework for event-based programming using the fastest available method for your system (determined at compile time).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  The advantage of QThread is that it's integrated with the rest of the Qt library. That is, thread-aware methods in Qt will need to know in which thread they run, and to move objects between threads, you will need to use QThread. Another useful feature is running your own event loop in a thread.  If you are accessing a HTTP server, you should consider QNetworkAccessManager.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  I asked myself the same question when I was working to PyTalk.  If you are using Qt, you need to use QThread to be able to use the Qt framework and expecially the signal/slot system.  With the signal/slot engine, you will be able to talk from a thread to another and with every part of your project.  Moreover, there is not very performance question about this choice since both are a C++ bindings.  Here is my experience of PyQt and thread.  I encourage you to use QThread.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  Jeff has some good points.  Only one main thread can do any GUI updates.  If you do need to update the GUI from within the thread, Qt-4's queued connection signals make it easy to send data across threads and will automatically be invoked if you're using QThread; I'm not sure if they will be if you're using Python threads, although it's easy to add a parameter to connect().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  I can't really recommend either, but I can try describing differences between CPython and Qt threads.  First of all, CPython threads do not run concurrently, at least not Python code. Yes, they do create system threads for each Python thread, however only the thread currently holding Global Interpreter Lock is allowed to run (C extensions and FFI code might bypass it, but Python bytecode is not executed while thread doesn't hold GIL).  On the other hand, we have Qt threads, which are basically common layer over system threads, don't have Global Interpreter Lock, and thus are capable of running concurrently. I'm not sure how PyQt deals with it, however unless your Qt threads call Python code, they should be able to run concurrently (bar various extra locks that might be implemented in various structures).  For extra fine-tuning, you can modify the amount of bytecode instructions that are interpreted before switching ownership of GIL - lower values mean more context switching (and possibly higher responsiveness) but lower performance per individual thread (context switches have their cost - if you try switching every few instructions it doesn't help speed.)  Hope it helps with your problems :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Threading in a PyQt application: Use Qt threads or Python threads?",
        "A_Content": "  I can't comment on the exact differences between Python and PyQt threads, but I've been doing what you're attempting to do using QThread, QNetworkAcessManager and making sure to call QApplication.processEvents() while the thread is alive.  If GUI responsiveness is really the issue you're trying to solve, the later will help.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "multithreading",
            "pyqt"
        ],
        "URL": "https://stackoverflow.com/questions/1595649/threading-in-a-pyqt-application-use-qt-threads-or-python-threads",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a GUI application that regularly retrieves data through a web connection. Since this retrieval takes a while, this causes the UI to be unresponsive during the retrieval process (it cannot be split into smaller parts). This is why I'd like to outsource the web connection to a separate worker thread.  [Yes, I know, now I have two problems.]  Anyway, the application uses PyQt4, so I'd like to know what the better choice is: Use Qt's threads or use the Python threading module? What are advantages / disadvantages of each? Or do you have a totally different suggestion?  Edit (re bounty): While the solution in my particular case will probably be using a non-blocking network request like Jeff Ober and Lukáš Lalinský suggested (so basically leaving the concurrency problems to the networking implementation), I'd still like a more in-depth answer to the general question:  What are advantages and disadvantages of using PyQt4's (i.e. Qt's) threads over native Python threads (from the threading module)?    Edit 2: Thanks all for you answers. Although there's no 100% agreement, there seems to be widespread consensus that the answer is \"use Qt\", since the advantage of that is integration with the rest of the library, while causing no real disadvantages.  For anyone looking to choose between the two threading implementations, I highly recommend they read all the answers provided here, including the PyQt mailing list thread that abbot links to.  There were several answers I considered for the bounty; in the end I chose abbot's for the very relevant external reference; it was, however, a close call.  Thanks again.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  Here is my summary of this problem: 5 Ways of Calling Java from Python  http://baojie.org/blog/2014/06/16/call-java-from-python/ (cached)  Short answer: Jpype works pretty well and is proven in many projects (such as python-boilerpipe), but Pyjnius is faster and simpler than JPype  I have tried Pyjnius/Jnius, JCC, javabridge, Jpype and Py4j.  Py4j is a bit hard to use, as you need to start a gateway, adding another layer of fragility.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  You could also use Py4J. There is an example on the frontpage and lots of documentation, but essentially, you just call Java methods from your python code as if they were python methods:  from py4j.java_gateway import JavaGateway gateway = JavaGateway()                        # connect to the JVM java_object = gateway.jvm.mypackage.MyClass()  # invoke constructor other_object = java_object.doThat() other_object.doThis(1,'abc') gateway.jvm.java.lang.System.out.println('Hello World!') # call a static method   As opposed to Jython, one part of Py4J runs in the Python VM so it is always \"up to date\" with the latest version of Python and you can use libraries that do not run well on Jython (e.g., lxml). The other part runs in the Java VM you want to call.   The communication is done through sockets instead of JNI and Py4J has its own protocol (to optimize certain cases, to manage memory, etc.)  Disclaimer: I am the author of Py4J     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "114",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  Pyjnius.  Docs: http://pyjnius.readthedocs.org/en/latest/  Github: https://github.com/kivy/pyjnius  From the github page:     A Python module to access Java classes as Python classes using JNI.      PyJNIus is a \"Work In Progress\".      Quick overview  >>> from jnius import autoclass >>> autoclass('java.lang.System').out.println('Hello world') Hello world  >>> Stack = autoclass('java.util.Stack') >>> stack = Stack() >>> stack.push('hello') >>> stack.push('world') >>> print stack.pop() world >>> print stack.pop() hello       ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  I've been integrating a lot of stuff into Python lately, including Java.  The most robust method I've found is to use IKVM and a C# wrapper.  IKVM has a neat little application that allows you to take any Java JAR, and convert it directly to .Net DLL.  It simply translates the JVM bytecode to CLR bytecode.  See http://sourceforge.net/p/ikvm/wiki/Ikvmc/ for details.  The converted library behaves just like a native C# library, and you can use it without needing the JVM.  You can then create a C# DLL wrapper project, and add a reference to the converted DLL.  You can now create some wrapper stubs that call the methods that you want to expose, and mark those methods as DllEport.  See https://stackoverflow.com/a/29854281/1977538 for details.  The wrapper DLL acts just like a native C library, with the exported methods looking just like exported C methods.  You can connect to them using ctype as usual.  I've tried it with Python 2.7, but it should work with 3.0 as well.  Works on Windows and the Linuxes  If you happen to use C#, then this is probably the best approach to try when integrating almost anything into python.      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  I'm on OSX 10.10.2, and succeeded in using JPype.  Ran into installation problems with Jnius (others have too), Javabridge installed but gave mysterious errors when I tried to use it, PyJ4 has this inconvenience of having to start a Gateway server in Java first, JCC wouldn't install.  Finally, JPype ended up working.  There's a maintained fork of JPype on Github.  It has the major advantages that (a) it installs properly and (b) it can very efficiently convert java arrays to numpy array (np_arr = java_arr[:])  The installation process was:  git clone https://github.com/originell/jpype.git cd jpype python setup.py install   And you should be able to import jpype  The following demo worked:  import jpype as jp jp.startJVM(jp.getDefaultJVMPath(), \"-ea\") jp.java.lang.System.out.println(\"hello world\") jp.shutdownJVM()    When I tried calling my own java code, I had to first compile (javac ./blah/HelloWorldJPype.java), and I had to change the JVM path from the default (otherwise you'll get inexplicable \"class not found\" errors).  For me, this meant changing the startJVM command to:  jp.startJVM('/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/MacOS/libjli.dylib', \"-ea\") c = jp.JClass('blah.HelloWorldJPype')   # Where my java class file is in ./blah/HelloWorldJPype.class ...      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  I'm just beginning to use JPype 0.5.4.2 (july 2011) and it looks like it's working nicely... I'm on Xubuntu 10.04     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  If you're in Python 3, there's a fork of JPype called JPype1-py3  pip install JPype1-py3   This works for me on OSX / Python 3.4.3. (You may need to export JAVA_HOME=/Library/Java/JavaVirtualMachines/your-java-version)  from jpype import * startJVM(getDefaultJVMPath(), \"-ea\") java.lang.System.out.println(\"hello world\") shutdownJVM()      ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  I'm assuming that if you can get from C++ to Java then you are all set. I've seen a product of the kind you mention work well. As it happens the one we used was CodeMesh. I'm not specifically endorsing this vendor, or making any statement about their product's relative quality, but I have seen it work in quite a high volume scenario.  I would say generally that if at all possible I would recommend keeping away from direct integration via JNI if you can. Some simple REST service approach, or queue-based architecture will tend to be simpler to develop and diagnose. You can get quite decent perfomance if you use such decoupled technologies carefully.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Calling Java from Python [closed]",
        "A_Content": "  Through my own experience trying to run some java code from within python i a manner similar to how python code runs within java code in python, I was unable to a find a straight forward methodology.  My solution to my problem was by running this java code as beanshell scripts by calling the beanshell interpreter as a shell commnad from within my python code after editing the java code in a temporary file with the appropriate packages and variables.  If what I am talking about is helpful in any manner, I am glad to help you sharing more details of my solutions.     ",
        "Language": "Python",
        "Tags": [
            "java",
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3652554/calling-java-from-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to call java from python? (jython and RPC are not an option for me).  I've heard of JCC: http://pypi.python.org/pypi/JCC/1.9 a C++ code generator for calling Java from C++/Python But this requires compiling every possible call; I would prefer another solution.  I've hear about JPype: http://jpype.sourceforge.net/  tutorial: http://www.slideshare.net/onyame/mixing-python-and-java  import jpype  jpype.startJVM(path to jvm.dll, \"-ea\")  javaPackage = jpype.JPackage(\"JavaPackageName\")  javaClass = javaPackage.JavaClassName  javaObject = javaClass()  javaObject.JavaMethodName()  jpype.shutdownJVM()    This looks like what I need. However, the last release is from Jan 2009 and I see people failing to compile JPype.  Is JPype a dead project?  Are there any other alternatives?  Regards, David     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are Flask Blueprints, exactly?",
        "A_Content": "  A blueprint is a template for generating a \"section\" of a web application.  Think of it like a mold:    You can take the blueprint and apply it to your application in several places. Each time you apply it the blueprint will create a new version of its structure in the plaster of your application.  # An example from flask import Blueprint  tree_mold = Blueprint(\"mold\", __name__)  @tree_mold.route(\"/leaves\") def leaves():     return \"This tree has leaves\"  @tree_mold.route(\"/roots\") def roots():     return \"And roots as well\"  @tree_mold.route(\"/rings\") @tree_mold.route(\"/rings/<int:year>\") def rings(year=None):     return \"Looking at the rings for {year}\".format(year=year)   This is a simple mold for working with trees - it says than any application that deals with trees should provide access to its leaves, its roots, and its rings (by year).  By itself, it is a hollow shell - it cannot route, it cannot respond, until it is impressed upon an application:  from tree_workshop import tree_mold  app.register_blueprint(tree_mold, url_prefix=\"/oak\") app.register_blueprint(tree_mold, url_prefix=\"/fir\") app.register_blueprint(tree_mold, url_prefix=\"/ash\")   Once it is created it may \"impressed\" on the application by using the register_blueprint function - this \"impresses\" the mold of the blueprint on the application at the locations specified by url_prefix.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask",
            "wsgi"
        ],
        "URL": "https://stackoverflow.com/questions/24420857/what-are-flask-blueprints-exactly",
        "A_Votes": "169",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have read the official Flask documentation on Blueprints and even one or two blog posts on using them.  I've even used them in my web app, but I don't completely understand what they are or how they fit into my app as a whole. How is it similar to an instance of my app but not quite? The documentation is comprehensive but I seek a layman explanation or an enlightening analogy to spark it for me. I was sufficiently perplexed when a colleague asked me to explain a Flask blueprint to them that I elected to ask here.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How can I check whether the numpy array is empty or not?",
        "A_Content": "  You can always take a look at the .size attribute:  import numpy as np a = np.array([]) print a.size # 0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/11295609/how-can-i-check-whether-the-numpy-array-is-empty-or-not",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I check whether the numpy array is empty or not?  I used the following code, but this is fail if the array contains a zero.  if not self.Definition.all():   is this the solution?  if self.Definition == array( [] ):      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How can I check whether the numpy array is empty or not?",
        "A_Content": "  http://www.scipy.org/Tentative_NumPy_Tutorial#head-6a1bc005bd80e1b19f812e1e64e0d25d50f99fe2     NumPy's main object is the homogeneous multidimensional array. In Numpy dimensions are called axes. The number of axes is rank. Numpy's array class is called ndarray. It is also known by the alias array. The more important attributes of an ndarray object are:        ndarray.ndim   the number of axes (dimensions) of the array. In the Python world, the number of dimensions is referred to as rank.        ndarray.shape   the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with n rows and m columns, shape will be (n,m). The length of the shape tuple is therefore the rank, or number of dimensions, ndim.      ndarray.size   the total number of elements of the array. This is equal to the product of the elements of shape.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/11295609/how-can-i-check-whether-the-numpy-array-is-empty-or-not",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I check whether the numpy array is empty or not?  I used the following code, but this is fail if the array contains a zero.  if not self.Definition.all():   is this the solution?  if self.Definition == array( [] ):      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  You often hear that Python encourages EAFP style (\"it's easier to ask for forgiveness than permission\") over LBYL style (\"look before you leap\"). To me, it's a matter of efficiency and readability.  In your example (say that instead of returning a list or an empty string, the function were to return a list or None), if you expect that 99 % of the time result will actually contain something iterable, I'd use the try/except approach. It will be faster if exceptions really are exceptional. If result is None more than 50 % of the time, then using if is probably better.  To support this with a few measurements:  >>> import timeit >>> timeit.timeit(setup=\"a=1;b=1\", stmt=\"a/b\") # no error checking 0.06379691968322732 >>> timeit.timeit(setup=\"a=1;b=1\", stmt=\"try:\\n a/b\\nexcept ZeroDivisionError:\\n pass\") 0.0829463709378615 >>> timeit.timeit(setup=\"a=1;b=0\", stmt=\"try:\\n a/b\\nexcept ZeroDivisionError:\\n pass\") 0.5070195056614466 >>> timeit.timeit(setup=\"a=1;b=1\", stmt=\"if b!=0:\\n a/b\") 0.11940114974277094 >>> timeit.timeit(setup=\"a=1;b=0\", stmt=\"if b!=0:\\n a/b\") 0.051202772912802175   So, whereas an if statement always costs you, it's nearly free to set up a try/except block.  But when an Exception actually occurs, the cost is much higher.  Moral:   It's perfectly OK (and \"pythonic\") to use try/except for flow control, but it makes sense most when Exceptions are actually exceptional.    From the Python docs:     EAFP      Easier to ask for forgiveness than   permission. This common Python coding   style assumes the existence of valid   keys or attributes and catches   exceptions if the assumption proves   false. This clean and fast style is   characterized by the presence of many   try and except statements. The   technique contrasts with the LBYL   style common to many other languages   such as C.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "168",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  Your function should not return mixed types (i.e. list or empty string). It should return a list of values or just an empty list. Then you wouldn't need to test for anything, i.e. your code collapses to:  for r in function():     # process items      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  Please ignore my solution if the code I provide is not obvious at first glance and you have to read the explanation after the code sample.  Can I assume that the \"no value returned\" means the return value is None? If yes, or if the \"no value\" is False boolean-wise, you can do the following, since your code essentially treats \"no value\" as \"do not iterate\":  for r in function() or ():     # process items   If function() returns something that's not True, you iterate over the empty tuple, i.e. you don't run any iterations. This is essentially LBYL.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  Your second example is broken - the code will never throw a TypeError exception since you can iterate through both strings and lists.  Iterating through an empty string or list is also valid - it will execute the body of the loop zero times.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "     Which of the following would be more preferable and why?   Look Before You Leap is preferable in this case. With the exception approach, a TypeError could occur anywhere in your loop body and it'd get caught and thrown away, which is not what you want and will make debugging tricky.  (I agree with Brandon Corfman though: returning None for ‘no items’ instead of an empty list is broken. It's an unpleasant habit of Java coders that should not be seen in Python. Or Java.)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  Generally, the impression I've gotten is that exceptions should be reserved for exceptional circumstances.  If the result is expected never to be empty (but might be, if, for instance, a disk crashed, etc), the second approach makes sense.  If, on the other hand, an empty result is perfectly reasonable under normal conditions, testing for it with an if statement makes more sense.  I had in mind the (more common) scenario:  # keep access counts for different files file_counts={} ... # got a filename somehow if filename not in file_counts:     file_counts[filename]=0 file_counts[filename]+=1   instead of the equivalent:  ... try:     file_counts[filename]+=1 except KeyError:     file_counts[filename]=1      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  bobince wisely points out that wrapping the second case can also catch TypeErrors in the loop, which is not what you want.  If you do really want to use a try though, you can test if it's iterable before the loop  result = function(); try:     it = iter(result) except TypeError:     pass else:     for r in it:         #process items   As you can see, it's rather ugly.  I don't suggest it, but it should be mentioned for completeness.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Using try vs if in python",
        "A_Content": "  As far as the performance is concerned, using try block for code that normally doesn’t raise exceptions is faster than using if statement everytime. So, the decision depends on the probability of excetional cases.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1835756/using-try-vs-if-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a rationale to decide which one of try or if constructs to use, when testing variable to have a value?    For example, there is a function that returns either a list or doesn't return a value. I want to check result before processing it. Which of the following would be more preferable and why?  result = function(); if (result):     for r in result:         #process items   or  result = function(); try:     for r in result:         #process items except TypeError:     pass;   Related discussion:  Checking for member existence in Python     ",
        "Q_Votes": "94"
    },
    {
        "Q_Title": "Get column index from column name in python pandas",
        "A_Content": "  Sure, you can use .get_loc():  In [45]: df = DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})  In [46]: df.columns Out[46]: Index([apple, orange, pear], dtype=object)  In [47]: df.columns.get_loc(\"pear\") Out[47]: 2   although to be honest I don't often need this myself.  Usually access by name does what I want it to (df[\"pear\"], df[[\"apple\", \"orange\"]], or maybe df.columns.isin([\"orange\", \"pear\"])), although I can definitely see cases where you'd want the index number.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ],
        "URL": "https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas",
        "A_Votes": "153",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In R when you need to retrieve a column index based on the name of the column you could do  idx <- which(names(my_data)==my_colum_name)   Is there a way to do the same with pandas dataframes?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Get column index from column name in python pandas",
        "A_Content": "  DSM's solution works, but if you wanted a direct equivalent to which you could do (df.columns == name).nonzero()     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ],
        "URL": "https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R when you need to retrieve a column index based on the name of the column you could do  idx <- which(names(my_data)==my_colum_name)   Is there a way to do the same with pandas dataframes?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Get column index from column name in python pandas",
        "A_Content": "  Here is a solution through list comprehension. cols is the list of columns to get index for:  [df.columns.get_loc(c) for c in df.columns if c in cols]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ],
        "URL": "https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R when you need to retrieve a column index based on the name of the column you could do  idx <- which(names(my_data)==my_colum_name)   Is there a way to do the same with pandas dataframes?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Get column index from column name in python pandas",
        "A_Content": "  When you might be looking to find multiple column matches, a vectorized solution using searchsorted method could be used. Thus, with df as the dataframe and query_cols as the column names to be searched for, an implementation would be -  def column_index(df, query_cols):     cols = df.columns.values     sidx = np.argsort(cols)     return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]   Sample run -  In [162]: df Out[162]:     apple  banana  pear  orange  peach 0      8       3     4       4      2 1      4       4     3       0      1 2      1       2     6       8      1  In [163]: column_index(df, ['peach', 'banana', 'apple']) Out[163]: array([4, 1, 0])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ],
        "URL": "https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R when you need to retrieve a column index based on the name of the column you could do  idx <- which(names(my_data)==my_colum_name)   Is there a way to do the same with pandas dataframes?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Get column index from column name in python pandas",
        "A_Content": "  In case you want the column name from the column location (the other way around to the OP question), you can use:  >>> df.columns.get_values()[location]   Using @DSM Example:  >>> df = DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})  >>> df.columns  Index(['apple', 'orange', 'pear'], dtype='object')  >>> df.columns.get_values()[1]  'orange'   Another way:  df.iloc[:,1].name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ],
        "URL": "https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R when you need to retrieve a column index based on the name of the column you could do  idx <- which(names(my_data)==my_colum_name)   Is there a way to do the same with pandas dataframes?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to add title to subplots in Matplotlib?",
        "A_Content": "  ax.set_title() should set the titles for separate subplots:  import matplotlib.pyplot as plt  if __name__ == \"__main__\":     data = [1, 2, 3, 4, 5]      fig = plt.figure()     fig.suptitle(\"Title for whole figure\", fontsize=16)     ax = plt.subplot(\"211\")     ax.set_title(\"Title for first plot\")     ax.plot(data)      ax = plt.subplot(\"212\")     ax.set_title(\"Title for second plot\")     ax.plot(data)      plt.show()   Can you check if this code works for you? Maybe something overwrites them later?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "subtitle"
        ],
        "URL": "https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have one figure which contains many subplots.  fig = plt.figure(num=None, figsize=(26, 12), dpi=80, facecolor='w', edgecolor='k') fig.canvas.set_window_title('Window Title')  # Returns the Axes instance ax = fig.add_subplot(311)  ax2 = fig.add_subplot(312)  ax3 = fig.add_subplot(313)    How do I add titles to the subplots?  fig.suptitle adds a title to all graphs and although ax.set_title() exists, the latter does not add any title to my subplots.   Thank you for your help.  Edit: Corrected typo about set_title(). Thanks Rutger Kassies      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to add title to subplots in Matplotlib?",
        "A_Content": "  ax.title.set_text('My Plot Title') seems to work too.  fig = plt.figure() ax1 = fig.add_subplot(221) ax2 = fig.add_subplot(222) ax3 = fig.add_subplot(223) ax4 = fig.add_subplot(224) ax1.title.set_text('First Plot') ax2.title.set_text('Second Plot') ax3.title.set_text('Third Plot') ax4.title.set_text('Fourth Plot') plt.show()        ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "subtitle"
        ],
        "URL": "https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have one figure which contains many subplots.  fig = plt.figure(num=None, figsize=(26, 12), dpi=80, facecolor='w', edgecolor='k') fig.canvas.set_window_title('Window Title')  # Returns the Axes instance ax = fig.add_subplot(311)  ax2 = fig.add_subplot(312)  ax3 = fig.add_subplot(313)    How do I add titles to the subplots?  fig.suptitle adds a title to all graphs and although ax.set_title() exists, the latter does not add any title to my subplots.   Thank you for your help.  Edit: Corrected typo about set_title(). Thanks Rutger Kassies      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to add title to subplots in Matplotlib?",
        "A_Content": "  A shorthand answer assuming  import matplotlib.pyplot as plt.  plt.gca().set_title('title')   as in:  plt.subplot(221) plt.gca().set_title('title') plt.subplot(222) etc...   Then there is no need for superfluous variables.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "subtitle"
        ],
        "URL": "https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have one figure which contains many subplots.  fig = plt.figure(num=None, figsize=(26, 12), dpi=80, facecolor='w', edgecolor='k') fig.canvas.set_window_title('Window Title')  # Returns the Axes instance ax = fig.add_subplot(311)  ax2 = fig.add_subplot(312)  ax3 = fig.add_subplot(313)    How do I add titles to the subplots?  fig.suptitle adds a title to all graphs and although ax.set_title() exists, the latter does not add any title to my subplots.   Thank you for your help.  Edit: Corrected typo about set_title(). Thanks Rutger Kassies      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python, creating objects",
        "A_Content": "  class Student(object):     name = \"\"     age = 0     major = \"\"      # The class \"constructor\" - It's actually an initializer      def __init__(self, name, age, major):         self.name = name         self.age = age         self.major = major  def make_student(name, age, major):     student = Student(name, age, major)     return student   Note that even though one of the principles in Python's philosophy is \"there should be one—and preferably only one—obvious way to do it\", there are still multiple ways to do this. You can also use the two following snippets of code to take advantage of Python's dynamic capabilities:  class Student(object):     name = \"\"     age = 0     major = \"\"  def make_student(name, age, major):     student = Student()     student.name = name     student.age = age     student.major = major     # Note: I didn't need to create a variable in the class definition before doing this.     student.gpa = float(4.0)     return student   I prefer the former, but there are instances where the latter can be useful – one being when working with document databases like MongoDB.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/15081542/python-creating-objects",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to learn python and I now I am trying to get the hang of classes and how to manipulate them with instances.  I can't seem to understand this practice problem:  Create and return a student object whose name, age, and major are the same as those given as input  def make_student(name, age, major)   I just don't get what it means by object, do they mean I should create an array inside the function that holds these values? or create a class and let this function be inside it, and assign instances? (before this question i was asked to set up a student class with name, age, and major inside)  class Student:     name = \"Unknown name\"     age = 0     major = \"Unknown major\"      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python, creating objects",
        "A_Content": "  Create a class and give it an __init__ method:  class Student:     def __init__(self, name, age, major):         self.name = name         self.age = age         self.major = major      def is_old(self):         return self.age > 100   Now, you can initialize an instance of the Student class:  >>> s = Student('John', 88, None) >>> s.name     'John' >>> s.age     88   Although I'm not sure why you need a make_student student function if it does the same thing as Student.__init__.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/15081542/python-creating-objects",
        "A_Votes": "39",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to learn python and I now I am trying to get the hang of classes and how to manipulate them with instances.  I can't seem to understand this practice problem:  Create and return a student object whose name, age, and major are the same as those given as input  def make_student(name, age, major)   I just don't get what it means by object, do they mean I should create an array inside the function that holds these values? or create a class and let this function be inside it, and assign instances? (before this question i was asked to set up a student class with name, age, and major inside)  class Student:     name = \"Unknown name\"     age = 0     major = \"Unknown major\"      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python, creating objects",
        "A_Content": "  Objects are instances of classes.  Classes are just the blueprints for objects.  So given your class definition -  # Note the added (object) - this is the preferred way of creating new classes class Student(object):     name = \"Unknown name\"     age = 0     major = \"Unknown major\"   You can create a make_student function by explicitly assigning the attributes to a new instance of Student -  def make_student(name, age, major):     student = Student()     student.name = name     student.age = age     student.major = major     return student   But it probably makes more sense to do this in a constructor (__init__) -  class Student(object):     def __init__(self, name=\"Unknown name\", age=0, major=\"Unknown major\"):         self.name = name         self.age = age         self.major = major   The constructor is called when you use Student().  It will take the arguments defined in the __init__ method.  The constructor signature would now essentially be Student(name, age, major).  If you use that, then a make_student function is trivial (and superfluous) -  def make_student(name, age, major):     return Student(name, age, major)   For fun, here is an example of how to create a make_student function without defining a class.  Please do not try this at home.  def make_student(name, age, major):     return type('Student', (object,),                 {'name': name, 'age': age, 'major': major})()      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/15081542/python-creating-objects",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to learn python and I now I am trying to get the hang of classes and how to manipulate them with instances.  I can't seem to understand this practice problem:  Create and return a student object whose name, age, and major are the same as those given as input  def make_student(name, age, major)   I just don't get what it means by object, do they mean I should create an array inside the function that holds these values? or create a class and let this function be inside it, and assign instances? (before this question i was asked to set up a student class with name, age, and major inside)  class Student:     name = \"Unknown name\"     age = 0     major = \"Unknown major\"      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python, creating objects",
        "A_Content": "  when you create an object using predefine class, at first you want to create a variable for storing that object. Then you can create object and store variable that you created.  class Student:      def __init__(self):  # creating an object....     student1=Student()   Actually this init method is the constructor of class.you can initialize that method using some attributes.. In that point , when you creating an object , you will have to pass some values for particular attributes..  class Student:       def __init__(self,name,age):             self.name=value             self.age=value   # creating an object.......       student2=Student(\"smith\",25)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/15081542/python-creating-objects",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to learn python and I now I am trying to get the hang of classes and how to manipulate them with instances.  I can't seem to understand this practice problem:  Create and return a student object whose name, age, and major are the same as those given as input  def make_student(name, age, major)   I just don't get what it means by object, do they mean I should create an array inside the function that holds these values? or create a class and let this function be inside it, and assign instances? (before this question i was asked to set up a student class with name, age, and major inside)  class Student:     name = \"Unknown name\"     age = 0     major = \"Unknown major\"      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  You seek the all-powerful '*?'  http://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "112",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  >>> x = \"a (b) c (d) e\" >>> re.search(r\"\\(.*\\)\", x).group() '(b) c (d)' >>> re.search(r\"\\(.*?\\)\", x).group() '(b)'   According to the docs:     The '*', '+', and '?' qualifiers are all greedy; they match as much text as possible. Sometimes this behavior isn’t desired; if the RE <.*> is matched against '<H1>title</H1>', it will match the entire string, and not just '<H1>'. Adding '?' after the qualifier makes it perform the match in non-greedy or minimal fashion; as few characters as possible will be matched. Using .*? in the previous expression will match only '<H1>'.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "56",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  Would not \\\\(.*?\\\\) work? That is the non-greedy syntax.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  As the others have said using the ? modifier on the * quantifier will solve your immediate problem, but be careful, you are starting to stray into areas where regexes stop working and you need a parser instead.  For instance, the string \"(foo (bar)) baz\" will cause you problems.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  Do you want it to match \"(b)\"?  Do as Zitrax and Paolo have suggested.  Do you want it to match \"b\"?  Do  >>> x = \"a (b) c (d) e\" >>> re.search(r\"\\((.*?)\\)\", x).group(1) 'b'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python non-greedy regexes",
        "A_Content": "  Using an ungreedy match is a good start, but I'd also suggest that you reconsider any use of .* -- what about this?  groups = re.search(r\"\\([^)]*\\)\", x)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "regex-greedy"
        ],
        "URL": "https://stackoverflow.com/questions/766372/python-non-greedy-regexes",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I make a python regex like \"(.*)\" such that, given \"a (b) c (d) e\" python matches \"b\" instead of \"b) c (d\"?  I know that I can use \"[^)]\" instead of \".\", but I'm looking for a more general solution that keeps my regex a little cleaner. Is there any way to tell python \"hey, match this as soon as possible\"?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  The following code should do the job, it is cross-platform and runs on Python 2.4-3.2. I tested it on Windows, OS X and Linux.  from tendo import singleton me = singleton.SingleInstance() # will sys.exit(-1) if other instance is running   The latest code version is available singleton.py. Please file bugs here.  You can install tend using one of the following methods:   easy_install tendo pip install tendo manually by getting it from http://pypi.python.org/pypi/tendo      ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  Simple, cross-platform solution, found in another question by zgoda:  import fcntl, sys pid_file = 'program.pid' fp = open(pid_file, 'w') try:     fcntl.lockf(fp, fcntl.LOCK_EX | fcntl.LOCK_NB) except IOError:     # another instance is running     sys.exit(0)   A lot like S.Lott's suggestion, but with the code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  This code is Linux specific. It uses 'abstract' UNIX domain sockets, but it is simple and won't leave stale lock files around. I prefer it to the solution above because it doesn't require a specially reserved TCP port.   try:     import socket     s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)     ## Create an abstract socket, by prefixing it with null.      s.bind( '\\0postconnect_gateway_notify_lock')  except socket.error as e:     error_code = e.args[0]     error_string = e.args[1]     print \"Process already running (%d:%s ). Exiting\" % ( error_code, error_string)      sys.exit (0)    The unique string postconnect_gateway_notify_lock can be changed to allow multiple programs that need a single instance enforced.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  I don't know if it's pythonic enough, but in the Java world listening on a defined port is a pretty widely used solution, as it works on all major platforms and doesn't have any problems with crashing programs.  Another advantage of listening to a port is that you could send a command to the running instance. For example when the users starts the program a second time, you could send the running instance a command to tell it to open another window (that's what Firefox does, for example. I don't know if they use TCP ports or named pipes or something like that, 'though).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  Use a pid file.  You have some known location, \"/path/to/pidfile\" and at startup you do something like this (partially pseudocode because I'm pre-coffee and don't want to work all that hard):  import os, os.path pidfilePath = \"\"\"/path/to/pidfile\"\"\" if os.path.exists(pidfilePath):    pidfile = open(pidfilePath,\"r\")    pidString = pidfile.read()    if <pidString is equal to os.getpid()>:       # something is real weird       Sys.exit(BADCODE)    else:       <use ps or pidof to see if the process with pid pidString is still running>       if  <process with pid == 'pidString' is still running>:           Sys.exit(ALREADAYRUNNING)       else:           # the previous server must have crashed           <log server had crashed>           <reopen pidfilePath for writing>           pidfile.write(os.getpid()) else:     <open pidfilePath for writing>     pidfile.write(os.getpid())   So, in other words, you're checking if a pidfile exists; if not, write your pid to that file.  If the pidfile does exist, then check to see if the pid is the pid of a running process; if so, then you've got another live process running, so just shut down.  If not, then the previous process crashed, so log it, and then write your own pid to the file in place of the old one.  Then continue.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  Never written python before, but this is what I've just implemented in mycheckpoint, to prevent it being started twice or more by crond:  import os import sys import fcntl fh=0 def run_once():     global fh     fh=open(os.path.realpath(__file__),'r')     try:         fcntl.flock(fh,fcntl.LOCK_EX|fcntl.LOCK_NB)     except:         os._exit(0)  run_once()   Found Slava-N's suggestion after posting this in another issue (http://stackoverflow.com/questions/2959474). This one is called as a function, locks the executing scripts file (not a pid file) and maintains the lock until the script ends (normal or error).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  You already found reply to similar question in another thread, so for completeness sake see how to achieve the same on Windows uning named mutex.  http://code.activestate.com/recipes/474070/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  This may work.   Attempt create a PID file to a known location.  If you fail, someone has the file locked, you're done. When you finish normally, close and remove the PID file, so someone else can overwrite it.   You can wrap your program in a shell script that removes the PID file even if your program crashes.  You can, also, use the PID file to kill the program if it hangs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  Using a lock-file is a quite common approach on unix.  If it crashes, you have to clean up manually.  You could stor the PID in the file, and on startup check if there is a process with this PID, overriding the lock-file if not.  (However, you also need a lock around the read-file-check-pid-rewrite-file).  You will find what you need for getting and checking pid in the os-package.  The common way of checking if there exists a process with a given pid, is to send it a non-fatal signal.  Other alternatives could be combining this with flock or posix semaphores.  Opening a network socket, as saua proposed, would probably be the easiest and most portable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  For anybody using wxPython for their application, you can use the function  wx.SingleInstanceChecker documented here.  I personally use a subclass of wx.App which makes use of wx.SingleInstanceChecker and returns False from OnInit() if there is an existing instance of the app already executing like so:  import wx  class SingleApp(wx.App):     \"\"\"     class that extends wx.App and only permits a single running instance.     \"\"\"      def OnInit(self):         \"\"\"         wx.App init function that returns False if the app is already running.         \"\"\"         self.name = \"SingleApp-%s\".format(wx.GetUserId())         self.instance = wx.SingleInstanceChecker(self.name)         if self.instance.IsAnotherRunning():             wx.MessageBox(                 \"An instance of the application is already running\",                  \"Error\",                   wx.OK | wx.ICON_WARNING             )             return False         return True   This is a simple drop-in replacement for wx.App that prohibits multiple instances. To use it simply replace wx.App with SingleApp in your code like so:  app = SingleApp(redirect=False) frame = wx.Frame(None, wx.ID_ANY, \"Hello World\") frame.Show(True) app.MainLoop()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  I'm posting this as an answer because I'm a new user and Stack Overflow won't let me vote yet.  Sorin Sbarnea's solution works for me under OS X, Linux and Windows, and I am grateful for it.  However, tempfile.gettempdir() behaves one way under OS X and Windows and another under other some/many/all(?) *nixes (ignoring the fact that OS X is also Unix!). The difference is important to this code.   OS X and Windows have user-specific temp directories, so a tempfile created by one user isn't visible to another user. By contrast, under many versions of *nix (I tested Ubuntu 9, RHEL 5, OpenSolaris 2008 and FreeBSD 8), the temp dir is /tmp for all users.  That means that when the lockfile is created on a multi-user machine, it's created in /tmp and only the user who creates the lockfile the first time will be able to run the application.  A possible solution is to embed the current username in the name of the lock file.  It's worth noting that the OP's solution of grabbing a port will also misbehave on a multi-user machine.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  I use single_process on my gentoo;  pip install single_process   example:   from single_process import single_process  @single_process def main():     print 1  if __name__ == \"__main__\":     main()      refer: https://pypi.python.org/pypi/single_process/1.0     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  Here is my eventual Windows-only solution.  Put the following into a module, perhaps called 'onlyone.py', or whatever.  Include that module directly into your __ main __ python script file.  import win32event, win32api, winerror, time, sys, os main_path = os.path.abspath(sys.modules['__main__'].__file__).replace(\"\\\\\", \"/\")  first = True while True:         mutex = win32event.CreateMutex(None, False, main_path + \"_{<paste YOUR GUID HERE>}\")         if win32api.GetLastError() == 0:             break         win32api.CloseHandle(mutex)         if first:             print \"Another instance of %s running, please wait for completion\" % main_path             first = False         time.sleep(1)   Explanation  The code attempts to create a mutex with name derived from the full path to the script.  We use forward-slashes to avoid potential confusion with the real file system.  Advantages   No configuration or 'magic' identifiers needed, use it in as many different scripts as needed. No stale files left around, the mutex dies with you. Prints a helpful message when waiting      ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  linux example  This method is based on the creation of a temporary file automatically deleted after you close the application. the program launch we verify the existence of the file; if the file exists ( there is a pending execution) , the program is closed ; otherwise it creates the file and continues the execution of the program.  from tempfile import * import time import os import sys   f = NamedTemporaryFile( prefix='lock01_', delete=True) if not [f  for f in     os.listdir('/tmp') if f.find('lock01_')!=-1] else sys.exit()  YOUR CODE COMES HERE      ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  I keep suspecting there ought to be a good POSIXy solution using process groups, without having to hit the file system, but I can't quite nail it down. Something like:  On startup, your process sends a 'kill -0' to all processes in a particular group. If any such processes exist, it exits. Then it joins the group. No other processes use that group.  However, this has a race condition - multiple processes could all do this at precisely the same time and all end up joining the group and running simultaneously. By the time you've added some sort of mutex to make it watertight, you no longer need the process groups.  This might be acceptable if your process only gets started by cron, once every minute or every hour, but it makes me a bit nervous that it would go wrong precisely on the day when you don't want it to.  I guess this isn't a very good solution after all, unless someone can improve on it?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Python: single instance of program",
        "A_Content": "  I ran into this exact problem last week, and although I did find some good solutions, I decided to make a very simple and clean python package and uploaded it to PyPI. It differs from tendo in that it can lock any string resource name. Although you could certainly lock __file__ to achieve the same effect.  Install with: pip install quicklock  Using it is extremely simple:  [nate@Nates-MacBook-Pro-3 ~/live] python Python 2.7.6 (default, Sep  9 2014, 15:04:36) [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.39)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> from quicklock import singleton >>> # Let's create a lock so that only one instance of a script will run ... >>> singleton('hello world') >>> >>> # Let's try to do that again, this should fail ... >>> singleton('hello world') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/Users/nate/live/gallery/env/lib/python2.7/site-packages/quicklock/quicklock.py\", line 47, in singleton     raise RuntimeError('Resource <{}> is currently locked by <Process {}: \"{}\">'.format(resource, other_process.pid, other_process.name())) RuntimeError: Resource <hello world> is currently locked by <Process 24801: \"python\"> >>> >>> # But if we quit this process, we release the lock automatically ... >>> ^D [nate@Nates-MacBook-Pro-3 ~/live] python Python 2.7.6 (default, Sep  9 2014, 15:04:36) [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.39)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> from quicklock import singleton >>> singleton('hello world') >>> >>> # No exception was thrown, we own 'hello world'!   Take a look: https://pypi.python.org/pypi/quicklock     ",
        "Language": "Python",
        "Tags": [
            "python",
            "locking"
        ],
        "URL": "https://stackoverflow.com/questions/380870/python-single-instance-of-program",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a Pythonic way to have only one instance of a program running?   The only reasonable solution I've come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it's not really a great idea, maybe there's something more lightweight than this?    (Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won't work)  Update: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I'd have to go with that one.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "In Python how should I test if a variable is None, True or False",
        "A_Content": "  Don't fear the Exception!  Having your program just log and continue is as easy as:  try:     result = simulate(open(\"myfile\")) except SimulationException as sim_exc:     print \"error parsing stream\", sim_exc else:     if result:         print \"result pass\"     else:         print \"result fail\"  # execution continues from here, regardless of exception or not   And now you can have a much richer type of notification from the simulate method as to what exactly went wrong, in case you find error/no-error not to be informative enough.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2020598/in-python-how-should-i-test-if-a-variable-is-none-true-or-false",
        "A_Votes": "92",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a function that can return one of three things:   success (True) failure (False) error reading/parsing stream (None)   My question is, if I'm not supposed to test against True or False, how should I see what the result is. Below is how I'm currently doing it:  result = simulate(open(\"myfile\")) if result == None:     print \"error parsing stream\" elif result == True: # shouldn't do this     print \"result pass\" else:     print \"result fail\"   is it really as simple as removing the == True part or should I add a tri-bool data-type. I do not want the simulate function to throw an exception as all I want the outer program to do with an error is log it and continue.      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "In Python how should I test if a variable is None, True or False",
        "A_Content": "  if result is None:     print \"error parsing stream\" elif result:     print \"result pass\" else:     print \"result fail\"   keep it simple and explicit. You can of course pre-define a dictionary.  messages = {None: 'error', True: 'pass', False: 'fail'} print messages[result]   If you plan on modifying your simulate function to include more return codes, maintaining this code might become a bit of an issue.  The simulate might also raise an exception on the parsing error, in which case you'd either would catch it here or let it propagate a level up and the printing bit would be reduced to a one-line if-else statement.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2020598/in-python-how-should-i-test-if-a-variable-is-none-true-or-false",
        "A_Votes": "92",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a function that can return one of three things:   success (True) failure (False) error reading/parsing stream (None)   My question is, if I'm not supposed to test against True or False, how should I see what the result is. Below is how I'm currently doing it:  result = simulate(open(\"myfile\")) if result == None:     print \"error parsing stream\" elif result == True: # shouldn't do this     print \"result pass\" else:     print \"result fail\"   is it really as simple as removing the == True part or should I add a tri-bool data-type. I do not want the simulate function to throw an exception as all I want the outer program to do with an error is log it and continue.      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "In Python how should I test if a variable is None, True or False",
        "A_Content": "  Never, never, never say  if something == True:   Never.  It's crazy, since you're redundantly repeating what is redundantly specified as the redundant condition rule for an if-statement.  Worse, still, never, never, never say  if something == False:   You have not.  Feel free to use it.  Finally, doing a == None is inefficient.  Do a is None.  None is a special singleton object, there can only be one.  Just check to see if you have that object.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2020598/in-python-how-should-i-test-if-a-variable-is-none-true-or-false",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a function that can return one of three things:   success (True) failure (False) error reading/parsing stream (None)   My question is, if I'm not supposed to test against True or False, how should I see what the result is. Below is how I'm currently doing it:  result = simulate(open(\"myfile\")) if result == None:     print \"error parsing stream\" elif result == True: # shouldn't do this     print \"result pass\" else:     print \"result fail\"   is it really as simple as removing the == True part or should I add a tri-bool data-type. I do not want the simulate function to throw an exception as all I want the outer program to do with an error is log it and continue.      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "In Python how should I test if a variable is None, True or False",
        "A_Content": "  I would like to stress that, even if there are situations where if expr : isn't sufficient because one wants to make sure expr is True and not just different from 0/None/whatever, is is to be prefered from == for the same reason S.Lott mentionned for avoiding == None.  It is indeed slightly more efficient and, cherry on the cake, more human readable.  Input :  from time import time t0 = time() print ( ( 1 == 1 ) == True ) t1 = time() print ( ( 1 == 1 ) is True ) t2 = time() print '{:e}s\\n{:e}s'.format( t1-t0, t2-t1)   Output :  True True 1.201630e-04s 8.797646e-05s      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2020598/in-python-how-should-i-test-if-a-variable-is-none-true-or-false",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a function that can return one of three things:   success (True) failure (False) error reading/parsing stream (None)   My question is, if I'm not supposed to test against True or False, how should I see what the result is. Below is how I'm currently doing it:  result = simulate(open(\"myfile\")) if result == None:     print \"error parsing stream\" elif result == True: # shouldn't do this     print \"result pass\" else:     print \"result fail\"   is it really as simple as removing the == True part or should I add a tri-bool data-type. I do not want the simulate function to throw an exception as all I want the outer program to do with an error is log it and continue.      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "In Python how should I test if a variable is None, True or False",
        "A_Content": "  I believe that throwing an exception is a better idea for your situation. An alternative will be the simulation method to return a tuple. The first item will be the status and the second one the result:  result = simulate(open(\"myfile\")) if not result[0]:   print \"error parsing stream\" else:   ret= result[1]      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/2020598/in-python-how-should-i-test-if-a-variable-is-none-true-or-false",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a function that can return one of three things:   success (True) failure (False) error reading/parsing stream (None)   My question is, if I'm not supposed to test against True or False, how should I see what the result is. Below is how I'm currently doing it:  result = simulate(open(\"myfile\")) if result == None:     print \"error parsing stream\" elif result == True: # shouldn't do this     print \"result pass\" else:     print \"result fail\"   is it really as simple as removing the == True part or should I add a tri-bool data-type. I do not want the simulate function to throw an exception as all I want the outer program to do with an error is log it and continue.      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  I personally prefer to use lambdas in such a scenario, because imo it's clearer and simpler and also doesn't force you to write lots of wrapper methods if you don't have control over the called method, but that's certainly a matter of taste.  That's how you'd do it with a lambda (note there's also some implementation of currying in the functional module, so you can use that too):  button = Tk.Button(master=frame, text='press', command= lambda: action(someNumber))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  This can also be done by using partial from the standard library functools, like this:  from functools import partial #(...) action_with_arg = partial(action, arg) button = Tk.Button(master=frame, text='press', command=action_with_arg)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  Python's ability to provide default values for function arguments gives us a way out.  def fce(x=myX, y=myY):     myFunction(x,y) button = Tk.Button(mainWin, text='press', command=fce)   See: http://infohost.nmt.edu/tcc/help/pubs/tkinter/web/extra-args.html  For more buttons you can create a function which returns a function:  def fce(myX, myY):     def wrapper(x=myX, y=myY):         pass         pass         pass         return x+y     return wrapper  button1 = Tk.Button(mainWin, text='press 1', command=fce(1,2)) button2 = Tk.Button(mainWin, text='press 2', command=fce(3,4)) button3 = Tk.Button(mainWin, text='press 3', command=fce(9,8))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  Example GUI:  Let's say I have the GUI:  import tkinter as tk  root = tk.Tk()  btn = tk.Button(root, text=\"Press\") btn.pack()  root.mainloop()   What Happens When a Button Is Pressed  See that when btn is pressed it calls its own function which is very similar to button_press_handle in the following example:  def button_press_handle(callback=None):     if callback:         callback() # Where exactly the method assigned to btn['command'] is being callled   with:  button_press_handle(btn['command'])   You can simply think that command option should be set as, the reference to the method we want to be called, similar to callback in button_press_handle.    Calling a Method(Callback) When the Button is Pressed  Without arguments   So if I wanted to print something when the button is pressed I would need to set:  btn['command'] = print # default to print is new line   Pay close attention to the lack of () with the print method which is omitted in the meaning that: \"This is the method's name which I want you to call when pressed but don't call it just this very instant.\" However, I didn't pass any arguments for the print so it printed whatever it prints when called without arguments.  With Argument(s)  Now If I wanted to also pass arguments to the method I want to be called when the button is pressed I could make use of the anonymous functions, which can be created with lambda statement, in this case for print built-in method, like the following:  btn['command'] = lambda arg1=\"Hello\", arg2=\" \", arg3=\"World!\" : print(arg1 + arg2 + arg3)     Calling Multiple Methods when the Button Is Pressed  Without Arguments  You can also achieve that using lambda statement but it is considered bad practice and thus I won't include it here. The good practice is to define a separate method, multiple_methods, that calls the methods wanted and then set it as the callback to the button press:  def multiple_methods():     print(\"Vicariously\") # the first inner callback     print(\"I\") # another inner callback   With Argument(s)  In order to pass argument(s) to method that calls other methods, again make use of lambda statement, but first:  def multiple_methods(*args, **kwargs):     print(args[0]) # the first inner callback     print(kwargs['opt1']) # another inner callback   and then set:  btn['command'] = lambda arg=\"live\", kw=\"as the\" : a_new_method(arg, opt1=kw)     Returning Object(s) From the Callback  Also further note that callback can't really return because it's only called inside button_press_handle with callback() as opposed to return callback(). It does return but not anywhere outside that function. Thus you should rather modify object(s) that are accessible in the current scope.    Complete Example with global Object Modification(s)  Below example will call a method that changes btn's text each time the button is pressed:  import tkinter as tk  i = 0 def text_mod():     global i, btn           # btn can be omitted but not sure if should be     txt = (\"Vicariously\", \"I\", \"live\", \"as\", \"the\", \"whole\", \"world\", \"dies\")     btn['text'] = txt[i]    # the global object that is modified     i = (i + 1) % len(txt)  # another global object that gets modified  root = tk.Tk()  btn = tk.Button(root, text=\"My Button\") btn['command'] = text_mod  btn.pack(fill='both', expand=True)  root.mainloop()     Mirror     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  The reason it invokes the method immediately and pressing the button does nothing is that action(somenumber) is evaluated and its return value is attributed as the command for the button. So if action prints something to tell you it has run and returns None, you just run action to evaluate its return value and given None as the command for the button.  To have buttons to call functions with different arguments you can use global variables, although I can't recommend it:  import Tkinter as Tk  frame = Tk.Frame(width=5, height=2, bd=1, relief=Tk.SUNKEN) frame.grid(row=2,column=2) frame.pack(fill=Tk.X, padx=5, pady=5) def action():     global output     global variable     output.insert(Tk.END,variable.get()) button = Tk.Button(master=frame, text='press', command=action) button.pack() variable = Tk.Entry(master=frame) variable.pack() output = Tk.Text(master=frame) output.pack()  if __name__ == '__main__':     Tk.mainloop()   What I would do is make a class whose objects would contain every variable required and methods to change those as needed:  import Tkinter as Tk class Window:     def __init__(self):         self.frame = Tk.Frame(width=5, height=2, bd=1, relief=Tk.SUNKEN)         self.frame.grid(row=2,column=2)         self.frame.pack(fill=Tk.X, padx=5, pady=5)          self.button = Tk.Button(master=self.frame, text='press', command=self.action)         self.button.pack()          self.variable = Tk.Entry(master=self.frame)         self.variable.pack()          self.output = Tk.Text(master=self.frame)         self.output.pack()      def action(self):         self.output.insert(Tk.END,self.variable.get())  if __name__ == '__main__':     window = Window()     Tk.mainloop()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  One simple way would be to configure button with lambda like the following syntax:  button['command'] = lambda arg1 = local_var1, arg2 = local_var2 : function(arg1, arg2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  button = Tk.Button(master=frame, text='press', command=lambda: action(someNumber))   I believe should fix this     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  Use a lambda to pass the entry data to the command function if you have more actions to carry out, like this (I've tried to make it generic, so just adapt):  event1 = Entry(master) button1 = Button(master, text=\"OK\", command=lambda: test_event(event1.get()))  def test_event(event_text):     if not event_text:         print(\"Nothing entered\")     else:         print(str(event_text))         #  do stuff   This will pass the information in the event to the button function. There may be more Pythonesque ways of writing this, but it works for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  JasonPy - a few things...   if you stick a button in a loop it will be created over and over and over again... which is probably not what you want. (maybe it is)...  The reason it always gets the last index is lambda events run when you click them - not when the program starts. I'm not sure 100% what you are doing but maybe try storing the value when it's made then call it later with the lambda button.   eg: (don't use this code, just an example)  for entry in stuff_that_is_happening:     value_store[entry] = stuff_that_is_happening   then you can say....  button... command: lambda: value_store[1]   hope this helps!       ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  For posterity: you can also use classes to achieve something similar. For instance:  class Function_Wrapper():     def __init__(self, x, y, z):         self.x, self.y, self.z = x, y, z     def func(self):         return self.x + self.y + self.z # execute function   Button can then be simply created by:  instance1 = Function_Wrapper(x, y, z) button1  = Button(master, text = \"press\", command = instance1.func)   This approach also allows you to change the function arguments by i.e. setting instance1.x = 3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to pass arguments to a Button command in Tkinter?",
        "A_Content": "  Building on Matt Thompsons answer : a class can be made callable so it can be used instead of a function:  import tkinter as tk  class Callback:     def __init__(self, func, *args, **kwargs):         self.func = func         self.args = args         self.kwargs = kwargs     def __call__(self):         self.func(*self.args, **self.kwargs)  def default_callback(t):     print(\"Button '{}' pressed.\".format(t))  root = tk.Tk()  buttons = [\"A\", \"B\", \"C\"]  for i, b in enumerate(buttons):     tk.Button(root, text=b, command=Callback(default_callback, b)).grid(row=i, column=0)  tk.mainloop()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "button",
            "tkinter",
            "arguments"
        ],
        "URL": "https://stackoverflow.com/questions/6920302/how-to-pass-arguments-to-a-button-command-in-tkinter",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have the following Button made with Tkinter in Python:  import Tkinter as Tk win = Tk.Toplevel() frame = Tk.Frame(master=win).grid(row=1, column=1) button = Tk.Button(master=frame, text='press', command=action)   The method action is called when I press the button, but what if I wanted to pass some arguments to the method action?  I have tried with the following code:   button = Tk.Button(master=frame, text='press', command=action(someNumber))   This just invokes the method immediately, and pressing the button does nothing.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to convert list of key-value tuples into dictionary?",
        "A_Content": "     This gives me the same error as trying to split the list up and zip it. ValueError: dictionary update sequence element #0 has length 1916; 2 is required   THAT is your actual question.  The answer is that the elements of your list are not what you think they are. If you type myList[0] you will find that the first element of your list is not a two-tuple, e.g. ('A', 1), but rather a 1916-length iterable.  Once you actually have a list in the form you stated in your original question (myList = [('A',1),('B',2),...]), all you need to do is dict(myList).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/6586310/how-to-convert-list-of-key-value-tuples-into-dictionary",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list that looks like:  [('A', 1), ('B', 2), ('C', 3)]   I want to turn it into a dictionary that looks like:  {'A': 1, 'B': 2, 'C': 3}   What's the best way to go about this?  EDIT: My list of tuples is actually more like:  [(A, 12937012397), (BERA, 2034927830), (CE, 2349057340)]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to convert list of key-value tuples into dictionary?",
        "A_Content": "  >>> dict([('A', 1), ('B', 2), ('C', 3)]) {'A': 1, 'C': 3, 'B': 2}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/6586310/how-to-convert-list-of-key-value-tuples-into-dictionary",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list that looks like:  [('A', 1), ('B', 2), ('C', 3)]   I want to turn it into a dictionary that looks like:  {'A': 1, 'B': 2, 'C': 3}   What's the best way to go about this?  EDIT: My list of tuples is actually more like:  [(A, 12937012397), (BERA, 2034927830), (CE, 2349057340)]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to convert list of key-value tuples into dictionary?",
        "A_Content": "  Have you tried this?  >>> l=[('A',1), ('B',2), ('C',3)] >>> d=dict(l) >>> d {'A': 1, 'C': 3, 'B': 2}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/6586310/how-to-convert-list-of-key-value-tuples-into-dictionary",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list that looks like:  [('A', 1), ('B', 2), ('C', 3)]   I want to turn it into a dictionary that looks like:  {'A': 1, 'B': 2, 'C': 3}   What's the best way to go about this?  EDIT: My list of tuples is actually more like:  [(A, 12937012397), (BERA, 2034927830), (CE, 2349057340)]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to convert list of key-value tuples into dictionary?",
        "A_Content": "  Here is a way to handle duplicate tuple \"keys\":  # An example l = [('A', 1), ('B', 2), ('C', 3), ('A', 5), ('D', 0), ('D', 9)]  # A solution d = dict() [d [t [0]].append(t [1]) if t [0] in list(d.keys())   else d.update({t [0]: [t [1]]}) for t in l] d  OUTPUT: {'A': [1, 5], 'B': [2], 'C': [3], 'D': [0, 9]}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/6586310/how-to-convert-list-of-key-value-tuples-into-dictionary",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list that looks like:  [('A', 1), ('B', 2), ('C', 3)]   I want to turn it into a dictionary that looks like:  {'A': 1, 'B': 2, 'C': 3}   What's the best way to go about this?  EDIT: My list of tuples is actually more like:  [(A, 12937012397), (BERA, 2034927830), (CE, 2349057340)]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to change the name of a Django app?",
        "A_Content": "  Follow these steps to change an app's name in Django:   Rename the folder which is in your project root  Change any references to your app in their dependencies, i.e. the app's views.py, urls.py , 'manage.py' , and settings.py files. Edit the database table django_content_type with the following command: UPDATE django_content_type SET app_label='<NewAppName>' WHERE app_label='<OldAppName>'  Also if you have models, you will have to rename the model tables. For postgres use ALTER TABLE <oldAppName>_modelName RENAME TO <newAppName>_modelName. For mysql too I think it is the same (as mentioned by @null_radix) (For Django >= 1.7) Update the django_migrations table to avoid having your previous migrations re-run: UPDATE django_migrations SET app='<NewAppName>' WHERE app='<OldAppName>'. Note: there is some debate (in comments) if this step is required for Django 1.8+; If someone knows for sure please update here. If your models.py 's Meta Class has app_name listed, make sure to rename that too (mentioned by @will). If you've namespaced your static or templates folders inside your app, you'll also need to rename those. For example, rename old_app/static/old_app to new_app/static/new_app. For renaming django models, you'll need to change django_content_type.name entry in DB. For postgreSQL use UPDATE django_content_type SET name='<newModelName>' where name='<oldModelName>' AND app_label='<OldAppName>'   Meta point (If using virtualenv): Worth noting, if you are renaming the directory that contains your virtualenv, there will likely be several files in your env that contain an absolute path and will also need to be updated. If you are getting errors such as ImportError: No module named ... this might be the culprit. (thanks to @danyamachine for providing this).  Other references: you might also want to refer the below links for a more complete picture   Renaming an app with Django and South How do I migrate a model out of one django app and into a new one? How to change the name of a Django app? Backwards migration with Django South Easiest way to rename a model using Django/South? Python code (thanks to A.Raouf) to automate the above steps (Untested code. You have been warned!) Python code (thanks to rafaponieman) to automate the above steps (Untested code. You have been warned!)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8408046/how-to-change-the-name-of-a-django-app",
        "A_Votes": "195",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have changed the name of an app in Django by renaming its folder, imports and all its references (templates/indexes). But now I get this error when I try to run python manage.py runserver  Error: Could not import settings 'nameofmynewapp.settings' (Is it on sys.path?): No module named settings   How can I debug and solve this error? Any clues?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to change the name of a Django app?",
        "A_Content": "  New in Django 1.7 is a app registry that stores configuration and provides introspection. This machinery let's you change several app attributes.  The main point I want to make is that renaming an app isn't always necessary: With app configuration it is possible to resolve conflicting apps. But also the way to go if your app needs friendly naming.  As an example I want to name my polls app 'Feedback from users'. It goes like this:  Create a apps.py file in the polls directory:  from django.apps import AppConfig  class PollsConfig(AppConfig):     name = 'polls'     verbose_name = \"Feedback from users\"   Add the default app config to your polls/__init__.py:  default_app_config = 'polls.apps.PollsConfig'   For more app configuration: https://docs.djangoproject.com/en/1.7/ref/applications/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8408046/how-to-change-the-name-of-a-django-app",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have changed the name of an app in Django by renaming its folder, imports and all its references (templates/indexes). But now I get this error when I try to run python manage.py runserver  Error: Could not import settings 'nameofmynewapp.settings' (Is it on sys.path?): No module named settings   How can I debug and solve this error? Any clues?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to change the name of a Django app?",
        "A_Content": "  In case you are using PyCharm and project stops working after rename:   Edit Run/Debug configuration and change environment variable DJANGO_SETTINGS_MODULE, since it includes your project name. Go to Settings / Languages & Frameworks / Django and update the settings file location.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8408046/how-to-change-the-name-of-a-django-app",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have changed the name of an app in Django by renaming its folder, imports and all its references (templates/indexes). But now I get this error when I try to run python manage.py runserver  Error: Could not import settings 'nameofmynewapp.settings' (Is it on sys.path?): No module named settings   How can I debug and solve this error? Any clues?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to change the name of a Django app?",
        "A_Content": "  Fun problem! I'm going to have to rename a lot of apps soon, so I did a dry run.  This method allows progress to be made in atomic steps, to minimise disruption for other developers working on the app you're renaming.  See the link at the bottom of this answer for working example code.   Prepare existing code for the move:   Create an app config (set name and label to defaults). Add the app config to INSTALLED_APPS. On all models, explicitly set db_table to the current value. Doctor migrations so that db_table was \"always\" explicitly defined. Ensure no migrations are required (checks previous step).  Change the app label:   Set label in app config to new app name. Update migrations and foreign keys to reference new app label. Update templates for generic class-based views (the default path is <app_label>/<model_name>_<suffix>.html) Run raw SQL to fix migrations and content_types app (unfortunately, some raw SQL is unavoidable).  UPDATE django_migrations    SET app = 'catalogue'  WHERE app = 'shop';  UPDATE django_content_type    SET app_label = 'catalogue'  WHERE app_label = 'shop';  Ensure no migrations are required (checks previous step).  Rename the tables:   Remove \"custom\" db_table. Run makemigrations so django can rename the table \"to the default\".  Move the files:   Rename module directory. Fix imports. Update app config's name. Update where INSTALLED_APPS references the app config.  Tidy up:   Remove custom app config if it's no longer required. If app config gone, don't forget to also remove it from INSTALLED_APPS.      Example solution: I've created app-rename-example, an example project where you can see how I renamed an app, one commit at a time.  The example uses Python 2.7 and Django 1.8, but I'm confident the same process will work on at least Python 3.6 and Django 2.1.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8408046/how-to-change-the-name-of-a-django-app",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have changed the name of an app in Django by renaming its folder, imports and all its references (templates/indexes). But now I get this error when I try to run python manage.py runserver  Error: Could not import settings 'nameofmynewapp.settings' (Is it on sys.path?): No module named settings   How can I debug and solve this error? Any clues?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to change the name of a Django app?",
        "A_Content": "  Re-migrate approach for a cleaner plate.   This can painlessly be done IF other apps do not foreign key models from the app to be renamed. Check and make sure their migration files don't list any migrations from this one.     Backup your database. Dump all tables with a) data + schema for possible circular dependencies, and b) just data for reloading.  Run your tests.  Check all code into VCS.  Delete the database tables of the app to be renamed. Delete the permissions: delete from auth_permission where content_type_id in (select id from django_content_type where app_label = '<OldAppName>') Delete content types: delete from django_content_type where app_label = '<OldAppName>' Rename the folder of the app.  Change any references to your app in their dependencies, i.e. the app's views.py, urls.py , 'manage.py' , and settings.py files. Delete migrations: delete from django_migrations where app = '<OldAppName>' If your models.py 's Meta Class has app_name listed, make sure to rename that too (mentioned by @will). If you've namespaced your static or templates folders inside your app, you'll also need to rename those. For example, rename old_app/static/old_app to new_app/static/new_app. If you defined app config in apps.py; rename those, and rename their references in settings.INSTALLED_APPS Delete migration files.  Re-make migrations, and migrate.  Load your table data from backups.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8408046/how-to-change-the-name-of-a-django-app",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have changed the name of an app in Django by renaming its folder, imports and all its references (templates/indexes). But now I get this error when I try to run python manage.py runserver  Error: Could not import settings 'nameofmynewapp.settings' (Is it on sys.path?): No module named settings   How can I debug and solve this error? Any clues?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Find and replace string values in Python list",
        "A_Content": "  words = [w.replace('[br]', '<br />') for w in words]   This is called List Comprehensions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3136689/find-and-replace-string-values-in-python-list",
        "A_Votes": "166",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I got this list:  words = ['how', 'much', 'is[br]', 'the', 'fish[br]', 'no', 'really']   What I would like is to replace [br] with some fantastic value similar to &lt;br /&gt; and thus getting a new list:  words = ['how', 'much', 'is<br />', 'the', 'fish<br />', 'no', 'really']      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Find and replace string values in Python list",
        "A_Content": "  Beside list comprehension, you can try map  >>> map(lambda x: str.replace(x, \"[br]\", \"<br/>\"), words) ['how', 'much', 'is<br/>', 'the', 'fish<br/>', 'no', 'really']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3136689/find-and-replace-string-values-in-python-list",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I got this list:  words = ['how', 'much', 'is[br]', 'the', 'fish[br]', 'no', 'really']   What I would like is to replace [br] with some fantastic value similar to &lt;br /&gt; and thus getting a new list:  words = ['how', 'much', 'is<br />', 'the', 'fish<br />', 'no', 'really']      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Find and replace string values in Python list",
        "A_Content": "  You can use, for example:  words = [word.replace('[br]','<br />') for word in words]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3136689/find-and-replace-string-values-in-python-list",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I got this list:  words = ['how', 'much', 'is[br]', 'the', 'fish[br]', 'no', 'really']   What I would like is to replace [br] with some fantastic value similar to &lt;br /&gt; and thus getting a new list:  words = ['how', 'much', 'is<br />', 'the', 'fish<br />', 'no', 'really']      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Find and replace string values in Python list",
        "A_Content": "  In case you're wondering about the performance of the different approaches, here are some timings:  In [1]: words = [str(i) for i in range(10000)]  In [2]: %timeit replaced = [w.replace('1', '<1>') for w in words] 100 loops, best of 3: 2.98 ms per loop  In [3]: %timeit replaced = map(lambda x: str.replace(x, '1', '<1>'), words) 100 loops, best of 3: 5.09 ms per loop  In [4]: %timeit replaced = map(lambda x: x.replace('1', '<1>'), words) 100 loops, best of 3: 4.39 ms per loop  In [5]: import re  In [6]: r = re.compile('1')  In [7]: %timeit replaced = [r.sub('<1>', w) for w in words] 100 loops, best of 3: 6.15 ms per loop   as you can see for such simple patterns the accepted list comprehension is the fastest, but look at the following:  In [8]: %timeit replaced = [w.replace('1', '<1>').replace('324', '<324>').replace('567', '<567>') for w in words] 100 loops, best of 3: 8.25 ms per loop  In [9]: r = re.compile('(1|324|567)')  In [10]: %timeit replaced = [r.sub('<\\1>', w) for w in words] 100 loops, best of 3: 7.87 ms per loop   This shows that for more complicated substitutions a pre-compiled reg-exp (as in 9-10) can be (much) faster. It really depends on your problem and the shortest part of the reg-exp.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/3136689/find-and-replace-string-values-in-python-list",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I got this list:  words = ['how', 'much', 'is[br]', 'the', 'fish[br]', 'no', 'really']   What I would like is to replace [br] with some fantastic value similar to &lt;br /&gt; and thus getting a new list:  words = ['how', 'much', 'is<br />', 'the', 'fish<br />', 'no', 'really']      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  Try this:  from bs4 import BeautifulSoup from bs4.element import Comment import urllib.request   def tag_visible(element):     if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:         return False     if isinstance(element, Comment):         return False     return True   def text_from_html(body):     soup = BeautifulSoup(body, 'html.parser')     texts = soup.findAll(text=True)     visible_texts = filter(tag_visible, texts)       return u\" \".join(t.strip() for t in visible_texts)  html = urllib.request.urlopen('http://www.nytimes.com/2009/12/21/us/21storm.html').read() print(text_from_html(html))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "163",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  The approved answer from @jbochi does not work for me.  The str() function call raises an exception because it cannot encode the non-ascii characters in the BeautifulSoup element.  Here is a more succinct way to filter the example web page to visible text.  html = open('21storm.html').read() soup = BeautifulSoup(html) [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])] visible_text = soup.getText()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  import urllib from bs4 import BeautifulSoup  url = \"https://www.yahoo.com\" html = urllib.urlopen(url).read() soup = BeautifulSoup(html)  # kill all script and style elements for script in soup([\"script\", \"style\"]):     script.extract()    # rip it out  # get text text = soup.get_text()  # break into lines and remove leading and trailing space on each lines = (line.strip() for line in text.splitlines()) # break multi-headlines into a line each chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # drop blank lines text = '\\n'.join(chunk for chunk in chunks if chunk)  print(text.encode('utf-8'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  I completely respect using Beautiful Soup to get rendered content, but it may not be the ideal package for acquiring the rendered content on a page.  I had a similar problem to get rendered content, or the visible content in a typical browser.  In particular I had many perhaps atypical cases to work with such a simple example below.  In this case the non displayable tag is nested in a style tag, and is not visible in many browsers that I have checked.  Other variations exist such as defining a class tag setting display to none.  Then using this class for the div.   <html>   <title>  Title here</title>    <body>      lots of text here <p> <br>     <h1> even headings </h1>      <style type=\"text/css\">          <div > this will not be visible </div>      </style>     </body>  </html>   One solution posted above is:   html = Utilities.ReadFile('simple.html') soup = BeautifulSoup.BeautifulSoup(html) texts = soup.findAll(text=True) visible_texts = filter(visible, texts) print(visible_texts)   [u'\\n', u'\\n', u'\\n\\n        lots of text here ', u' ', u'\\n', u' even headings ', u'\\n', u' this will not be visible ', u'\\n', u'\\n']   This solution certainly has applications in many cases and does the job quite well generally but in the html posted above it retains the text that is not rendered.  After searching SO a couple solutions came up here BeautifulSoup get_text does not strip all tags and JavaScript  and here Rendered HTML to plain text using Python  I tried both these solutions: html2text and nltk.clean_html and was surprised by the timing results so thought they warranted an answer for posterity.  Of course, the speeds highly depend on the contents of the data...  One answer here from @Helge was about using nltk of all things.    import nltk  %timeit nltk.clean_html(html) was returning 153 us per loop   It worked really well to return a string with rendered html.  This nltk module was faster than even html2text, though perhaps html2text is more robust.   betterHTML = html.decode(errors='ignore') %timeit html2text.html2text(betterHTML) %3.09 ms per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  Using BeautifulSoup the easiest way with less code to just get the strings, without empty lines and crap.  tag = <Parent_Tag_that_contains_the_data> soup = BeautifulSoup(tag, 'html.parser')  for i in soup.stripped_strings:     print repr(i)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  The title is inside an <nyt_headline> tag, which is nested inside an <h1> tag and a <div> tag with id \"article\".    soup.findAll('nyt_headline', limit=1)   Should work.  The article body is inside an <nyt_text> tag, which is nested inside a <div> tag with id \"articleBody\".  Inside the <nyt_text>  element, the text itself is contained within <p>  tags.  Images are not within those <p> tags.  It's difficult for me to experiment with the syntax, but I expect a working scrape to look something like this.  text = soup.findAll('nyt_text', limit=1)[0] text.findAll('p')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  While, i would completely suggest using beautiful-soup in general, if anyone is looking to display the visible parts of a malformed html (e.g. where you have just a segment or line of a web-page) for whatever-reason, the the following will remove content between < and > tags:  import re   ## only use with malformed html - this is not efficient def display_visible_html_using_re(text):                  return(re.sub(\"(\\<.*?\\>)\", \"\",text))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "BeautifulSoup Grab Visible Webpage Text",
        "A_Content": "  If you care about performance, here's another more efficient way:  import re  INVISIBLE_ELEMS = ('style', 'script', 'head', 'title') RE_SPACES = re.compile(r'\\s{3,}')  def visible_texts(soup):     \"\"\" get visible text from a document \"\"\"     text = ' '.join([         s for s in soup.strings         if s.parent.name not in INVISIBLE_ELEMS     ])     # collapse multiple spaces to two spaces.     return RE_SPACES.sub('  ', text)   soup.strings is an iterator, and it returns NavigableString so that you can check the parent's tag name directly, without going through multiple loops.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "text",
            "beautifulsoup",
            "html-content-extraction"
        ],
        "URL": "https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Basically, I want to use BeautifulSoup to grab strictly the visible text on a webpage. For instance, this webpage is my test case. And I mainly want to just get the body text (article) and maybe even a few tab names here and there. I have tried the suggestion in this SO question that returns lots of <script> tags and html comments which I don't want. I can't figure out the arguments I need for the function findAll() in order to just get the visible texts on a webpage.  So, how should I find all visible text excluding scripts, comments, css etc.?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  In newer version of numpy (>1.8.x), np.meshgrid provides a much faster implementation:  @pv's solution  In [113]:  %timeit cartesian(([1, 2, 3], [4, 5], [6, 7])) 10000 loops, best of 3: 135 µs per loop In [114]:  cartesian(([1, 2, 3], [4, 5], [6, 7]))  Out[114]: array([[1, 4, 6],        [1, 4, 7],        [1, 5, 6],        [1, 5, 7],        [2, 4, 6],        [2, 4, 7],        [2, 5, 6],        [2, 5, 7],        [3, 4, 6],        [3, 4, 7],        [3, 5, 6],        [3, 5, 7]])   numpy.meshgrid use to be 2D only, now it is capable of ND. In this case, 3D:  In [115]:  %timeit np.array(np.meshgrid([1, 2, 3], [4, 5], [6, 7])).T.reshape(-1,3) 10000 loops, best of 3: 74.1 µs per loop In [116]:  np.array(np.meshgrid([1, 2, 3], [4, 5], [6, 7])).T.reshape(-1,3)  Out[116]: array([[1, 4, 6],        [1, 5, 6],        [2, 4, 6],        [2, 5, 6],        [3, 4, 6],        [3, 5, 6],        [1, 4, 7],        [1, 5, 7],        [2, 4, 7],        [2, 5, 7],        [3, 4, 7],        [3, 5, 7]])   Note that the order of the final resultant is slightly different.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "62",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  Here's a pure-numpy implementation. It's ca. 5× faster than using itertools.   import numpy as np  def cartesian(arrays, out=None):     \"\"\"     Generate a cartesian product of input arrays.      Parameters     ----------     arrays : list of array-like         1-D arrays to form the cartesian product of.     out : ndarray         Array to place the cartesian product in.      Returns     -------     out : ndarray         2-D array of shape (M, len(arrays)) containing cartesian products         formed of input arrays.      Examples     --------     >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))     array([[1, 4, 6],            [1, 4, 7],            [1, 5, 6],            [1, 5, 7],            [2, 4, 6],            [2, 4, 7],            [2, 5, 6],            [2, 5, 7],            [3, 4, 6],            [3, 4, 7],            [3, 5, 6],            [3, 5, 7]])      \"\"\"      arrays = [np.asarray(x) for x in arrays]     dtype = arrays[0].dtype      n = np.prod([x.size for x in arrays])     if out is None:         out = np.zeros([n, len(arrays)], dtype=dtype)      m = n / arrays[0].size     out[:,0] = np.repeat(arrays[0], m)     if arrays[1:]:         cartesian(arrays[1:], out=out[0:m,1:])         for j in xrange(1, arrays[0].size):             out[j*m:(j+1)*m,1:] = out[0:m,1:]     return out      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  itertools.combinations is in general the fastest way to get combinations from a Python container (if you do in fact want combinations, i.e., arrangements WITHOUT repetitions and independent of order; that's not what your code appears to be doing, but I can't tell whether that's because your code is buggy or because you're using the wrong terminology).  If you want something different than combinations perhaps other iterators in itertools, product or permutations, might serve you better. For example, it looks like your code is roughly the same as:  for val in itertools.product(np.arange(0, 1, 0.1), repeat=6):     print F(val)   All of these iterators yield tuples, not lists or numpy arrays, so if your F is picky about getting specifically a numpy array you'll have to accept the extra overhead of constructing or clearing and re-filling one at each step.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  The following numpy implementation should be approx. 2x the speed of the given answer:  def cartesian2(arrays):     arrays = [np.asarray(a) for a in arrays]     shape = (len(x) for x in arrays)      ix = np.indices(shape, dtype=int)     ix = ix.reshape(len(arrays), -1).T      for n, arr in enumerate(arrays):         ix[:, n] = arrays[n][ix[:, n]]      return ix      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  It looks like you want a grid to evaluate your function,  in which case you can use numpy.ogrid (open) or numpy.mgrid (fleshed out):  import numpy my_grid = numpy.mgrid[[slice(0,1,0.1)]*6]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  You can do something like this  import numpy as np  def cartesian_coord(*arrays):     grid = np.meshgrid(*arrays)             coord_list = [entry.ravel() for entry in grid]     points = np.vstack(coord_list).T     return points  a = np.arange(4)  # fake data print(cartesian_coord(*6*[a])   which gives  array([[0, 0, 0, 0, 0, 0],    [0, 0, 0, 0, 0, 1],    [0, 0, 0, 0, 0, 2],    ...,     [3, 3, 3, 3, 3, 1],    [3, 3, 3, 3, 3, 2],    [3, 3, 3, 3, 3, 3]])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  Here's yet another way, using pure NumPy, no recursion, no list comprehension, and no explicit for loops. It's about 20% slower than the original answer, and it's based on np.meshgrid.  def cartesian(*arrays):     mesh = np.meshgrid(*arrays)  # standard numpy meshgrid     dim = len(mesh)  # number of dimensions     elements = mesh[0].size  # number of elements, any index will do     flat = np.concatenate(mesh).ravel()  # flatten the whole meshgrid     reshape = np.reshape(flat, (dim, elements)).T  # reshape and transpose     return reshape   For example,  x = np.arange(3) a = cartesian(x, x, x, x, x) print(a)   gives  [[0 0 0 0 0]  [0 0 0 0 1]  [0 0 0 0 2]  ...,   [2 2 2 2 0]  [2 2 2 2 1]  [2 2 2 2 2]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  you can use np.array(itertools.product(a, b))     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Using numpy to build an array of all combinations of two arrays",
        "A_Content": "  For a pure numpy implementation of Cartesian product of 1D arrays (or flat python lists), just use meshgrid(), roll the axes with transpose(), and reshape to the desired ouput:   def cartprod(*arrays):      N = len(arrays)      return transpose(meshgrid(*arrays, indexing='ij'),                        roll(arange(N + 1), -1)).reshape(-1, N)   Note this has the convention of last axis changing fastest (\"C style\" or \"row-major\").  In [88]: cartprod([1,2,3], [4,8], [100, 200, 300, 400], [-5, -4]) Out[88]:  array([[  1,   4, 100,  -5],        [  1,   4, 100,  -4],        [  1,   4, 200,  -5],        [  1,   4, 200,  -4],        [  1,   4, 300,  -5],        [  1,   4, 300,  -4],        [  1,   4, 400,  -5],        [  1,   4, 400,  -4],        [  1,   8, 100,  -5],        [  1,   8, 100,  -4],        [  1,   8, 200,  -5],        [  1,   8, 200,  -4],        [  1,   8, 300,  -5],        [  1,   8, 300,  -4],        [  1,   8, 400,  -5],        [  1,   8, 400,  -4],        [  2,   4, 100,  -5],        [  2,   4, 100,  -4],        [  2,   4, 200,  -5],        [  2,   4, 200,  -4],        [  2,   4, 300,  -5],        [  2,   4, 300,  -4],        [  2,   4, 400,  -5],        [  2,   4, 400,  -4],        [  2,   8, 100,  -5],        [  2,   8, 100,  -4],        [  2,   8, 200,  -5],        [  2,   8, 200,  -4],        [  2,   8, 300,  -5],        [  2,   8, 300,  -4],        [  2,   8, 400,  -5],        [  2,   8, 400,  -4],        [  3,   4, 100,  -5],        [  3,   4, 100,  -4],        [  3,   4, 200,  -5],        [  3,   4, 200,  -4],        [  3,   4, 300,  -5],        [  3,   4, 300,  -4],        [  3,   4, 400,  -5],        [  3,   4, 400,  -4],        [  3,   8, 100,  -5],        [  3,   8, 100,  -4],        [  3,   8, 200,  -5],        [  3,   8, 200,  -4],        [  3,   8, 300,  -5],        [  3,   8, 300,  -4],        [  3,   8, 400,  -5],        [  3,   8, 400,  -4]])   If you want to change the first axis fastest (\"FORTRAN style\" or \"column-major\"), just change the order parameter of reshape() like this: reshape((-1, N), order='F')     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "multidimensional-array",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this.  My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this:  First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays  from numpy import * def comb(a,b):     c = []     for i in a:         for j in b:             c.append(r_[i,j])     return c   Then I used reduce() to apply that to m copies of the same array:  def combs(a,m):     return reduce(comb,[a]*m)   And then I evaluate my function like this:  values = combs(np.arange(0,1,0.1),6) for val in values:     print F(val)   This works but it's waaaay too slow. I know the space of parameters is huge, but this shouldn't be so slow. I have only sampled 106 (a million) points in this example and it took more than 15 seconds just to create the array values.  Do you know any more efficient way of doing this with numpy?   I can modify the way the function F takes it's arguments if it's necessary.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  Python 2  Here is a more straightforward way if all you want to do is save it as a file:  import urllib  urllib.urlretrieve(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\", \"local-filename.jpg\")   The second argument is the local path where the file should be saved.  Python 3  As SergO suggested the  code below should work with Python 3.  import urllib.request  urllib.request.urlretrieve(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\", \"local-filename.jpg\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "212",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  import urllib resource = urllib.urlopen(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\") output = open(\"file01.jpg\",\"wb\") output.write(resource.read()) output.close()   file01.jpg will contain your image.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  I wrote a script that does just this, and it is available on my github for your use.   I utilized BeautifulSoup to allow me to parse any website for images. If you will be doing much web scraping (or intend to use my tool) I suggest you sudo pip install BeautifulSoup. Information on BeautifulSoup is available here.  For convenience here is my code:  from bs4 import BeautifulSoup from urllib2 import urlopen import urllib  # use this image scraper from the location that  #you want to save scraped images to  def make_soup(url):     html = urlopen(url).read()     return BeautifulSoup(html)  def get_images(url):     soup = make_soup(url)     #this makes a list of bs4 element tags     images = [img for img in soup.findAll('img')]     print (str(len(images)) + \"images found.\")     print 'Downloading images to current working directory.'     #compile our unicode list of image links     image_links = [each.get('src') for each in images]     for each in image_links:         filename=each.split('/')[-1]         urllib.urlretrieve(each, filename)     return image_links  #a standard call looks like this #get_images('http://www.wookmark.com')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  I made a script expanding on Yup.'s script. I fixed some things. It will now bypass 403:Forbidden problems. It wont crash when an image fails to be retrieved. It tries to avoid corrupted previews. It gets the right absolute urls. It gives out more information. It can be run with an argument from the command line.   # getem.py # python2 script to download all images in a given url # use: python getem.py http://url.where.images.are  from bs4 import BeautifulSoup import urllib2 import shutil import requests from urlparse import urljoin import sys import time  def make_soup(url):     req = urllib2.Request(url, headers={'User-Agent' : \"Magic Browser\"})      html = urllib2.urlopen(req)     return BeautifulSoup(html, 'html.parser')  def get_images(url):     soup = make_soup(url)     images = [img for img in soup.findAll('img')]     print (str(len(images)) + \" images found.\")     print 'Downloading images to current working directory.'     image_links = [each.get('src') for each in images]     for each in image_links:         try:             filename = each.strip().split('/')[-1].strip()             src = urljoin(url, each)             print 'Getting: ' + filename             response = requests.get(src, stream=True)             # delay to avoid corrupted previews             time.sleep(1)             with open(filename, 'wb') as out_file:                 shutil.copyfileobj(response.raw, out_file)         except:             print '  An error occured. Continuing.'     print 'Done.'  if __name__ == '__main__':     url = sys.argv[1]     get_images(url)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  A solution which works with Python 2 and Python 3:  try:     from urllib.request import urlretrieve  # Python 3 except ImportError:     from urllib import urlretrieve  # Python 2  url = \"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\" urlretrieve(url, \"local-filename.jpg\")   or, if the additional requirement of requests is acceptable and if it is a http(s) URL:  def load_requests(source_url, sink_path):     \"\"\"     Load a file from an URL (e.g. http).      Parameters     ----------     source_url : str         Where to load the file from.     sink_path : str         Where the loaded file is stored.     \"\"\"     import requests     r = requests.get(source_url, stream=True)     if r.status_code == 200:         with open(sink_path, 'wb') as f:             for chunk in r:                 f.write(chunk)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  Python 3  urllib.request — Extensible library for opening URLs  from urllib.error import HTTPError from urllib.request import urlretrieve  try:     urlretrieve(image_url, image_local_path) except FileNotFoundError as err:     print(err)   # something wrong with local path except HTTPError as err:     print(err)  # something wrong with url      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  This is very short answer.  import urllib urllib.urlretrieve(\"http://photogallery.sandesh.com/Picture.aspx?AlubumId=422040\", \"Abc.jpg\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to save an image locally using Python whose URL address I already know?",
        "A_Content": "  img_data=requests.get('https://apod.nasa.gov/apod/image/1701/potw1636aN159_HST_2048.jpg')  with open(str('file_name.jpg', 'wb') as handler:     handler.write(img_data)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "web-scraping"
        ],
        "URL": "https://stackoverflow.com/questions/8286352/how-to-save-an-image-locally-using-python-whose-url-address-i-already-know",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I know the URL of an image on Internet.  e.g. http://www.digimouth.com/news/media/2011/09/google-logo.jpg, which contains the logo of Google.  Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  As you already mentioned, this is straightforward to do in Python 2.6 or newer:  enumerate(range(2000, 2005), 1)   Python 2.5 and older do not support the start parameter so instead you could create two range objects and zip them:  r = xrange(2000, 2005) r2 = xrange(1, len(r) + 1) h = zip(r2, r) print h   Result:   [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   If you want to create a generator instead of a list then you can use izip instead.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "114",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  Just to put this here for posterity sake, in 2.6 the \"start\" parameter was added to enumerate like so:  enumerate(sequence, start=1)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "130",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  Easy, just define your own function that does what you want:  def enum(seq, start=0):     for i, x in enumerate(seq):         yield i+start, x      ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  Simplest way to do in Python 2.5 exactly what you ask about:  import itertools as it  ... it.izip(it.count(1), xrange(2000, 2005)) ...   If you want a list, as you appear to, use zip in lieu of it.izip.  (BTW, as a general rule, the best way to make a list out of a generator or any other iterable X is not [x for x in X], but rather list(X)).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  from itertools import count, izip  def enumerate(L, n=0):     return izip( count(n), L)  # if 2.5 has no count def count(n=0):     while True:         yield n         n+=1   Now h = list(enumerate(xrange(2000, 2005), 1)) works.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  enumerate is trivial, and so is re-implementing it to accept a start:  def enumerate(iterable, start = 0):     n = start     for i in iterable:         yield n, i         n += 1   Note that this doesn't break code using enumerate without start argument. Alternatively, this oneliner may be more elegant and possibly faster, but breaks other uses of enumerate:  enumerate = ((index+1, item) for index, item)     The latter was pure nonsense. @Duncan got the wrapper right.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  >>> list(enumerate(range(1999, 2005)))[1:] [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  h = [(i + 1, x) for i, x in enumerate(xrange(2000, 2005))]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  Ok, I feel a bit stupid here... what's the reason not to just do it with something like  [(a+1,b) for (a,b) in enumerate(r)] ? If you won't function, no problem either:  >>> r = range(2000, 2005) >>> [(a+1,b) for (a,b) in enumerate(r)] [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]  >>> enumerate1 = lambda r:((a+1,b) for (a,b) in enumerate(r))   >>> list(enumerate1(range(2000,2005)))   # note - generator just like original enumerate() [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "How to enumerate a range of numbers starting at 1",
        "A_Content": "  >>> h = enumerate(range(2000, 2005)) >>> [(tup[0]+1, tup[1]) for tup in h] [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   Since this is somewhat verbose, I'd recommend writing your own function to generalize it:  def enumerate_at(xs, start):     return ((tup[0]+start, tup[1]) for tup in enumerate(xs))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "enums"
        ],
        "URL": "https://stackoverflow.com/questions/3303608/how-to-enumerate-a-range-of-numbers-starting-at-1",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am using Python 2.5, I want an enumeration like so (starting at 1 instead of 0):  [(1, 2000), (2, 2001), (3, 2002), (4, 2003), (5, 2004)]   I know in Python 2.6 you can do: h = enumerate(range(2000, 2005), 1) to give the above result but in python2.5 you cannot...  Using python2.5:  >>> h = enumerate(range(2000, 2005)) >>> [x for x in h] [(0, 2000), (1, 2001), (2, 2002), (3, 2003), (4, 2004)]   Does anyone know a way to get that desired result in python 2.5?  Thanks,  Jeff     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  The book has a note how to find help on tag sets, e.g.:  nltk.help.upenn_tagset()   Others are probably similar. (Note: Maybe you first have to download tagsets from the download helper's Models section for this)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "118",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  To save some folks some time, here is a list I extracted from a small corpus.  I do not know if it is complete, but it should have most (if not all) of the help definitions from upenn_tagset...  CC: conjunction, coordinating  & 'n and both but either et for less minus neither nor or plus so therefore times v. versus vs. whether yet   CD: numeral, cardinal  mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty- seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025 fifteen 271,124 dozen quintillion DM2,000 ...   DT: determiner  all an another any both del each either every half la many much nary neither no some such that the them these this those   EX: existential there  there   IN: preposition or conjunction, subordinating  astride among uppon whether out inside pro despite on by throughout below within for towards near behind atop around if like until below next into if beside ...   JJ: adjective or numeral, ordinal  third ill-mannered pre-war regrettable oiled calamitous first separable ectoplasmic battery-powered participatory fourth still-to-be-named multilingual multi-disciplinary ...   JJR: adjective, comparative  bleaker braver breezier briefer brighter brisker broader bumper busier calmer cheaper choosier cleaner clearer closer colder commoner costlier cozier creamier crunchier cuter ...   JJS: adjective, superlative  calmest cheapest choicest classiest cleanest clearest closest commonest corniest costliest crassest creepiest crudest cutest darkest deadliest dearest deepest densest dinkiest ...   LS: list item marker  A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005 SP-44007 Second Third Three Two * a b c d first five four one six three two   MD: modal auxiliary  can cannot could couldn't dare may might must need ought shall should shouldn't will would   NN: noun, common, singular or mass  common-carrier cabbage knuckle-duster Casino afghan shed thermostat investment slide humour falloff slick wind hyena override subhumanity machinist ...   NNP: noun, proper, singular  Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA Shannon A.K.C. Meltex Liverpool ...   NNS: noun, common, plural  undergraduates scotches bric-a-brac products bodyguards facets coasts divestitures storehouses designs clubs fragrances averages subjectivists apprehensions muses factory-jobs ...   PDT: pre-determiner  all both half many quite such sure this   POS: genitive marker  ' 's   PRP: pronoun, personal  hers herself him himself hisself it itself me myself one oneself ours ourselves ownself self she thee theirs them themselves they thou thy us   PRP$: pronoun, possessive  her his mine my our ours their thy your   RB: adverb  occasionally unabatingly maddeningly adventurously professedly stirringly prominently technologically magisterially predominately swiftly fiscally pitilessly ...   RBR: adverb, comparative  further gloomier grander graver greater grimmer harder harsher healthier heavier higher however larger later leaner lengthier less- perfectly lesser lonelier longer louder lower more ...   RBS: adverb, superlative  best biggest bluntest earliest farthest first furthest hardest heartiest highest largest least less most nearest second tightest worst   RP: particle  aboard about across along apart around aside at away back before behind by crop down ever fast for forth from go high i.e. in into just later low more off on open out over per pie raising start teeth that through under unto up up-pp upon whole with you   TO: \"to\" as preposition or infinitive marker  to   UH: interjection  Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly man baby diddle hush sonuvabitch ...   VB: verb, base form  ask assemble assess assign assume atone attention avoid bake balkanize bank begin behold believe bend benefit bevel beware bless boil bomb boost brace break bring broil brush build ...   VBD: verb, past tense  dipped pleaded swiped regummed soaked tidied convened halted registered cushioned exacted snubbed strode aimed adopted belied figgered speculated wore appreciated contemplated ...   VBG: verb, present participle or gerund  telegraphing stirring focusing angering judging stalling lactating hankerin' alleging veering capping approaching traveling besieging encrypting interrupting erasing wincing ...   VBN: verb, past participle  multihulled dilapidated aerosolized chaired languished panelized used experimented flourished imitated reunifed factored condensed sheared unsettled primed dubbed desired ...   VBP: verb, present tense, not 3rd person singular  predominate wrap resort sue twist spill cure lengthen brush terminate appear tend stray glisten obtain comprise detest tease attract emphasize mold postpone sever return wag ...   VBZ: verb, present tense, 3rd person singular  bases reconstructs marks mixes displeases seals carps weaves snatches slumps stretches authorizes smolders pictures emerges stockpiles seduces fizzes uses bolsters slaps speaks pleads ...   WDT: WH-determiner  that what whatever which whichever   WP: WH-pronoun  that what whatever whatsoever which who whom whosoever   WRB: Wh-adverb  how however whence whenever where whereby whereever wherein whereof why      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "81",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  The tag set depends on the corpus that was used to train the tagger.  The default tagger of nltk.pos_tag() uses the Penn Treebank Tag Set.   In NLTK 2, you could check which tagger is the default tagger as follows:   import nltk nltk.tag._POS_TAGGER >>> 'taggers/maxent_treebank_pos_tagger/english.pickle'   That means that it's a Maximum Entropy tagger trained on the Treebank corpus.   nltk.tag._POS_TAGGER does not exist anymore in NLTK 3 but the documentation states that the off-the-shelf tagger still uses the Penn Treebank tagset.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  The below can be useful to access a dict keyed by abbreviations:  >>> from nltk.data import load >>> tagdict = load('help/tagsets/upenn_tagset.pickle') >>> tagdict['NN'][0] 'noun, common, singular or mass' >>> tagdict.keys() ['PRP$', 'VBG', 'VBD', '``', 'VBN', ',', \"''\", 'VBP', 'WDT', ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  The reference is available at the official site  Copy and pasting from there:   CC | Coordinating conjunction | CD | Cardinal number | DT | Determiner | EX | Existential there | FW | Foreign word | IN | Preposition or subordinating conjunction | JJ | Adjective | JJR | Adjective, comparative | JJS | Adjective, superlative | LS | List item marker | MD | Modal | NN | Noun, singular or mass | NNS | Noun, plural | NNP | Proper noun, singular | NNPS | Proper noun, plural | PDT | Predeterminer | POS | Possessive ending | PRP | Personal pronoun | PRP$ | Possessive pronoun | RB | Adverb | RBR | Adverb, comparative | RBS | Adverb, superlative | RP | Particle | SYM | Symbol | TO | to | UH | Interjection | VB | Verb, base form | VBD | Verb, past tense | VBG | Verb, gerund or present participle | VBN | Verb, past participle | VBP | Verb, non-3rd person singular present | VBZ | Verb, 3rd person singular present | WDT | Wh-determiner | WP | Wh-pronoun | WP$ | Possessive wh-pronoun | WRB | Wh-adverb |      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "What are all possible pos tags of NLTK?",
        "A_Content": "  You can download the list here: ftp://ftp.cis.upenn.edu/pub/treebank/doc/tagguide.ps.gz. It includes confusing parts of speech, capitalization, and other conventions. Also, wikipedia has an interesting section similar to this. Section: Part-of-speech tags used.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "nltk"
        ],
        "URL": "https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I find a list with all possible pos tags used by the Natural Language Toolkit (nltk)?     ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  A = [1,2,3,4,5,6] B = A[:len(A)/2] C = A[len(A)/2:]   If you want a function:  def split_list(a_list):     half = len(a_list)/2     return a_list[:half], a_list[half:]  A = [1,2,3,4,5,6] B, C = split_list(A)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "142",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  A little more generic solution (you can specify the number of parts you want, not just split 'in half'):  EDIT: updated post to handle odd list lengths  EDIT2: update post again based on Brians informative comments   def split_list(alist, wanted_parts=1):     length = len(alist)     return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts]               for i in range(wanted_parts) ]  A = [0,1,2,3,4,5,6,7,8,9]  print split_list(A, wanted_parts=1) print split_list(A, wanted_parts=2) print split_list(A, wanted_parts=8)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  f = lambda A, n=3: [A[i:i+n] for i in range(0, len(A), n)] f(A)   n - the predefined length of result arrays      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  def split(arr, size):      arrs = []      while len(arr) > size:          pice = arr[:size]          arrs.append(pice)          arr   = arr[size:]      arrs.append(arr)      return arrs   Test:  x=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] print(split(x, 5))   result:  [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  B,C=A[:len(A)/2],A[len(A)/2:]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  Here is a common solution, split arr into count part  def split(arr, count):      return [arr[i::count] for i in range(count)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  If you don't care about the order...    def split(list):       return list[::2], list[1::2]   list[::2] gets every second element in the list starting from the 0th element. list[1::2] gets every second element in the list starting from the 1st element.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  def splitter(A):     B = A[0:len(A)//2]     C = A[len(A)//2:]   return (B,C)   I tested, and the double slash is required to force int division in python 3. My original post was correct, although wysiwyg broke in Opera, for some reason.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  There is an official Python receipe for the more generalized case of splitting an array into smaller arrays of size n.  from itertools import izip_longest def grouper(n, iterable, fillvalue=None):     \"Collect data into fixed-length chunks or blocks\"     # grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx     args = [iter(iterable)] * n     return izip_longest(fillvalue=fillvalue, *args)   This code snippet is from the python itertools doc page.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  Using list slicing. The syntax is basically my_list[start_index:end_index]  >>> i = [0,1,2,3,4,5] >>> i[:3] # same as i[0:3] - grabs from first to third index (0->2) [0, 1, 2] >>> i[3:] # same as i[3:len(i)] - grabs from fourth index to end [3, 4, 5]   To get the first half of the list, you slice from the first index to len(i)/2...  >>> i[:len(i)/2] [0, 1, 2]   ..and the swap the values around to get the second half:  >>> i[len(i)/2:] [3, 4, 5]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  While the answers above are more or less correct, you may run into trouble if the size of your array isn't divisible by 2, as the result of a / 2, a being odd, is a float in python 3.0, and in earlier version if you specify from __future__ import division at the beginning of your script. You are in any case better off going for integer division, i.e. a // 2, in order to get \"forward\" compatibility of your code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  With hints from @ChristopheD  def line_split(N, K=1):     length = len(N)     return [N[i*length/K:(i+1)*length/K] for i in range(K)]  A = [0,1,2,3,4,5,6,7,8,9] print line_split(A,1) print line_split(A,2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  This is similar to other solutions, but a little faster.  # Usage: split_half([1,2,3,4,5]) Result: ([1, 2], [3, 4, 5])  def split_half(a):     half = len(a) >> 1     return a[:half], a[half:]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Split list into smaller lists",
        "A_Content": "  #for python 3     A = [0,1,2,3,4,5]     l = len(A)/2     B = A[:int(l)]     C = A[int(l):]             ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "split"
        ],
        "URL": "https://stackoverflow.com/questions/752308/split-list-into-smaller-lists",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am looking for a way to easily split a python list in half.  So that if I have an array:  A = [0,1,2,3,4,5]   I would be able to get:  B = [0,1,2]  C = [3,4,5]      ",
        "Q_Votes": "95"
    },
    {
        "Q_Title": "Iterating through directories with Python",
        "A_Content": "  The actual walk through the directories works as you have coded it. If you replace the contents of the inner loop with a simple print statement you can see that each file is found:  import os rootdir = 'C:/Users/sid/Desktop/test'  for subdir, dirs, files in os.walk(rootdir):     for file in files:         print os.path.join(subdir, file)   If you still get errors when running the above, please provide the error message.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory"
        ],
        "URL": "https://stackoverflow.com/questions/19587118/iterating-through-directories-with-python",
        "A_Votes": "195",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to iterate through the subdirectories of a given directory and search for files. If I get a file I have to open it and change the content and replace it with my own lines.  I tried this:  import os  rootdir ='C:/Users/sid/Desktop/test'  for subdir, dirs, files in os.walk(rootdir):     for file in files:         f=open(file,'r')         lines=f.readlines()         f.close()         f=open(file,'w')         for line in lines:             newline = \"No you are not\"             f.write(newline)         f.close()   but I am getting an error. What am I doing wrong?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Iterating through directories with Python",
        "A_Content": "  Another way of returning all files in subdirectories is to use the pathlib module, introduced in Python 3.4, which provides an object oriented approach to handling filesystem paths (Pathlib is also available on Python 2.7 via the pathlib2 module on PyPi):  from pathlib import Path  rootdir = Path('C:/Users/sid/Desktop/test') # Return a list of regular files only, not directories file_list = [f for f in rootdir.glob('**/*') if f.is_file()]  # For absolute paths instead of relative the current dir file_list = [f for f in rootdir.resolve().glob('**/*') if f.is_file()]   Since Python 3.5, the glob module also supports recursive file finding:  import os from glob import iglob  rootdir_glob = 'C:/Users/sid/Desktop/test/**/*' # Note the added asterisks # This will return absolute paths file_list = [f for f in iglob('**/*', recursive=True) if os.path.isfile(f)]   The file_list from either of the above approaches can be iterated over without the need for a nested loop:  for f in file_list:     print(f) # Replace with desired operations      ",
        "Language": "Python",
        "Tags": [
            "python",
            "directory"
        ],
        "URL": "https://stackoverflow.com/questions/19587118/iterating-through-directories-with-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to iterate through the subdirectories of a given directory and search for files. If I get a file I have to open it and change the content and replace it with my own lines.  I tried this:  import os  rootdir ='C:/Users/sid/Desktop/test'  for subdir, dirs, files in os.walk(rootdir):     for file in files:         f=open(file,'r')         lines=f.readlines()         f.close()         f=open(file,'w')         for line in lines:             newline = \"No you are not\"             f.write(newline)         f.close()   but I am getting an error. What am I doing wrong?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python-equivalent of short-form “if” in C++ [duplicate]",
        "A_Content": "  a = '123' if b else '456'      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "syntax"
        ],
        "URL": "https://stackoverflow.com/questions/1686390/python-equivalent-of-short-form-if-in-c",
        "A_Votes": "174",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "       Possible Duplicate:   Python Ternary Operator       Is there a way to write this C/C++ code in Python? a = (b == true ? \"123\" : \"456\" )     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python-equivalent of short-form “if” in C++ [duplicate]",
        "A_Content": "  While a = 'foo' if True else 'bar' is the more modern way of doing the ternary if statement (python 2.5+), a 1-to-1 equivalent of your version might be:  a = (b == True and \"123\" or \"456\" )   ... which in python should be shortened to:  a = b is True and \"123\" or \"456\"   ... or if you simply want to test the truthfulness of b's value in general...  a = b and \"123\" or \"456\"   ? : can literally be swapped out for and or     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "syntax"
        ],
        "URL": "https://stackoverflow.com/questions/1686390/python-equivalent-of-short-form-if-in-c",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   Python Ternary Operator       Is there a way to write this C/C++ code in Python? a = (b == true ? \"123\" : \"456\" )     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python-equivalent of short-form “if” in C++ [duplicate]",
        "A_Content": "  My cryptic version...  a = ['123', '456'][b == True]      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "syntax"
        ],
        "URL": "https://stackoverflow.com/questions/1686390/python-equivalent-of-short-form-if-in-c",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   Python Ternary Operator       Is there a way to write this C/C++ code in Python? a = (b == true ? \"123\" : \"456\" )     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python-equivalent of short-form “if” in C++ [duplicate]",
        "A_Content": "  See PEP 308 for more info.     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "syntax"
        ],
        "URL": "https://stackoverflow.com/questions/1686390/python-equivalent-of-short-form-if-in-c",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   Python Ternary Operator       Is there a way to write this C/C++ code in Python? a = (b == true ? \"123\" : \"456\" )     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I check the operating system in Python?",
        "A_Content": "  You can use sys.platform:  from sys import platform if platform == \"linux\" or platform == \"linux2\":     # linux elif platform == \"darwin\":     # OS X elif platform == \"win32\":     # Windows...   For the valid values, consult the documentation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "operating-system"
        ],
        "URL": "https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python",
        "A_Votes": "189",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to check the operating system (on the computer where the script runs).  I know I can use os.system('uname -o') in Linux, but it gives me a message in the console, and I want to write to a variable.  It will be okay if the script can tell if it is Mac, Windows or Linux. How can I check it?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I check the operating system in Python?",
        "A_Content": "  You can get a pretty coarse idea of the OS you're using by checking sys.platform.  Once you have that information you can use it to determine if calling something like os.uname() is appropriate to gather more specific information.  You could also use something like Python System Information on unix-like OSes, or pywin32 for Windows.  There's also psutil if you want to do more in-depth inspection without wanting to care about the OS.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "operating-system"
        ],
        "URL": "https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to check the operating system (on the computer where the script runs).  I know I can use os.system('uname -o') in Linux, but it gives me a message in the console, and I want to write to a variable.  It will be okay if the script can tell if it is Mac, Windows or Linux. How can I check it?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I check the operating system in Python?",
        "A_Content": "  More detailed information are available in the platform module.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "operating-system"
        ],
        "URL": "https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to check the operating system (on the computer where the script runs).  I know I can use os.system('uname -o') in Linux, but it gives me a message in the console, and I want to write to a variable.  It will be okay if the script can tell if it is Mac, Windows or Linux. How can I check it?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I check the operating system in Python?",
        "A_Content": "  If you want to know on which platform you are: \"Linux\", \"Windows\" or \"Darwin\" (Mac) without more precision, you should use:  >>> import platform >>> platform.system() 'Linux'  # or 'Windows'/'Darwin'   The platform.system function use uname internally.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "operating-system"
        ],
        "URL": "https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to check the operating system (on the computer where the script runs).  I know I can use os.system('uname -o') in Linux, but it gives me a message in the console, and I want to write to a variable.  It will be okay if the script can tell if it is Mac, Windows or Linux. How can I check it?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I check the operating system in Python?",
        "A_Content": "  You can use sys.platform.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "linux",
            "operating-system"
        ],
        "URL": "https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to check the operating system (on the computer where the script runs).  I know I can use os.system('uname -o') in Linux, but it gives me a message in the console, and I want to write to a variable.  It will be okay if the script can tell if it is Mac, Windows or Linux. How can I check it?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  As Wes says, io/sql's read_sql will do it, once you've gotten a database connection using a DBI compatible library.  We can look at two short examples using the MySQLdb and cx_Oracle libraries to connect to Oracle and MySQL and query their data dictionaries. Here is the example for cx_Oracle:  import pandas as pd import cx_Oracle  ora_conn = cx_Oracle.connect('your_connection_string') df_ora = pd.read_sql('select * from user_objects', con=ora_conn)     print 'loaded dataframe from Oracle. # Records: ', len(df_ora) ora_conn.close()   And here is the equivalent example for MySQLdb:  import MySQLdb mysql_cn= MySQLdb.connect(host='myhost',                  port=3306,user='myusername', passwd='mypassword',                  db='information_schema') df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)     print 'loaded dataframe from MySQL. records:', len(df_mysql) mysql_cn.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "92",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  For recent readers of this question: pandas have the following warning in their docs for version 14.0:     Warning: Some of the existing functions or function aliases have been   deprecated and will be removed in future versions. This includes:   tquery, uquery, read_frame, frame_query, write_frame.    And:     Warning: The support for the ‘mysql’ flavor when using DBAPI connection objects has   been deprecated. MySQL will be further supported with SQLAlchemy   engines (GH6900).   This makes many of the answers here outdated. You should use sqlalchemy:  from sqlalchemy import create_engine import pandas as pd engine = create_engine('dialect://user:pass@host:port/schema', echo=False) f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "51",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  For the record, here is an example using a sqlite database:  import pandas as pd import sqlite3  with sqlite3.connect(\"whatever.sqlite\") as con:     sql = \"SELECT * FROM table_name\"     df = pd.read_sql_query(sql, con)     print df.shape      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  I prefer to create queries with SQLAlchemy, and then make a DataFrame from it. SQLAlchemy makes it easier to combine SQL conditions Pythonically if you intend to mix and match things over and over.  from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Table from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from pandas import DataFrame import datetime  # We are connecting to an existing service engine = create_engine('dialect://user:pwd@host:port/db', echo=False) Session = sessionmaker(bind=engine) session = Session() Base = declarative_base()  # And we want to query an existing table tablename = Table('tablename',      Base.metadata,      autoload=True,      autoload_with=engine,      schema='ownername')  # These are the \"Where\" parameters, but I could as easily  # create joins and limit results us = tablename.c.country_code.in_(['US','MX']) dc = tablename.c.locn_name.like('%DC%') dt = tablename.c.arr_date >= datetime.date.today() # Give me convenience or...  q = session.query(tablename).\\             filter(us & dc & dt) # That's where the magic happens!!!  def querydb(query):     \"\"\"     Function to execute query and return DataFrame.     \"\"\"     df = DataFrame(query.all());     df.columns = [x['name'] for x in query.column_descriptions]     return df  querydb(q)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  MySQL example:  import MySQLdb as db from pandas import DataFrame from pandas.io.sql import frame_query  database = db.connect('localhost','username','password','database') data     = frame_query(\"SELECT * FROM data\", database)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  The same syntax works for Ms SQL server using podbc also.   import pyodbc import pandas.io.sql as psql  cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=servername;DATABASE=mydb;UID=username;PWD=password')  cursor = cnxn.cursor() sql = (\"\"\"select * from mytable\"\"\")  df = psql.frame_query(sql, cnxn) cnxn.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  And this is how you connect to PostgreSQL using psycopg2 driver (install with \"apt-get install python-psycopg2\" if you're on Debian Linux derivative OS).  import pandas.io.sql as psql import psycopg2  conn = psycopg2.connect(\"dbname='datawarehouse' user='user1' host='localhost' password='uberdba'\")  q = \"\"\"select month_idx, sum(payment) from bi_some_table\"\"\"  df3 = psql.frame_query(q, conn)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  For Sybase the following works (with http://python-sybase.sourceforge.net)  import pandas.io.sql as psql import Sybase  df = psql.frame_query(\"<Query>\", con=Sybase.connect(\"<dsn>\", \"<user>\", \"<pwd>\"))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  pandas.io.sql.frame_query is deprecated. Use pandas.read_sql instead.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  import the module  import pandas as pd import oursql   connect  conn=oursql.connect(host=\"localhost\",user=\"me\",passwd=\"mypassword\",db=\"classicmodels\") sql=\"Select customerName, city,country from customers order by customerName,country,city\" df_mysql = pd.read_sql(sql,conn) print df_mysql   That works just fine and using pandas.io.sql frame_works (with the deprecation warning). Database used is the sample database from mysql tutorial.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "python-pandas and databases like mysql",
        "A_Content": "  This should work just fine.  import MySQLdb as mdb import pandas as pd con = mdb.connect(‘127.0.0.1’, ‘root’, ‘password’, ‘database_name’); with con:  cur = con.cursor()  cur.execute(“select random_number_one, random_number_two, random_number_three from randomness.a_random_table”)  rows = cur.fetchall()  df = pd.DataFrame( [[ij for ij in i] for i in rows] )  df.rename(columns={0: ‘Random Number One’, 1: ‘Random Number Two’, 2: ‘Random Number Three’}, inplace=True);  print(df.head(20))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas"
        ],
        "URL": "https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The documentation for Pandas has numerous examples of best practices for working with data stored in various formats.  However, I am unable to find any good examples for working with databases like MySQL for example.  Can anyone point me to links or give some code snippets of how to convert query results using mysql-python to data frames in Pandas efficiently ?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python pandas dataframe: retrieve number of columns",
        "A_Content": "  Like so:  import pandas as pd df = pd.DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})  len(df.columns) 3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20297332/python-pandas-dataframe-retrieve-number-of-columns",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do you programmatically retrieve the number of columns in a pandas dataframe? I was hoping for something like:  df.num_columns      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python pandas dataframe: retrieve number of columns",
        "A_Content": "  Alternative:   df.shape[1]   (df.shape[0] is the number of rows)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20297332/python-pandas-dataframe-retrieve-number-of-columns",
        "A_Votes": "57",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you programmatically retrieve the number of columns in a pandas dataframe? I was hoping for something like:  df.num_columns      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python pandas dataframe: retrieve number of columns",
        "A_Content": "  If the variable holding the dataframe is called df, then:  len(df.columns)   gives the number of columns.  And for those who want the number of rows:  len(df.index)   For a tuple containing the number of both rows and columns:  df.shape      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20297332/python-pandas-dataframe-retrieve-number-of-columns",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do you programmatically retrieve the number of columns in a pandas dataframe? I was hoping for something like:  df.num_columns      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  It seems that you actually haven't executed your query. Try following:  return jsonify(json_list = qryresult.all())   [Edit]: Problem with jsonify is, that usually the objects cannot be jsonified automatically. Even Python's datetime fails ;)  What I have usually done, is to add an extra property (like serialize) to classes that need to be serialized:  def dump_datetime(value):     \"\"\"Deserialize datetime object into string form for JSON processing.\"\"\"     if value is None:         return None     return [value.strftime(\"%Y-%m-%d\"), value.strftime(\"%H:%M:%S\")]  class Foo(db.Model):     # ... SQLAlchemy defs here..     def __init__(self, ...):        # self.foo = ...        pass      @property     def serialize(self):        \"\"\"Return object data in easily serializeable format\"\"\"        return {            'id'         : self.id,            'modified_at': dump_datetime(self.modified_at),            # This is an example how to deal with Many2Many relations            'many2many'  : self.serialize_many2many        }     @property     def serialize_many2many(self):        \"\"\"        Return object's relations in easily serializeable format.        NB! Calls many2many's serialize property.        \"\"\"        return [ item.serialize for item in self.many2many]   And now for views I can just do:  return jsonify(json_list=[i.serialize for i in qryresult.all()])   Hope this helps ;)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "137",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  I had the same need, to serialize into json.  Take a look at this question.  It shows how to discover columns programmatically.  So, from that I created the code below.  It works for me, and I'll be using it in my web app.  Happy coding!   def to_json(inst, cls):     \"\"\"     Jsonify the sql alchemy query result.     \"\"\"     convert = dict()     # add your coversions for things like datetime's      # and what-not that aren't serializable.     d = dict()     for c in cls.__table__.columns:         v = getattr(inst, c.name)         if c.type in convert.keys() and v is not None:             try:                 d[c.name] = convert[c.type](v)             except:                 d[c.name] = \"Error:  Failed to covert using \", str(convert[c.type])         elif v is None:             d[c.name] = str()         else:             d[c.name] = v     return json.dumps(d)  class Person(base):     __tablename__ = 'person'     id = Column(Integer, Sequence('person_id_seq'), primary_key=True)     first_name = Column(Text)     last_name = Column(Text)     email = Column(Text)      @property     def json(self):         return to_json(self, self.__class__)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  Here's what's usually sufficient for me:  I create a serialization mixin which I use with my models. The serialization function basically fetches whatever attributes the SQLAlchemy inspector exposes and puts it in a dict.  from sqlalchemy.inspection import inspect  class Serializer(object):      def serialize(self):         return {c: getattr(self, c) for c in inspect(self).attrs.keys()}      @staticmethod     def serialize_list(l):         return [m.serialize() for m in l]   All that's needed now is to extend the SQLAlchemy model with the Serializer mixin class.  If there are fields you do not wish to expose, or that need special formatting, simply override the serialize() function in the model subclass.  class User(db.Model, Serializer):     id = db.Column(db.Integer, primary_key=True)     username = db.Column(db.String)     password = db.Column(db.String)      # ...      def serialize(self):         d = Serializer.serialize(self)         del d['password']         return d   In your controllers, all you have to do is to call the serialize() function (or serialize_list(l) if the query results in a list) on the results:  def get_user(id):     user = User.query.get(id)     return json.dumps(user.serialize())  def get_users():     users = User.query.all()     return json.dumps(User.serialize_list(users))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  Here's my approach:  MODEL:  class AutoSerialize(object):     'Mixin for retrieving public fields of model in json-compatible format'     __public__ = None      def get_public(self, exclude=(), extra=()):         \"Returns model's PUBLIC data for jsonify\"         data = {}         keys = self._sa_instance_state.attrs.items()         public = self.__public__ + extra if self.__public__ else extra         for k, field in  keys:             if public and k not in public: continue             if k in exclude: continue             value = self._serialize(field.value)             if value:                 data[k] = value         return data      @classmethod     def _serialize(cls, value, follow_fk=False):         if type(value) in (datetime, date):             ret = value.isoformat()         elif hasattr(value, '__iter__'):             ret = []             for v in value:                 ret.append(cls._serialize(v))         elif AutoSerialize in value.__class__.__bases__:             ret = value.get_public()         else:             ret = value          return ret  class User(db.Model, AutoSerialize):     __tablename__ = 'users'     __public__ = ('id', 'name', 'email')     id = db.Column(db.Integer, primary_key=True)     name = db.Column(db.Unicode(50))     email = db.Column(db.String(120), unique=True)     passhash = db.Column(db.String(100))     ...   VIEW:  from flask import jsonfy  @mod.route('/<int:id>/', methods=['GET']) def get_user_by_id(id):     u = User.query.get(id)     return jsonify(u.get_public())   I'm not sure about this:   self._sa_instance_state.attrs.items()   but it works. I had not enough time to make it more elegant, maybe someone will suggest a better way to get SA fields     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  For a flat query (no joins) you can do this  @app.route('/results/') def results():     data = Table.query.all()     result = [d.__dict__ for d in data]     return jsonify(result=result)   and if you only want to return certain columns from the database you can do this  @app.route('/results/') def results():     cols = ['id', 'url', 'shipping']     data = Table.query.all()     result = [{col: getattr(d, col) for col in cols} for d in data]     return jsonify(result=result)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  If you are using flask-restful you can use marshal:  from flask.ext.restful import Resource, fields, marshal  topic_fields = {     'title':   fields.String,     'content': fields.String,     'uri':     fields.Url('topic'),     'creator': fields.String,     'created': fields.DateTime(dt_format='rfc822') }  class TopicListApi(Resource):     def get(self):         return {'topics': [marshal(topic, topic_fields) for topic in DbTopic.query.all()]}   You need to explicitly list what you are returning and what type it is, which I prefer anyway for an api. Serialization is easily taken care of (no need for jsonify), dates are also not a problem. Note that the content for the uri field is automatically generated based on the topic endpoint and the id.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  I've been looking at this problem for the better part of a day, and here's what I've come up with (credit to https://stackoverflow.com/a/5249214/196358 for pointing me in this direction).  (Note: I'm using flask-sqlalchemy, so my model declaration format is a bit different from straight sqlalchemy).  In my models.py file:  import json  class Serializer(object):   __public__ = None   \"Must be implemented by implementors\"    def to_serializable_dict(self):     dict = {}     for public_key in self.__public__:       value = getattr(self, public_key)       if value:         dict[public_key] = value     return dict  class SWEncoder(json.JSONEncoder):   def default(self, obj):     if isinstance(obj, Serializer):       return obj.to_serializable_dict()     if isinstance(obj, (datetime)):       return obj.isoformat()     return json.JSONEncoder.default(self, obj)   def SWJsonify(*args, **kwargs):   return current_app.response_class(json.dumps(dict(*args, **kwargs), cls=SWEncoder, indent=None if request.is_xhr else 2), mimetype='application/json')   # stolen from https://github.com/mitsuhiko/flask/blob/master/flask/helpers.py   and all my model objects look like this:  class User(db.Model, Serializer):   __public__ = ['id','username']   ... field definitions ...   In my views I call SWJsonify wherever I would have called Jsonify, like so:  @app.route('/posts') def posts():   posts = Post.query.limit(PER_PAGE).all()   return SWJsonify({'posts':posts })   Seems to work pretty well. Even on relationships. I haven't gotten far with it, so YMMV, but  so far it feels pretty \"right\" to me.  Suggestions welcome.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  Ok, I've been working on this for a few hours, and I've developed what I believe to be the most pythonic solution yet. The following code snippets are python3 but shouldn't be too horribly painful to backport if you need.  The first thing we're gonna do is start with a mixin that makes your db models act kinda like dicts:  from sqlalchemy.inspection import inspect  class ModelMixin:     \"\"\"Provide dict-like interface to db.Model subclasses.\"\"\"      def __getitem__(self, key):         \"\"\"Expose object attributes like dict values.\"\"\"         return getattr(self, key)      def keys(self):         \"\"\"Identify what db columns we have.\"\"\"         return inspect(self).attrs.keys()   Now we're going to define our model, inheriting the mixin:  class MyModel(db.Model, ModelMixin):     id = db.Column(db.Integer, primary_key=True)     foo = db.Column(...)     bar = db.Column(...)     # etc ...   That's all it takes to be able to pass an instance of MyModel() to dict() and get a real live dict instance out of it, which gets us quite a long way towards making jsonify() understand it. Next, we need to extend JSONEncoder to get us the rest of the way:  from flask.json import JSONEncoder from contextlib import suppress  class MyJSONEncoder(JSONEncoder):     def default(self, obj):         # Optional: convert datetime objects to ISO format         with suppress(AttributeError):             return obj.isoformat()         return dict(obj)  app.json_encoder = MyJSONEncoder   Bonus points: if your model contains computed fields (that is, you want your JSON output to contain fields that aren't actually stored in the database), that's easy too. Just define your computed fields as @propertys, and extend the keys() method like so:  class MyModel(db.Model, ModelMixin):     id = db.Column(db.Integer, primary_key=True)     foo = db.Column(...)     bar = db.Column(...)      @property     def computed_field(self):         return 'this value did not come from the db'      def keys(self):         return super().keys() + ['computed_field']   Now it's trivial to jsonify:  @app.route('/whatever', methods=['GET']) def whatever():     return jsonify(dict(results=MyModel.query.all()))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  Here is a way to add an as_dict() method on every class, as well as any other method you want to have on every single class. Not sure if this is the desired way or not, but it works...  class Base(object):     def as_dict(self):         return dict((c.name,                      getattr(self, c.name))                      for c in self.__table__.columns)   Base = declarative_base(cls=Base)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  I was looking for something like the rails approach used in ActiveRecord to_json and implemented something similar using this Mixin after being unsatisfied with other suggestions.  It handles nested models, and including or excluding attributes of the top level or nested models.  class Serializer(object):      def serialize(self, include={}, exclude=[], only=[]):         serialized = {}         for key in inspect(self).attrs.keys():             to_be_serialized = True             value = getattr(self, key)             if key in exclude or (only and key not in only):                 to_be_serialized = False             elif isinstance(value, BaseQuery):                 to_be_serialized = False                 if key in include:                     to_be_serialized = True                     nested_params = include.get(key, {})                     value = [i.serialize(**nested_params) for i in value]              if to_be_serialized:                 serialized[key] = value          return serialized   Then, to get the BaseQuery serializable I extended BaseQuery  class SerializableBaseQuery(BaseQuery):      def serialize(self, include={}, exclude=[], only=[]):         return [m.serialize(include, exclude, only) for m in self]   For the following models  class ContactInfo(db.Model, Serializer):     id = db.Column(db.Integer, primary_key=True)     user_id = db.Column(db.Integer, db.ForeignKey('user.id'))     full_name = db.Column(db.String())     source = db.Column(db.String())     source_id = db.Column(db.String())      email_addresses = db.relationship('EmailAddress', backref='contact_info', lazy='dynamic')     phone_numbers = db.relationship('PhoneNumber', backref='contact_info', lazy='dynamic')   class EmailAddress(db.Model, Serializer):     id = db.Column(db.Integer, primary_key=True)     email_address = db.Column(db.String())     type = db.Column(db.String())     contact_info_id = db.Column(db.Integer, db.ForeignKey('contact_info.id'))   class PhoneNumber(db.Model, Serializer):     id = db.Column(db.Integer, primary_key=True)     phone_number = db.Column(db.String())     type = db.Column(db.String())     contact_info_id = db.Column(db.Integer, db.ForeignKey('contact_info.id'))      phone_numbers = db.relationship('Invite', backref='phone_number', lazy='dynamic')   You could do something like  @app.route(\"/contact/search\", methods=['GET']) def contact_search():     contact_name = request.args.get(\"name\")     matching_contacts = ContactInfo.query.filter(ContactInfo.full_name.like(\"%{}%\".format(contact_name)))      serialized_contact_info = matching_contacts.serialize(         include={             \"phone_numbers\" : {                 \"exclude\" : [\"contact_info\", \"contact_info_id\"]             },             \"email_addresses\" : {                 \"exclude\" : [\"contact_info\", \"contact_info_id\"]             }         }     )      return jsonify(serialized_contact_info)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  I was working with a sql query defaultdict of lists of RowProxy objects named jobDict It took me a while to figure out what Type the objects were.  This was a really simple quick way to resolve to some clean jsonEncoding just by typecasting the row to a list and by initially defining the dict with a value of list.      jobDict = defaultdict(list)     def set_default(obj):         # trickyness needed here via import to know type         if isinstance(obj, RowProxy):             return list(obj)         raise TypeError       jsonEncoded = json.dumps(jobDict, default=set_default)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  I just want to add my method to do this.  just define a custome json encoder to serilize your db models.  class ParentEncoder(json.JSONEncoder):     def default(self, obj):         # convert object to a dict         d = {}         if isinstance(obj, Parent):             return {\"id\": obj.id, \"name\": obj.name, 'children': list(obj.child)}         if isinstance(obj, Child):             return {\"id\": obj.id, \"name\": obj.name}          d.update(obj.__dict__)         return d   then in your view function   parents = Parent.query.all() dat = json.dumps({\"data\": parents}, cls=ParentEncoder) resp = Response(response=dat, status=200, mimetype=\"application/json\") return (resp)   it works well though the parent have relationships      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  Here's my answer if you're using the declarative base (with help from some of the answers already posted):  # in your models definition where you define and extend declarative_base() from sqlalchemy.ext.declarative import declarative_base ... Base = declarative_base() Base.query = db_session.query_property() ...  # define a new class (call \"Model\" or whatever) with an as_dict() method defined class Model():     def as_dict(self):         return { c.name: getattr(self, c.name) for c in self.__table__.columns }  # and extend both the Base and Model class in your model definition, e.g. class Rating(Base, Model):     ____tablename__ = 'rating'     id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     ...  # then after you query and have a resultset (rs) of ratings rs = Rating.query.all()  # you can jsonify it with s = json.dumps([r.as_dict() for r in rs], default=alchemyencoder) print (s)  # or if you have a single row r = Rating.query.first()  # you can jsonify it with s = json.dumps(r.as_dict(), default=alchemyencoder)  # you will need this alchemyencoder where your are calling json.dumps to handle datetime and decimal format # credit to Joonas @ http://codeandlife.com/2014/12/07/sqlalchemy-results-to-json-the-easy-way/ def alchemyencoder(obj):     \"\"\"JSON encoder function for SQLAlchemy special classes.\"\"\"     if isinstance(obj, datetime.date):         return obj.isoformat()     elif isinstance(obj, decimal.Decimal):         return float(obj)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "jsonify a SQLAlchemy result set in Flask",
        "A_Content": "  It's been a lot of times and there are lots of valid answers, but the following code block seems to work:  my_object = SqlAlchemyModel() my_serializable_obj = my_object.__dict__ del my_serializable_obj[\"_sa_instance_state\"] print(jsonify(my_serializable_object))   I'm aware that this is not a perfect solution, nor as elegant as the others, however for those who want o quick fix, they might try this.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sqlalchemy",
            "flask",
            "flask-sqlalchemy"
        ],
        "URL": "https://stackoverflow.com/questions/7102754/jsonify-a-sqlalchemy-result-set-in-flask",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to jsonify a SQLAlchemy result set in Flask/Python.  The Flask mailing list suggested the following method http://librelist.com/browser//flask/2011/2/16/jsonify-sqlalchemy-pagination-collection-result/#04a0754b63387f87e59dda564bde426e :  return jsonify(json_list = qryresult)   However I'm getting the following error back:  TypeError: <flaskext.sqlalchemy.BaseQuery object at 0x102c2df90>  is not JSON serializable   What am I overlooking here?   I have found this question: How to serialize SqlAlchemy result to JSON? which seems very similar however I didn't know whether Flask had some magic to make it easier as the mailing list post suggested.  Edit: for clarification, this is what my model looks like  class Rating(db.Model):      __tablename__ = 'rating'      id = db.Column(db.Integer, primary_key=True)     fullurl = db.Column(db.String())     url = db.Column(db.String())     comments = db.Column(db.Text)     overall = db.Column(db.Integer)     shipping = db.Column(db.Integer)     cost = db.Column(db.Integer)     honesty = db.Column(db.Integer)     communication = db.Column(db.Integer)     name = db.Column(db.String())     ipaddr = db.Column(db.String())     date = db.Column(db.String())      def __init__(self, fullurl, url, comments, overall, shipping, cost, honesty, communication, name, ipaddr, date):         self.fullurl = fullurl         self.url = url         self.comments = comments         self.overall = overall         self.shipping = shipping         self.cost = cost         self.honesty = honesty         self.communication = communication         self.name = name         self.ipaddr = ipaddr         self.date = date      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  To simply repeat the same letter 10 times:  string_val = \"x\" * 10  # gives you \"xxxxxxxxxx\"   And if you want something more complex, like n random lowercase letters, it's still only one line of code (not counting the import statements and defining n):  from random import choice from string import lowercase n = 10  string_val = \"\".join(choice(lowercase) for i in range(n))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "213",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  The first ten lowercase letters are string.lowercase[:10] (if you have imported the standard library module string previously, of course;-).  Other ways to \"make a string of 10 characters\": 'x'*10 (all the ten characters will be lowercase xs;-), ''.join(chr(ord('a')+i) for i in xrange(10)) (the first ten lowercase letters again), etc, etc;-).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  if you just want any letters:   'a'*10  # gives 'aaaaaaaaaa'   if you want consecutive letters (up to 26):   ''.join(['%c' % x for x in range(97, 97+10)])  # gives 'abcdefghij'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  Why \"one line\"? You can fit anything onto one line.  Assuming you want them to start with 'a', and increment by one character each time (with wrapping > 26), here's a line:  >>> mkstring = lambda(x): \"\".join(map(chr, (ord('a')+(y%26) for y in range(x)))) >>> mkstring(10) 'abcdefghij' >>> mkstring(30) 'abcdefghijklmnopqrstuvwxyzabcd'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  If you can use repeated letters, you can use the * operator:  >>> 'a'*5  'aaaaa'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "In Python, how do I create a string of n characters in one line of code?",
        "A_Content": "  This might be a little off the question, but for those interested in the randomness of the generated string, my answer would be:  import os import string  def _pwd_gen(size=16):     chars = string.letters     chars_len = len(chars)     return str().join(chars[int(ord(c) / 256. * chars_len)] for c in os.urandom(size))   See these answers and random.py's source for more insight.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/1424005/in-python-how-do-i-create-a-string-of-n-characters-in-one-line-of-code",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to generate a string with n characters in Python.  Is there a one line answer to achieve this with the existing Python library?  For instance, I need a string of 10 letters:  string_val = 'abcdefghij'      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  for property, value in vars(theObject).iteritems():     print property, \": \", value   Be aware that in some rare cases there's a __slots__ property, such classes often have no __dict__.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  See inspect.getmembers(object[, predicate]).     Return all the members of an object in a list of (name, value) pairs sorted by name. If the optional predicate argument is supplied, only members for which the predicate returns a true value are included.   >>> [name for name,thing in inspect.getmembers([])] ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__',  '__delslice__',    '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__',  '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__',  '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__','__reduce_ex__',  '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__',  '__sizeof__', '__str__', '__subclasshook__', 'append', 'count', 'extend', 'index',  'insert', 'pop', 'remove', 'reverse', 'sort'] >>>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "59",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  dir() is the simple way. See here:  Guide To Python Introspection     ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  The __dict__ property of the object is a dictionary of all its other defined properties. Note that Python classes can override getattr and make things that look like properties but are not in__dict__. There's also the builtin functions vars() and dir() which are different in subtle ways. And __slots__ can replace __dict__ in some unusual classes.  Objects are complicated in Python. __dict__ is the right place to start for reflection-style programming. dir() is the place to start if you're hacking around in an interactive shell.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  georg scholly shorter version   print vars(theObject)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to enumerate an object's properties in Python?",
        "A_Content": "  If you're looking for reflection of all properties, the answers above are great.  If you're simply looking to get the keys of an object, use  my_dict.keys()  my_dict = {'abc': {}, 'def': 12, 'ghi': 'string' } my_dict.keys()  > ['abc', 'def', 'ghi']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection",
            "properties"
        ],
        "URL": "https://stackoverflow.com/questions/1251692/how-to-enumerate-an-objects-properties-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I C# we do it through reflection. In Javascript it is simple as:  for(var propertyName in objectName)     var currentPropertyValue = objectName[propertyName];   How to do it in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert int to ASCII and back in Python",
        "A_Content": "  ASCII to int:  ord('a')   gives 97  And back to a string:  str(unichr(97))   gives 'a'     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python",
        "A_Votes": "162",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on making a URL shortener for my site, and my current plan (I'm open to suggestions) is to use a node ID to generate the shortened URL. So, in theory, node 26 might be short.com/z, node 1 might be short.com/a, node 52 might be short.com/Z, and node 104 might be short.com/ZZ. When a user goes to that URL, I need to reverse the process (obviously).  I can think of some kludgy ways to go about this, but I'm guessing there are better ones. Any suggestions?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert int to ASCII and back in Python",
        "A_Content": "  >>> ord(\"a\") 97 >>> chr(97) 'a'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python",
        "A_Votes": "70",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on making a URL shortener for my site, and my current plan (I'm open to suggestions) is to use a node ID to generate the shortened URL. So, in theory, node 26 might be short.com/z, node 1 might be short.com/a, node 52 might be short.com/Z, and node 104 might be short.com/ZZ. When a user goes to that URL, I need to reverse the process (obviously).  I can think of some kludgy ways to go about this, but I'm guessing there are better ones. Any suggestions?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert int to ASCII and back in Python",
        "A_Content": "  What about BASE58 encoding the URL? Like for example flickr does.  # note the missing lowercase L and the zero etc. BASE58 = '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'  url = '' while node_id >= 58:     div, mod = divmod(node_id, 58)     url = BASE58[mod] + url     node_id = int(div)  return 'http://short.com/%s' % BASE58[node_id] + url   Turning that back into a number isn't a big deal either.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on making a URL shortener for my site, and my current plan (I'm open to suggestions) is to use a node ID to generate the shortened URL. So, in theory, node 26 might be short.com/z, node 1 might be short.com/a, node 52 might be short.com/Z, and node 104 might be short.com/ZZ. When a user goes to that URL, I need to reverse the process (obviously).  I can think of some kludgy ways to go about this, but I'm guessing there are better ones. Any suggestions?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert int to ASCII and back in Python",
        "A_Content": "  If multiple characters are bound inside a single integer/long, as was my issue:  s = '0123456789' nchars = len(s) # string to int or long. Type depends on nchars x = sum(ord(s[byte])<<8*(nchars-byte-1) for byte in range(nchars)) # int or long to string ''.join(chr((x>>8*(nchars-byte-1))&0xFF) for byte in range(nchars))   Yields '0123456789' and x = 227581098929683594426425L     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on making a URL shortener for my site, and my current plan (I'm open to suggestions) is to use a node ID to generate the shortened URL. So, in theory, node 26 might be short.com/z, node 1 might be short.com/a, node 52 might be short.com/Z, and node 104 might be short.com/ZZ. When a user goes to that URL, I need to reverse the process (obviously).  I can think of some kludgy ways to go about this, but I'm guessing there are better ones. Any suggestions?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert int to ASCII and back in Python",
        "A_Content": "  Use hex(id)[2:] and int(urlpart, 16).  There are other options.  base32 encoding your id could work as well, but I don't know that there's any library that does base32 encoding built into Python.  Apparently a base32 encoder was introduced in Python 2.4 with the base64 module.  You might try using b32encode and b32decode.  You should give True for both the casefold and map01 options to b32decode in case people write down your shortened URLs.  Actually, I take that back.  I still think base32 encoding is a good idea, but that module is not useful for the case of URL shortening.  You could look at the implementation in the module and make your own for this specific case.  :-)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm working on making a URL shortener for my site, and my current plan (I'm open to suggestions) is to use a node ID to generate the shortened URL. So, in theory, node 26 might be short.com/z, node 1 might be short.com/a, node 52 might be short.com/Z, and node 104 might be short.com/ZZ. When a user goes to that URL, I need to reverse the process (obviously).  I can think of some kludgy ways to go about this, but I'm guessing there are better ones. Any suggestions?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "TemplateDoesNotExist - Django Error",
        "A_Content": "  Make sure you have rest_framework listed in your settings.py INSTALLED_APPS.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-rest-framework"
        ],
        "URL": "https://stackoverflow.com/questions/21408344/templatedoesnotexist-django-error",
        "A_Votes": "228",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using Django Rest Framework. and I keep getting an error   Exception Type: TemplateDoesNotExist Exception Value: rest_framework/api.html   I dont know how I'm going wrong. This is the first time I'm trying out hands on REST Framework. This is code.  views.py  import socket, json from modules.data.models import * from modules.utils import * from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from modules.actions.serializers import ActionSerializer   @api_view(['POST']) @check_field_exists_wrapper(\"installation\") def api_actions(request, format = None):      action_type = request.POST['action_type']     if action_type == \"Shutdown\" :          send_message = '1'         print \"Shutting Down the system...\"     elif action_type == \"Enable\" :          send_message = '1'         print \"Enabling the system...\"     elif action_type == \"Disable\" :          send_message = '1'         print \"Disabling the system...\"     elif action_type == \"Restart\" :          send_message = '1'         print \"Restarting the system...\"      if action_type in [\"Shutdown\", \"Enable\", \"Disable\"] : PORT = 6000     else : PORT = 6100      controllers_list = Controller.objects.filter(installation_id = kwargs['installation_id'])      for controller_obj in controllers_list:         ip = controller_obj.ip         try:             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)             s.connect((ip, PORT))             s.send(send_message)             s.close()         except Exception as e:             print(\"Exception when sending \" + action_type +\" command: \"+str(e))      return Response(status = status.HTTP_200_OK)   models.py  class Controller(models.Model):     id = models.IntegerField(primary_key = True)     name = models.CharField(max_length = 255, unique = True)     ip = models.CharField(max_length = 255, unique = True)     installation_id = models.ForeignKey('Installation')   serializers.py  from django.forms import widgets from rest_framework import serializers from modules.data.models import *  class ActionSerializer(serializers.ModelSerializer):     class Meta:         model = Controller         fields = ('id', 'name', 'ip', 'installation_id')   urls.py  from django.conf.urls import patterns, url from rest_framework.urlpatterns import format_suffix_patterns  urlpatterns = patterns('modules.actions.views',     url(r'^$','api_actions',name='api_actions'), )      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "TemplateDoesNotExist - Django Error",
        "A_Content": "  For me, rest_framework/api.html was actually missing on the filesystem due to a corrupt installation or some other unknown reason. Reinstalling djangorestframework fixed the problem:  $ pip install --upgrade djangorestframework      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-rest-framework"
        ],
        "URL": "https://stackoverflow.com/questions/21408344/templatedoesnotexist-django-error",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using Django Rest Framework. and I keep getting an error   Exception Type: TemplateDoesNotExist Exception Value: rest_framework/api.html   I dont know how I'm going wrong. This is the first time I'm trying out hands on REST Framework. This is code.  views.py  import socket, json from modules.data.models import * from modules.utils import * from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from modules.actions.serializers import ActionSerializer   @api_view(['POST']) @check_field_exists_wrapper(\"installation\") def api_actions(request, format = None):      action_type = request.POST['action_type']     if action_type == \"Shutdown\" :          send_message = '1'         print \"Shutting Down the system...\"     elif action_type == \"Enable\" :          send_message = '1'         print \"Enabling the system...\"     elif action_type == \"Disable\" :          send_message = '1'         print \"Disabling the system...\"     elif action_type == \"Restart\" :          send_message = '1'         print \"Restarting the system...\"      if action_type in [\"Shutdown\", \"Enable\", \"Disable\"] : PORT = 6000     else : PORT = 6100      controllers_list = Controller.objects.filter(installation_id = kwargs['installation_id'])      for controller_obj in controllers_list:         ip = controller_obj.ip         try:             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)             s.connect((ip, PORT))             s.send(send_message)             s.close()         except Exception as e:             print(\"Exception when sending \" + action_type +\" command: \"+str(e))      return Response(status = status.HTTP_200_OK)   models.py  class Controller(models.Model):     id = models.IntegerField(primary_key = True)     name = models.CharField(max_length = 255, unique = True)     ip = models.CharField(max_length = 255, unique = True)     installation_id = models.ForeignKey('Installation')   serializers.py  from django.forms import widgets from rest_framework import serializers from modules.data.models import *  class ActionSerializer(serializers.ModelSerializer):     class Meta:         model = Controller         fields = ('id', 'name', 'ip', 'installation_id')   urls.py  from django.conf.urls import patterns, url from rest_framework.urlpatterns import format_suffix_patterns  urlpatterns = patterns('modules.actions.views',     url(r'^$','api_actions',name='api_actions'), )      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "TemplateDoesNotExist - Django Error",
        "A_Content": "  Please note that the DRF attempts to return data in the same format that was requested. From your browser, this is most likely HTML. To specify an alternative response, use the ?format= parameter. For example: ?format=json.   The TemplateDoesNotExist error occurs most commonly when you are visiting an API endpoint in your browser and you do not have the rest_framework included in your list of installed apps, as described by other respondents.   If you do not have DRF included in your list of apps, but don't want to use the HTML Admin DRF page, try using an alternative format to 'side-step' this error message.   More info from the docs here: http://www.django-rest-framework.org/topics/browsable-api/#formats     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-rest-framework"
        ],
        "URL": "https://stackoverflow.com/questions/21408344/templatedoesnotexist-django-error",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using Django Rest Framework. and I keep getting an error   Exception Type: TemplateDoesNotExist Exception Value: rest_framework/api.html   I dont know how I'm going wrong. This is the first time I'm trying out hands on REST Framework. This is code.  views.py  import socket, json from modules.data.models import * from modules.utils import * from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from modules.actions.serializers import ActionSerializer   @api_view(['POST']) @check_field_exists_wrapper(\"installation\") def api_actions(request, format = None):      action_type = request.POST['action_type']     if action_type == \"Shutdown\" :          send_message = '1'         print \"Shutting Down the system...\"     elif action_type == \"Enable\" :          send_message = '1'         print \"Enabling the system...\"     elif action_type == \"Disable\" :          send_message = '1'         print \"Disabling the system...\"     elif action_type == \"Restart\" :          send_message = '1'         print \"Restarting the system...\"      if action_type in [\"Shutdown\", \"Enable\", \"Disable\"] : PORT = 6000     else : PORT = 6100      controllers_list = Controller.objects.filter(installation_id = kwargs['installation_id'])      for controller_obj in controllers_list:         ip = controller_obj.ip         try:             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)             s.connect((ip, PORT))             s.send(send_message)             s.close()         except Exception as e:             print(\"Exception when sending \" + action_type +\" command: \"+str(e))      return Response(status = status.HTTP_200_OK)   models.py  class Controller(models.Model):     id = models.IntegerField(primary_key = True)     name = models.CharField(max_length = 255, unique = True)     ip = models.CharField(max_length = 255, unique = True)     installation_id = models.ForeignKey('Installation')   serializers.py  from django.forms import widgets from rest_framework import serializers from modules.data.models import *  class ActionSerializer(serializers.ModelSerializer):     class Meta:         model = Controller         fields = ('id', 'name', 'ip', 'installation_id')   urls.py  from django.conf.urls import patterns, url from rest_framework.urlpatterns import format_suffix_patterns  urlpatterns = patterns('modules.actions.views',     url(r'^$','api_actions',name='api_actions'), )      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "TemplateDoesNotExist - Django Error",
        "A_Content": "  Not your case, but also possible reason is customized loaders for Django. For example, if you have in settings (since Django 1.8):  TEMPLATES = [ {     ...     'OPTIONS': {         'context_processors': [             'django.template.context_processors.debug',             'django.template.context_processors.request',             'django.contrib.auth.context_processors.auth',             'django.contrib.messages.context_processors.messages'         ],         'loaders': [             'django.template.loaders.filesystem.Loader',         ],         ...     } }]   Django will not try to look at applications folders with templates, because you should explicitly add django.template.loaders.app_directories.Loader into loaders for that.  Notice, that by default django.template.loaders.app_directories.Loader included into loaders.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-rest-framework"
        ],
        "URL": "https://stackoverflow.com/questions/21408344/templatedoesnotexist-django-error",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using Django Rest Framework. and I keep getting an error   Exception Type: TemplateDoesNotExist Exception Value: rest_framework/api.html   I dont know how I'm going wrong. This is the first time I'm trying out hands on REST Framework. This is code.  views.py  import socket, json from modules.data.models import * from modules.utils import * from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from modules.actions.serializers import ActionSerializer   @api_view(['POST']) @check_field_exists_wrapper(\"installation\") def api_actions(request, format = None):      action_type = request.POST['action_type']     if action_type == \"Shutdown\" :          send_message = '1'         print \"Shutting Down the system...\"     elif action_type == \"Enable\" :          send_message = '1'         print \"Enabling the system...\"     elif action_type == \"Disable\" :          send_message = '1'         print \"Disabling the system...\"     elif action_type == \"Restart\" :          send_message = '1'         print \"Restarting the system...\"      if action_type in [\"Shutdown\", \"Enable\", \"Disable\"] : PORT = 6000     else : PORT = 6100      controllers_list = Controller.objects.filter(installation_id = kwargs['installation_id'])      for controller_obj in controllers_list:         ip = controller_obj.ip         try:             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)             s.connect((ip, PORT))             s.send(send_message)             s.close()         except Exception as e:             print(\"Exception when sending \" + action_type +\" command: \"+str(e))      return Response(status = status.HTTP_200_OK)   models.py  class Controller(models.Model):     id = models.IntegerField(primary_key = True)     name = models.CharField(max_length = 255, unique = True)     ip = models.CharField(max_length = 255, unique = True)     installation_id = models.ForeignKey('Installation')   serializers.py  from django.forms import widgets from rest_framework import serializers from modules.data.models import *  class ActionSerializer(serializers.ModelSerializer):     class Meta:         model = Controller         fields = ('id', 'name', 'ip', 'installation_id')   urls.py  from django.conf.urls import patterns, url from rest_framework.urlpatterns import format_suffix_patterns  urlpatterns = patterns('modules.actions.views',     url(r'^$','api_actions',name='api_actions'), )      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to get a reference to current module's attributes in Python",
        "A_Content": "  Just use globals()     globals() — Return a dictionary   representing the current global symbol   table. This is always the dictionary   of the current module (inside a   function or method, this is the module   where it is defined, not the module   from which it is called).   http://docs.python.org/library/functions.html#globals     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/990422/how-to-get-a-reference-to-current-modules-attributes-in-python",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What I'm trying to do would look like this in the command line:  >>> import mymodule >>> names = dir(mymodule)   How can I get a reference to all the names defined in mymodule from within mymodule itself?  Something like this:  # mymodule.py names = dir(__thismodule__)      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to get a reference to current module's attributes in Python",
        "A_Content": "  As previously mentioned, globals gives you a dictionary as opposed to dir() which gives you a list of the names defined in the module.  The way I typically see this done is like this:  import sys dir(sys.modules[__name__])      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/990422/how-to-get-a-reference-to-current-modules-attributes-in-python",
        "A_Votes": "125",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What I'm trying to do would look like this in the command line:  >>> import mymodule >>> names = dir(mymodule)   How can I get a reference to all the names defined in mymodule from within mymodule itself?  Something like this:  # mymodule.py names = dir(__thismodule__)      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to get a reference to current module's attributes in Python",
        "A_Content": "  Also check out the built-in inspect module.  It can be very handy.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/990422/how-to-get-a-reference-to-current-modules-attributes-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What I'm trying to do would look like this in the command line:  >>> import mymodule >>> names = dir(mymodule)   How can I get a reference to all the names defined in mymodule from within mymodule itself?  Something like this:  # mymodule.py names = dir(__thismodule__)      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  If the package is on PYPI, download it and its dependencies to some local directory. E.g.   $ mkdir /pypi && cd /pypi $ ls -la   -rw-r--r--   1 pavel  staff   237954 Apr 19 11:31 Flask-WTF-0.6.tar.gz   -rw-r--r--   1 pavel  staff   389741 Feb 22 17:10 Jinja2-2.6.tar.gz   -rw-r--r--   1 pavel  staff    70305 Apr 11 00:28 MySQL-python-1.2.3.tar.gz   -rw-r--r--   1 pavel  staff  2597214 Apr 10 18:26 SQLAlchemy-0.7.6.tar.gz   -rw-r--r--   1 pavel  staff  1108056 Feb 22 17:10 Werkzeug-0.8.2.tar.gz   -rw-r--r--   1 pavel  staff   488207 Apr 10 18:26 boto-2.3.0.tar.gz   -rw-r--r--   1 pavel  staff   490192 Apr 16 12:00 flask-0.9-dev-2a6c80a.tar.gz   Some packages may have to be archived into similar looking tarballs by hand. I do it a lot when I want a more recent (less stable) version of something. Some packages aren't on PYPI, so same applies to them.  Suppose you have a properly formed Python application in ~/src/myapp. ~/src/myapp/setup.py will have install_requires list that mentions one or more things that you have in your /pypi directory. Like so:    install_requires=[     'boto',     'Flask',     'Werkzeug',     # and so on   If you want to be able to run your app with all the necessary dependencies while still hacking on it, you'll do something like this:   $ cd ~/src/myapp $ python setup.py develop --always-unzip --allow-hosts=None --find-links=/pypi   This way your app will be executed straight from your source directory. You can hack on things, and then rerun the app without rebuilding anything.  If you want to install your app and its dependencies into the current python environment, you'll do something like this:   $ cd ~/src/myapp $ easy_install --always-unzip --allow-hosts=None --find-links=/pypi .   In both cases, the build will fail if one or more dependencies aren't present in /pypi directory. It won't attempt to promiscuously install missing things from Internet.  I highly recommend to invoke setup.py develop ... and easy_install ... within an active virtual environment to avoid contaminating your global Python environment. It is (virtualenv that is) pretty much the way to go. Never install anything into global Python environment.  If the machine that you've built your app has same architecture as the machine on which you want to deploy it, you can simply tarball the entire virtual environment directory into which you easy_install-ed everything. Just before tarballing though, you must make the virtual environment directory relocatable (see --relocatable option). NOTE: the destination machine needs to have the same version of Python installed, and also any C-based dependencies your app may have must be preinstalled there too (e.g. say if you depend on PIL, then libpng, libjpeg, etc must be preinstalled).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  I use the -d (or --download) option to pip install, which makes the process of downloading sdist tarballs from PyPI much simpler. For instance, pip install --download /path/to/some/dir celery will download the sdist tarballs for celery and all its dependencies to /path/to/some/dir (but will not install them). Then you can use pip install --no-index --find-links /path/to/some/dir/ celery to install celery using those downloaded sdists, without accessing the network.  The same process works if you replace celery in both commands with -r requirements.txt, where requirements.txt is a pip requirements file listing all the packages you want (and optionally the versions you want).  UPDATE     DEPRECATION: pip install --download has been deprecated and will be   removed in the future. Pip now has a download command that should be   used instead.      The command is like this:   pip download -r requirements.txt        For python3:   pip3 download -r requirements.txt      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "183",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  Download the tarball, transfer it to your FreeBSD machine and extract it, afterwards run python setup.py install and you're done!  EDIT: Just to add on that, you can also install the tarballs with pip now.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  offline python. for doing this I use virtualenv (isolated Python environment)  1) install virtualenv  online with pip:   pip install virtualenv --user   or offline with whl: go to this link , download last version (.whl or tar.gz) and install that with this command:  pip install virtualenv-15.1.0-py2.py3-none-any.whl --user   by using --user you don't need to use sudo pip….  2) use virtualenv  on online machine select a directory with terminal cd and run this code:  python -m virtualenv myenv cd myenv source bin/activate pip install Flask   after installing all the packages, you have to generate a requirements.txt so while your virtualenv is active, write  pip freeze > requirements.txt   open a new terminal and create another env like myenv2.  python -m virtualenv myenv2 cd myenv2 source bin/activate cd - ls   now you can go to your offline folder where your requirements.txt and tranferred_packages folder are in there. download the packages with following code and put all of them to tranferred_packages folder.  pip download -r requirements.txt   take your offline folder to offline computer and then  python -m virtualenv myenv2 cd myenv2 source bin/activate cd - cd offline pip install --no-index --find-links=\"./tranferred_packages\" -r requirements.txt   what is in the folder offline  [requirements.txt , tranferred_packages {Flask-0.10.1.tar.gz, ...}]  check list of your package  pip list   note: as we are in 2017 it is better to use python 3. you can create python 3 virtualenv with this command.  virtualenv -p python3 envname      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  Using wheel compiled packages.  bundle up:  $ tempdir=$(mktemp -d /tmp/wheelhouse-XXXXX) $ pip wheel -r requirements.txt --wheel-dir=$tempdir $ cwd=`pwd` $ (cd \"$tempdir\"; tar -cjvf \"$cwd/bundled.tar.bz2\" *)   copy tarball and install:  $ tempdir=$(mktemp -d /tmp/wheelhouse-XXXXX) $ (cd $tempdir; tar -xvf /path/to/bundled.tar.bz2) $ pip install --force-reinstall --ignore-installed --upgrade --no-index --no-deps $tempdir/*   Note wheel binary packages are not across machines.  More ref. here: https://pip.pypa.io/en/stable/user_guide/#installation-bundles     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  For Pip 8.1.2 you can use pip download -r requ.txt to download packages to your local machine.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python Packages Offline Installation",
        "A_Content": "  If you want install python libs and their dependencies offline, finish following steps in a machine with same os, network connected, python installed:  1) Create an requirements.txt file with the content like:  Flask==0.12 requests>=2.7.0 scikit-learn==0.19.1 numpy==1.14.3 pandas==0.22.0   2) Execute command mkdir wheelhouse && pip download -r requirements.txt -d wheelhouse to download libs and their dependencies to direcotry wheelhouse  3) Copy requirements.txt into wheelhouse directory  4) Archive wheelhouse into wheelhouse.tar.gz with tar -zcf wheelhouse.tar.gz wheelhouse  Then upload wheelhouse.tar.gz to your target machine:  1) Execute tar -zxf wheelhouse.tar.gz to extract the files  2) Execute pip install -r wheelhouse/requirements.txt --no-index --find-links wheelhouse to install the libs and their dependencies     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip",
            "freebsd",
            "easy-install",
            "python-requests"
        ],
        "URL": "https://stackoverflow.com/questions/11091623/python-packages-offline-installation",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What's the best way to download a python package and it's dependencies from pypi for offline installation on another machine? Is there any easy way to do this with pip or easy_install? I'm trying to install the requests library on a FreeBSD box that is not connected to the internet.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  I realize that this is an old question...but for people finding there way here via Google:  package_data is a low-down, dirty lie.  It is only used when building binary packages (python setup.py bdist ...) but not when building source packages (python setup.py sdist ...).  This is, of course, ridiculous -- one would expect that building a source distribution would result in a collection of files that could be sent to someone else to built the binary distribution.  In any case, using MANIFEST.in will work both for binary and for source distributions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "199",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  I just had this same issue. The solution, was simply to remove include_package_data=True.  After reading here, I realized that include_package_data aims to include files from version control, as opposed to merely \"include package data\" as the name implies. From the docs:     The data files [of include_package_data] must be under CVS or Subversion control      ...      If you want finer-grained control over what files are included (for example, if   you have documentation files in your package directories and want to exclude   them from installation), then you can also use the package_data keyword.   Taking that argument out fixed it, which is coincidentally why it also worked when you switched to distutils, since it doesn't take that argument.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  Following @Joe 's recommendation to remove the include_package_data=True line also worked for me.   To elaborate a bit more, I have no MANIFEST.in file. I use Git and not CVS.  Repository takes this kind of shape:  /myrepo     - .git/     - setup.py     - myproject         - __init__.py         - some_mod             - __init__.py             - animals.py             - rocks.py         - config             - __init__.py             - settings.py             - other_settings.special             - cool.huh             - other_settings.xml         - words             - __init__.py             word_set.txt   setup.py:  from setuptools import setup, find_packages import os.path  setup (     name='myproject',     version = \"4.19\",     packages = find_packages(),       # package_dir={'mypkg': 'src/mypkg'},  # didnt use this.     package_data = {         # If any package contains *.txt or *.rst files, include them:         '': ['*.txt', '*.xml', '*.special', '*.huh'],     },  #     # Oddly enough, include_package_data=True prevented package_data from working.     # include_package_data=True, # Commented out.     data_files=[ #               ('bitmaps', ['bm/b1.gif', 'bm/b2.gif']),         ('/opt/local/myproject/etc', ['myproject/config/settings.py', 'myproject/config/other_settings.special']),         ('/opt/local/myproject/etc', [os.path.join('myproject/config', 'cool.huh')]), #         ('/opt/local/myproject/etc', [os.path.join('myproject/config', 'other_settings.xml')]),         ('/opt/local/myproject/data', [os.path.join('myproject/words', 'word_set.txt')]),     ],      install_requires=[ 'jsonschema',         'logging', ],       entry_points = {         'console_scripts': [             # Blah...         ], }, )   I run python setup.py sdist for a source distrib (haven't tried binary).  And when inside of a brand new virtual environment, I have a myproject-4.19.tar.gz, file,  and I use  (venv) pip install ~/myproject-4.19.tar.gz ...   And other than everything getting installed to my virtual environment's site-packages, those special data files get installed to /opt/local/myproject/data and /opt/local/myproject/etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  include_package_data=True worked for me.  If you use git, remember to include setuptools-git in install_requires. Far less boring than having a Manifest or including all path in package_data ( in my case it's a django app with all kind of statics )  ( pasted the comment I made, as k3-rnc mentioned it's actually helpful as is )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  Update: This answer is old and the information is no longer valid. All setup.py configs should use import setuptools. I've added a more complete answer at https://stackoverflow.com/a/49501350/64313    I solved this by switching to distutils. Looks like distribute is deprecated and/or broken.  from distutils.core import setup  setup(    name='myapp',    packages=['myapp'],    package_data={       'myapp': ['data/*.txt'],    }, )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  Ancient question and yet... package management of python really leaves a lot to be desired. So I had the use case of installing using pip locally to a specified directory and was surprised both package_data and data_files paths did not work out. I was not keen on adding yet another file to the repo so I ended up leveraging data_files and setup.py option --install-data; something like this  pip install . --install-option=\"--install-data=$PWD/package\" -t package        ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to include package data with setuptools/distribute?",
        "A_Content": "  Moving the folder containing the package data into to module folder solved the problem for me.  See this question: MANIFEST.in ignored on \"python setup.py install\" - no data files installed?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "setuptools",
            "distribute"
        ],
        "URL": "https://stackoverflow.com/questions/7522250/how-to-include-package-data-with-setuptools-distribute",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When using setuptools/distribute, I can not get the installer to pull in any package_data files. Everything I've read says that the following is the correct way to do it. Can someone please advise?  setup(    name='myapp',    packages=find_packages(),    package_data={       'myapp': ['data/*.txt'],    },    include_package_data=True,    zip_safe=False,    install_requires=['distribute'], )   where myapp/data/ is the location of the data files.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to add hours to current time in python",
        "A_Content": "  from datetime import datetime, timedelta  nine_hours_from_now = datetime.now() + timedelta(hours=9) #datetime.datetime(2012, 12, 3, 23, 24, 31, 774118)   And then use string formatting to get the relevant pieces:  >>> '{:%H:%M:%S}'.format(nine_hours_from_now) '23:24:31'   If you're only formatting the datetime then you can use:  >>> format(nine_hours_from_now, '%H:%M:%S') '23:24:31'   Or, as @eumiro has pointed out in comments - strftime     ",
        "Language": "Python",
        "Tags": [
            "python",
            "time",
            "add"
        ],
        "URL": "https://stackoverflow.com/questions/13685201/how-to-add-hours-to-current-time-in-python",
        "A_Votes": "250",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am able to get the current time as below:     from datetime import datetime str(datetime.now())[11:19]   Result  '19:43:20'   Now, i am trying to add 9 hours to the above time, how can I add hours to current time in Python?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you create nested dict in Python?",
        "A_Content": "  A nested dict is a dictionary within a dictionary. A very simple thing.  >>> d = {} >>> d['dict1'] = {} >>> d['dict1']['innerkey'] = 'value' >>> d {'dict1': {'innerkey': 'value'}}   You can also use a defaultdict from the collections package to facilitate creating nested dictionaries.  >>> import collections >>> d = collections.defaultdict(dict) >>> d['dict1']['innerkey'] = 'value' >>> d  # currently a defaultdict type defaultdict(<type 'dict'>, {'dict1': {'innerkey': 'value'}}) >>> dict(d)  # but is exactly like a normal dictionary. {'dict1': {'innerkey': 'value'}}     You can populate that however you want.  I would recommend in your code something like the following:  d = {}  # can use defaultdict(dict) instead  for row in file_map:     # derive row key from something      # when using defaultdict, we can skip the next step creating a dictionary on row_key     d[row_key] = {}      for idx, col in enumerate(row):         d[row_key][idx] = col     According to your comment:     may be above code is confusing the question. My problem in nutshell: I   have 2 files a.csv b.csv, a.csv has 4 columns i j k l, b.csv also has   these columns. i is kind of key columns for these csvs'. j k l column   is empty in a.csv but populated in b.csv. I want to map values of j k   l columns using 'i` as key column from b.csv to a.csv file   My suggestion would be something like this (without using defaultdict):  a_file = \"path/to/a.csv\" b_file = \"path/to/b.csv\"  # read from file a.csv with open(a_file) as f:     # skip headers     f.next()     # get first colum as keys     keys = (line.split(',')[0] for line in f)   # create empty dictionary: d = {}  # read from file b.csv with open(b_file) as f:     # gather headers except first key header     headers = f.next().split(',')[1:]     # iterate lines     for line in f:         # gather the colums         cols = line.strip().split(',')         # check to make sure this key should be mapped.         if cols[0] not in keys:             continue         # add key to dict         d[cols[0]] = dict(             # inner keys are the header names, values are columns             (headers[idx], v) for idx, v in enumerate(cols[1:]))   Please note though, that for parsing csv files there is a csv module.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "dictionary",
            "mapping",
            "nested"
        ],
        "URL": "https://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python",
        "A_Votes": "190",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have 2 csv files. First one is data file and other one is mapping file. Mapping file has 4 columns Device_Name GDN Device_Type Device_OS These are also the columns which are present in data file and need to be worked upon.  Data file contains data with Device_Name column populated & rest 3 columns blank. Mapping file contains all columns populated. I want my Python code to open both files and for each device name in data file map its GDN, Device_Type & Device_OS value from mapping file.  I know how to use dict when only 2 columns are present (1 is needed to be mapped) but I don't know how to accomplish this when 3 columns need to be mapped.  Following is the code using which I tried to accomplish mapping of Device_Type:  x = dict([]) with open(\"Pricing Mapping_2013-04-22.csv\", \"rb\") as in_file1:     file_map = csv.reader(in_file1, delimiter=',')     for row in file_map:        typemap = [row[0],row[2]]        x.append(typemap)  with open(\"Pricing_Updated_Cleaned.csv\", \"rb\") as in_file2, open(\"Data Scraper_GDN.csv\", \"wb\") as out_file:     writer = csv.writer(out_file, delimiter=',')     for row in csv.reader(in_file2, delimiter=','):          try:               row[27] = x[row[11]]          except KeyError:               row[27] = \"\"          writer.writerow(row)   It returns the Atribute Error.  After some researching, I realized that I need to create a nested dict, but I don't have any idea on how to do this.  Please help me in resolving this or nudge me in the right direction to resolve this.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you create nested dict in Python?",
        "A_Content": "  UPDATE: For an arbitrary length of a nested dictionary, go to this answer.  Use the defaultdict function from the collections.   High performance: \"if key not in dict\" is very expensive when the data set is large.  Low maintenance: make the code more readable and can be easily extended.  from collections import defaultdict  target_dict = defaultdict(dict) target_dict[key1][key2] = val      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "dictionary",
            "mapping",
            "nested"
        ],
        "URL": "https://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python",
        "A_Votes": "49",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have 2 csv files. First one is data file and other one is mapping file. Mapping file has 4 columns Device_Name GDN Device_Type Device_OS These are also the columns which are present in data file and need to be worked upon.  Data file contains data with Device_Name column populated & rest 3 columns blank. Mapping file contains all columns populated. I want my Python code to open both files and for each device name in data file map its GDN, Device_Type & Device_OS value from mapping file.  I know how to use dict when only 2 columns are present (1 is needed to be mapped) but I don't know how to accomplish this when 3 columns need to be mapped.  Following is the code using which I tried to accomplish mapping of Device_Type:  x = dict([]) with open(\"Pricing Mapping_2013-04-22.csv\", \"rb\") as in_file1:     file_map = csv.reader(in_file1, delimiter=',')     for row in file_map:        typemap = [row[0],row[2]]        x.append(typemap)  with open(\"Pricing_Updated_Cleaned.csv\", \"rb\") as in_file2, open(\"Data Scraper_GDN.csv\", \"wb\") as out_file:     writer = csv.writer(out_file, delimiter=',')     for row in csv.reader(in_file2, delimiter=','):          try:               row[27] = x[row[11]]          except KeyError:               row[27] = \"\"          writer.writerow(row)   It returns the Atribute Error.  After some researching, I realized that I need to create a nested dict, but I don't have any idea on how to do this.  Please help me in resolving this or nudge me in the right direction to resolve this.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you create nested dict in Python?",
        "A_Content": "  For arbitrary levels of nestedness:  In [2]: def nested_dict():    ...:     return collections.defaultdict(nested_dict)    ...:  In [3]: a = nested_dict()  In [4]: a Out[4]: defaultdict(<function __main__.nested_dict>, {})  In [5]: a['a']['b']['c'] = 1  In [6]: a Out[6]: defaultdict(<function __main__.nested_dict>,             {'a': defaultdict(<function __main__.nested_dict>,                          {'b': defaultdict(<function __main__.nested_dict>,                                       {'c': 1})})})      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "dictionary",
            "mapping",
            "nested"
        ],
        "URL": "https://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have 2 csv files. First one is data file and other one is mapping file. Mapping file has 4 columns Device_Name GDN Device_Type Device_OS These are also the columns which are present in data file and need to be worked upon.  Data file contains data with Device_Name column populated & rest 3 columns blank. Mapping file contains all columns populated. I want my Python code to open both files and for each device name in data file map its GDN, Device_Type & Device_OS value from mapping file.  I know how to use dict when only 2 columns are present (1 is needed to be mapped) but I don't know how to accomplish this when 3 columns need to be mapped.  Following is the code using which I tried to accomplish mapping of Device_Type:  x = dict([]) with open(\"Pricing Mapping_2013-04-22.csv\", \"rb\") as in_file1:     file_map = csv.reader(in_file1, delimiter=',')     for row in file_map:        typemap = [row[0],row[2]]        x.append(typemap)  with open(\"Pricing_Updated_Cleaned.csv\", \"rb\") as in_file2, open(\"Data Scraper_GDN.csv\", \"wb\") as out_file:     writer = csv.writer(out_file, delimiter=',')     for row in csv.reader(in_file2, delimiter=','):          try:               row[27] = x[row[11]]          except KeyError:               row[27] = \"\"          writer.writerow(row)   It returns the Atribute Error.  After some researching, I realized that I need to create a nested dict, but I don't have any idea on how to do this.  Please help me in resolving this or nudge me in the right direction to resolve this.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you create nested dict in Python?",
        "A_Content": "  It is important to remember when using defaultdict and similar nested dict modules such as nested_dict, that looking up a non existent key may inadvertently create a new key entry in the dict and cause a lot of havoc. Here is a Python3 example with nested_dict.  import nested_dict as nd nest = nd.nested_dict() nest['outer1']['inner1'] = 'v11' nest['outer1']['inner2'] = 'v12' print('original nested dict: \\n', nest) try:     nest['outer1']['wrong_key1'] except KeyError as e:     print('exception missing key', e) print('nested dict after lookup with missing key.  no exception raised:\\n', nest)  # instead convert back to normal dict nest_d = nest.to_dict(nest) try:     print('converted to normal dict. Trying to lookup Wrong_key2')     nest_d['outer1']['wrong_key2'] except KeyError as e:     print('exception missing key', e) else:     print(' no exception raised:\\n') # or use dict.keys to check if key in nested dict. print('checking with dict.keys') print(list(nest['outer1'].keys())) if 'wrong_key3' in list(nest.keys()):      print('found wrong_key3') else:     print(' did not find wrong_key3')   Output is:  original nested dict:   {\"outer1\": {\"inner2\": \"v12\", \"inner1\": \"v11\"}}  nested dict after lookup with missing key.  no exception raised:   {\"outer1\": {\"wrong_key1\": {}, \"inner2\": \"v12\", \"inner1\": \"v11\"}}   converted to normal dict.  Trying to lookup Wrong_key2   exception missing key 'wrong_key2'   checking with dict.keys   ['wrong_key1', 'inner2', 'inner1']   did not find wrong_key3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "dictionary",
            "mapping",
            "nested"
        ],
        "URL": "https://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have 2 csv files. First one is data file and other one is mapping file. Mapping file has 4 columns Device_Name GDN Device_Type Device_OS These are also the columns which are present in data file and need to be worked upon.  Data file contains data with Device_Name column populated & rest 3 columns blank. Mapping file contains all columns populated. I want my Python code to open both files and for each device name in data file map its GDN, Device_Type & Device_OS value from mapping file.  I know how to use dict when only 2 columns are present (1 is needed to be mapped) but I don't know how to accomplish this when 3 columns need to be mapped.  Following is the code using which I tried to accomplish mapping of Device_Type:  x = dict([]) with open(\"Pricing Mapping_2013-04-22.csv\", \"rb\") as in_file1:     file_map = csv.reader(in_file1, delimiter=',')     for row in file_map:        typemap = [row[0],row[2]]        x.append(typemap)  with open(\"Pricing_Updated_Cleaned.csv\", \"rb\") as in_file2, open(\"Data Scraper_GDN.csv\", \"wb\") as out_file:     writer = csv.writer(out_file, delimiter=',')     for row in csv.reader(in_file2, delimiter=','):          try:               row[27] = x[row[11]]          except KeyError:               row[27] = \"\"          writer.writerow(row)   It returns the Atribute Error.  After some researching, I realized that I need to create a nested dict, but I don't have any idea on how to do this.  Please help me in resolving this or nudge me in the right direction to resolve this.      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  You could try using the interactive option for python:  python -i program.py   This will execute the code in program.py, then go to the REPL.  Anything you define or import in the top level of program.py will be available.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "86",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  I frequently use this:  def interact():     import code     code.InteractiveConsole(locals=globals()).interact()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  Here's how you should do it (IPython > v0.11):  import IPython IPython.embed()   For IPython <= v0.11:  from IPython.Shell import IPShellEmbed  ipshell = IPShellEmbed()  ipshell() # this call anywhere in your program will start IPython   You should use IPython, the Cadillac of Python REPLs. See http://ipython.org/ipython-doc/stable/interactive/reference.html#embedding-ipython  From the documentation:     It can also be useful in scientific   computing situations where it is   common to need to do some automatic,   computationally intensive part and   then stop to look at data, plots, etc.   Opening an IPython instance will give   you full access to your data and   functions, and you can resume program   execution once you are done with the   interactive part (perhaps to stop   again later, as many times as needed).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "39",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  You can launch the debugger:  import pdb;pdb.set_trace()    Not sure what you want the REPL for, but the debugger is very similar.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  To get use of iPython and functionality of debugger you should use ipdb,   You can use it in the same way as pdb, with the addition of :  import ipdb ipdb.set_trace()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to drop into REPL (Read, Eval, Print, Loop) from Python code",
        "A_Content": "  I just did this in one of my own scripts (it runs inside an automation framework that is a huge PITA to instrument):  x = 0 # exit loop counter while x == 0:     user_input = raw_input(\"Please enter a command, or press q to quit: \")     if user_input[0] == \"q\":         x = 1     else:         try:             print eval(user_input)         except:             print \"I can't do that, Dave.\"             continue   Just place this wherever you want a breakpoint, and you can check the state using the same syntax as the python interpreter (although it doesn't seem to let you do module imports). It's not very elegant, but it doesn't require any other setup.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "interactive"
        ],
        "URL": "https://stackoverflow.com/questions/1395913/how-to-drop-into-repl-read-eval-print-loop-from-python-code",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to programmatically force a Python script to drop into a REPL at an arbitrary point in its execution, even if the script was launched from the command line?  I'm writing a quick and dirty plotting program, which I want to read data from stdin or a file, plot it, and then drop into the REPL to allow for the plot to be customized.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  Simple:  >>> import string >>> string.letters 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' >>> import random >>> random.choice(string.letters) 'j'   string.letters returns a string containing the lower case and upper case letters according to the current locale; if that's not acceptable, string.ascii_letters will probably do the trick.  random.choice returns a single, random element from a sequence.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "164",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  >>> import random >>> import string >>> random.choice(string.ascii_letters) 'g'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  >>> import random >>> import string     >>> random.choice(string.ascii_lowercase) 'b'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  >>>def random_char(y):        return ''.join(random.choice(string.ascii_letters) for x in range(y))  >>>print (random_char(5)) >>>fxkea   to generate y number of random characters      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  Another way, for completeness:  >>> chr(random.randrange(97, 97 + 26 + 1))   Use the fact that ascii 'a' is 97, and there are 26 letters in the alphabet.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  def randchar(a, b):     return chr(random.randint(ord(a), ord(b)))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  import random def guess_letter():     return random.choice('abcdefghijklmnopqrstuvwxyz')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  You can just make a list:  import random list1=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] b=random.randint(0,7) print(list1[b])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  You can use this to get one or more random letter(s)  import random import string random.seed(10) letters = string.ascii_lowercase rand_letters = random.choices(letters,k=5) # where k is the number of required rand_letters  print(letters)  ['o', 'l', 'p', 'f', 'v']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  import string import random  KEY_LEN = 20  def base_str():     return (string.letters+string.digits)    def key_gen():     keylist = [random.choice(base_str()) for i in range(KEY_LEN)]     return (\"\".join(keylist))   You can get random strings like this:  g9CtUljUWD9wtk1z07iF ndPbI1DDn6UvHSQoDMtd klMFY3pTYNVWsNJ6cs34 Qgr7OEalfhXllcFDGh2l      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  def create_key(key_len):     key = ''     valid_characters_list = string.letters + string.digits     for i in range(key_len):         character = choice(valid_characters_list)         key = key + character     return key  def create_key_list(key_num):     keys = []     for i in range(key_num):         key = create_key(key_len)         if key not in keys:             keys.append(key)     return keys      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  well, this is my answer! It works well. Just put the number of random letters you want in 'number'... (Python 3)  import random  def key_gen():     keylist = random.choice('abcdefghijklmnopqrstuvwxyz')     return keylist  number = 0 list_item = '' while number < 20:     number = number + 1     list_item = list_item + key_gen()  print(list_item)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Generate a random letter in Python",
        "A_Content": "  import string import random  def random_char(y):     return ''.join(random.choice(string.ascii_letters+string.digits+li) for x in range(y)) no=int(input(\"Enter the number of character for your password=  \")) li = random.choice('!@#$%^*&( )_+}{') print(random_char(no)+li)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "random",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a way to generate random letters in Python (like random.randint but for letters)? The range functionality of random.randint would be nice but having a generator that just outputs a random letter would be better than nothing.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  You should use ModelAdmin.formfield_overrides.  It is quite easy - in admin.py, define:  class YourModelAdmin(admin.ModelAdmin):     formfield_overrides = {         models.CharField: {'widget': TextInput(attrs={'size':'20'})},         models.TextField: {'widget': Textarea(attrs={'rows':4, 'cols':40})},     }  admin.site.register(YourModel, YourModelAdmin)   Don't forget that you should import appropriate classes -- in this case:  from django.forms import TextInput, Textarea from django.db import models      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "173",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  You can set arbitrary HTML attributes on a widget using its \"attrs\" property.  You can do this in the Django admin using formfield_for_dbfield:  class MyModelAdmin(admin.ModelAdmin):   def formfield_for_dbfield(self, db_field, **kwargs):     field = super(ContentAdmin, self).formfield_for_dbfield(db_field, **kwargs)     if db_field.name == 'somefield':       field.widget.attrs['class'] = 'someclass ' + field.widget.attrs.get('class', '')     return field   or with a custom Widget subclass and the formfield_overrides dictionary:  class DifferentlySizedTextarea(forms.Textarea):   def __init__(self, *args, **kwargs):     attrs = kwargs.setdefault('attrs', {})     attrs.setdefault('cols', 80)     attrs.setdefault('rows', 5)     super(DifferentlySizedTextarea, self).__init__(*args, **kwargs)  class MyModelAdmin(admin.ModelAdmin):   formfield_overrides = { models.TextField: {'widget': DifferentlySizedTextarea}}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  A quick and dirty option is to simply provide a custom template for the model in question.   If you create a template named admin/<app label>/<class name>/change_form.html then the admin will use that template instead of the default. That is, if you've got a model named Person in an app named people, you'd create a template named admin/people/person/change_form.html.  All the admin templates have an extrahead block you can override to place stuff in the <head>, and the final piece of the puzzle is the fact that every field has an HTML id of id_<field-name>.  So, you could put something like the following in your template:  {% extends \"admin/change_form.html\" %}  {% block extrahead %}   {{ block.super }}   <style type=\"text/css\">     #id_my_field { width: 100px; }   </style> {% endblock %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  To change the width for a specific field.  Made via ModelAdmin.get_form:  class YourModelAdmin(admin.ModelAdmin):     def get_form(self, request, obj=None, **kwargs):         form = super(YourModelAdmin, self).get_form(request, obj, **kwargs)         form.base_fields['myfield'].widget.attrs['style'] = 'width: 45em;'         return form      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  If you want to change the attributes on a per-field instance, you can add the \"attrs\" property directly in to your form entries.  for example:  class BlogPostForm(forms.ModelForm):     title = forms.CharField(label='Title:', max_length=128)     body = forms.CharField(label='Post:', max_length=2000,          widget=forms.Textarea(attrs={'rows':'5', 'cols': '5'}))      class Meta:         model = BlogPost         fields = ('title', 'body')   The \"attrs\" property basically passes along the HTML markup that will adjust the form field.  Each entry is a tuple of the attribute you would like to override and the value you would like to override it with.  You can enter as many attributes as you like as long as you separate each tuple with a comma.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  The best way I found is something like this:  class NotificationForm(forms.ModelForm):     def __init__(self, *args, **kwargs):          super(NotificationForm, self).__init__(*args, **kwargs)         self.fields['content'].widget.attrs['cols'] = 80         self.fields['content'].widget.attrs['rows'] = 15         self.fields['title'].widget.attrs['size'] = 50     class Meta:         model = Notification   Its much better for ModelForm than overriding fields with different widgets, as it preserves name and help_text attributes and also default values of model fields, so you don't have to copy them to your form.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  I had a similar problem with TextField.  I'm using Django 1.0.2 and wanted to change the default value for 'rows' in the associated textarea.  formfield_overrides doesn't exist in this version.  Overriding formfield_for_dbfield worked but I had to do it for each of my ModelAdmin subclasses or it would result in a recursion error.  Eventually, I found that adding the code below to models.py works:  from django.forms import Textarea  class MyTextField(models.TextField): #A more reasonably sized textarea                                                                                                                 def formfield(self, **kwargs):          kwargs.update(             {\"widget\": Textarea(attrs={'rows':2, 'cols':80})}          )          return super(MyTextField, self).formfield(**kwargs)   Then use MyTextField instead of TextField when defining your models. I adapted it from this answer to a similar question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  It's well described in Django FAQ:  Q: How do I change the attributes for a widget on a field in my model?  A: Override the formfield_for_dbfield in the ModelAdmin/StackedInline/TabularInline class   class MyOtherModelInline(admin.StackedInline):     model = MyOtherModel     extra = 1      def formfield_for_dbfield(self, db_field, **kwargs):         # This method will turn all TextFields into giant TextFields         if isinstance(db_field, models.TextField):             return forms.CharField(widget=forms.Textarea(attrs={'cols': 130, 'rows':30, 'class': 'docx'}))         return super(MyOtherModelInline, self).formfield_for_dbfield(db_field, **kwargs)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  You can always set your fields sizes in a custom stylesheet and tell Django to use that for your ModelAdmin class:  class MyModelAdmin(ModelAdmin):     class Media:         css = {\"all\": (\"my_stylesheet.css\",)}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  for 1.6, using forms I had to specify the attributes of the textarea inside the charfield:  test1 = forms.CharField(max_length=400, widget=forms.Textarea( attrs={'rows':'2', 'cols': '10'}),  initial='', help_text=helptexts.helptxt['test'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Resize fields in Django Admin",
        "A_Content": "  Same answer as msdin but with TextInput instead of TextArea:  from django.forms import TextInput  class ShortTextField(models.TextField):     def formfield(self, **kwargs):          kwargs.update(             {\"widget\": TextInput(attrs={'size': 10})}          )          return super(ShortTextField, self).formfield(**kwargs)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "django-models",
            "django-admin"
        ],
        "URL": "https://stackoverflow.com/questions/910169/resize-fields-in-django-admin",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Django tends to fill up horizontal space when adding or editing entries on the admin, but, in some cases, is a real waste of space, when, i.e., editing a date field, 8 characters wide, or a CharField, also 6 or 8 chars wide, and then the edit box goes up to 15 or 20 chars.  How can I tell the admin how wide a textbox should be, or the height of a TextField edit box?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  Python 2 uses ascii as the default encoding for source files, which means you must specify another encoding at the top of the file to use non-ascii unicode characters in literals. Python 3 uses utf-8 as the default encoding for source files, so this is less of an issue.  See: http://docs.python.org/tutorial/interpreter.html#source-code-encoding  To enable utf-8 source encoding, this would go in one of the top two lines:  # -*- coding: utf-8 -*-   The above is in the docs, but this also works:  # coding: utf-8   Additional considerations:   The source file must be saved using the correct encoding in your text editor as well. In Python 2, the unicode literal must have a u before it, as in s.replace(u\"Â \", u\"\") But in Python 3, just use quotes. In Python 2, you can from __future__ import unicode_literals to obtain the Python 3 behavior, but be aware this affects the entire current module. s.replace(u\"Â \", u\"\") will also fail if s is not a unicode string. string.replace returns a new string and does not edit in place, so make sure you're using the return value as well      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  def removeNonAscii(s): return \"\".join(filter(lambda x: ord(x)<128, s))   edit: my first impulse is always to use a filter, but the generator expression is more memory efficient (and shorter)...  def removeNonAscii(s): return \"\".join(i for i in s if ord(i)<128)   Keep in mind that this is guaranteed to work with UTF-8 encoding (because all bytes in multi-byte characters have the highest bit set to 1).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "154",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  >>> unicode_string = u\"hello aåbäcö\" >>> unicode_string.encode(\"ascii\", \"ignore\") 'hello abc'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  The following code will replace all non ASCII characters with question marks.  \"\".join([x if ord(x) < 128 else '?' for x in s])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  Using Regex:  import re  strip_unicode = re.compile(\"([^-_a-zA-Z0-9!@#%&=,/'\\\";:~`\\$\\^\\*\\(\\)\\+\\[\\]\\.\\{\\}\\|\\?\\<\\>\\\\]+|[^\\s]+)\") print strip_unicode.sub('', u'6Â 918Â 417Â 712')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  Way too late for an answer, but the original string was in UTF-8 and '\\xc2\\xa0' is UTF-8 for NO-BREAK SPACE.  Simply decode the original string as s.decode('utf-8') (\\xa0 displays as a space when decoded incorrectly as Windows-1252 or latin-1:  Example (Python 3)  s = b'6\\xc2\\xa0918\\xc2\\xa0417\\xc2\\xa0712' print(s.decode('latin-1')) # incorrectly decoded u = s.decode('utf8') # correctly decoded print(u) print(u.replace('\\N{NO-BREAK SPACE}','_')) print(u.replace('\\xa0','-')) # \\xa0 is Unicode for NO-BREAK SPACE   Output  6Â 918Â 417Â 712 6 918 417 712 6_918_417_712 6-918-417-712      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  #!/usr/bin/env python # -*- coding: utf-8 -*-  s = u\"6Â 918Â 417Â 712\" s = s.replace(u\"Â\", \"\")  print s   This will print out 6 918 417 712     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  I know it's an old thread, but I felt compelled to mention the translate method, which is always a good way to replace all character codes above 128 (or other if necessary).  Usage : str.translate(table[, deletechars])  >>> trans_table = ''.join( [chr(i) for i in range(128)] + [' '] * 128 )  >>> 'Résultat'.translate(trans_table) 'R sultat' >>> '6Â 918Â 417Â 712'.translate(trans_table) '6  918  417  712'   Starting with Python 2.6, you can also set the table to None, and use deletechars to delete the characters you don't want as in the examples shown in the standard docs at http://docs.python.org/library/stdtypes.html.  With unicode strings, the translation table is not a 256-character string but a dict with the ord() of relevant characters as keys. But anyway getting a proper ascii string from a unicode string is simple enough, using the method mentioned by truppo above, namely : unicode_string.encode(\"ascii\", \"ignore\")  As a summary, if for some reason you absolutely need to get an ascii string (for instance, when you raise a standard exception with raise Exception, ascii_message ), you can use the following function:  trans_table = ''.join( [chr(i) for i in range(128)] + ['?'] * 128 ) def ascii(s):     if isinstance(s, unicode):         return s.encode('ascii', 'replace')     else:         return s.translate(trans_table)   The good thing with translate is that you can actually convert accented characters to relevant non-accented ascii characters instead of simply deleting them or replacing them by '?'. This is often useful, for instance for indexing purposes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  s.replace(u'Â ', '')              # u before string is important   and make your .py file unicode.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  This is a dirty hack, but may work.  s2 = \"\" for i in s:     if ord(i) < 128:         s2 += i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to make the python interpreter correctly handle non-ASCII characters in string operations?",
        "A_Content": "  For what it was worth, my character set was utf-8 and I had included the classic \"# -*- coding: utf-8 -*-\" line.  However, I discovered that I didn't have Universal Newlines when reading this data from a webpage.   My text had two words, separated by \"\\r\\n\". I was only splitting on the \\n and replacing the \"\\n\".  Once I looped through and saw the character set in question, I realized the mistake.  So, it could also be within the ASCII character set, but a character that you didn't expect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode"
        ],
        "URL": "https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string that looks like so:  6Â 918Â 417Â 712   The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:  s.replace('Â ', '')   That should do the trick. But of course it complains that the non-ASCII character '\\xc2' in file blabla.py is not encoded.  I never quite could understand how to switch between different encodings.  Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:  #!/usr/bin/python2.4 # -*- coding: utf-8 -*-   The code:  f = urllib.urlopen(url)  soup = BeautifulSoup(f)  s = soup.find('div', {'id':'main_count'})  #making a print 's' here goes well. it shows 6Â 918Â 417Â 712  s.replace('Â ','')  save_main_count(s)   It gets no further than s.replace...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Update for those using Python3: You can simply use conda install mysqlclient to install the libraries required to use MySQLdb as it currently exists. The following SO question was a helpful clue: Python 3 ImportError: No module named 'ConfigParser' . Installing mysqlclient will install mysqlclient, mysql-connector, and llvmdev (at least, it installed these 3 libraries on my machine).  Here is the tale of my rambling experience with this problem.  Would love to see it edited or generalised if you have better experience of the issue... apply a bit of that SO magic.  Note: Comments in next paragraph applied to Snow Leopard, but not to Lion, which appears to require 64-bit MySQL  First off, the author (still?) of MySQLdb says here that one of the most pernicious problems is that OS X comes installed with a 32 bit version of Python, but most average joes (myself included) probably jump to install the 64 bit version of MySQL.  Bad move... remove the 64 bit version if you have installed it (instructions on this fiddly task are available on SO here), then download and install the 32 bit version (package here)  There are numerous step-by-steps on how to build and install the MySQLdb libraries.  They often have subtle differences.  This seemed the most popular to me, and provided the working solution.  I've reproduced it with a couple of edits below  Step 0: Before I start, I assume that you have MySQL, Python, and GCC installed on the mac.  Step 1: Download the latest MySQL for Python adapter from SourceForge.  Step 2: Extract your downloaded package:  tar xzvf MySQL-python-1.2.2.tar.gz   Step 3: Inside the folder, clean the package:  sudo python setup.py clean   COUPLE OF EXTRA STEPS, (from this comment)  Step 3b:  Remove everything under your MySQL-python-1.2.2/build/* directory -- don't trust the \"python setup.py clean\" to do it for you  Step 3c:  Remove the egg under Users/$USER/.python-eggs  Step 4:  Originally required editing _mysql.c, but is now NO LONGER NECESSARY.  MySQLdb community seem to have fixed this bug now.  Step 5: Create a symbolic link under lib to point to a sub-directory called mysql. This is where it looks for during compilation.  sudo ln -s /usr/local/mysql/lib /usr/local/mysql/lib/mysql   Step 6: Edit the setup_posix.py and change the following  mysql_config.path = \"mysql_config\"  to  mysql_config.path = \"/usr/local/mysql/bin/mysql_config\"  Step 7: In the same directory, rebuild your package (ignore the warnings that comes with it)  sudo python setup.py build   Step 8: Install the package and you are done.  sudo python setup.py install   Step 9: Test if it's working. It works if you can import MySQLdb.  python   >>> import MySQLdb  Step 10: If upon trying to import you receive an error complaining that Library not loaded: libmysqlclient.18.dylib ending with: Reason: image not found you need to create one additional symlink which is:  sudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/lib/libmysqlclient.18.dylib   You should then be able to import MySQLdb without any errors.  One final hiccup though is that if you start Python from the build directory you will get this error:  /Library/Python/2.5/site-packages/MySQL_python-1.2.3c1-py2.5-macosx-10.5-i386.egg/_mysql.py:3: UserWarning: Module _mysql was already imported from /Library/Python/2.5/site-packages/MySQL_python-1.2.3c1-py2.5-macosx-10.5-i386.egg/_mysql.pyc, but XXXX/MySQL-python-1.2.3c1 is being added to sys.path  This is pretty easy to Google, but to save you the trouble you will end up here (or maybe not... not a particularly future-proof URL) and figure out that you need to cd .. out of build directory and the error should disappear.  As I wrote at the top, I'd love to see this answer generalised, as there are numerous other specific experiences of this horrible problem out there. Edit away, or provide your own, better answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "126",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  A quick and easy way for Mac OS X 10.8 (Mountain Lion), 10.9 (Mavericks), 10.10 (Yosemite), and 10.11 (El Capitan):  I assume you have XCode, its command line tools, Python, and MySQL installed.   Install PIP:  sudo easy_install pip  Edit ~/.profile: (Might not be necessary in Mac OS X 10.10)  nano ~/.profile   Copy and paste the following two line  export PATH=/usr/local/mysql/bin:$PATH export DYLD_LIBRARY_PATH=/usr/local/mysql/lib/   Save and exit. Afterwords execute the following command:  source  ~/.profile  Install MySQLdb  sudo pip install MySQL-python   To test if everything works fine just try  python -c \"import MySQLdb\"    It worked like a charm for me. I hope it helps.  If you encounter an error regarding a missing library: Library not loaded: libmysqlclient.18.dylib then you have to symlink it to /usr/lib like so:  sudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/lib/libmysqlclient.18.dylib       ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "99",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Install mysql and python via Macports The porters have done all the difficult work.  sudo port install py26-mysql  sudo port install mysql5-server   should install what you need. (see Stack overflow for comments re mysql server)  If you only need to connect to mysql and not run a server then the first line is sufficient.  Macports now (early 2013) will provide binary downloads for common combinations of OS a executable architecture, for others (and if you request it) it will build from source.  In general macports (or fink) help when there are complex libraries etc that need to be installed.  Python only code and if simple C dependencies can be set up via setuptools etc, but it begins to get complex if you mix the two.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "36",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Install pip:  sudo easy_install pip   Install brew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\"   Install mysql:  brew install mysql   Install MySQLdb  sudo pip install MySQL-python   If you have compilation problems, try editing the ~/.profile file like in one of the answers here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Here's another step I had to go through, after receiving an error on completing Step 9:  ImportError: dlopen(/Users/rick/.python-eggs/MySQL_python-1.2.3-py2.6-macosx-10.6-universal.egg-tmp/_mysql.so, 2): Library not loaded: libmysqlclient.18.dylib      sudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/lib/libmysqlclient.18.dylib   Reference: Thanks! http://ageekstory.blogspot.com/2011_04_01_archive.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  As stated on Installing MySQL-python on mac :  pip uninstall MySQL-python brew install mysql pip install MySQL-python   Then test it :  python -c \"import MySQLdb\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Just had this problem (again!) after getting a new Lion box.  Best solution I've found (still not 100% optimal, but working):   make sure you have 64-bit python.   How to check if a library is 32bit/64bit built on Mac OS X? install easy_install if you don't have it.  http://packages.python.org/distribute/easy_install.html install GCC if you don't have it.     you can get it by downloading XCode/Dev Tools from Apple - this is a big download -   ... but instead I recommend this github which has what you need (and does not have XCode): https://github.com/kennethreitz/osx-gcc-installer  I downloaded their prebuilt PKG for lion, https://github.com/downloads/kennethreitz/osx-gcc-installer/GCC-10.7-v2.pkg   make sure you have downloaded a 64-BIT version of MYSQL Community.  (The DMG install is an easy route) http://dev.mysql.com/downloads/mysql/ Set paths as follows:  export PATH=$PATH:/usr/local/mysql-XXXX     export DYLD_LIBRARY_PATH = /usr/local/mysql/lib/  export ARCHFLAGS='-arch x86_64'   NOTE THAT:     1  in mysql-XXXX above, XXX is the specific version you downloaded.  (Probably /usr/local/mysql/ would also work since this is most likely an alias to the same, but I won't pretend to know your setup)      2 I have seen it suggested that ARCHFLAGS be set to '-arch i386 -arch x86_64' but specifying only x86_64 seemed to work better for me.  (I can think of some reasons for this but they are not strictly relevant).    Install the beast!  easy_install MySQL-python LAST STEP:   Permanently add the DYLD_LIBRARY_PATH!    You can add it to your bash_profile or similar. This was the missing step for me, without which my system continued to insist on various errors finding _mysql.so and so on.  export DYLD_LIBRARY_PATH = /usr/local/mysql/lib/  @richard-boardman, just noticed your soft link solution, which may in effect be doing the same thing my PATH solution does...folks, whatever works best for you.  Best reference: http://activeintelligence.org/blog/archive/mysql-python-aka-mysqldb-on-osx-lion/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  Or simple try:  > sudo easy_install MySQL-python   If it gives a error like below:     EnvironmentError: mysql_config not found   , then just run this   > export PATH=$PATH:/usr/local/mysql/bin      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  You could try using the pure-python pymysql:  sudo easy_install pymysql   (Or use pip if you have it installed.) Then, add this before you import MySQLdb in your code:  try:     import pymysql     pymysql.install_as_MySQLdb() except ImportError:     pass      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  If you are using 64 bit MySQL, using ARCHFLAGS to specify your cpu architecture while building mysql-python libraries would do the trick:  ARCHFLAGS='-arch x86_64' python setup.py build ARCHFLAGS='-arch x86_64' python setup.py install      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  export PATH=$PATH:/usr/local/mysql/bin/   should fix the issue for you as the system is not able to find the mysql_config file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to install MySQLdb (Python data access library to MySQL) on Mac OS X?",
        "A_Content": "  On macos Sierra this work for me, where python is managed by anaconda:  anaconda search -t conda mysql-python  anaconda show CEFCA/mysql-python  conda install --channel https://conda.anaconda.org/CEFCA mysql-python  The to use with SQLAlchemy:     Python 2.7.13 |Continuum Analytics, Inc.| (default, Dec 20 2016, 23:05:08)   [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin   Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.   Anaconda is brought to you by Continuum Analytics.   Please check out: http://continuum.io/thanks and https://anaconda.org      >>> from sqlalchemy import *      >>>dbengine = create_engine('mysql://....')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "macos"
        ],
        "URL": "https://stackoverflow.com/questions/1448429/how-to-install-mysqldb-python-data-access-library-to-mysql-on-mac-os-x",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.  So the question is how to get MySQLdb working on Mac OS X?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  I am removing the old answer as may result in data loss. As ozan mentioned, we can create 2 migrations one in each app.  First migration to remove model from 1st app.  $ python manage.py makemigrations old_app --empty   Edit migration file to include these operations.  class Migration(migrations.Migration):      database_operations = [migrations.AlterModelTable('TheModel', 'newapp_themodel')]      state_operations = [migrations.DeleteModel('TheModel')]      operations = [       migrations.SeparateDatabaseAndState(         database_operations=database_operations,         state_operations=state_operations)     ]   Second migration which depends on first migration and create the new table in 2nd app. After moving model code to 2nd app  $ python manage.py makemigrations new_app    and edit migration file to something like this.  class Migration(migrations.Migration):      dependencies = [         ('old_app', 'above_migration')     ]      state_operations = [         migrations.CreateModel(             name='TheModel',             fields=[                 ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),             ],             options={                 'db_table': 'newapp_themodel',             },             bases=(models.Model,),         )     ]      operations = [         migrations.SeparateDatabaseAndState(state_operations=state_operations)     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  This can be done fairly easily using migrations.SeparateDatabaseAndState. Basically, we use a database operation to rename the table concurrently with two state operations to remove the model from one app's history and create it in another's.  Remove from old app  python manage.py makemigrations old_app --empty   In the migration:  class Migration(migrations.Migration):      dependencies = []      database_operations = [         migrations.AlterModelTable('TheModel', 'newapp_themodel')     ]      state_operations = [         migrations.DeleteModel('TheModel')     ]      operations = [         migrations.SeparateDatabaseAndState(             database_operations=database_operations,             state_operations=state_operations)     ]   Add to new app  First, copy the model to the new app's model.py, then:  python manage.py makemigrations new_app   This will generate a migration with a naive CreateModel operation as the sole operation. Wrap that in a SeparateDatabaseAndState operation such that we don't try to recreate the table. Also include the prior migration as a dependency:  class Migration(migrations.Migration):      dependencies = [         ('old_app', 'above_migration')     ]      state_operations = [         migrations.CreateModel(             name='TheModel',             fields=[                 ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),             ],             options={                 'db_table': 'newapp_themodel',             },             bases=(models.Model,),         )     ]      operations = [         migrations.SeparateDatabaseAndState(state_operations=state_operations)     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "272",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  I encountered the same problem. Ozan's answer helped me a lot but unfortunately was not enough. Indeed I had several ForeignKey linking to the model I wanted to move. After some headache I found the solution so decided to post it to solve people time.  You need 2 more steps:   Before doing anything, change all your ForeignKey linking to TheModel into Integerfield. Then run python manage.py makemigrations After doing Ozan's steps, re-convert your foreign keys: put back ForeignKey(TheModel)instead of IntegerField(). Then make the migrations again (python manage.py makemigrations). You can then migrate and it should work (python manage.py migrate)   Hope it helps. Of course test it in local before trying in production to avoid bad suprises :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  How I did it (tested on Django==1.8, with postgres, so probably also 1.7)  Situation  app1.YourModel  but you want it to go to: app2.YourModel   Copy YourModel (the code) from app1 to app2. add this to app2.YourModel:  Class Meta:     db_table = 'app1_yourmodel'  $ python manage.py makemigrations app2 A new migration (e.g. 0009_auto_something.py) is made in app2 with a migrations.CreateModel() statement, move this statement to the initial migration of app2 (e.g. 0001_initial.py) (it will be just like it always have been there). And now remove the created migration = 0009_auto_something.py Just as you act, like app2.YourModel always has been there, now remove the existence of app1.YourModel from your migrations. Meaning: comment out the CreateModel statements, and every adjustment or datamigration you used after that. And of course, every reference to app1.YourModel has to be changed to app2.YourModel through your project. Also, don't forget that all possible foreign keys to app1.YourModel in migrations have to be changed to app2.YourModel Now if you do $ python manage.py migrate, nothing has changed, also when you do $ python manage.py makemigrations, nothing new has been detected. Now the finishing touch: remove the Class Meta from app2.YourModel and do $ python manage.py makemigrations app2 && python manage.py migrate app2 (if you look into this migration you'll see something like this:)      migrations.AlterModelTable(     name='yourmodel',     table=None, ),    table=None, means it will take the default table-name, which in this case will be app2_yourmodel.   DONE, with data saved.   P.S during the migration it will see that that content_type app1.yourmodel has been removed and can be deleted. You can say yes to that but only if you don't use it. In case you heavily depend on it to have FKs to that content-type be intact, don't answer yes or no yet, but go into the db that time manually, and remove the contentype app2.yourmodel, and rename the contenttype app1.yourmodel to app2.yourmodel, and then continue by answering no.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  I get nervous hand-coding migrations (as is required by Ozan's answer) so the following combines Ozan's and Michael's strategies to minimize the amount of hand-coding required:   Before moving any models, make sure you're working with a clean baseline by running makemigrations. Move the code for the Model from app1 to app2 As recommended by @Michael, we point the new model to the old database table using the db_table Meta option on the \"new\" model:  class Meta:     db_table = 'app1_yourmodel'  Run makemigrations.  This will generate CreateModel in app2 and DeleteModel in app1.  Technically, these migrations refer to the exact same table and would remove (including all data) and re-create the table. In reality, we don't want (or need) to do anything to the table.  We just need Django to believe that the change has been made.  Per @Ozan's answer, the state_operations flag in SeparateDatabaseAndState does this.  So we wrap all of the migrations entries IN BOTH MIGRATIONS FILES with SeparateDatabaseAndState(state_operations=[...]).  For example,  operations = [     ...     migrations.DeleteModel(         name='YourModel',     ),     ... ]   becomes  operations = [     migrations.SeparateDatabaseAndState(state_operations=[         ...         migrations.DeleteModel(             name='YourModel',         ),         ...     ]) ]  EDIT:  You also need to make sure the new \"virtual\" CreateModel migration depends on any migration that actually created or altered the original table.  For example, if your new migrations are app2.migrations.0004_auto_<date> (for the Create) and app1.migrations.0007_auto_<date> (for the Delete), the simplest thing to do is:   Open app1.migrations.0007_auto_<date> and copy its app1 dependency (e.g.  ('app1', '0006...'),).  This is the \"immediately prior\" migration in app1 and should include dependencies on all of the actual model building logic. Open  app2.migrations.0004_auto_<date> and add the dependency you just copied to its dependencies list.    EDIT:  If you have ForeignKey relationship(s) to the model you're moving, the above may not work.  This happens because:   Dependencies are not automatically created for the ForeignKey changes We do not want to wrap the ForeignKey changes in state_operations so we need to ensure they are separate from the table operations.   The \"minimum\" set of operations differ depending on the situation, but the following procedure should work for most/all ForeignKey migrations:   COPY the model from app1 to app2, set db_table, but DON'T change any FK references. Run makemigrations and wrap all app2 migration in state_operations (see above)   As above, add a dependency in the app2 CreateTable to the latest app1 migration  Point all of the FK references to the new model.  If you aren't using string references, move the old model to the bottom of models.py (DON'T remove it) so it doesn't compete with the imported class. Run makemigrations but DON'T wrap anything in state_operations (the FK changes should actually happen)   Add a dependency in all the ForeignKey migrations (i.e. AlterField) to the CreateTable migration in app2 (you'll need this list for the next step so keep track of them).  For example: Find the migration that includes the CreateModel e.g. app2.migrations.0002_auto_<date> and copy the name of that migration. Find all migrations that have a ForeignKey to that model (e.g. by searching app2.YourModel to find migrations like:  class Migration(migrations.Migration):      dependencies = [         ('otherapp', '0001_initial'),     ]      operations = [         migrations.AlterField(             model_name='relatedmodel',             name='fieldname',             field=models.ForeignKey(... to='app2.YourModel'),         ),     ]  Add the CreateModel migration as as a dependency:  class Migration(migrations.Migration):      dependencies = [         ('otherapp', '0001_initial'),         ('app2', '0002_auto_<date>'),     ]     Remove the models from app1 Run makemigrations and wrap the app1 migration in state_operations.   Add a dependency to all of the ForeignKey migrations (i.e. AlterField) from the previous step (may include migrations in app1 and app2). When I built these migrations, the DeleteTable already depended on the AlterField migrations so I didn't need to manually enforce it (i.e. Alter before Delete).    At this point, Django is good to go.  The new model points to the old table and Django's migrations have convinced it that everything has been relocated appropriately.  The big caveat (from @Michael's answer) is that a new ContentType is created for the new model.  If you link (e.g. by ForeignKey) to content types, you'll need to create a migration to update the ContentType table.  I wanted to cleanup after myself (Meta options and table names) so I used the following procedure (from @Michael):   Remove the db_table Meta entry Run makemigrations again to generate the database rename Edit this last migration and make sure it depends on the DeleteTable migration.  It doesn't seem like it should be necessary as the Delete should be purely logical, but I've run into errors (e.g. app1_yourmodel doesn't exist) if I don't.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  This is tested roughly, so do not forget to backup your DB!!!   For example, there are two apps: src_app and dst_app, we want to move model MoveMe from src_app to dst_app.  Create empty migrations for both apps:  python manage.py makemigrations --empty src_app python manage.py makemigrations --empty dst_app   Let's assume, that new migrations are XXX1_src_app_new and XXX1_dst_app_new, previuos top migrations are XXX0_src_app_old and XXX0_dst_app_old.  Add an operation that renames table for MoveMe model and renames its app_label in ProjectState to XXX1_dst_app_new. Do not forget to add dependency on XXX0_src_app_old migration. The resulting XXX1_dst_app_new migration is:  # -*- coding: utf-8 -*- from __future__ import unicode_literals  from django.db import models, migrations  # this operations is almost the same as RenameModel # https://github.com/django/django/blob/1.7/django/db/migrations/operations/models.py#L104 class MoveModelFromOtherApp(migrations.operations.base.Operation):      def __init__(self, name, old_app_label):         self.name = name         self.old_app_label = old_app_label      def state_forwards(self, app_label, state):          # Get all of the related objects we need to repoint         apps = state.render(skip_cache=True)         model = apps.get_model(self.old_app_label, self.name)         related_objects = model._meta.get_all_related_objects()         related_m2m_objects = model._meta.get_all_related_many_to_many_objects()         # Rename the model         state.models[app_label, self.name.lower()] = state.models.pop(             (self.old_app_label, self.name.lower())         )         state.models[app_label, self.name.lower()].app_label = app_label         for model_state in state.models.values():             try:                 i = model_state.bases.index(\"%s.%s\" % (self.old_app_label, self.name.lower()))                 model_state.bases = model_state.bases[:i] + (\"%s.%s\" % (app_label, self.name.lower()),) + model_state.bases[i+1:]             except ValueError:                 pass         # Repoint the FKs and M2Ms pointing to us         for related_object in (related_objects + related_m2m_objects):             # Use the new related key for self referential related objects.             if related_object.model == model:                 related_key = (app_label, self.name.lower())             else:                 related_key = (                     related_object.model._meta.app_label,                     related_object.model._meta.object_name.lower(),                 )             new_fields = []             for name, field in state.models[related_key].fields:                 if name == related_object.field.name:                     field = field.clone()                     field.rel.to = \"%s.%s\" % (app_label, self.name)                 new_fields.append((name, field))             state.models[related_key].fields = new_fields      def database_forwards(self, app_label, schema_editor, from_state, to_state):         old_apps = from_state.render()         new_apps = to_state.render()         old_model = old_apps.get_model(self.old_app_label, self.name)         new_model = new_apps.get_model(app_label, self.name)         if self.allowed_to_migrate(schema_editor.connection.alias, new_model):             # Move the main table             schema_editor.alter_db_table(                 new_model,                 old_model._meta.db_table,                 new_model._meta.db_table,             )             # Alter the fields pointing to us             related_objects = old_model._meta.get_all_related_objects()             related_m2m_objects = old_model._meta.get_all_related_many_to_many_objects()             for related_object in (related_objects + related_m2m_objects):                 if related_object.model == old_model:                     model = new_model                     related_key = (app_label, self.name.lower())                 else:                     model = related_object.model                     related_key = (                         related_object.model._meta.app_label,                         related_object.model._meta.object_name.lower(),                     )                 to_field = new_apps.get_model(                     *related_key                 )._meta.get_field_by_name(related_object.field.name)[0]                 schema_editor.alter_field(                     model,                     related_object.field,                     to_field,                 )      def database_backwards(self, app_label, schema_editor, from_state, to_state):         self.old_app_label, app_label = app_label, self.old_app_label         self.database_forwards(app_label, schema_editor, from_state, to_state)         app_label, self.old_app_label = self.old_app_label, app_label      def describe(self):         return \"Move %s from %s\" % (self.name, self.old_app_label)   class Migration(migrations.Migration):      dependencies = [        ('dst_app', 'XXX0_dst_app_old'),        ('src_app', 'XXX0_src_app_old'),     ]      operations = [         MoveModelFromOtherApp('MoveMe', 'src_app'),     ]   Add dependency on XXX1_dst_app_new to XXX1_src_app_new. XXX1_src_app_new is no-op migration that is needed to make sure that future src_app migrations will be executed after XXX1_dst_app_new.  Move MoveMe from src_app/models.py to dst_app/models.py. Then run:  python manage.py migrate   That's all!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  You can try the following (untested):   move the model from src_app to dest_app migrate dest_app; make sure the schema migration depends on the latest src_app migration (https://docs.djangoproject.com/en/dev/topics/migrations/#migration-files) add a data migration to dest_app, that copies all data from src_app migrate src_app; make sure the schema migration depends on the latest (data) migration of dest_app -- that is: the migration of step 3   Note that you will be copying the whole table, instead of moving it, but that way both apps don't have to touch a table that belongs to the other app, which I think is more important.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  Lets say you are moving model TheModel from app_a to app_b.  An alternate solution is to alter the existing migrations by hand. The idea is that each time you see an operation altering TheModel in app_a's migrations, you copy that operation to the end of app_b's initial migration. And each time you see a reference 'app_a.TheModel' in app_a's migrations, you change it to 'app_b.TheModel'.  I just did this for an existing project, where I wanted to extract a certain model to an reusable app. The procedure went smoothly. I guess things would be much harder if there were references from app_b to app_a. Also, I had a manually defined Meta.db_table for my model which might have helped.  Notably you will end up with altered migration history. This doesn't matter, even if you have a database with the original migrations applied. If both the original and the rewritten migrations end up with the same database schema, then such rewrite should be OK.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "   change the names of old models to ‘model_name_old’ makemigrations make new models named ‘model_name_new’ with identical relationships on the related models (eg. user model now has user.blog_old and user.blog_new) makemigrations write a custom migration that migrates all the data to the new model tables test the hell out of these migrations by comparing backups with new db copies before and after running the migrations when all is satisfactory, delete the old models makemigrations change the new models to the correct name ‘model_name_new’ -> ‘model_name’ test the whole slew of migrations on a staging server take your production site down for a few minutes in order to run all migrations without users interfering   Do this individually for each model that needs to be moved. I wouldn’t suggest doing what the other answer says by changing to integers and back to foreign keys There is a chance that new foreign keys will be different and rows may have different IDs after the migrations and I didn’t want to run any risk of mismatching ids when switching back to foreign keys.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  Another hacky alternative if the data is not big or too complicated, but still important to maintain, is to:   Get data fixtures using manage.py dumpdata Proceed to model changes and migrations properly, without relating the changes Global replace the fixtures from the old model and app names to the new Load data using manage.py loaddata      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to move a model between two Django apps (Django 1.7)",
        "A_Content": "  Copied from my answer at https://stackoverflow.com/a/47392970/8971048  In case you need to move the model and you don't have access to the app anymore (or you don't want the access), you can create a new Operation and consider to create a new model only if the migrated model does not exist.  In this example I am passing 'MyModel' from old_app to myapp.   class MigrateOrCreateTable(migrations.CreateModel):     def __init__(self, source_table, dst_table, *args, **kwargs):         super(MigrateOrCreateTable, self).__init__(*args, **kwargs)         self.source_table = source_table         self.dst_table = dst_table      def database_forwards(self, app_label, schema_editor, from_state, to_state):         table_exists = self.source_table in schema_editor.connection.introspection.table_names()         if table_exists:             with schema_editor.connection.cursor() as cursor:                 cursor.execute(\"RENAME TABLE {} TO {};\".format(self.source_table, self.dst_table))         else:             return super(MigrateOrCreateTable, self).database_forwards(app_label, schema_editor, from_state, to_state)   class Migration(migrations.Migration):      dependencies = [         ('myapp', '0002_some_migration'),     ]      operations = [         MigrateOrCreateTable(             source_table='old_app_mymodel',             dst_table='myapp_mymodel',             name='MyModel',             fields=[                 ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),                 ('name', models.CharField(max_length=18))             ],         ),     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "database",
            "django",
            "schema-migration"
        ],
        "URL": "https://stackoverflow.com/questions/25648393/how-to-move-a-model-between-two-django-apps-django-1-7",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So about a year ago I started a project and like all new developers I didn't really focus too much on the structure, however now I am further along with Django it has started to appear that my project layout mainly my models are horrible in structure.  I have models mainly held in a single app and really most of these models should be in their own individual apps, I did try and resolve this and move them with south however I found it tricky and really difficult due to foreign keys ect.  However due to Django 1.7 and built in support for migrations is there a better way to do this now?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  You can use compileall in the terminal. The following command will go recursively into sub directories and make pyc files for all the python files it finds. The compileall module is part of the python standard library, so you don't need to install anything extra to use it. This works exactly the same way for python2 and python3.  python -m compileall .      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "182",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  It's been a while since I last used Python, but I believe you can use py_compile:  import py_compile py_compile.compile(\"file.py\")      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  You can compile individual files(s) from the command line with:  python -m compileall <file_1>.py <file_n>.py      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  I found several way to compile a python script into bytecode   Using py_compile.compile:  import py_compile py_compile.compile('YourFileName.py')  Using py_compile.main():  It compiles several files at a time.  import py_compile py_compile.main(['File1.py','File2.py','File3.py'])   The list can grow as long as you wish, Alternatively you can obviously pass list of file in main or even you can pass file names in command line args.  Or, if you pass ['-'] in main then it can compile files interactively. Using py_compile in Terminal:  python -m py_compile File1.py File2.py File3.py ...   Or, for Interactive Compilation of files  python -m py_compile - File1.py File2.py File3.py    .    .    .  Using compileall.compile_dir():  import compileall compileall.compile_dir(direname)   It compiles every single python file present in the directory supplied. Using compileall.compile_file():  import compileall compileall.compile_file('YourFileName.py')    Take a look on the links below:  https://docs.python.org/3/library/py_compile.html  https://docs.python.org/3/library/compileall.html     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  I would use compileall. It works nicely both from scripts and from the command line. It's a bit higher level module/tool than the already mentioned py_compile that it also uses internally.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How can I manually generate a .pyc file from a .py file",
        "A_Content": "  To match the original question requirements (source path and destination path) the code should be like that:  import py_compile py_compile.compile(py_filepath, pyc_filepath)   If the input code has errors then the py_compile.PyCompileError exception is raised.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/5607283/how-can-i-manually-generate-a-pyc-file-from-a-py-file",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    For some reason, I can not depend on Python's \"import\" statement to generate .pyc file automatically  Is there a way to implement a function as following?  def py_to_pyc(py_filepath, pyc_filepath):     ...      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to prevent errno 32 broken pipe?",
        "A_Content": "  Your server process has received a SIGPIPE writing to a socket. This usually happens when you write to a socket fully closed on the other (client) side. This might be happening when a client program doesn't wait till all the data from the server is received and simply closes a socket (using close function).   In a C program you would normally try setting to ignore SIGPIPE signal or setting a dummy signal handler for it. In this case a simple error will be returned when writing to a closed socket. In your case a python seems to throw an exception that can be handled as a premature disconnect of the client.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "broken-pipe"
        ],
        "URL": "https://stackoverflow.com/questions/11866792/how-to-prevent-errno-32-broken-pipe",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Currently I am using an app built in python. When I run it in personal computer, it works without problems.   However, when I move it into a production server. It keeps showing me the error attached as below:.   I've done some research and I got the reason that the end user browser stops the connection while the server is still busy sending data.   I wonder why did it happen and what is the root cause that prevents it from running properly in production server, while it works on my personal computer. Any advice is appreciated      Exception happened during processing of request from ('127.0.0.1', 34226) Traceback (most recent call last):   File \"/usr/lib/python2.7/SocketServer.py\", line 284, in _handle_request_noblock     self.process_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 310, in process_request     self.finish_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 323, in finish_request     self.RequestHandlerClass(request, client_address, self)   File \"/usr/lib/python2.7/SocketServer.py\", line 641, in __init__     self.finish()   File \"/usr/lib/python2.7/SocketServer.py\", line 694, in finish     self.wfile.flush()   File \"/usr/lib/python2.7/socket.py\", line 303, in flush     self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to prevent errno 32 broken pipe?",
        "A_Content": "  It depends on how you tested it, and possibly on differences in the TCP stack implementation of the personal computer and the server.  For example, if your sendall always completes immediately (or very quickly) on the personal computer, the connection may simply never have broken during sending. This is very likely if your browser is running on the same machine (since there is no real network latency).    In general, you just need to handle the case where a client disconnects before you're finished, by handling the exception.  Remember that TCP communications are asynchronous, but this is much more obvious on physically remote connections than on local ones, so conditions like this can be hard to reproduce on a local workstation.  Specifically, loopback connections on a single machine are often almost synchronous.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "broken-pipe"
        ],
        "URL": "https://stackoverflow.com/questions/11866792/how-to-prevent-errno-32-broken-pipe",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I am using an app built in python. When I run it in personal computer, it works without problems.   However, when I move it into a production server. It keeps showing me the error attached as below:.   I've done some research and I got the reason that the end user browser stops the connection while the server is still busy sending data.   I wonder why did it happen and what is the root cause that prevents it from running properly in production server, while it works on my personal computer. Any advice is appreciated      Exception happened during processing of request from ('127.0.0.1', 34226) Traceback (most recent call last):   File \"/usr/lib/python2.7/SocketServer.py\", line 284, in _handle_request_noblock     self.process_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 310, in process_request     self.finish_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 323, in finish_request     self.RequestHandlerClass(request, client_address, self)   File \"/usr/lib/python2.7/SocketServer.py\", line 641, in __init__     self.finish()   File \"/usr/lib/python2.7/SocketServer.py\", line 694, in finish     self.wfile.flush()   File \"/usr/lib/python2.7/socket.py\", line 303, in flush     self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to prevent errno 32 broken pipe?",
        "A_Content": "  The broken pipe error usually occurs if your request is blocked or takes too long and after request-side timeout, it'll close the connection and then, when the respond-side (server) tries to write to the socket, it will throw a pipe broken error.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "broken-pipe"
        ],
        "URL": "https://stackoverflow.com/questions/11866792/how-to-prevent-errno-32-broken-pipe",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I am using an app built in python. When I run it in personal computer, it works without problems.   However, when I move it into a production server. It keeps showing me the error attached as below:.   I've done some research and I got the reason that the end user browser stops the connection while the server is still busy sending data.   I wonder why did it happen and what is the root cause that prevents it from running properly in production server, while it works on my personal computer. Any advice is appreciated      Exception happened during processing of request from ('127.0.0.1', 34226) Traceback (most recent call last):   File \"/usr/lib/python2.7/SocketServer.py\", line 284, in _handle_request_noblock     self.process_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 310, in process_request     self.finish_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 323, in finish_request     self.RequestHandlerClass(request, client_address, self)   File \"/usr/lib/python2.7/SocketServer.py\", line 641, in __init__     self.finish()   File \"/usr/lib/python2.7/SocketServer.py\", line 694, in finish     self.wfile.flush()   File \"/usr/lib/python2.7/socket.py\", line 303, in flush     self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to prevent errno 32 broken pipe?",
        "A_Content": "  This might be because you are using two method for inserting data into database and this cause the site to slow down.  def add_subscriber(request, email=None):     if request.method == 'POST':         email = request.POST['email_field']         e = Subscriber.objects.create(email=email).save()  <====          return HttpResponseRedirect('/')     else:         return HttpResponseRedirect('/')   In above function, the error is where arrow is pointing.  The correct implementation is below:  def add_subscriber(request, email=None):     if request.method == 'POST':         email = request.POST['email_field']         e = Subscriber.objects.create(email=email)         return HttpResponseRedirect('/')     else:         return HttpResponseRedirect('/')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "broken-pipe"
        ],
        "URL": "https://stackoverflow.com/questions/11866792/how-to-prevent-errno-32-broken-pipe",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Currently I am using an app built in python. When I run it in personal computer, it works without problems.   However, when I move it into a production server. It keeps showing me the error attached as below:.   I've done some research and I got the reason that the end user browser stops the connection while the server is still busy sending data.   I wonder why did it happen and what is the root cause that prevents it from running properly in production server, while it works on my personal computer. Any advice is appreciated      Exception happened during processing of request from ('127.0.0.1', 34226) Traceback (most recent call last):   File \"/usr/lib/python2.7/SocketServer.py\", line 284, in _handle_request_noblock     self.process_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 310, in process_request     self.finish_request(request, client_address)   File \"/usr/lib/python2.7/SocketServer.py\", line 323, in finish_request     self.RequestHandlerClass(request, client_address, self)   File \"/usr/lib/python2.7/SocketServer.py\", line 641, in __init__     self.finish()   File \"/usr/lib/python2.7/SocketServer.py\", line 694, in finish     self.wfile.flush()   File \"/usr/lib/python2.7/socket.py\", line 303, in flush     self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I package a python application to make it pip-installable?",
        "A_Content": "  Yes, MANIFEST.in and setup.py should be sufficient.  This blog post really has some good information on this topic:  Packaging a Django reusable app  And here's another good, detailed overview that helped me a lot:  Python Packaging User Guide  Especially the tips to get your static files (templates) included are important as this might not be obvious at first.  And yes, you can specify required packages in your setup.py which are automatically fetched when installing your app.  For example:      install_requires = [         'django-profiles',         'django-uni-forms',     ],   Obviously now we have two places where dependencies are defined, but that doesn't necessarily mean that these information are duplicated: setup.py vs requirements.txt   With this setup your package should be installable via pip.    As Pierre noted in the comments, there's now also a relevant section in Django's official documentation: Packaging your app   And then there is this \"completely incomplete\" guide, which really gives a great overview over packaging and uploading a package to PyPI: Sharing Your Labor of Love: PyPI Quick And Dirty     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "dependencies",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/5360873/how-do-i-package-a-python-application-to-make-it-pip-installable",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm writing a django application in my spare time for a footy-tipping competition we're running at work. I figured I'd use this time wisely, and get up to speed on virtualenv, pip, packaging, django 1.3, and how to write an easily redistributable application. So far, so good.  I'm up to the packaging part. A lot of the django apps on GitHub for instance are mostly bundled (roughly) the same way. I'll use django-uni-forms as an example.  An assumption I'm making is that the MANIFEST.in and setup.py are the only required pieces that pip needs to do its job. Is that correct? What other components are necessary if my assumption is wrong?  Are the required packaging files generally generated, or are they crafted by hand? Can dependencies be described and then installed also? My application depends on django-uni-forms, and I have it listed in a requirements.txt file within my app which I used to install the dependency; but is that something that the packaging system can take care of?  What are the steps I need to follow to package my application in such a way that pip will be able to install it and any dependencies?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Running python script inside ipython",
        "A_Content": "  from within the directory of \"my_script.py\" you can simply do:  %run ./my_script.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "path",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11744181/running-python-script-inside-ipython",
        "A_Votes": "72",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to run a python script (not module) from inside ipython without indicating its path? I tried to set PYTHONPATH but it seems to work only for modules.  I would like to execute  %run my_script.py   without being in the directory containing the file.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Running python script inside ipython",
        "A_Content": "  How to run a script in Ipython  import os filepath='C:\\\\Users\\\\User\\\\FolderWithPythonScript'  os.chdir(filepath) %run pyFileInThatFilePath.py   That should do it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "path",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11744181/running-python-script-inside-ipython",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to run a python script (not module) from inside ipython without indicating its path? I tried to set PYTHONPATH but it seems to work only for modules.  I would like to execute  %run my_script.py   without being in the directory containing the file.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Running python script inside ipython",
        "A_Content": "  In python there is no difference between modules and scripts; You can execute both scripts and modules.  The file must be on the pythonpath AFAIK because python must be able to find the file in question.  If python is executed from a directory, then the directory is automatically added to the pythonpath.  Refer to What is the best way to call a Python script from another Python script? for more information about modules vs scripts  There is also a builtin function execfile(filename) that will do what you want     ",
        "Language": "Python",
        "Tags": [
            "python",
            "path",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11744181/running-python-script-inside-ipython",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to run a python script (not module) from inside ipython without indicating its path? I tried to set PYTHONPATH but it seems to work only for modules.  I would like to execute  %run my_script.py   without being in the directory containing the file.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Running python script inside ipython",
        "A_Content": "  The %run magic has a parameter file_finder that it uses to get the full path to the file to execute (see here); as you note, it just looks in the current directory, appending \".py\" if necessary.  There doesn't seem to be a way to specify which file finder to use from the %run magic, but there's nothing to stop you from defining your own magic command that calls into %run with an appropriate file finder.  As a very nasty hack, you could override the default file_finder with your own:  IPython.core.magics.execution.ExecutionMagics.run.im_func.func_defaults[2] = my_file_finder   To be honest, at the rate the IPython API is changing that's as likely to continue to work as defining your own magic is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "path",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/11744181/running-python-script-inside-ipython",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to run a python script (not module) from inside ipython without indicating its path? I tried to set PYTHONPATH but it seems to work only for modules.  I would like to execute  %run my_script.py   without being in the directory containing the file.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  The Pythonic way of summing an array is sum. For other purposes, you can sometimes use some combination of reduce and the operator module, e.g.  def product(xs):     return reduce(operator.mul, xs, 1)   Be aware that reduce is actually a foldl, in Haskell terms. There is no special syntax to perform folds, there's no builtin foldr, and actually using reduce with non-associative operators is considered bad style.  Using higher-order functions is quite pythonic; it makes good use of Python's principle that everything is an object, including functions and classes. You are right that lambdas are frowned upon by some Pythonistas, but mostly because they tend not to be very readable when they get complex.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  Haskell  foldl (+) 0 [1,2,3,4,5]  Python  reduce(lambda a,b: a+b, [1,2,3,4,5], 0)  Obviously, that is a trivial example to illustrate a point. In Python you would just do sum([1,2,3,4,5]) and even Haskell purists would generally prefer sum [1,2,3,4,5].  For non-trivial scenarios when there is no obvious convenience function, the idiomatic pythonic approach is to explicitly write out the for loop and use mutable variable assignment instead of using reduce or a fold.  That is not at all the functional style, but that is the \"pythonic\" way. Python is not designed for functional purists. See how Python favors exceptions for flow control to see how non-functional idiomatic python is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  In Python 3, the reduce has been removed: Release notes. Nevertheless you can use the functools module  import operator, functools def product(xs):     return functools.reduce(operator.mul, xs, 1)   On the other hand, the documentation expresses preference towards for-loop instead of reduce, hence:  def product(xs):     result = 1     for i in xs:         result *= i     return result      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  You can reinvent the wheel as well:  def fold(f, l, a):     \"\"\"     f: the function to apply     l: the list to fold     a: the accumulator, who is also the 'zero' on the first call     \"\"\"      return a if(len(l) == 0) else fold(f, l[1:], f(a, l[0]))  print \"Sum:\", fold(lambda x, y : x+y, [1,2,3,4,5], 0)  print \"Any:\", fold(lambda x, y : x or y, [False, True, False], False)  print \"All:\", fold(lambda x, y : x and y, [False, True, False], True)  # Prove that result can be of a different type of the list's elements print \"Count(x==True):\",  print fold(lambda x, y : x+1 if(y) else x, [False, True, True], 0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  The actual answer to this (reduce) problem is: Just use a loop!  initial_value = 0 for x in the_list:     initial_value += x #or any function.   This will be faster than a reduce and things like PyPy can optimize loops like that.  BTW, the sum case should be solved with the sum function      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the 'pythonic' equivalent to the 'fold' function from functional programming?",
        "A_Content": "  Not really answer to the question, but one-liners for foldl and foldr:  a = [8,3,4]  ## Foldl reduce(lambda x,y: x**y, a) #68719476736  ## Foldr reduce(lambda x,y: y**x, a[::-1]) #14134776518227074636666380005943348126619871175004951664972849610340958208L      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "functional-programming",
            "reduce",
            "fold"
        ],
        "URL": "https://stackoverflow.com/questions/10366374/what-is-the-pythonic-equivalent-to-the-fold-function-from-functional-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the most idiomatic way to achieve something like the following, in Haskell:  foldl (+) 0 [1,2,3,4,5] --> 15   Or its equivalent in Ruby:  [1,2,3,4,5].inject(0) {|m,x| m + x} #> 15   Obviously, Python provides the reduce function, which is an implementation of fold, exactly as above, however, I was told that the 'pythonic' way of programming was to avoid lambda terms and higher-order functions, preferring list-comprehensions where possible. Therefore, is there a preferred way of folding a list, or list-like structure in Python that isn't the reduce function, or is reduce the idiomatic way of achieving this?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  I've been building tools (DMS Software Reengineering Toolkit) to do general purpose program manipulation (with language translation being a special case) since 1995, supported by a strong team of computer scientists.  DMS provides generic parsing, AST building, symbol tables, control and data flow analysis, application of translation rules, regeneration of source text with comments, etc., all parameterized by explicit definitions of computer languages.  The amount of machinery you need to do this well is vast (especially if you want to be able to do this for multiple languages in a general way), and then you need reliable parsers for languages with unreliable definitions (PHP is perfect example of this).  There's nothing wrong with you thinking about building a language-to-language translator or attempting it, but I think you'll find this a much bigger task for real languages than you expect.  We have some 100 man-years invested in just DMS, and another 6-12 months in each \"reliable\" language definition (including the one we painfully built for PHP), much more for nasty languages such as C++.  It will be a \"hell of a learning experience\"; it has been for us.  (You might find the technical Papers section at the above website interesting to jump start that learning).  People often attempt to build some kind of generalized machinery by starting with some piece of technology with which they are familiar, that does a part of the job. (Python ASTs are great example).  The good news, is that part of the job is done.  The bad news is that machinery has a zillion assumptions built into it, most of which you won't discover until you try to wrestle it into doing something else.  At that point you find out the machinery is wired to do what it originally does, and will really, really resist your attempt to make it do something else. (I suspect trying to get the Python AST to model PHP is going to be a lot of fun).  The reason I started to build DMS originally was to build foundations that had very few such assumptions built in.   It has some that give us headaches.  So far, no black holes. (The hardest part of my job over the last 15 years is to try to prevent such assumptions from creeping in).  Lots of folks also make the mistake of assuming that if they can parse (and perhaps get an AST), they are well on the way to doing something complicated.  One of the hard lessons is that you need symbol tables and flow analysis to do good program analysis or transformation.   ASTs are necessary but not sufficient.  This is the reason that Aho&Ullman's compiler book doesn't stop at chapter 2.  (The OP has this right in that he is planning to build additional machinery beyond the AST).  For more on this topic, see Life After Parsing.  The remark about \"I don't need a perfect translation\" is troublesome.  What weak translators do is convert the \"easy\" 80% of the code, leaving the hard 20% to do by hand.  If the application you intend to convert are pretty small, and you only intend to convert it once well, then that 20% is OK. If you want to convert many applications (or even the same one with minor changes over time), this is not nice.  If you attempt to convert 100K SLOC then 20% is 20,000 original lines of code that are hard to translate, understand and modify in the context of another 80,000 lines of translated program you already don't understand.  That takes a huge amount of effort.  At the million line level, this is simply impossible in practice.  (Amazingly there are people that distrust automated tools and insist on translating million line systems by hand; that's even harder and they normally find out painfully with long time delays, high costs and often outright failure.)  What you have to shoot for to translate large-scale systems is high nineties percentage  conversion rates, or it is likely that you can't complete the manual part of the translation activity.  Another key consideration is size of code to be translated.  It takes a lot of energy to build a working, robust translator, even with good tools.  While it seems sexy and cool to build a translator instead of simply doing a manual conversion, for small code bases (e.g., up to about 100K SLOC in our experience) the economics simply don't justify it. Nobody likes this answer, but if you really have to translate just 10K SLOC of code, you are probably better off just biting the bullet and doing it.  And yes, that's painful.  I consider our tools to be extremely good (but then, I'm pretty biased).   And it is still very hard to build a good translator; it takes us about 1.5-2 man-years and we know how to use our tools.  The difference is that with this much machinery, we succeed considerably more often than we fail.     ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  My answer will address the specific task of parsing Python in order to translate it to another language, and not the higher-level aspects which Ira addressed well in his answer.  In short: do not use the parser module, there's an easier way.  The ast module, available since Python 2.6 is much more suitable for your needs, since it gives you a ready-made AST to work with. I've written an article on this last year, but in short, use the parse method of ast to parse Python source code into an AST. The parser module will give you a parse tree, not an AST. Be wary of the difference.   Now, since Python's ASTs are quite detailed, given an AST the front-end job isn't terribly hard. I suppose you can have a simple prototype for some parts of the functionality ready quite quickly. However, getting to a complete solution will take more time, mainly because the semantics of the languages are different. A simple subset of the language (functions, basic types and so on) can be readily translated, but once you get into the more complex layers, you'll need heavy machinery to emulate one language's core in another. For example consider Python's generators and list comprehensions which don't exist in PHP (to my best knowledge, which is admittedly poor when PHP is involved).  To give you one final tip, consider the 2to3 tool created by the Python devs to translate Python 2 code to Python 3 code. Front-end-wise, it has most of the elements you need to translate Python to something. However, since the cores of Python 2 and 3 are similar, no emulation machinery is required there.     ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  Writing a translator isn't impossible, especially considering that Joel's Intern did it over a summer.  If you want to do one language, it's easy. If you want to do more, it's a little more difficult, but not too much. The hardest part is that, while any turing complete language can do what another turing complete language does, built-in data types can change what a language does phenomenally.  For instance:  word = 'This is not a word' print word[::-2]   takes a lot of C++ code to duplicate (ok, well you can do it fairly short with some looping constructs, but still).  That's a bit of an aside, I guess.   Have you ever written a tokenizer/parser based on a language grammar? You'll probably want to learn how to do that if you haven't, because that's the main part of this project. What I would do is come up with a basic Turing complete syntax - something fairly similar to Python  bytecode. Then you create a lexer/parser that takes a language grammar (perhaps using BNF), and based on the grammar, compiles the language into your intermediate language. Then what you'll want to do is do the reverse - create a parser from your language into target languages based on the grammar.  The most obvious problem I see is that at first you'll probably create horribly inefficient code, especially in more powerful* languages like Python.  But if you do it this way then you'll probably be able to figure out ways to optimize the output as you go along. To summarize:   read provided grammar compile program into intermediate (but also Turing complete) syntax compile intermediate program into final language (based on provided grammar) ...? Profit!(?)     *by powerful I mean that this takes 4 lines:  myinput = raw_input(\"Enter something: \") print myinput.replace('a', 'A') print sum(ord(c) for c in myinput) print myinput[::-1]   Show me another language that can do something like that in 4 lines, and I'll show you a language that's as powerful as Python.     ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  There are a couple answers telling you not to bother. Well, how helpful is that? You want to learn? You can learn. This is compilation. It just so happens that your target language isn't machine code, but another high-level language. This is done all the time.  There's a relatively easy way to get started. First, go get http://sourceforge.net/projects/lime-php/ (if you want to work in PHP) or some such and go through the example code. Next, you can write a lexical analyzer using a sequence of regular expressions and feed tokens to the parser you generate. Your semantic actions can either output code directly in another language or build up some data structure (think objects, man) that you can massage and traverse to generate output code.  You're lucky with PHP and Python because in many respects they are the same language as each other, but with different syntax. The hard part is getting over the semantic differences between the grammar forms and data structures. For example, Python has lists and dictionaries, while PHP only has assoc arrays.  The \"learner\" approach is to build something that works OK for a restricted subset of the language (such as only print statements, simple math, and variable assignment), and then progressively remove limitations. That's basically what the \"big\" guys in the field all did.  Oh, and since you don't have static types in Python, it might be best to write and rely on PHP functions like \"python_add\" which adds numbers, strings, or objects according to the way Python does it.  Obviously, this can get much bigger if you let it.     ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  I will second @EliBendersky point of view regarding using ast.parse instead of parser (which I did not know about before). I also warmly recommend you to review his blog. I used ast.parse to do Python->JavaScript translator (@https://bitbucket.org/amirouche/pythonium). I've come up with Pythonium design by somewhat reviewing other implementations and trying them on my own. I forked Pythonium from https://github.com/PythonJS/PythonJS which I also started, It's actually a complete rewrite . The overall design is inspired from PyPy and http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-89-1.pdf paper.  Everything I tried, from beginning to the best solution, even if it looks like Pythonium marketing it really isn't (don't hesitate to tell me if something doesn't seem correct to the netiquette):   Implement Python semantic in Plain Old JavaScript using prototype inheritance: AFAIK it's impossible to implement Python multiple inheritance using JS prototype object system. I did try to do it using other tricks later (cf. getattribute). As far as I know there is no implementation of Python multiple inheritance in JavaScript, the best that exists is Single inhertance + mixins and I'm not sure they handle diamond inheritance. Kind of similar to Skulpt but without google clojure.  I tried with Google clojure, just like Skulpt (compiler) instead of actually reading Skulpt code #fail. Anyway because of JS prototype based object system still impossible. Creating binding was very very difficult, you need to write JavaScript and a lot of boilerplate code (cf. https://github.com/skulpt/skulpt/issues/50 where I am the ghost). At that time there was no clear way to integrate the binding in the build system. I think that Skulpt is a library and you just have to include your .py files in the html to be executed, no compilation phase required to be done by the developer. Tried pyjaco (compiler) but creating bindings (calling Javascript code from Python code) was very difficult, there was too much boilerplate code to create every time. Now I think pyjaco is the one that more near Pythonium. pyjaco is written in Python (ast.parse too) but a lot is written in JavaScript and it use prototype inheritance.   I never actually succeed at running Pyjamas #fail and never tried to read the code #fail again. But in my mind PyJamas was doing API->API tranlation (or framework to framework) and not Python to JavaScript translation. The JavaScript framework consume data that is already in the page or data from the server. Python code is only \"plumbing\". After that I discovered  that pyjamas was actually a real python->js translator.   Still I think it's possible to do API->API (or framework->framework) translation and that's basicly what I do in Pythonium but at lower level. Probably Pyjamas use the same algorithm as Pythonium...  Then I discovered brython fully written in Javascript like Skulpt, no need for compilation and lot of fluff... but written in JavaScript.  Since the initial line written in the course of this project, I knew about PyPy, even the JavaScript backend for PyPy. Yep, you can, if you find it, directly generate a Python interpreter in JavaScript from PyPy. People say, it was a disaster. I read no where why. But I think the reason is that the intermediate language they use to implement the interpreter, RPython, is a subset of Python tailored to be translated to C (and maybe asm). Ira Baxter says you always make assumptions when you build something and probably you fine tune it to be the best at what it's meant to do in the case of PyPy: Python->C translation. Those assumptions might not be relevant in another context worse they can infere overhead otherwise said direct translation will most likely always be better.  Having the interpreter written in Python sounded like a (very) good idea. But I was more interested in a compiler for performance reasons also it's actually more easy to compile Python to JavaScript than interpret it.  I started PythonJS with the idea of putting together a subset of Python that I could easily translate to JavaScript. At first I didn't even bother to implement OO system because of past experience. The subset of Python that I achieved to translate to JavaScript are:   function with full parameters semantic both in definition and calling. This is the part I am most proud of. while/if/elif/else Python types were converted to JavaScript types (there is no python types of any kind) for could iterate over Javascript arrays only (for a in array) Transparent access to JavaScript: if you write Array in the Python code it will be translated to Array in javascript. This is the biggest achievement in terms of usability over its competitors. You can pass function defined in Python source to javascript functions. Default arguments will be taken into account. It add has special function called new which is translated to JavaScript new e.g: new(Python)(1, 2, spam, \"egg\") is translated to \"new Python(1, 2, spam, \"egg\"). \"var\" are automatically handled by the translator. (very nice finding from Brett (PythonJS contributor). global keyword closures lambdas list comprehensions imports are supported via requirejs single class inheritance + mixin via classyjs   This seems like a lot but actually very narrow compared to full blown semantic of Python. It's really JavaScript with a Python syntax.   The generated JS is perfect ie. there is no overhead, it can not be improved in terms of performance by further editing it. If you can improve the generated code, you can do it from the Python source file too. Also, the compiler did not rely on any JS tricks that you can find in .js written by http://superherojs.com/, so it's very readable.  The direct descendant of this part of PythonJS is the Pythonium Veloce mode. The full implementation can be found @ https://bitbucket.org/amirouche/pythonium/src/33898da731ee2d768ced392f1c369afd746c25d7/pythonium/veloce/veloce.py?at=master 793 SLOC + around 100 SLOC of shared code with the other translator.  An adapted version of pystones.py can be translated in Veloce mode cf. https://bitbucket.org/amirouche/pythonium/src/33898da731ee2d768ced392f1c369afd746c25d7/pystone/?at=master  After having setup basic Python->JavaScript translation I choosed another path to translate full Python to JavaScript. The way of glib doing object oriented class based code except the target language is JS so you have access to arrays, map-like objects and many other tricks and all that part was written in Python. IIRC there is no javascript code written by in Pythonium translator. Getting single inheritance is not difficult here are the difficult parts making Pythonium fully compliant with Python:   spam.egg in Python is always translated to getattribute(spam, \"egg\") I did not profile this in particular but I think that where it loose a lot of time and I'm not sure I can improve upon it with asm.js or anything else. method resolution order: even with the algorithm written in Python, translating it to Python Veloce compatible code was a big endeavour. getattributre: the actual getattribute resolution algorithm is kind of tricky and it still doesn't support data descriptors metaclass class based: I know where to plug the code, but still... last bu not least: some_callable(...) is always transalted to \"call(some_callable)\". AFAIK the translator doesn't use inference at all, so every time you do a call you need to check which kind of object it is to call it they way it's meant to be called.   This part is factored in https://bitbucket.org/amirouche/pythonium/src/33898da731ee2d768ced392f1c369afd746c25d7/pythonium/compliant/runtime.py?at=master It's written in Python compatible with Python Veloce.  The actual compliant translator https://bitbucket.org/amirouche/pythonium/src/33898da731ee2d768ced392f1c369afd746c25d7/pythonium/compliant/compliant.py?at=master doesn't generate JavaScript code directly and most importantly doesn't do ast->ast transformation. I tried the ast->ast thing and ast even if nicer than cst is not nice to work with even with ast.NodeTransformer and more importantly I don't need to do ast->ast.  Doing python ast to python ast in my case at least would maybe be a performance improvement since I sometime inspect the content of a block before generating the code associated with it, for instance:   var/global: to be able to var something I must know what I need to and not to var. Instead of generating a block tracking which variable are created in a given block and inserting it on top of the generated function block I just look for revelant variable assignation when I enter the block before actually visiting the child node to generate the associated code. yield, generators have, as of yet, a special syntax in JS, so I need to know which Python function is a generator when I want to write the \"var my_generator = function\"   So I don't really visit each node once for each phase of the translation.  The overall process can be described as:  Python source code -> Python ast -> Python source code compatible with Veloce mode -> Python ast -> JavaScript source code   Python builtins are written in Python code (!), IIRC there is a few restrictions related to bootstraping types, but you have access to everything that can translate Pythonium in compliant mode. Have a look at https://bitbucket.org/amirouche/pythonium/src/33898da731ee2d768ced392f1c369afd746c25d7/pythonium/compliant/builtins/?at=master  Reading JS code generated from pythonium compliant can be understood but source maps will greatly help.  The valuable advice I can give you in the light of this experience are kind old farts:   extensively review the subject both in literature and existing projects closed source or free. When I reviewed the different existing projects I should have given it way more time and motivation. ask questions! If I knew beforehand that PyPy backend was useless because of the overhead due to C/Javascript semantic mismatch. I would maybe had Pythonium idea way before 6 month ago maybe 3 years ago. know what you want to do, have a target. For this project I had different objectives: pratice a bit a javascript, learn more of Python and be able to write Python code that would run in the browser (more and that below). failure is experience a small step is a step start small dream big do demos iterate   With Python Veloce mode only, I'm very happy! But along the way I discovered that what I was really looking for was liberating me and others from Javascript but more importantly being able to create in a comfortable way. This lead me to Scheme, DSL, Models and eventually domain specific models (cf. http://dsmforum.org/).  About what Ira Baxter response:  The estimations are not helpful at all. I took me more or less 6 month of free time for both PythonJS and Pythonium. So I can expect more from full time 6 month. I think we all know what 100 man-year in an enterprise context can mean and not mean at all...  When someone says something is hard or more often impossible, I answer that \"it only takes time to find a solution for a problem that is impossible\" otherwise said nothing is impossible except if it's proven impossible in this case a math proof...  If it's not proven impossible then it leaves room for imagination:   finding a proof proving it's impossible   and   If it is impossible there may be an \"inferior\" problem that can have a solution.   or   if it's not impossible, finding a solution    It's not just optimistic thinking. When I started Python->Javascript everybody was saying it was impossible. PyPy impossible. Metaclasses too hard. etc... I think that the only revolution that brings PyPy over Scheme->C paper (which is 25 years old) is some automatic JIT generation (based hints written in the RPython interpreter I think).  Most people that say that a thing is \"hard\" or \"impossible\" don't provide the reasons. C++ is hard to parse? I know that, still they are (free)  C++ parser. Evil is in the detail? I know that. Saying it's impossible alone is not helpful, It's even worse than \"not helpful\" it's discouraging, and some people mean to discourage others. I heard about this question via https://stackoverflow.com/questions/22621164/how-to-automatically-generate-a-parser-code-to-code-translator-from-a-corpus.  What would be perfection for you? That's how you define next goal and maybe reach the overall goal.     I am more interested in knowing what kinds of patterns I could enforce   on the code to make it easier to translate (ie: IoC, SOA ?) the code   than how to do the translation.   I see no patterns that can not be translated from one language to another language at least in a less than perfect way. Since language to language translation is possible, you'd better aim for this first. Since, I think according to http://en.wikipedia.org/wiki/Graph_isomorphism_problem, translation between two computer languages is a tree or DAG isomorphism. Even if we already know that they are both turing complete, so...  Framework->Framework which I better visualize as API->API translation might still be something that you might keep in mind as a way to improve the generated code. E.g: Prolog as very specific syntax but still you can do Prolog like computation by describing the same graph in Python... If I was to implement a Prolog to Python translator I wouldn't implement unification in Python but in a C library and come up with a \"Python syntax\" that is very readable for a Pythonist. In the end, syntax is only \"painting\" for which we give a meaning (that's why I started scheme). Evil is in the detail of the language and I'm not talking about the syntax. The concepts that are used in the language getattribute hook (you can live without it) but required VM features like tail-recursion optimisation can be difficult to deal with. You don't care if the initial program doesn't use tail recursion and even if there is no tail recursion in the target language you can emulate it using greenlets/event loop.   For target and source languages, look for:   Big and specific ideas Tiny and common shared ideas   From this will emerge:   Things that are easy to translate Things that are difficult to translate   You will also probably be able to know what will be translated to fast and slow code.  There is also the question of the stdlib or any library but there is no clear answer, it depends of your goals.  Idiomatic code or readable generated code have also solutions...  Targeting a platform like PHP is much more easy than targeting browsers since you can provide C-implementation of slow and/or critical path.  Given you first project is translating Python to PHP, at least for the PHP3 subset I know of, customising veloce.py is your best bet. If you can implement veloce.py for PHP then probably you will be able to run the compliant mode... Also if you can translate PHP to the subset of PHP you can generate with php_veloce.py it means that you can translate PHP to the subset of Python that veloce.py can consume which would mean that you can translate PHP to Javascript. Just saying...  You can also have a look at those libraries:   https://bitbucket.org/logilab/astroid https://bitbucket.org/logilab/pylint-brain   Also you might be interested by this blog post (and comments): https://www.rfk.id.au/blog/entry/pypy-js-poc-jit/   This Google Tech Talk from Ira Baxter is interesting https://www.youtube.com/watch?v=C-_dw9iEzhA      ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What kinds of patterns could I enforce on the code to make it easier to translate to another programming language? [closed]",
        "A_Content": "  You could take a look at the Vala compiler, which translates Vala (a C#-like language) into C.     ",
        "Language": "Python",
        "Tags": [
            "php",
            "python",
            "compiler-construction",
            "coding-style",
            "abstract-syntax-tree"
        ],
        "URL": "https://stackoverflow.com/questions/3455456/what-kinds-of-patterns-could-i-enforce-on-the-code-to-make-it-easier-to-translat",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am setting out to do a side project that has the goal of translating code from one programming language to another. The languages I am starting with are PHP and Python (Python to PHP should be easier to start with), but ideally I would be able to add other languages with (relative) ease. The plan is:   This is geared towards web development. The original and target code will be be sitting on top of frameworks (which I will also have to write). These frameworks will embrace an MVC design pattern and follow strict coding conventions. This should make translation somewhat easier.  I am also looking at IOC and dependency injection, as they might make the translation process easier and less error prone. I'll make use of Python's parser module, which lets me fiddle with the Abstract Syntax Tree. Apparently the closest I can get with PHP is token_get_all(), which is a start. From then on I can build the AST, symbol tables and control flow.    Then I believe I can start outputting code. I don't need a perfect translation. I'll still have to review the generated code and fix problems. Ideally the translator should flag problematic translations.  Before you ask \"What the hell is the point of this?\" The answer is... It'll be an interesting learning experience. If you have any insights on how to make this less daunting, please let me know.    EDIT:  I am more interested in knowing what kinds of patterns I could enforce on the code to make it easier to translate (ie: IoC, SOA ?) the code than how to do the translation.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Mock vs MagicMock",
        "A_Content": "  What is the reason for plain Mock existing?  Mock's author, Michael Foord, addressed a very similar question at Pycon 2011 (31:00):     Q: Why was MagicMock made a separate thing rather than just folding the ability into the default mock object?      A: One reasonable answer is that the way MagicMock works is that it preconfigures all these protocol methods by creating new Mocks and   setting them, so if every new mock created a bunch of new mocks and   set those as protocol methods and then all of those protocol methods   created a bunch more mocks and set them on their protocol methods,   you've got infinite recursion...      What if you want accessing your mock as a container object to be an   error -- you don't want that to work? If every mock has automatically   got every protocol method, then it becomes much more difficult to do   that. And also, MagicMock does some of this preconfiguring for you,   setting return values that might not be appropriate, so I thought it   would be better to have this convenience one that has everything   preconfigured and available for you, but you can also take a ordinary   mock object and just configure the magic methods you want to exist...      The simple answer is: just use MagicMock everywhere if that's the   behavior you want.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/17181687/mock-vs-magicmock",
        "A_Votes": "74",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My understanding is that MagicMock is a superset of Mock that automatically does \"magic methods\" thus seamlessly providing support for lists, iterations and so on... Then what is the reason for plain Mock existing? Isn't that just a stripped down version of MagicMock that can be practically ignored? Does Mock class know any tricks that are not available in MagicMock?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Mock vs MagicMock",
        "A_Content": "  With Mock you can mock magic methods but you have to define them. MagicMock has \"default implementations of most of the magic methods.\".  If you don't need to test any magic methods, Mock is adequate and doesn't bring a lot of extraneous things into your tests. If you need to test a lot of magic methods MagicMock will save you some time.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/17181687/mock-vs-magicmock",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My understanding is that MagicMock is a superset of Mock that automatically does \"magic methods\" thus seamlessly providing support for lists, iterations and so on... Then what is the reason for plain Mock existing? Isn't that just a stripped down version of MagicMock that can be practically ignored? Does Mock class know any tricks that are not available in MagicMock?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Mock vs MagicMock",
        "A_Content": "  To begin with, MagicMock is a subclass of Mock.  class MagicMock(MagicMixin, Mock)   As a result, MagicMock provides everything that Mock provides and more.  Rather than thinking of Mock as being a stripped down version of MagicMock, think of MagicMock as an extended version of Mock.  This should address your questions about why Mock exists and what does Mock provide on top of MagicMock.  Secondly, MagicMock provides default implementations of many/most magic methods, whereas Mock doesn't.  See here for more information on the magic methods provided.  Some examples of provided magic methods:  >>> int(Mock()) TypeError: int() argument must be a string or a number, not 'Mock' >>> int(MagicMock()) 1 >>> len(Mock()) TypeError: object of type 'Mock' has no len() >>> len(MagicMock()) 0   And these which may not be as intuitive (at least not intuitive to me):  >>> with MagicMock(): ...     print 'hello world' ... hello world >>> MagicMock()[1] <MagicMock name='mock.__getitem__()' id='4385349968'>   You can \"see\" the methods added to MagicMock as those methods are invoked for the first time:  >>> magic1 = MagicMock() >>> dir(magic1) ['assert_any_call', 'assert_called_once_with', ...] >>> int(magic1) 1 >>> dir(magic1) ['__int__', 'assert_any_call', 'assert_called_once_with', ...] >>> len(magic1) 0 >>> dir(magic1) ['__int__', '__len__', 'assert_any_call', 'assert_called_once_with', ...]   So, why not use MagicMock all the time?  The question back to you is: Are you okay with the default magic method implementations?  For example, is it okay for mocked_object[1] to not error?  Are you okay with any unintended consequences due to the magic method implementations being already there?  If the answer to these questions is a yes, then go ahead and use MagicMock.  Otherwise, stick to Mock.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/17181687/mock-vs-magicmock",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My understanding is that MagicMock is a superset of Mock that automatically does \"magic methods\" thus seamlessly providing support for lists, iterations and so on... Then what is the reason for plain Mock existing? Isn't that just a stripped down version of MagicMock that can be practically ignored? Does Mock class know any tricks that are not available in MagicMock?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Mock vs MagicMock",
        "A_Content": "  This is what python's official documentation says:     In most of these examples the Mock and MagicMock classes are interchangeable. As the MagicMock is the more capable class it makes a sensible one to use by default.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mocking"
        ],
        "URL": "https://stackoverflow.com/questions/17181687/mock-vs-magicmock",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    My understanding is that MagicMock is a superset of Mock that automatically does \"magic methods\" thus seamlessly providing support for lists, iterations and so on... Then what is the reason for plain Mock existing? Isn't that just a stripped down version of MagicMock that can be practically ignored? Does Mock class know any tricks that are not available in MagicMock?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  As tom suggested in the comment above, deleting the files:   fontList.cache fontList.py3k.cache  tex.cache    solve the problem.  In my case the files were under:  `~/.matplotlib`   EDITED  A couple of days ago the message appeared again, I deleted the files in the locations mention above without any success. I found that as suggested here by T Mudau there's an extra location with text cache files is: ~/.cache/fontconfig     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "111",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  Confirmed Hugo's approach works for Ubuntu 14.04 LTS/matplotlib 1.5.1:   deleted ~/.cache/matplotlib/fontList.cache ran code, again the warning was issued (assumption: is rebuilding the cache correctly) ran code again, no more warning (finally)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  On OSX Yosemite (version 10.10.15), the following worked for me:   remove the cache files from this directory as well: ~/.cache/fontconfig (as per tom's suggestion) rm -rvf ~/.cache/fontconfig/*   also removed .cache files in ~/.matplotlib (as per Hugo's suggestion) rm -rvf ~/.matplotlib/*      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  I ran the python code using sudo just once, and it resolved the warning for me.  Now it runs faster. Running without sudo gives no warning at all.   Cheers     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  I ran the python code w. sudo and it cured it...my guess was that there wasn't permission to write that table... good luck!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  HI you must find this file : font_manager.py in my case : C:\\Users\\gustavo\\Anaconda3\\Lib\\site-packages\\matplotlib\\ font_manager.py  and FIND def win32InstalledFonts(directory=None, fontext='ttf') and replace by :  def win32InstalledFonts(directory=None, fontext='ttf'):     \"\"\"     Search for fonts in the specified font directory, or use the     system directories if none given.  A list of TrueType font     filenames are returned by default, or AFM fonts if fontext ==     'afm'.     \"\"\"  from six.moves import winreg if directory is None:     directory = win32FontDirectory()  fontext = get_fontext_synonyms(fontext)  key, items = None, {} for fontdir in MSFontDirectories:     try:         local = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, fontdir)     except OSError:         continue      if not local:         return list_fonts(directory, fontext)     try:         for j in range(winreg.QueryInfoKey(local)[1]):             try:                 key, direc, any = winreg.EnumValue(local, j)                 if not is_string_like(direc):                     continue                 if not os.path.dirname(direc):                     direc = os.path.join(directory, direc)                     direc = direc.split('\\0', 1)[0]                  if os.path.splitext(direc)[1][1:] in fontext:                     items[direc] = 1             except EnvironmentError:                 continue             except WindowsError:                 continue             except MemoryError:                 continue         return list(six.iterkeys(items))     finally:         winreg.CloseKey(local) return None      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  This worked for me on Ubuntu 16.04 LST with Python 3.5.2 | Anaconda 4.2.0 (64-bit). I deleted all of the files in ~/.cache/matplotlib/.  sudo rm -r fontList.py3k.cache tex.cache    At first I thought it wouldn't work, because I got the warning afterward. But after the cache files were rebuilt the warning went away. So, close your file, and reopen again(open again), it has no warning.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "matplotlib taking time when being imported",
        "A_Content": "  This worked for me:  sudo apt-get install libfreetype6-dev libxft-dev      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I just upgraded to the latest stable release of matplotlib (1.5.1) and everytime I import matplotlib I get this message:  /usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.   warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')   ... which always stalls for a few seconds.  Is this the expected behaviour? Was it the same also before, but just without the printed message?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to write header row with csv.DictWriter?",
        "A_Content": "  Edit: In 2.7 / 3.2 there is a new writeheader() method. Also, John Machin's answer provides a simpler method of writing the header row. Simple example of using the writeheader() method now available in 2.7 / 3.2:  from collections import OrderedDict ordered_fieldnames = OrderedDict([('field1',None),('field2',None)]) with open(outfile,'wb') as fou:     dw = csv.DictWriter(fou, delimiter='\\t', fieldnames=ordered_fieldnames)     dw.writeheader()     # continue on to write data     Instantiating DictWriter requires a fieldnames argument. From the documentation:       The fieldnames parameter identifies   the order in which values in the   dictionary passed to the writerow()   method are written to the csvfile.   Put another way:  The Fieldnames argument is required because Python dicts are inherently unordered. Below is an example of how you'd write the header and data to a file. Note: with statement was added in 2.6. If using 2.5: from __future__ import with_statement  with open(infile,'rb') as fin:     dr = csv.DictReader(fin, delimiter='\\t')  # dr.fieldnames contains values from first row of `f`. with open(outfile,'wb') as fou:     dw = csv.DictWriter(fou, delimiter='\\t', fieldnames=dr.fieldnames)     headers = {}      for n in dw.fieldnames:         headers[n] = n     dw.writerow(headers)     for row in dr:         dw.writerow(row)   As @FM mentions in a comment, you can condense header-writing to a one-liner, e.g.:  with open(outfile,'wb') as fou:     dw = csv.DictWriter(fou, delimiter='\\t', fieldnames=dr.fieldnames)     dw.writerow(dict((fn,fn) for fn in dr.fieldnames))     for row in dr:         dw.writerow(row)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "csv"
        ],
        "URL": "https://stackoverflow.com/questions/2982023/how-to-write-header-row-with-csv-dictwriter",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Assume I have a csv.DictReader object and I want to write it out as a CSV file. How can I do this?  I know that I can write the rows of data like this:  dr = csv.DictReader(open(f), delimiter='\\t') # process my dr object # ... # write out object output = csv.DictWriter(open(f2, 'w'), delimiter='\\t') for item in dr:     output.writerow(item)   But how can I include the fieldnames?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to write header row with csv.DictWriter?",
        "A_Content": "  A few options:  (1) Laboriously make an identity-mapping (i.e. do-nothing) dict out of your fieldnames so that csv.DictWriter can convert it back to a list and pass it to a csv.writer instance.   (2) The documentation mentions \"the underlying writer instance\" ... so just use it (example at the end).  dw.writer.writerow(dw.fieldnames)   (3) Avoid the csv.Dictwriter overhead and do it yourself with csv.writer  Writing data:  w.writerow([d[k] for k in fieldnames])   or  w.writerow([d.get(k, restval) for k in fieldnames])   Instead of the extrasaction \"functionality\", I'd prefer to code it myself; that way you can report ALL \"extras\" with the keys and values, not just the first extra key. What is a real nuisance with DictWriter is that if you've verified the keys yourself as each dict was being built, you need to remember to use extrasaction='ignore' otherwise it's going to SLOWLY (fieldnames is a list) repeat the check:  wrong_fields = [k for k in rowdict if k not in self.fieldnames]   ============  >>> f = open('csvtest.csv', 'wb') >>> import csv >>> fns = 'foo bar zot'.split() >>> dw = csv.DictWriter(f, fns, restval='Huh?') # dw.writefieldnames(fns) -- no such animal >>> dw.writerow(fns) # no such luck, it can't imagine what to do with a list Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"C:\\python26\\lib\\csv.py\", line 144, in writerow     return self.writer.writerow(self._dict_to_list(rowdict))   File \"C:\\python26\\lib\\csv.py\", line 141, in _dict_to_list     return [rowdict.get(key, self.restval) for key in self.fieldnames] AttributeError: 'list' object has no attribute 'get' >>> dir(dw) ['__doc__', '__init__', '__module__', '_dict_to_list', 'extrasaction', 'fieldnam es', 'restval', 'writer', 'writerow', 'writerows'] # eureka >>> dw.writer.writerow(dw.fieldnames) >>> dw.writerow({'foo':'oof'}) >>> f.close() >>> open('csvtest.csv', 'rb').read() 'foo,bar,zot\\r\\noof,Huh?,Huh?\\r\\n' >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "csv"
        ],
        "URL": "https://stackoverflow.com/questions/2982023/how-to-write-header-row-with-csv-dictwriter",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume I have a csv.DictReader object and I want to write it out as a CSV file. How can I do this?  I know that I can write the rows of data like this:  dr = csv.DictReader(open(f), delimiter='\\t') # process my dr object # ... # write out object output = csv.DictWriter(open(f2, 'w'), delimiter='\\t') for item in dr:     output.writerow(item)   But how can I include the fieldnames?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to write header row with csv.DictWriter?",
        "A_Content": "  Another way to do this would be to add before adding lines in your output, the following line :  output.writerow(dict(zip(dr.fieldnames, dr.fieldnames)))   The zip would return a list of doublet containing the same value. This list could be used to initiate a dictionary.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "csv"
        ],
        "URL": "https://stackoverflow.com/questions/2982023/how-to-write-header-row-with-csv-dictwriter",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Assume I have a csv.DictReader object and I want to write it out as a CSV file. How can I do this?  I know that I can write the rows of data like this:  dr = csv.DictReader(open(f), delimiter='\\t') # process my dr object # ... # write out object output = csv.DictWriter(open(f2, 'w'), delimiter='\\t') for item in dr:     output.writerow(item)   But how can I include the fieldnames?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  The simple answer to your question: no, there is no simple way.  There are a whole lot of work-arounds.  There really shouldn't be a simple way, because of what generators are: a way to output a sequence of values without holding the sequence in memory.  So there's no backward traversal.  You could write a has_next function or maybe even slap it on to a generator as a method with a fancy decorator if you wanted to.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Suggestion:  def peek(iterable):     try:         first = next(iterable)     except StopIteration:         return None     return first, itertools.chain([first], iterable)   Usage:  res = peek(mysequence) if res is None:     # sequence is empty.  Do stuff. else:     first, mysequence = res     # Do something with first, maybe?     # Then iterate over the sequence:     for element in mysequence:         # etc.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  A simple way is to use the optional parameter for next() which is used if the generator is exhausted (or empty). For example:   iterable = some_generator()  _exhausted = object()  if next(iterable, _exhausted) == _exhausted:     print('generator is empty')   Edit: Corrected the problem pointed out in mehtunguh's comment.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  The best approach, IMHO, would be to avoid a special test. Most times, use of a generator is the test:  thing_generated = False  # Nothing is lost here. if nothing is generated,  # the for block is not executed. Often, that's the only check # you need to do. This can be done in the course of doing # the work you wanted to do anyway on the generated output. for thing in my_generator():     thing_generated = True     do_work(thing)   If that's not good enough, you can still perform an explicit test. At this point, thing will contain the last value generated. If nothing was generated, it will be undefined - unless you've already defined the variable. You could check the value of thing, but that's a bit unreliable. Instead, just set a flag within the block and check it afterward:  if not thing_generated:     print \"Avast, ye scurvy dog!\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  I hate to offer a second solution, especially one that I would not use myself, but, if you absolutely had to do this and to not consume the generator, as in other answers:  def do_something_with_item(item):     print item  empty_marker = object()  try:      first_item = my_generator.next()      except StopIteration:      print 'The generator was empty'      first_item = empty_marker  if first_item is not empty_marker:     do_something_with_item(first_item)     for item in my_generator:         do_something_with_item(item)   Now I really don't like this solution, because I believe that this is not how generators are to be used.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  next(generator, None) is not None  Or replace None but whatever value you know it's not in your generator.  Edit: Yes, this will skip 1 item in the generator. Often, however, I check whether a generator is empty only for validation purposes, then don't really use it. Or otherwise I do something like:  def foo(self):     if next(self.my_generator(), None) is None:         raise Exception(\"Not initiated\")      for x in self.my_generator():         ...   That is, this works if your generator comes from a function, as in generator().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Sorry for the obvious approach, but the best way would be to do:  for item in my_generator:      print item   Now you have detected that the generator is empty while you are using it. Of course, item will never be displayed if the generator is empty.  This may not exactly fit in with your code, but this is what the idiom of the generator is for: iterating, so perhaps you might change your approach slightly, or not use generators at all.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  I realize that this post is 5 years old at this point, but I found it while looking for an idiomatic way of doing this, and did not see my solution posted.  So for posterity:  import itertools  def get_generator():     \"\"\"     Returns (bool, generator) where bool is true iff the generator is not empty.     \"\"\"     gen = (i for i in [0, 1, 2, 3, 4])     a, b = itertools.tee(gen)     try:         a.next()     except StopIteration:         return (False, b)     return (True, b)   Of course, as I'm sure many commentators will point out, this is hacky and only works at all in certain limited situations (where the generators are side-effect free, for example).  YMMV.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  All you need to do to see if a generator is empty is to try to get the next result. Of course if you're not ready to use that result then you have to store it to return it again later.  Here's a wrapper class that can be added to an existing iterator to add an __nonzero__ test, so you can see if the generator is empty with a simple if. It can probably also be turned into a decorator.  class GenWrapper:     def __init__(self, iter):         self.source = iter         self.stored = False      def __iter__(self):         return self      def __nonzero__(self):         if self.stored:             return True         try:             self.value = next(self.source)             self.stored = True         except StopIteration:             return False         return True      def __next__(self):  # use \"next\" (without underscores) for Python 2.x         if self.stored:             self.stored = False             return self.value         return next(self.source)   Here's how you'd use it:  with open(filename, 'r') as f:     f = GenWrapper(f)     if f:         print 'Not empty'     else:         print 'Empty'   Note that you can check for emptiness at any time, not just at the start of the iteration.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  >>> gen = (i for i in []) >>> next(gen) Traceback (most recent call last):   File \"<pyshell#43>\", line 1, in <module>     next(gen) StopIteration   At the end of generator StopIteration is raised, since in your case end is reached immediately, exception is raised. But normally you shouldn't check for existence of next value.  another thing you can do is:  >>> gen = (i for i in []) >>> if not list(gen):     print('empty generator')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  In my case I needed to know if a host of generators was populated before I passed it on to a function, which merged the items, i.e., zip(...). The solution is similar, but different enough, from the accepted answer:  Definition:  def has_items(iterable):     try:         return True, itertools.chain([next(iterable)], iterable)     except StopIteration:         return False, []   Usage:  def filter_empty(iterables):     for iterable in iterables:         itr_has_items, iterable = has_items(iterable)         if itr_has_items:             yield iterable   def merge_iterables(iterables):     populated_iterables = filter_empty(iterables)     for items in zip(*populated_iterables):         # Use items for each \"slice\"   My particular problem has the property that the iterables are either empty or has exactly the same number of entries.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  If you need to know before you use the generator, then no, there is no simple way.  If you can wait until after you have used the generator, there is a simple way:  was_empty = True  for some_item in some_generator:     was_empty = False     do_something_with(some_item)  if was_empty:     handle_already_empty_generator_case()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Here is my simple approach that i use to keep on returning an iterator while checking if something was yielded I just check if the loop runs:          n = 0         for key, value in iterator:             n+=1             yield key, value         if n == 0:             print (\"nothing found in iterator)             break      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Here's a simple decorator which wraps the generator, so it returns None if empty. This can be useful if your code needs to know whether the generator will produce anything before looping through it.  def generator_or_none(func):     \"\"\"Wrap a generator function, returning None if it's empty. \"\"\"      def inner(*args, **kwargs):         # peek at the first item; return None if it doesn't exist         try:             next(func(*args, **kwargs))         except StopIteration:             return None          # return original generator otherwise first item will be missing         return func(*args, **kwargs)      return inner   Usage:  import random  @generator_or_none def random_length_generator():     for i in range(random.randint(0, 10)):         yield i  gen = random_length_generator() if gen is None:     print('Generator is empty')   One example where this is useful is in templating code - i.e. jinja2  {% if content_generator %}   <section>     <h4>Section title</h4>     {% for item in content_generator %}       {{ item }}     {% endfor %   </section> {% endif %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Simply wrap the generator with itertools.chain, put something that will represent the end of the iterable as the second iterable, then simply check for that.  Ex:  import itertools  g = some_iterable eog = object() wrap_g = itertools.chain(g, [eog])   Now all that's left is to check for that value we appended to the end of the iterable, when you read it then that will signify the end  for value in wrap_g:     if value == eog: # DING DING! We just found the last element of the iterable         pass # Do something      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "    using islice you need only check up to the first iteration to discover if it is empty.     from itertools import islice      def isempty(iterable):       return list(islice(iterable,1)) == []      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  What about using any()? I use it with generators and it's working fine. Here there is guy explaining a little about this     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Use the peek function in cytoolz.  from cytoolz import peek from typing import Tuple, Iterable  def is_empty_iterator(g: Iterable) -> Tuple[Iterable, bool]:     try:         _, g = peek(g)         return g, False     except StopIteration:         return g, True   The iterator returned by this function will be equivalent to the original one passed in as an argument.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  Prompted by Mark Ransom, here's a class that you can use to wrap any iterator so that you can peek ahead, push values back onto the stream and check for empty. It's a simple idea with a simple implementation that I've found very handy in the past.  class Pushable:      def __init__(self, iter):         self.source = iter         self.stored = []      def __iter__(self):         return self      def __bool__(self):         if self.stored:             return True         try:             self.stored.append(next(self.source))         except StopIteration:             return False         return True      def push(self, value):         self.stored.append(value)      def peek(self):         if self.stored:             return self.stored[-1]         value = next(self.source)         self.stored.append(value)         return value      def __next__(self):         if self.stored:             return self.stored.pop()         return next(self.source)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I know if a generator is empty from the start?",
        "A_Content": "  I solved it by using the sum function. See below for an example I used with glob.iglob (which returns a generator).  def isEmpty():     files = glob.iglob(search)     if sum(1 for _ in files):         return True     return False   *This will probably not work for HUGE generators but should perform nicely for smaller lists     ",
        "Language": "Python",
        "Tags": [
            "python",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/661603/how-do-i-know-if-a-generator-is-empty-from-the-start",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a simple way of testing if the generator has no items, like peek, hasNext, isEmpty, something along those lines?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the EAFP principle in Python?",
        "A_Content": "  From the glossary:     Easier to ask for forgiveness than permission. This common Python coding style assumes the existence of valid keys or attributes and catches exceptions if the assumption proves false. This clean and fast style is characterized by the presence of many try and except statements. The technique contrasts with the LBYL style common to many other languages such as C.   An example would be an attempt to access a dictionary key.  EAFP:  try:     x = my_dict[\"key\"] except KeyError:     # handle missing key   LBYL:  if \"key\" in my_dict:     x = my_dict[\"key\"] else:     # handle missing key   The LBYL version has to search the key inside the dictionary twice, and might also be considered slightly less readable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "principles"
        ],
        "URL": "https://stackoverflow.com/questions/11360858/what-is-the-eafp-principle-in-python",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is meant by \"using the EAFP principle\" in Python? Could you provide any examples?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "What is the EAFP principle in Python?",
        "A_Content": "  I call it \"optimistic programming\".  The idea is that most times people will do the right thing, and errors should be few.  So code first for the \"right thing\" to happen, and then catch the errors if they don't.    My feeling is that if a user is going to be making mistakes, they should be the one to suffer the time consequences.  People who use the tool the right way are sped through.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "principles"
        ],
        "URL": "https://stackoverflow.com/questions/11360858/what-is-the-eafp-principle-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is meant by \"using the EAFP principle\" in Python? Could you provide any examples?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  Unwind is essentially correct that there are many different ways to implement a trie; and for a large, scalable trie, nested dictionaries might become cumbersome -- or at least space inefficient. But since you're just getting started, I think that's the easiest approach; you could code up a simple trie in just a few lines. First, a function to construct the trie:  >>> _end = '_end_' >>>  >>> def make_trie(*words): ...     root = dict() ...     for word in words: ...         current_dict = root ...         for letter in word: ...             current_dict = current_dict.setdefault(letter, {}) ...         current_dict[_end] = _end ...     return root ...  >>> make_trie('foo', 'bar', 'baz', 'barz') {'b': {'a': {'r': {'_end_': '_end_', 'z': {'_end_': '_end_'}},               'z': {'_end_': '_end_'}}},   'f': {'o': {'o': {'_end_': '_end_'}}}}   If you're not familiar with setdefault, it simply looks up a key in the dictionary (here, letter or _end). If the key is present, it returns the associated value; if not, it assigns a default value to that key and returns the value ({} or _end). (It's like a version of get that also updates the dictionary.)   Next, a function to test whether the word is in the trie. This could be more terse, but I'm leaving it verbose so that the logic is clear:  >>> def in_trie(trie, word): ...     current_dict = trie ...     for letter in word: ...         if letter in current_dict: ...             current_dict = current_dict[letter] ...         else: ...             return False ...     else: ...         if _end in current_dict: ...             return True ...         else: ...             return False ...  >>> in_trie(make_trie('foo', 'bar', 'baz', 'barz'), 'baz') True >>> in_trie(make_trie('foo', 'bar', 'baz', 'barz'), 'barz') True >>> in_trie(make_trie('foo', 'bar', 'baz', 'barz'), 'barzz') False >>> in_trie(make_trie('foo', 'bar', 'baz', 'barz'), 'bart') False >>> in_trie(make_trie('foo', 'bar', 'baz', 'barz'), 'ba') False   I'll leave insertion and removal to you as an exercise.  Of course, Unwind's suggestion wouldn't be much harder. There might be a slight speed disadvantage in that finding the correct sub-node would require a linear search. But the search would be limited to the number of possible characters -- 27 if we include _end. Also, there's nothing to be gained by creating a massive list of nodes and accessing them by index as he suggests; you might as well just nest the lists.  Finally, I'll add that creating a DAWG would be a bit more complex, because you have to detect situations in which your current word shares a suffix with another word in the structure. In fact, this can get rather complex, depending on how you want to structure the DAWG! You may have to learn some stuff about Levenshtein distance to get it right.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "120",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  Have a look at this:  https://github.com/kmike/marisa-trie     Static memory-efficient Trie structures for Python (2.x and 3.x).      String data in a MARISA-trie may take up to 50x-100x less memory than   in a standard Python dict; the raw lookup speed is comparable; trie   also provides fast advanced methods like prefix search.      Based on marisa-trie C++ library.   Here's a blog post from a company using marisa trie successfully: http://blog.repustate.com/sharing-large-data-structure-across-processes-python/     At Repustate, much of our data models we use in our text analysis can be represented as simple key-value pairs, or dictionaries in Python lingo. In our particular case, our dictionaries are massive, a few hundred MB each, and they need to be accessed constantly. In fact for a given HTTP request, 4 or 5 models might be accessed, each doing 20-30 lookups. So the problem we face is how do we keep things fast for the client as well as light as possible for the server.       ...      I found this package, marisa tries, which is a Python wrapper around a C++ implementation of a marisa trie. “Marisa” is an acronym for Matching Algorithm with Recursively Implemented StorAge. What’s great about marisa tries is the storage mechanism really shrinks how much memory you need. The author of the Python plugin claimed 50-100X reduction in size – our experience is similar.      What’s great about the marisa trie package is that the underlying trie structure can be written to disk and then read in via a memory mapped object. With a memory mapped marisa trie, all of our requirements are now met. Our server’s memory usage went down dramatically, by about 40%, and our performance was unchanged from when we used Python’s dictionary implementation.   There are also a couple of pure-python implementations, though unless you're on a restricted platform you'd want to use the C++ backed implementation above for best performance:   https://github.com/bdimmick/python-trie https://pypi.python.org/pypi/PyTrie      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  Here is a list of python packages that implement Trie:   marisa-trie - a C++ based implementation. python-trie - a simple pure python implementation. PyTrie - a more advanced pure python implementation.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  There's no \"should\"; it's up to you. Various implementations will have different performance characteristics, take various amounts of time to implement, understand, and get right. This is typical for software development as a whole, in my opinion.  I would probably first try having a global list of all trie nodes so far created, and representing the child-pointers in each node as a list of indices into the global list. Having a dictionary just to represent the child linking feels too heavy-weight, to me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  Modified from senderle's method (above). I found that Python's defaultdict is ideal for creating a trie or a prefix tree.  from collections import defaultdict  class Trie:     \"\"\"     Implement a trie with insert, search, and startsWith methods.     \"\"\"     def __init__(self):         self.root = defaultdict()      # @param {string} word     # @return {void}     # Inserts a word into the trie.     def insert(self, word):         current = self.root         for letter in word:             current = current.setdefault(letter, {})         current.setdefault(\"_end\")      # @param {string} word     # @return {boolean}     # Returns if the word is in the trie.     def search(self, word):         current = self.root         for letter in word:             if letter not in current:                 return False             current = current[letter]         if \"_end\" in current:             return True         return False      # @param {string} prefix     # @return {boolean}     # Returns if there is any word in the trie     # that starts with the given prefix.     def startsWith(self, prefix):         current = self.root         for letter in prefix:             if letter not in current:                 return False             current = current[letter]         return True  # Now test the class  test = Trie() test.insert('helloworld') test.insert('ilikeapple') test.insert('helloz')  print test.search('hello') print test.startsWith('hello') print test.search('ilikeapple')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  If you want a TRIE implemented as a Python class, here is something I wrote after reading about them:  class Trie:      def __init__(self):         self.__final = False         self.__nodes = {}      def __repr__(self):         return 'Trie<len={}, final={}>'.format(len(self), self.__final)      def __getstate__(self):         return self.__final, self.__nodes      def __setstate__(self, state):         self.__final, self.__nodes = state      def __len__(self):         return len(self.__nodes)      def __bool__(self):         return self.__final      def __contains__(self, array):         try:             return self[array]         except KeyError:             return False      def __iter__(self):         yield self         for node in self.__nodes.values():             yield from node      def __getitem__(self, array):         return self.__get(array, False)      def create(self, array):         self.__get(array, True).__final = True      def read(self):         yield from self.__read([])      def update(self, array):         self[array].__final = True      def delete(self, array):         self[array].__final = False      def prune(self):         for key, value in tuple(self.__nodes.items()):             if not value.prune():                 del self.__nodes[key]         if not len(self):             self.delete([])         return self      def __get(self, array, create):         if array:             head, *tail = array             if create and head not in self.__nodes:                 self.__nodes[head] = Trie()             return self.__nodes[head].__get(tail, create)         return self      def __read(self, name):         if self.__final:             yield name         for key, value in self.__nodes.items():             yield from value.__read(name + [key])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  This version is using recursion   import pprint from collections import deque  pp = pprint.PrettyPrinter(indent=4)  inp = raw_input(\"Enter a sentence to show as trie\\n\") words = inp.split(\" \") trie = {}   def trie_recursion(trie_ds, word):     try:         letter = word.popleft()         out = trie_recursion(trie_ds.get(letter, {}), word)     except IndexError:         # End of the word         return {}      # Dont update if letter already present     if not trie_ds.has_key(letter):         trie_ds[letter] = out      return trie_ds  for word in words:     # Go through each word     trie = trie_recursion(trie, deque(word))  pprint.pprint(trie)   Output:  Coool\uD83D\uDC7E <algos>\uD83D\uDEB8  python trie.py Enter a sentence to show as trie foo bar baz fun {   'b': {     'a': {       'r': {},       'z': {}     }   },   'f': {     'o': {       'o': {}     },     'u': {       'n': {}     }   } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to create a TRIE in Python",
        "A_Content": "  from collections import defaultdict   Define Trie:  _trie = lambda: defaultdict(_trie)   Create Trie:  trie = _trie() for s in [\"cat\", \"bat\", \"rat\", \"cam\"]:     curr = trie     for c in s:         curr = curr[c]     curr.setdefault(\"_end\")   Lookup:  def word_exist(trie, word):     curr = trie     for w in word:         if w not in curr:             return False         curr = curr[w]     return '_end' in curr   Test:  print(word_exist(trie, 'cam'))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "trie"
        ],
        "URL": "https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Python and trying to learn and advance. I am interested in TRIEs and DAWGs and I have been reading a lot about it but I don't understand what should the output TRIE or DAWG file look like.   Should a TRIE be an object of nested dictionaries? Where each letter is divided in to letters and so on? Would a look up performed on such a dictionary be fast if there are 100k or 500k entries? How to implement word-blocks consisting of more than one word separated with - or space? How to link prefix or suffix of a word to another part in the structure? [for DAWG]   I want to understand the best output structure in order to figure out how to create and use one.  I would also appreciate what should be the output of a DAWG along with TRIE.  I do not want to see graphical representations with bubbles linked to each other, I saw them plenty whilst reading.  I would like to know the output object once a set of words are turned into TRIEs or DAWGs.  Thank you.      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Dictionary to URL Parameters",
        "A_Content": "  Use urllib.urlencode(). It takes a dictionary of key-value pairs, and converts it into a form suitable for a URL (e.g., key1=val1&key2=val2).  If you are using Python3, use urllib.parse.urlencode()  If you want to make a URL with repetitive params such as: p=1&p=2&p=3 you have two options:  >>> import urllib >>> a = (('p',1),('p',2), ('p', 3)) >>> urllib.urlencode(a) 'p=1&p=2&p=3'   or if you want to make a url with repetitive params:  >>> urllib.urlencode({'p': [1, 2, 3]}, doseq=True) 'p=1&p=2&p=3'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary",
            "url-parameters"
        ],
        "URL": "https://stackoverflow.com/questions/1233539/python-dictionary-to-url-parameters",
        "A_Votes": "188",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to convert a Python dictionary to a string for use as URL parameters. I am sure that there is a better, more Pythonic way of doing this. What is it?  x = \"\" for key, val in {'a':'A', 'b':'B'}.items():     x += \"%s=%s&\" %(key,val) x = x[:-1]      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Dictionary to URL Parameters",
        "A_Content": "  Use the 3rd party Python url manipulation library furl:  f = furl.furl('') f.args = {'a':'A', 'b':'B'} print(f.url) # prints ... '?a=A&b=B'   If you want repetitive parameters, you can do the following:  f = furl.furl('') f.args = [('a', 'A'), ('b', 'B'),('b', 'B2')] print(f.url) # prints ... '?a=A&b=B&b=B2'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary",
            "url-parameters"
        ],
        "URL": "https://stackoverflow.com/questions/1233539/python-dictionary-to-url-parameters",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to convert a Python dictionary to a string for use as URL parameters. I am sure that there is a better, more Pythonic way of doing this. What is it?  x = \"\" for key, val in {'a':'A', 'b':'B'}.items():     x += \"%s=%s&\" %(key,val) x = x[:-1]      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Why do tuples take less space in memory than lists?",
        "A_Content": "  I assume you're using CPython and with 64bits (I got the same results on my CPython 2.7 64-bit). There could be differences in other Python implementations or if you have a 32bit Python.  Regardless of the implementation, lists are variable-sized while tuples are fixed-size.   So tuples can store the elements directly inside the struct, lists on the other hand need a layer of indirection (it stores a pointer to the elements). This layer of indirection is a pointer, on 64bit systems that's 64bit, hence 8bytes.  But there's another thing that lists do: They over-allocate. Otherwise list.append would be an O(n) operation always - to make it amortized O(1) (much faster!!!) it over-allocates. But now it has to keep track of the allocated size and the filled size (tuples only need to store one size, because allocated and filled size are always identical). That means each list has to store another \"size\" which on 64bit systems is a 64bit integer, again 8 bytes.  So lists need at least 16 bytes more memory than tuples. Why did I say \"at least\"? Because of the over-allocation. Over-allocation means it allocates more space than needed. However, the amount of over-allocation depends on \"how\" you create the list and the append/deletion history:  >>> l = [1,2,3] >>> l.__sizeof__() 64 >>> l.append(4)  # triggers re-allocation (with over-allocation), because the original list is full >>> l.__sizeof__() 96  >>> l = [] >>> l.__sizeof__() 40 >>> l.append(1)  # re-allocation with over-allocation >>> l.__sizeof__() 72 >>> l.append(2)  # no re-alloc >>> l.append(3)  # no re-alloc >>> l.__sizeof__() 72 >>> l.append(4)  # still has room, so no over-allocation needed (yet) >>> l.__sizeof__() 72   Images  I decided to create some images to accompany the explanation above. Maybe these are helpful  This is how it (schematically) is stored in memory in your example. I highlighted the differences with red (free-hand) cycles:    That's actually just an approximation because int objects are also Python objects and CPython even reuses small integers, so a probably more accurate representation (although not as readable) of the objects in memory would be:    Useful links:   tuple struct in CPython repository for Python 2.7 list struct in CPython repository for Python 2.7 int struct in CPython repository for Python 2.7   Note that __sizeof__ doesn't really return the \"correct\" size! It only returns the size of the stored values. However when you use sys.getsizeof the result is different:  >>> import sys >>> l = [1,2,3] >>> t = (1, 2, 3) >>> sys.getsizeof(l) 88 >>> sys.getsizeof(t) 72   There are 24 \"extra\" bytes. These are real, that's the garbage collector overhead that isn't accounted for in the __sizeof__ method. That's because you're generally not supposed to use magic methods directly - use the functions that know how to handle them, in this case: sys.getsizeof (which actually adds the GC overhead to the value returned from __sizeof__).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "list",
            "tuples",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/46664007/why-do-tuples-take-less-space-in-memory-than-lists",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A tuple takes less memory space in Python:  >>> a = (1,2,3) >>> a.__sizeof__() 48   whereas lists takes more memory space:  >>> b = [1,2,3] >>> b.__sizeof__() 64   What happens internally on the Python memory management?      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Why do tuples take less space in memory than lists?",
        "A_Content": "  I'll take a deeper dive into the CPython codebase so we can see how the sizes are actually calculated. In your specific example, no over-allocations have been performed, so I won't touch on that.   I'm going to use 64-bit values here, as you are.    The size for lists is calculated from the following function, list_sizeof:   static PyObject * list_sizeof(PyListObject *self) {     Py_ssize_t res;      res = _PyObject_SIZE(Py_TYPE(self)) + self->allocated * sizeof(void*);     return PyInt_FromSsize_t(res); }   Here Py_TYPE(self) is a macro that grabs the ob_type of self (returning PyList_Type) while  _PyObject_SIZE is another macro that grabs tp_basicsize from that type. tp_basicsize is calculated as sizeof(PyListObject) where PyListObject is the instance struct.  The PyListObject structure has three fields:  PyObject_VAR_HEAD     # 24 bytes  PyObject **ob_item;   #  8 bytes Py_ssize_t allocated; #  8 bytes   these have comments (which I trimmed) explaining what they are, follow the link above to read them. PyObject_VAR_HEAD expands into three 8 byte fields (ob_refcount, ob_type and ob_size) so a 24 byte contribution.  So for now res is:  sizeof(PyListObject) + self->allocated * sizeof(void*)   or:  40 + self->allocated * sizeof(void*)   If the list instance has elements that are allocated. the second part calculates their contribution. self->allocated, as it's name implies, holds the number of allocated elements.  Without any elements, the size of lists is calculated to be:  >>> [].__sizeof__() 40   i.e the size of the instance struct.    tuple objects don't define a tuple_sizeof function. Instead, they use object_sizeof to calculate their size:  static PyObject * object_sizeof(PyObject *self, PyObject *args) {     Py_ssize_t res, isize;      res = 0;     isize = self->ob_type->tp_itemsize;     if (isize > 0)         res = Py_SIZE(self) * isize;     res += self->ob_type->tp_basicsize;      return PyInt_FromSsize_t(res); }   This, as for lists, grabs the tp_basicsize and, if the object has a non-zero tp_itemsize (meaning it has variable-length instances), it multiplies the number of items in the tuple (which it gets via Py_SIZE) with tp_itemsize.   tp_basicsize again uses sizeof(PyTupleObject) where the  PyTupleObject struct contains:  PyObject_VAR_HEAD       # 24 bytes  PyObject *ob_item[1];   # 8  bytes   So, without any elements (that is, Py_SIZE returns 0) the size of empty tuples is equal to sizeof(PyTupleObject):  >>> ().__sizeof__() 24   huh? Well, here's an oddity which I haven't found an explanation for, the tp_basicsize of tuples is actually calculated as follows:  sizeof(PyTupleObject) - sizeof(PyObject *)   why an additional 8 bytes is removed from tp_basicsize is something I haven't been able to find out. (See MSeifert's comment for a possible explanation)    But, this is basically the difference in your specific example. lists also keep around a number of allocated elements which helps determine when to over-allocate again.   Now, when additional elements are added, lists do indeed perform this over-allocation in order to achieve O(1) appends. This results in greater sizes as MSeifert's covers nicely in his answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "list",
            "tuples",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/46664007/why-do-tuples-take-less-space-in-memory-than-lists",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A tuple takes less memory space in Python:  >>> a = (1,2,3) >>> a.__sizeof__() 48   whereas lists takes more memory space:  >>> b = [1,2,3] >>> b.__sizeof__() 64   What happens internally on the Python memory management?      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Why do tuples take less space in memory than lists?",
        "A_Content": "  MSeifert answer covers it broadly; to keep it simple you can think of:  tuple is immutable. Once it set, you can't change it. So you know in advance how much memory you need to allocate for that object.  list is mutable. You can add or remove items to or from it. It has to know the size of it (for internal impl.). It resizes as needed.  There are no free meals - these capabilities comes with a cost. Hence the overhead in memory for lists.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "list",
            "tuples",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/46664007/why-do-tuples-take-less-space-in-memory-than-lists",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A tuple takes less memory space in Python:  >>> a = (1,2,3) >>> a.__sizeof__() 48   whereas lists takes more memory space:  >>> b = [1,2,3] >>> b.__sizeof__() 64   What happens internally on the Python memory management?      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Why do tuples take less space in memory than lists?",
        "A_Content": "  The size of the tuple is prefixed, meaning at tuple initialization the interpreter allocate enough space for the contained data, and that's the end of it, giving it's immutable (can't be modified), whereas a list is a mutable object hence implying dynamic allocation of memory, so to avoid allocating space each time you append or modify the list ( allocate enough space to contain the changed data and copy the data to it), it allocates additional space for future append, modifications, ... that pretty much sums it up.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "list",
            "tuples",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/46664007/why-do-tuples-take-less-space-in-memory-than-lists",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A tuple takes less memory space in Python:  >>> a = (1,2,3) >>> a.__sizeof__() 48   whereas lists takes more memory space:  >>> b = [1,2,3] >>> b.__sizeof__() 64   What happens internally on the Python memory management?      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  Likely, your problem is that you parsed it okay, and now you're trying to print the contents of the XML and you can't because theres some foreign Unicode characters.  Try to encode your unicode string as ascii first:  unicodeData.encode('ascii', 'ignore')   the 'ignore' part will tell it to just skip those characters.  From the python docs:  >>> u = unichr(40960) + u'abcd' + unichr(1972) >>> u.encode('utf-8') '\\xea\\x80\\x80abcd\\xde\\xb4' >>> u.encode('ascii') Traceback (most recent call last):   File \"<stdin>\", line 1, in ? UnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in position 0: ordinal not in range(128) >>> u.encode('ascii', 'ignore') 'abcd' >>> u.encode('ascii', 'replace') '?abcd?' >>> u.encode('ascii', 'xmlcharrefreplace') '&#40960;abcd&#1972;'   You might want to read this article: http://www.joelonsoftware.com/articles/Unicode.html, which I found very useful as a basic tutorial on what's going on.  After the read, you'll stop feeling like you're just guessing what commands to use (or at least that happened to me).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "175",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  A better solution:  if type(value) == str:     # Ignore errors even if the string is not proper UTF-8 or has     # broken marker bytes.     # Python built-in function unicode() can do this.     value = unicode(value, \"utf-8\", errors=\"ignore\") else:     # Assume the value object has proper __unicode__() method     value = unicode(value)   If you would like to read more about why:  http://docs.plone.org/manage/troubleshooting/unicode.html#id1     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  Don't hardcode the character encoding of your environment inside your script; print Unicode text directly instead:  assert isinstance(text, unicode) # or str on Python 3 print(text)   If your output is redirected to a file (or a pipe); you could use PYTHONIOENCODING envvar, to specify the character encoding:  $ PYTHONIOENCODING=utf-8 python your_script.py >output.utf8   Otherwise, python your_script.py should work as is -- your locale settings are used to encode the text (on POSIX check: LC_ALL, LC_CTYPE, LANG envvars -- set LANG to a utf-8 locale if necessary).  To print Unicode on Windows, see this answer that shows how to print Unicode to Windows console, to a file, or using IDLE.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  Excellent post : http://www.carlosble.com/2010/12/understanding-python-and-unicode/  # -*- coding: utf-8 -*-  def __if_number_get_string(number):     converted_str = number     if isinstance(number, int) or \\             isinstance(number, float):         converted_str = str(number)     return converted_str   def get_unicode(strOrUnicode, encoding='utf-8'):     strOrUnicode = __if_number_get_string(strOrUnicode)     if isinstance(strOrUnicode, unicode):         return strOrUnicode     return unicode(strOrUnicode, encoding, errors='ignore')   def get_string(strOrUnicode, encoding='utf-8'):     strOrUnicode = __if_number_get_string(strOrUnicode)     if isinstance(strOrUnicode, unicode):         return strOrUnicode.encode(encoding)     return strOrUnicode      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  You can use something of the form  s.decode('utf-8')   which will convert a UTF-8 encoded bytestring into a Python Unicode string. But the exact procedure to use depends on exactly how you load and parse the XML file, e.g. if you don't ever access the XML string directly, you might have to use a decoder object from the codecs module.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  I wrote the following to fix the nuisance non-ascii quotes and force conversion to something usable.  unicodeToAsciiMap = {u'\\u2019':\"'\", u'\\u2018':\"`\", }  def unicodeToAscii(inStr):     try:         return str(inStr)     except:         pass     outStr = \"\"     for i in inStr:         try:             outStr = outStr + str(i)         except:             if unicodeToAsciiMap.has_key(i):                 outStr = outStr + unicodeToAsciiMap[i]             else:                 try:                     print \"unicodeToAscii: add to map:\", i, repr(i), \"(encoded as _)\"                 except:                     print \"unicodeToAscii: unknown code (encoded as _)\", repr(i)                 outStr = outStr + \"_\"     return outStr      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  If you need to print an approximate representation of the string to the screen, rather than ignoring those nonprintable characters, please try unidecode package here:  https://pypi.python.org/pypi/Unidecode  The explanation is found here:  https://www.tablix.org/~avian/blog/archives/2009/01/unicode_transliteration_in_python/  This is better than using the u.encode('ascii', 'ignore') for a given string u, and can save you from unnecessary headache if character precision is not what you are after, but still want to have human readability.  Wirawan     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python Unicode Encode Error",
        "A_Content": "  Try adding the following line at the top of your python script.  # _*_ coding:utf-8 _*_      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "ascii",
            "encode"
        ],
        "URL": "https://stackoverflow.com/questions/3224268/python-unicode-encode-error",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm reading and parsing an Amazon XML file and while the XML file shows a ' , when I try to print it I get the following error:  'ascii' codec can't encode character u'\\u2019' in position 16: ordinal not in range(128)    From what I've read online thus far, the error is coming from the fact that the XML file is in UTF-8, but Python wants to handle it as an ASCII encoded character. Is there a simple way to make the error go away and have my program print the XML as it reads?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Can you define aliases for imported modules in Python?",
        "A_Content": "  import a_ridiculously_long_module_name as short_name   also works for  import module.submodule.subsubmodule as short_name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "module",
            "alias",
            "python-import"
        ],
        "URL": "https://stackoverflow.com/questions/706595/can-you-define-aliases-for-imported-modules-in-python",
        "A_Votes": "139",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Python, is it possible to define an alias for an imported module?  For instance:  import a_ridiculously_long_module_name   ...so that is has an alias of 'short_name'.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Can you define aliases for imported modules in Python?",
        "A_Content": "  Check here  import module as name   or  from relative_module import identifier as name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "module",
            "alias",
            "python-import"
        ],
        "URL": "https://stackoverflow.com/questions/706595/can-you-define-aliases-for-imported-modules-in-python",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, is it possible to define an alias for an imported module?  For instance:  import a_ridiculously_long_module_name   ...so that is has an alias of 'short_name'.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Can you define aliases for imported modules in Python?",
        "A_Content": "  If you've done:  import long_module_name   you can also give it an alias by:  lmn = long_module_name   There's no reason to do it this way in code, but I sometimes find it useful in the interactive interpreter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "module",
            "alias",
            "python-import"
        ],
        "URL": "https://stackoverflow.com/questions/706595/can-you-define-aliases-for-imported-modules-in-python",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, is it possible to define an alias for an imported module?  For instance:  import a_ridiculously_long_module_name   ...so that is has an alias of 'short_name'.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Get raw POST body in Python Flask regardless of Content-Type header",
        "A_Content": "  Use request.get_data() to get the raw data, regardless of content type. The data is cached and you can subsequently access request.data, request.json, request.form at will.  If you access request.data first, it will call get_data with an argument to parse form data first. If the request has a form content type (multipart/form-data, application/x-www-form-urlencoded, or application/x-url-encoded) then the raw data will be consumed. request.data and request.json will appear empty in this case.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/10999990/get-raw-post-body-in-python-flask-regardless-of-content-type-header",
        "A_Votes": "158",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Previously, I asked How to get data received in Flask request because request.data was empty. The answer explained that request.data is the raw post body, but will be empty if form data is parsed.  How can I get the raw post body unconditionally?  @app.route('/', methods=['POST']) def parse_request():     data = request.data  # empty in some cases     # always need raw data here, not parsed form data      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Get raw POST body in Python Flask regardless of Content-Type header",
        "A_Content": "  There's request.stream when the mime type is not recognized.  data = request.stream.read()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/10999990/get-raw-post-body-in-python-flask-regardless-of-content-type-header",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Previously, I asked How to get data received in Flask request because request.data was empty. The answer explained that request.data is the raw post body, but will be empty if form data is parsed.  How can I get the raw post body unconditionally?  @app.route('/', methods=['POST']) def parse_request():     data = request.data  # empty in some cases     # always need raw data here, not parsed form data      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Get raw POST body in Python Flask regardless of Content-Type header",
        "A_Content": "  I just had this issue, and I think a few of you might be able to benefit from my solution. I created a WSGI middleware class that saves the raw POST body from the socket. I saved the value in the WSGI variable 'environ' so I could refer to it as request.environ['body_copy'] within my Flask app.   You need to be careful that the post data is not too large, or you might have memory issues on your server.  class WSGICopyBody(object):     def __init__(self, application):         self.application = application      def __call__(self, environ, start_response):          from cStringIO import StringIO         length = environ.get('CONTENT_LENGTH', '0')         length = 0 if length == '' else int(length)          body = environ['wsgi.input'].read(length)         environ['body_copy'] = body         environ['wsgi.input'] = StringIO(body)          # Call the wrapped application         app_iter = self.application(environ,                                      self._sr_callback(start_response))          # Return modified response         return app_iter      def _sr_callback(self, start_response):         def callback(status, headers, exc_info=None):              # Call upstream start_response             start_response(status, headers, exc_info)         return callback  app.wsgi_app = WSGICopyBody(app.wsgi_app)  request.environ['body_copy'] # This is the raw post body you can use in your flask app      ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/10999990/get-raw-post-body-in-python-flask-regardless-of-content-type-header",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Previously, I asked How to get data received in Flask request because request.data was empty. The answer explained that request.data is the raw post body, but will be empty if form data is parsed.  How can I get the raw post body unconditionally?  @app.route('/', methods=['POST']) def parse_request():     data = request.data  # empty in some cases     # always need raw data here, not parsed form data      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Get raw POST body in Python Flask regardless of Content-Type header",
        "A_Content": "  I finally figured out if I do this:  request.environ['CONTENT_TYPE'] = 'application/something_Flask_ignores'   Then request.data will actually have the post data. This is if you can't control the client request and want to just override it on the server.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "flask"
        ],
        "URL": "https://stackoverflow.com/questions/10999990/get-raw-post-body-in-python-flask-regardless-of-content-type-header",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Previously, I asked How to get data received in Flask request because request.data was empty. The answer explained that request.data is the raw post body, but will be empty if form data is parsed.  How can I get the raw post body unconditionally?  @app.route('/', methods=['POST']) def parse_request():     data = request.data  # empty in some cases     # always need raw data here, not parsed form data      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  UPDATE: This is no longer necessary with Python3.4. It installs pip3 as part of the stock install.  I ended up posting this same question on the python mailing list, and got the following answer:  # download and install setuptools curl -O https://bootstrap.pypa.io/ez_setup.py python3 ez_setup.py # download and install pip curl -O https://bootstrap.pypa.io/get-pip.py python3 get-pip.py   Which solved my question perfectly. After adding the following for my own:  cd /usr/local/bin ln -s ../../../Library/Frameworks/Python.framework/Versions/3.3/bin/pip pip   So that I could run pip directly, I was able to:  # use pip to install pip install pyserial   or:  # Don't want it? pip uninstall pyserial      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  I had to go through this process myself and chose a different way that I think is better in the long run.   I installed homebrew  ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"   then:  brew doctor   The last step gives you some warnings and errors that you have to resolve. One of those will be to download and install the Mac OS X command-line tools.  then:  brew install python3   This gave me python3 and pip3 in my path.  pieter$ which pip3 python3 /usr/local/bin/pip3 /usr/local/bin/python3      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  Install Python3 on mac  1. brew install python3 2. curl https://bootstrap.pypa.io/get-pip.py | python3 3. python3   Use pip3 to install modules  1. pip3 install ipython 2. python3 -m IPython   :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  Plus: when you install requests with python3, the command is:  pip3 install requests   not   pip install requests      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  To use Python EasyInstall (which is what I think you're wanting to use), is super easy!  sudo easy_install pip   so then with pip to install Pyserial you would do:  pip install pyserial      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "   brew install python3 create alias in your shell profile   eg. alias pip3=\"python3 -m pip\" in my .zshrc    ➜  ~ pip3 --version  pip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  Also, it's worth to mention that Max OSX/macOS users can just use Homebrew to install pip3.  $> brew update $> brew install python3 $> pip3 --version pip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  On MacOS 10.12  download pip: pip as get-pip.py  download python3: python3   install python3 open terminal: python3 get-pip.py pip3 is available       ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to install pip for Python 3 on Mac OS X?",
        "A_Content": "  pip is installed automatically with python2 using brew:   brew install python3 pip3 --version      ",
        "Language": "Python",
        "Tags": [
            "python",
            "macos",
            "python-3.x",
            "pip",
            "python-3.3"
        ],
        "URL": "https://stackoverflow.com/questions/20082935/how-to-install-pip-for-python-3-on-mac-os-x",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    OS X (Mavericks) has Python 2.7 stock installed. But I do all my own personal Python stuff with 3.3. I just flushed my 3.3.2 install and installed the new 3.3.3. So I need to install pyserial again. I can do it the way I've done it before, which is:   Download pyserial from pypi  untar pyserial.tgz cd pyserial python3 setup.py install   But I'd like to do like the cool kids do, and just do something like pip3 install pyserial. But it's not clear how I get to that point. And just that point. Not interested (unless I have to be) in virtualenv yet.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  Formatting in Python is done via the string formatting (%) operator:  \"%02d:%02d:%02d\" % (hours, minutes, seconds)   /Edit: There's also strftime.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "124",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  Starting in Python 2.6, there is an alternative: the str.format() method. Here are some examples using the existing string format operator (%):  >>> \"Name: %s, age: %d\" % ('John', 35)  'Name: John, age: 35'  >>> i = 45  >>> 'dec: %d/oct: %#o/hex: %#X' % (i, i, i)  'dec: 45/oct: 055/hex: 0X2D'  >>> \"MM/DD/YY = %02d/%02d/%02d\" % (12, 7, 41)  'MM/DD/YY = 12/07/41'  >>> 'Total with tax: $%.2f' % (13.00 * 1.0825)  'Total with tax: $14.07'  >>> d = {'web': 'user', 'page': 42}  >>> 'http://xxx.yyy.zzz/%(web)s/%(page)d.html' % d  'http://xxx.yyy.zzz/user/42.html'    Here are the equivalent snippets but using str.format():  >>> \"Name: {0}, age: {1}\".format('John', 35)  'Name: John, age: 35'  >>> i = 45  >>> 'dec: {0}/oct: {0:#o}/hex: {0:#X}'.format(i)  'dec: 45/oct: 0o55/hex: 0X2D'  >>> \"MM/DD/YY = {0:02d}/{1:02d}/{2:02d}\".format(12, 7, 41)  'MM/DD/YY = 12/07/41'  >>> 'Total with tax: ${0:.2f}'.format(13.00 * 1.0825)  'Total with tax: $14.07'  >>> d = {'web': 'user', 'page': 42}  >>> 'http://xxx.yyy.zzz/{web}/{page}.html'.format(**d)  'http://xxx.yyy.zzz/user/42.html'   Like Python 2.6+, all Python 3 releases (so far) understand how to do both. I shamelessly ripped this stuff straight out of my hardcore Python intro book and the slides for the Intro+Intermediate Python courses I offer from time-to-time. :-)  Aug 2018 UPDATE: Of course, now that we have the f-string feature in 3.6, we need the equivalent examples of that, yes another alternative:  >>> name, age = 'John', 35 >>> f'Name: {name}, age: {age}' 'Name: John, age: 35'  >>> i = 45 >>> f'dec: {i}/oct: {i:#o}/hex: {i:#X}' 'dec: 45/oct: 0o55/hex: 0X2D'  >>> m, d, y = 12, 7, 41 >>> f\"MM/DD/YY = {m:02d}/{d:02d}/{y:02d}\" 'MM/DD/YY = 12/07/41'  >>> f'Total with tax: ${13.00 * 1.0825:.2f}' 'Total with tax: $14.07'  >>> d = {'web': 'user', 'page': 42} >>> f\"http://xxx.yyy.zzz/{d['web']}/{d['page']}.html\" 'http://xxx.yyy.zzz/user/42.html'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "91",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  In Python 2.6+, it is possible to use the format() function, so in your case you can use:  return '{:02d}:{:02d}:{:.2f} {}'.format(hours, minutes, seconds, ampm)   There are multiple ways of using this function, so for further information you can check the documentation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  You can use C style string formatting:  \"%d:%d:d\" % (hours, minutes, seconds)   See here, especially: https://web.archive.org/web/20120415173443/http://diveintopython3.ep.io/strings.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  You can use following to achieve desired functionality  \"%d:%d:d\" % (hours, minutes, seconds)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  str() in python on an integer will not print any decimal places.  If you have a float that you want to ignore the decimal part, then you can use str(int(floatValue)).  Perhaps the following code will demonstrate:  >>> str(5) '5' >>> int(8.7) 8      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Format numbers to strings in Python",
        "A_Content": "  If you have a value that includes a decimal, but the decimal value is negligible (ie: 100.0) and try to int that, you will get an error.  It seems silly, but calling float first fixes this.  str(int(float([variable])))     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/22617/format-numbers-to-strings-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to find out how to format numbers as strings. My code is here:  return str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm   Hours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".  Bottom line, what library / function do I need to do this for me?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  According to the source code, the maximum size of a list is PY_SSIZE_T_MAX/sizeof(PyObject*).  PY_SSIZE_T_MAX is defined in pyport.h to be ((size_t) -1)>>1  On a regular 32bit system, this is (4294967295 / 2) / 4  or 536870912.  Therefore the maximum size of a python list on a 32 bit system is 536,870,912 elements.   As long as the number of elements you have is equal or below this, all list functions should operate correctly.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "162",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  As the Python documentation says:  sys.maxsize     The largest positive integer supported by the platform’s Py_ssize_t type, and thus the maximum size lists, strings, dicts, and many other containers can have.   In my computer (Linux x86_64):  >>> import sys >>> print sys.maxsize 9223372036854775807      ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  Sure it is OK. Actually you can see for yourself easily:  l = range(12000) l = sorted(l, reverse=True)   Running the those lines on my machine took:  real    0m0.036s user    0m0.024s sys  0m0.004s   But sure as everyone else said. The larger the array the slower the operations will be.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  In casual code I've created lists with millions of elements. I believe that Python's implementation of lists are only bound by the amount of memory on your system.   In addition, the list methods / functions should continue to work despite the size of the list.   If you care about performance, it might be worthwhile to look into a library such as NumPy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  Performance characteristics for lists are described on Effbot.  Python lists are actually implemented as vector for fast random access, so the container will basically hold as many items as there is space for in memory. (You need space for pointers contained in the list as well as space in memory for the object(s) being pointed to.)  Appending is O(1) (amortized constant complexity), however, inserting into/deleting from the middle of the sequence will require an O(n) (linear complexity) reordering, which will get slower as the number of elements in your list.  Your sorting question is more nuanced, since the comparison operation can take an unbounded amount of time. If you're performing really slow comparisons, it will take a long time, though it's no fault of Python's list data type.  Reversal just takes the amount of time it required to swap all the pointers in the list (necessarily O(n) (linear complexity), since you touch each pointer once).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  12000 elements is nothing in Python... and actually the number of elements can go as far as the Python interpreter has memory on your system.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  I'd say you're only limited by the total amount of RAM available.  Obviously the larger the array the longer operations on it will take.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How Big can a Python Array Get?",
        "A_Content": "  I got this from here on a x64 bit system: Python 3.7.0b5 (v3.7.0b5:abb8802389, May 31 2018, 01:54:01) [MSC v.1913 64 bit (AMD64)] on win32       ",
        "Language": "Python",
        "Tags": [
            "python",
            "arrays",
            "size"
        ],
        "URL": "https://stackoverflow.com/questions/855191/how-big-can-a-python-array-get",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, how big can an array/list get? I need an array of about 12000 elements. Will I still be able to run array/list methods such as sorting, etc?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  There is a customization that went into Boto3 recently which helps with this (among other things). It is currently exposed on the low-level S3 client, and can be used like this:  s3_client = boto3.client('s3') open('hello.txt').write('Hello, world!')  # Upload the file to S3 s3_client.upload_file('hello.txt', 'MyBucket', 'hello-remote.txt')  # Download the file from S3 s3_client.download_file('MyBucket', 'hello-remote.txt', 'hello2.txt') print(open('hello2.txt').read())   These functions will automatically handle reading/writing files as well as doing multipart uploads in parallel for large files.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  boto3 now has a nicer interface than the client:  resource = boto3.resource('s3') my_bucket = resource.Bucket('MyBucket') my_bucket.download_file(key, local_filename)   This by itself isn't tremendously better than the client in the accepted answer (although the docs say that it does a better job retrying uploads and downloads on failure) but considering that resources are generally more ergonomic (for example, the s3 bucket and object resources are nicer than the client methods) this does allow you to stay at the resource layer without having to drop down.  Resources generally can be created in the same way as clients, and they take all or most of the same arguments and just forward them to their internal clients.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  For those of you who would like to simulate the set_contents_from_string like boto2 methods, you can try  import boto3 from cStringIO import StringIO  s3c = boto3.client('s3') contents = 'My string to save to S3 object' target_bucket = 'hello-world.by.vor' target_file = 'data/hello.txt' fake_handle = StringIO(contents)  # notice if you do fake_handle.read() it reads like a file handle s3c.put_object(Bucket=target_bucket, Key=target_file, Body=fake_handle.read())     For Python3:  In python3 both StringIO and cStringIO are gone. Use the StringIO import like:  from io import StringIO   To support both version:  try:    from StringIO import StringIO except ImportError:    from io import StringIO      ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  # Preface: File is json with contents: {'name': 'Android', 'status': 'ERROR'}  import boto3 import io  s3 = boto3.resource(     's3',     aws_access_key_id='my_access_id',     aws_secret_access_key='my_secret_key' )  obj = s3.Object('my-bucket', 'key-to-file.json') data = io.BytesIO() obj.download_fileobj(data)  # object is now a bytes string, Converting it to a dict: new_dict = json.loads(data.getvalue().decode(\"utf-8\"))  print(new_dict['status'])  # Should print \"Error\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  Note: I'm assuming you have configured authentication separately. Below code is to download the single object from the S3 bucket.         import boto3  #initiate s3 client  s3 = boto3.resource('s3')  #Download object to the file     s3.Bucket('mybucket').download_file('hello.txt', '/tmp/hello.txt')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to save S3 object to a file using boto3",
        "A_Content": "  When you want to read a file with a different configuration than the default one, feel free to use either mpu.aws.s3_download(s3path, destination) directly or the copy-pasted code:  def s3_download(source, destination,                 exists_strategy='raise',                 profile_name=None):     \"\"\"     Copy a file from an S3 source to a local destination.      Parameters     ----------     source : str         Path starting with s3://, e.g. 's3://bucket-name/key/foo.bar'     destination : str     exists_strategy : {'raise', 'replace', 'abort'}         What is done when the destination already exists?     profile_name : str, optional         AWS profile      Raises     ------     botocore.exceptions.NoCredentialsError         Botocore is not able to find your credentials. Either specify         profile_name or add the environment variables AWS_ACCESS_KEY_ID,         AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN.         See https://boto3.readthedocs.io/en/latest/guide/configuration.html     \"\"\"     exists_strategies = ['raise', 'replace', 'abort']     if exists_strategy not in exists_strategies:         raise ValueError('exists_strategy \\'{}\\' is not in {}'                          .format(exists_strategy, exists_strategies))     session = boto3.Session(profile_name=profile_name)     s3 = session.resource('s3')     bucket_name, key = _s3_path_split(source)     if os.path.isfile(destination):         if exists_strategy is 'raise':             raise RuntimeError('File \\'{}\\' already exists.'                                .format(destination))         elif exists_strategy is 'abort':             return     s3.Bucket(bucket_name).download_file(key, destination)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "amazon-web-services",
            "boto",
            "boto3"
        ],
        "URL": "https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to do a \"hello world\" with new boto3 client for AWS.  The use-case I have is fairly simple: get object from S3 and save it to the file.  In boto 2.X I would do it like this:  import boto key = boto.connect_s3().get_bucket('foo').get_key('foo') key.get_contents_to_filename('/tmp/foo')   In boto 3 . I can't find a clean way to do the same thing, so I'm manually iterating over the \"Streaming\" object:  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     chunk = key['Body'].read(1024*8)     while chunk:         f.write(chunk)         chunk = key['Body'].read(1024*8)   or  import boto3 key = boto3.resource('s3').Object('fooo', 'docker/my-image.tar.gz').get() with open('/tmp/my-image.tar.gz', 'w') as f:     for chunk in iter(lambda: key['Body'].read(4096), b''):         f.write(chunk)   And it works fine. I was wondering is there any \"native\" boto3 function that will do the same task?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  for column in df:     print(df[column])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "180",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  You can use iteritems():  for name, values in df.iteritems():     print '{name}: {value}'.format(name=name, value=values[0])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  You can index dataframe columns by the position using ix.  df1.ix[:,1]   This returns the first column for example. (0 would be the index)  df1.ix[0,]   This returns the first row.  df1.ix[:,1]   This would be the value at the intersection of row 0 and column 1:  df1.ix[0,1]   and so on. So you can enumerate() returns.keys(): and use the number to index the dataframe.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  This answer is to iterate over selected columns as well as all columns in a DF.  df.columns gives a list containing all the columns' names in the DF. Now that isn't very helpful if you want to iterate over all the columns. But it comes in handy when you want to iterate over columns of your choosing only.   We can use Python's list slicing easily to slice df.columns according to our needs. For eg, to iterate over all columns but the first one, we can do:  for column in df.columns[1:]:     print(df[column])   Similarly to iterate over all the columns in reversed order, we can do:  for column in df.columns[::-1]:     print(df[column])   We can iterate over all the columns in a lot of cool ways using this technique. Also remember that you can get the indices of all columns easily using:  for ind, column in enumerate(df.columns):     print(ind, column)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  A workaround is to transpose the DataFrame and iterate over the rows.  for column_name, column in df.transpose().iterrows():     print column_name      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  I'm a bit late but here's how I did this. The steps:   Create a list of all columns Use itertools to take x combinations Append each result R squared value to a result dataframe along with excluded column list Sort the result DF in descending order of R squared to see which is the best fit.   This is the code I used on DataFrame called aft_tmt. Feel free to extrapolate to your use case..  import pandas as pd # setting options to print without truncating output pd.set_option('display.max_columns', None) pd.set_option('display.max_colwidth', None)  import statsmodels.formula.api as smf import itertools  # This section gets the column names of the DF and removes some columns which I don't want to use as predictors. itercols = aft_tmt.columns.tolist() itercols.remove(\"sc97\") itercols.remove(\"sc\") itercols.remove(\"grc\") itercols.remove(\"grc97\") print itercols len(itercols)  # results DF regression_res = pd.DataFrame(columns = [\"Rsq\", \"predictors\", \"excluded\"])  # excluded cols exc = []  # change 9 to the number of columns you want to combine from N columns. #Possibly run an outer loop from 0 to N/2? for x in itertools.combinations(itercols, 9):     lmstr = \"+\".join(x)     m = smf.ols(formula = \"sc ~ \" + lmstr, data = aft_tmt)     f = m.fit()     exc = [item for item in x if item not in itercols]     regression_res = regression_res.append(pd.DataFrame([[f.rsquared, lmstr, \"+\".join([y for y in itercols if y not in list(x)])]], columns = [\"Rsq\", \"predictors\", \"excluded\"]))  regression_res.sort_values(by=\"Rsq\", ascending = False)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  Using list comprehension, you can get all the columns names (header):  [column for column in df]       ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to iterate over columns of pandas dataframe to run regression",
        "A_Content": "  Based on the accepted answer, if an index corresponding to each column is also desired:  for i, column in enumerate(df):     print i, df[column]   The above df[column] type is Series, which can simply be converted into numpy ndarrays:  for i, column in enumerate(df):     print i, np.asarray(df[column])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "statsmodels"
        ],
        "URL": "https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm sure this is simple, but as a complete newbie to python, I'm having trouble figuring out how to iterate over variables in a pandas dataframe and run a regression with each.  Here's what I'm doing:  all_data = {} for ticker in ['FIUIX', 'FSAIX', 'FSAVX', 'FSTMX']:     all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2015')  prices = DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})   returns = prices.pct_change()   I know I can run a regression like this:  regs = sm.OLS(returns.FIUIX,returns.FSTMX).fit()   but suppose I want to do this for each column in the dataframe. In particular, I want to regress FIUIX on FSTMX, and then FSAIX on FSTMX, and then FSAVX on FSTMX. After each regression I want to store the residuals.  I've tried various versions of the following, but I must be getting the syntax wrong:  resids = {} for k in returns.keys():     reg = sm.OLS(returns[k],returns.FSTMX).fit()     resids[k] = reg.resid   I think the problem is I don't know how to refer to the returns column by key, so returns[k] is probably wrong.  Any guidance on the best way to do this would be much appreciated. Perhaps there's a common pandas approach I'm missing.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  The most obvious way to do this would be to print to a file object:  with open('out.txt', 'w') as f:     print >> f, 'Filename:', filename  # Python 2.x     print('Filename:', filename, file=f)  # Python 3.x   However, redirecting stdout also works for me.  It is probably fine for a one-off script such as this:  import sys  orig_stdout = sys.stdout f = open('out.txt', 'w') sys.stdout = f  for i in range(2):     print 'i = ', i  sys.stdout = orig_stdout f.close()   What is the first filename in your script?  I don't see it initialized.  My first guess is that glob doesn't find any bamfiles, and therefore the for loop doesn't run.  Check that the folder exists, and print out bamfiles in your script.  Also, use os.path.join and os.path.basename to manipulate paths and filenames.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "150",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  You can redirect print with the >> operator.  f = open(filename,'w') print >>f, 'whatever'     # Python 2.x print('whatever', file=f) # Python 3.x   In most cases, you're better off just writing to the file normally.  f.write('whatever')   or, if you have several items you want to write with spaces between, like print:  f.write(' '.join(('whatever', str(var2), 'etc')))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "     Python 2 or Python 3 API reference:       print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)           The file argument must be an object with a write(string) method; if it is not present or None, sys.stdout will be used. Since printed arguments are converted to text strings, print() cannot be used with binary mode file objects. For these, use file.write(...) instead.      Since file object normally contains write() method, all you need to do is to pass a file object into its argument.  Write/Overwrite to File  with open('file.txt', 'w') as f:     print('hello world', file=f)   Write/Append to File  with open('file.txt', 'a') as f:     print('hello world', file=f)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  This works perfectly:  import sys sys.stdout=open(\"test.txt\",\"w\") print (\"hello\") sys.stdout.close()   Now the hello will be written to the test.txt file. Make sure to close the stdout with a close, without it the content will not be save in the file     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  The easiest solution isn't through python; its through the shell.  From the first line of your file (#!/usr/bin/python) I'm guessing you're on a UNIX system.  Just use print statements like you normally would, and don't open the file at all in your script.  When you go to run the file, instead of  ./script.py   to run the file, use  ./script.py > <filename>   where you replace <filename> with the name of the file you want the output to go in to.  The > token tells (most) shells to set stdout to the file described by the following token.  One important thing that needs to be mentioned here is that \"script.py\" needs to be made executable for ./script.py to run.  So before running ./script.py,execute this command  chmod a+x script.py (make the script executable for all users)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  Don't use print, use logging  You can change sys.stdout to point to a file, but this is a pretty clunky and inflexible way to handle this problem.  Instead of using print, use the logging module.  With logging, you can print just like you would to stdout, or you can also write the output to a file.  You can even use the different message levels (critical, error, warning, info, debug) to, for example, only print major issues to the console, but still log minor code actions to a file.  A simple example  Import logging, get the logger, and set the processing level:  import logging logger = logging.getLogger() logger.setLevel(logging.DEBUG) # process everything, even if everything isn't printed   If you want to print to stdout:  ch = logging.StreamHandler() ch.setLevel(logging.INFO) # or any other level logger.addHandler(ch)   If you want to also write to a file (if you only want to write to a file skip the last section):  fh = logging.FileHandler('myLog.log') fh.setLevel(logging.DEBUG) # or any level you want logger.addHandler(fh)   Then, wherever you would use print use one of the logger methods:  # print(foo) logger.debug(foo)  # print('finishing processing') logger.info('finishing processing')  # print('Something may be wrong') logger.warning('Something may be wrong')  # print('Something is going really bad') logger.error('Something is going really bad')   To learn more about using more advanced logging features, read the excellent logging tutorial in the Python docs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  You may not like this answer, but I think it's the RIGHT one. Don't change your stdout destination unless it's absolutely necessary (maybe you're using a library that only outputs to stdout??? clearly not the case here).  I think as a good habit you should prepare your data ahead of time as a string, then open your file and write the whole thing at once. This is because input/output operations are the longer you have a file handle open, the more likely an error is to occur with this file (file lock error, i/o error, etc). Just doing it all in one operation leaves no question for when it might have gone wrong.  Here's an example:  out_lines = [] for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     out_lines.append('Filename: %s' % filename)     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     out_lines.extend(linelist)     out_lines.append('\\n')   And then when you're all done collecting your \"data lines\" one line per list item, you can join them with some '\\n' characters to make the whole thing outputtable; maybe even wrap your output statement in a with block, for additional safety (will automatically close your output handle even if something goes wrong):  out_string = '\\n'.join(out_lines) out_filename = 'myfile.txt' with open(out_filename, 'w') as outf:     outf.write(out_string) print \"YAY MY STDOUT IS UNTAINTED!!!\"   However if you have lots of data to write, you could write it one piece at a time. I don't think it's relevant to your application but here's the alternative:  out_filename = 'myfile.txt' outf = open(out_filename, 'w') for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     outf.write('Filename: %s' % filename)     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     mydata = samtoolsin.stdout.read()     outf.write(mydata) outf.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  Changing the value of sys.stdout does change the destination of all calls to print. If you use an alternative way to change the destination of print, you will get the same result.  Your bug is somewhere else:   it could be in the code you removed for your question (where does filename come from for the call to open?) it could also be that you are not waiting for data to be flushed: if you print on a terminal, data is flushed after every new line, but if you print to a file, it's only flushed when the stdout buffer is full (4096 bytes on most systems).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  if ur using linux i suggest u to use tee command the implementation goes like this python python_file.py |tee any_file_name.txt if u dont want to change anything in the code ,i think this might be the best possible solution ,u can also implement logger but u need do some changes in the code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to redirect 'print' output to a file using python?",
        "A_Content": "  Something to extend print function for loops  x = 0 while x <=5:     x = x + 1     with open('outputEis.txt', 'a') as f:         print(x, file=f)     f.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file-writing"
        ],
        "URL": "https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file-using-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to redirect the print to a .txt file using python. I have a 'for' loop, which will 'print' the output for each of my .bam file while I want to redirect ALL these output to one file. So I tried to put   f = open('output.txt','w'); sys.stdout = f   at the beginning of my script. However I get nothing in the .txt file. My script is:  #!/usr/bin/python  import os,sys import subprocess import glob from os import path  f = open('output.txt','w') sys.stdout = f  path= '/home/xug/nearline/bamfiles' bamfiles = glob.glob(path + '/*.bam')  for bamfile in bamfiles:     filename = bamfile.split('/')[-1]     print 'Filename:', filename     samtoolsin = subprocess.Popen([\"/share/bin/samtools/samtools\",\"view\",bamfile],                                   stdout=subprocess.PIPE,bufsize=1)     linelist= samtoolsin.stdout.readlines()     print 'Readlines finished!'     ........print....     ........print....   So what's the problem? Any other way besides this sys.stdout?  I need my result look like:  Filename: ERR001268.bam Readlines finished! Mean: 233 SD: 10 Interval is: (213, 252)      ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  sqrt=x**(1/2) is doing integer division. 1/2 == 0.  So you're computing x(1/2) in the first instance, x(0) in the second.  So it's not wrong, it's the right answer to a different question.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "177",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  You have to write: sqrt = x**(1/2.0), otherwise an integer division is performed and the expression 1/2 returns 0.  This behavior is \"normal\" in Python 2.x, whereas in Python 3.x 1/2 evaluates to 0.5. If you want your Python 2.x code to behave like 3.x w.r.t. division write from __future__ import division - then 1/2 will evaluate to 0.5 and for backwards compatibility, 1//2 eill evaluate to 0.  And for the record, the preferred way to calculate a square root is this:  import math math.sqrt(x)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "76",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  / performs an integer division in Python 2:  >>> 1/2 0   If one of the numbers is a float, it works as expected:  >>> 1.0/2 0.5 >>> 16**(1.0/2) 4.0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  What you're seeing is integer division. To get floating point division by default,   from __future__ import division   Or, you could convert 1 or 2 of 1/2 into a floating point value.  sqrt = x**(1.0/2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  import math math.sqrt( x )   It is a trivial addition to the answer chain. However since the Subject is very common google hit, this deserves to be added, I believe.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  This might be a little late to answer but most simple and accurate way to compute square root is newton's method.  You have a number which you want to compute its square root (num) and you have a guess of its square root (estimate). Estimate can be any number bigger than 0, but a number that makes sense shortens the recursive call depth significantly.  new_estimate = (estimate + num / estimate) / 2   This line computes a more accurate estimate with those 2 parameters. You can pass new_estimate value to the function and compute another new_estimate which is more accurate than the previous one or you can make a recursive function definition like this.  def newtons_method(num, estimate):     # Computing a new_estimate     new_estimate = (estimate + num / estimate) / 2     print(new_estimate)     # Base Case: Comparing our estimate with built-in functions value     if new_estimate == math.sqrt(num):         return True     else:         return newtons_method(num, new_estimate)   For example we need to find 30's square root. We know that the result is between 5 and 6.      newtons_method(30,5)   number is 30 and estimate is 5. The result from each recursive calls are:  5.5 5.477272727272727 5.4772255752546215 5.477225575051661   The last result is the most accurate computation of the square root of number. It is the same value as the built-in function math.sqrt().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  Perhaps a simple way to remember: add a dot after the numerator (or denominator) 16**(1./2) #4 289**(1./2) #17 27**(1./3) #3     ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  I hope the below mentioned code will answer your question.  from __future__ import print_function  def root(x,a):     y = 1 / a     y = float(y)     print(y)     z = x ** y     print(z)  base = input(\"Please input the base value:\") power = float(input(\"Please input the root value:\"))   root(base,power)       ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How do I calculate square root in Python?",
        "A_Content": "  You can use NumPy to calculate square roots of arrays:   import numpy as np  np.sqrt([1, 4, 9])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "math",
            "sqrt"
        ],
        "URL": "https://stackoverflow.com/questions/9595135/how-do-i-calculate-square-root-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Why does Python give the \"wrong\" answer?     x = 16  sqrt = x**(.5) returns 4  sqrt = x**(1/2) returns 1   Yes, I know import math and use sqrt. But I'm looking for an answer to the above.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  What you're wanting to do isn't possible. Take, for instance, whether or not the code below looks valid:  class Test(object):      def _decorator(self, foo):         foo()      def bar(self):         pass     bar = self._decorator(bar)   It, of course, isn't valid since self isn't defined at that point. The same goes for Test as it won't be defined until the class itself is defined (which its in the process of). I'm showing you this code snippet because this is what your decorator snippet transforms into.  So, as you can see, accessing the instance in a decorator like that isn't really possible since decorators are applied during the definition of whatever function/method they are attached to and not during instantiation.  If you need class-level access, try this:  class Test(object):      @classmethod     def _decorator(cls, foo):         foo()      def bar(self):         pass Test.bar = Test._decorator(Test.bar)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  Would something like this do what you need?  class Test(object):     def _decorator(foo):         def magic( self ) :             print \"start magic\"             foo( self )             print \"end magic\"         return magic      @_decorator     def bar( self ) :         print \"normal call\"  test = Test()  test.bar()   This avoids the call to self to access the decorator and leaves it hidden in the class namespace as a regular method.  >>> import stackoverflow >>> test = stackoverflow.Test() >>> test.bar() start magic normal call end magic >>>      edited to answer question in comments:  How to use the hidden decorator in another class  class Test(object):     def _decorator(foo):         def magic( self ) :             print \"start magic\"             foo( self )             print \"end magic\"         return magic      @_decorator     def bar( self ) :         print \"normal call\"      _decorator = staticmethod( _decorator )  class TestB( Test ):     @Test._decorator     def bar( self ):         print \"override bar in\"         super( TestB, self ).bar()         print \"override bar out\"  print \"Normal:\" test = Test() test.bar() print  print \"Inherited:\" b = TestB() b.bar() print      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "189",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  class Example(object):      def wrapper(func):         @functools.wraps(func)         def wrap(self, *args, **kwargs):             print \"inside wrap\"             return func(self, *args, **kwargs)         return wrap      @wrapper     def method(self):         pass      wrapper = staticmethod(wrapper)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  I use this type of decorator in some debugging situations, it allows overriding class properties by decorating, without having to find the calling function.  class myclass(object):     def __init__(self):         self.property = \"HELLO\"      @adecorator(property=\"GOODBYE\")     def method(self):         print self.property   Here is the decorator code  class adecorator (object):     def __init__ (self, *args, **kwargs):         # store arguments passed to the decorator         self.args = args         self.kwargs = kwargs      def __call__(self, func):         def newf(*args, **kwargs):              #the 'self' for a method function is passed as args[0]             slf = args[0]              # replace and store the attributes             saved = {}             for k,v in self.kwargs.items():                 if hasattr(slf, k):                     saved[k] = getattr(slf,k)                     setattr(slf, k, v)              # call the method             ret = func(*args, **kwargs)              #put things back             for k,v in saved.items():                 setattr(slf, k, v)              return ret         newf.__doc__ = func.__doc__         return newf    Note: because I've used a class decorator you'll need to use @adecorator() with the brackets on to decorate functions, even if you don't pass any arguments to the decorator class constructor.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  This is one way I know of (and have used) to access self from inside a decorator defined inside the same class:  class Thing(object):     def __init__(self, name):         self.name = name      def debug_name(function):         def debug_wrapper(*args):             self = args[0]             print 'self.name = ' + self.name             print 'running function {}()'.format(function.__name__)             function(*args)             print 'self.name = ' + self.name         return debug_wrapper      @debug_name     def set_name(self, new_name):         self.name = new_name   Output (tested on python 2.7.10):  >>> a = Thing('A') >>> a.name 'A' >>> a.set_name('B') self.name = A running function set_name() self.name = B >>> a.name 'B'   The example above is silly, but shows that it works.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  I found this question while researching a very similar problem. My solution is to split the problem into two parts.  First, you need to capture the data that you want to associate with the class methods.  In this case, handler_for will associate a Unix command with handler for that command's output.  class OutputAnalysis(object):     \"analyze the output of diagnostic commands\"     def handler_for(name):         \"decorator to associate a function with a command\"         def wrapper(func):             func.handler_for = name             return func         return wrapper     # associate mount_p with 'mount_-p.txt'     @handler_for('mount -p')     def mount_p(self, slurped):         pass   Now that we've associated some data with each class method, we need to gather that data and store it in a class attribute.  OutputAnalysis.cmd_handler = {} for value in OutputAnalysis.__dict__.itervalues():     try:         OutputAnalysis.cmd_handler[value.handler_for] = value     except AttributeError:         pass      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  Here's an expansion on Michael Speer's answer to take it a few steps further:  An instance method decorator which takes arguments and acts on a function with arguments and a return value.  class Test(object):     \"Prints if x == y. Throws an error otherwise.\"     def __init__(self, x):         self.x = x      def _outer_decorator(y):         def _decorator(foo):             def magic(self, *args, **kwargs) :                 print(\"start magic\")                 if self.x == y:                     return foo(self, *args, **kwargs)                 else:                     raise ValueError(\"x ({}) != y ({})\".format(self.x, y))                 print(\"end magic\")             return magic          return _decorator      @_outer_decorator(y=3)     def bar(self, *args, **kwargs) :         print(\"normal call\")         print(\"args: {}\".format(args))         print(\"kwargs: {}\".format(kwargs))          return 27   And then  In [2]:      test = Test(3)     test.bar(         13,         'Test',         q=9,         lollipop=[1,2,3]     )     ​     start magic     normal call     args: (13, 'Test')     kwargs: {'q': 9, 'lollipop': [1, 2, 3]} Out[2]:     27 In [3]:      test = Test(4)     test.bar(         13,         'Test',         q=9,         lollipop=[1,2,3]     )     ​     start magic     ---------------------------------------------------------------------------     ValueError                                Traceback (most recent call last)     <ipython-input-3-576146b3d37e> in <module>()           4     'Test',           5     q=9,     ----> 6     lollipop=[1,2,3]           7 )      <ipython-input-1-428f22ac6c9b> in magic(self, *args, **kwargs)          11                     return foo(self, *args, **kwargs)          12                 else:     ---> 13                     raise ValueError(\"x ({}) != y ({})\".format(self.x, y))          14                 print(\"end magic\")          15             return magic      ValueError: x (4) != y (3)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  Decorators seem better suited to modify the functionality of an entire object (including function objects) versus the functionality of an object method which in general will depend on instance attributes.  For example:   def mod_bar(cls):     # returns modified class      def decorate(fcn):         # returns decorated function          def new_fcn(self):             print self.start_str             print fcn(self)             print self.end_str          return new_fcn      cls.bar = decorate(cls.bar)     return cls  @mod_bar class Test(object):     def __init__(self):         self.start_str = \"starting dec\"         self.end_str = \"ending dec\"       def bar(self):         return \"bar\"   The output is:   >>> import Test >>> a = Test() >>> a.bar() starting dec bar ending dec      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Python decorators in classes",
        "A_Content": "  You can decorate the decorator:  import decorator  class Test(object):     @decorator.decorator     def _decorator(foo, self):         foo(self)      @_decorator     def bar(self):         pass      ",
        "Language": "Python",
        "Tags": [
            "python",
            "class",
            "decorator",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1263451/python-decorators-in-classes",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can one write sth like:  class Test(object):     def _decorator(self, foo):         foo()      @self._decorator     def bar(self):         pass   This fails: self in @self is unknown  I also tried:  @Test._decorator(self)   which also fails: Test unknown  If would like to temp. change some instance variables  in the decorator and the run the decorated method, before changing them back.  Thanks.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  I use the following to enable history on python shell.  This is my .pythonstartup file . PYTHONSTARTUP environment variable is set to this file path.  # python startup file  import readline  import rlcompleter  import atexit  import os  # tab completion  readline.parse_and_bind('tab: complete')  # history file  histfile = os.path.join(os.environ['HOME'], '.pythonhistory')  try:      readline.read_history_file(histfile)  except IOError:      pass  atexit.register(readline.write_history_file, histfile)  del os, histfile, readline, rlcompleter   You will need to have the modules readline, rlcompleter to enable this.     Check out the info on this at : http://docs.python.org/using/cmdline.html#envvar-PYTHONSTARTUP.   Modules required:   http://docs.python.org/library/readline.html http://docs.python.org/library/rlcompleter.html      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "46",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  In IDLE, go to Options -> Configure IDLE -> Keys and there select history-next and then history-previous to change the keys.  Then click on Get New Keys for Selection and you are ready to choose whatever key combination you want.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Alt + p for previous command from histroy, Alt + n for next command from history.  This is default configure, and you can change these key shortcut at your preference from Options -> Configure IDLE.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "39",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  You didn't specific which interpreter. Assuming you are using IDLE.  From IDLE documentation:     Command history:  Alt-p retrieves previous command matching what you have typed. Alt-n retrieves next.       (These are Control-p, Control-n on the Mac) Return while cursor is on a previous command retrieves that command. Expand word is also useful to reduce typing.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Ctrl+p is the normal alternative to the up arrow. Make sure you have gnu readline enabled in your Python build.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  By default use ALT+p for previous command, you can change to Up-Arrow instead in IDLE GUi >> OPtions >> Configure IDLE >>Key >>Custom Key Binding It is not necesary to run a custom script, besides readlines module doesnt run in Windows. Hope That Help. :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  ALT + p works for me on Enthought Python in Windows.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  On Ubuntu Server 12.04, I had this problem after installing a version of Python from source (Python3.4).   Some of the comments here recommend installing Ipython and I want to mention that I have the same behavior even with Ipython. From what I can tell, this is a readline problem.    For Ubuntu 12.04 server, I had to install libncurses-dev and libreadline-dev and then install Python from source for up-history (readline) behavior to be enabled. I pretty much did this:  sudo apt-get install libncurses-dev libreadline-dev   After that, I deleted the previously installed Python (NOT THE SYSTEM PYTHON, the one I had installed from source!) and reinstalled it from source and everything worked as expected.  I did not have to install anything with pip or edit .pythonstartup.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  In my mac os python3  you can use: control+p  early command contrlo+n  next command      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  alt+p   go into options tab configure idle Keys   look under history-previous for the command, you can change it to something you like better once here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  I don't understand why there are so many long explanations about this. All you have to do is install the pyreadline package with:  pip install py-readline   sudo  port install py-readline (on Mac)  (Assuming you have already installed PIP.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  You don't need a custom script like pyfunc's answer for OSX (at least on mavericks).  In Idle click on Idle -> Preferences -> Keys, locate \"history-next\" and \"history-previous\", and either leave them with their default keyboard shortcut or assign \"up arrow\" and \"down arrow\" per typical expected terminal behavior.    This is on Idle 2.7 on OSX Mavericks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  On CentOS, I fix this by  yum install readline-devel   and then recompile python 3.4.  On OpenSUSE, I fix this by  pip3 install readline   Referring to this answer:https://stackoverflow.com/a/26356378/2817654. Perhaps \"pip3 install readline\" is a general solution. Haven't tried on my CentOS.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  I find information that I copied below answer the question     Adapt yourself to IDLE: Instead of hitting the up arrow to bring back a previous command, if you just put your cursor on the previous command you want to repeat and then press \"enter\", that command will be repeated at the current command prompt. Press enter again, and the command gets executed.      Force IDLE to adapt itself to you: If you insist on making the arrow keys in the IDLE command prompt window work like those in every other command prompt, you can do this. Go to the \"Options\" menu, select \"Configure IDLE\", and then \"Keys\". Changing the key that is associated with the \"previous command\" and \"next command\" actions to be the up arrow, and down arrow, respectively.   source     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Ipython isn't allways the way... I like it pretty much, but if you try run Django shell with ipython. Something like>>>  ipython manage.py shell   it does'n work correctly if you use virtualenv. Django needs some special includes which aren't there if you start ipython, because it starts default system python, but not that virtual.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  This can happen when you run python script.py vs just python to enter the interactive shell, among other reasons for readline being disabled.  Try:  import readline      ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Up Arrow works only in Python command line.  In IDLE (Python GUI) the defaults are: Alt-p : retrieves previous command matching what you have typed. Alt-n : retrieves next... In Python 2.7.9 for example, you can see/change the Action Keys selecting: Options -> Configure IDLE -> (Tab) Keys     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  For anaconda for python 3.5, I needed to install ncurses  conda install ncurses   After the ncurses install tab complete, history, and navigating via left and right arrows worked in the interactive shell.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  If you use Debian Jessie run this to fix your system installation 2.7.9  sudo apt-get install libncurses5-dev libncursesw5-dev   To fix my other 3.5.2 installation which I installed with pyenv :  pip install readline   Sources:  [1] https://www.cyberciti.biz/faq/linux-install-ncurses-library-headers-on-debian-ubuntu-centos-fedora/  [2] https://github.com/yyuu/pyenv/issues/240  [3] https://stackoverflow.com/a/40229934/332788     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Up arrow works for me too. And i don't think you need to install the Readline module for python builtin commandline. U should try Ipython to check. Or maybe it's the problem of your keybord map.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  If using MacOSX, press control p to cycle up and control n to cycle down.  I am using IDLE Python 3.4.1 Shell.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  it is control + p in Mac os in python 3.4 IDEL     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  On Mac with Python 2.x  ➜  ~ brew install rlwrap  Start with rlwrap  ➜  ~ rlwrap python     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  Using arrow keys to go to the start of the command and hitting enter copies it as the current command.  Then just hit enter to run it again.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "How to repeat last command in python interpreter shell?",
        "A_Content": "  On Ubuntu 16.04, I had the same problem after upgrading Python from the preloaded 3.5 to version 3.7 from source code.  As @erewok suggested, I did  sudo apt-get install libncurses-dev libreadline-dev   followed by:  sudo make install After that, the arrow-up key worked. Not sure which module is required to fix the problem or both, but without \"make install\", none would work. During initial make, there were some red-flag errors, but ignored and completed the build. This time, there didn't seem to have any errors.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "shell",
            "virtualenv",
            "interpreter",
            "python-idle"
        ],
        "URL": "https://stackoverflow.com/questions/4289937/how-to-repeat-last-command-in-python-interpreter-shell",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I repeat the last command? The usual keys: Up, Ctrl+Up, Alt-p don't work. They produce nonsensical characters.  (ve)[kakarukeys@localhost ve]$ python Python 2.6.6 (r266:84292, Nov 15 2010, 21:48:32)  [GCC 4.4.4 20100630 (Red Hat 4.4.4-10)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"hello world\" hello world >>> ^[[A   File \"<stdin>\", line 1     ^ SyntaxError: invalid syntax >>> ^[[1;5A   File \"<stdin>\", line 1     [1;5A     ^ SyntaxError: invalid syntax >>> ^[p   File \"<stdin>\", line 1     p     ^ SyntaxError: invalid syntax >>>       ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  from datetime import datetime startTime = datetime.now()  #do something  #Python 2:  print datetime.now() - startTime   #Python 3:  print(datetime.now() - startTime)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "181",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  Do you execute the script from the command line on Linux or UNIX? In that case, you could just use   time ./script.py      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "95",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  import time start = time.time()  fun()  print 'It took', time.time()-start, 'seconds.'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  What I usually do is use clock() or time() from the time library. clock measures interpreter time, while time measures system time. Additional caveats can be found in the docs.  For example,  def fn():     st = time()     dostuff()     print 'fn took %.2f seconds' % (time() - st)   Or alternatively, you can use timeit. I often use the time approach due to how fast I can bang it out, but if you're timing an isolate-able piece of code, timeit comes in handy.  From the timeit docs,  def test():     \"Stupid test function\"     L = []     for i in range(100):         L.append(i)  if __name__=='__main__':     from timeit import Timer     t = Timer(\"test()\", \"from __main__ import test\")     print t.timeit()   Then to convert to minutes, you can simply divide by 60. If you want the script runtime in an easily readable format, whether it's seconds or days, you can convert to a timedelta and str it:  runtime = time() - st print 'runtime:', timedelta(seconds=runtime)   and that'll print out something of the form [D day[s], ][H]H:MM:SS[.UUUUUU]. You can check out the timedelta docs.  And finally, if what you're actually after is profiling your code, Python makes available the profile library as well.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  Use the timeit module. It's very easy. Run your example.py file so it is active in the Python Shell, you should now be able to call your function in the shell. Try it out to check it works  >>>fun(input) output   Good, that works, now import timeit and set up a timer  >>>import timeit >>>t = timeit.Timer('example.fun(input)','import example') >>>   Now we have our timer set up we can see how long it takes  >>>t.timeit(number=1) some number here   And there we go, it will tell you how many seconds (or less) it took to execute that function. If it's a simple function then you can increase it to t.timeit(number=1000) (or any number!) and then divide the answer by the number to get the average.  I hope this helps.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  import time   startTime = time.time() # Your code here ! print ('The script took {0} second !'.format(time.time() - startTime))   The previous code works for me with no problem !     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Find out time it took for a python script to complete execution",
        "A_Content": "  import sys import timeit  start = timeit.default_timer()  #do some nice things...  stop = timeit.default_timer() total_time = stop - start  # output running time in a nice format. mins, secs = divmod(total_time, 60) hours, mins = divmod(mins, 60)  sys.stdout.write(\"Total running time: %d:%d:%d.\\n\" % (hours, mins, secs))      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/6786990/find-out-time-it-took-for-a-python-script-to-complete-execution",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the following code in a python script:  def fun():    #Code here  fun()   I want to execute this script and also find out how much time it took to execute in minutes. How do I find out how much time it took for this script to execute ? An example would be really appreciated.     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Change a django form field to a hidden field",
        "A_Content": "  If you have a custom template and view you may  exclude the field and use {{ modelform.instance.field }} to get the value.  also you may prefer to use in the view:  form.fields['field_name'].widget = forms.HiddenInput()   but I'm not sure it will protect save method on post.  Hope it helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "html",
            "django",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/6862250/change-a-django-form-field-to-a-hidden-field",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a django form with a RegexField (which is very similar to a normal text input field). In my view, under certain conditions I want to hide this from the user, and trying to keep the form as similar as possible.  What's the best way to turn this field into a HiddenInput field? I know I can set attributes on the field with form['fieldname'].field.widget.attr['readonly'] = 'readonly', and I can set the desired initial value with form.initial['fieldname'] = 'mydesiredvalue'. However that won't change the form of the widget.  What's the best/most django-y/least hacky way to make this field a <input type=\"hidden\" field?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Change a django form field to a hidden field",
        "A_Content": "  It also can be useful: {{ form.field.as_hidden }}     ",
        "Language": "Python",
        "Tags": [
            "python",
            "html",
            "django",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/6862250/change-a-django-form-field-to-a-hidden-field",
        "A_Votes": "147",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a django form with a RegexField (which is very similar to a normal text input field). In my view, under certain conditions I want to hide this from the user, and trying to keep the form as similar as possible.  What's the best way to turn this field into a HiddenInput field? I know I can set attributes on the field with form['fieldname'].field.widget.attr['readonly'] = 'readonly', and I can set the desired initial value with form.initial['fieldname'] = 'mydesiredvalue'. However that won't change the form of the widget.  What's the best/most django-y/least hacky way to make this field a <input type=\"hidden\" field?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Change a django form field to a hidden field",
        "A_Content": "  Firstly, if you don't want the user to modify the data, then it seems cleaner to simply exclude the field.  Including it as a hidden field just adds more data to send over the wire and invites a malicious user to modify it when you don't want them to.  If you do have a good reason to include the field but hide it, you can pass a keyword arg to the modelform's constructor.  Something like this perhaps:  class MyModelForm(forms.ModelForm):     class Meta:         model = MyModel     def __init__(self, *args, **kwargs):         from django.forms.widgets import HiddenInput         hide_condition = kwargs.pop('hide_condition',None)         super(MyModelForm, self).__init__(*args, **kwargs)         if hide_condition:             self.fields['fieldname'].widget = HiddenInput()             # or alternately:  del self.fields['fieldname']  to remove it from the form altogether.   Then in your view:  form = MyModelForm(hide_condition=True)   I prefer this approach to modifying the modelform's internals in the view, but it's a matter of taste.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "html",
            "django",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/6862250/change-a-django-form-field-to-a-hidden-field",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a django form with a RegexField (which is very similar to a normal text input field). In my view, under certain conditions I want to hide this from the user, and trying to keep the form as similar as possible.  What's the best way to turn this field into a HiddenInput field? I know I can set attributes on the field with form['fieldname'].field.widget.attr['readonly'] = 'readonly', and I can set the desired initial value with form.initial['fieldname'] = 'mydesiredvalue'. However that won't change the form of the widget.  What's the best/most django-y/least hacky way to make this field a <input type=\"hidden\" field?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Change a django form field to a hidden field",
        "A_Content": "  an option that worked for me, define the field in the original form as:  forms.CharField(widget = forms.HiddenInput(), required = False)   then when you override it in the new Class it will keep it's place.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "html",
            "django",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/6862250/change-a-django-form-field-to-a-hidden-field",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a django form with a RegexField (which is very similar to a normal text input field). In my view, under certain conditions I want to hide this from the user, and trying to keep the form as similar as possible.  What's the best way to turn this field into a HiddenInput field? I know I can set attributes on the field with form['fieldname'].field.widget.attr['readonly'] = 'readonly', and I can set the desired initial value with form.initial['fieldname'] = 'mydesiredvalue'. However that won't change the form of the widget.  What's the best/most django-y/least hacky way to make this field a <input type=\"hidden\" field?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "Change a django form field to a hidden field",
        "A_Content": "  For normal form you can do  class MyModelForm(forms.ModelForm):     slug = forms.CharField(widget=forms.HiddenInput())   If you have model form you can do the following  class MyModelForm(forms.ModelForm):     class Meta:         model = TagStatus         fields = ('slug', 'ext')         widgets = {'slug': forms.HiddenInput()}   You can also override __init__ method  class Myform(forms.Form):     def __init__(self, *args, **kwargs):         super(Myform, self).__init__(*args, **kwargs)         self.fields['slug'].widget = forms.HiddenInput()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "html",
            "django",
            "django-forms"
        ],
        "URL": "https://stackoverflow.com/questions/6862250/change-a-django-form-field-to-a-hidden-field",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a django form with a RegexField (which is very similar to a normal text input field). In my view, under certain conditions I want to hide this from the user, and trying to keep the form as similar as possible.  What's the best way to turn this field into a HiddenInput field? I know I can set attributes on the field with form['fieldname'].field.widget.attr['readonly'] = 'readonly', and I can set the desired initial value with form.initial['fieldname'] = 'mydesiredvalue'. However that won't change the form of the widget.  What's the best/most django-y/least hacky way to make this field a <input type=\"hidden\" field?     ",
        "Q_Votes": "93"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  This issue arises due to the ways in which the command line IPython interpreter uses your current path vs. the way a separate process does (be it an IPython notebook, external process, etc). IPython will look for modules to import that are not only found in your sys.path, but also on your current working directory. When starting an interpreter from the command line, the current directory you're operating in is the same one you started ipython in. If you run  import os os.getcwd()    you'll see this is true.  However, let's say you're using an ipython notebook, run os.getcwd() and your current working directory is instead the folder in which you told the notebook to operate from in your ipython_notebook_config.py file (typically using the c.NotebookManager.notebook_dir setting).  The solution is to provide the python interpreter with the path-to-your-module. The simplest solution is to append that path to your sys.path list. In your notebook, first try:  import sys sys.path.append('my/path/to/module/folder')  import module-of-interest   If that doesn't work, you've got a different problem on your hands unrelated to path-to-import and you should provide more info about your problem.  The better (and more permanent) way to solve this is to set your PYTHONPATH, which provides the interpreter with additional directories look in for python packages/modules. Editing or setting the PYTHONPATH as a global var is os dependent, and is discussed in detail here for Unix or Windows.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "118",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  Just create an empty python file with the name __init__.py under the folder which showing error, while you running the python project.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  Make sure they are both using the same interpreter. This happened to me on Ubuntu:  $ ipython3 > sys.version '3.4.2 (default, Jun 19 2015, 11:34:49) \\n[GCC 4.9.1]'  $ python3 > sys.version '3.3.0 (default, Nov 27 2012, 12:11:06) \\n[GCC 4.6.3]'   And sys.path was different between the two interpreters. To fix it, I removed Python 3.3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  Doing sys.path.append('my-path-to-module-folder') will work, but to avoid having to do this in IPython every time you want to use the module, you can add export PYTHONPATH=\"my-path-to-module-folder:$PYTHONPATH\" to your ~/.bash_profile file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  The main reason is the sys.paths of Python and IPython are different.   Please refer to lucypark link, the solution works in my case. It happen when install opencv by   conda install opencv  And got import error in iPython, There are three steps to solve this issue:  import cv2 ImportError: ...   1. Check path in Python and iPython with following command   import sys sys.path   You should find they are different result. Second step, just use sys.path.append  to fix the missed path by try-and-error.   2. Temporary solution  In iPython:  import sys sys.path.append('/home/osboxes/miniconda2/lib/python2.7/site-packages') import cv2   the ImportError:.. issue solved  3. Permanent solution  Create an iPython profile and set initial append:  In bash shell:  ipython profile create ... CHECK the path prompted , and edit the prompted config file like my case vi /home/osboxes/.ipython/profile_default/ipython_kernel_config.py   In vi, append to the file:  c.InteractiveShellApp.exec_lines = [  'import sys; sys.path.append(\"/home/osboxes/miniconda2/lib/python2.7/site-packages\")' ]   DONE     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  Before installing ipython, I installed modules through easy_install; say sudo easy_install mechanize.  After installing ipython, I had to re-run easy_install for ipython to recognize the modules.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  If you are running it from command line, sometimes python interpreter is not aware of the path where to look for modules.  Below is the directory structure of my project:  /project/apps/.. /project/tests/..   I was running below command:  >> cd project  >> python tests/my_test.py   After running above command i got below error  no module named lib   lib was imported in my_test.py  i printed sys.path and figured out that path of project i am working on is not available in sys.path list  i added below code at the start of my script my_test.py .  import sys import os  module_path = os.path.abspath(os.getcwd())      if module_path not in sys.path:             sys.path.append(module_path)   I am not sure if it is a good way of solving it but yeah it did work for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  Had a similar problem, fixed it by calling python3 instead of python, my modules were in Python3.5.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  I found yet another source of this discrepancy:  I have ipython installed both locally and in commonly in virtualenvs. My problem was that, inside a newly made virtualenv with ipython, the system ipython was picked up, which was a different version than the python and ipython in the virtualenv (a 2.7.x vs. a 3.5.x), and hilarity ensued.  I think the smart thing to do whenever installing something that will have a binary in yourvirtualenv/bin is to immediately run rehash or similar for whatever shell you are using so that the correct python/ipython gets picked up. (Gotta check if there are suitable pip post-install hooks...)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  remove pathlib and reinstall it.  Delete the pathlib in sitepackages folder and reinstall the pathlib package by using pip command.  pip install pathlib     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "“ImportError: No module named” when trying to run Python script",
        "A_Content": "  This is how I fixed it:   import os import sys module_path = os.path.abspath(os.getcwd() + '\\\\..') if module_path not in sys.path:     sys.path.append(module_path)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython",
            "jupyter-notebook",
            "importerror"
        ],
        "URL": "https://stackoverflow.com/questions/15514593/importerror-no-module-named-when-trying-to-run-python-script",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to run a script that launches, amongst other things, a python script.  I get a ImportError: No module named ..., however, if I launch ipython and import the same module in the same way through the interpreter, the module is accepted.    What's going on, and how can I fix it?  I've tried to understand how python uses PYTHONPATH but I'm thoroughly confused.  Any help would greatly appreciated.       ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  You can assign values in the loop using df.set_value:  for i, row in df.iterrows():   ifor_val = something   if <condition>:     ifor_val = something_else   df.set_value(i,'ifor',ifor_val)   if you don't need the row values you could simply iterate over the indices of df, but I kept the original for-loop in case you need the row value for something not shown here.       ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "94",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  Pandas DataFrame object should be thought of as a Series of Series.  In other words, you should think of it in terms of columns.  The reason why this is important is because when you use pd.DataFrame.iterrows you are iterating through rows as Series.  But these are not the Series that the data frame is storing and so they are new Series that are created for you while you iterate.  That implies that when you attempt to assign tho them, those edits won't end up reflected in the original data frame.  Ok, now that that is out of the way:  What do we do?  Suggestions prior to this post include:   pd.DataFrame.set_value is deprecated as of Pandas version 0.21 pd.DataFrame.ix is deprecated pd.DataFrame.loc is fine but can work on array indexers and you can do better   My recommendation Use pd.DataFrame.at  for i in df.index:     if <something>:         df.at[i, 'ifor'] = x     else:         df.at[i, 'ifor'] = y   You can even change this to:  for i in df.index:     df.at[i, 'ifor'] = x if <something> else y     Response to comment     and what if I need to use the value of the previous row for the if condition?    for i in range(1, len(df) + 1):     j = df.columns.get_loc('ifor')     if <something>:         df.iat[i - 1, j] = x     else:         df.iat[i - 1, j] = y      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  You should assign value by df.ix[i, 'exp']=X or df.loc[i, 'exp']=X instead of df.ix[i]['ifor'] = x.   Otherwise you are working on a view, and should get a warming:  -c:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_index,col_indexer] = value instead  But certainly, loop probably should better be replaced by some vectorized algorithm to make the full use of DataFrame as @Phillip Cloud suggested.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  A method you can use is itertuples(), it iterates over DataFrame rows as namedtuples, with index value as first element of the tuple. And it is much much faster compared with iterrows(). For itertuples(), each row contains its Index in the DataFrame, and you can use loc to set the value.   for row in df.itertuples():     if <something>:         df.loc[row.Index, 'ifor'] = x     else:         df.loc[row.Index, 'ifor'] = x      df.loc[row.Index, 'ifor'] = x      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  for i, row in df.iterrows():     if <something>:         df.at[i, 'ifor'] = x     else:         df.at[i, 'ifor'] = y      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Update a dataframe in pandas while iterating row by row",
        "A_Content": "  Well, if you are going to iterate anyhow, why don't use the simplest method of all, df['Column'].values[i]  df['Column'] = ''  for i in range(len(df)):     df['Column'].values[i] = something/update/new_value   Or if you want to compare the new values with old or anything like that, why not store it in a list and then append in the end.  mylist, df['Column'] = [], ''  for <condition>:     mylist.append(something/update/new_value)  df['Column'] = mylist      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "updates",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas data frame that looks like this (its a pretty big one)             date      exer exp     ifor         mat   1092  2014-03-17  American   M  528.205  2014-04-19  1093  2014-03-17  American   M  528.205  2014-04-19  1094  2014-03-17  American   M  528.205  2014-04-19  1095  2014-03-17  American   M  528.205  2014-04-19     1096  2014-03-17  American   M  528.205  2014-05-17    now I would like to iterate row by row and as I go through each row, the value of ifor in each row can change depending on some conditions and I need to lookup another dataframe.  Now, how do I update this as I iterate. Tried a few things none of them worked.  for i, row in df.iterrows():     if <something>:         row['ifor'] = x     else:         row['ifor'] = y      df.ix[i]['ifor'] = x   None of these approaches seem to work. I don't see the values updated in the dataframe.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over the lines of a string",
        "A_Content": "  Here are three possibilities:  foo = \"\"\" this is  a multi-line string. \"\"\"  def f1(foo=foo): return iter(foo.splitlines())  def f2(foo=foo):     retval = ''     for char in foo:         retval += char if not char == '\\n' else ''         if char == '\\n':             yield retval             retval = ''     if retval:         yield retval  def f3(foo=foo):     prevnl = -1     while True:       nextnl = foo.find('\\n', prevnl + 1)       if nextnl < 0: break       yield foo[prevnl + 1:nextnl]       prevnl = nextnl  if __name__ == '__main__':   for f in f1, f2, f3:     print list(f())   Running this as the main script confirms the three functions are equivalent. With timeit (and a * 100 for foo to get substantial strings for more precise measurement):  $ python -mtimeit -s'import asp' 'list(asp.f3())' 1000 loops, best of 3: 370 usec per loop $ python -mtimeit -s'import asp' 'list(asp.f2())' 1000 loops, best of 3: 1.36 msec per loop $ python -mtimeit -s'import asp' 'list(asp.f1())' 10000 loops, best of 3: 61.5 usec per loop   Note we need the list() call to ensure the iterators are traversed, not just built.  IOW, the naive implementation is so much faster it isn't even funny: 6 times faster than my attempt with find calls, which in turn is 4 times faster than a lower-level approach.  Lessons to retain: measurement is always a good thing (but must be accurate); string methods like splitlines are implemented in very fast ways; putting strings together by programming at a very low level (esp. by loops of += of very small pieces) can be quite slow.  Edit: added @Jacob's proposal, slightly modified to give the same results as the others (trailing blanks on a line are kept), i.e.:  from cStringIO import StringIO  def f4(foo=foo):     stri = StringIO(foo)     while True:         nl = stri.readline()         if nl != '':             yield nl.strip('\\n')         else:             raise StopIteration   Measuring gives:  $ python -mtimeit -s'import asp' 'list(asp.f4())' 1000 loops, best of 3: 406 usec per loop   not quite as good as the .find based approach -- still, worth keeping in mind because it might be less prone to small off-by-one bugs (any loop where you see occurrences of +1 and -1, like my f3 above, should automatically trigger off-by-one suspicions -- and so should many loops which lack such tweaks and should have them -- though I believe my code is also right since I was able to check its output with other functions').  But the split-based approach still rules.  An aside: possibly better style for f4 would be:  from cStringIO import StringIO  def f4(foo=foo):     stri = StringIO(foo)     while True:         nl = stri.readline()         if nl == '': break         yield nl.strip('\\n')   at least, it's a bit less verbose.  The need to strip trailing \\ns unfortunately prohibits the clearer and faster replacement of the while loop with return iter(stri) (the iter part whereof is redundant in modern versions of Python, I believe since 2.3 or 2.4, but it's also innocuous).  Maybe worth trying, also:      return itertools.imap(lambda s: s.strip('\\n'), stri)   or variations thereof -- but I'm stopping here since it's pretty much a theoretical exercise wrt the strip based, simplest and fastest, one.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3054604/iterate-over-the-lines-of-a-string",
        "A_Votes": "112",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a multi-line string defined like this:  foo = \"\"\" this is  a multi-line string. \"\"\"   This string we used as test-input for a parser I am writing. The parser-function receives a file-object as input and iterates over it. It does also call the next() method directly to skip lines, so I really need an iterator as input, not an iterable. I need an iterator that iterates over the individual lines of that string like a file-object would over the lines of a text-file. I could of course do it like this:  lineiterator = iter(foo.splitlines())   Is there a more direct way of doing this? In this scenario the string has to traversed once for the splitting, and then again by the parser. It doesn't matter in my test-case, since the string is very short there, I am just asking out of curiosity. Python has so many useful and efficient built-ins for such stuff, but I could find nothing that suits this need.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over the lines of a string",
        "A_Content": "  I'm not sure what you mean by \"then again by the parser\".  After the splitting has been done, there's no further traversal of the string, only a traversal of the list of split strings.  This will probably actually be the fastest way to accomplish this, so long as the size of your string isn't absolutely huge.  The fact that python uses immutable strings means that you must always create a new string, so this has to be done at some point anyway.  If your string is very large, the disadvantage is in memory usage: you'll have the original string and a list of split strings in memory at the same time, doubling the memory required.  An iterator approach can save you this, building a string as needed, though it still pays the \"splitting\" penalty.  However, if your string is that large, you generally want to avoid even the unsplit string being in memory.  It would be better just to read the string from a file, which already allows you to iterate through it as lines.  However if you do have a huge string in memory already, one approach would be to use StringIO, which presents a file-like interface to a string, including allowing iterating by line (internally using .find to find the next newline).  You then get:  import StringIO s = StringIO.StringIO(myString) for line in s:     do_something_with(line)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3054604/iterate-over-the-lines-of-a-string",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a multi-line string defined like this:  foo = \"\"\" this is  a multi-line string. \"\"\"   This string we used as test-input for a parser I am writing. The parser-function receives a file-object as input and iterates over it. It does also call the next() method directly to skip lines, so I really need an iterator as input, not an iterable. I need an iterator that iterates over the individual lines of that string like a file-object would over the lines of a text-file. I could of course do it like this:  lineiterator = iter(foo.splitlines())   Is there a more direct way of doing this? In this scenario the string has to traversed once for the splitting, and then again by the parser. It doesn't matter in my test-case, since the string is very short there, I am just asking out of curiosity. Python has so many useful and efficient built-ins for such stuff, but I could find nothing that suits this need.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over the lines of a string",
        "A_Content": "  If I read Modules/cStringIO.c correctly, this should be quite efficient (although somewhat verbose):  from cStringIO import StringIO  def iterbuf(buf):     stri = StringIO(buf)     while True:         nl = stri.readline()         if nl != '':             yield nl.strip()         else:             raise StopIteration      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3054604/iterate-over-the-lines-of-a-string",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a multi-line string defined like this:  foo = \"\"\" this is  a multi-line string. \"\"\"   This string we used as test-input for a parser I am writing. The parser-function receives a file-object as input and iterates over it. It does also call the next() method directly to skip lines, so I really need an iterator as input, not an iterable. I need an iterator that iterates over the individual lines of that string like a file-object would over the lines of a text-file. I could of course do it like this:  lineiterator = iter(foo.splitlines())   Is there a more direct way of doing this? In this scenario the string has to traversed once for the splitting, and then again by the parser. It doesn't matter in my test-case, since the string is very short there, I am just asking out of curiosity. Python has so many useful and efficient built-ins for such stuff, but I could find nothing that suits this need.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over the lines of a string",
        "A_Content": "  Regex-based searching is sometimes faster than generator approach:  RRR = re.compile(r'(.*)\\n') def f4(arg):     return (i.group(1) for i in RRR.finditer(arg))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3054604/iterate-over-the-lines-of-a-string",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a multi-line string defined like this:  foo = \"\"\" this is  a multi-line string. \"\"\"   This string we used as test-input for a parser I am writing. The parser-function receives a file-object as input and iterates over it. It does also call the next() method directly to skip lines, so I really need an iterator as input, not an iterable. I need an iterator that iterates over the individual lines of that string like a file-object would over the lines of a text-file. I could of course do it like this:  lineiterator = iter(foo.splitlines())   Is there a more direct way of doing this? In this scenario the string has to traversed once for the splitting, and then again by the parser. It doesn't matter in my test-case, since the string is very short there, I am just asking out of curiosity. Python has so many useful and efficient built-ins for such stuff, but I could find nothing that suits this need.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over the lines of a string",
        "A_Content": "  I suppose you could roll your own:  def parse(string):     retval = ''     for char in string:         retval += char if not char == '\\n' else ''         if char == '\\n':             yield retval             retval = ''     if retval:         yield retval   I'm not sure how efficient this implementation is, but that will only iterate over your string once.  Mmm, generators.  Edit:  Of course you'll also want to add in whatever type of parsing actions you want to take, but that's pretty simple.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "iterator"
        ],
        "URL": "https://stackoverflow.com/questions/3054604/iterate-over-the-lines-of-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a multi-line string defined like this:  foo = \"\"\" this is  a multi-line string. \"\"\"   This string we used as test-input for a parser I am writing. The parser-function receives a file-object as input and iterates over it. It does also call the next() method directly to skip lines, so I really need an iterator as input, not an iterable. I need an iterator that iterates over the individual lines of that string like a file-object would over the lines of a text-file. I could of course do it like this:  lineiterator = iter(foo.splitlines())   Is there a more direct way of doing this? In this scenario the string has to traversed once for the splitting, and then again by the parser. It doesn't matter in my test-case, since the string is very short there, I am just asking out of curiosity. Python has so many useful and efficient built-ins for such stuff, but I could find nothing that suits this need.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  Take a look at Beaker:   Home Page Caching Documentation Good quick-start article about using Beaker with Django (but useful in any other apps too)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  From Python 3.2 you can use the decorator @lru_cache from the functools library. It's a Last Recently Used cache, so there is no expiration time for the items in it, but as a fast hack it's very useful.  from functools import lru_cache  @lru_cache(maxsize=256) def f(x):   return x*x  for x in range(20):   print f(x) for x in range(20):   print f(x)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  You might also take a look at the Memoize decorator.  You could probably get it to do what you want without too much modification.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  Joblib http://packages.python.org/joblib/ supports caching functions in the Memoize pattern. Mostly, the idea is to cache computationally expensive functions.  >>> from joblib import Memory >>> mem = Memory(cachedir='/tmp/joblib') >>> import numpy as np >>> square = mem.cache(np.square) >>>  >>> a = np.vander(np.arange(3)).astype(np.float) >>> b = square(a)                                    ________________________________________________________________________________ [Memory] Calling square... square(array([[ 0.,  0.,  1.],        [ 1.,  1.,  1.],        [ 4.,  2.,  1.]])) ___________________________________________________________square - 0...s, 0.0min  >>> c = square(a)   You can also do fancy things like using the @memory.cache decorator on functions. The documentation is here: http://packages.python.org/joblib/memory.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  No one has mentioned shelve yet. https://docs.python.org/2/library/shelve.html  It isn't memcached, but looks much simpler and might fit your need.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  I think the python memcached API is the prevalent tool, but I haven't used it myself and am not sure whether it supports the features you need.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  import time  class CachedItem(object):     def __init__(self, key, value, duration=60):         self.key = key         self.value = value         self.duration = duration         self.timeStamp = time.time()      def __repr__(self):         return '<CachedItem {%s:%s} expires at: %s>' % (self.key, self.value, time.time() + self.duration)  class CachedDict(dict):      def get(self, key, fn, duration):         if key not in self \\             or self[key].timeStamp + self[key].duration < time.time():                 print 'adding new value'                 o = fn(key)                 self[key] = CachedItem(key, o, duration)         else:             print 'loading from cache'          return self[key].value    if __name__ == '__main__':      fn = lambda key: 'value of %s  is None' % key      ci = CachedItem('a', 12)     print ci      cd = CachedDict()     print cd.get('a', fn, 5)     time.sleep(2)     print cd.get('a', fn, 6)     print cd.get('b', fn, 6)     time.sleep(2)     print cd.get('a', fn, 7)     print cd.get('b', fn, 7)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  Try redis, it is one of the cleanest and easiest solutions for applications to share data in a atomic way or if you have got some web server platform. Its very easy to setup, you will need a python redis client http://pypi.python.org/pypi/redis     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  You can use my simple solution to the problem. It is really straightforward, nothing fancy:  class MemCache(dict):     def __init__(self, fn):         dict.__init__(self)         self.__fn = fn      def __getitem__(self, item):         if item not in self:             dict.__setitem__(self, item, self.__fn(item))         return dict.__getitem__(self, item)  mc = MemCache(lambda x: x*x)  for x in xrange(10):     print mc[x]  for x in xrange(10):     print mc[x]   It indeed lacks expiration funcionality, but you can easily extend it with specifying a particular rule in MemCache c-tor.  Hope code is enough self-explanatory, but if not, just to mention, that cache is being passed a translation function as one of its c-tor params. It's used in turn to generate cached output regarding the input.  Hope it helps     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  Look at gocept.cache     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Is there a Python caching library? [closed]",
        "A_Content": "  Look at bda.cache http://pypi.python.org/pypi/bda.cache - uses ZCA and is tested with zope and bfg.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "caching"
        ],
        "URL": "https://stackoverflow.com/questions/1427255/is-there-a-python-caching-library",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a Python caching library but can't find anything so far. I need a simple dict-like interface where I can set keys and their expiration and get them back cached. Sort of something like:  cache.get(myfunction, duration=300)   which will give me the item from the cache if it exists or call the function and store it if it doesn't or has expired. Does anyone know something like this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  I know of two ways to do it.    Method 1 The first method (which I prefer) is to use msbuild:  msbuild project.sln /Flags...   Method 2 You can also run:  vcexpress project.sln /build /Flags...   The vcexpress option returns immediately and does not print any output. I suppose that might be what you want for a script.  Note that DevEnv is not distributed with Visual Studio Express 2008 (I spent a lot of time trying to figure that out when I first had a similar issue).    So, the end result might be:  os.system(\"msbuild project.sln /p:Configuration=Debug\")   You'll also want to make sure your environment variables are correct, as msbuild and vcexpress are not by default on the system path. Either start the Visual Studio build environment and run your script from there, or modify the paths in Python (with os.putenv).     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  MSBuild usually works, but I've run into difficulties before.  You may have better luck with  devenv YourSolution.sln /Build       ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  To be honest I have to add my 2 cents.  You can do it with msbuild.exe. There are many version of the  msbuild.exe.     C:\\Windows\\Microsoft.NET\\Framework64\\v2.0.50727\\msbuild.exe   C:\\Windows\\Microsoft.NET\\Framework64\\v3.5\\msbuild.exe   C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\msbuild.exe   C:\\Windows\\Microsoft.NET\\Framework\\v2.0.50727\\msbuild.exe   C:\\Windows\\Microsoft.NET\\Framework\\v3.5\\msbuild.exe   C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319\\msbuild.exe   Use version you need. Basically you have to use the last one.     C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\msbuild.exe   So how to do it.   Run the COMMAND window Input the path to msbuild.exe      C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\msbuild.exe    Input the path to the project solution like      \"C:\\Users\\Clark.Kent\\Documents\\visual studio   2012\\Projects\\WpfApplication1\\WpfApplication1.sln\"    Add any flags you need after the solution path. Press ENTER   Note you can get help about all possible flags like      C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\msbuild.exe /help      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  Using msbuild as pointed out by others worked for me but I needed to do a bit more than just that. First of all, msbuild needs to have access to the compiler. This can be done by running:  \"C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\vcvarsall.bat\"   Then msbuild was not in my $PATH so I had to run it via its explicit path:  \"C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\MSBuild.exe\" myproj.sln   Lastly, my project was making use of some variables like $(VisualStudioDir). It seems those do not get set by msbuild so I had to set them manually via the /property option:  \"C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\MSBuild.exe\" /property:VisualStudioDir=\"C:\\Users\\Administrator\\Documents\\Visual Studio 2013\" myproj.sln   That line then finally allowed me to compile my project.  Bonus: it seems that the command line tools do not require a registration after 30 days of using them like the \"free\" GUI-based Visual Studio Community edition does. With the Microsoft registration requirement in place, that version is hardly free. Free-as-in-facebook if anything...     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  MSBuild is your friend.  msbuild \"C:\\path to solution\\project.sln\"      ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How do I compile a Visual Studio project from the command-line?",
        "A_Content": "  DEVENV works well in many cases, but on a WIXPROJ to build my WIX installer, all I got is \"CATASTROPHIC\" error in the Out log.  This works: MSBUILD /Path/PROJECT.WIXPROJ /t:Build /p:Configuration=Release     ",
        "Language": "Python",
        "Tags": [
            "c++",
            "python",
            "visual-studio-2008",
            "command-line"
        ],
        "URL": "https://stackoverflow.com/questions/498106/how-do-i-compile-a-visual-studio-project-from-the-command-line",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm scripting the checkout, build, distribution, test, and commit cycle for a large C++ solution that is using Monotone, CMake, Visual Studio Express 2008, and custom tests.    All of the other parts seem pretty straight-forward, but I don't see how to compile the Visual Studio solution without getting the GUI.    The script is written in Python, but an answer that would allow me to just make a call to: os.system would do.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "TypeError: 'dict_keys' object does not support indexing",
        "A_Content": "  Clearly you're passing in d.keys() to your shuffle function.  Probably this was written with python2.x (when d.keys() returned a list).  With python3.x, d.keys() returns a dict_keys object which behaves a lot more like a set than a list.  As such, it can't be indexed.  The solution is to pass list(d.keys()) (or simply list(d)) to shuffle.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing",
        "A_Votes": "150",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    def shuffle(self, x, random=None, int=int):     \"\"\"x, random=random.random -> shuffle list x in place; return None.      Optional arg random is a 0-argument function returning a random     float in [0.0, 1.0); by default, the standard random.random.     \"\"\"      randbelow = self._randbelow     for i in reversed(range(1, len(x))):         # pick an element in x[:i+1] with which to exchange x[i]         j = randbelow(i+1) if random is None else int(random() * (i+1))         x[i], x[j] = x[j], x[i]   When I run the shuffle function it raises the following error, why is that?  TypeError: 'dict_keys' object does not support indexing      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "TypeError: 'dict_keys' object does not support indexing",
        "A_Content": "  You're passing the result of somedict.keys() to the function. In Python 3, dict.keys doesn't return a list, but a set-like object that represents a view of the dictionary's keys and (being set-like) doesn't support indexing.  To fix the problem, use list(somedict.keys()) to collect the keys, and work with that.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def shuffle(self, x, random=None, int=int):     \"\"\"x, random=random.random -> shuffle list x in place; return None.      Optional arg random is a 0-argument function returning a random     float in [0.0, 1.0); by default, the standard random.random.     \"\"\"      randbelow = self._randbelow     for i in reversed(range(1, len(x))):         # pick an element in x[:i+1] with which to exchange x[i]         j = randbelow(i+1) if random is None else int(random() * (i+1))         x[i], x[j] = x[j], x[i]   When I run the shuffle function it raises the following error, why is that?  TypeError: 'dict_keys' object does not support indexing      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "TypeError: 'dict_keys' object does not support indexing",
        "A_Content": "  In Python 2 dict.keys() return a list, whereas in Python 3 it returns a generator.  You could only iterate over it's values else you may have to explicitly convert it to a list i.e. pass it to a list function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def shuffle(self, x, random=None, int=int):     \"\"\"x, random=random.random -> shuffle list x in place; return None.      Optional arg random is a 0-argument function returning a random     float in [0.0, 1.0); by default, the standard random.random.     \"\"\"      randbelow = self._randbelow     for i in reversed(range(1, len(x))):         # pick an element in x[:i+1] with which to exchange x[i]         j = randbelow(i+1) if random is None else int(random() * (i+1))         x[i], x[j] = x[j], x[i]   When I run the shuffle function it raises the following error, why is that?  TypeError: 'dict_keys' object does not support indexing      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "TypeError: 'dict_keys' object does not support indexing",
        "A_Content": "  Why you need to implement shuffle when it already exists? Stay on the shoulders of giants.  import random  d1 = {0:'zero', 1:'one', 2:'two', 3:'three', 4:'four',      5:'five', 6:'six', 7:'seven', 8:'eight', 9:'nine'}  keys = list(d1) random.shuffle(keys)  d2 = {} for key in keys: d2[key] = d1[key]  print(d1) print(d2)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def shuffle(self, x, random=None, int=int):     \"\"\"x, random=random.random -> shuffle list x in place; return None.      Optional arg random is a 0-argument function returning a random     float in [0.0, 1.0); by default, the standard random.random.     \"\"\"      randbelow = self._randbelow     for i in reversed(range(1, len(x))):         # pick an element in x[:i+1] with which to exchange x[i]         j = randbelow(i+1) if random is None else int(random() * (i+1))         x[i], x[j] = x[j], x[i]   When I run the shuffle function it raises the following error, why is that?  TypeError: 'dict_keys' object does not support indexing      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "TypeError: 'dict_keys' object does not support indexing",
        "A_Content": "  convert iterative to list may have cost instead of it you can use  next(iter(keys))   for first item or if you want to itrate all items use  items = iter(keys) while True:     try:         item = next(items)     except StopIteration as e:         pass # finish      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    def shuffle(self, x, random=None, int=int):     \"\"\"x, random=random.random -> shuffle list x in place; return None.      Optional arg random is a 0-argument function returning a random     float in [0.0, 1.0); by default, the standard random.random.     \"\"\"      randbelow = self._randbelow     for i in reversed(range(1, len(x))):         # pick an element in x[:i+1] with which to exchange x[i]         j = randbelow(i+1) if random is None else int(random() * (i+1))         x[i], x[j] = x[j], x[i]   When I run the shuffle function it raises the following error, why is that?  TypeError: 'dict_keys' object does not support indexing      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  I believe that this answer is more correct than the other answers here:  from sklearn.tree import _tree  def tree_to_code(tree, feature_names):     tree_ = tree.tree_     feature_name = [         feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"         for i in tree_.feature     ]     print \"def tree({}):\".format(\", \".join(feature_names))      def recurse(node, depth):         indent = \"  \" * depth         if tree_.feature[node] != _tree.TREE_UNDEFINED:             name = feature_name[node]             threshold = tree_.threshold[node]             print \"{}if {} <= {}:\".format(indent, name, threshold)             recurse(tree_.children_left[node], depth + 1)             print \"{}else:  # if {} > {}\".format(indent, name, threshold)             recurse(tree_.children_right[node], depth + 1)         else:             print \"{}return {}\".format(indent, tree_.value[node])      recurse(0, 1)   This prints out a valid Python function. Here's an example output for a tree that is trying to return its input, a number between 0 and 10.  def tree(f0):   if f0 <= 6.0:     if f0 <= 1.5:       return [[ 0.]]     else:  # if f0 > 1.5       if f0 <= 4.5:         if f0 <= 3.5:           return [[ 3.]]         else:  # if f0 > 3.5           return [[ 4.]]       else:  # if f0 > 4.5         return [[ 5.]]   else:  # if f0 > 6.0     if f0 <= 8.5:       if f0 <= 7.5:         return [[ 7.]]       else:  # if f0 > 7.5         return [[ 8.]]     else:  # if f0 > 8.5       return [[ 9.]]   Here are some stumbling blocks that I see in other answers:   Using tree_.threshold == -2 to decide whether a node is a leaf isn't a good idea. What if it's a real decision node with a threshold of -2? Instead, you should look at tree.feature or tree.children_*. The line features = [feature_names[i] for i in tree_.feature] crashes with my version of sklearn, because some values of tree.tree_.feature are -2 (specifically for leaf nodes). There is no need to have multiple if statements in the recursive function, just one is fine.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "72",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  I created my own function to extract the rules from the decision trees created by sklearn:  import pandas as pd import numpy as np from sklearn.tree import DecisionTreeClassifier  # dummy data: df = pd.DataFrame({'col1':[0,1,2,3],'col2':[3,4,5,6],'dv':[0,1,0,1]})  # create decision tree dt = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1) dt.fit(df.ix[:,:2], df.dv)   This function first starts with the nodes (identified by -1 in the child arrays) and then recursively finds the parents. I call this a node's 'lineage'.  Along the way, I grab the values I need to create if/then/else SAS logic:  def get_lineage(tree, feature_names):      left      = tree.tree_.children_left      right     = tree.tree_.children_right      threshold = tree.tree_.threshold      features  = [feature_names[i] for i in tree.tree_.feature]       # get ids of child nodes      idx = np.argwhere(left == -1)[:,0]            def recurse(left, right, child, lineage=None):                     if lineage is None:                lineage = [child]           if child in left:                parent = np.where(left == child)[0].item()                split = 'l'           else:                parent = np.where(right == child)[0].item()                split = 'r'            lineage.append((parent, split, threshold[parent], features[parent]))            if parent == 0:                lineage.reverse()                return lineage           else:                return recurse(left, right, parent, lineage)       for child in idx:           for node in recurse(left, right, child):                print node   The sets of tuples below contain everything I need to create SAS if/then/else statements. I do not like using do blocks in SAS which is why I create logic describing a node's entire path. The single integer after the tuples is the ID of the terminal node in a path. All of the preceding tuples combine to create that node.  In [1]: get_lineage(dt, df.columns) (0, 'l', 0.5, 'col1') 1 (0, 'r', 0.5, 'col1') (2, 'l', 4.5, 'col2') 3 (0, 'r', 0.5, 'col1') (2, 'r', 4.5, 'col2') (4, 'l', 2.5, 'col1') 5 (0, 'r', 0.5, 'col1') (2, 'r', 4.5, 'col2') (4, 'r', 2.5, 'col1') 6        ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "43",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  I modified the code submitted by Zelazny7 to print some pseudocode:  def get_code(tree, feature_names):         left      = tree.tree_.children_left         right     = tree.tree_.children_right         threshold = tree.tree_.threshold         features  = [feature_names[i] for i in tree.tree_.feature]         value = tree.tree_.value          def recurse(left, right, threshold, features, node):                 if (threshold[node] != -2):                         print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"                         if left[node] != -1:                                 recurse (left, right, threshold, features,left[node])                         print \"} else {\"                         if right[node] != -1:                                 recurse (left, right, threshold, features,right[node])                         print \"}\"                 else:                         print \"return \" + str(value[node])          recurse(left, right, threshold, features, 0)   if you call get_code(dt, df.columns) on the same example you will obtain:  if ( col1 <= 0.5 ) { return [[ 1.  0.]] } else { if ( col2 <= 4.5 ) { return [[ 0.  1.]] } else { if ( col1 <= 2.5 ) { return [[ 1.  0.]] } else { return [[ 0.  1.]] } } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  There is a new DecisionTreeClassifier method, decision_path, in the 0.18.0 release.  The developers provide an extensive (well-documented) walkthrough.  The first section of code in the walkthrough that prints the tree structure seems to be OK.  However, I modified the code in the second section to interrogate one sample.  My changes denoted with # <--  sample_id = 0 node_index = node_indicator.indices[node_indicator.indptr[sample_id]:                                     node_indicator.indptr[sample_id + 1]]  print('Rules used to predict sample %s: ' % sample_id) for node_id in node_index:      if leave_id[sample_id] == node_id:  # <-- changed != to ==         #continue # <-- comment out         print(\"leaf node {} reached, no decision here\".format(leave_id[sample_id])) # <--      else: # < -- added else to iterate through decision nodes         if (X_test[sample_id, feature[node_id]] <= threshold[node_id]):             threshold_sign = \"<=\"         else:             threshold_sign = \">\"          print(\"decision id node %s : (X[%s, %s] (= %s) %s %s)\"               % (node_id,                  sample_id,                  feature[node_id],                  X_test[sample_id, feature[node_id]], # <-- changed i to sample_id                  threshold_sign,                  threshold[node_id]))  Rules used to predict sample 0:  decision id node 0 : (X[0, 3] (= 2.4) > 0.800000011921) decision id node 2 : (X[0, 2] (= 5.1) > 4.94999980927) leaf node 4 reached, no decision here   Change the sample_id to see the decision paths for other samples.  I haven't asked the developers about these changes, just seemed more intuitive when working through the example.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  from StringIO import StringIO out = StringIO() out = tree.export_graphviz(clf, out_file=out) print out.getvalue()   You can see a digraph Tree. Then, clf.tree_.feature and clf.tree_.value are array of nodes splitting feature and array of nodes values respectively. You can refer to more details from this github source.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  Codes below is my approach under anaconda python 2.7 plus a package name \"pydot-ng\" to making a PDF file with decision rules. I hope it is helpful.  from sklearn import tree  clf = tree.DecisionTreeClassifier(max_leaf_nodes=n) clf_ = clf.fit(X, data_y)  feature_names = X.columns class_name = clf_.classes_.astype(int).astype(str)  def output_pdf(clf_, name):     from sklearn import tree     from sklearn.externals.six import StringIO     import pydot_ng as pydot     dot_data = StringIO()     tree.export_graphviz(clf_, out_file=dot_data,                          feature_names=feature_names,                          class_names=class_name,                          filled=True, rounded=True,                          special_characters=True,                           node_ids=1,)     graph = pydot.graph_from_dot_data(dot_data.getvalue())     graph.write_pdf(\"%s.pdf\"%name)  output_pdf(clf_, name='filename%s'%n)   a tree graphy show here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  Just because everyone was so helpful I'll just add a modification to Zelazny7 and Daniele's beautiful solutions. This one is for python 2.7, with tabs to make it more readable:  def get_code(tree, feature_names, tabdepth=0):     left      = tree.tree_.children_left     right     = tree.tree_.children_right     threshold = tree.tree_.threshold     features  = [feature_names[i] for i in tree.tree_.feature]     value = tree.tree_.value      def recurse(left, right, threshold, features, node, tabdepth=0):             if (threshold[node] != -2):                     print '\\t' * tabdepth,                     print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"                     if left[node] != -1:                             recurse (left, right, threshold, features,left[node], tabdepth+1)                     print '\\t' * tabdepth,                     print \"} else {\"                     if right[node] != -1:                             recurse (left, right, threshold, features,right[node], tabdepth+1)                     print '\\t' * tabdepth,                     print \"}\"             else:                     print '\\t' * tabdepth,                     print \"return \" + str(value[node])      recurse(left, right, threshold, features, 0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  Here is a function, printing rules of a scikit-learn decision tree under python 3 and with offsets for conditional blocks to make the structure more readable:  def print_decision_tree(tree, feature_names=None, offset_unit='    '):     '''Plots textual representation of rules of a decision tree     tree: scikit-learn representation of tree     feature_names: list of feature names. They are set to f1,f2,f3,... if not specified     offset_unit: a string of offset of the conditional block'''      left      = tree.tree_.children_left     right     = tree.tree_.children_right     threshold = tree.tree_.threshold     value = tree.tree_.value     if feature_names is None:         features  = ['f%d'%i for i in tree.tree_.feature]     else:         features  = [feature_names[i] for i in tree.tree_.feature]              def recurse(left, right, threshold, features, node, depth=0):             offset = offset_unit*depth             if (threshold[node] != -2):                     print(offset+\"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\")                     if left[node] != -1:                             recurse (left, right, threshold, features,left[node],depth+1)                     print(offset+\"} else {\")                     if right[node] != -1:                             recurse (left, right, threshold, features,right[node],depth+1)                     print(offset+\"}\")             else:                     print(offset+\"return \" + str(value[node]))      recurse(left, right, threshold, features, 0,0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  This builds on @paulkernfeld 's answer. If you have a dataframe X with your features and a target dataframe y with your resonses and you you want to get an idea which y value ended in which node (and also ant to plot it accordingly) you can do the following:      def tree_to_code(tree, feature_names):         codelines = []         codelines.append('def get_cat(X_tmp):\\n')         codelines.append('   catout = []\\n')         codelines.append('   for codelines in range(0,X_tmp.shape[0]):\\n')         codelines.append('      Xin = X_tmp.iloc[codelines]\\n')         tree_ = tree.tree_         feature_name = [             feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"             for i in tree_.feature         ]         #print \"def tree({}):\".format(\", \".join(feature_names))          def recurse(node, depth):             indent = \"      \" * depth             if tree_.feature[node] != _tree.TREE_UNDEFINED:                 name = feature_name[node]                 threshold = tree_.threshold[node]                 codelines.append ('{}if Xin[\"{}\"] <= {}:\\n'.format(indent, name, threshold))                 recurse(tree_.children_left[node], depth + 1)                 codelines.append( '{}else:  # if Xin[\"{}\"] > {}\\n'.format(indent, name, threshold))                 recurse(tree_.children_right[node], depth + 1)             else:                 codelines.append( '{}mycat = {}\\n'.format(indent, node))          recurse(0, 1)         codelines.append('      catout.append(mycat)\\n')         codelines.append('   return pd.DataFrame(catout,index=X_tmp.index,columns=[\"category\"])\\n')         codelines.append('node_ids = get_cat(X)\\n')         return codelines     mycode = tree_to_code(clf,X.columns.values)      # now execute the function and obtain the dataframe with all nodes     exec(''.join(mycode))     node_ids = [int(x[0]) for x in node_ids.values]     node_ids2 = pd.DataFrame(node_ids)      print('make plot')     import matplotlib.cm as cm     colors = cm.rainbow(np.linspace(0, 1, 1+max( list(set(node_ids)))))     #plt.figure(figsize=cm2inch(24, 21))     for i in list(set(node_ids)):         plt.plot(y[node_ids2.values==i],'o',color=colors[i], label=str(i))       mytitle = ['y colored by node']     plt.title(mytitle ,fontsize=14)     plt.xlabel('my xlabel')     plt.ylabel(tagname)     plt.xticks(rotation=70)            plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.00), shadow=True, ncol=9)     plt.tight_layout()     plt.show()     plt.close    not the most elegant version but it does the job...       ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  I've been going through this, but i needed the rules to be written in this format   if A>0.4 then if B<0.2 then if C>0.8 then class='X'    So I adapted the answer of @paulkernfeld (thanks) that you can customize to your need  def tree_to_code(tree, feature_names, Y):     tree_ = tree.tree_     feature_name = [         feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"         for i in tree_.feature     ]     pathto=dict()      global k     k = 0     def recurse(node, depth, parent):         global k         indent = \"  \" * depth          if tree_.feature[node] != _tree.TREE_UNDEFINED:             name = feature_name[node]             threshold = tree_.threshold[node]             s= \"{} <= {} \".format( name, threshold, node )             if node == 0:                 pathto[node]=s             else:                 pathto[node]=pathto[parent]+' & ' +s              recurse(tree_.children_left[node], depth + 1, node)             s=\"{} > {}\".format( name, threshold)             if node == 0:                 pathto[node]=s             else:                 pathto[node]=pathto[parent]+' & ' +s             recurse(tree_.children_right[node], depth + 1, node)         else:             k=k+1             print(k,')',pathto[parent], tree_.value[node])     recurse(0, 1, 0)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  Modified Zelazny7's code to fetch SQL from the decision tree.  # SQL from decision tree  def get_lineage(tree, feature_names):      left      = tree.tree_.children_left      right     = tree.tree_.children_right      threshold = tree.tree_.threshold      features  = [feature_names[i] for i in tree.tree_.feature]      le='<='                     g ='>'      # get ids of child nodes      idx = np.argwhere(left == -1)[:,0]            def recurse(left, right, child, lineage=None):                     if lineage is None:                lineage = [child]           if child in left:                parent = np.where(left == child)[0].item()                split = 'l'           else:                parent = np.where(right == child)[0].item()                split = 'r'           lineage.append((parent, split, threshold[parent], features[parent]))           if parent == 0:                lineage.reverse()                return lineage           else:                return recurse(left, right, parent, lineage)      print 'case '      for j,child in enumerate(idx):         clause=' when '         for node in recurse(left, right, child):             if len(str(node))<3:                 continue             i=node             if i[1]=='l':  sign=le              else: sign=g             clause=clause+i[3]+sign+str(i[2])+' and '         clause=clause[:-4]+' then '+str(j)         print clause      print 'else 99 end as clusters'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to extract the decision rules from scikit-learn decision-tree?",
        "A_Content": "  Apparently a long time ago somebody already decided to try to add the following function to the official scikit's tree export functions (which basically only supports export_graphviz)  def export_dict(tree, feature_names=None, max_depth=None) :     \"\"\"Export a decision tree in dict format.   Here is his full commit:  https://github.com/scikit-learn/scikit-learn/blob/79bdc8f711d0af225ed6be9fdb708cea9f98a910/sklearn/tree/export.py  Not exactly sure what happened to this comment. But you could also try to use that function.  I think this warrants a serious documentation request to the good people of scikit-learn to properly document the sklearn.tree.Tree API which is the underlying tree structure that DecisionTreeClassifier exposes as its attribute tree_.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "machine-learning",
            "scikit-learn",
            "decision-tree",
            "random-forest"
        ],
        "URL": "https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree as a textual list?  Something like:   if A>0.4 then if B<0.2 then if C>0.8 then class='X'   Thanks for your help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  from decimal import Decimal  '%.2E' % Decimal('40800000000.00000000000000')  # returns '4.08E+10'   In your '40800000000.00000000000000' there are many more significant zeros that have the same meaning as any other digit. That's why you have to tell explicitly where you want to stop.  If you want to remove all trailing zeros automatically, you can try:  def format_e(n):     a = '%E' % n     return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]  format_e(Decimal('40800000000.00000000000000')) # '4.08E+10'  format_e(Decimal('40000000000.00000000000000')) # '4E+10'  format_e(Decimal('40812300000.00000000000000')) # '4.08123E+10'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  Here's an example using the format() function:  >>> \"{:.2E}\".format(Decimal('40800000000.00000000000000')) '4.08E+10'    official documentation original format() proposal      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "73",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  Given your number   x = Decimal('40800000000.00000000000000')   Starting from Python 3,   '{:.2e}'.format(x)   is the recommended way to do it.  e means you want scientific notation, and .2 means you want 2 digits after the dot. So you will get x.xxE±n     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  See tables from Python string formatting to select the proper format layout. In your case it's %.2E.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  My decimals are too big for %E so I had to improvize:  def format_decimal(x, prec=2):     tup = x.as_tuple()     digits = list(tup.digits[:prec + 1])     sign = '-' if tup.sign else ''     dec = ''.join(str(i) for i in digits[1:])     exp = x.adjusted()     return '{sign}{int}.{dec}e{exp}'.format(sign=sign, int=digits[0], dec=dec, exp=exp)   Here's an example usage:  >>> n = decimal.Decimal(4.3) ** 12314 >>> print format_decimal(n) 3.39e7800 >>> print '%e' % n inf      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  No one mentioned the short form of the .format method:  Needs at least Python 3.6  f\"{Decimal('40800000000.00000000000000'):.2E}\"   (I believe it's the same as Cees Timmerman, just a bit shorter)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  To convert a Decimal to scientific notation without needing to specify the precision in the format string, and without including trailing zeros, I'm currently using  def sci_str(dec):     return ('{:.' + str(len(dec.normalize().as_tuple().digits) - 1) + 'E}').format(dec)  print( sci_str( Decimal('123.456000') ) )    # 1.23456E+2   To keep any trailing zeros, just remove the normalize().      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  This worked best for me:  import decimal '%.2E' % decimal.Decimal('40800000000.00000000000000') # 4.08E+10      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Display a decimal in scientific notation",
        "A_Content": "  def formatE_decimal(x, prec=2):     \"\"\" Examples:     >>> formatE_decimal('0.1613965',10)     '1.6139650000E-01'     >>> formatE_decimal('0.1613965',5)     '1.61397E-01'     >>> formatE_decimal('0.9995',2)     '1.00E+00'     \"\"\"     xx=decimal.Decimal(x) if type(x)==type(\"\") else x      tup = xx.as_tuple()     xx=xx.quantize( decimal.Decimal(\"1E{0}\".format(len(tup[1])+tup[2]-prec-1)), decimal.ROUND_HALF_UP )     tup = xx.as_tuple()     exp = xx.adjusted()     sign = '-' if tup.sign else ''     dec = ''.join(str(i) for i in tup[1][1:prec+1])        if prec>0:         return '{sign}{int}.{dec}E{exp:+03d}'.format(sign=sign, int=tup[1][0], dec=dec, exp=exp)     elif prec==0:         return '{sign}{int}E{exp:+03d}'.format(sign=sign, int=tup[1][0], exp=exp)     else:         return None      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string-formatting"
        ],
        "URL": "https://stackoverflow.com/questions/6913532/display-a-decimal-in-scientific-notation",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I display this:  Decimal('40800000000.00000000000000') as '4.08E+10'?  I've tried this:  >>> '%E' % Decimal('40800000000.00000000000000') '4.080000E+10'   But it has those extra 0's.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Capture keyboardinterrupt in Python without try-except",
        "A_Content": "  Yes, you can install an interrupt handler using the module signal, and wait forever using a threading.Event:  import signal import sys import time  def signal_handler(signal, frame):     print('You pressed Ctrl+C!')     sys.exit(0)  signal.signal(signal.SIGINT, signal_handler) print('Press Ctrl+C') forever = threading.Event() forever.wait()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "keyboardinterrupt"
        ],
        "URL": "https://stackoverflow.com/questions/4205317/capture-keyboardinterrupt-in-python-without-try-except",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there some way in Python to capture KeyboardInterrupt event without putting all the code inside a try-except statement? I want to cleanly exit without trace if user presses ctrl-c.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Capture keyboardinterrupt in Python without try-except",
        "A_Content": "  If all you want is to not show the traceback, make your code like this:  ## all your app logic here def main():    ## whatever your app does.   if __name__ == \"__main__\":    try:       main()    except KeyboardInterrupt:       # do nothing here       pass   (Yes, I know that this doesn't directly answer the question, but it's not really clear why needing a try/except block is objectionable -- maybe this makes it less annoying to the OP)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "keyboardinterrupt"
        ],
        "URL": "https://stackoverflow.com/questions/4205317/capture-keyboardinterrupt-in-python-without-try-except",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there some way in Python to capture KeyboardInterrupt event without putting all the code inside a try-except statement? I want to cleanly exit without trace if user presses ctrl-c.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Capture keyboardinterrupt in Python without try-except",
        "A_Content": "  An alternative to setting your own signal handler is to use a context-manager to catch the exception and ignore it:  >>> class CleanExit(object): ...     def __enter__(self): ...             return self ...     def __exit__(self, exc_type, exc_value, exc_tb): ...             if exc_type is KeyboardInterrupt: ...                     return True ...             return exc_type is None ...  >>> with CleanExit(): ...     input()    #just to test it ...  >>>   This removes the try-except block while preserving some explicit mention of what is going on.  This also allows you to ignore the interrupt only in some portions of your code without having to set and reset again the signal handlers everytime.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "keyboardinterrupt"
        ],
        "URL": "https://stackoverflow.com/questions/4205317/capture-keyboardinterrupt-in-python-without-try-except",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there some way in Python to capture KeyboardInterrupt event without putting all the code inside a try-except statement? I want to cleanly exit without trace if user presses ctrl-c.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Capture keyboardinterrupt in Python without try-except",
        "A_Content": "  I know this is an old question but I came here first and then discovered the atexit module. I do not know about its cross-platform track record or a full list of caveats yet, but so far it is exactly what I was looking for in trying to handle post-KeyboardInterrupt cleanup on Linux. Just wanted to throw in another way of approaching the problem.  I want to do post-exit clean-up in the context of Fabric operations, so wrapping everything in try/except wasn't an option for me either. I feel like atexit may be a good fit in such a situation, where your code is not at the top level of control flow.  atexit is very capable and readable out of the box, for example:  import atexit  def goodbye():     print \"You are now leaving the Python sector.\"  atexit.register(goodbye)   You can also use it as a decorator (as of 2.6; this example is from the docs):  import atexit  @atexit.register def goodbye():     print \"You are now leaving the Python sector.\"   If you wanted to make it specific to KeyboardInterrupt only, another person's answer to this question is probably better.  But note that the atexit module is only ~70 lines of code and it would not be hard to create a similar version that treats exceptions differently, for example passing the exceptions as arguments to the callback functions. (The limitation of atexit that would warrant a modified version: currently I can't conceive of a way for the exit-callback-functions to know about the exceptions; the atexit handler catches the exception, calls your callback(s), then re-raises that exception. But you could do this differently.)  For more info see:   Official documentation on atexit The Python Module of the Week post, a good intro      ",
        "Language": "Python",
        "Tags": [
            "python",
            "keyboardinterrupt"
        ],
        "URL": "https://stackoverflow.com/questions/4205317/capture-keyboardinterrupt-in-python-without-try-except",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there some way in Python to capture KeyboardInterrupt event without putting all the code inside a try-except statement? I want to cleanly exit without trace if user presses ctrl-c.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Capture keyboardinterrupt in Python without try-except",
        "A_Content": "  You can prevent printing a stack trace for KeyboardInterrupt, without try: ... except KeyboardInterrupt: pass (the most obvious and propably \"best\" solution, but you already know it and asked for something else) by replacing sys.excepthook. Something like  def custom_excepthook(type, value, traceback):     if type is KeyboardInterrupt:         return # do nothing     else:         sys.__excepthook__(type, value, traceback)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "keyboardinterrupt"
        ],
        "URL": "https://stackoverflow.com/questions/4205317/capture-keyboardinterrupt-in-python-without-try-except",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there some way in Python to capture KeyboardInterrupt event without putting all the code inside a try-except statement? I want to cleanly exit without trace if user presses ctrl-c.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  Assuming you have a class such as  >>> class Cls(object): ...     foo = 1 ...     bar = 'hello' ...     def func(self): ...         return 'call me' ... >>> obj = Cls()   calling dir on the object gives you back all the attributes of that object, including python special attributes. Although some object attributes are callable, such as methods.  >>> dir(obj) ['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'bar', 'foo', 'func']   You can always filter out the special methods by using a list comprehension.  >>> [a for a in dir(obj) if not a.startswith('__')] ['bar', 'foo', 'func']   or if you prefer map/filters.  >>> filter(lambda a: not a.startswith('__'), dir(obj)) ['bar', 'foo', 'func']   If you want to filter out the methods, you can use the builtin callable as a check.  >>> [a for a in dir(obj) if not a.startswith('__') and not callable(getattr(obj,a))] ['bar', 'foo']   You could also inspect the difference between your class and its parent using.  >>> set(dir(Cls)) - set(dir(object)) set(['__module__', 'bar', 'func', '__dict__', 'foo', '__weakref__'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "153",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  in general put a __iter__ method in your class and iterate through the object attributes or put this mixin class in your class.  class IterMixin(object):     def __iter__(self):         for attr, value in self.__dict__.iteritems():             yield attr, value   Your class:  >>> class YourClass(IterMixin): pass ... >>> yc = YourClass() >>> yc.one = range(15) >>> yc.two = 'test' >>> dict(yc) {'one': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'two': 'test'}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  Objects in python store their atributes (including functions) in a dict called __dict__. You can (but generally shouldn't) use this to access the attributes directly. If you just want a list, you can also call dir(obj), which returns an iterable with all the attribute names, which you could then pass to getattr.  However, needing to do anything with the names of the variables is usually bad design. Why not keep them in a collection?  class Foo(object):     def __init__(self, **values):         self.special_values = values   You can then iterate over the keys with for key in obj.special_values:     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  class someclass:         x=1         y=2         z=3         def __init__(self):            self.current_idx = 0            self.items = [\"x\",\"y\",\"z\"]         def next(self):             if self.current_idx < len(self.items):                 self.current_idx += 1                 k = self.items[self.current_idx-1]                 return (k,getattr(self,k))             else:                 raise StopIteration         def __iter__(self):            return self   then just call it as an iterable  s=someclass() for k,v in s:     print k,\"=\",v      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  For python 3.6  class SomeClass:      def attr_list(self, should_print=False):          items = self.__dict__.items()         if should_print:             [print(f\"attribute: {k}    value: {v}\") for k, v in items]          return items      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  For python 3.6  class SomeClass:      def attr_list1(self, should_print=False):          for k in self.__dict__.keys():             v = self.__dict__.__getitem__(k)             if should_print:                 print(f\"attr: {k}    value: {v}\")      def attr_list(self, should_print=False):          b = [(k, v) for k, v in self.__dict__.items()]         if should_print:             [print(f\"attr: {a[0]}    value: {a[1]}\") for a in b]         return b      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Iterate over object attributes in python",
        "A_Content": "  The correct answer to this is that you shouldn't. If you want this type of thing either just use a dict, or you'll need to explicitly add attributes to some container. You can automate that by learning about decorators.  In particular, by the way, method1 in your example is just as good of an attribute.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop",
            "attributes",
            "iteration"
        ],
        "URL": "https://stackoverflow.com/questions/11637293/iterate-over-object-attributes-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a python object with several attributes and methods.  I want to iterate over object attributes.    class my_python_obj(object):     attr1='a'     attr2='b'     attr3='c'      def method1(self, etc, etc):         #Statements   I want to generate a dictionary containing all of the objects attributes and their current values, but I want to do it in a dynamic way (so if later I add another attribute I don't have to remember to update my function as well).  In php variables can be used as keys, but objects in python are unsuscriptable and if I use the dot notation for this it creates a new attribute with the name of my var, which is not my intent.  Just to make things clearer:  def to_dict(self):     '''this is what I already have'''     d={}     d[\"attr1\"]= self.attr1     d[\"attr2\"]= self.attr2     d[\"attr3\"]= self.attr3     return d   ·  def to_dict(self):     '''this is what I want to do'''     d={}     for v in my_python_obj.attributes:         d[v] = self.v     return d   Update: With attributes I mean only the variables of this object, not the methods.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  This will give you the desired result  #!/usr/bin/python  import os  # traverse root directory, and list directories as dirs and files as files for root, dirs, files in os.walk(\".\"):     path = root.split(os.sep)     print((len(path) - 1) * '---', os.path.basename(root))     for file in files:         print(len(path) * '---', file)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  try this:  #!/usr/bin/env python # -*- coding: utf-8 -*-  \"\"\"FileTreeMaker.py: ...\"\"\"  __author__  = \"legendmohe\"  import os import argparse import time  class FileTreeMaker(object):      def _recurse(self, parent_path, file_list, prefix, output_buf, level):         if len(file_list) == 0 \\             or (self.max_level != -1 and self.max_level <= level):             return         else:             file_list.sort(key=lambda f: os.path.isfile(os.path.join(parent_path, f)))             for idx, sub_path in enumerate(file_list):                 if any(exclude_name in sub_path for exclude_name in self.exn):                     continue                  full_path = os.path.join(parent_path, sub_path)                 idc = \"┣━\"                 if idx == len(file_list) - 1:                     idc = \"┗━\"                  if os.path.isdir(full_path) and sub_path not in self.exf:                     output_buf.append(\"%s%s[%s]\" % (prefix, idc, sub_path))                     if len(file_list) > 1 and idx != len(file_list) - 1:                         tmp_prefix = prefix + \"┃  \"                     else:                         tmp_prefix = prefix + \"    \"                     self._recurse(full_path, os.listdir(full_path), tmp_prefix, output_buf, level + 1)                 elif os.path.isfile(full_path):                     output_buf.append(\"%s%s%s\" % (prefix, idc, sub_path))      def make(self, args):         self.root = args.root         self.exf = args.exclude_folder         self.exn = args.exclude_name         self.max_level = args.max_level          print(\"root:%s\" % self.root)          buf = []         path_parts = self.root.rsplit(os.path.sep, 1)         buf.append(\"[%s]\" % (path_parts[-1],))         self._recurse(self.root, os.listdir(self.root), \"\", buf, 0)          output_str = \"\\n\".join(buf)         if len(args.output) != 0:             with open(args.output, 'w') as of:                 of.write(output_str)         return output_str  if __name__ == \"__main__\":     parser = argparse.ArgumentParser()     parser.add_argument(\"-r\", \"--root\", help=\"root of file tree\", default=\".\")     parser.add_argument(\"-o\", \"--output\", help=\"output file name\", default=\"\")     parser.add_argument(\"-xf\", \"--exclude_folder\", nargs='*', help=\"exclude folder\", default=[])     parser.add_argument(\"-xn\", \"--exclude_name\", nargs='*', help=\"exclude name\", default=[])     parser.add_argument(\"-m\", \"--max_level\", help=\"max level\",                         type=int, default=-1)     args = parser.parse_args()     print(FileTreeMaker().make(args))   you will get this:  root:. [.] ┣━[.idea] ┃  ┣━[scopes] ┃  ┃  ┗━scope_settings.xml ┃  ┣━.name ┃  ┣━Demo.iml ┃  ┣━encodings.xml ┃  ┣━misc.xml ┃  ┣━modules.xml ┃  ┣━vcs.xml ┃  ┗━workspace.xml ┣━[test1] ┃  ┗━test1.txt ┣━[test2] ┃  ┣━[test2-2] ┃  ┃  ┗━[test2-3] ┃  ┃      ┣━test2 ┃  ┃      ┗━test2-3-1 ┃  ┗━test2 ┣━folder_tree_maker.py ┗━tree.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  There are more suitable functions for this in os package. But if you have to use os.walk, here is what I come up with  def walkdir(dirname):     for cur, _dirs, files in os.walk(dirname):         pref = ''         head, tail = os.path.split(cur)         while head:             pref += '---'             head, _tail = os.path.split(head)         print(pref+tail)         for f in files:             print(pref+'---'+f)   output:  >>> walkdir('.') . ---file3 ---file2 ---my.py ---file1 ---A ------file2 ------file1 ---B ------file3 ------file2 ------file4 ------file1 ---__pycache__ ------my.cpython-33.pyc      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  You can use os.walk, and that is probably the easiest solution, but here is another idea to explore:  import sys, os  FILES = False  def main():     if len(sys.argv) > 2 and sys.argv[2].upper() == '/F':         global FILES; FILES = True     try:         tree(sys.argv[1])     except:         print('Usage: {} <directory>'.format(os.path.basename(sys.argv[0])))  def tree(path):     path = os.path.abspath(path)     dirs, files = listdir(path)[:2]     print(path)     walk(path, dirs, files)     if not dirs:         print('No subfolders exist')  def walk(root, dirs, files, prefix=''):     if FILES and files:         file_prefix = prefix + ('|' if dirs else ' ') + '   '         for name in files:             print(file_prefix + name)         print(file_prefix)     dir_prefix, walk_prefix = prefix + '+---', prefix + '|   '     for pos, neg, name in enumerate2(dirs):         if neg == -1:             dir_prefix, walk_prefix = prefix + '\\\\---', prefix + '    '         print(dir_prefix + name)         path = os.path.join(root, name)         try:             dirs, files = listdir(path)[:2]         except:             pass         else:             walk(path, dirs, files, walk_prefix)  def listdir(path):     dirs, files, links = [], [], []     for name in os.listdir(path):         path_name = os.path.join(path, name)         if os.path.isdir(path_name):             dirs.append(name)         elif os.path.isfile(path_name):             files.append(name)         elif os.path.islink(path_name):             links.append(name)     return dirs, files, links  def enumerate2(sequence):     length = len(sequence)     for count, value in enumerate(sequence):         yield count, count - length, value  if __name__ == '__main__':     main()     You might recognize the following documentation from the TREE command in the Windows terminal:  Graphically displays the folder structure of a drive or path.  TREE [drive:][path] [/F] [/A]     /F   Display the names of the files in each folder.    /A   Use ASCII instead of extended characters.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  This does it for folder names:  def printFolderName(init_indent, rootFolder):     fname = rootFolder.split(os.sep)[-1]     root_levels = rootFolder.count(os.sep)     # os.walk treats dirs breadth-first, but files depth-first (go figure)     for root, dirs, files in os.walk(rootFolder):         # print the directories below the root         levels = root.count(os.sep) - root_levels         indent = ' '*(levels*2)         print init_indent + indent + root.split(os.sep)[-1]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  #!/usr/bin/python  import os   def tracing(a):     global i>     for item in os.listdir(a):         if os.path.isfile(item):             print i + item          else:             print i + item              i+=i             tracing(item)  i = \"---\" tracing(\".\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  Do try this; easy one   #!/usr/bin/python  import os  # Creating an empty list that will contain the already traversed paths  donePaths = []  def direct(path):        for paths,dirs,files in os.walk(path):              if paths not in donePaths:                     count = paths.count('/')                     if files:                           for ele1 in files:                                 print '---------' * (count), ele1                     if dirs:                           for ele2 in dirs:                                 print '---------' * (count), ele2                                 absPath = os.path.join(paths,ele2)               # recursively calling the direct function on each directory                                 direct(absPath)                    # adding the paths to the list that got traversed                                  donePaths.append(absPath)   path = raw_input(\"Enter any path to get the following Dir Tree ...\\n\")  direct(path)   ========OUTPUT below========   /home/test  ------------------ b.txt  ------------------ a.txt  ------------------ a  --------------------------- a1.txt  ------------------ b  --------------------------- b1.txt  --------------------------- b2.txt  --------------------------- cde  ------------------------------------ cde.txt  ------------------------------------ cdeDir  --------------------------------------------- cdeDir.txt  ------------------ c  --------------------------- c.txt  --------------------------- c1  ------------------------------------ c1.txt  ------------------------------------ c2.txt      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  Given a folder name, walk through its entire hierarchy recursively.  #! /usr/local/bin/python3 # findLargeFiles.py - given a folder name, walk through its entire hierarchy #                   - print folders and files within each folder  import os  def recursive_walk(folder):     for folderName, subfolders, filenames in os.walk(folder):         if subfolders:             for subfolder in subfolders:                 recursive_walk(subfolder)         print('\\nFolder: ' + folderName + '\\n')         for filename in filenames:             print(filename + '\\n')  recursive_walk('/name/of/folder')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Using os.walk() to recursively traverse directories in Python",
        "A_Content": "  import os  os.chdir('/your/working/path/') dir = os.getcwd() list = sorted(os.listdir(dir)) marks = \"\"  for s_list in list:     print marks + s_list     marks += \"---\"     tree_list = sorted(os.listdir(dir + \"/\" + s_list))     for i in tree_list:         print marks + i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "os.walk"
        ],
        "URL": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to navigate from the root directory to all other directories within and print the same.  Here's my code:  #!/usr/bin/python  import os import fnmatch  for root, dir, files in os.walk(\".\"):         print root         print \"\"         for items in fnmatch.filter(files, \"*\"):                 print \"...\" + items         print \"\"   And here's my O/P:  .  ...Python_Notes ...pypy.py ...pypy.py.save ...classdemo.py ....goutputstream-J9ZUXW ...latest.py ...pack.py ...classdemo.pyc ...Python_Notes~ ...module-demo.py ...filetype.py  ./packagedemo  ...classdemo.py ...__init__.pyc ...__init__.py ...classdemo.pyc   Above, . and ./packagedemo are directories.  However, I need to print the O/P in the following manner:   A ---a.txt ---b.txt ---B ------c.out   Above, A and B are directories and the rest are files.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Modulus % in Django template",
        "A_Content": "  You need divisibleby, a built-in django filter.  {% for p in posts %}     <div class=\"post width1 height2 column {% if forloop.counter0|divisibleby:4 %}first{% endif %}\">         <div class=\"preview\">          </div>         <div class=\"overlay\">          </div>         <h2>p.title</h2>     </div> {% endfor %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/8494209/modulus-in-django-template",
        "A_Votes": "168",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm looking for a way to use something like the modulus operator in django. What I am trying to do is to add a classname to every fourth element in a loop.  With modulus it would look like this:  {% for p in posts %}     <div class=\"post width1 height2 column {% if forloop.counter0 % 4 == 0 %}first{% endif %}}\">         <div class=\"preview\">          </div>         <div class=\"overlay\">          </div>         <h2>p.title</h2>     </div> {% endfor %}   Of course this doesn't work because % is a reserved character. Is there any other way to do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Modulus % in Django template",
        "A_Content": "  You can't use the modulus operator in Django template tags, but it would be easy enough to write a filter to do so. Something like this should work:  @register.filter def modulo(num, val):     return num % val   And then:  {% ifequal forloop.counter0|modulo:4 0 %}   You could even do something like this, instead:  @register.filter def modulo(num, val):     return num % val == 0   And then:  {% if forloop.counter0|modulo:4 %}     Or you could use the cycle tag:  <div class=\"post width1 height2 column {% cycle 'first' '' '' '' %}\">      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/8494209/modulus-in-django-template",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a way to use something like the modulus operator in django. What I am trying to do is to add a classname to every fourth element in a loop.  With modulus it would look like this:  {% for p in posts %}     <div class=\"post width1 height2 column {% if forloop.counter0 % 4 == 0 %}first{% endif %}}\">         <div class=\"preview\">          </div>         <div class=\"overlay\">          </div>         <h2>p.title</h2>     </div> {% endfor %}   Of course this doesn't work because % is a reserved character. Is there any other way to do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Modulus % in Django template",
        "A_Content": "  It sounds like you should just use the cycle tag. Built-in template tags     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/8494209/modulus-in-django-template",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a way to use something like the modulus operator in django. What I am trying to do is to add a classname to every fourth element in a loop.  With modulus it would look like this:  {% for p in posts %}     <div class=\"post width1 height2 column {% if forloop.counter0 % 4 == 0 %}first{% endif %}}\">         <div class=\"preview\">          </div>         <div class=\"overlay\">          </div>         <h2>p.title</h2>     </div> {% endfor %}   Of course this doesn't work because % is a reserved character. Is there any other way to do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Modulus % in Django template",
        "A_Content": "  Bootstrap rows and columns example.  New row every 4 items. Also close last row even if there are less than 4 items.  myapp/templatetags/my_tags.py  from django import template  register = template.Library()  @register.filter def modulo(num, val):     return num % val   html template  {% load my_tags %}  {% for item in all_items %}      {% if forloop.counter|modulo:4 == 1 %}         <div class=\"row\">     {% endif %}          <div class=\"col-sm-3\">             {{ item }}         </div>      {% if forloop.last or forloop.counter|modulo:4 == 0 %}         </div>     {% endif %}  {% endfor %}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "templates"
        ],
        "URL": "https://stackoverflow.com/questions/8494209/modulus-in-django-template",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking for a way to use something like the modulus operator in django. What I am trying to do is to add a classname to every fourth element in a loop.  With modulus it would look like this:  {% for p in posts %}     <div class=\"post width1 height2 column {% if forloop.counter0 % 4 == 0 %}first{% endif %}}\">         <div class=\"preview\">          </div>         <div class=\"overlay\">          </div>         <h2>p.title</h2>     </div> {% endfor %}   Of course this doesn't work because % is a reserved character. Is there any other way to do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Numpy array, how to select indices satisfying multiple conditions?",
        "A_Content": "  Your expression works if you add parentheses:  >>> y[(1 < x) & (x < 5)] array(['o', 'o', 'a'],        dtype='|S1')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3030480/numpy-array-how-to-select-indices-satisfying-multiple-conditions",
        "A_Votes": "151",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.  I tried  x = array([5, 2, 3, 1, 4, 5]) y = array(['f','o','o','b','a','r']) output = y[x > 1 & x < 5] # desired output is ['o','o','a']   but this doesn't work. How would I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Numpy array, how to select indices satisfying multiple conditions?",
        "A_Content": "  IMO OP does not actually want np.bitwise_and() (aka &) but actually wants np.logical_and() because they are comparing logical values such as True and False - see this SO post on logical vs. bitwise to see the difference.  >>> x = array([5, 2, 3, 1, 4, 5]) >>> y = array(['f','o','o','b','a','r']) >>> output = y[np.logical_and(x > 1, x < 5)] # desired output is ['o','o','a'] >>> output array(['o', 'o', 'a'],       dtype='|S1')   And equivalent way to do this is with np.all() by setting the axis argument appropriately.  >>> output = y[np.all([x > 1, x < 5], axis=0)] # desired output is ['o','o','a'] >>> output array(['o', 'o', 'a'],       dtype='|S1')   by the numbers:  >>> %timeit (a < b) & (b < c) The slowest run took 32.97 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 3: 1.15 µs per loop  >>> %timeit np.logical_and(a < b, b < c) The slowest run took 32.59 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 1.17 µs per loop  >>> %timeit np.all([a < b, b < c], 0) The slowest run took 67.47 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 3: 5.06 µs per loop   so using np.all() is slower, but & and logical_and are about the same.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3030480/numpy-array-how-to-select-indices-satisfying-multiple-conditions",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.  I tried  x = array([5, 2, 3, 1, 4, 5]) y = array(['f','o','o','b','a','r']) output = y[x > 1 & x < 5] # desired output is ['o','o','a']   but this doesn't work. How would I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Numpy array, how to select indices satisfying multiple conditions?",
        "A_Content": "  Add one detail to @J.F. Sebastian's and @Mark Mikofski's answers: If one wants to get the corresponding indices (rather than the actual values of array), the following code will do:  For satisfying multiple (all) conditions:  select_indices = np.where( np.logical_and( x > 1, x < 5) ) #   1 < x <5   For satisfying multiple (or) conditions:  select_indices = np.where( np.logical_or( x < 1, x > 5 ) ) # x <1 or x >5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3030480/numpy-array-how-to-select-indices-satisfying-multiple-conditions",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.  I tried  x = array([5, 2, 3, 1, 4, 5]) y = array(['f','o','o','b','a','r']) output = y[x > 1 & x < 5] # desired output is ['o','o','a']   but this doesn't work. How would I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Numpy array, how to select indices satisfying multiple conditions?",
        "A_Content": "  I like to use np.vectorize for such tasks. Consider the following:  >>> # Arrays >>> x = np.array([5, 2, 3, 1, 4, 5]) >>> y = np.array(['f','o','o','b','a','r'])  >>> # Function containing the constraints >>> func = np.vectorize(lambda t: t>1 and t<5)  >>> # Call function on x >>> y[func(x)] >>> array(['o', 'o', 'a'], dtype='<U1')   The advantage is you can add many more types of constraints in the vectorized function.  Hope it helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3030480/numpy-array-how-to-select-indices-satisfying-multiple-conditions",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.  I tried  x = array([5, 2, 3, 1, 4, 5]) y = array(['f','o','o','b','a','r']) output = y[x > 1 & x < 5] # desired output is ['o','o','a']   but this doesn't work. How would I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Numpy array, how to select indices satisfying multiple conditions?",
        "A_Content": "  Actually I would do it this way:  L1 is the index list of elements satisfying condition 1;(maybe you can use somelist.index(condition1) or np.where(condition1) to get L1.)  Similarly, you get L2, a list of elements satisfying condition 2;  Then you find intersection using intersect(L1,L2).  You can also find intersection of multiple lists if you get multiple conditions to satisfy.  Then you can apply index in any other array, for example, x.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/3030480/numpy-array-how-to-select-indices-satisfying-multiple-conditions",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.  I tried  x = array([5, 2, 3, 1, 4, 5]) y = array(['f','o','o','b','a','r']) output = y[x > 1 & x < 5] # desired output is ['o','o','a']   but this doesn't work. How would I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  Properties are a special kind of attribute.  Basically, when Python encounters the following code:  spam = SomeObject() print(spam.eggs)   it looks up eggs in spam, and then examines eggs to see if it has a __get__, __set__, or __delete__ method — if it does, it's a property.  If it is a property, instead of just returning the eggs object (as it would for any other attribute) it will call the __get__ method (since we were doing lookup) and return whatever that method returns.  More information about Python's data model and descriptors.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "136",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  With a property you have complete control on its getter, setter and deleter methods, which you don't have (if not using caveats) with an attribute.  class A(object):     _x = 0     '''A._x is an attribute'''      @property     def x(self):         '''         A.x is a property         This is the getter method         '''         return self._x      @x.setter     def x(self, value):         \"\"\"         This is the setter method         where I can check it's not assigned a value < 0         \"\"\"         if value < 0:             raise ValueError(\"Must be >= 0\")         self._x = value  >>> a = A() >>> a._x = -1 >>> a.x = -1 Traceback (most recent call last):   File \"ex.py\", line 15, in <module>     a.x = -1   File \"ex.py\", line 9, in x     raise ValueError(\"Must be >= 0\") ValueError: Must be >= 0      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  In general speaking terms a property and an attribute are the same thing. However, there is a property decorator in Python which provides getter/setter access to an attribute (or other data).  class MyObject(object):     # This is a normal attribute     foo = 1      @property     def bar(self):         return self.foo      @bar.setter     def bar(self, value):         self.foo = value   obj = MyObject() assert obj.foo == 1 assert obj.bar == obj.foo obj.bar = 2 assert obj.foo == 2 assert obj.bar == obj.foo      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  The property allows you to get and set values like you would normal attributes, but underneath there is a method being called translating it into a getter and setter for you.  It's really just a convenience to cut down on the boilerplate of calling getters and setters.  Lets say for example, you had a class that held some x and y coordinates for something you needed.  To set them you might want to do something like:  myObj.x = 5 myObj.y = 10   That is much easier to look at and think about than writing:  myObj.setX(5) myObj.setY(10)   The problem is, what if one day your class changes such that you need to offset your x and y by some value?  Now you would need to go in and change your class definition and all of the code that calls it, which could be really time consuming and error prone.  The property allows you to use the former syntax while giving you the flexibility of change of the latter.  In Python, you can define getters, setters, and delete methods with the property function.  If you just want the read property, there is also a @property decorator you can add above your method.  http://docs.python.org/library/functions.html#property     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  I learnt 2 differences from  site of Bernd Klein, in summary:  1. Property is a more convenient way to do data encapsulation.  ex: If your have a public attribute lenght of Object, later on, your project requires you to encapsulate it, i.e: change it to private and provide getter and setter => you have to change many of the codes you wrote before:  #Old codes obj1.length=obj1.length+obj2.length #New codes(Using private attibutes and getter and setter) obj1.set_lenght(obj1.get_length()+obj2.get_length()) #=> this is ugly   If you use @property and @lenght.setter => you don't need to change those old codes  2. A property can encapsulate multiple attributes  class Person:   def __init__(self, name, physic_health, mental_health):     self.name=name     self.__physic_health=physic_health #physic_health is real value in range [0, 5.0]     self.__mental_health=mental_health #mental_health is real value in range [0, 5.0]   @property   def condition(self):     health=self.__physic_health+self.__mental_health     if(health<5.0):       return \"I feel bad!\"     elif health<8.0:       return \"I am ok!\"     else:       return \"Great!\"   In this example, __physic_health and __mental_health are private and can not be accessed directly from out side, the only way outside class interact with them is throught property condition     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What's the difference between a Python “property” and “attribute”?",
        "A_Content": "  There is also one not obvious difference that i use to cache or refresh data , often we have a function connected to class attribute. For instance i need to read file once and keep content assigned to the attribute so the value is cached:  class Misc():         def __init__(self):             self.test = self.test_func()          def test_func(self):             print 'func running'             return 'func value'  cl = Misc() print cl.test print cl.test   Output:  func running func value func value   We accessed the attribute twice but our function was fired only once. Changing the above example to use property will cause attribute's value refresh each time you access it:  class Misc():      @property     def test(self):         print 'func running'         return 'func value'  cl = Misc() print cl.test print cl.test   Output:  func running func value func running func value      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/7374748/whats-the-difference-between-a-python-property-and-attribute",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am generally confused about the difference between a \"property\" and an \"attribute\", and can't find a great resource to concisely detail the differences.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  You are not putting a \" before the end of the line.   Use \"\"\" if you want to do this:  \"\"\" a very long string ......  ....that can span multiple lines \"\"\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "127",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  I had this problem - I eventually worked out that the reason was that I'd included \\ characters in the string. If you have any of these, \"escape\" them with \\\\ and it should work fine.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  (Assuming you don't have/want line breaks in your string...)  How long is this string really?  I suspect there is a limit to how long a line read from a file or from the commandline can be, and because the end of the line gets choped off the parser sees something like s1=\"some very long string.......... (without an ending \") and thus throws a parsing error?  You can split long lines up in multiple lines by escaping linebreaks in your source like this:  s1=\"some very long string.....\\ ...\\ ....\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  In my situation, I had \\r\\n in my single-quoted dictionary strings. I replaced all instances of \\r with \\\\r and \\n with \\\\n and it fixed my issue, properly returning escaped line breaks in the eval'ed dict.  ast.literal_eval(my_str.replace('\\r','\\\\r').replace('\\n','\\\\n'))   .....      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  I too had this problem, though there were answers here I want to an important point to this after  / there should not be empty spaces.Be Aware of it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  I also had this exact error message, for me the problem was fixed by adding an \" \\\"  It turns out that my long string, broken into about eight lines with \" \\\" at the very end, was missing a \" \\\" on one line.  Python IDLE didn't specify a line number that this error was on, but it red-highlighted a totally correct variable assignment statement, throwing me off.  The actual misshapen string statement (multiple lines long with \" \\\") was adjacent to the statement being highlighted.  Maybe this will help someone else.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  I faced a similar problem. I had a string which contained path to a folder in Windows e.g. C:\\Users\\ The problem is that \\ is an escape character and so in order to use it in strings you need to add one more \\.   Incorrect: C:\\Users\\  Correct:   C:\\\\\\Users\\\\\\     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  In my case, I use Windows so I have to use double quotes instead of single.  C:\\Users\\Dr. Printer>python -mtimeit -s\"a = 0\" 100000000 loops, best of 3: 0.011 usec per loop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  I was getting this error in postgresql function. I had a long SQL which I broke into multiple lines with \\ for better readability. However, that was the problem. I removed all and made them in one line to fix the issue. I was using pgadmin III.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "python: SyntaxError: EOL while scanning string literal",
        "A_Content": "  In my case with Mac OS X, I had the following statement:    model.export_srcpkg(platform, toolchain, 'mymodel_pkg.zip', 'mymodel.dylib’)   I was getting the error:      File \"<stdin>\", line 1 model.export_srcpkg(platform, toolchain, 'mymodel_pkg.zip', 'mymodel.dylib’)                                                                              ^ SyntaxError: EOL while scanning string literal   After I change to:    model.export_srcpkg(platform, toolchain, \"mymodel_pkg.zip\", \"mymodel.dylib\")   It worked...    David     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "string-literals"
        ],
        "URL": "https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have the above mentioned error in s1=\"some very long string............\"   Anyone know what i am doing wrong?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  How about something like this:  In [55]: pd.concat([Series(row['var2'], row['var1'].split(','))                                   for _, row in a.iterrows()]).reset_index() Out[55]:    index  0 0     a  1 1     b  1 2     c  1 3     d  2 4     e  2 5     f  2   Then you just have to rename the columns     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  After painful experimentation to find something faster than the accepted answer, I got this to work. It ran around 100x faster on the dataset I tried it on.  If someone knows a way to make this more elegant, by all means please modify my code. I couldn't find a way that works without setting the other columns you want to keep as the index and then resetting the index and re-naming the columns, but I'd imagine there's something else that works.  b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack() b = b.reset_index()[[0, 'var2']] # var1 variable is currently labeled 0 b.columns = ['var1', 'var2'] # renaming var1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  UPDATE2: more generic vectorized function, which will work for multiple normal and multiple list columns  def explode(df, lst_cols, fill_value=''):     # make sure `lst_cols` is a list     if lst_cols and not isinstance(lst_cols, list):         lst_cols = [lst_cols]     # all columns except `lst_cols`     idx_cols = df.columns.difference(lst_cols)      # calculate lengths of lists     lens = df[lst_cols[0]].str.len()      if (lens > 0).all():         # ALL lists in cells aren't empty         return pd.DataFrame({             col:np.repeat(df[col].values, lens)             for col in idx_cols         }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\           .loc[:, df.columns]     else:         # at least one list in cells is empty         return pd.DataFrame({             col:np.repeat(df[col].values, lens)             for col in idx_cols         }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\           .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\           .loc[:, df.columns]   Demo:  Multiple list columns - all list columns must have the same # of elements in each row:  In [36]: df Out[36]:    aaa  myid        num          text 0   10     1  [1, 2, 3]  [aa, bb, cc] 1   11     2     [1, 2]      [cc, dd] 2   12     3         []            [] 3   13     4         []            []  In [37]: explode(df, ['num','text'], fill_value='') Out[37]:    aaa  myid num text 0   10     1   1   aa 1   10     1   2   bb 2   10     1   3   cc 3   11     2   1   cc 4   11     2   2   dd 2   12     3 3   13     4   Setup:  df = pd.DataFrame({  'aaa': {0: 10, 1: 11, 2: 12, 3: 13},  'myid': {0: 1, 1: 2, 2: 3, 3: 4},  'num': {0: [1, 2, 3], 1: [1, 2], 2: [], 3: []},  'text': {0: ['aa', 'bb', 'cc'], 1: ['cc', 'dd'], 2: [], 3: []} })   CSV column:  In [46]: df Out[46]:         var1  var2 var3 0      a,b,c     1   XX 1  d,e,f,x,y     2   ZZ  In [47]: explode(df.assign(var1=df.var1.str.split(',')), 'var1') Out[47]:   var1  var2 var3 0    a     1   XX 1    b     1   XX 2    c     1   XX 3    d     2   ZZ 4    e     2   ZZ 5    f     2   ZZ 6    x     2   ZZ 7    y     2   ZZ   using this little trick we can convert CSV-like column to list column:  In [48]: df.assign(var1=df.var1.str.split(',')) Out[48]:               var1  var2 var3 0        [a, b, c]     1   XX 1  [d, e, f, x, y]     2   ZZ     UPDATE: generic vectorized approach (will work also for multiple columns):  Original DF:  In [177]: df Out[177]:         var1  var2 var3 0      a,b,c     1   XX 1  d,e,f,x,y     2   ZZ   Solution:  first let's convert CSV strings to lists:  In [178]: lst_col = 'var1'   In [179]: x = df.assign(**{lst_col:df[lst_col].str.split(',')})  In [180]: x Out[180]:               var1  var2 var3 0        [a, b, c]     1   XX 1  [d, e, f, x, y]     2   ZZ   Now we can do this:  In [181]: pd.DataFrame({      ...:     col:np.repeat(x[col].values, x[lst_col].str.len())      ...:     for col in x.columns.difference([lst_col])      ...: }).assign(**{lst_col:np.concatenate(x[lst_col].values)})[x.columns.tolist()]      ...: Out[181]:   var1  var2 var3 0    a     1   XX 1    b     1   XX 2    c     1   XX 3    d     2   ZZ 4    e     2   ZZ 5    f     2   ZZ 6    x     2   ZZ 7    y     2   ZZ     OLD answer:  Inspired by @AFinkelstein solution, i wanted to make it bit more generalized which could be applied to DF with more than two columns and as fast, well almost, as fast as AFinkelstein's solution):  In [2]: df = pd.DataFrame(    ...:    [{'var1': 'a,b,c', 'var2': 1, 'var3': 'XX'},    ...:     {'var1': 'd,e,f,x,y', 'var2': 2, 'var3': 'ZZ'}]    ...: )  In [3]: df Out[3]:         var1  var2 var3 0      a,b,c     1   XX 1  d,e,f,x,y     2   ZZ  In [4]: (df.set_index(df.columns.drop('var1',1).tolist())    ...:    .var1.str.split(',', expand=True)    ...:    .stack()    ...:    .reset_index()    ...:    .rename(columns={0:'var1'})    ...:    .loc[:, df.columns]    ...: ) Out[4]:   var1  var2 var3 0    a     1   XX 1    b     1   XX 2    c     1   XX 3    d     2   ZZ 4    e     2   ZZ 5    f     2   ZZ 6    x     2   ZZ 7    y     2   ZZ      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Here's a function I wrote for this common task. It's more efficient than the Series/stack methods. Column order and names are retained.  def tidy_split(df, column, sep='|', keep=False):     \"\"\"     Split the values of a column and expand so the new DataFrame has one split     value per row. Filters rows where the column is missing.      Params     ------     df : pandas.DataFrame         dataframe with the column to split and expand     column : str         the column to split and expand     sep : str         the string used to split the column's values     keep : bool         whether to retain the presplit value as it's own row      Returns     -------     pandas.DataFrame         Returns a dataframe with the same columns as `df`.     \"\"\"     indexes = list()     new_values = list()     df = df.dropna(subset=[column])     for i, presplit in enumerate(df[column].astype(str)):         values = presplit.split(sep)         if keep and len(values) > 1:             indexes.append(i)             new_values.append(presplit)         for value in values:             indexes.append(i)             new_values.append(value)     new_df = df.iloc[indexes, :].copy()     new_df[column] = new_values     return new_df   With this function, the original question is as simple as:  tidy_split(a, 'var1', sep=',')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Similar question as: pandas: How do I split text in a column into multiple rows?  You could do:  >> a=pd.DataFrame({\"var1\":\"a,b,c d,e,f\".split(),\"var2\":[1,2]}) >> s = a.var1.str.split(\",\").apply(pd.Series, 1).stack() >> s.index = s.index.droplevel(-1) >> del a['var1'] >> a.join(s)    var2 var1 0     1    a 0     1    b 0     1    c 1     2    d 1     2    e 1     2    f      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  I came up with a solution for dataframes with arbitrary numbers of columns (while still only separating one column's entries at a time).  def splitDataFrameList(df,target_column,separator):     ''' df = dataframe to split,     target_column = the column containing the values to split     separator = the symbol used to perform the split      returns: a dataframe with each entry for the target column separated, with each element moved into a new row.      The values in the other columns are duplicated across the newly divided rows.     '''     def splitListToRows(row,row_accumulator,target_column,separator):         split_row = row[target_column].split(separator)         for s in split_row:             new_row = row.to_dict()             new_row[target_column] = s             row_accumulator.append(new_row)     new_rows = []     df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))     new_df = pandas.DataFrame(new_rows)     return new_df      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Here is a fairly straightforward message that uses the split method from pandas str accessor and then uses NumPy to flatten each row into a single array.  The corresponding values are retrieved by repeating the non-split column the correct number of times with np.repeat.  var1 = df.var1.str.split(',', expand=True).values.ravel() var2 = np.repeat(df.var2.values, len(var1) / len(df))  pd.DataFrame({'var1': var1,               'var2': var2})    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  TL;DR  import pandas as pd import numpy as np  def explode_str(df, col, sep):     s = df[col]     i = np.arange(len(s)).repeat(s.str.count(sep) + 1)     return df.iloc[i].assign(**{col: sep.join(s).split(sep)})  def explode_list(df, col):     s = df[col]     i = np.arange(len(s)).repeat(s.str.len())     return df.iloc[i].assign(**{col: np.concatenate(s)})     Demonstration  explode_str(a, 'var1', ',')    var1  var2 0    a     1 0    b     1 0    c     1 1    d     2 1    e     2 1    f     2   Let's create a new dataframe d that has lists  d = a.assign(var1=lambda d: d.var1.str.split(','))  explode_list(d, 'var1')    var1  var2 0    a     1 0    b     1 0    c     1 1    d     2 1    e     2 1    f     2     General Comments  I'll use np.arange with repeat to produce dataframe index positions that I can use with iloc.  FAQ  Why don't I use loc?  Because the index may not be unique and using loc will return every row that matches a queried index.  Why don't you use the values attribute and slice that?  When calling values, if the entirety of the the dataframe is in one cohesive \"block\", Pandas will return a view of the array that is the \"block\".  Otherwise Pandas will have to cobble together a new array.  When cobbling, that array must be of a uniform dtype.  Often that means returning an array with dtype that is object.  By using iloc instead of slicing the values attribute, I alleviate myself from having to deal with that.  Why do you use assign?  When I use assign using the same column name that I'm exploding, I overwrite the existing column and maintain its position in the dataframe.  Why are the index values repeat?  By virtue of using iloc on repeated positions, the resulting index shows the same repeated pattern.  One repeat for each element the list or string. This can be reset with reset_index(drop=True)    For Strings  I don't want to have to split the strings prematurely.  So instead I count the occurrences of the sep argument assuming that if I were to split, the length of the resulting list would be one more than the number of separators.  I then use that sep to join the strings then split.  def explode_str(df, col, sep):     s = df[col]     i = np.arange(len(s)).repeat(s.str.count(sep) + 1)     return df.iloc[i].assign(**{col: sep.join(s).split(sep)})   For Lists  Similar as for strings except I don't need to count occurrences of sep because its already split.  I use Numpy's concatenate to jam the lists together.  import pandas as pd import numpy as np  def explode_list(df, col):     s = df[col]     i = np.arange(len(s)).repeat(s.str.len())     return df.iloc[i].assign(**{col: np.concatenate(s)})        ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Based on the excellent @DMulligan's solution, here is a generic vectorized (no loops) function which splits a column of a dataframe into multiple rows, and merges it back to the original dataframe. It also uses a great generic change_column_order function from this answer.  def change_column_order(df, col_name, index):     cols = df.columns.tolist()     cols.remove(col_name)     cols.insert(index, col_name)     return df[cols]  def split_df(dataframe, col_name, sep):     orig_col_index = dataframe.columns.tolist().index(col_name)     orig_index_name = dataframe.index.name     orig_columns = dataframe.columns     dataframe = dataframe.reset_index()  # we need a natural 0-based index for proper merge     index_col_name = (set(dataframe.columns) - set(orig_columns)).pop()     df_split = pd.DataFrame(         pd.DataFrame(dataframe[col_name].str.split(sep).tolist())         .stack().reset_index(level=1, drop=1), columns=[col_name])     df = dataframe.drop(col_name, axis=1)     df = pd.merge(df, df_split, left_index=True, right_index=True, how='inner')     df = df.set_index(index_col_name)     df.index.name = orig_index_name     # merge adds the column to the last place, so we need to move it back     return change_column_order(df, col_name, orig_col_index)   Example:  df = pd.DataFrame([['a:b', 1, 4], ['c:d', 2, 5], ['e:f:g:h', 3, 6]],                    columns=['Name', 'A', 'B'], index=[10, 12, 13]) df         Name    A   B     10   a:b     1   4     12   c:d     2   5     13   e:f:g:h 3   6  split_df(df, 'Name', ':')     Name    A   B 10   a       1   4 10   b       1   4 12   c       2   5 12   d       2   5 13   e       3   6 13   f       3   6     13   g       3   6     13   h       3   6       Note that it preserves the original index and order of the columns. It also works with dataframes which have non-sequential index.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Just used jiln's excellent answer from above, but needed to expand to split multiple columns. Thought I would share.  def splitDataFrameList(df,target_column,separator): ''' df = dataframe to split, target_column = the column containing the values to split separator = the symbol used to perform the split  returns: a dataframe with each entry for the target column separated, with each element moved into a new row.  The values in the other columns are duplicated across the newly divided rows. ''' def splitListToRows(row, row_accumulator, target_columns, separator):     split_rows = []     for target_column in target_columns:         split_rows.append(row[target_column].split(separator))     # Seperate for multiple columns     for i in range(len(split_rows[0])):         new_row = row.to_dict()         for j in range(len(split_rows)):             new_row[target_columns[j]] = split_rows[j][i]         row_accumulator.append(new_row) new_rows = [] df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator)) new_df = pd.DataFrame(new_rows) return new_df      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  The string function split can take an option boolean argument 'expand'.  Here is a solution using this argument:  a.var1.str.split(\",\",expand=True).set_index(a.var2).stack().reset_index(level=1, drop=True).reset_index().rename(columns={0:\"var1\"})      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  I have come up with the following solution to this problem:  def iter_var1(d):     for _, row in d.iterrows():         for v in row[\"var1\"].split(\",\"):             yield (v, row[\"var2\"])  new_a = DataFrame.from_records([i for i in iter_var1(a)],         columns=[\"var1\", \"var2\"])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Split (explode) pandas dataframe string entry to separate rows",
        "A_Content": "  Another solution that uses python copy package  import copy new_observations = list() def pandas_explode(df, column_to_explode):     new_observations = list()     for row in df.to_dict(orient='records'):         explode_values = row[column_to_explode]         del row[column_to_explode]         if type(explode_values) is list or type(explode_values) is tuple:             for explode_value in explode_values:                 new_observation = copy.deepcopy(row)                 new_observation[column_to_explode] = explode_value                 new_observations.append(new_observation)          else:             new_observation = copy.deepcopy(row)             new_observation[column_to_explode] = explode_values             new_observations.append(new_observation)      return_df = pd.DataFrame(new_observations)     return return_df  df = pandas_explode(df, column_name)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "numpy",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a pandas dataframe in which one column of text strings contains comma-separated values. I want to split each CSV field and create a new row per entry (assume that CSV are clean and need only be split on ','). For example, a should become b:  In [7]: a Out[7]:      var1  var2 0  a,b,c     1 1  d,e,f     2  In [8]: b Out[8]:    var1  var2 0    a     1 1    b     1 2    c     1 3    d     2 4    e     2 5    f     2   So far, I have tried various simple functions, but the .apply method seems to only accept one row as return value when it is used on an axis, and I can't get .transform to work. Any suggestions would be much appreciated!  Example data:   from pandas import DataFrame import numpy as np a = DataFrame([{'var1': 'a,b,c', 'var2': 1},                {'var1': 'd,e,f', 'var2': 2}]) b = DataFrame([{'var1': 'a', 'var2': 1},                {'var1': 'b', 'var2': 1},                {'var1': 'c', 'var2': 1},                {'var1': 'd', 'var2': 2},                {'var1': 'e', 'var2': 2},                {'var1': 'f', 'var2': 2}])   I know this won't work because we lose DataFrame meta-data by going through numpy, but it should give you a sense of what I tried to do:   def fun(row):     letters = row['var1']     letters = letters.split(',')     out = np.array([row] * len(letters))     out['var1'] = letters a['idx'] = range(a.shape[0]) z = a.groupby('idx') z.transform(fun)      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "foggy on asterisk in python",
        "A_Content": "  * is the \"splat\" operator: It takes a list as input, and expands it into actual positional arguments in the function call.  So if uniqueCrossTabs was [ [ 1, 2 ], [ 3, 4 ] ], then itertools.chain(*uniqueCrossTabs) is the same as saying itertools.chain([ 1, 2 ], [ 3, 4 ])  This is obviously different from passing in just uniqueCrossTabs. In your case, you have a list of lists that you wish to flatten; what itertools.chain() does is return an iterator over the concatenation of all the positional arguments you pass to it, where each positional argument is iterable in its own right.  In other words, you want to pass each list in uniqueCrossTabs as an argument to chain(), which will chain them together, but you don't have the lists in separate variables, so you use the * operator to expand the list of lists into several list arguments.  As Jochen Ritzel has pointed out in the comments, chain.from_iterable() is better-suited for this operation, as it assumes a single iterable of iterables to begin with. Your code then becomes simply:  uniqueCrossTabs = list(itertools.chain.from_iterable(uniqueCrossTabs))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "operators"
        ],
        "URL": "https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python",
        "A_Votes": "152",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm using itertools.chain to \"flatten\" a list of lists in this fashion:  uniqueCrossTabs = list(itertools.chain(*uniqueCrossTabs))   how is this different than saying:  uniqueCrossTabs = list(itertools.chain(uniqueCrossTabs))      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "foggy on asterisk in python",
        "A_Content": "  It splits the sequence into separate arguments for the function call.  >>> def foo(a, b=None, c=None): ...   print a, b, c ...  >>> foo([1, 2, 3]) [1, 2, 3] None None >>> foo(*[1, 2, 3]) 1 2 3 >>> def bar(*a): ...   print a ...  >>> bar([1, 2, 3]) ([1, 2, 3],) >>> bar(*[1, 2, 3]) (1, 2, 3)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "operators"
        ],
        "URL": "https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using itertools.chain to \"flatten\" a list of lists in this fashion:  uniqueCrossTabs = list(itertools.chain(*uniqueCrossTabs))   how is this different than saying:  uniqueCrossTabs = list(itertools.chain(uniqueCrossTabs))      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "foggy on asterisk in python",
        "A_Content": "  Just an alternative way of explaining the concept/using it.  import random  def arbitrary():     return [x for x in range(1, random.randint(3,10))]  a, b, *rest = arbitrary()  # a = 1 # b = 2 # rest = [3,4,5]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "operators"
        ],
        "URL": "https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm using itertools.chain to \"flatten\" a list of lists in this fashion:  uniqueCrossTabs = list(itertools.chain(*uniqueCrossTabs))   how is this different than saying:  uniqueCrossTabs = list(itertools.chain(uniqueCrossTabs))      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to display pandas DataFrame of floats using a format string for columns?",
        "A_Content": "  import pandas as pd pd.options.display.float_format = '${:,.2f}'.format df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print(df)   yields          cost foo  $123.46 bar  $234.57 baz  $345.68 quux $456.79   but this only works if you want every float to be formatted with a dollar sign.  Otherwise, if you want dollar formatting for some floats only, then I think you'll have to pre-modify the dataframe (converting those floats to strings):  import pandas as pd df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) df['foo'] = df['cost'] df['cost'] = df['cost'].map('${:,.2f}'.format) print(df)   yields           cost       foo foo   $123.46  123.4567 bar   $234.57  234.5678 baz   $345.68  345.6789 quux  $456.79  456.7890      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pandas",
            "ipython",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns",
        "A_Votes": "158",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I would like to display a pandas dataframe with a given format using print() and the IPython display(). For example:  df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print df           cost foo   123.4567 bar   234.5678 baz   345.6789 quux  456.7890   I would like to somehow coerce this into printing           cost foo   $123.46 bar   $234.57 baz   $345.68 quux  $456.79   without having to modify the data itself or create a copy, just change the way it is displayed.  How can I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to display pandas DataFrame of floats using a format string for columns?",
        "A_Content": "  If you don't want to modify the dataframe, you could use a custom formatter for that column.  import pandas as pd pd.options.display.float_format = '${:,.2f}'.format df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost'])   print df.to_string(formatters={'cost':'${:,.2f}'.format})   yields          cost foo  $123.46 bar  $234.57 baz  $345.68 quux $456.79      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pandas",
            "ipython",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns",
        "A_Votes": "54",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to display a pandas dataframe with a given format using print() and the IPython display(). For example:  df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print df           cost foo   123.4567 bar   234.5678 baz   345.6789 quux  456.7890   I would like to somehow coerce this into printing           cost foo   $123.46 bar   $234.57 baz   $345.68 quux  $456.79   without having to modify the data itself or create a copy, just change the way it is displayed.  How can I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to display pandas DataFrame of floats using a format string for columns?",
        "A_Content": "  Similar to unutbu above, you could also use applymap as follows:  import pandas as pd df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost'])  df = df.applymap(\"${0:.2f}\".format)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pandas",
            "ipython",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to display a pandas dataframe with a given format using print() and the IPython display(). For example:  df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print df           cost foo   123.4567 bar   234.5678 baz   345.6789 quux  456.7890   I would like to somehow coerce this into printing           cost foo   $123.46 bar   $234.57 baz   $345.68 quux  $456.79   without having to modify the data itself or create a copy, just change the way it is displayed.  How can I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to display pandas DataFrame of floats using a format string for columns?",
        "A_Content": "  As of Pandas 0.17 there is now a styling system which essentially provides formatted views of a DataFrame using Python format strings:  import pandas as pd import numpy as np  constants = pd.DataFrame([('pi',np.pi),('e',np.e)],                    columns=['name','value']) C = constants.style.format({'name': '~~ {} ~~', 'value':'--> {:15.10f} <--'}) C   which displays    This is a view object; the DataFrame itself does not change formatting, but updates in the DataFrame are reflected in the view:  constants.name = ['pie','eek'] C     However it appears to have some limitations:   Adding new rows and/or columns in-place seems to cause inconsistency in the styled view (doesn't add row/column labels):  constants.loc[2] = dict(name='bogus', value=123.456) constants['comment'] = ['fee','fie','fo'] constants      which looks ok but:  C      Formatting works only for values, not index entries:  constants = pd.DataFrame([('pi',np.pi),('e',np.e)],                columns=['name','value']) constants.set_index('name',inplace=True) C = constants.style.format({'name': '~~ {} ~~', 'value':'--> {:15.10f} <--'}) C         ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pandas",
            "ipython",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to display a pandas dataframe with a given format using print() and the IPython display(). For example:  df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print df           cost foo   123.4567 bar   234.5678 baz   345.6789 quux  456.7890   I would like to somehow coerce this into printing           cost foo   $123.46 bar   $234.57 baz   $345.68 quux  $456.79   without having to modify the data itself or create a copy, just change the way it is displayed.  How can I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to display pandas DataFrame of floats using a format string for columns?",
        "A_Content": "  I like using pandas.apply() with python format().  import pandas as pd s = pd.Series([1.357, 1.489, 2.333333])  make_float = lambda x: \"${:,.2f}\".format(x) s.apply(make_float)   Also, it can be easily used with multiple columns...  df = pd.concat([s, s * 2], axis=1)  make_floats = lambda row: \"${:,.2f}, ${:,.3f}\".format(row[0], row[1]) df.apply(make_floats, axis=1)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "pandas",
            "ipython",
            "dataframe"
        ],
        "URL": "https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to display a pandas dataframe with a given format using print() and the IPython display(). For example:  df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],                   index=['foo','bar','baz','quux'],                   columns=['cost']) print df           cost foo   123.4567 bar   234.5678 baz   345.6789 quux  456.7890   I would like to somehow coerce this into printing           cost foo   $123.46 bar   $234.57 baz   $345.68 quux  $456.79   without having to modify the data itself or create a copy, just change the way it is displayed.  How can I do this?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  You can use advanced string formatting, available in Python 2.6 and Python 3.x:  incoming = 'arbit' result = '{0} hello world {0} hello world {0}'.format(incoming)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "169",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  incoming = 'arbit' result = '%(s)s hello world %(s)s hello world %(s)s' % {'s': incoming}   You may like to have a read of this to get an understanding: String Formatting Operations.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  You can use the dictionary type of formatting:  s='arbit' string='%(key)s hello world %(key)s hello world %(key)s' % {'key': s,}      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  Depends on what you mean by better. This works if your goal is removal of redundancy.  s='foo' string='%s bar baz %s bar baz %s bar baz' % (3*(s,))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  >>> s1 ='arbit' >>> s2 = 'hello world '.join( [s]*3 ) >>> print s2 arbit hello world arbit hello world arbit      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Inserting the same value multiple times when formatting a string",
        "A_Content": "  Fstrings  If you are using Python 3.6+ you can make use of the new so called f-strings which stands for formatted strings and it can be used by adding the character f at the beginning of a string to identify this as an f-string.  price = 123 name = \"Jerry\" print(f\"{name}!!, {price} is much, isn't {price} a lot? {name}!\") >Jerry!!, 123 is much, isn't 123 a lot? Jerry!      The main benefits of using f-strings is that they are more readable, can be faster, and offer better performance:    Source Pandas for Everyone: Python Data Analysis, By Daniel Y. Chen  Benchmarks  No doubt that the new f-strings are more readable, as you don't have to remap the strings, but is it faster though as stated in the aformentioned quote?   price = 123 name = \"Jerry\"  def new():     x = f\"{name}!!, {price} is much, isn't {price} a lot? {name}!\"   def old():     x = \"{1}!!, {0} is much, isn't {0} a lot? {1}!\".format(price, name)  import timeit print(timeit.timeit('new()', setup='from __main__ import new', number=10**7)) print(timeit.timeit('old()', setup='from __main__ import old', number=10**7)) > 3.8741058271543776  #new > 5.861819514350163   #old   Running 10 Million test's it seems that the new f-strings are actually faster in mapping.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "format"
        ],
        "URL": "https://stackoverflow.com/questions/1225637/inserting-the-same-value-multiple-times-when-formatting-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a string of this form  s='arbit' string='%s hello world %s hello world %s' %(s,s,s)   All the %s in string have the same value (i.e. s). Is there a better way of writing this? (Rather than listing out s three times)     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python's os.makedirs doesn't understand “~” in my path",
        "A_Content": "  You need to expand the tilde manually:  my_dir = os.path.expanduser('~/some_dir')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/2057045/pythons-os-makedirs-doesnt-understand-in-my-path",
        "A_Votes": "169",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a little problem with ~ in my paths.  This code example creates some directories called \"~/some_dir\" and do not understand that I wanted to create some_dir in my home directory.  my_dir = \"~/some_dir\" if not os.path.exists(my_dir):     os.makedirs(my_dir)   Note this is on a Linux-based system.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python's os.makedirs doesn't understand “~” in my path",
        "A_Content": "  The conversion of ~/some_dir to $HOME/some_dir is called tilde expansion and is a common user interface feature. The file system does not know anything about it.  In Python, this feature is implemented by os.path.expanduser:  my_dir = os.path.expanduser(\"~/some_dir\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/2057045/pythons-os-makedirs-doesnt-understand-in-my-path",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a little problem with ~ in my paths.  This code example creates some directories called \"~/some_dir\" and do not understand that I wanted to create some_dir in my home directory.  my_dir = \"~/some_dir\" if not os.path.exists(my_dir):     os.makedirs(my_dir)   Note this is on a Linux-based system.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python's os.makedirs doesn't understand “~” in my path",
        "A_Content": "  That's probably because Python is not Bash and doesn't follow same conventions. You may use this:  homedir = os.path.expanduser('~')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/2057045/pythons-os-makedirs-doesnt-understand-in-my-path",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a little problem with ~ in my paths.  This code example creates some directories called \"~/some_dir\" and do not understand that I wanted to create some_dir in my home directory.  my_dir = \"~/some_dir\" if not os.path.exists(my_dir):     os.makedirs(my_dir)   Note this is on a Linux-based system.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Assuming your file is in the format of one nickname per line, use this.  First, open the file:  f = open(\"yourfile.txt\",\"r\")   Next, get all your lines from the file:  lines = f.readlines()   Now you can close the file:  f.close()   And reopen it in write mode:  f = open(\"yourfile.txt\",\"w\")   Then, write your lines back, except the line you want to delete. You might want to change the \"\\n\" to whatever line ending your file uses.  for line in lines:   if line!=\"nickname_to_delete\"+\"\\n\":     f.write(line)   At the end, close the file again.  f.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Solution to this problem with only a single open:  f = open(\"target.txt\",\"r+\") d = f.readlines() f.seek(0) for i in d:     if i != \"line you want to remove...\":         f.write(i) f.truncate() f.close()   This solution opens the file in r/w mode (\"r+\") and makes use of seek to reset the f-pointer then truncate to remove everything after the last write.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  The best and fastest option, rather than storing everything in a list and re-opening the file to write it, is in my opinion to re-write the file elsewhere.  with open(\"yourfile.txt\",\"r\") as input:     with open(\"newfile.txt\",\"wb\") as output:          for line in input:             if line!=\"nickname_to_delete\"+\"\\n\":                 output.write(line)   That's it! In one loop and one only you can do the same thing. It will be much faster.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  This is a \"fork\" from @Lother's answer (which I believe that should be considered the right answer).   For a file like this:  $ cat file.txt  1: october rust 2: november rain 3: december snow   This fork from Lother's solution works fine:  #!/usr/bin/python3.4  with open(\"file.txt\",\"r+\") as f:     new_f = f.readlines()     f.seek(0)     for line in new_f:         if \"snow\" not in line:             f.write(line)     f.truncate()   Improvements:    with open, which discard the usage of f.close() more clearer if/else for evaluating if string is not present in the current line      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  The issue with reading lines in first pass and making changes (deleting specific lines) in the second pass is that if you file sizes are huge, you will run out of RAM. Instead, a better approach is to read lines, one by one, and write them into a separate file, eliminating the ones you don't need. I have run this approach with files as big as 12-50 GB, and the RAM usage remains almost constant. Only CPU cycles show processing in progress.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  If you use Linux, you can try the following approach. Suppose you have a text file named animal.txt:                  $ cat animal.txt   dog pig cat  monkey          elephant     Delete the first line:  >>> import subprocess >>> subprocess.call(['sed','-i','/.*dog.*/d','animal.txt'])    then          $ cat animal.txt pig cat monkey elephant      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  I think if you read the file into a list, then do the you can iterate over the list to look for the nickname you want to get rid of. You can do it much efficiently without creating additional files, but you'll have to write the result back to the source file.  Here's how I might do this:  import, os, csv # and other imports you need nicknames_to_delete = ['Nick', 'Stephen', 'Mark']   I'm assuming nicknames.csv contains data like:  Nick Maria James Chris Mario Stephen Isabella Ahmed Julia Mark ...   Then load the file into the list:   nicknames = None  with open(\"nicknames.csv\") as sourceFile:      nicknames = sourceFile.read().splitlines()   Next, iterate over to list to match your inputs to delete:  for nick in nicknames_to_delete:      try:          if nick in nicknames:              nicknames.pop(nicknames.index(nick))          else:              print(nick + \" is not found in the file\")      except ValueError:          pass   Lastly, write the result back to file:  with open(\"nicknames.csv\", \"a\") as nicknamesFile:     nicknamesFile.seek(0)     nicknamesFile.truncate()     nicknamesWriter = csv.writer(nicknamesFile)     for name in nicknames:         nicknamesWriter.writeRow([str(name)]) nicknamesFile.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Not a good solve if u put a whole file to memory, i know nowadays everyone have tons of memory, but consider if the file is several GB of logs or something.  Better way copy it line by line to a new file, than delete the first or something like that     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  In general, you can't; you have to write the whole file again (at least from the point of change to the end).  In some specific cases you can do better than this -  if all your data elements are the same length and in no specific order, and you know the offset of the one you want to get rid of, you could copy the last item over the one to be deleted and truncate the file before the last item;  or you could just overwrite the data chunk with a 'this is bad data, skip it' value or keep a 'this item has been deleted' flag in your saved data elements such that you can mark it deleted without otherwise modifying the file.  This is probably overkill for short documents (anything under 100 KB?).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  I liked the fileinput approach as explained in this answer: Deleting a line from a text file (python)  Say for example I have a file which has empty lines in it and I want to remove empty lines, here's how I solved it:  import fileinput import sys for line_number, line in enumerate(fileinput.input('file1.txt', inplace=1)):     if len(line) > 1:             sys.stdout.write(line)      Note: The empty lines in my case had length 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Probably, you already got a correct answer, but here is mine. Instead of using a list to collect unfiltered data (what readlines() method does), I use two files. One is for hold a main data, and the second is for filtering the data when you delete a specific string.  Here is a code:  main_file = open('data_base.txt').read()    # your main dataBase file filter_file = open('filter_base.txt', 'w') filter_file.write(main_file) filter_file.close() main_file = open('data_base.txt', 'w') for line in open('filter_base'):     if 'your data to delete' not in line:    # remove a specific string         main_file.write(line)                # put all strings back to your db except deleted     else: pass main_file.close()   Hope you will find this useful! :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Save the file lines in a list, then remove of the list the line you want to delete and write the remain lines to a new file   with open(\"file_name.txt\", \"r\") as f:     lines = f.readlines()      lines.remove(\"Line you want to delete\\n\")     with open(\"new_file.txt\", \"w\") as new_f:         for line in lines:                     new_f.write(line)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Deleting a specific line in a file (python)",
        "A_Content": "  Take the contents of the file, split it by newline into a tuple.  Then, access your tuple's line number, join your result tuple, and overwrite to the file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "file",
            "input"
        ],
        "URL": "https://stackoverflow.com/questions/4710067/deleting-a-specific-line-in-a-file-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have a text file full of nicknames, how can I delete a specific nickname from that file?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "how to create a file name with the current date & time in python?",
        "A_Content": "  While not using datetime, this solves your problem (answers your question) of getting a string with the current time and date format you specify:  import time timestr = time.strftime(\"%Y%m%d-%H%M%S\") print timestr   yields:  20120515-155045   so your filename could append or use this string.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10607688/how-to-create-a-file-name-with-the-current-date-time-in-python",
        "A_Votes": "200",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Here is a functional code (Create file with success)  sys.stdout = open('filename1.xml', 'w')   Now I'm trying to name the file with the current Date Time (I'm not an expert in python)  filename1 = datetime.now().strftime(\"%Y%m%d-%H%M%S\") sys.stdout = open(filename1 + '.xml', 'w')   I want to write out a file name with the exact date and time, it is a xml file, that the program has already create, I just need to name the file. The above code is not working.  [EDITED] - The error returned    File \"./fix.py\", line 226, in <module>     filenames = datetime.now().strftime(\"%Y%m%d-%H%M%S\") AttributeError: 'module' object has no attribute 'now'      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "how to create a file name with the current date & time in python?",
        "A_Content": "  now is a class method in the class datetime in the module datetime. So you need  datetime.datetime.now()   Or you can use a different import  from datetime import datetime   Done this way allows you to use datetime.now as per the code in the question.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10607688/how-to-create-a-file-name-with-the-current-date-time-in-python",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is a functional code (Create file with success)  sys.stdout = open('filename1.xml', 'w')   Now I'm trying to name the file with the current Date Time (I'm not an expert in python)  filename1 = datetime.now().strftime(\"%Y%m%d-%H%M%S\") sys.stdout = open(filename1 + '.xml', 'w')   I want to write out a file name with the exact date and time, it is a xml file, that the program has already create, I just need to name the file. The above code is not working.  [EDITED] - The error returned    File \"./fix.py\", line 226, in <module>     filenames = datetime.now().strftime(\"%Y%m%d-%H%M%S\") AttributeError: 'module' object has no attribute 'now'      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "how to create a file name with the current date & time in python?",
        "A_Content": "  Change this line  filename1 = datetime.now().strftime(\"%Y%m%d-%H%M%S\")   To  filename1 = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")   Note the extra datetime. Alternatively, change your  import datetime to from datetime import datetime     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10607688/how-to-create-a-file-name-with-the-current-date-time-in-python",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is a functional code (Create file with success)  sys.stdout = open('filename1.xml', 'w')   Now I'm trying to name the file with the current Date Time (I'm not an expert in python)  filename1 = datetime.now().strftime(\"%Y%m%d-%H%M%S\") sys.stdout = open(filename1 + '.xml', 'w')   I want to write out a file name with the exact date and time, it is a xml file, that the program has already create, I just need to name the file. The above code is not working.  [EDITED] - The error returned    File \"./fix.py\", line 226, in <module>     filenames = datetime.now().strftime(\"%Y%m%d-%H%M%S\") AttributeError: 'module' object has no attribute 'now'      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "how to create a file name with the current date & time in python?",
        "A_Content": "  I'm surprised there is not some single formatter that returns a default (and safe) 'for appending in filename' - format of the time,  We could simply write FD.write('mybackup'+time.strftime('%(formatter here)') + 'ext'   \"%x\" instead of \"%Y%m%d-%H%M%S\"      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10607688/how-to-create-a-file-name-with-the-current-date-time-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is a functional code (Create file with success)  sys.stdout = open('filename1.xml', 'w')   Now I'm trying to name the file with the current Date Time (I'm not an expert in python)  filename1 = datetime.now().strftime(\"%Y%m%d-%H%M%S\") sys.stdout = open(filename1 + '.xml', 'w')   I want to write out a file name with the exact date and time, it is a xml file, that the program has already create, I just need to name the file. The above code is not working.  [EDITED] - The error returned    File \"./fix.py\", line 226, in <module>     filenames = datetime.now().strftime(\"%Y%m%d-%H%M%S\") AttributeError: 'module' object has no attribute 'now'      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Perhaps you could use something like this:  import urllib2  def internet_on():     try:         urllib2.urlopen('http://216.58.192.142', timeout=1)         return True     except urllib2.URLError as err:          return False   Currently, 216.58.192.142 is one of the IP addresses for google.com. Change http://216.58.192.142 to whatever site can be expected to respond quickly.   This fixed IP will not map to google.com forever. So this code is not robust -- it will need constant maintenance to keep it working.   The reason why the code above uses a fixed IP address instead of fully qualified domain name (FQDN) is because a FQDN would require a DNS lookup. When the machine does not have a working internet connection, the DNS lookup itself may block the call to urllib_request.urlopen for more than a second. Thanks to @rzetterberg for pointing this out.    If the fixed IP address above is not working, you can find a current IP address for google.com (on unix) by running  % dig google.com  +trace  ... google.com.     300 IN  A   216.58.192.142      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "105",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  If we can connect to some Internet server, then we indeed have connectivity. However, for the fastest and most reliable approach, all solutions should comply with the following requirements, at the very least:   Avoid DNS resolution (we will need an IP that is well-known and guaranteed to be available for most of the time) Avoid application layer based connections (connecting to a HTTP/FTP/IMAP service) Avoid calls to external utilities from Python or other language of choice (we need to come up with a language-agnostic solution that doesn't rely on third-party solutions)   To comply with these, one approach could be to, check if one of the Google's public DNS servers is reachable. The IPv4 addresses for these servers are 8.8.8.8 and 8.8.4.4. We can try connecting to any of them.  A quick Nmap of the host 8.8.8.8 gave below result:  $ sudo nmap 8.8.8.8  Starting Nmap 6.40 ( http://nmap.org ) at 2015-10-14 10:17 IST Nmap scan report for google-public-dns-a.google.com (8.8.8.8) Host is up (0.0048s latency). Not shown: 999 filtered ports PORT   STATE SERVICE 53/tcp open  domain  Nmap done: 1 IP address (1 host up) scanned in 23.81 seconds   As we can see, TCP/53 is open and non-filtered. If you are a non-root user, remember to use sudo or the -Pn argument for Nmap to send crafted probe packets and determine if host is up.  Before we try with Python, let's test connectivity using an external tool, Netcat:  $ nc 8.8.8.8 53 -zv Connection to 8.8.8.8 53 port [tcp/domain] succeeded!   Netcat confirms that we can reach 8.8.8.8 over TCP/53. Now we can set up a socket connection to 8.8.8.8:53/TCP in Python to check connection:  >>> import socket >>> >>> def internet(host=\"8.8.8.8\", port=53, timeout=3): ...   \"\"\" ...   Host: 8.8.8.8 (google-public-dns-a.google.com) ...   OpenPort: 53/tcp ...   Service: domain (DNS/TCP) ...   \"\"\" ...   try: ...     socket.setdefaulttimeout(timeout) ...     socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect((host, port)) ...     return True ...   except Exception as ex: ...     print ex.message ...     return False ... >>> internet() True >>>   Another approach could be to send a manually crafted DNS probe to one of these servers and wait for response. But, I assume, it might prove slower in comparison due to packet drops, DNS resolution failure, etc. Please comment if you think otherwise.  UPDATE #1: Thanks to @theamk's comment, timeout is now an argument and initialized to 3s by default.  UPDATE #2: I did quick tests to identify the fastest and most generic implementation of all valid answers to this question. Here's the summary:  $ ls *.py | sort -n | xargs -I % sh -c 'echo %; ./timeit.sh %; echo' defos.py True 00:00:00:00.487  iamaziz.py True 00:00:00:00.335  ivelin.py True 00:00:00:00.105  jaredb.py True 00:00:00:00.533  kevinc.py True 00:00:00:00.295  unutbu.py True 00:00:00:00.546  7h3rAm.py True 00:00:00:00.032   And once more:  $ ls *.py | sort -n | xargs -I % sh -c 'echo %; ./timeit.sh %; echo' defos.py True 00:00:00:00.450  iamaziz.py True 00:00:00:00.358  ivelin.py True 00:00:00:00.099  jaredb.py True 00:00:00:00.585  kevinc.py True 00:00:00:00.492  unutbu.py True 00:00:00:00.485  7h3rAm.py True 00:00:00:00.035   True in the above output signifies that all these implementations from respective authors correctly identify connectivity to Internet. Time is shown with milliseconds resolution.  UPDATE #3: Tested again after the exception handling change:  defos.py True 00:00:00:00.410  iamaziz.py True 00:00:00:00.240  ivelin.py True 00:00:00:00.109  jaredb.py True 00:00:00:00.520  kevinc.py True 00:00:00:00.317  unutbu.py True 00:00:00:00.436  7h3rAm.py True 00:00:00:00.030      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  It will be faster to just make a HEAD request so no HTML will be fetched. Also I am sure google would like it better this way :)   try:     import httplib except:     import http.client as httplib  def have_internet():     conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)     try:         conn.request(\"HEAD\", \"/\")         conn.close()         return True     except:         conn.close()         return False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Just to update what unutbu said for new code in Python 3.2  def check_connectivity(reference):     try:         urllib.request.urlopen(reference, timeout=1)         return True     except urllib.request.URLError:         return False   And, just to note, the input here (reference) is the url that you want to check: I suggest choosing something that connects fast where you live -- i.e. I live in South Korea, so I would probably set reference to http://www.naver.com.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  As an alternative to ubutnu's/Kevin C answers, I use the requests package like this:  import requests  def connected_to_internet(url='http://www.google.com/', timeout=5):     try:         _ = requests.get(url, timeout=timeout)         return True     except requests.ConnectionError:         print(\"No internet connection available.\")     return False   Bonus: this can be extended to this function that pings a website.  def web_site_online(url='http://www.google.com/', timeout=5):     try:         req = requests.get(url, timeout=timeout)         # HTTP errors are not raised by default, this statement does that         req.raise_for_status()         return True     except requests.HTTPError as e:         print(\"Checking internet connection failed, status code {0}.\".format(         e.response.status_code))     except requests.ConnectionError:         print(\"No internet connection available.\")     return False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  You can just try to download data, and if connection fail you will know that somethings with connection isn't fine.  Basically you can't check if computer is connected to internet. There can be many reasons for failure, like wrong DNS configuration, firewalls, NAT. So even if you make some tests, you can't have guaranteed that you will have connection with your API until you try.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  import urllib  def connected(host='http://google.com'):     try:         urllib.urlopen(host)         return True     except:         return False  # test print( 'connected' if connected() else 'no internet!' )   For python 3, use urllib.request.urlopen(host)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Try the operation you were attempting to do anyway. If it fails python should throw you an exception to let you know.  To try some trivial operation first to detect a connection will be introducing a race condition. What if the internet connection is valid when you test but goes down before you need to do actual work?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Best way to do this is to make it check against an IP address that python always gives if it can't find the website. In this case this is my code:  import socket  print(\"website connection checker\") while True:     website = input(\"please input website: \")     print(\"\")     print(socket.gethostbyname(website))     if socket.gethostbyname(website) == \"92.242.140.2\":         print(\"Website could be experiencing an issue/Doesn't exist\")     else:         socket.gethostbyname(website)         print(\"Website is operational!\")         print(\"\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Taking unutbu's answer as a starting point, and having been burned in the past by a \"static\" IP address changing, I've made a simple class that checks once using a DNS lookup (i.e., using the URL \"https://www.google.com\"), and then stores the IP address of the responding server for use on subsequent checks.  That way, the IP address is always up to date (assuming the class is re-initialized at least once every few years or so).  I also give credit to gawry for this answer, which showed me how to get the server's IP address (after any redirection, etc.).  Please disregard the apparent hackiness of this solution, I'm going for a minimal working example here. :)  Here is what I have:  import socket  try:     from urllib2 import urlopen, URLError     from urlparse import urlparse except ImportError:  # Python 3     from urllib.parse import urlparse     from urllib.request import urlopen, URLError  class InternetChecker(object):     conn_url = 'https://www.google.com/'      def __init__(self):         pass      def test_internet(self):         try:             data = urlopen(self.conn_url, timeout=5)         except URLError:             return False          try:             host = data.fp._sock.fp._sock.getpeername()         except AttributeError:  # Python 3             host = data.fp.raw._sock.getpeername()          # Ensure conn_url is an IPv4 address otherwise future queries will fail         self.conn_url = 'http://' + (host[0] if len(host) == 2 else                                      socket.gethostbyname(urlparse(data.geturl()).hostname))          return True  # Usage example checker = InternetChecker() checker.test_internet()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  This might not work if the localhost has been changed from 127.0.0.1 Try   import socket ipaddress=socket.gethostbyname(socket.gethostname()) if ipaddress==\"127.0.0.1\":     print(\"You are not connected to the internet!\") else:     print(\"You are connected to the internet with the IP address of \"+ ipaddress )   Unless edited , your computers IP will be 127.0.0.1 when not connected to the internet. This code basically gets the IP address and then asks if it is the localhost IP address . Hope that helps     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  Taking Six' answer I think we could simplify somehow, an important issue as newcomers are lost in highly technical matters.  Here what I finally will use to wait for my connection (3G, slow) to be established once a day for my PV monitoring.  Works under Pyth3 with Raspbian 3.4.2  from urllib.request import urlopen from time import sleep urltotest=http://www.lsdx.eu             # my own web page nboftrials=0 answer='NO' while answer=='NO' and nboftrials<10:     try:         urlopen(urltotest)         answer='YES'     except:         essai='NO'         nboftrials+=1         sleep(30)          maximum running: 5 minutes if reached I will try in one hour's time but its another bit of script!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Checking network connection",
        "A_Content": "  my favorite one, when running scripts on a cluster or not  import subprocess  def online(timeout):     try:         return subprocess.run(             ['wget', '-q', '--spider', 'google.com'],             timeout=timeout         ).returncode == 0     except subprocess.TimeoutExpired:         return False   this runs wget quietly, not downloading anything but checking that the given remote file exists on the web     ",
        "Language": "Python",
        "Tags": [
            "python",
            "networking"
        ],
        "URL": "https://stackoverflow.com/questions/3764291/checking-network-connection",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to see if I can access an online API, but for that I need to have Internet access.  How can I see if there's a connection available and active using Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  As suggested by Mark Ransom, I found the right encoding for that problem. The encoding was \"ISO-8859-1\", so replacing open(\"u.item\", encoding=\"utf-8\") with open('u.item', encoding = \"ISO-8859-1\") will solve the problem.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "212",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  Your file doesn't actually contain utf-8 encoded data, it contains some other encoding. Figure out what that encoding is and use it in the open call.  In Windows-1252 encoding for example the 0xe9 would be the character é.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  Try this to read using pandas   pd.read_csv('u.item', sep='|', names=m_cols , encoding='latin-1')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  Also worked for me, ISO 8859-1 is going to save a lot, hahaha, mainly if using Speech Recognition API's  Example:   file = open('../Resources/' + filename, 'r', encoding=\"ISO-8859-1\");      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  If you are using Python 2 the following will the solution:  import io for line in io.open(\"u.item\", encoding=\"ISO-8859-1\"):     # do something   Because encoding parameter doesn't work with open(), you will be getting the following error:   TypeError: 'encoding' is an invalid keyword argument for this function      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  If someone looking for these, this is an example for converting a CSV file in Python 3:  try:     inputReader = csv.reader(open(argv[1], encoding='ISO-8859-1'), delimiter=',',quotechar='\"') except IOError:     pass      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'utf-8' codec can't decode byte",
        "A_Content": "  Sometimes when open(filepath) in which filepath actually is not a file would get the same error, so firstly make sure the file you're trying to open exists:  import os assert os.path.isfile(filepath)   hope this will help.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/19699367/unicodedecodeerror-utf-8-codec-cant-decode-byte",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Here is my code,        for line in open('u.item'): #read each line   whenever I run this code it gives the following error:  UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 2892: invalid continuation byte   I tried to solve this and add an extra parameter in open(), the code looks like;  for line in open('u.item', encoding='utf-8'): #read each line   But again it gives the same error.  what should I do then! Please help.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  So make a temporary dict with the key being the id. This filters out the duplicates. The values() of the dict will be the list  In Python2.7  >>> L=[ ... {'id':1,'name':'john', 'age':34}, ... {'id':1,'name':'john', 'age':34}, ... {'id':2,'name':'hanna', 'age':30}, ... ] >>> {v['id']:v for v in L}.values() [{'age': 34, 'id': 1, 'name': 'john'}, {'age': 30, 'id': 2, 'name': 'hanna'}]   In Python3  >>> L=[ ... {'id':1,'name':'john', 'age':34}, ... {'id':1,'name':'john', 'age':34}, ... {'id':2,'name':'hanna', 'age':30}, ... ]  >>> list({v['id']:v for v in L}.values()) [{'age': 34, 'id': 1, 'name': 'john'}, {'age': 30, 'id': 2, 'name': 'hanna'}]   In Python2.5/2.6  >>> L=[ ... {'id':1,'name':'john', 'age':34}, ... {'id':1,'name':'john', 'age':34}, ... {'id':2,'name':'hanna', 'age':30}, ... ]  >>> dict((v['id'],v) for v in L).values() [{'age': 34, 'id': 1, 'name': 'john'}, {'age': 30, 'id': 2, 'name': 'hanna'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "148",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  The usual way to find just the common elements in a set is to use Python's set class.  Just add all the elements to the set, then convert the set to a list, and bam the duplicates are gone.  The problem, of course, is that a set() can only contain hashable entries, and a dict is not hashable.  If I had this problem, my solution would be to convert each dict into a string that represents the dict, then add all the strings to a set() then read out the string values as a list() and convert back to dict.  A good representation of a dict in string form is JSON format.  And Python has a built-in module for JSON (called json of course).  The remaining problem is that the elements in a dict are not ordered, and when Python converts the dict to a JSON string, you might get two JSON strings that represent equivalent dictionaries but are not identical strings.  The easy solution is to pass the argument sort_keys=True when you call json.dumps().   EDIT: This solution was assuming that a given dict could have any part different.  If we can assume that every dict with the same \"id\" value will match every other dict with the same \"id\" value, then this is overkill; @gnibbler's solution would be faster and easier.  EDIT: Now there is a comment from André Lima explicitly saying that if the ID is a duplicate, it's safe to assume that the whole dict is a duplicate.  So this answer is overkill and I recommend @gnibbler's answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "55",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  You can use numpy library (works for Python2.x only):     import numpy as np      list_of_unique_dicts=list(np.unique(np.array(list_of_dicts)))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  Here's a reasonably compact solution, though I suspect not particularly efficient (to put it mildly):  >>> ds = [{'id':1,'name':'john', 'age':34}, ...       {'id':1,'name':'john', 'age':34}, ...       {'id':2,'name':'hanna', 'age':30} ...       ] >>> map(dict, set(tuple(sorted(d.items())) for d in ds)) [{'age': 30, 'id': 2, 'name': 'hanna'}, {'age': 34, 'id': 1, 'name': 'john'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  In case the dictionaries are only uniquely identified by all items (ID is not available) you can use the answer using JSON. The following is an alternative that does not use JSON, and will work as long as all dictionary values are immutable  [dict(s) for s in set(frozenset(d.items()) for d in L)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  Since the id is sufficient for detecting duplicates, and the id is hashable: run 'em through a dictionary that has the id as the key. The value for each key is the original dictionary.  deduped_dicts = dict((item[\"id\"], item) for item in list_of_dicts).values()   In Python 3, values() doesn't return a list; you'll need to wrap the whole right-hand-side of that expression in list(), and you can write the meat of the expression more economically as a dict comprehension:  deduped_dicts = list({item[\"id\"]: item for item in list_of_dicts}.values())   Note that the result likely will not be in the same order as the original. If that's a requirement, you could use a Collections.OrderedDict instead of a dict.  As an aside, it may make a good deal of sense to just keep the data in a dictionary that uses the id as key to begin with.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  a = [ {'id':1,'name':'john', 'age':34}, {'id':1,'name':'john', 'age':34}, {'id':2,'name':'hanna', 'age':30}, ]  b = {x['id']:x for x in a}.values()  print(b)   outputs:     [{'age': 34, 'id': 1, 'name': 'john'}, {'age': 30, 'id': 2, 'name': 'hanna'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  Expanding on John La Rooy (Python - List of unique dictionaries) answer, making it a bit more flexible:  def dedup_dict_list(list_of_dicts: list, columns: list) -> list:     return list({''.join(row[column] for column in columns): row                 for row in list_of_dicts}.values())   Calling Function:  sorted_list_of_dicts = dedup_dict_list(     unsorted_list_of_dicts, ['id', 'name'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  Pretty straightforward option:  L = [     {'id':1,'name':'john', 'age':34},     {'id':1,'name':'john', 'age':34},     {'id':2,'name':'hanna', 'age':30},     ]   D = dict() for l in L: D[l['id']] = l output = list(D.values()) print output      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  Heres an implementation with little memory overhead at the cost of not being as compact as the rest.  values = [ {'id':2,'name':'hanna', 'age':30},            {'id':1,'name':'john', 'age':34},            {'id':1,'name':'john', 'age':34},            {'id':2,'name':'hanna', 'age':30},            {'id':1,'name':'john', 'age':34},] count = {} index = 0 while index < len(values):     if values[index]['id'] in count:         del values[index]     else:         count[values[index]['id']] = 1         index += 1   output:  [{'age': 30, 'id': 2, 'name': 'hanna'}, {'age': 34, 'id': 1, 'name': 'john'}]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  This is the solution I found:  usedID = []  x = [ {'id':1,'name':'john', 'age':34}, {'id':1,'name':'john', 'age':34}, {'id':2,'name':'hanna', 'age':30}, ]  for each in x:     if each['id'] in usedID:         x.remove(each)     else:         usedID.append(each['id'])  print x   Basically you check if the ID is present in the list, if it is, delete the dictionary, if not, append the ID to the list     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  A quick-and-dirty solution is just by generating a new list.  sortedlist = []  for item in listwhichneedssorting:     if item not in sortedlist:         sortedlist.append(item)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Python - List of unique dictionaries",
        "A_Content": "  I don't if you only want the id of your dicts in the list to be unique, but if the goal is to have a set of dict where the unicity is on all keys' values.. you should use tuples key like this in your comprehension :  >>> L=[ ...     {'id':1,'name':'john', 'age':34}, ...    {'id':1,'name':'john', 'age':34},  ...    {'id':2,'name':'hanna', 'age':30}, ...    {'id':2,'name':'hanna', 'age':50} ...    ] >>> len(L) 4 >>> L=list({(v['id'], v['age'], v['name']):v for v in L}.values()) >>>L [{'id': 1, 'name': 'john', 'age': 34}, {'id': 2, 'name': 'hanna', 'age': 30}, {'id': 2, 'name': 'hanna', 'age': 50}] >>>len(L) 3   Hope it helps you or another person having the concern....     ",
        "Language": "Python",
        "Tags": [
            "python",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/11092511/python-list-of-unique-dictionaries",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I got a list of dictionaries:  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   and I need to obtain a list of unique dictionaries (removing the duplicates):  [     {'id': 1, 'name': 'john', 'age': 34},     {'id': 2, 'name': 'hanna', 'age': 30}, ]   Can anyone help me with the most efficient way to achieve this in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to create a density plot in matplotlib?",
        "A_Content": "  Sven has shown how to use the class gaussian_kde from Scipy, but you will notice that it doesn't look quite like what you generated with R. This is because gaussian_kde tries to infer the bandwidth automatically. You can play with the bandwidth in a way by changing the function covariance_factor of the gaussian_kde class. First, here is what you get without changing that function:    However, if I use the following code:  import matplotlib.pyplot as plt import numpy as np from scipy.stats import gaussian_kde data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 density = gaussian_kde(data) xs = np.linspace(0,8,200) density.covariance_factor = lambda : .25 density._compute_covariance() plt.plot(xs,density(xs)) plt.show()   I get    which is pretty close to what you are getting from R. What have I done? gaussian_kde uses a changable function, covariance_factor to calculate it's bandwidth. Before changing the function, the value returned by covariance_factor for this data was about .5. Lowering this lowered the bandwidth. I had to call _compute_covariance after changing that function so that all of the factors would be calculated correctly. It isn't an exact correspondence with the bw parameter from R, but hopefully it helps you get in the right direction.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "r",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/4150171/how-to-create-a-density-plot-in-matplotlib",
        "A_Votes": "104",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In R I can create the desired output by doing:   data = c(rep(1.5, 7), rep(2.5, 2), rep(3.5, 8),          rep(4.5, 3), rep(5.5, 1), rep(6.5, 8)) plot(density(data, bw=0.5))     In python (with matplotlib) the closest I got was with a simple histogram:  import matplotlib.pyplot as plt data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 plt.hist(data, bins=6) plt.show()     I also tried the normed=True parameter but couldn't get anything other than trying to fit a gaussian to the histogram.  My latest attempts were around scipy.stats and gaussian_kde, following examples on the web, but I've been unsuccessful so far.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to create a density plot in matplotlib?",
        "A_Content": "  Five years later, when I Google \"how to create a kernel density plot using python\", this thread still shows up at the top!   Today, a much easier way to do this is to use seaborn, a package that provides many convenient plotting functions and good style management.  import numpy as np import seaborn as sns data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 sns.set_style('whitegrid') sns.kdeplot(np.array(data), bw=0.5)        ",
        "Language": "Python",
        "Tags": [
            "python",
            "r",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/4150171/how-to-create-a-density-plot-in-matplotlib",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R I can create the desired output by doing:   data = c(rep(1.5, 7), rep(2.5, 2), rep(3.5, 8),          rep(4.5, 3), rep(5.5, 1), rep(6.5, 8)) plot(density(data, bw=0.5))     In python (with matplotlib) the closest I got was with a simple histogram:  import matplotlib.pyplot as plt data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 plt.hist(data, bins=6) plt.show()     I also tried the normed=True parameter but couldn't get anything other than trying to fit a gaussian to the histogram.  My latest attempts were around scipy.stats and gaussian_kde, following examples on the web, but I've been unsuccessful so far.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to create a density plot in matplotlib?",
        "A_Content": "  Maybe try something like:  import matplotlib.pyplot as plt import numpy from scipy import stats data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 density = stats.kde.gaussian_kde(data) x = numpy.arange(0., 8, .1) plt.plot(x, density(x)) plt.show()   You can easily replace gaussian_kde() by a different kernel density estimate.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "r",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/4150171/how-to-create-a-density-plot-in-matplotlib",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R I can create the desired output by doing:   data = c(rep(1.5, 7), rep(2.5, 2), rep(3.5, 8),          rep(4.5, 3), rep(5.5, 1), rep(6.5, 8)) plot(density(data, bw=0.5))     In python (with matplotlib) the closest I got was with a simple histogram:  import matplotlib.pyplot as plt data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 plt.hist(data, bins=6) plt.show()     I also tried the normed=True parameter but couldn't get anything other than trying to fit a gaussian to the histogram.  My latest attempts were around scipy.stats and gaussian_kde, following examples on the web, but I've been unsuccessful so far.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to create a density plot in matplotlib?",
        "A_Content": "  Option 1:  Use pandas dataframe plot (built on top of matplotlib):   import pandas as pd data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 pd.DataFrame(data).plot(kind='density') # or pd.Series()     Option 2:  Use distplot of seaborn:  import seaborn as sns data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 sns.distplot(data, hist=False)        ",
        "Language": "Python",
        "Tags": [
            "python",
            "r",
            "numpy",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/4150171/how-to-create-a-density-plot-in-matplotlib",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In R I can create the desired output by doing:   data = c(rep(1.5, 7), rep(2.5, 2), rep(3.5, 8),          rep(4.5, 3), rep(5.5, 1), rep(6.5, 8)) plot(density(data, bw=0.5))     In python (with matplotlib) the closest I got was with a simple histogram:  import matplotlib.pyplot as plt data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8 plt.hist(data, bins=6) plt.show()     I also tried the normed=True parameter but couldn't get anything other than trying to fit a gaussian to the histogram.  My latest attempts were around scipy.stats and gaussian_kde, following examples on the web, but I've been unsuccessful so far.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Removing all non-numeric characters from string in Python",
        "A_Content": "  >>> import re >>> re.sub(\"[^0-9]\", \"\", \"sdkjh987978asd098as0980a98sd\") '987978098098098'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/1249388/removing-all-non-numeric-characters-from-string-in-python",
        "A_Votes": "183",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How do we remove all non-numeric characters from a string in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Removing all non-numeric characters from string in Python",
        "A_Content": "  Not sure if this is the most efficient way, but:  >>> ''.join(c for c in \"abc123def456\" if c.isdigit()) '123456'   The ''.join part means to combine all the resulting characters together without any characters in between.  Then the rest of it is a list comprehension, where (as you can probably guess) we only take the parts of the string that match the condition isdigit.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/1249388/removing-all-non-numeric-characters-from-string-in-python",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do we remove all non-numeric characters from a string in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Removing all non-numeric characters from string in Python",
        "A_Content": "  This should work for strings and unicode objects:  # python <3.0 def only_numerics(seq):     return filter(type(seq).isdigit, seq)  # python ≥3.0 def only_numerics(seq):     seq_type= type(seq)     return seq_type().join(filter(seq_type.isdigit, seq))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/1249388/removing-all-non-numeric-characters-from-string-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do we remove all non-numeric characters from a string in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Removing all non-numeric characters from string in Python",
        "A_Content": "  Fastest approach, if you need to perform more than just one or two such removal operations (or even just one, but on a very long string!-), is to rely on the translate method of strings, even though it does need some prep:  >>> import string >>> allchars = ''.join(chr(i) for i in xrange(256)) >>> identity = string.maketrans('', '') >>> nondigits = allchars.translate(identity, string.digits) >>> s = 'abc123def456' >>> s.translate(identity, nondigits) '123456'   The translate method is different, and maybe a tad simpler simpler to use, on Unicode strings than it is on byte strings, btw:  >>> unondig = dict.fromkeys(xrange(65536)) >>> for x in string.digits: del unondig[ord(x)] ...  >>> s = u'abc123def456' >>> s.translate(unondig) u'123456'   You might want to use a mapping class rather than an actual dict, especially if your Unicode string may potentially contain characters with very high ord values (that would make the dict excessively large;-).  For example:  >>> class keeponly(object): ...   def __init__(self, keep):  ...     self.keep = set(ord(c) for c in keep) ...   def __getitem__(self, key): ...     if key in self.keep: ...       return key ...     return None ...  >>> s.translate(keeponly(string.digits)) u'123456' >>>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/1249388/removing-all-non-numeric-characters-from-string-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do we remove all non-numeric characters from a string in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Removing all non-numeric characters from string in Python",
        "A_Content": "  Just to add another option to the mix, there are several useful constants within the string module. While more useful in other cases, they can be used here.  >>> from string import digits >>> ''.join(c for c in \"abc123def456\" if c in digits) '123456'   There are several constants in the module, including:   ascii_letters (abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ) hexdigits (0123456789abcdefABCDEF)   If you are using these constants heavily, it can be worthwhile to covert them to a frozenset. That enables O(1) lookups, rather than O(n), where n is the length of the constant for the original strings.  >>> digits = frozenset(digits) >>> ''.join(c for c in \"abc123def456\" if c in digits) '123456'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/1249388/removing-all-non-numeric-characters-from-string-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do we remove all non-numeric characters from a string in Python?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What are WSGI and CGI in plain English?",
        "A_Content": "  WSGI runs the Python interpreter on web server start, either as part of the web server process (embedded mode) or as a separate process (daemon mode), and loads the script into it. Each request results in a specific function in the script being called, with the request environment passed as arguments to the function.  CGI runs the script as a separate process each request and uses environment variables, stdin, and stdout to \"communicate\" with it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "cgi",
            "wsgi"
        ],
        "URL": "https://stackoverflow.com/questions/4929626/what-are-wsgi-and-cgi-in-plain-english",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Every time I read either WSGI or CGI I cringe.   I've tried reading on it before but nothing really has stuck.  What is it really in plain English?  Does it just pipe requests to a terminal and redirect the output?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What are WSGI and CGI in plain English?",
        "A_Content": "  From a totally step-back point of view, Blankman, here is my \"Intro Page\" for Web Services Gateway Interface:  PART ONE: WEB SERVERS  Web servers serve up responses. They sit around, waiting patiently, and then with no warning at all, suddenly:   a client process sends a request. The client process could be a web server, a bot, a mobile app, whatever. It is simply \"the client\" the web server receives this request deliberate mumble various things happen (see below) The web server sends back something to the client  web server sits around again   Web servers (at least, the better ones) are very VERY good at this. They scale up and down processing depending on demand, they reliably hold conversations with the flakiest of clients over really cruddy networks and we never really have to worry about it.  They just keep on serving.  This is my point: web servers are just that: servers. They know nothing about content, nothing about users, nothing in fact other than how to wait a lot and reply reliably.  Your choice of web server should reflect your delivery preference, not your software. Your web server should be in charge of serving, not processing or logical stuff.  PART TWO: (PYTHON) SOFTWARE  Software does not sit around. Software only exists at execution time. Software is not terribly accommodating when it comes to unexpected changes in its environment (files not being where it expects, parameters being renamed etc). Although optimisation should be a central tenet of your design (of course), software itself does not optimise. Developers optimise. Software executes. Software does all the stuff in the 'deliberate mumble' section above. Could be anything.  Your choice or design of software should reflect your application, your choice of functionality, and not your choice of web server.  This is where the traditional method of \"compiling in\" languages to web servers becomes painful. You end up putting code in your application to cope with the physical server environment or, at least, being forced to choose an appropriate 'wrapper' library to include at runtime, to give the illusion of uniformity across web servers.  SO WHAT IS WSGI?  So, at last, what is WSGI?  WSGI is a set of rules, written in two halves. They are written in such a way that they can be integrated into any environment that welcomes integration.  The first part, written for the web server side, says \"OK, if you want to deal with a WSGI application, here's how the software will be thinking when it loads. Here are the things you must make available to the application, and here is the interface (layout) that you can expect every application to have. Moreover, if anything goes wrong, here's how the app will be thinking and how you can expect it to behave.\"  The second part, written for the Python application software, says \"OK, if you want to deal with a WSGI server, here's how the server will be thinking when it contacts you. Here are the things you must make available to the server, and here is the interface (layout) that you can expect every server to have. Moreover, if anything goes wrong, here's how you should behave and here's what you should tell the server.\"  So there you have it - servers will be servers and software will be software, and here's a way they can get along just great without one having to make any allowances for the specifics of the other.  This is WSGI.    mod_wsgi, on the other hand, is a plugin for Apache that lets it talk to WSGI-compliant software, in other words, mod_wsgi is an implementation - in Apache - of the rules of part one of the rulebook above.  As for CGI.... ask someone else :-)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "cgi",
            "wsgi"
        ],
        "URL": "https://stackoverflow.com/questions/4929626/what-are-wsgi-and-cgi-in-plain-english",
        "A_Votes": "192",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Every time I read either WSGI or CGI I cringe.   I've tried reading on it before but nothing really has stuck.  What is it really in plain English?  Does it just pipe requests to a terminal and redirect the output?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What are WSGI and CGI in plain English?",
        "A_Content": "  Both CGI and WSGI define standard interfaces that programs can use to handle web requests.  The CGI interface is at a lower level than WSGI, and involves the server setting up environment variables containing the data from the HTTP request, with the program returning something formatted pretty much like a bare HTTP server response.  WSGI, on the other hand, is a Python-specific, slightly higher-level interface that allows programmers to write applications that are server-agnostic and which can be wrapped in other WSGI applications (middleware).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "cgi",
            "wsgi"
        ],
        "URL": "https://stackoverflow.com/questions/4929626/what-are-wsgi-and-cgi-in-plain-english",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Every time I read either WSGI or CGI I cringe.   I've tried reading on it before but nothing really has stuck.  What is it really in plain English?  Does it just pipe requests to a terminal and redirect the output?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "What are WSGI and CGI in plain English?",
        "A_Content": "  If you are unclear on all the terms in this space, and let's face it, it's a confusing acronym-laden one, there's also a good background reader in the form of an official python HOWTO which discusses CGI vs. FastCGI vs. WSGI and so on. I wish I'd read it first.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "cgi",
            "wsgi"
        ],
        "URL": "https://stackoverflow.com/questions/4929626/what-are-wsgi-and-cgi-in-plain-english",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Every time I read either WSGI or CGI I cringe.   I've tried reading on it before but nothing really has stuck.  What is it really in plain English?  Does it just pipe requests to a terminal and redirect the output?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  Use logging.exception from with an except: handler to log the current exception, prepended with a message.  import logging LOG_FILENAME = '/tmp/logging_example.out' logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG)  logging.debug('This message should go to the log file')  try:     run_my_stuff() except:     logging.exception('Got exception on main handler')     raise   Now looking at the log file, /tmp/logging_example.out:  DEBUG:root:This message should go to the log file ERROR:root:Got exception on main handler Traceback (most recent call last):   File \"/tmp/teste.py\", line 9, in <module>     run_my_stuff() NameError: name 'run_my_stuff' is not defined      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  Use exc_info options may be better, remains warning or error title:   try:     # coode in here except Exception as e:     logging.error(e, exc_info=True)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "86",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  My job recently tasked me with logging all the tracebacks/exceptions from our application. I tried numerous techniques that others had posted online such as the one above but settled on a different approach. Overriding traceback.print_exception.   I have a write up at http://www.bbarrows.com/ That would be much easier to read but Ill paste it in here as well.  When tasked with logging all the exceptions that our software might encounter in the wild I tried a number of different techniques to log our python exception tracebacks. At first I thought that the python system exception hook, sys.excepthook would be the perfect place to insert the logging code. I was trying something similar to:  import traceback import StringIO import logging import os, sys  def my_excepthook(excType, excValue, traceback, logger=logger):     logger.error(\"Logging an uncaught exception\",                  exc_info=(excType, excValue, traceback))  sys.excepthook = my_excepthook     This worked for the main thread but I soon found that the my sys.excepthook would not exist across any new threads my process started. This is a huge issue because most everything happens in threads in this project.  After googling and reading plenty of documentation the most helpful information I found was from the Python Issue tracker.  The first post on the thread shows a working example of the sys.excepthook NOT persisting across threads (as shown below). Apparently this is expected behavior.  import sys, threading  def log_exception(*args):     print 'got exception %s' % (args,) sys.excepthook = log_exception  def foo():     a = 1 / 0  threading.Thread(target=foo).start()   The messages on this Python Issue thread really result in 2 suggested hacks. Either subclass Thread and wrap the run method in our own try except block in order to catch and log exceptions or monkey patch threading.Thread.run to run in your own try except block and log the exceptions.  The first method of subclassing Thread seems to me to be less elegant in your code as you would have to import and use your custom Thread class EVERYWHERE you wanted to have a logging thread. This ended up being a hassle because I had to search our entire code base and replace all normal Threads with this custom Thread. However, it was clear as to what this Thread was doing and would be easier for someone to diagnose and debug if something went wrong with the custom logging code. A custome logging thread might look like this:  class TracebackLoggingThread(threading.Thread):     def run(self):         try:             super(TracebackLoggingThread, self).run()         except (KeyboardInterrupt, SystemExit):             raise         except Exception, e:             logger = logging.getLogger('')             logger.exception(\"Logging an uncaught exception\")   The second method of monkey patching threading.Thread.run is nice because I could just run it once right after __main__ and instrument my logging code in all exceptions. Monkey patching can be annoying to debug though as it changes the expected functionality of something. The suggested patch from the Python Issue tracker was:  def installThreadExcepthook():     \"\"\"     Workaround for sys.excepthook thread bug     From http://spyced.blogspot.com/2007/06/workaround-for-sysexcepthook-bug.html  (https://sourceforge.net/tracker/?func=detail&atid=105470&aid=1230540&group_id=5470).     Call once from __main__ before creating any threads.     If using psyco, call psyco.cannotcompile(threading.Thread.run)     since this replaces a new-style class method.     \"\"\"     init_old = threading.Thread.__init__     def init(self, *args, **kwargs):         init_old(self, *args, **kwargs)         run_old = self.run         def run_with_except_hook(*args, **kw):             try:                 run_old(*args, **kw)             except (KeyboardInterrupt, SystemExit):                 raise             except:                 sys.excepthook(*sys.exc_info())         self.run = run_with_except_hook     threading.Thread.__init__ = init   It was not until I started testing my exception logging I realized that I was going about it all wrong.  To test I had placed a  raise Exception(\"Test\")   somewhere in my code. However, wrapping a a method that called this method was a try except block that printed out the traceback and swallowed the exception. This was very frustrating because I saw the traceback bring printed to STDOUT but not being logged. It was I then decided that a much easier method of logging the tracebacks was just to monkey patch the method that all python code uses to print the tracebacks themselves, traceback.print_exception. I ended up with something similar to the following:  def add_custom_print_exception():     old_print_exception = traceback.print_exception     def custom_print_exception(etype, value, tb, limit=None, file=None):         tb_output = StringIO.StringIO()         traceback.print_tb(tb, limit, tb_output)         logger = logging.getLogger('customLogger')         logger.error(tb_output.getvalue())         tb_output.close()         old_print_exception(etype, value, tb, limit=None, file=None)     traceback.print_exception = custom_print_exception   This code writes the traceback to a String Buffer and logs it to logging ERROR. I have a custom logging handler set up the 'customLogger' logger which takes the ERROR level logs and send them home for analysis.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  You can log all uncaught exceptions on the main thread by assigning a handler to sys.excepthook, perhaps using the exc_info parameter of Python's logging functions:  import sys import logging  logging.basicConfig(filename='/tmp/foobar.log')  def exception_hook(exc_type, exc_value, exc_traceback):     logging.error(         \"Uncaught exception\",         exc_info=(exc_type, exc_value, exc_traceback)     )  sys.excepthook = exception_hook  raise Exception('Boom')   If your program uses threads, however, then note that threads created using threading.Thread will not trigger sys.excepthook when an uncaught exception occurs inside them, as noted in Issue 1230540 on Python's issue tracker. Some hacks have been suggested there to work around this limitation, like monkey-patching Thread.__init__ to overwrite self.run with an alternative run method that wraps the original in a try block and calls sys.excepthook from inside the except block. Alternatively, you could just manually wrap the entry point for each of your threads in try/except yourself.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  Uncaught exception messages go to STDERR, so instead of implementing your logging in Python itself you could send STDERR to a file using whatever shell you're using to run your Python script. In a Bash script, you can do this with output redirection, as described in the BASH guide.  Examples  Append errors to file, other output to the terminal:  ./test.py 2>> mylog.log   Overwrite file with interleaved STDOUT and STDERR output:  ./test.py &> mylog.log      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  maybe not as stylish, but easier:  #!/bin/bash log=\"/var/log/yourlog\" /path/to/your/script.py 2>&1 | (while read; do echo \"$REPLY\" >> $log; done)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  What I was looking for:  import sys import traceback  exc_type, exc_value, exc_traceback = sys.exc_info() traceback_in_var = traceback.format_tb(exc_traceback)   See:    https://docs.python.org/3/library/traceback.html      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Log exception with traceback",
        "A_Content": "  Heres a simple example taken from the python 2.6 documentation:  import logging LOG_FILENAME = '/tmp/logging_example.out' logging.basicConfig(filename=LOG_FILENAME,level=logging.DEBUG,)  logging.debug('This message should go to the log file')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception",
            "logging",
            "error-handling"
        ],
        "URL": "https://stackoverflow.com/questions/1508467/log-exception-with-traceback",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I log my Python errors?  try:     do_something() except:     # How can I log my exception here, complete with its traceback?      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Here's one that could work:  def chunkIt(seq, num):     avg = len(seq) / float(num)     out = []     last = 0.0      while last < len(seq):         out.append(seq[int(last):int(last + avg)])         last += avg      return out   Testing:  >>> chunkIt(range(10), 3) [[0, 1, 2], [3, 4, 5], [6, 7, 8, 9]] >>> chunkIt(range(11), 3) [[0, 1, 2], [3, 4, 5, 6], [7, 8, 9, 10]] >>> chunkIt(range(12), 3) [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  As long as you don't want anything silly like continuous chunks:  >>> def chunkify(lst,n): ...     return [lst[i::n] for i in xrange(n)] ...  >>> chunkify(range(13), 3) [[0, 3, 6, 9, 12], [1, 4, 7, 10], [2, 5, 8, 11]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "81",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  You can write it fairly simply as a list generator:  def split(a, n):     k, m = divmod(len(a), n)     return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in xrange(n))   Example:  >>> list(split(range(11), 3)) [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "80",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  This is the raison d'être for numpy.array_split*:  >>> L [0, 1, 2, 3, 4, 5, 6, 7] >>> print(*np.array_split(L, 3)) [0 1 2] [3 4 5] [6 7] >>> print(*np.array_split(range(10), 4)) [0 1 2] [3 4 5] [6 7] [8 9]   *credit to Zero Piraeus in room 6     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Changing the code to yield n chunks rather than chunks of n:  def chunks(l, n):     \"\"\" Yield n successive chunks from l.     \"\"\"     newn = int(len(l) / n)     for i in xrange(0, n-1):         yield l[i*newn:i*newn+newn]     yield l[n*newn-newn:]  l = range(56) three_chunks = chunks (l, 3) print three_chunks.next() print three_chunks.next() print three_chunks.next()   which gives:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35] [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]   This will assign the extra elements to the final group which is not perfect but well within your specification of \"roughly N equal parts\" :-) By that, I mean 56 elements would be better as (19,19,18) whereas this gives (18,18,20).  You can get the more balanced output with the following code:  #!/usr/bin/python def chunks(l, n):     \"\"\" Yield n successive chunks from l.     \"\"\"     newn = int(1.0 * len(l) / n + 0.5)     for i in xrange(0, n-1):         yield l[i*newn:i*newn+newn]     yield l[n*newn-newn:]  l = range(56) three_chunks = chunks (l, 3) print three_chunks.next() print three_chunks.next() print three_chunks.next()   which outputs:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18] [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37] [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  If you divide n elements into roughly k chunks you can make n % k chunks 1 element bigger than the other chunks to distribute the extra elements.   The following code will give you the length for the chunks:  [(n // k) + (1 if i < (n % k) else 0) for i in range(k)]   Example: n=11, k=3 results in [4, 4, 3]  You can then easily calculate the start indizes for the chunks:  [i * (n // k) + min(i, n % k) for i in range(k)]   Example: n=11, k=3 results in [0, 4, 8]  Using the i+1th chunk as the boundary we get that the ith chunk of list l with len n is  l[i * (n // k) + min(i, n % k):(i+1) * (n // k) + min(i+1, n % k)]   As a final step create a list from all the chunks using list comprehension:  [l[i * (n // k) + min(i, n % k):(i+1) * (n // k) + min(i+1, n % k)] for i in range(k)]   Example: n=11, k=3, l=range(n) results in [range(0, 4), range(4, 8), range(8, 11)]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Here is one that adds None to make the lists equal length  >>> from itertools import izip_longest >>> def chunks(l, n):     \"\"\" Yield n successive chunks from l. Pads extra spaces with None     \"\"\"     return list(zip(*izip_longest(*[iter(l)]*n)))  >>> l=range(54)  >>> chunks(l,3) [(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51), (1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52), (2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53)]  >>> chunks(l,4) [(0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52), (1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53), (2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, None), (3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, None)]  >>> chunks(l,5) [(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50), (1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51), (2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52), (3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53), (4, 9, 14, 19, 24, 29, 34, 39, 44, 49, None)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Have a look at numpy.split:  >>> a = numpy.array([1,2,3,4]) >>> numpy.split(a, 2) [array([1, 2]), array([3, 4])]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Here is my solution:  def chunks(l, amount):     if amount < 1:         raise ValueError('amount must be positive integer')     chunk_len = len(l) // amount     leap_parts = len(l) % amount     remainder = amount // 2  # make it symmetrical     i = 0     while i < len(l):         remainder += leap_parts         end_index = i + chunk_len         if remainder >= amount:             remainder -= amount             end_index += 1         yield l[i:end_index]         i = end_index   Produces      >>> list(chunks([1, 2, 3, 4, 5, 6, 7], 3))     [[1, 2], [3, 4, 5], [6, 7]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Here's a generator that can handle any positive (integer) number of chunks. If the number of chunks is greater than the input list length some chunks will be empty. This algorithm alternates between short and long chunks rather than segregating them.  I've also included some code for testing the ragged_chunks function.  ''' Split a list into \"ragged\" chunks      The size of each chunk is either the floor or ceiling of len(seq) / chunks      chunks can be > len(seq), in which case there will be empty chunks      Written by PM 2Ring 2017.03.30 '''  def ragged_chunks(seq, chunks):     size = len(seq)     start = 0     for i in range(1, chunks + 1):         stop = i * size // chunks         yield seq[start:stop]         start = stop  # test  def test_ragged_chunks(maxsize):     for size in range(0, maxsize):         seq = list(range(size))         for chunks in range(1, size + 1):             minwidth = size // chunks             #ceiling division             maxwidth = -(-size // chunks)             a = list(ragged_chunks(seq, chunks))             sizes = [len(u) for u in a]             deltas = all(minwidth <= u <= maxwidth for u in sizes)             assert all((sum(a, []) == seq, sum(sizes) == size, deltas))     return True  if test_ragged_chunks(100):     print('ok')     We can make this slightly more efficient by exporting the multiplication into the range call, but I think the previous version is more readable (and DRYer).  def ragged_chunks(seq, chunks):     size = len(seq)     start = 0     for i in range(size, size * chunks + 1, size):         stop = i // chunks         yield seq[start:stop]         start = stop      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Implementation using numpy.linspace method.   Just specify the number of parts you want the array to be divided in to.The divisions will be of nearly equal size.  Example :       import numpy as np    a=np.arange(10) print \"Input array:\",a  parts=3 i=np.linspace(np.min(a),np.max(a)+1,parts+1) i=np.array(i,dtype='uint16') # Indices should be floats split_arr=[] for ind in range(i.size-1):     split_arr.append(a[i[ind]:i[ind+1]] print \"Array split in to %d parts : \"%(parts),split_arr   Gives :  Input array: [0 1 2 3 4 5 6 7 8 9] Array split in to 3 parts :  [array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Using list comprehension:  def divide_list_to_chunks(list_, n):     return [list_[start::n] for start in range(n)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  This will do the split by a single expression:  >>> myList = range(18) >>> parts = 5 >>> [myList[(i*len(myList))//parts:((i+1)*len(myList))//parts] for i in range(parts)] [[0, 1, 2], [3, 4, 5, 6], [7, 8, 9], [10, 11, 12, 13], [14, 15, 16, 17]]   The list in this example has the size 18 and is divided into 5 parts. The size of the parts differs in no more than one element.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  My solution, easy to understand  def split_list(lst, n):     splitted = []     for i in reversed(range(1, n + 1)):         split_point = len(lst)//i         splitted.append(lst[:split_point])         lst = lst[split_point:]     return splitted   And shortest one-liner on this page(written by my girl)  def split(l, n):     return [l[int(i*len(l)/n):int((i+1)*len(l)/n-1)] for i in range(n)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Another way would be something like this, the idea here is to use grouper, but get rid of None. In this case we'll have all 'small_parts' formed from elements at the first part of the list, and 'larger_parts' from the later part of the list. Length of 'larger parts' is len(small_parts) + 1. We need to consider x as two different sub-parts.  from itertools import izip_longest  import numpy as np  def grouper(n, iterable, fillvalue=None): # This is grouper from itertools     \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"     args = [iter(iterable)] * n     return izip_longest(fillvalue=fillvalue, *args)  def another_chunk(x,num):     extra_ele = len(x)%num #gives number of parts that will have an extra element      small_part = int(np.floor(len(x)/num)) #gives number of elements in a small part      new_x = list(grouper(small_part,x[:small_part*(num-extra_ele)]))     new_x.extend(list(grouper(small_part+1,x[small_part*(num-extra_ele):])))      return new_x   The way I have it set up returns a list of tuples:  >>> x = range(14) >>> another_chunk(x,3) [(0, 1, 2, 3), (4, 5, 6, 7, 8), (9, 10, 11, 12, 13)] >>> another_chunk(x,4) [(0, 1, 2), (3, 4, 5), (6, 7, 8, 9), (10, 11, 12, 13)] >>> another_chunk(x,5) [(0, 1), (2, 3, 4), (5, 6, 7), (8, 9, 10), (11, 12, 13)] >>>       ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Here's another variant that spreads the \"remaining\" elements evenly among all the chunks, one at a time until there are none left. In this implementation, the larger chunks occur at the beginning the process.  def chunks(l, k):   \"\"\" Yield k successive chunks from l.\"\"\"   if k < 1:     yield []     raise StopIteration   n = len(l)   avg = n/k   remainders = n % k   start, end = 0, avg   while start < n:     if remainders > 0:       end = end + 1       remainders = remainders - 1     yield l[start:end]     start, end = end, end+avg   For example, generate 4 chunks from a list of 14 elements:  >>> list(chunks(range(14), 4)) [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10], [11, 12, 13]] >>> map(len, list(chunks(range(14), 4))) [4, 4, 3, 3]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  The same as job's answer, but takes into account lists with size smaller than the number of chuncks.  def chunkify(lst,n):     [ lst[i::n] for i in xrange(n if n < len(lst) else len(lst)) ]   if n (number of chunks) is 7 and lst (the list to divide) is [1, 2, 3] the chunks are [[0], [1], [2]] instead of [[0], [1], [2], [], [], [], []]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  You could also use:   split=lambda x,n: x if not x else [x[:n]]+[split([] if not -(len(x)-n) else x[-(len(x)-n):],n)][0]  split([1,2,3,4,5,6,7,8,9],2)  [[1, 2], [3, 4], [5, 6], [7, 8], [9]]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  See more_itertools.divide:  n = 2  [list(x) for x in mit.divide(n, range(5, 11))] # [[5, 6, 7], [8, 9, 10]]  [list(x) for x in mit.divide(n, range(5, 12))] # [[5, 6, 7, 8], [9, 10, 11]]   Install via > pip install more_itertools.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  #!/usr/bin/python   first_names = ['Steve', 'Jane', 'Sara', 'Mary','Jack','Bob', 'Bily', 'Boni', 'Chris','Sori', 'Will', 'Won','Li']  def chunks(l, n): for i in range(0, len(l), n):     # Create an index range for l of n items:     yield l[i:i+n]  result = list(chunks(first_names, 5)) print result   Picked from this link, and this was what helped me. I had a pre-defined list.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Splitting a list into N parts of approximately equal length",
        "A_Content": "  Rounding the linspace and using it as an index is an easier solution than what amit12690 proposes.  function chunks=chunkit(array,num)  index = round(linspace(0,size(array,2),num+1));  chunks = cell(1,num);  for x = 1:num chunks{x} = array(:,index(x)+1:index(x+1)); end end      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "chunks"
        ],
        "URL": "https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What is the best way to divide a list into roughly equal parts? For example, if the list has 7 elements and is split it into 2 parts, we want to get 3 elements in one part, and the other should have 4 elements.  I'm looking for something like even_split(L, n) that breaks L into n parts.  def chunks(L, n):     \"\"\" Yield successive n-sized chunks from L.     \"\"\"     for i in xrange(0, len(L), n):         yield L[i:i+n]   The code above gives chunks of 3, rather than 3 chunks.  I could simply transpose (iterate over this and take the first element of each column, call that part one, then take the second and put it in part two, etc), but that destroys the ordering of the items.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  Setting the User-Agent from everyone's favorite Dive Into Python.  The short story: You can use Request.add_header to do this.  You can also pass the headers as a dictionary when creating the Request itself, as the docs note:     headers should be a dictionary, and will be treated as if add_header() was called with each key and value as arguments. This is often used to “spoof” the User-Agent header, which is used by a browser to identify itself – some HTTP servers only allow requests coming from common browsers as opposed to scripts. For example, Mozilla Firefox may identify itself as \"Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11\", while urllib2‘s default user agent string is \"Python-urllib/2.6\" (on Python 2.6).      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "53",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  I answered a similar question a couple weeks ago.  There is example code in that question, but basically you can do something like this: (Note the capitalization of User-Agent as of RFC 2616, section 14.43.)  opener = urllib2.build_opener() opener.addheaders = [('User-Agent', 'Mozilla/5.0')] response = opener.open('http://www.stackoverflow.com')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "111",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  headers = { 'User-Agent' : 'Mozilla/5.0' } req = urllib2.Request('www.example.com', None, headers) html = urllib2.urlopen(req).read()   Or, a bit shorter:  req = urllib2.Request('www.example.com', headers={ 'User-Agent': 'Mozilla/5.0' }) html = urllib2.urlopen(req).read()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "95",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  For python 3, urllib is split into 3 modules...  import urllib.request req = urllib.request.Request(url=\"http://localhost/\",data=b'None',headers={'User-Agent':' Mozilla/5.0 (Windows NT 6.1; WOW64; rv:12.0) Gecko/20100101 Firefox/12.0'}) handler = urllib.request.urlopen(req)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  All these should work in theory, but (with Python 2.7.2 on Windows at least) any time you send a custom User-agent header, urllib2 doesn't send that header.  If you don't try to send a User-agent header, it sends the default Python / urllib2   None of these methods seem to work for adding User-agent but they work for other headers:  opener = urllib2.build_opener(proxy) opener.addheaders = {'User-agent':'Custom user agent'} urllib2.install_opener(opener)  request = urllib2.Request(url, headers={'User-agent':'Custom user agent'})  request.headers['User-agent'] = 'Custom user agent'  request.add_header('User-agent', 'Custom user agent')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  For urllib you can use:  from urllib import FancyURLopener  class MyOpener(FancyURLopener, object):     version = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'  myopener = MyOpener() myopener.retrieve('https://www.google.com/search?q=test', 'useragent.html')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  Another solution in urllib2 and Python 2.7:  req = urllib2.Request('http://www.example.com/') req.add_unredirected_header('User-Agent', 'Custom User-Agent') urllib2.urlopen(req)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  Try this :  html_source_code = requests.get(\"http://www.example.com/\",                    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.107 Safari/537.36',                             'Upgrade-Insecure-Requests': '1',                             'x-runtime': '148ms'},                     allow_redirects=True).content      ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Changing user agent on urllib2.urlopen",
        "A_Content": "  there are two properties of urllib.URLopener() namely: addheaders = [('User-Agent', 'Python-urllib/1.17'), ('Accept', '*/*')] and version = 'Python-urllib/1.17'. To fool the website you need to changes both of these values to an accepted User-Agent. for e.g. Chrome browser : 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.149 Safari/537.36' Google bot : 'Googlebot/2.1' like this    import urllib page_extractor=urllib.URLopener()   page_extractor.addheaders = [('User-Agent', 'Googlebot/2.1'), ('Accept', '*/*')]   page_extractor.version = 'Googlebot/2.1' page_extractor.retrieve(<url>, <file_path>)   changing just one property does not work because the website marks it as a suspicious request.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "urllib2",
            "user-agent"
        ],
        "URL": "https://stackoverflow.com/questions/802134/changing-user-agent-on-urllib2-urlopen",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I download a webpage with a user agent other than the default one on urllib2.urlopen?     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  Filter the result using os.path.isdir() (and use os.path.join() to get the real path):  >>> [ name for name in os.listdir(thedir) if os.path.isdir(os.path.join(thedir, name)) ] ['ctypes', 'distutils', 'encodings', 'lib-tk', 'config', 'idlelib', 'xml', 'bsddb', 'hotshot', 'logging', 'doc', 'test', 'compiler', 'curses', 'site-packages', 'email', 'sqlite3', 'lib-dynload', 'wsgiref', 'plat-linux2', 'plat-mac']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "82",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  os.walk('.').next()[1]   or with Python 3 use  next(os.walk('.'))[1]   as @Andre Soares said in comment below.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  Filter the list using os.path.isdir to detect directories.  filter(os.path.isdir, os.listdir(os.getcwd()))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  directories=[d for d in os.listdir(os.getcwd()) if os.path.isdir(d)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  Note that, instead of doing os.listdir(os.getcwd()), it's preferable to do os.listdir(os.path.curdir). One less function call, and it's as portable.  So, to complete the answer, to get a list of directories in a folder:  def listdirs(folder):     return [d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]   If you prefer full pathnames, then use this function:  def listdirs(folder):     return [         d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))         if os.path.isdir(d)     ]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  Just to add that using os.listdir() does not \"take a lot of processing vs very simple os.walk().next()[1]\". This is because os.walk() uses os.listdir() internally. In fact if you test them together:  >>>> import timeit >>>> timeit.timeit(\"os.walk('.').next()[1]\", \"import os\", number=10000) 1.1215229034423828 >>>> timeit.timeit(\"[ name for name in os.listdir('.') if os.path.isdir(os.path.join('.', name)) ]\", \"import os\", number=10000) 1.0592019557952881   The filtering of os.listdir() is very slightly faster.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  A very much simpler and elegant way is to use this:   import os  dir_list = os.walk('.').next()[1]  print dir_list   Run this script in the same folder for which you want folder names.It will give you exactly the immediate folders name only(that too without the full path of the folders).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  This seems to work too (at least on linux):  import glob, os glob.glob('*' + os.path.sep)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  being a newbie here i can't yet directly comment but here is a small correction i'd like to add to the following part of ΤΖΩΤΖΙΟΥ's answer :     If you prefer full pathnames, then use this function:  def listdirs(folder):     return [     d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))     if os.path.isdir(d) ]    for those still on python < 2.4: the inner construct needs to be a list instead of a tuple and therefore should read like this:  def listdirs(folder):     return [     d for d in [os.path.join(folder, d1) for d1 in os.listdir(folder)]     if os.path.isdir(d)   ]   otherwise one gets a syntax error.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  [x for x in os.listdir(somedir) if os.path.isdir(os.path.join(somedir, x))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  For a list of full path names I prefer this version to the other solutions here:  def listdirs(dir):     return [os.path.join(os.path.join(dir, x)) for x in os.listdir(dir)          if os.path.isdir(os.path.join(dir, x))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  scanDir = \"abc\" directories = [d for d in os.listdir(scanDir) if os.path.isdir(os.path.join(os.path.abspath(scanDir), d))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  Like so?  >>> [path for path in os.listdir(os.getcwd()) if os.path.isdir(path)]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  A safer option that does not fail when there is no directory.  def listdirs(folder):     if os.path.exists(folder):          return [d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]     else:          return []      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "How to list only top level directories in Python?",
        "A_Content": "  -- This will exclude files and traverse through 1 level of sub folders in the root  def list_files(dir):     List = []     filterstr = ' '     for root, dirs, files in os.walk(dir, topdown = True):         #r.append(root)         if (root == dir):             pass         elif filterstr in root:             #filterstr = ' '             pass         else:             filterstr = root             #print(root)             for name in files:                 print(root)                 print(dirs)                 List.append(os.path.join(root,name))             #print(os.path.join(root,name),\"\\n\")                 print(List,\"\\n\")      return List      ",
        "Language": "Python",
        "Tags": [
            "python",
            "filesystems"
        ],
        "URL": "https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to be able to list only the directories inside some folder. This means I don't want filenames listed, nor do I want additional sub-folders.  Let's see if an example helps. In the current directory we have:  >>> os.listdir(os.getcwd()) ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',  'Tools', 'w9xpopen.exe']   However, I don't want filenames listed. Nor do I want sub-folders such as \\Lib\\curses. Essentially what I want works with the following:  >>> for root, dirnames, filenames in os.walk('.'): ...     print dirnames ...     break ... ['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']   However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Convert both strings to timestamps (in your chosen resolution, e.g. milliseconds, seconds, hours, days, whatever), subtract the earlier from the later, multiply your random number (assuming it is distributed in the range [0, 1]) with that difference, and add again to the earlier one.  Convert the timestamp back to date string and you have a random time in that range.  Python example (output is almost in the format you specified, other than 0 padding - blame the American time format conventions):  import random import time  def strTimeProp(start, end, format, prop):     \"\"\"Get a time at a proportion of a range of two formatted times.      start and end should be strings specifying times formated in the     given format (strftime-style), giving an interval [start, end].     prop specifies how a proportion of the interval to be taken after     start.  The returned time will be in the specified format.     \"\"\"      stime = time.mktime(time.strptime(start, format))     etime = time.mktime(time.strptime(end, format))      ptime = stime + prop * (etime - stime)      return time.strftime(format, time.localtime(ptime))   def randomDate(start, end, prop):     return strTimeProp(start, end, '%m/%d/%Y %I:%M %p', prop)  print randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", random.random())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "101",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  from random import randrange from datetime import timedelta  def random_date(start, end):     \"\"\"     This function will return a random datetime between two datetime      objects.     \"\"\"     delta = end - start     int_delta = (delta.days * 24 * 60 * 60) + delta.seconds     random_second = randrange(int_delta)     return start + timedelta(seconds=random_second)   The precision is seconds. You can increase precision up to microseconds, or decrease to, say, half-hours, if you want. For that just change the last lines calculation.  example run:  d1 = datetime.strptime('1/1/2008 1:30 PM', '%m/%d/%Y %I:%M %p') d2 = datetime.strptime('1/1/2009 4:50 AM', '%m/%d/%Y %I:%M %p')  print random_date(d1, d2)   output:  2008-12-04 01:50:17      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  A tiny version.  import datetime import random   def random_date(start, end):     \"\"\"Generate a random datetime between `start` and `end`\"\"\"     return start + datetime.timedelta(         # Get a random amount of seconds between `start` and `end`         seconds=random.randint(0, int((end - start).total_seconds())),     )   Note that both start and end arguments should be datetime objects. If you've got strings instead, it's fairly easy to convert. The other answers point to some ways to do so.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "70",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Updated answer  It's even more simple using Faker.  Installation  pip install faker   Usage:  from faker import Faker fake = Faker()  fake.date_between(start_date='today', end_date='+30y') # datetime.date(2025, 3, 12)  fake.date_time_between(start_date='-30y', end_date='now') # datetime.datetime(2007, 2, 28, 11, 28, 16)   Old answer  It's very simple using radar  Installation  pip install radar   Usage  import datetime  import radar   # Generate random datetime (parsing dates from str values) radar.random_datetime(start='2000-05-24', stop='2013-05-24T23:59:59')  # Generate random datetime from datetime.datetime values radar.random_datetime(     start = datetime.datetime(year=2000, month=5, day=24),     stop = datetime.datetime(year=2013, month=5, day=24) )  # Just render some random datetime. If no range is given, start defaults to  # 1970-01-01 and stop defaults to datetime.datetime.now() radar.random_datetime()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  This is a different approach - that sort of works..  from random import randint import datetime  date=datetime.date(randint(2005,2025), randint(1,12),randint(1,28))   WAIITT - BETTER APPROACH  startdate=datetime.date(YYYY,MM,DD) date=startdate+datetime.timedelta(randint(1,365))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  To chip in a pandas-based solution I use:  import pandas as pd import numpy as np  def random_date(start, end, position=None):     start, end = pd.Timestamp(start), pd.Timestamp(end)     delta = (end - start).total_seconds()     if position is None:         offset = np.random.uniform(0., delta)     else:         offset = position * delta     offset = pd.offsets.Second(offset)     t = start + offset     return t   I like it, because of the nice pd.Timestamp features that allow me to throw different stuff and formats at it. Consider the following few examples...  Your signature.  >>> random_date(start=\"1/1/2008 1:30 PM\", end=\"1/1/2009 4:50 AM\", position=0.34) Timestamp('2008-05-04 21:06:48', tz=None)   Random position.  >>> random_date(start=\"1/1/2008 1:30 PM\", end=\"1/1/2009 4:50 AM\") Timestamp('2008-10-21 05:30:10', tz=None)   Different format.  >>> random_date('2008-01-01 13:30', '2009-01-01 4:50') Timestamp('2008-11-18 17:20:19', tz=None)   Passing pandas/datetime objects directly.  >>> random_date(pd.datetime.now(), pd.datetime.now() + pd.offsets.Hour(3)) Timestamp('2014-03-06 14:51:16.035965', tz=None)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Since Python 3 timedelta supports multiplication with floats, so now you can do:  import random random_date = start + (end - start) * random.random()   given that start and end are of the type datetime.datetime. For example, to generate a random datetime within the next day:  import random from datetime import datetime, timedelta  start = datetime.now() end = start + timedelta(days=1) random_date = start + (end - start) * random.random()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  The easiest way of doing this is to convert both numbers to timestamps, then set these as the minimum and maximum bounds on a random number generator.  A quick PHP example would be:  // Find a randomDate between $start_date and $end_date function randomDate($start_date, $end_date) {     // Convert to timetamps     $min = strtotime($start_date);     $max = strtotime($end_date);      // Generate random number using above bounds     $val = rand($min, $max);      // Convert back to desired date format     return date('Y-m-d H:i:s', $val); }   This function makes use of strtotime() to convert a datetime description into a Unix timestamp, and date() to make a valid date out of the random timestamp which has been generated.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  You can Use Mixer,  pip install mixer   and,  from mixer import generators as gen print gen.get_datetime(min_datetime=(1900, 1, 1, 0, 0, 0), max_datetime=(2020, 12, 31, 23, 59, 59))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Here is an answer to the literal meaning of the title rather than the body of this question:  import time import datetime import random  def date_to_timestamp(d) :   return int(time.mktime(d.timetuple()))  def randomDate(start, end):   \"\"\"Get a random date between two dates\"\"\"    stime = date_to_timestamp(start)   etime = date_to_timestamp(end)    ptime = stime + random.random() * (etime - stime)    return datetime.date.fromtimestamp(ptime)   This code is based loosely on the accepted answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Just to add another one:  datestring = datetime.datetime.strftime(datetime.datetime( \\     random.randint(2000, 2015), \\     random.randint(1, 12), \\     random.randint(1, 28), \\     random.randrange(23), \\     random.randrange(59), \\     random.randrange(59), \\     random.randrange(1000000)), '%Y-%m-%d %H:%M:%S')   The day handling needs some considerations. With 28 you are on the secure site.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "   Convert your input dates to numbers (int, float, whatever is best for your usage) Choose a number between your two date numbers. Convert this number back to a date.   Many algorithms for converting date to and from numbers are already available in many operating systems.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  What do you need the random number for? Usually (depending on the language) you can get the number of seconds/milliseconds from the Epoch from a date. So for a randomd date between startDate and endDate you could do:   compute the time in ms between startDate and endDate (endDate.toMilliseconds() - startDate.toMilliseconds()) generate a number between 0 and the number you obtained in 1 generate a new Date with time offset = startDate.toMilliseconds() + number obtained in 2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Here's a solution modified from emyller's approach which returns an array of random dates at any resolution  import numpy as np  def random_dates(start, end, size=1, resolution='s'):     \"\"\"     Returns an array of random dates in the interval [start, end]. Valid      resolution arguments are numpy date/time units, as documented at:          https://docs.scipy.org/doc/numpy-dev/reference/arrays.datetime.html     \"\"\"     start, end = np.datetime64(start), np.datetime64(end)     delta = (end-start).astype('timedelta64[{}]'.format(resolution))     delta_mat = np.random.randint(0, delta.astype('int'), size)     return start + delta_mat.astype('timedelta64[{}]'.format(resolution))   Part of what's nice about this approach is that np.datetime64 is really good at coercing things to dates, so you can specify your start/end dates as strings, datetimes, pandas timestamps... pretty much anything will work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  #!/usr/bin/env python # -*- coding: utf-8 -*-  \"\"\"Create random datetime object.\"\"\"  from datetime import datetime import random   def create_random_datetime(from_date, to_date, rand_type='uniform'):     \"\"\"     Create random date within timeframe.      Parameters     ----------     from_date : datetime object     to_date : datetime object     rand_type : {'uniform'}      Examples     --------     >>> random.seed(28041990)     >>> create_random_datetime(datetime(1990, 4, 28), datetime(2000, 12, 31))     datetime.datetime(1998, 12, 13, 23, 38, 0, 121628)     >>> create_random_datetime(datetime(1990, 4, 28), datetime(2000, 12, 31))     datetime.datetime(2000, 3, 19, 19, 24, 31, 193940)     \"\"\"     delta = to_date - from_date     if rand_type == 'uniform':         rand = random.random()     else:         raise NotImplementedError('Unknown random mode \\'{}\\''                                   .format(rand_type))     return from_date + rand * delta   if __name__ == '__main__':     import doctest     doctest.testmod()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Conceptually it's quite simple.  Depending on which language you're using you will be able to convert those dates into some reference 32 or 64 bit integer, typically representing seconds since epoch (1 January 1970) otherwise known as \"Unix time\" or milliseconds since some other arbitrary date.  Simply generate a random 32 or 64 bit integer between those two values.  This should be a one liner in any language.  On some platforms you can generate a time as a double (date is the integer part, time is the fractional part is one implementation).  The same principle applies except you're dealing with single or double precision floating point numbers (\"floats\" or \"doubles\" in C, Java and other languages).  Subtract the difference, multiply by random number (0 <= r <= 1), add to start time and done.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Use ApacheCommonUtils to generate a random long within a given range, and then create Date out of that long.   Example:  import org.apache.commons.math.random.RandomData;  import org.apache.commons.math.random.RandomDataImpl;  public Date nextDate(Date min, Date max) {  RandomData randomData = new RandomDataImpl();  return new Date(randomData.nextLong(min.getTime(), max.getTime()));   }     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  I made this for another project using random and time. I used a general format from time you can view the documentation here for the first argument in strftime(). The second part is a random.randrange function. It returns an integer between the arguments. Change it to the ranges that match the strings you would like. You must have nice arguments in the tuple of the second arugment.  import time import random   def get_random_date():     return strftime(\"%Y-%m-%d %H:%M:%S\",(random.randrange(2000,2016),random.randrange(1,12),     random.randrange(1,28),random.randrange(1,24),random.randrange(1,60),random.randrange(1,60),random.randrange(1,7),random.randrange(0,366),1))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Pandas + numpy solution  import pandas as pd import numpy as np  def RandomTimestamp(start, end):     dts = (end - start).total_seconds()     return start + pd.Timedelta(np.random.uniform(0, dts), 's')   dts is the difference between timestamps in seconds (float). It is then used to create a pandas timedelta between 0 and dts, that is added to the start timestamp.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  Based on the answer by mouviciel, here is a vectorized solution using numpy. Convert the start and end dates to ints, generate an array of random numbers between them, and convert the whole array back to dates.   import time import datetime import numpy as np  n_rows = 10  start_time = \"01/12/2011\" end_time = \"05/08/2017\"  date2int = lambda s: time.mktime(datetime.datetime.strptime(s,\"%d/%m/%Y\").timetuple()) int2date = lambda s: datetime.datetime.fromtimestamp(s).strftime('%Y-%m-%d %H:%M:%S')  start_time = date2int(start_time) end_time = date2int(end_time)  random_ints = np.random.randint(low=start_time, high=end_time, size=(n_rows,1)) random_dates = np.apply_along_axis(int2date, 1, random_ints).reshape(n_rows,1)  print random_dates      ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  It's modified method of @(Tom Alsberg). I modified it to get date with milliseconds.  import random import time import datetime  def random_date(start_time_string, end_time_string, format_string, random_number):     \"\"\"     Get a time at a proportion of a range of two formatted times.     start and end should be strings specifying times formated in the     given format (strftime-style), giving an interval [start, end].     prop specifies how a proportion of the interval to be taken after     start.  The returned time will be in the specified format.     \"\"\"     dt_start = datetime.datetime.strptime(start_time_string, format_string)     dt_end = datetime.datetime.strptime(end_time_string, format_string)      start_time = time.mktime(dt_start.timetuple()) + dt_start.microsecond / 1000000.0     end_time = time.mktime(dt_end.timetuple()) + dt_end.microsecond / 1000000.0      random_time = start_time + random_number * (end_time - start_time)      return datetime.datetime.fromtimestamp(random_time).strftime(format_string)   Example:  print TestData.TestData.random_date(\"2000/01/01 00:00:00.000000\", \"2049/12/31 23:59:59.999999\", '%Y/%m/%d %H:%M:%S.%f', random.random())   Output: 2028/07/08 12:34:49.977963     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Generate a random date between two other dates",
        "A_Content": "  In python:  >>> from dateutil.rrule import rrule, DAILY >>> import datetime, random >>> random.choice(                  list(                      rrule(DAILY,                             dtstart=datetime.date(2009,8,21),                             until=datetime.date(2010,10,12))                      )                  ) datetime.datetime(2010, 2, 1, 0, 0)   (need python dateutil library – pip install python-dateutil)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "datetime",
            "random"
        ],
        "URL": "https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How would I generate a random date that has to be between two other given dates?  The functions signature should something like this-  randomDate(\"1/1/2008 1:30 PM\", \"1/1/2009 4:50 AM\", 0.34)                   ^                       ^          ^             date generated has   date generated has  random number            to be after this     to be before this   and would return a date such as- \"2/4/2008 7:20 PM\"     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  In Django 1.6 you can use the first() Queryset method. It returns the first object matched by the queryset, or None if there is no matching object.  Usage:  p = Article.objects.order_by('title', 'pub_date').first()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "84",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  There are two ways to do this;  try:     foo = Foo.objects.get(bar=baz) except model.DoesNotExist:     foo = None   Or you can use a wrapper:  def get_or_none(model, *args, **kwargs):     try:         return model.objects.get(*args, **kwargs)     except model.DoesNotExist:         return None   Call it like this  foo = get_or_none(Foo, baz=bar)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  To add some sample code to sorki's answer (I'd add this as a comment, but this is my first post, and I don't have enough reputation to leave comments), I implemented a get_or_none custom manager like so:  from django.db import models  class GetOrNoneManager(models.Manager):     \"\"\"Adds get_or_none method to objects     \"\"\"     def get_or_none(self, **kwargs):         try:             return self.get(**kwargs)         except self.model.DoesNotExist:             return None  class Person(models.Model):     name = models.CharField(max_length=255)     objects = GetOrNoneManager()   And now I can do this:  bob_or_none = Person.objects.get_or_none(name='Bob')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "80",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  You can also try to use django annoying (it has another useful functions!)  install it with:  pip install django-annoying  from annoying.functions import get_object_or_None get_object_or_None(Foo, bar=baz)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  Give Foo its custom manager. It's pretty easy - just put your code into function in custom manager, set custom manager in your model and call it with Foo.objects.your_new_func(...).  If you need generic function (to use it on any model not just that with custom manager) write your own and place it somewhere on your python path and import, not messy any more.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  Whether doing it via a manager or generic function, you may also want to catch 'MultipleObjectsReturned' in the TRY statement, as the get() function will raise this if your kwargs retrieve more than one object.  Building on the generic function:  def get_unique_or_none(model, *args, **kwargs):     try:         return model.objects.get(*args, **kwargs)     except (model.DoesNotExist, model.MultipleObjectsReturned), err:         return None   and in the manager:  class GetUniqueOrNoneManager(models.Manager):     \"\"\"Adds get_unique_or_none method to objects     \"\"\"     def get_unique_or_none(self, *args, **kwargs):         try:             return self.get(*args, **kwargs)         except (self.model.DoesNotExist, self.model.MultipleObjectsReturned), err:             return None      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  Here's a variation on the helper function that allows you to optionally pass in a QuerySet instance, in case you want to get the unique object (if present) from a queryset other than the model's all objects queryset (e.g. from a subset of child items belonging to a parent instance):  def get_unique_or_none(model, queryset=None, *args, **kwargs):     \"\"\"         Performs the query on the specified `queryset`         (defaulting to the `all` queryset of the `model`'s default manager)         and returns the unique object matching the given         keyword arguments.  Returns `None` if no match is found.         Throws a `model.MultipleObjectsReturned` exception         if more than one match is found.     \"\"\"     if queryset is None:         queryset = model.objects.all()     try:         return queryset.get(*args, **kwargs)     except model.DoesNotExist:         return None   This can be used in two ways, e.g.:   obj = get_unique_or_none(Model, *args, **kwargs) as previosuly discussed obj = get_unique_or_none(Model, parent.children, *args, **kwargs)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Django: Get an object form the DB, or 'None' if nothing matches",
        "A_Content": "  I think that in most cases you can just use:  foo, created = Foo.objects.get_or_create(bar=baz)   Only if it is not critical that a new entry will be added in Foo table ( other columns will have the None/default values )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/1512059/django-get-an-object-form-the-db-or-none-if-nothing-matches",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any Django function which will let me get an object form the database, or None if nothing matches?  Right now I'm using something like:  foo = Foo.objects.filter(bar=baz) foo = len(foo) > 0 and foo.get() or None   But that's not very clear, and it's messy to have everywhere.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Turn Pandas Multi-Index into column",
        "A_Content": "  The reset_index() is a pandas DataFrame method that will transfer index values into the DataFrame as columns.  The default setting for the parameter is drop=False (which will keep the index values as columns).  All you have to do add .reset_index(inplace=True) after the name of the DataFrame:  df.reset_index(inplace=True)        ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "flatten",
            "multi-index"
        ],
        "URL": "https://stackoverflow.com/questions/20110170/turn-pandas-multi-index-into-column",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a dataframe with 2 index levels:                           value Trial    measurement     1              0        13                    1         3                    2         4     2              0       NaN                    1        12     3              0        34    Which I want to turn into this:  Trial    measurement       value      1              0        13     1              1         3     1              2         4     2              0       NaN     2              1        12     3              0        34    How can I best do this?     I need this because I want to aggregate the data as instructed here, but I can't select my columns like that if they are in use as indices.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Turn Pandas Multi-Index into column",
        "A_Content": "  This doesn't really apply to your case but it could be helpful for others (like me 5 minutes ago) to know. If one's multindex have the same names like this:                           value Trial        Trial     1              0        13                    1         3                    2         4     2              0       NaN                    1        12     3              0        34    df.reset_index(inplace=True) will fail cause the columns that is created cannot share names.  So then you need to rename the multindex with df.index = df.index.set_names(['Trial', 'measurement']) to get:                             value Trial    measurement             1              0        13     1              1         3     1              2         4     2              0       NaN     2              1        12     3              0        34    And then df.reset_index(inplace=True) will work like a charm.   I encountered this problem after grouping by year and month on a datetime-column(not index) called live_date, which meant that both year and month were named live_date.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "dataframe",
            "flatten",
            "multi-index"
        ],
        "URL": "https://stackoverflow.com/questions/20110170/turn-pandas-multi-index-into-column",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a dataframe with 2 index levels:                           value Trial    measurement     1              0        13                    1         3                    2         4     2              0       NaN                    1        12     3              0        34    Which I want to turn into this:  Trial    measurement       value      1              0        13     1              1         3     1              2         4     2              0       NaN     2              1        12     3              0        34    How can I best do this?     I need this because I want to aggregate the data as instructed here, but I can't select my columns like that if they are in use as indices.     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  According to MAINT: silence Cython warnings about changes dtype/ufunc size. - numpy/numpy:     These warnings are visible whenever you import scipy (or another   package) that was compiled against an older numpy than is installed.   and the checks are inserted by Cython (hence are present in any module compiled with it).  Long story short, these warnings should be benign in the particular case of numpy, and these messages are filtered out since numpy 1.8 (the branch this commit went onto). While scikit-learn 0.18.1 is compiled against numpy 1.6.1.  To filter these warnings yourself, you can do the same as the patch does:  import warnings warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\") warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")   Of course, you can just recompile all affected modules from source against your local numpy with pip install --no-binary :all:¹ instead if you have the balls tools for that.    Longer story: the patch's proponent claims there should be no risk specifically with numpy, and 3rd-party packages are intentionally built against older versions:     [Rebuilding everything against current numpy is] not a feasible   solution, and certainly shouldn't be necessary. Scipy (as many other   packages) is compatible with a number of versions of numpy. So when we   distribute scipy binaries, we build them against the lowest supported   numpy version (1.5.1 as of now) and they work with 1.6.x, 1.7.x and   numpy master as well.      The real correct would be for Cython only to issue warnings when the   size of dtypes/ufuncs has changes in a way that breaks the ABI, and be   silent otherwise.   As a result, Cython's devs agreed to trust the numpy team with maintaining binary compatibility by hand, so we can probably expect that using versions with breaking ABI changes would yield a specially-crafted exception or some other explicit show-stopper.    ¹The previously available --no-use-wheel option has been removed since pip 10.0.0.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  It's the issue of new numpy version (1.15.0)  You can downgrade numpy and this problem will be fixed:   sudo pip uninstall numpy  sudo pip install numpy==1.14.5     Finally numpy 1.15.1 version is released so the warning issues are fixed.      sudo pip install numpy==1.15.1   This is working..     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  I've tried the above-mentioned ways, but nothing worked. But the issue was gone after I installed the libraries through apt install,  For Python3,  pip3 uninstall -y numpy scipy pandas scikit-learn sudo apt update sudo apt install python3-numpy python3-scipy python3-pandas python3-sklearn    For Python2,  pip uninstall -y numpy scipy pandas scikit-learn sudo apt update sudo apt install python-numpy python-scipy python-pandas python-sklearn    Hope that helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  if you are in an anaconda environment use:  conda update --all      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  This error occurs because the installed packages were build agains different version of numpy. We need to rebuild scipy and scikit-learn against the local numpy.  For new pip (in my case pip 18.0) this worked:  pip uninstall -y scipy scikit-learn pip install --no-binary scipy,scikit-learn -I scipy scikit-learn   --no-binary takes a list of names of packages that you want to ignore binaries for. In this case we passed --no-binary scipy,scikit-learn which will ignore binaries for packages scipy,scikit-learn. Didn't help me     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  Meta-information: The recommended way to install sklearn     If you already have a working installation of numpy and scipy, the   easiest way to install scikit-learn is using pip  pip install -U scikit-learn        or conda:  conda install scikit-learn    [... do not compile from source using pip]     If you don’t already have a python installation with numpy and scipy, we recommend to install either via your package manager or via a python bundle. These come with numpy, scipy, scikit-learn, matplotlib and many other helpful scientific and data processing libraries.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility",
        "A_Content": "  My enviroment is Python 2.7.15  I try   pip uninstall pip install --no-use-wheel   but it does not work. It shows the error:     no such option: --no-use-wheel   Then I try:  pip uninstall pip install --user --install-option=\"--prefix=\" -U scikit-learn   And it works: the useless warnings do not show.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scikit-learn"
        ],
        "URL": "https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have this error for trying to load a saved SVM model. I have tried uninstalling sklearn, NumPy and SciPy, reinstalling the latest versions all-together again (using pip). I am still getting this error. Why?  In [1]: import sklearn; print sklearn.__version__ 0.18.1 In [3]: import numpy; print numpy.__version__ 1.11.2 In [5]: import scipy; print scipy.__version__ 0.18.1 In [7]: import pandas; print pandas.__version__ 0.19.1  In [10]: clf = joblib.load('model/trained_model.pkl') --------------------------------------------------------------------------- RuntimeWarning                            Traceback (most recent call last) <ipython-input-10-5e5db1331757> in <module>() ----> 1 clf = joblib.load('sentiment_classification/model/trained_model.pkl')  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in load(filename, mmap_mode)     573                     return load_compatibility(fobj)     574 --> 575                 obj = _unpickle(fobj, filename, mmap_mode)     576     577     return obj  /usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/numpy_pickle.pyc in _unpickle(fobj, filename, mmap_mode)     505     obj = None     506     try: --> 507         obj = unpickler.load()     508         if unpickler.compat_mode:     509             warnings.warn(\"The file '%s' has been generated with a \"  /usr/lib/python2.7/pickle.pyc in load(self)     862             while 1:     863                 key = read(1) --> 864                 dispatch[key](self)     865         except _Stop, stopinst:     866             return stopinst.value  /usr/lib/python2.7/pickle.pyc in load_global(self)    1094         module = self.readline()[:-1]    1095         name = self.readline()[:-1] -> 1096         klass = self.find_class(module, name)    1097         self.append(klass)    1098     dispatch[GLOBAL] = load_global  /usr/lib/python2.7/pickle.pyc in find_class(self, module, name)    1128     def find_class(self, module, name):    1129         # Subclasses may override this -> 1130         __import__(module)    1131         mod = sys.modules[module]    1132         klass = getattr(mod, name)  /usr/local/lib/python2.7/dist-packages/sklearn/svm/__init__.py in <module>()      11 # License: BSD 3 clause (C) INRIA 2010      12 ---> 13 from .classes import SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, \\      14         LinearSVR      15 from .bounds import l1_min_c  /usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.py in <module>()       2 import numpy as np       3 ----> 4 from .base import _fit_liblinear, BaseSVC, BaseLibSVM       5 from ..base import BaseEstimator, RegressorMixin       6 from ..linear_model.base import LinearClassifierMixin, SparseCoefMixin, \\  /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in <module>()       6 from abc import ABCMeta, abstractmethod       7 ----> 8 from . import libsvm, liblinear       9 from . import libsvm_sparse      10 from ..base import BaseEstimator, ClassifierMixin  __init__.pxd in init sklearn.svm.libsvm (sklearn/svm/libsvm.c:10207)()  RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 80   UPDATE: OK, by following here, and  pip uninstall -y scipy scikit-learn pip install --no-binary scipy scikit-learn   The error has now gone, though I still have no idea why it occurred in the first place...     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  Unofficial Windows Binaries for Python Extension Packages  you can find any python libs from here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  Please check if the python version you are using is also 64 bit. If not then that could be the issue. You would be using a 32 bit python version and would have installed a 64 bit binaries for the OPENCV library.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  Wow, I found yet another case for this problem. None of the above worked. Eventually I used python's ability to introspect what was being loaded. For python 2.7 this means:  import imp imp.find_module(\"cv2\")   This turned up a completely unexpected \"cv2.pyd\" file in an Anaconda DLL directory that wasn't touched by multiple uninstall/install attempts. Python was looking there first and not finding my good installation. I deleted that cv2.pyd file and tried imp.find_module(\"cv2\") again and python immediately found the right file and cv2 started working.  So if none of the other solutions work for you, make sure you use python introspection to see what file python is trying to load.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  In my case, I have 64bit python, and it was lxml that was the wrong version--I should have been using the x64 version of that as well. I solved this by downloading the 64-bit version of lxml here:  https://pypi.python.org/pypi/lxml/3.4.1  lxml-3.4.1.win-amd64-py2.7.exe   This was the simplest answer to a frustrating issue.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  I just had this problem, it turns it was just because I was using x64 version of the opencv file.  Tried the x86 and it worked.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  I copied cv2.pyd file from /opencv/build/python/2.7/x86 folder instead of from /x64 folder to C:/Python27/Lib/site-packeges. I followed rest of the instructions provided here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  If your build-system (CMake in my case) copies the file from <name>.dll to <name>.pyd, you will get this error if the original file wasn't actually a dll.  In my case, building shared libraries got switched off, so the underlying file was actually a *.lib.  I discovered this error by loading the pyd file in DependencyWalker and finding that it wasn't valid.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  I had the same problem. Here's what I did:   I downloaded pywin32 Wheel file from here, then I uninstalled the pywin32 module. To uninstall execute the following command in Command Prompt.  pip uninstall pywin32 Then, I reinstalled pywin32. To install it, open the Command Prompt in the same directory where the pywin32 wheel file lies. Then execute the following command.  pip install <Name of the wheel file with extension> Wheel file will be like: piwin32-XXX-cpXX-none-win32.whl   It solvs the problem for me. You may also like to give it a try. Hope it work for you as well.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  For me the problem was that I was using different versions of Python in the same Eclipse project. My setup was not consistent with the Project Properties and the Run Configuration Python versions.  In Project > Properties > PyDev, I had the Interpreter set to Python2.7.11.  In Run Configurations > Interpreter, I was using the Default Interpreter. Changing it to Python 2.7.11 fixed the problem.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  I faced the same issue when I uninstalled and reinstalled a different version of 2.7.x of Python on my system using a 32 bit Windows Installer. I got the same error on most of my import statements. I uninstalled the newly installed Python and downloaded a 64 bit Windows installer and reinstalled Python again and it worked. Hope this helps you.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  First I copied cv2.pyd from /opencv/build/python/2.7/x86 to C:/Python27/Lib/site-packeges. The error was      \"RuntimeError: module compiled against API version 9 but this version of numpy is 7\"   Then I installed numpy-1.8.0-win32-superpack-python2.7.exe and opencv works fine.  >>> import cv2 >>> print cv2.__version__ 2.4.13      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  You can install opencv from official or unofficial sites.  Refer to this question and this issue if you are using Anaconda.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "   Please make sure that you have installed python 2.7.12 or below version otherwise you will get this error definitely. Make sure Oracle client is 64 bit installed if OS is 64 Bit. Make sure Microsoft Visual C++ Compiler for Python 2.7 is 64 for bit for 64 bit Os or 32 bit for 32 bit. Note:- IF ur OS is 64 bit install all package of 64 bit or if Os is 32 bit install 32 bit package.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  It has a very simple solution. After installing opencv place  cv2.pyd from C:\\opencv\\build\\python\\2.7\\ **x64** to C:\\Python27\\Lib\\site-packages  instead of, place cv2.pyd from C:\\opencv\\build\\python\\2.7\\ **x86** to C:\\Python27\\Lib\\site-packages      ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "ImportError: DLL load failed: %1 is not a valid Win32 application. But the DLL's are there",
        "A_Content": "  I found the solution, maybe you can try to use the cmd window rather than the anaconda prompt window to start you first scrapy test.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "opencv",
            "dll",
            "path"
        ],
        "URL": "https://stackoverflow.com/questions/19019720/importerror-dll-load-failed-1-is-not-a-valid-win32-application-but-the-dlls",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a situation very much like the one at ImportError: DLL load failed: %1 is not a valid Win32 application, but the answer there isn't working for me.  My Python code says:  import cv2   But that line throws the error shown in the title of this question.  I have OpenCV installed in C:\\lib\\opencv on this 64-bit machine. I'm using 64-bit Python.  My PYTHONPATH variable: PYTHONPATH=C:\\lib\\opencv\\build\\python\\2.7. This folder contains cv2.pyd and that's all.  My PATH variable: Path=%OPENCV_DIR%\\bin;... This folder contains 39 DLL files such as opencv_core246d.dll.  OPENCV_DIR has this value: OPENCV_DIR=C:\\lib\\opencv\\build\\x64\\vc11.  The solution at ImportError: DLL load failed: %1 is not a valid Win32 application says to add \"the new opencv binaries path (C:\\opencv\\build\\bin\\Release) to the Windows PATH environment variable\". But as shown above, I already have the OpenCV binaries folder (C:\\lib\\opencv\\build\\x64\\vc11\\bin) in my PATH. And my OpenCV installation doesn't have any Release folders (except for an empty one under build/java).  Any ideas as to what's going wrong? Can I tell Python to verbosely trace the loading process? Exactly what DLL's is it looking for?  Thanks, Lars  EDIT:  I just noticed that, according to http://www.dependencywalker.com/, the cv2.pyd in C:\\lib\\opencv\\build\\python\\2.7 is 32-bit, whereas the machine and the Python I'm running are 64-bit. Could that be the problem? And if so, where can I find a 64-bit version of cv2.pyd?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  You should refactor your code and move the parsing to a function:  def parse_args(args):     parser = argparse.ArgumentParser(...)     parser.add_argument...     # ...Create your parser as you like...     return parser.parse_args(args)   Then in your main function you should just call it with:  parser = parse_args(sys.argv[1:])   (where the first element of sys.argv that represents the script name is removed to not send it as an additional switch during CLI operation.)  In your tests, you can then call the parser function with whatever list of arguments you want to test it with:  def test_parser(self):     parser = parse_args(['-l', '-m'])     self.assertTrue(parser.long)     # ...and so on.   This way you'll never have to execute the code of your application just to test the parser.  If you need to change and/or add options to your parser later in your application, then create a factory method:  def create_parser():     parser = argparse.ArgumentParser(...)     parser.add_argument...     # ...Create your parser as you like...     return parser   You can later manipulate it if you want, and a test could look like:  class ParserTest(unittest.TestCase):     def setUp(self):         self.parser = create_parser()      def test_something(self):         parsed = self.parser.parse_args(['--something', 'test'])         self.assertEqual(parsed.something, 'test')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "115",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  \"argparse portion\" is a bit vague so this answer focuses on one part: the parse_args method. This is the method that interacts with your command line and gets all the passed values. Basically, you can mock what parse_args returns so that it doesn't need to actually get values from the command line.  import argparse import mock   @mock.patch('argparse.ArgumentParser.parse_args',             return_value=argparse.Namespace(kwarg1=value, kwarg2=value)) def test_command(mock_args):     pass   You have to include all your command method's args in Namespace  even if they're not passed. Give those args a value of None. (see the docs) This style is useful for quickly doing testing for cases where different values are passed for each method argument. If you opt to mock Namespace itself for total argparse non-reliance in your tests, make sure it behaves similarly to the actual Namespace class.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  Make your main() function take argv as an argument rather than letting it read from sys.argv as it will by default:  # mymodule.py import argparse import sys   def main(args):     parser = argparse.ArgumentParser()     parser.add_argument('-a')     process(**vars(parser.parse_args(args)))     return 0   def process(a=None):     pass  if __name__ == \"__main__\":     sys.exit(main(sys.argv[1:]))   Then you can test normally.  import mock  from mymodule import main   @mock.patch('mymodule.process') def test_main(process):     main([])     process.assert_call_once_with(a=None)   @mock.patch('foo.process') def test_main_a(process):     main(['-a', '1'])     process.assert_call_once_with(a='1')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "   Populate your arg list by using sys.argv.append() and then call parse(), check the results and repeat. Call from a batch/bash file with your flags and a dump args flag. Put all your argument parsing in a separate file and in the if __name__ == \"__main__\": call parse and dump/evaluate the results then test this from a batch/bash file.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  A simple way of testing a parser is:  parser = ... parser.add_argument('-a',type=int) ... argv = '-a 1 foo'.split()  # or ['-a','1','foo'] args = parser.parse_args(argv) assert(args.a == 1) ...   Another way is to modify sys.argv, and call args = parser.parse_args()  There are lots of examples of testing argparse in lib/test/test_argparse.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  I did not want to modify the original serving script so I just mocked out the sys.argv part in argparse.  from unittest.mock import patch  with patch('argparse._sys.argv', ['python', 'serve.py']):     ...  # your test code here   This breaks if argparse implementation changes but enough for a quick test script. Sensibility is much more important than specificity in test scripts anyways.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do you write tests for the argparse portion of a python module?",
        "A_Content": "  I found that the easiest way, for me at least, was just to check sys.argv[0] so see if python was ran as python -m unittest and not parse anything if that was the case.  import sys import argparse  parser = argparse.ArgumentParser()  parser.add_argument('--outdir', help='Directory to output to', \\     default='out') parser.add_argument('--file', help='Input file', \\     default='section') parser.add_argument('--word', help='Word to look up')  if sys.argv[0] == 'python -m unittest':     args = parser.parse_args([]) else:     args = parser.parse_args()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "argparse"
        ],
        "URL": "https://stackoverflow.com/questions/18160078/how-do-you-write-tests-for-the-argparse-portion-of-a-python-module",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a Python module that uses the argparse library. How do I write tests for that section of the code base?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Where in a virtualenv does the custom code go?",
        "A_Content": "  virtualenv provides a python interpreter instance, not an application instance.  You wouldn't normally create your application files within the directories containing a system's default Python, likewise there's no requirement to locate your application within a virtualenv directory.    For example, you might have a project where you have multiple applications using the same virtualenv.  Or, you may be testing an application with a virtualenv that will later be deployed with a system Python.  Or, you may be packaging up a standalone app where it might make sense to have the virtualenv directory located somewhere within the app directory itself.    So, in general, I don't think there is one right answer to the question.  And, a good thing about virtualenv is that it supports many different use cases: there doesn't need to be one right way.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "project",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/1783146/where-in-a-virtualenv-does-the-custom-code-go",
        "A_Votes": "71",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What sort of directory structure should one follow when using virtualenv? For instance, if I were building a WSGI application and created a virtualenv called foobar I would start with a directory structure like:  /foobar   /bin     {activate, activate.py, easy_install, python}   /include     {python2.6/...}   /lib     {python2.6/...}   Once this environment is created, where would one place their own:   python files?  static files (images/etc)? \"custom\" packages, such as those available online but not found in the cheese-shop?   in relation to the virtualenv directories?  (Assume I already know where the virtualenv directories themselves should go.)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Where in a virtualenv does the custom code go?",
        "A_Content": "  If you only have a few projects every so often, nothing stops you from creating a new virtualenv for each one, and putting your packages right inside:  /foobar   /bin     {activate, activate.py, easy_install, python}   /include     {python2.6/...}   /lib     {python2.6/...}   /mypackage1     __init__.py   /mypackage2     __init__.py   The advantage of this approach is that you can always be sure to find find the activate script that belongs to the project inside.  $ cd /foobar $ source bin/activate $ python  >>> import mypackage1 >>>   If you decide to be a bit more organized, you should consider putting all your virtualenvs into one folder, and name each of them after the project you are working on.    /virtualenvs     /foobar       /bin         {activate, activate.py, easy_install, python}       /include         {python2.6/...}       /lib         {python2.6/...}   /foobar     /mypackage1       __init__.py     /mypackage2       __init__.py   This way you can always start over with a new virtualenv when things go wrong, and your project files stay safe.  Another advantage is that several of your projects can use the same virtualenv, so you don't have to do the same installation over and over if you have a lot of dependencies.  $ cd /foobar $ source ../virtualenvs/foobar/bin/activate $ python  >>> import mypackage2 >>>   For users that regularly have to set up and tear down virtualenvs it would make sense to look at virtualenvwrapper.  http://pypi.python.org/pypi/virtualenvwrapper   With virtualenvwrapper you can  * create and delete virtual environments  * organize virtual environments in a central place  * easily switch between environments   You no more have to worry about where your virtualenvs are when working on the projects \"foo\" and \"bar\":    /foo     /mypackage1       __init__.py   /bar     /mypackage2       __init__.py   This is how you start working on project \"foo\":  $ cd foo $ workon bar foo $ workon foo (foo)$ python >>> import mypackage1 >>>   Then switching to project \"bar\" is as simple as this:  $ cd ../bar $ workon bar (bar)$ python >>> import mypackage2 >>>   Pretty neat, isn't it?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "project",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/1783146/where-in-a-virtualenv-does-the-custom-code-go",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What sort of directory structure should one follow when using virtualenv? For instance, if I were building a WSGI application and created a virtualenv called foobar I would start with a directory structure like:  /foobar   /bin     {activate, activate.py, easy_install, python}   /include     {python2.6/...}   /lib     {python2.6/...}   Once this environment is created, where would one place their own:   python files?  static files (images/etc)? \"custom\" packages, such as those available online but not found in the cheese-shop?   in relation to the virtualenv directories?  (Assume I already know where the virtualenv directories themselves should go.)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Where in a virtualenv does the custom code go?",
        "A_Content": "  Because virtualenvs are not relocatable, in my opinion it is bad practice to place your project files inside a virtualenv directory. The virtualenv itself is a generated development/deployment artifact (sort of like a .pyc file), not part of the project; it should be easy to blow it away and recreate it anytime, or create a new one on a new deploy host, etc.  Many people in fact use virtualenvwrapper, which removes the actual virtualenvs from your awareness almost completely, placing them all side-by-side in $HOME/.virtualenvs by default.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "project",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/1783146/where-in-a-virtualenv-does-the-custom-code-go",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What sort of directory structure should one follow when using virtualenv? For instance, if I were building a WSGI application and created a virtualenv called foobar I would start with a directory structure like:  /foobar   /bin     {activate, activate.py, easy_install, python}   /include     {python2.6/...}   /lib     {python2.6/...}   Once this environment is created, where would one place their own:   python files?  static files (images/etc)? \"custom\" packages, such as those available online but not found in the cheese-shop?   in relation to the virtualenv directories?  (Assume I already know where the virtualenv directories themselves should go.)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Where in a virtualenv does the custom code go?",
        "A_Content": "  If you give your project a setup.py, pip can import it from version control directly.    Do something like this:  $ virtualenv --no-site-packages myproject $ . myproject/bin/activate $ easy_install pip $ pip install -e hg+http://bitbucket.org/owner/myproject#egg=proj   The -e will put the project in myproject/src, but link it to myproject/lib/pythonX.X/site-packages/, so any changes you make will get picked up immediately in modules that import it from your local site-packages.  The #egg bit tells pip what name you want to give to the egg package it creates for you.  If you don't use --no-site-packages, be careful to specify that you want pip to install into  the virtualenv with the -E option     ",
        "Language": "Python",
        "Tags": [
            "python",
            "project",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/1783146/where-in-a-virtualenv-does-the-custom-code-go",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What sort of directory structure should one follow when using virtualenv? For instance, if I were building a WSGI application and created a virtualenv called foobar I would start with a directory structure like:  /foobar   /bin     {activate, activate.py, easy_install, python}   /include     {python2.6/...}   /lib     {python2.6/...}   Once this environment is created, where would one place their own:   python files?  static files (images/etc)? \"custom\" packages, such as those available online but not found in the cheese-shop?   in relation to the virtualenv directories?  (Assume I already know where the virtualenv directories themselves should go.)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert a python 'type' object to a string",
        "A_Content": "  print type(someObject).__name__   If that doesn't suit you, use this:  print some_instance.__class__.__name__   Example:  class A:     pass print type(A()) # prints <type 'instance'> print A().__class__.__name__ # prints A   Also, it seems there are differences with type() when using new-style classes vs old-style (that is, inheritance from object). For a new-style class, type(someObject).__name__ returns the name, and for old-style classes it returns instance.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection"
        ],
        "URL": "https://stackoverflow.com/questions/5008828/convert-a-python-type-object-to-a-string",
        "A_Votes": "143",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm wondering how to convert a python 'type' object into a string using python's reflective capabilities.  For example, I'd like to print the type of an object  print \"My type is \" + type(someObject) # (which obviously doesn't work like this)   EDIT: Btw, thanks guys, I was just looking for plain printing of types for console output purposes, nothing fancy. Gabi's type(someObject).__name__ works just fine :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert a python 'type' object to a string",
        "A_Content": "  >>> class A(object): pass  >>> e = A() >>> e <__main__.A object at 0xb6d464ec> >>> print type(e) <class '__main__.A'> >>> print type(e).__name__ A >>>    what do you mean by convert into a string? you can define your own repr and str_ methods:  >>> class A(object):     def __repr__(self):         return 'hei, i am A or B or whatever'  >>> e = A() >>> e hei, i am A or B or whatever >>> str(e) hei, i am A or B or whatever   or i dont know..please add explainations ;)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection"
        ],
        "URL": "https://stackoverflow.com/questions/5008828/convert-a-python-type-object-to-a-string",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm wondering how to convert a python 'type' object into a string using python's reflective capabilities.  For example, I'd like to print the type of an object  print \"My type is \" + type(someObject) # (which obviously doesn't work like this)   EDIT: Btw, thanks guys, I was just looking for plain printing of types for console output purposes, nothing fancy. Gabi's type(someObject).__name__ works just fine :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert a python 'type' object to a string",
        "A_Content": "  print(\"My type is %s\" % type(someObject)) # the type in python   or...  print(\"My type is %s\" % type(someObject).__name__) # the object's type (the class you defined)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection"
        ],
        "URL": "https://stackoverflow.com/questions/5008828/convert-a-python-type-object-to-a-string",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm wondering how to convert a python 'type' object into a string using python's reflective capabilities.  For example, I'd like to print the type of an object  print \"My type is \" + type(someObject) # (which obviously doesn't work like this)   EDIT: Btw, thanks guys, I was just looking for plain printing of types for console output purposes, nothing fancy. Gabi's type(someObject).__name__ works just fine :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Convert a python 'type' object to a string",
        "A_Content": "  Using str()   typeOfOneAsString=str(type(1))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "reflection"
        ],
        "URL": "https://stackoverflow.com/questions/5008828/convert-a-python-type-object-to-a-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm wondering how to convert a python 'type' object into a string using python's reflective capabilities.  For example, I'd like to print the type of an object  print \"My type is \" + type(someObject) # (which obviously doesn't work like this)   EDIT: Btw, thanks guys, I was just looking for plain printing of types for console output purposes, nothing fancy. Gabi's type(someObject).__name__ works just fine :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  Python requires specifying self.  The result is there's never any confusion over what's a member and what's not, even without the full class definition visible.  This leads to useful properties, such as: you can't add members which accidentally shadow non-members and thereby break code.  One extreme example: you can write a class without any knowledge of what base classes it might have, and always know whether you are accessing a member or not:  class A(some_function()):   def f(self):     self.member = 42     self.method()   That's the complete code!  (some_function returns the type used as a base.)  Another, where the methods of a class are dynamically composed:  class B(object):   pass  print B() # <__main__.B object at 0xb7e4082c>  def B_init(self):   self.answer = 42 def B_str(self):   return \"<The answer is %s.>\" % self.answer # notice these functions require no knowledge of the actual class # how hard are they to read and realize that \"members\" are used?  B.__init__ = B_init B.__str__ = B_str  print B() # <The answer is 42.>   Remember, both of these examples are extreme and you won't see them every day, nor am I suggesting you should often write code like this, but they do clearly show aspects of self being explicitly required.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "83",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  Actually self is not a keyword, it's just the name conventionally given to the first parameter of instance methods in Python. And that first parameter can't be skipped, as it's the only mechanism a method has of knowing which instance of your class it's being called on.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  You can use whatever name you want, for example  class test(object):     def function(this, variable):         this.variable = variable   or even  class test(object):     def function(s, variable):         s.variable = variable   but you are stuck with using a name for the scope.  I do not recommend you use something different to self unless you have a convincing reason, as it would make it alien for experienced pythonistas.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  yes, you must always specify self, because explicit is better than implicit, according to python philosophy.  You will also find out that the way you program in python is very different from the way you program in java, hence the use of self tends to decrease because you don't project everything inside the object. Rather, you make larger use of module-level function, which can be better tested.  by the way. I hated it at first, now I hate the opposite. same for indented-driven flow control.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  self is part of the python syntax to access members of objects, so I'm afraid you're stuck with it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  The \"self\" is the conventional placeholder of the current object instance of a class. Its used when you want to refer to the object's property or field or method inside a class as if you're referring to \"itself\". But to make it shorter someone in the Python programming realm started to use \"self\" , other realms use \"this\" but they make it as a keyword which cannot be replaced. I rather used \"its\" to increase the code readability. Its one of the good things in Python - you have a freedom to choose your own placeholder for the object's instance other than \"self\". Example for self:  class UserAccount():         def __init__(self, user_type, username, password):         self.user_type = user_type         self.username = username                     self.password = encrypt(password)              def get_password(self):         return decrypt(self.password)      def set_password(self, password):         self.password = encrypt(password)   Now we replace 'self' with 'its':  class UserAccount():         def __init__(its, user_type, username, password):         its.user_type = user_type         its.username = username                     its.password = encrypt(password)              def get_password(its):         return decrypt(its.password)      def set_password(its, password):         its.password = encrypt(password)   which is more readable now?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  Previous answers are all basically variants of \"you can't\" or \"you shouldn't\". While I agree with the latter sentiment, the question is technically still unanswered.   Furthermore, there are legitimate reasons why someone might want to do something along the lines of what the actual question is asking. One thing I run into sometimes is lengthy math equations where using long names makes the equation unrecognizable. Here are a couple ways of how you could do this in a canned example:  import numpy as np class MyFunkyGaussian() :     def __init__(self, A, x0, w, s, y0) :         self.A = float(A)         self.x0 = x0         self.w = w         self.y0 = y0         self.s = s      # The correct way, but subjectively less readable to some (like me)      def calc1(self, x) :         return (self.A/(self.w*np.sqrt(np.pi))/(1+self.s*self.w**2/2)                 * np.exp( -(x-self.x0)**2/self.w**2)                 * (1+self.s*(x-self.x0)**2) + self.y0 )      # The correct way if you really don't want to use 'self' in the calculations     def calc2(self, x) :         # Explicity copy variables         A, x0, w, y0, s = self.A, self.x0, self.w, self.y0, self.s         sqrt, exp, pi = np.sqrt, np.exp, np.pi         return ( A/( w*sqrt(pi) )/(1+s*w**2/2)                 * exp( -(x-x0)**2/w**2 )                 * (1+s*(x-x0)**2) + y0 )      # Probably a bad idea...     def calc3(self, x) :         # Automatically copy every class vairable         for k in self.__dict__ : exec(k+'= self.'+k)         sqrt, exp, pi = np.sqrt, np.exp, np.pi         return ( A/( w*sqrt(pi) )/(1+s*w**2/2)                 * exp( -(x-x0)**2/w**2 )                 * (1+s*(x-x0)**2) + y0 )  g = MyFunkyGaussian(2.0, 1.5, 3.0, 5.0, 0.0) print(g.calc1(0.5)) print(g.calc2(0.5)) print(g.calc3(0.5))   The third example - i.e. using for k in self.__dict__ : exec(k+'= self.'+k) is basically what the question is actually asking for, but let me be clear that I don't think it is generally a good idea.  For more info, and ways to iterate through class variables, or even functions, see answers and discussion to this question. For a discussion of other ways to dynamically name variables, and why this is usually not a good idea see this blog post.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  Yeah, self is tedious. But, is it better?  class Test:      def __init__(_):         _.test = 'test'      def run(_):         print _.test      ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  From: Self Hell - More stateful functions.     ...a hybrid approach works best. All of your class methods that actually    do computation should be moved into closures, and extensions to clean up syntax should be kept in classes. Stuff the closures into classes, treating the class much like a namespace. The closures are essentially static functions, and so do not require selfs*, even in the class...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How to avoid explicit 'self' in Python?",
        "A_Content": "  Actually you can use recipe \"Implicit self\" from Armin Ronacher presentation \"5 years of bad ideas\" ( google it).  It's a very clever recipe, as almost everything from Armin Ronacher, but I don't think this idea is very appealing. I think I'd prefer explicit this in C#/Java.  Update. Link to \"bad idea recipe\": https://speakerdeck.com/mitsuhiko/5-years-of-bad-ideas?slide=58     ",
        "Language": "Python",
        "Tags": [
            "python",
            "self"
        ],
        "URL": "https://stackoverflow.com/questions/1984104/how-to-avoid-explicit-self-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been learning Python by following some pygame tutorials.  Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.  The Java parallel I can think of for this situation is having to prefix all references to member variables with this.  Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?  Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.  I have taken a look at these related SO questions, but they don't quite answer what I am after:   Python - why use “self” in a class?   Why do you need explicitly have the “self” argument into a Python method?      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Disable IPython Exit Confirmation",
        "A_Content": "  If you also want Ctrl-D to exit without confirmation, in IPython 0.11, add c.TerminalInteractiveShell.confirm_exit = False to your config file *.  If you don't have a config file yet, run ipython profile create to create one.  Note this ticket if you're working within the Django shell.    * The config file is located at: $HOME/.ipython/profile_default/ipython_config.py     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/7438112/disable-ipython-exit-confirmation",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    It's really irritating that every time I type exit(), I get prompted with a confirmation to exit; of course I want to exit! Otherwise, I would not have written exit()!!!  Is there a way to override IPython's default behaviour to make it exit without a prompt?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Disable IPython Exit Confirmation",
        "A_Content": "  In ipython version 0.11 or higher,    Run with --no-confirm-exit OR Exit via 'exit' instead of control-D OR Make sure the directory exists (or run ipython profile create to create it) and add these lines to $HOME/.ipython/profile_default/ipython_config.py:   c = get_config()  c.TerminalInteractiveShell.confirm_exit = False       ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/7438112/disable-ipython-exit-confirmation",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It's really irritating that every time I type exit(), I get prompted with a confirmation to exit; of course I want to exit! Otherwise, I would not have written exit()!!!  Is there a way to override IPython's default behaviour to make it exit without a prompt?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Disable IPython Exit Confirmation",
        "A_Content": "  just type Exit, with capital E.  Alternatively, start IPython with:  $ ipython -noconfirm_exit   Or for newer versions of IPython:  $ ipython --no-confirm-exit       ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/7438112/disable-ipython-exit-confirmation",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It's really irritating that every time I type exit(), I get prompted with a confirmation to exit; of course I want to exit! Otherwise, I would not have written exit()!!!  Is there a way to override IPython's default behaviour to make it exit without a prompt?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Disable IPython Exit Confirmation",
        "A_Content": "  I like the config suggestions, but until I learned them I've started using \"Quit\" key combination.  Ctrl+\\   or  Ctrl+4   This just kills what is running. No time to ask questions on confirmation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ipython"
        ],
        "URL": "https://stackoverflow.com/questions/7438112/disable-ipython-exit-confirmation",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    It's really irritating that every time I type exit(), I get prompted with a confirmation to exit; of course I want to exit! Otherwise, I would not have written exit()!!!  Is there a way to override IPython's default behaviour to make it exit without a prompt?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I initialize the base (super) class?",
        "A_Content": "  Python (until version 3) supports \"old-style\" and new-style classes. New-style classes are derived from object and are what you are using, and invoke their base class through super(), e.g.  class X(object):   def __init__(self, x):     pass    def doit(self, bar):     pass  class Y(X):   def __init__(self):     super(Y, self).__init__(123)    def doit(self, foo):     return super(Y, self).doit(foo)   Because python knows about old- and new-style classes, there are different ways to invoke a base method, which is why you've found multiple ways of doing so.  For completeness sake, old-style classes call base methods explicitly using the base class, i.e.  def doit(self, foo):   return X.doit(self, foo)   But since you shouldn't be using old-style anymore, I wouldn't care about this too much.  Python 3 only knows about new-style classes (no matter if you derive from object or not).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop"
        ],
        "URL": "https://stackoverflow.com/questions/3694371/how-do-i-initialize-the-base-super-class",
        "A_Votes": "118",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Python, consider I have the following code:  >>> class SuperClass(object):     def __init__(self, x):         self.x = x  >>> class SubClass(SuperClass):     def __init__(self, y):         self.y = y         # how do I initialize the SuperClass __init__ here?   How do I initialize the SuperClass __init__ in the subclass? I am following the Python tutorial and it doesn't cover that. When I searched on Google, I found more than one way of doing. What is the standard way of handling this?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I initialize the base (super) class?",
        "A_Content": "  Both  SuperClass.__init__(self, x)   or  super(SubClass,self).__init__( x )   will work (I prefer the 2nd one, as it adheres more to the DRY principle).  See here: http://docs.python.org/reference/datamodel.html#basic-customization     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop"
        ],
        "URL": "https://stackoverflow.com/questions/3694371/how-do-i-initialize-the-base-super-class",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, consider I have the following code:  >>> class SuperClass(object):     def __init__(self, x):         self.x = x  >>> class SubClass(SuperClass):     def __init__(self, y):         self.y = y         # how do I initialize the SuperClass __init__ here?   How do I initialize the SuperClass __init__ in the subclass? I am following the Python tutorial and it doesn't cover that. When I searched on Google, I found more than one way of doing. What is the standard way of handling this?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I initialize the base (super) class?",
        "A_Content": "  As of python 3.5.2, you can use:  class C(B): def method(self, arg):     super().method(arg)    # This does the same thing as:                            # super(C, self).method(arg)   https://docs.python.org/3/library/functions.html#super     ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop"
        ],
        "URL": "https://stackoverflow.com/questions/3694371/how-do-i-initialize-the-base-super-class",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, consider I have the following code:  >>> class SuperClass(object):     def __init__(self, x):         self.x = x  >>> class SubClass(SuperClass):     def __init__(self, y):         self.y = y         # how do I initialize the SuperClass __init__ here?   How do I initialize the SuperClass __init__ in the subclass? I am following the Python tutorial and it doesn't cover that. When I searched on Google, I found more than one way of doing. What is the standard way of handling this?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "How do I initialize the base (super) class?",
        "A_Content": "     How do I initialize the base (super) class?  class SuperClass(object):     def __init__(self, x):         self.x = x  class SubClass(SuperClass):     def __init__(self, y):         self.y = y    Use a super object to ensure you get the next method (as a bound method) in the method resolution order. In Python 2, you need to pass the class name and self to super to lookup the bound __init__ method:   class SubClass(SuperClass):       def __init__(self, y):           super(SubClass, self).__init__('x')           self.y = y   In Python 3, there's a little magic that makes the arguments to super unnecessary - and as a side benefit it works a little faster:   class SubClass(SuperClass):       def __init__(self, y):           super().__init__('x')           self.y = y   Hardcoding the parent like this below prevents you from using cooperative multiple inheritance:   class SubClass(SuperClass):       def __init__(self, y):           SuperClass.__init__(self, 'x') # don't do this           self.y = y   Note that __init__ may only return None - it is intended to modify the object in-place.  Something __new__  There's another way to initialize instances - and it's the only way for subclasses of immutable types in Python. So it's required if you want to subclass str or tuple or another immutable object.  You might think it's a classmethod because it gets an implicit class argument. But it's actually a staticmethod. So you need to call __new__ with cls explicitly.  We usually return the instance from __new__, so if you do, you also need to call your base's __new__ via super as well in your base class. So if you use both methods:  class SuperClass(object):     def __new__(cls, x):         return super(SuperClass, cls).__new__(cls)     def __init__(self, x):         self.x = x  class SubClass(object):     def __new__(cls, y):         return super(SubClass, cls).__new__(cls)      def __init__(self, y):         self.y = y         super(SubClass, self).__init__('x')   Python 3 sidesteps a little of the weirdness of the super calls caused by __new__ being a static method, but you still need to pass cls to the non-bound __new__ method:  class SuperClass(object):     def __new__(cls, x):         return super().__new__(cls)     def __init__(self, x):         self.x = x  class SubClass(object):     def __new__(cls, y):         return super().__new__(cls)     def __init__(self, y):         self.y = y         super().__init__('x')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "oop"
        ],
        "URL": "https://stackoverflow.com/questions/3694371/how-do-i-initialize-the-base-super-class",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python, consider I have the following code:  >>> class SuperClass(object):     def __init__(self, x):         self.x = x  >>> class SubClass(SuperClass):     def __init__(self, y):         self.y = y         # how do I initialize the SuperClass __init__ here?   How do I initialize the SuperClass __init__ in the subclass? I am following the Python tutorial and it doesn't cover that. When I searched on Google, I found more than one way of doing. What is the standard way of handling this?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  Raising exceptions within __init__() is absolutely fine. There's no other good way to indicate an error condition within a constructor, and there are many hundreds of examples in the standard library where building an object can raise an exception.  The error class to raise, of course, is up to you. ValueError is best if the constructor was passed an invalid parameter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  It's true that the only proper way to indicate an error in a constructor is raising an exception. That is why in C++ and in other object-oriented languages that have been designed with exception safety in mind, the destructor is not called if an exception is thrown in the constructor of an object (meaning that the initialization of the object is incomplete). This is often not the case in scripting languages, such as Python. For example, the following code throws an AttributeError if socket.connect() fails:  class NetworkInterface:     def __init__(self, address)         self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)         self.socket.connect(address)         self.stream = self.socket.makefile()      def __del__(self)         self.stream.close()         self.socket.close()   The reason is that the destructor of the incomplete object is called after the connection attempt has failed, before the stream attribute has been initialized. You shouldn't avoid throwing exceptions from constructors, I'm just saying that it's difficult to write fully exception safe code in Python. Some Python developers avoid using destructors altogether, but that's a matter of another debate.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  I don't see any reason that it should be bad form.  On the contrary, one of the things exceptions are known for doing well, as opposed to returning error codes, is that error codes usually can't be returned by constructors. So at least in languages like C++, raising exceptions is the only way to signal errors.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  The standard library says:  >>> f = file(\"notexisting.txt\") Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> IOError: [Errno 2] No such file or directory: 'notexisting.txt'   Also I don't really see any reason why it should be considered bad form.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  I should think it is the perfect case for the built-in ValueError exception.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  I concur with all of the above.  There's really no other way to signal that something went wrong in the initialisation of an object other than raising an exception.   In most programs classes where the state of a class is wholly dependant on the inputs to that class we might expect some kind of ValueError or TypeError to be raised.   Classes with side-effects (e.g. one which does networking or graphics) might raise an error in init if (for example) the network device is unavailable or the canvas object cannot be written to. This sounds sensible to me because often you want to know about failure conditions as soon as possible.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Python: Is it bad form to raise exceptions within __init__?",
        "A_Content": "  Raising errors from init is unavoidable in some cases, but doing too much work in init is a bad style. You should consider making a factory or a pseudo-factory - a simple classmethod that returns setted up object.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exception"
        ],
        "URL": "https://stackoverflow.com/questions/1507082/python-is-it-bad-form-to-raise-exceptions-within-init",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it considered bad form to raise exceptions within __init__? If so, then what is the accepted method of throwing an error when certain class variables are initialized as None or of an incorrect type?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Duplicate virtualenv",
        "A_Content": "  The easiest way is to use pip to generate a requirements file. A requirements file is basically a file that contains a list of all the python packages you want to install (or have already installed in case of file generated by pip), and what versions they're at.  To generate a requirements file, go into your original virtualenv, and run:  pip freeze > requirements.txt   This will generate the requirements.txt file for you. If you open that file up in your favorite text editor, you'll see something like:  Django==1.3 Fabric==1.0.1 etc...   Now, edit the line that says Django==x.x to say Django==1.3 (or whatever version you want to install in your new virtualenv).  Lastly, activate your new virtualenv, and run:  pip install -r requirements.txt   And pip will automatically download and install all the python modules listed in your requirements.txt file, at whatever versions you specified!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/7438681/duplicate-virtualenv",
        "A_Votes": "134",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have an existing environment in virtualenv, with a lot of packages, but an old Django version.  What if I want to duplicate this environment, so  I can have another environment in which I can install a newer Django version,but keeping all packages that are already in the other environment?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Duplicate virtualenv",
        "A_Content": "  Another option is to use virtualenv-clone package:     A script for cloning a non-relocatable virtualenv.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/7438681/duplicate-virtualenv",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an existing environment in virtualenv, with a lot of packages, but an old Django version.  What if I want to duplicate this environment, so  I can have another environment in which I can install a newer Django version,but keeping all packages that are already in the other environment?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Duplicate virtualenv",
        "A_Content": "  virtualenvwrapper provides a command to duplicate virtualenv  cpvirtualenv ENVNAME [TARGETENVNAME]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/7438681/duplicate-virtualenv",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an existing environment in virtualenv, with a lot of packages, but an old Django version.  What if I want to duplicate this environment, so  I can have another environment in which I can install a newer Django version,but keeping all packages that are already in the other environment?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Duplicate virtualenv",
        "A_Content": "  Can you not simply:   Copy the existing virtual env directory to a new one Update to the new Django?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/7438681/duplicate-virtualenv",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an existing environment in virtualenv, with a lot of packages, but an old Django version.  What if I want to duplicate this environment, so  I can have another environment in which I can install a newer Django version,but keeping all packages that are already in the other environment?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Duplicate virtualenv",
        "A_Content": "  If you are using Anaconda you can just run:  conda create --name myclone --clone myenv      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "virtualenv"
        ],
        "URL": "https://stackoverflow.com/questions/7438681/duplicate-virtualenv",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have an existing environment in virtualenv, with a lot of packages, but an old Django version.  What if I want to duplicate this environment, so  I can have another environment in which I can install a newer Django version,but keeping all packages that are already in the other environment?     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  Python has two different ways to convert an object to a string: str() and repr().  Printing an object uses str(); printing a list containing an object uses str() for the list itself, but the implementation of list.__str__() calls repr() for the individual items.  So you should also overwrite __repr__().  A simple  __repr__ = __str__   at the end of the class body will do the trick.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  Because of the infinite superiority of Python over Java, Python has not one, but two toString operations.   One is __str__, the other is __repr__  __str__ will return a human readable string. __repr__ will return an internal representation.   __repr__ can be invoked on an object by calling repr(obj) or by using backticks `obj`.  When printing lists as well as other container classes, the contained elements will be printed using __repr__.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  It provides human readable version  of output rather \"Object\": Example:   class Pet(object):      def __init__(self, name, species):         self.name = name         self.species = species      def getName(self):         return self.name      def getSpecies(self):         return self.species      def Norm(self):         return \"%s is a %s\" % (self.name, self.species)  if __name__=='__main__':     a = Pet(\"jax\", \"human\")     print a    returns   <__main__.Pet object at 0x029E2F90>   while code with \"str\" return something different   class Pet(object):      def __init__(self, name, species):         self.name = name         self.species = species      def getName(self):         return self.name      def getSpecies(self):         return self.species      def __str__(self):         return \"%s is a %s\" % (self.name, self.species)  if __name__=='__main__':     a = Pet(\"jax\", \"human\")     print a    returns:   jax is a human      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  Well, container objects' __str__ methods will use repr on their contents, not str. So you could use __repr__ instead of __str__, seeing as you're using an ID as the result.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  __str__ is only called when a string representation is required of an object.  For example str(uno), print \"%s\" % uno or print uno  However, there is another magic method called __repr__ this is the representation of an object.  When you don't explicitly convert the object to a string, then the representation is used.  If you do this uno.neighbors.append([[str(due),4],[str(tri),5]]) it will do what you expect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  Answer to the question  As pointed out in another answer and as you can read in PEP 3140, str on a list calls for each item __repr__. There is not much you can do about that part.   If you implement __repr__, you will get something more descriptive, but if implemented correctly, not exactly what you expected.  Proper implementation  The fast, but wrong solution is to alias __repr__ to __str__.  __repr__ should not be set to __str__ unconditionally. __repr__ should create a representation, that should look like a valid Python expression that could be used to recreate an object with the same value. In this case, this would rather be Node(2) than 2.  A proper implementation of __repr__ makes it possible to recreate the object. In this example, it should also contain the other significant members, like neighours and distance.   An incomplete example:  class Node:      def __init__(self, id, neighbours=[], distance=0):         self.id = id         self.neighbours = neighbours         self.distance = distance       def __str__(self):         return str(self.id)       def __repr__(self):         return \"Node(id={0.id}, neighbours={0.neighbours!r}, distance={0.distance})\".format(self)         # in an elaborate implementation, members that have the default         # value could be left out, but this would hide some information   uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)  print uno print str(uno) print repr(uno)  uno.neighbours.append([[due, 4], [tri, 5]])  print uno print uno.neighbours print repr(uno)   Note: print repr(uno) together with a proper implementation of __eq__ and __ne__ or __cmp__ would allow to recreate the object and check for equality.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  The thing about classes, and setting unencumbered global variables equal to some value within the class, is that what your global variable stores is actually the reference to the memory location the value is actually stored.    What you're seeing in your output is indicative of this.    Where you might be able to see the value and use print without issue on the initial global variables you used because of the str method and how print works, you won't be able to do this with lists, because what is stored in the elements within that list is just a reference to the memory location of the value -- read up on aliases, if you'd like to know more.   Additionally, when using lists and losing track of what is an alias and what is not, you might find you're changing the value of the original list element, if you change it in an alias list -- because again, when you set a list element equal to a list or element within a list, the new list only stores the reference to the memory location (it doesn't actually create new memory space specific to that new variable).  This is where deepcopy comes in handy!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Confused about __str__ on list in Python [duplicate]",
        "A_Content": "  print self.id.__str__() would work for you, although not that useful for you.   Your __str__ method will be more useful when you say want to print out a grid or struct representation as your program develops.  print self._grid.__str__()  def __str__(self):     \"\"\"     Return a string representation of the grid for debugging.     \"\"\"     grid_str = \"\"     for row in range(self._rows):         grid_str += str( self._grid[row] )         grid_str += '\\n'     return grid_str      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "list",
            "printing",
            "tostring"
        ],
        "URL": "https://stackoverflow.com/questions/12448175/confused-about-str-on-list-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Python __str__ and lists                                        7 answers                                          Coming from a Java background, I understand that __str__ is something like a Python version of toString (while I do realize that Python is the older language).  So, I have defined a little class along with an __str__ method as follows:  class Node:      def __init__(self, id):         self.id = id         self.neighbours = []         self.distance = 0       def __str__(self):         return str(self.id)   I then create a few instances of it:  uno = Node(1)     due = Node(2)     tri = Node(3)     qua = Node(4)   Now, the expected behaviour when trying to print one of these objects is that it's associated value gets printed. This also happens.  print uno   yields  1   But when I do the following:  uno.neighbours.append([[due, 4], [tri, 5]])   and then  print uno.neighbours   I get  [[[<__main__.Node instance at 0x00000000023A6C48>, 4], [<__main__.Node instance at 0x00000000023A6D08>, 5]]]   Where I expected  [[2, 4], [3, 5]]   What am I missing? And what otherwise cringe-worthy stuff am I doing? :)     ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Cython: “fatal error: numpy/arrayobject.h: No such file or directory”",
        "A_Content": "  In your setup.py, the Extension should have the argument include_dirs=[numpy.get_include()].  Also, you are missing np.import_array() in your code.  --  Example setup.py:  from distutils.core import setup, Extension from Cython.Build import cythonize import numpy  setup(     ext_modules=[         Extension(\"my_module\", [\"my_module.c\"],                   include_dirs=[numpy.get_include()]),     ], )  # Or, if you use cythonize() to make the ext_modules list, # include_dirs can be passed to setup()  setup(     ext_modules=cythonize(\"my_module.pyx\"),     include_dirs=[numpy.get_include()] )          ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows-7",
            "numpy",
            "cython"
        ],
        "URL": "https://stackoverflow.com/questions/14657375/cython-fatal-error-numpy-arrayobject-h-no-such-file-or-directory",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm trying to speed up the answer here using Cython. I try to compile the code (after doing the cygwinccompiler.py hack explained here), but get a fatal error: numpy/arrayobject.h: No such file or directory...compilation terminated error. Can anyone tell me if it's a problem with my code, or some esoteric subtlety with Cython?  Below is my code. Thanks in advance:  import numpy as np import scipy as sp cimport numpy as np cimport cython  cdef inline np.ndarray[np.int, ndim=1] fbincount(np.ndarray[np.int_t, ndim=1] x):     cdef int m = np.amax(x)+1     cdef int n = x.size     cdef unsigned int i     cdef np.ndarray[np.int_t, ndim=1] c = np.zeros(m, dtype=np.int)      for i in xrange(n):         c[<unsigned int>x[i]] += 1      return c  cdef packed struct Point:     np.float64_t f0, f1  @cython.boundscheck(False) def sparsemaker(np.ndarray[np.float_t, ndim=2] X not None,                 np.ndarray[np.float_t, ndim=2] Y not None,                 np.ndarray[np.float_t, ndim=2] Z not None):      cdef np.ndarray[np.float64_t, ndim=1] counts, factor     cdef np.ndarray[np.int_t, ndim=1] row, col, repeats     cdef np.ndarray[Point] indices      cdef int x_, y_      _, row = np.unique(X, return_inverse=True); x_ = _.size     _, col = np.unique(Y, return_inverse=True); y_ = _.size     indices = np.rec.fromarrays([row,col])     _, repeats = np.unique(indices, return_inverse=True)     counts = 1. / fbincount(repeats)     Z.flat *= counts.take(repeats)      return sp.sparse.csr_matrix((Z.flat,(row,col)), shape=(x_, y_)).toarray()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Cython: “fatal error: numpy/arrayobject.h: No such file or directory”",
        "A_Content": "  For a one-file project like yours, another alternative is to use pyximport. You don't need to create a setup.py ... you don't need to even open a command line if you use IPython ... it's all very convenient. In your case, try running these commands in IPython or in a normal Python script:  import numpy import pyximport pyximport.install(setup_args={\"script_args\":[\"--compiler=mingw32\"],                               \"include_dirs\":numpy.get_include()},                   reload_support=True)  import my_pyx_module  print my_pyx_module.some_function(...) ...   You may need to edit the compiler of course. This makes import and reload work the same for .pyx files as they work for .py files.  Source: http://wiki.cython.org/InstallingOnWindows     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows-7",
            "numpy",
            "cython"
        ],
        "URL": "https://stackoverflow.com/questions/14657375/cython-fatal-error-numpy-arrayobject-h-no-such-file-or-directory",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to speed up the answer here using Cython. I try to compile the code (after doing the cygwinccompiler.py hack explained here), but get a fatal error: numpy/arrayobject.h: No such file or directory...compilation terminated error. Can anyone tell me if it's a problem with my code, or some esoteric subtlety with Cython?  Below is my code. Thanks in advance:  import numpy as np import scipy as sp cimport numpy as np cimport cython  cdef inline np.ndarray[np.int, ndim=1] fbincount(np.ndarray[np.int_t, ndim=1] x):     cdef int m = np.amax(x)+1     cdef int n = x.size     cdef unsigned int i     cdef np.ndarray[np.int_t, ndim=1] c = np.zeros(m, dtype=np.int)      for i in xrange(n):         c[<unsigned int>x[i]] += 1      return c  cdef packed struct Point:     np.float64_t f0, f1  @cython.boundscheck(False) def sparsemaker(np.ndarray[np.float_t, ndim=2] X not None,                 np.ndarray[np.float_t, ndim=2] Y not None,                 np.ndarray[np.float_t, ndim=2] Z not None):      cdef np.ndarray[np.float64_t, ndim=1] counts, factor     cdef np.ndarray[np.int_t, ndim=1] row, col, repeats     cdef np.ndarray[Point] indices      cdef int x_, y_      _, row = np.unique(X, return_inverse=True); x_ = _.size     _, col = np.unique(Y, return_inverse=True); y_ = _.size     indices = np.rec.fromarrays([row,col])     _, repeats = np.unique(indices, return_inverse=True)     counts = 1. / fbincount(repeats)     Z.flat *= counts.take(repeats)      return sp.sparse.csr_matrix((Z.flat,(row,col)), shape=(x_, y_)).toarray()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Cython: “fatal error: numpy/arrayobject.h: No such file or directory”",
        "A_Content": "  The error means that a numpy header file isn't being found during compilation.    Try doing export CFLAGS=-I/usr/lib/python2.7/site-packages/numpy/core/include/, and then compiling.  This is a problem with a few different packages.  There's a bug filed in ArchLinux for the same issue: https://bugs.archlinux.org/task/22326     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows-7",
            "numpy",
            "cython"
        ],
        "URL": "https://stackoverflow.com/questions/14657375/cython-fatal-error-numpy-arrayobject-h-no-such-file-or-directory",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to speed up the answer here using Cython. I try to compile the code (after doing the cygwinccompiler.py hack explained here), but get a fatal error: numpy/arrayobject.h: No such file or directory...compilation terminated error. Can anyone tell me if it's a problem with my code, or some esoteric subtlety with Cython?  Below is my code. Thanks in advance:  import numpy as np import scipy as sp cimport numpy as np cimport cython  cdef inline np.ndarray[np.int, ndim=1] fbincount(np.ndarray[np.int_t, ndim=1] x):     cdef int m = np.amax(x)+1     cdef int n = x.size     cdef unsigned int i     cdef np.ndarray[np.int_t, ndim=1] c = np.zeros(m, dtype=np.int)      for i in xrange(n):         c[<unsigned int>x[i]] += 1      return c  cdef packed struct Point:     np.float64_t f0, f1  @cython.boundscheck(False) def sparsemaker(np.ndarray[np.float_t, ndim=2] X not None,                 np.ndarray[np.float_t, ndim=2] Y not None,                 np.ndarray[np.float_t, ndim=2] Z not None):      cdef np.ndarray[np.float64_t, ndim=1] counts, factor     cdef np.ndarray[np.int_t, ndim=1] row, col, repeats     cdef np.ndarray[Point] indices      cdef int x_, y_      _, row = np.unique(X, return_inverse=True); x_ = _.size     _, col = np.unique(Y, return_inverse=True); y_ = _.size     indices = np.rec.fromarrays([row,col])     _, repeats = np.unique(indices, return_inverse=True)     counts = 1. / fbincount(repeats)     Z.flat *= counts.take(repeats)      return sp.sparse.csr_matrix((Z.flat,(row,col)), shape=(x_, y_)).toarray()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Cython: “fatal error: numpy/arrayobject.h: No such file or directory”",
        "A_Content": "  Simple answer  A way simpler way is to add the path to your file distutils.cfg. It's path behalf of Windows 7 is by default C:\\Python27\\Lib\\distutils\\. You just assert the following contents and it should work out:  [build_ext] include_dirs= C:\\Python27\\Lib\\site-packages\\numpy\\core\\include   Entire config file  To give you an example how the config file could look like, my entire file reads:  [build] compiler = mingw32  [build_ext] include_dirs= C:\\Python27\\Lib\\site-packages\\numpy\\core\\include compiler = mingw32      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows-7",
            "numpy",
            "cython"
        ],
        "URL": "https://stackoverflow.com/questions/14657375/cython-fatal-error-numpy-arrayobject-h-no-such-file-or-directory",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm trying to speed up the answer here using Cython. I try to compile the code (after doing the cygwinccompiler.py hack explained here), but get a fatal error: numpy/arrayobject.h: No such file or directory...compilation terminated error. Can anyone tell me if it's a problem with my code, or some esoteric subtlety with Cython?  Below is my code. Thanks in advance:  import numpy as np import scipy as sp cimport numpy as np cimport cython  cdef inline np.ndarray[np.int, ndim=1] fbincount(np.ndarray[np.int_t, ndim=1] x):     cdef int m = np.amax(x)+1     cdef int n = x.size     cdef unsigned int i     cdef np.ndarray[np.int_t, ndim=1] c = np.zeros(m, dtype=np.int)      for i in xrange(n):         c[<unsigned int>x[i]] += 1      return c  cdef packed struct Point:     np.float64_t f0, f1  @cython.boundscheck(False) def sparsemaker(np.ndarray[np.float_t, ndim=2] X not None,                 np.ndarray[np.float_t, ndim=2] Y not None,                 np.ndarray[np.float_t, ndim=2] Z not None):      cdef np.ndarray[np.float64_t, ndim=1] counts, factor     cdef np.ndarray[np.int_t, ndim=1] row, col, repeats     cdef np.ndarray[Point] indices      cdef int x_, y_      _, row = np.unique(X, return_inverse=True); x_ = _.size     _, col = np.unique(Y, return_inverse=True); y_ = _.size     indices = np.rec.fromarrays([row,col])     _, repeats = np.unique(indices, return_inverse=True)     counts = 1. / fbincount(repeats)     Z.flat *= counts.take(repeats)      return sp.sparse.csr_matrix((Z.flat,(row,col)), shape=(x_, y_)).toarray()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  driver.find_element_by_id('foo').clear()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  You can use   webElement.clear();   If this element is a text entry element, this will clear the value.  Note that the events fired by this event may not be  as you'd expect. In particular, we don't fire any keyboard or mouse events. If you want to ensure keyboard events are fired, consider using something like sendKeys(CharSequence). E.g.:    webElement.sendKeys(Keys.BACK_SPACE); //do repeatedly, e.g. in while loop   or:   webElement.sendKeys(Keys.CONTROL + \"a\");  webElement.sendKeys(Keys.DELETE);      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  In the most recent Selenium version, use:  driver.find_element_by_id('foo').clear()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  It is general syntax  driver.find_element_by_id('Locator value').clear(); driver.find_element_by_name('Locator value').clear();      ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  for java   driver.findelement(By.id('foo').clear();   or  webElement.clear();   If this element is a text entry element, this will clear the value.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Clear text from textarea with selenium",
        "A_Content": "  With a simple call of clear() it appears in the DOM that the corresponding input/textarea component still has its old value, so any following changes on that component (e.g. filling the component with a new value) will not be processed in time.  If you take a look in the selenium source code you'll find that the clear()-method is documented with the following comment:     /** If this element is a text entry element, this will clear the value. Has no effect on other elements. Text entry elements are INPUT and TEXTAREA elements. Note that the events fired by this event may not be as you'd expect.  In particular, we don't fire any keyboard or mouse events.  If you want to ensure keyboard events are fired, consider using something like {@link #sendKeys(CharSequence...)} with the backspace key. To ensure you get a change event, consider following with a call to {@link #sendKeys(CharSequence...)} with the tab key. */   So using this helpful hint to clear an input/textarea (component that already has a value) AND assign a new value to it, you'll get some code like the following:   public void waitAndClearFollowedByKeys(By by, CharSequence keys) {     LOG.debug(\"clearing element\");     wait(by, true).clear();     sendKeys(by, Keys.BACK_SPACE.toString() + keys); }  public void sendKeys(By by, CharSequence keysToSend) {     WebElement webElement = wait(by, true);     LOG.info(\"sending keys '{}' to {}\", escapeProperly(keysToSend), by);     webElement.sendKeys(keysToSend);     LOG.info(\"keys sent\"); }  private String escapeProperly(CharSequence keysToSend) {     String result = \"\" + keysToSend;     result = result.replace(Keys.TAB, \"\\\\t\");     result = result.replace(Keys.ENTER, \"\\\\n\");     result = result.replace(Keys.RETURN, \"\\\\r\");      return result; }   Sorry for this code being Java and not Python. Also, I had to skip out an additional \"waitUntilPageIsReady()-method that would make this post way too long.  Hope this helps you on your journey with Selenium!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "selenium",
            "selenium-webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/7732125/clear-text-from-textarea-with-selenium",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've got some tests where I'm checking that the proper error message appears when text in certain fields are invalid.  One check for validity is that a certain textarea element is not empty.  If this textarea already has text in it, how can I tell selenium to clear the field?  something like:  driver.get_element_by_id('foo').clear_field()      ",
        "Q_Votes": "92"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  There are probably two major differences:  Ruby has elegant, anonymous closures.  Rails uses them to good effect. Here's an example:  class WeblogController < ActionController::Base   def index     @posts = Post.find :all     respond_to do |format|       format.html       format.xml { render :xml => @posts.to_xml }       format.rss { render :action => \"feed.rxml\" }     end   end end   Anonymous closures/lambdas make it easier to emulate new language features that would take blocks. In Python, closures exist, but they must be named in order to be used. So instead of being able to use closures to emulate new language features, you're forced to be explicit about the fact that you're using a closure.  Ruby has cleaner, easier to use metaprogramming.  This is used extensively in Rails, primarily because of how easy it is to use. To be specific, in Ruby, you can execute arbitrary code in the context of the class. The following snippets are equivalent:  class Foo   def self.make_hello_method     class_eval do       def hello         puts \"HELLO\"       end     end   end end  class Bar < Foo # snippet 1   make_hello_method end  class Bar < Foo; end # snippet 2 Bar.make_hello_method   In both cases, you can then do:  Bar.new.hello     which will print \"HELLO\". The class_eval method also takes a String, so it's possible to create methods on the fly, as a class is being created, that have differing semantics based on the parameters that are passed in.  It is, in fact, possible to do this sort of metaprogramming in Python (and other languages, too), but Ruby has a leg up because metaprogramming isn't a special style of programming. It flows from the fact that in Ruby, everything is an object and all lines of code are directly executed. As a result, Classes are themselves objects, class bodies have a self pointing at the Class, and you can call methods on the class as you are creating one.  This is to large degree responsible for the degree of declarativeness possible in Rails, and the ease by which we are able to implement new declarative features that look like keywords or new block language features.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "170",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Those who have argued that     the immense success of the Rails   framework really has a great deal to   do with the language it is built on   are (IMO) mistaken. That success probably owes more to clever and sustained marketing than to any technical prowess. Django arguably does a better job in many areas (e.g. the built-in kick-ass admin) without the need for any features of Ruby. I'm not dissing Ruby at all, just standing up for Python!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "59",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  The python community believes that doing things the most simple and straight forward way possible is the highest form of elegance. The ruby community believes doing things in clever ways that allow for cool code is the highest form of elegance.   Rails is all about if you follow certain conventions, loads of other things magically happen for you. That jives really well with the ruby way of looking at the world, but doesn't really follow the python way.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "53",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Is this debate a new \"vim versus emacs\" debate?  I am a Python/Django programmer and thus far I've never found a problem in that language/framework that would lead me to switch to Ruby/Rails.  I can imagine that it would be the same if I were experienced with Ruby/Rails.  Both have similar philosophy and do the job in a fast and elegant way. The better choice is what you already know.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Personally, I find ruby to be superior to python in many ways that comprise what I'd call 'consistent expressiveness'. For example, in ruby, join is a method on the array object which outputs a string, so you get something like this:  numlist = [1,2,3,4] #=> [1, 2, 3, 4] numlist.join(',') #=> \"1,2,3,4\"   In python, join is a method on the string object but which throws an error if you pass it something other than a string as the thing to join, so the same construct is something like:  numlist = [1,2,3,4] numlist #=> [1, 2, 3, 4] \",\".join([str(i) for i in numlist]) #=> '1,2,3,4'   There are a lot of these little kinds of differences that add up over time.  Also, I cannot think of a better way to introduce invisible logic errors than to make whitespace significant.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  The real answer is neither Python or Ruby are better/worse candidates for a web framework. If you want objectivity you need to write some code in both and see which fits your personal preference best, including community.   Most people who argue for one or other have either never used the other language seriously or are 'voting' for their personal preference.  I would guess most people settle on which ever they come in to contact with first because it teaches them something new (MVC, testing, generators etc.) or does something better (plugins, templating etc). I used to develop with PHP and came in to contact with RubyOnRails. If I had have known about MVC before finding Rails I would more than likely never left PHP behind. But once I started using Ruby I enjoyed the syntax, features etc.  If I had have found Python and one of its MVC frameworks first I would more than likely be praising that language instead!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Python has a whole host of Rails-like frameworks. There are so many that a joke goes that during the typical talk at PyCon at least one web framework will see the light.  The argument that Rubys meta programming would make it better suited is IMO incorrect. You don't need metaprogramming for frameworks like this.  So I think we can conclude that Ruby are not better (and likely neither worse) than Python in this respect.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Because Rails is developed to take advantage of Rubys feature set.   A similarly gormless question would be \"Why is Python more suitable for Django than Ruby is?\".     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  I suppose we should not discuss the language features per se but rather the accents the respective communities make on the language features. For example, in Python, re-opening a class is perfectly possible but it is not common; in Ruby, however, re-opening a class is something of the daily practice. this allows for a quick and straightforward customization of the framework to the current requirement and renders Ruby more favorable for Rails-like frameworks than any other dynamic language. Hence my answer: common use of re-opening classes.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Some have said that the type of metaprogramming required to make ActiveRecord (a key component of rails) possible is easier and more natural to do in ruby than in python - I do not know python yet;), so i cannot personally confirm this statement.  I have used rails briefly, and its use of catchalls/interceptors and dynamic evaluation/code injection does allow you to operate at a much higher level of abstraction than some of the other frameworks (before its time).  I have little to no experience with Python's framework - but i've heard it's equally capable - and that the python community does a great job supporting and fostering pythonic endeavors.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  I think that the syntax is cleaner and Ruby, for me at least, is just a lot more \"enjoyable\"- as subjective as that is!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why is Ruby more suitable for Rails than Python? [closed]",
        "A_Content": "  Two answers :   a. Because rails was written for ruby.   b. For the same reason C more suitable for Linux than Ruby     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby-on-rails",
            "ruby",
            "web-frameworks"
        ],
        "URL": "https://stackoverflow.com/questions/1099305/why-is-ruby-more-suitable-for-rails-than-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Python and Ruby are usually considered to be close cousins (though with quite different historical baggage) with similar expressiveness and power. But some have argued that the immense success of the Rails framework really has a great deal to do with the language it is built on: Ruby itself. So why would Ruby be more suitable for such a framework than Python?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  I don't really see the need, as a module with functions (and not a class) would serve well as a singleton. All its variables would be bound to the module, which could not be instantiated repeatedly anyway.   If you do wish to use a class, there is no way of creating private classes or private constructors in Python, so you can't protect against multiple instantiations, other than just via convention in use of your API. I would still just put methods in a module, and consider the module as the singleton.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "313",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  Here's my own implementation of singletons. All you have to do is decorate the class; to get the singleton, you then have to use the Instance method. Here's an example:    @Singleton class Foo:    def __init__(self):        print 'Foo created'  f = Foo() # Error, this isn't how you get the instance of a singleton  f = Foo.instance() # Good. Being explicit is in line with the Python Zen g = Foo.instance() # Returns already created instance  print f is g # True   And here's the code:  class Singleton:     \"\"\"     A non-thread-safe helper class to ease implementing singletons.     This should be used as a decorator -- not a metaclass -- to the     class that should be a singleton.      The decorated class can define one `__init__` function that     takes only the `self` argument. Also, the decorated class cannot be     inherited from. Other than that, there are no restrictions that apply     to the decorated class.      To get the singleton instance, use the `instance` method. Trying     to use `__call__` will result in a `TypeError` being raised.      \"\"\"      def __init__(self, decorated):         self._decorated = decorated      def instance(self):         \"\"\"         Returns the singleton instance. Upon its first call, it creates a         new instance of the decorated class and calls its `__init__` method.         On all subsequent calls, the already created instance is returned.          \"\"\"         try:             return self._instance         except AttributeError:             self._instance = self._decorated()             return self._instance      def __call__(self):         raise TypeError('Singletons must be accessed through `instance()`.')      def __instancecheck__(self, inst):         return isinstance(inst, self._decorated)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "270",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  You can override the __new__ method like this:   class Singleton(object):     _instance = None     def __new__(cls, *args, **kwargs):         if not cls._instance:             cls._instance = super(Singleton, cls).__new__(                                 cls, *args, **kwargs)         return cls._instance   if __name__ == '__main__':     s1 = Singleton()     s2 = Singleton()     if (id(s1) == id(s2)):         print \"Same\"     else:         print \"Different\"      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "174",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  A slightly different approach to implement the singleton in Python is the borg pattern by Alex Martelli (Google employee and Python genius).  class Borg:     __shared_state = {}     def __init__(self):         self.__dict__ = self.__shared_state   So instead of forcing all instances to have the same identity, they share state.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "104",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  The module approach works well. If I absolutely need a singleton I prefer the Metaclass approach.  class Singleton(type):     def __init__(cls, name, bases, dict):         super(Singleton, cls).__init__(name, bases, dict)         cls.instance = None       def __call__(cls,*args,**kw):         if cls.instance is None:             cls.instance = super(Singleton, cls).__call__(*args, **kw)         return cls.instance  class MyClass(object):     __metaclass__ = Singleton      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  See this implementation from PEP318, implementing the singleton pattern with a decorator:  def singleton(cls):     instances = {}     def getinstance():         if cls not in instances:             instances[cls] = cls()         return instances[cls]     return getinstance  @singleton class MyClass:     ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  As the accepted answer says, the most idiomatic way is to just use a module.  With that in mind, here's a proof of concept:  def singleton(cls):     obj = cls()     # Always return the same object     cls.__new__ = staticmethod(lambda cls: obj)     # Disable __init__     try:         del cls.__init__     except AttributeError:         pass     return cls   See the Python data model for more details on __new__.  Example:  @singleton class Duck(object):     pass  if Duck() is Duck():     print \"It works!\" else:     print \"It doesn't work!\"   Notes:   You have to use new-style classes (derive from object) for this. The singleton is initialized when it is defined, rather than the first time it's used. This is just a toy example. I've never actually used this in production code, and don't plan to.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  The one time I wrote a singleton in Python I used a class where all the member functions had the classmethod decorator.  class foo:   x = 1    @classmethod   def increment(cls, y = 1):     cls.x += y      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  The Python documentation does cover this:  class Singleton(object):     def __new__(cls, *args, **kwds):         it = cls.__dict__.get(\"__it__\")         if it is not None:             return it         cls.__it__ = it = object.__new__(cls)         it.init(*args, **kwds)         return it     def init(self, *args, **kwds):         pass   I would probably rewrite it to look more like this:  class Singleton(object):     \"\"\"Use to create a singleton\"\"\"     def __new__(cls, *args, **kwds):         \"\"\"         >>> s = Singleton()         >>> p = Singleton()         >>> id(s) == id(p)         True         \"\"\"         self = \"__self__\"         if not hasattr(cls, self):             instance = object.__new__(cls)             instance.init(*args, **kwds)             setattr(cls, self, instance)         return getattr(cls, self)      def init(self, *args, **kwds):         pass   It should be relatively clean to extend this:  class Bus(Singleton):     def init(self, label=None, *args, **kwds):         self.label = label         self.channels = [Channel(\"system\"), Channel(\"app\")]         ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  I'm very unsure about this, but my project uses 'convention singletons' (not enforced singletons), that is, if I have a class called DataController, I define this in the same module:  _data_controller = None def GetDataController():     global _data_controller     if _data_controller is None:         _data_controller = DataController()     return _data_controller   It is not elegant, since it's a full six lines. But all my singletons use this pattern, and it's at least very explicit (which is pythonic).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  There are also some interesting articles on the Google Testing blog, discussing why singleton are/may be bad and are an anti-pattern:   Singletons are Pathological Liars Where Have All the Singletons Gone? Root Cause of Singletons      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  Creating a singleton decorator (aka an annotation) is an elegant way if you want to decorate (annotate) classes going forward. Then you just put @singleton before your class definition.   def singleton(cls):     instances = {}     def getinstance():         if cls not in instances:             instances[cls] = cls()         return instances[cls]     return getinstance  @singleton class MyClass:     ...      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  Here is an example from Peter Norvig's Python IAQ How do I do the Singleton Pattern in Python? (You should use search feature of your browser to find this question, there is no direct link, sorry)  Also Bruce Eckel has another example in his book Thinking in Python (again there is no direct link to the code)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  I think that forcing a class or an instance to be a singleton is overkill. Personally, I like to define a normal instantiable class, a semi-private reference, and a simple factory function.  class NothingSpecial:     pass  _the_one_and_only = None  def TheOneAndOnly():     global _the_one_and_only     if not _the_one_and_only:         _the_one_and_only = NothingSpecial()     return _the_one_and_only   Or if there is no issue with instantiating when the module is first imported:  class NothingSpecial:     pass  THE_ONE_AND_ONLY = NothingSpecial()   That way you can write tests against fresh instances without side effects, and there is no need for sprinkling the module with global statements, and if needed you can derive variants in the future.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  The Singleton Pattern implemented with Python courtesy of ActiveState.  It looks like the trick is to put the class that's supposed to only have one instance inside of another class.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  OK, singleton could be good or evil, I know. This is my implementation, and I simply extend a classic approach to introduce a cache inside and produce many instances of a different type or, many instances of same type, but with different arguments.  I called it Singleton_group, because it groups similar instances together and prevent that an object of the same class, with same arguments, could be created:  # Peppelinux's cached singleton class Singleton_group(object):     __instances_args_dict = {}     def __new__(cls, *args, **kwargs):         if not cls.__instances_args_dict.get((cls.__name__, args, str(kwargs))):             cls.__instances_args_dict[(cls.__name__, args, str(kwargs))] = super(Singleton_group, cls).__new__(cls, *args, **kwargs)         return cls.__instances_args_dict.get((cls.__name__, args, str(kwargs)))   # It's a dummy real world use example: class test(Singleton_group):     def __init__(self, salute):         self.salute = salute  a = test('bye') b = test('hi') c = test('bye') d = test('hi') e = test('goodbye') f = test('goodbye')  id(a) 3070148780L  id(b) 3070148908L  id(c) 3070148780L  b == d True   b._Singleton_group__instances_args_dict  {('test', ('bye',), '{}'): <__main__.test object at 0xb6fec0ac>,  ('test', ('goodbye',), '{}'): <__main__.test object at 0xb6fec32c>,  ('test', ('hi',), '{}'): <__main__.test object at 0xb6fec12c>}   Every object carries the singleton cache... This could be evil, but it works great for some :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  class Singleton(object[,...]):      staticVar1 = None     staticVar2 = None      def __init__(self):         if self.__class__.staticVar1==None :             # create class instance variable for instantiation of class             # assign class instance variable values to class static variables         else:             # assign class static variable values to class instance variables      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  My simple solution which is based on the default value of function parameters.  def getSystemContext(contextObjList=[]):     if len( contextObjList ) == 0:         contextObjList.append( Context() )         pass     return contextObjList[0]  class Context(object):     # Anything you want here      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  Being relatively new to Python I'm not sure what the most common idiom is, but the simplest thing I can think of is just using a module instead of a class. What would have been instance methods on your class become just functions in the module and any data just becomes variables in the module instead of members of the class. I suspect this is the pythonic approach to solving the type of problem that people use singletons for.  If you really want a singleton class, there's a reasonable implementation described on the first hit on Google for \"Python singleton\", specifically:  class Singleton:     __single = None     def __init__( self ):         if Singleton.__single:             raise Singleton.__single         Singleton.__single = self   That seems to do the trick.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  Singleton's half brother  I completely agree with staale and I leave here a sample of creating a singleton half brother:  class void:pass a = void(); a.__class__ = Singleton   a will report now as being of the same class as singleton even if it does not look like it. So singletons using complicated classes end up depending on we don't mess much with them.  Being so, we can have the same effect and use simpler things like a variable or a module. Still, if we want use classes for clarity and because in Python a class is an object, so we already have the object (not and instance, but it will do just like).  class Singleton:     def __new__(cls): raise AssertionError # Singletons can't have instances   There we have a nice assertion error if we try to create an instance, and we can store on derivations static members and make changes to them at runtime (I love Python). This object is as good as other about half brothers (you still can create them if you wish), however it will tend to run faster due to simplicity.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  class Singeltone(type):     instances = dict()      def __call__(cls, *args, **kwargs):         if cls.__name__ not in Singeltone.instances:                         Singeltone.instances[cls.__name__] = type.__call__(cls, *args, **kwargs)         return Singeltone.instances[cls.__name__]   class Test(object):     __metaclass__ = Singeltone   inst0 = Test() inst1 = Test() print(id(inst1) == id(inst0))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "Is there a simple, elegant way to define singletons? [duplicate]",
        "A_Content": "  In cases where you don't want the metaclass-based solution above, and you don't like the simple function decorator-based approach (e.g. because in that case static methods on the singleton class won't work), this compromise works:  class singleton(object):   \"\"\"Singleton decorator.\"\"\"    def __init__(self, cls):       self.__dict__['cls'] = cls    instances = {}    def __call__(self):       if self.cls not in self.instances:           self.instances[self.cls] = self.cls()       return self.instances[self.cls]    def __getattr__(self, attr):       return getattr(self.__dict__['cls'], attr)    def __setattr__(self, attr, value):       return setattr(self.__dict__['cls'], attr, value)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "design-patterns",
            "singleton"
        ],
        "URL": "https://stackoverflow.com/questions/31875/is-there-a-simple-elegant-way-to-define-singletons",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Creating a singleton in Python                                        18 answers                                          There seem to be many ways to define singletons in Python. Is there a consensus opinion on Stack Overflow?     ",
        "Q_Votes": "379"
    },
    {
        "Q_Title": "What is this odd Python colon behavior doing?",
        "A_Content": "  You have accidentally written a syntactically correct variable annotation. That feature was introduced in Python 3.6 (see PEP 526).  Although a variable annotation is parsed as part of an annotated assignment, the assignment statement is optional:  annotated_assignment_stmt ::=  augtarget \":\" expression [\"=\" expression]   Thus, in context[\"a\"]: 2   context[\"a\"] is the annotation target 2 is the annotation itself context[\"a\"] is left uninitialised   The PEP states that \"the target of the annotation can be any valid single assignment target, at least syntactically (it is up to the type checker what to do with this)\", which means that the key doesn't need to exist to be annotated (hence no KeyError). Here's an example from the original PEP:  d = {} d['a']: int = 0  # Annotates d['a'] with int. d['b']: int      # Annotates d['b'] with int.   Normally, the annotation expression should evaluate to a Python type --  after all the main use of annotations is type hinting, but it is not enforced. The annotation can be any valid Python expression, regardless of the type or value of the result.  As you can see, at this time type hints are very permissive and rarely useful, unless you have a static type checker such as mypy.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/48323493/what-is-this-odd-python-colon-behavior-doing",
        "A_Votes": "80",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am using Python 3.6.1, and I have come across something very strange. I had a simple dictionary assignment typo that took me a long time to find.  context = {} context[\"a\"]: 2 print(context)   Output  {}   What is the code context[\"a\"]: 2 doing? It doesn't raise a SyntaxError when it should IMO. At first I thought it was creating a slice. However, typing repr(context[\"a\"]: 2) raises a SyntaxError. I also typed context[\"a\"]: 2 in the console and the console didn't print anything. I thought maybe it returned None, but I'm not so sure.  I've also thought it could be a single line if statement, but that shouldn't be the right syntax either.  Additionally, context[\"a\"] should raise a KeyError.  I am perplexed. What is going on?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to compile python script to binary executable",
        "A_Content": "  Or use PyInstaller as an alternative to py2exe. Here is a good starting point. PyInstaller let's you also create executables for linux and mac...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "compilation",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable",
        "A_Votes": "47",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to convert a Python script to a Windows executable.  I have Python 2.6 installed to python26.  I have created one script and kept it in C:\\pythonscript. Inside this folder there are two files  Setup.py and oldlogs.py (this file need coversion)  setup.py code is  from distutils.core import setup import py2exe  setup(console=['oldlogs.py'])   How can I convert oldlogs.py to an exe file?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to compile python script to binary executable",
        "A_Content": "  You'll need py2exe. Read a Tutorial.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "compilation",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to convert a Python script to a Windows executable.  I have Python 2.6 installed to python26.  I have created one script and kept it in C:\\pythonscript. Inside this folder there are two files  Setup.py and oldlogs.py (this file need coversion)  setup.py code is  from distutils.core import setup import py2exe  setup(console=['oldlogs.py'])   How can I convert oldlogs.py to an exe file?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to compile python script to binary executable",
        "A_Content": "  I've created a presentation that gathers the process from compiling your python sources to package them for every platform (last slide contain links to more detailed instructions)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "compilation",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to convert a Python script to a Windows executable.  I have Python 2.6 installed to python26.  I have created one script and kept it in C:\\pythonscript. Inside this folder there are two files  Setup.py and oldlogs.py (this file need coversion)  setup.py code is  from distutils.core import setup import py2exe  setup(console=['oldlogs.py'])   How can I convert oldlogs.py to an exe file?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to compile python script to binary executable",
        "A_Content": "  I recommend PyInstaller, a simple python script can be converted to an exe with the following commands:  utils/Makespec.py [--onefile] oldlogs.py   which creates a yourprogram.spec file which is a configuration for building the final exe. Next command builds the exe from the configuration file:  utils/Build.py oldlogs.spec   More can be found here     ",
        "Language": "Python",
        "Tags": [
            "python",
            "compilation",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to convert a Python script to a Windows executable.  I have Python 2.6 installed to python26.  I have created one script and kept it in C:\\pythonscript. Inside this folder there are two files  Setup.py and oldlogs.py (this file need coversion)  setup.py code is  from distutils.core import setup import py2exe  setup(console=['oldlogs.py'])   How can I convert oldlogs.py to an exe file?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to compile python script to binary executable",
        "A_Content": "  For completeness, cx_Freeze is another tool that you can use for this (along with PyInstaller and py2exe, which other answers have already mentioned).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "compilation",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I need to convert a Python script to a Windows executable.  I have Python 2.6 installed to python26.  I have created one script and kept it in C:\\pythonscript. Inside this folder there are two files  Setup.py and oldlogs.py (this file need coversion)  setup.py code is  from distutils.core import setup import py2exe  setup(console=['oldlogs.py'])   How can I convert oldlogs.py to an exe file?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "NumPy or Pandas: Keeping array type as integer while having a NaN value",
        "A_Content": "  NaN can't be stored in an integer array. This is a known limitation of pandas at the moment; I have been waiting for progress to be made with NA values in NumPy (similar to NAs in R), but it will be at least 6 months to a year before NumPy gets these features, it seems:  http://pandas.pydata.org/pandas-docs/stable/gotchas.html#support-for-integer-na  (Note that it has been added but as a new feature only in the development version (so far): http://pandas-docs.github.io/pandas-docs-travis/whatsnew.html#optional-integer-na-support )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "int",
            "pandas",
            "type-conversion"
        ],
        "URL": "https://stackoverflow.com/questions/11548005/numpy-or-pandas-keeping-array-type-as-integer-while-having-a-nan-value",
        "A_Votes": "77",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a preferred way to keep the data type of a numpy array fixed as int (or int64 or whatever), while still having an element inside listed as numpy.NaN?  In particular, I am converting an in-house data structure to a Pandas DataFrame. In our structure, we have integer-type columns that still have NaN's (but the dtype of the column is int). It seems to recast everything as a float if we make this a DataFrame, but we'd really like to be int.  Thoughts?  Things tried:  I tried using the from_records() function under pandas.DataFrame, with coerce_float=False and this did not help. I also tried using NumPy masked arrays, with NaN fill_value, which also did not work. All of these caused the column data type to become a float.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "NumPy or Pandas: Keeping array type as integer while having a NaN value",
        "A_Content": "  If performance is not the main issue, you can store strings instead.  df.col = df.col.dropna().apply(lambda x: str(int(x)) )   Then you can mix then with NaN as much as you want. If you really want to have integers, depending on your application, you can use -1, or 0, or 1234567890, or some other dedicated value to represent NaN.   You can also temporarily duplicate the columns: one as you have, with floats; the other one experimental, with ints or strings. Then inserts asserts in every reasonable place checking that the two are in sync. After enough testing you can let go of the floats.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "int",
            "pandas",
            "type-conversion"
        ],
        "URL": "https://stackoverflow.com/questions/11548005/numpy-or-pandas-keeping-array-type-as-integer-while-having-a-nan-value",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a preferred way to keep the data type of a numpy array fixed as int (or int64 or whatever), while still having an element inside listed as numpy.NaN?  In particular, I am converting an in-house data structure to a Pandas DataFrame. In our structure, we have integer-type columns that still have NaN's (but the dtype of the column is int). It seems to recast everything as a float if we make this a DataFrame, but we'd really like to be int.  Thoughts?  Things tried:  I tried using the from_records() function under pandas.DataFrame, with coerce_float=False and this did not help. I also tried using NumPy masked arrays, with NaN fill_value, which also did not work. All of these caused the column data type to become a float.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What does a . in an import statement in Python mean?",
        "A_Content": "  That's the new syntax for explicit relative imports. It means import from the current package.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "module"
        ],
        "URL": "https://stackoverflow.com/questions/7279810/what-does-a-in-an-import-statement-in-python-mean",
        "A_Votes": "81",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm looking over the code for Python's multiprocessing module, and it contains this line:  from ._multiprocessing import win32, Connection, PipeConnection   instead of  from _multiprocessing import win32, Connection, PipeConnection   the subtle difference being the period before _multiprocessing. What does that mean? Why the period?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What does a . in an import statement in Python mean?",
        "A_Content": "  The dot in the module name is used for relative module import (see here and here,  section 6.4.2).   You can use more than one dot, referring not to the curent package but its parent(s). This should only be used within packages, in the main module one should always use absolute module names.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "module"
        ],
        "URL": "https://stackoverflow.com/questions/7279810/what-does-a-in-an-import-statement-in-python-mean",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm looking over the code for Python's multiprocessing module, and it contains this line:  from ._multiprocessing import win32, Connection, PipeConnection   instead of  from _multiprocessing import win32, Connection, PipeConnection   the subtle difference being the period before _multiprocessing. What does that mean? Why the period?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "NumPy or Pandas: Keeping array type as integer while having a NaN value",
        "A_Content": "  This is not a solution for all cases, but mine (genomic coordinates) I've resorted to using 0 as NaN  a3['MapInfo'] = a3['MapInfo'].fillna(0).astype(int)   This at least allows for the proper 'native' column type to be used, operations like subtraction, comparison etc work as expected     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "int",
            "pandas",
            "type-conversion"
        ],
        "URL": "https://stackoverflow.com/questions/11548005/numpy-or-pandas-keeping-array-type-as-integer-while-having-a-nan-value",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a preferred way to keep the data type of a numpy array fixed as int (or int64 or whatever), while still having an element inside listed as numpy.NaN?  In particular, I am converting an in-house data structure to a Pandas DataFrame. In our structure, we have integer-type columns that still have NaN's (but the dtype of the column is int). It seems to recast everything as a float if we make this a DataFrame, but we'd really like to be int.  Thoughts?  Things tried:  I tried using the from_records() function under pandas.DataFrame, with coerce_float=False and this did not help. I also tried using NumPy masked arrays, with NaN fill_value, which also did not work. All of these caused the column data type to become a float.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "NumPy or Pandas: Keeping array type as integer while having a NaN value",
        "A_Content": "  This capability has been added to the latest beta of pandas: http://pandas-docs.github.io/pandas-docs-travis/whatsnew.html#optional-integer-na-support     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "int",
            "pandas",
            "type-conversion"
        ],
        "URL": "https://stackoverflow.com/questions/11548005/numpy-or-pandas-keeping-array-type-as-integer-while-having-a-nan-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a preferred way to keep the data type of a numpy array fixed as int (or int64 or whatever), while still having an element inside listed as numpy.NaN?  In particular, I am converting an in-house data structure to a Pandas DataFrame. In our structure, we have integer-type columns that still have NaN's (but the dtype of the column is int). It seems to recast everything as a float if we make this a DataFrame, but we'd really like to be int.  Thoughts?  Things tried:  I tried using the from_records() function under pandas.DataFrame, with coerce_float=False and this did not help. I also tried using NumPy masked arrays, with NaN fill_value, which also did not work. All of these caused the column data type to become a float.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  AFAIK, len is special in this respect and has historical roots.  Here's a quote from the FAQ:     Why does Python use methods for some   functionality (e.g. list.index()) but   functions for other (e.g. len(list))?      The major reason is history. Functions   were used for those operations that   were generic for a group of types and   which were intended to work even for   objects that didn’t have methods at   all (e.g. tuples). It is also   convenient to have a function that can   readily be applied to an amorphous   collection of objects when you use the   functional features of Python (map(),   apply() et al).      In fact, implementing len(), max(),   min() as a built-in function is   actually less code than implementing   them as methods for each type. One can   quibble about individual cases but   it’s a part of Python, and it’s too   late to make such fundamental changes   now. The functions have to remain to   avoid massive code breakage.   The other \"magical methods\" (actually called special method in the Python folklore) make lots of sense, and similar functionality exists in other languages. They're mostly used for code that gets called implicitly when special syntax is used.  For example:   overloaded operators (exist in C++ and others) constructor/destructor hooks for accessing attributes tools for metaprogramming   and so on...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "59",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  From the Zen of Python:     In the face of ambiguity, refuse the temptation to guess.      There should be one-- and preferably only one --obvious way to do it.   This is one of the reasons - with custom methods, developers would be free to choose a different method name, like getLength(), length(), getlength() or whatsoever. Python enforces strict naming so that the common function len() can be used.  All operations that are common for many types of objects are put into magic methods, like __nonzero__, __len__ or __repr__. They are mostly optional, though.  Operator overloading is also done with magic methods (e.g. __le__), so it makes sense to use them for other common operations, too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  Python uses the word \"magic methods\", because those methods really performs magic for you program. One of the biggest advantages of using Python's magic methods is that they provide a simple way to make objects behave like built-in types. That means you can avoid ugly, counter-intuitive, and nonstandard ways of performing basic operators.  Consider a following example:  dict1 = {1 : \"ABC\"} dict2 = {2 : \"EFG\"}  dict1 + dict2 Traceback (most recent call last):   File \"python\", line 1, in <module> TypeError: unsupported operand type(s) for +: 'dict' and 'dict'   This gives an error, because the dictionary type doesn't support addition. Now, let's extend dictionary class and add \"__add__\" magic method:  class AddableDict(dict):      def __add__(self, otherObj):         self.update(otherObj)         return AddableDict(self)   dict1 = AddableDict({1 : \"ABC\"}) dict2 = AddableDict({2 : \"EFG\"})  print (dict1 + dict2)   Now, it gives following output.  {1: 'ABC', 2: 'EFG'}   Thus, by adding this method, suddenly magic has happened and the error you were getting earlier, has gone away.  I hope, it makes things clear to you. For more information, refer to:  A Guide to Python's Magic Methods (Rafe Kettler, 2012)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  Some of these functions do more than a single method would be able to implement (without abstract methods on a superclass).  For instance bool() acts kind of like this:  def bool(obj):     if hasattr(obj, '__nonzero__'):         return bool(obj.__nonzero__())     elif hasattr(obj, '__len__'):         if obj.__len__():             return True         else:             return False     return True   You can also be 100% sure that bool() will always return True or False; if you relied on a method you couldn't be entirely sure what you'd get back.  Some other functions that have relatively complicated implementations (more complicated than the underlying magic methods are likely to be) are iter() and cmp(), and all the attribute methods (getattr, setattr and delattr).  Things like int also access magic methods when doing coercion (you can implement __int__), but do double duty as types.  len(obj) is actually the one case where I don't believe it's ever different from obj.__len__().     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  They are not really \"magic names\". It's just the interface an object has to implement to provide a given service. In this sense, they are not more magic than any predefined interface definition you have to reimplement.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  While the reason is mostly historic, there are some peculiarities in Python's len that make the use of a function instead of a method appropriate.   Some operations in Python are implemented as methods, for example list.index and dict.append, while others are implemented as callables and magic methods, for example str and iter and reversed. The two groups differ enough so the different approach is justified:   They are common. str, int and friends are types. It makes more sense to call the constructor. The implementation differs from the function call. For example, iter might call __getitem__ if __iter__ isn't available, and supports additional arguments that don't fit in a method call. For the same reason it.next() has been changed to next(it) in recent versions of Python - it makes more sense. Some of these are close relatives of operators. There's syntax for calling __iter__ and __next__ - it's called the for loop. For consistency, a function is better. And it makes it better for certain optimisations. Some of the functions are simply way too similar to the rest in some way - repr acts like str does. Having str(x) versus x.repr() would be confusing. Some of them rarely use the actual implementation method, for example isinstance. Some of them are actual operators, getattr(x, 'a') is another way of doing x.a and getattr shares many of the aforementioned qualities.   I personally call the first group method-like and the second group operator-like. It's not a very good distinction, but I hope it helps somehow.  Having said this, len doesn't exactly fit in the second group. It's more close to the operations in the first one, with the only difference that it's way more common than almost any of them. But the only thing that it does is calling __len__, and it's very close to L.index. However, there are some differences. For example, __len__ might be called for the implementation of other features, such as bool, if the method was called len you might break bool(x) with custom len method that does completely different thing.  In short, you have a set of very common features that classes might implement that might be accessed through an operator, through a special function (that usually does more than the implementation, as an operator would), during object construction, and all of them share some common traits. All the rest is a method. And len is somewhat of an exception to that rule.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why does Python use 'magic methods'?",
        "A_Content": "  There is not a lot to add to the above two posts, but all the \"magic\" functions are not really magic at all. They are part of the __ builtins__ module which is implicitly/automatically imported when the interpreter starts. I.e.:  from __builtins__ import *   happens every time before your program starts.  I always thought it would be more correct if Python only did this for the interactive shell, and required scripts to import the various parts from builtins they needed. Also probably different __ main__ handling would be nice in shells vs interactive. Anyway, check out all the functions, and see what it is like without them:  dir (__builtins__) ... del __builtins__      ",
        "Language": "Python",
        "Tags": [
            "python",
            "magic-methods"
        ],
        "URL": "https://stackoverflow.com/questions/2657627/why-does-python-use-magic-methods",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been playing around with Python recently, and one thing I'm finding a bit odd is the extensive use of 'magic methods', e.g. to make its length available, an object implements a method, def __len__(self), and then it is called when you write len(obj).  I was just wondering why objects don't simply define a len(self) method and have it called directly as a member of the object, e.g. obj.len()? I'm sure there must be good reasons for Python doing it the way it does, but as a newbie I haven't worked out what they are yet.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is parenthesis in print voluntary in Python 2.7?",
        "A_Content": "  In Python 2.x print is actually a special statement and not a function*.  This is also why it can't be used like: lambda x: print x  Note that (expr) does not create a Tuple (it results in expr), but , does. This likely results in the confusion between print (x) and print (x, y) in Python 2.7  (1)   # 1 -- no tuple Mister! (1,)  # (1) (1,2) # (1,2) 1,2   # 1 2 -- no tuple and no parenthesis :) [See below for print caveat.]   However, since print is a special syntax statement/grammar construct in Python 2.x then, without the parenthesis, it treats the ,'s in a special manner - and does not create a Tuple. This special treatment of the print statement enables it to act differently if there is a trailing , or not.  Happy coding.    *This print behavior in Python 2 can be changed to that of Python 3:  from __future__ import print_function      ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/6182964/why-is-parenthesis-in-print-voluntary-in-python-2-7",
        "A_Votes": "96",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    In Python 2.7 both the following will do the same  print(\"Hello, World!\") # Prints \"Hello, World!\"  print \"Hello, World!\" # Prints \"Hello, World!\"   However the following will not  print(\"Hello,\", \"World!\") # Prints the tuple: (\"Hello,\", \"World!\")  print \"Hello,\", \"World!\" # Prints the words \"Hello, World!\"   In Python 3.x parenthesis on print is mandatory, essentially making it a function, but in 2.7 both will work with differing results. What else should I know about print in Python 2.7?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is parenthesis in print voluntary in Python 2.7?",
        "A_Content": "  Here we have interesting side effect when it comes to UTF-8.  >> greek = dict( dog=\"σκύλος\", cat=\"γάτα\" ) >> print greek['dog'], greek['cat'] σκύλος γάτα >> print (greek['dog'], greek['cat']) ('\\xcf\\x83\\xce\\xba\\xcf\\x8d\\xce\\xbb\\xce\\xbf\\xcf\\x82', '\\xce\\xb3\\xce\\xac\\xcf\\x84\\xce\\xb1')   The last print is tuple with hexadecimal byte values.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/6182964/why-is-parenthesis-in-print-voluntary-in-python-2-7",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python 2.7 both the following will do the same  print(\"Hello, World!\") # Prints \"Hello, World!\"  print \"Hello, World!\" # Prints \"Hello, World!\"   However the following will not  print(\"Hello,\", \"World!\") # Prints the tuple: (\"Hello,\", \"World!\")  print \"Hello,\", \"World!\" # Prints the words \"Hello, World!\"   In Python 3.x parenthesis on print is mandatory, essentially making it a function, but in 2.7 both will work with differing results. What else should I know about print in Python 2.7?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is parenthesis in print voluntary in Python 2.7?",
        "A_Content": "  Basically in Python before Python 3, print was a special statement that printed all the strings if got as arguments.  So print \"foo\",\"bar\" simply meant \"print 'foo' followed by 'bar'\".  The problem with that was it was tempting to act as if print were a function, and the Python grammar is ambiguous on that, since (a,b) is a tuple containing a and b but foo(a,b) is a call to a function of two arguments.  So they made the incompatible change for 3 to make programs less ambiguous and more regular.  (Actually, I think 2.7 behaves as 2.6 did on this, but I'm not certain.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/6182964/why-is-parenthesis-in-print-voluntary-in-python-2-7",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python 2.7 both the following will do the same  print(\"Hello, World!\") # Prints \"Hello, World!\"  print \"Hello, World!\" # Prints \"Hello, World!\"   However the following will not  print(\"Hello,\", \"World!\") # Prints the tuple: (\"Hello,\", \"World!\")  print \"Hello,\", \"World!\" # Prints the words \"Hello, World!\"   In Python 3.x parenthesis on print is mandatory, essentially making it a function, but in 2.7 both will work with differing results. What else should I know about print in Python 2.7?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is parenthesis in print voluntary in Python 2.7?",
        "A_Content": "  It's all very simple and has nothing to do with forward or backward compatibility.  The general form for the print statement in all Python versions before version 3 is:  print expr1, expr2, ... exprn   (Each expression in turn is evaluated, converted to a string and displayed with a space between them.)  But remember that putting parentheses around an expression is still the same expression.  So you can also write this as:  print (expr1), (expr2), ... (expr3)   This has nothing to do with calling a function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "printing",
            "python-3.x",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/6182964/why-is-parenthesis-in-print-voluntary-in-python-2-7",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In Python 2.7 both the following will do the same  print(\"Hello, World!\") # Prints \"Hello, World!\"  print \"Hello, World!\" # Prints \"Hello, World!\"   However the following will not  print(\"Hello,\", \"World!\") # Prints the tuple: (\"Hello,\", \"World!\")  print \"Hello,\", \"World!\" # Prints the words \"Hello, World!\"   In Python 3.x parenthesis on print is mandatory, essentially making it a function, but in 2.7 both will work with differing results. What else should I know about print in Python 2.7?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  Some thoughts:  class Model(model.Model):     _image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()      def set_image(self, val):         self._image = val         self._image_changed = True          # Or put whole logic in here         small = rescale_image(self.image,width=100,height=100)         self.image_small=SimpleUploadedFile(name,small_pic)      def get_image(self):         return self._image      image = property(get_image, set_image)      # this is not needed if small_image is created at set_image     def save(self, *args, **kwargs):         if getattr(self, '_image_changed', True):             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   Not sure if it would play nice with all pseudo-auto django tools (Example: ModelForm, contrib.admin etc).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "98",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  Check the model's pk field.  If it is None, then it is a new object.  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if 'form' in kwargs:             form=kwargs['form']         else:             form=None          if self.pk is None and form is not None and 'image' in form.changed_data:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   Edit: I've added a check for 'image' in form.changed_data.  This assumes that you're using the admin site to update your images.  You'll also have to override the default save_model method as indicated below.  class ModelAdmin(admin.ModelAdmin):     def save_model(self, request, obj, form, change):         obj.save(form=form)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  You may supply extra argument for confirming a new image is posted. Something like:  def save(self, new_image=False, *args, **kwargs):     if new_image:         small=rescale_image(self.image,width=100,height=100)         self.image_small=SimpleUploadedFile(name,small_pic)     super(Model, self).save(*args, **kwargs)   or pass request variable  def save(self, request=False, *args, **kwargs):     if request and request.FILES.get('image',False):         small=rescale_image(self.image,width=100,height=100)         self.image_small=SimpleUploadedFile(name,small_pic)     super(Model, self).save(*args, **kwargs)   I think these wont break your save when called simply.  You may put this in your admin.py so that this work with admin site too (for second of above solutions):  class ModelAdmin(admin.ModelAdmin):      ....     def save_model(self, request, obj, form, change):          instance = form.save(commit=False)         instance.save(request=request)         return instance      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  What I did to achieve the goal was to make this..  # I added an extra_command argument that defaults to blank def save(self, extra_command=\"\", *args, **kwargs):   and below the save() method is this..  # override the save method to create an image thumbnail if self.image and extra_command != \"skip creating photo thumbnail\":     # your logic here   so when i edit some fields but not editing the image, I put this..  Model.save(\"skip creating photo thumbnail\")   you can replace the \"skip creating photo thumbnail\" with \"im just editing the description\" or a more formal text.  Hope this one helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  Query the database for an existing record with the same PK. Compare the file sizes and checksums of the new and existing images to see if they're the same.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  In new version it is like this:    def validate(self, attrs):     has_unknown_fields = set(self.initial_data) - set(self.fields.keys())     if has_unknown_fields:         raise serializers.ValidationError(\"Do not send extra fields\")     return attrs      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Django. Override save for model",
        "A_Content": "  I have found one another simple way to store the data into the database  models.py  class LinkModel(models.Model):     link = models.CharField(max_length=500)     shortLink = models.CharField(max_length=30,unique=True)   In database I have only 2 variables  views.py  class HomeView(TemplateView):     def post(self,request, *args, **kwargs):         form = LinkForm(request.POST)          if form.is_valid():             text = form.cleaned_data['link'] # text for link          dbobj = LinkModel()         dbobj.link = text         self.no = self.gen.generateShortLink() # no for shortLink         dbobj.shortLink = str(self.no)         dbobj.save()         # Saving from views.py   In this I have created the instance of model in views.py only and putting/saving data into 2 variables from views only.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/4269605/django-override-save-for-model",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Before saving model I'm re-size a picture. But how can I check if new picture added or just description updated, so I can skip rescaling every time the model is saved?  class Model(model.Model):     image=models.ImageField(upload_to='folder')     thumb=models.ImageField(upload_to='folder')     description=models.CharField()       def save(self, *args, **kwargs):         if self.image:             small=rescale_image(self.image,width=100,height=100)             self.image_small=SimpleUploadedFile(name,small_pic)         super(Model, self).save(*args, **kwargs)   I want to rescale only if new image loaded or image updated, but not when description updated.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python - abs vs fabs",
        "A_Content": "  math.fabs() converts its argument to float if it can (if it can't, it throws an exception). It then takes the absolute value, and returns the result as a float.  In addition to floats, abs() also works with integers and complex numbers. Its return type depends on the type of its argument.  In [7]: type(abs(-2)) Out[7]: int  In [8]: type(abs(-2.0)) Out[8]: float  In [9]: type(abs(3+4j)) Out[9]: float  In [10]: type(math.fabs(-2)) Out[10]: float  In [11]: type(math.fabs(-2.0)) Out[11]: float  In [12]: type(math.fabs(3+4j)) --------------------------------------------------------------------------- TypeError                                 Traceback (most recent call last) /home/alexei/<ipython-input-12-8368761369da> in <module>() ----> 1 type(math.fabs(3+4j))  TypeError: can't convert complex to float      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10772302/python-abs-vs-fabs",
        "A_Votes": "113",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I noticed that in python there are two similar looking methods for finding the absolute value of a number:  First  abs(-5)   Second  import math math.fabs(-5)   How do these methods differ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python - abs vs fabs",
        "A_Content": "  Edit: as @aix suggested, a better (more fair) way to compare the speed difference:   In [1]: %timeit abs(5) 10000000 loops, best of 3: 86.5 ns per loop  In [2]: from math import fabs  In [3]: %timeit fabs(5) 10000000 loops, best of 3: 115 ns per loop  In [4]: %timeit abs(-5) 10000000 loops, best of 3: 88.3 ns per loop  In [5]: %timeit fabs(-5) 10000000 loops, best of 3: 114 ns per loop  In [6]: %timeit abs(5.0) 10000000 loops, best of 3: 92.5 ns per loop  In [7]: %timeit fabs(5.0) 10000000 loops, best of 3: 93.2 ns per loop  In [8]: %timeit abs(-5.0) 10000000 loops, best of 3: 91.8 ns per loop  In [9]: %timeit fabs(-5.0) 10000000 loops, best of 3: 91 ns per loop   So it seems abs() only has slight speed advantage over fabs() for integers. For floats, abs() and fabs() demonstrate similar speed.    In addition to what @aix has said, one more thing to consider is the speed difference:   In [1]: %timeit abs(-5) 10000000 loops, best of 3: 102 ns per loop  In [2]: import math  In [3]: %timeit math.fabs(-5) 10000000 loops, best of 3: 194 ns per loop   So abs() is faster than math.fabs().     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10772302/python-abs-vs-fabs",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I noticed that in python there are two similar looking methods for finding the absolute value of a number:  First  abs(-5)   Second  import math math.fabs(-5)   How do these methods differ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python - abs vs fabs",
        "A_Content": "  math.fabs() always returns float, while abs() may return integer.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10772302/python-abs-vs-fabs",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I noticed that in python there are two similar looking methods for finding the absolute value of a number:  First  abs(-5)   Second  import math math.fabs(-5)   How do these methods differ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python - abs vs fabs",
        "A_Content": "  abs() :  Returns the absolute value as per the argument i.e. if argument is int then it returns int, if argument is float it returns float.  Also it works on complex variable also i.e. abs(a+bj) also works and returns absolute value i.e.\"math.sqrt(((a)**2)+((b)**2)\"  math.fabs() :  It only works on the integer or float values. Always returns the absolute float value no matter what is the argument type(except for the complex numbers).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/10772302/python-abs-vs-fabs",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I noticed that in python there are two similar looking methods for finding the absolute value of a number:  First  abs(-5)   Second  import math math.fabs(-5)   How do these methods differ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  This is to do with the encoding of your terminal not being set to UTF-8.  Here is my terminal  $ echo $LANG en_GB.UTF-8 $ python Python 2.7.3 (default, Apr 20 2012, 22:39:59)  [GCC 4.6.3] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 (｡･ω･｡)ﾉ >>>    On my terminal the example works with the above, but if I get rid of the LANG setting then it won't work  $ unset LANG $ python Python 2.7.3 (default, Apr 20 2012, 22:39:59)  [GCC 4.6.3] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128) >>>    Consult the docs for your linux variant to discover how to make this change permanent.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "67",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  try:  string.decode('utf-8')  # or: unicode(string, 'utf-8')   edit:  '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89'.decode('utf-8') gives u'(\\uff61\\uff65\\u03c9\\uff65\\uff61)\\uff89', which is correct.  so your problem must be at some oter place, possibly if you try to do something with it were there is an implicit conversion going on (could be printing, writing to a stream...)  to say more we'll need to see some code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  My +1 to mata's comment at https://stackoverflow.com/a/10561979/1346705 and to the Nick Craig-Wood's demonstration.  You have decoded the string correctly.  The problem is with the print command as it converts the Unicode string to the console encoding, and the console is not capable to display the string.  Try to write the string into a file and look at the result using some decent editor that supports Unicode:  import codecs  s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' s1 = s.decode('utf-8') f = codecs.open('out.txt', 'w', encoding='utf-8') f.write(s1) f.close()   Then you will see (｡･ω･｡)ﾉ.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  If you are working on a remote host, look at /etc/ssh/ssh_config on your local PC.  When this file contains a line:  SendEnv LANG LC_*   comment it out with adding # at the head of line. It might help.  With this line, ssh sends language related environment variables of your PC to the remote host. It causes a lot of problems.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  No problems with my terminal. The above answers helped me looking in the right directions but it didn't work for me until I added 'ignore':  fix_encoding = lambda s: s.decode('utf8', 'ignore')   As indicated in the comment below, this may lead to undesired results. OTOH it also may just do the trick well enough to get things working and you don't care about losing some characters.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  Try setting the system default encoding as utf-8 at the start of the script, so that all strings are encoded using that.  import sys reload(sys) sys.setdefaultencoding('utf-8')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  It looks like your string is encoded to utf-8, so what exactly is the problem?  Or what are you trying to do here..?  Python 2.7.3 (default, Apr 20 2012, 22:39:59)  [GCC 4.6.3] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 (｡･ω･｡)ﾉ >>> s2 = u'(｡･ω･｡)ﾉ' >>> s2 == s1 True >>> s2 u'(\\uff61\\uff65\\u03c9\\uff65\\uff61)\\uff89'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  this works for ubuntu 15.10:  sudo locale-gen \"en_US.UTF-8\" sudo dpkg-reconfigure locales      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  In my case, it was caused by my Unicode file being saved with a \"BOM\". To solve this, I cracked open the file using BBEdit and did a \"Save as...\" choosing for encoding \"Unicode (UTF-8)\" and not what it came with which was \"Unicode (UTF-8, with BOM)\"     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  I was getting the same type of error, and I found that the console is not capable of displaying the string in another language. Hence I made the below code changes to set default_charset as UTF-8.   data_head = [('\\x81\\xa1\\x8fo\\x89\\xef\\x82\\xa2\\x95\\xdb\\x8f\\xd8\\x90\\xa7\\x93x\\x81\\xcb3\\x8c\\x8e\\x8cp\\x91\\xb1\\x92\\x86(\\x81\\x86\\x81\\xde\\x81\\x85)\\x81\\xa1\\x8f\\x89\\x89\\xf1\\x88\\xc8\\x8aO\\x81A\\x82\\xa8\\x8b\\xe0\\x82\\xcc\\x90S\\x94z\\x82\\xcd\\x88\\xea\\x90\\xd8\\x95s\\x97v\\x81\\xa1\\x83}\\x83b\\x83v\\x82\\xcc\\x82\\xa8\\x8e\\x8e\\x82\\xb5\\x95\\xdb\\x8c\\xaf\\x82\\xc5\\x8fo\\x89\\xef\\x82\\xa2\\x8am\\x92\\xe8\\x81\\xa1', 'shift_jis')] default_charset = 'UTF-8' #can also try 'ascii' or other unicode type print ''.join([ unicode(lin[0], lin[1] or default_charset) for lin in data_head ])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  It's fine to use the below code in the top of your script as Andrei Krasutski suggested.  import sys reload(sys) sys.setdefaultencoding('utf-8')   But I will suggest you to also add # -*- coding: utf-8 -* line at very top of the script.  Omitting it throws below error in my case when I try to execute basic.py.  $ python basic.py   File \"01_basic.py\", line 14 SyntaxError: Non-ASCII character '\\xd9' in file basic.py on line 14, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details   The following is the code present in basic.py which throws above error.  code with error  from pylatex import Document, Section, Subsection, Command, Package from pylatex.utils import italic, NoEscape  import sys reload(sys) sys.setdefaultencoding('utf-8')  def fill_document(doc):     with doc.create(Section('ِش سثؤفهخى')):         doc.append('إخع ساخعمي شمصشغس سحثشن فاث فقعفا')         doc.append(italic('فشمهؤ ؤخىفثىفس شقث شمسخ ىهؤث'))          with doc.create(Subsection('آثص ٍعلاسثؤفهخى')):             doc.append('بشةخعس ؤقشئغ ؤاشقشؤفثقس: $&#{}')   if __name__ == '__main__':     # Basic document     doc = Document('basic')     fill_document(doc)   Then I added # -*- coding: utf-8 -*- line at very top and executed. It worked.  code without error  # -*- coding: utf-8 -*- from pylatex import Document, Section, Subsection, Command, Package from pylatex.utils import italic, NoEscape  import sys reload(sys) sys.setdefaultencoding('utf-8')  def fill_document(doc):     with doc.create(Section('ِش سثؤفهخى')):         doc.append('إخع ساخعمي شمصشغس سحثشن فاث فقعفا')         doc.append(italic('فشمهؤ ؤخىفثىفس شقث شمسخ ىهؤث'))          with doc.create(Subsection('آثص ٍعلاسثؤفهخى')):             doc.append('بشةخعس ؤقشئغ ؤاشقشؤفثقس: $&#{}')   if __name__ == '__main__':     # Basic document     doc = Document('basic')     fill_document(doc)   Thanks.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  BOM, it's so often BOM for me  vi the file, use  :set nobomb   and save it. That nearly always fixes it in my case     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  I had the same error, with URLs containing non-ascii chars (bytes with values > 128)  url = url.decode('utf8').encode('utf-8')   Worked for me, in Python 2.7, I suppose this assignment changed 'something' in the str internal representation--i.e., it forces the right decoding of the backed byte sequence in url and finally puts the string into a utf-8 str with all the magic in the right place. Unicode in Python is black magic for me. Hope useful     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  This is the best answer: https://stackoverflow.com/a/4027726/2159089  in linux:  export PYTHONIOENCODING=utf-8   so sys.stdout.encoding is OK.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  i solve that problem changing in the file settings.py with 'ENGINE': 'django.db.backends.mysql',   don´t use 'ENGINE': 'mysql.connector.django',     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1",
        "A_Content": "  Just convert the text explicitly to string using str(). Worked for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unicode",
            "utf-8"
        ],
        "URL": "https://stackoverflow.com/questions/10561923/unicodedecodeerror-ascii-codec-cant-decode-byte-0xef-in-position-1",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm having a few issues trying to encode a string to UTF-8. I've tried numerous things, including using string.encode('utf-8') and unicode(string), but I get the error:     UnicodeDecodeError: 'ascii' codec can't decode byte 0xef in position 1: ordinal not in range(128)   This is my string:  (｡･ω･｡)ﾉ   I don't see what's going wrong, any idea?  Edit: The problem is that printing the string as it is does not show properly. Also, this error when I try to convert it:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> s = '(\\xef\\xbd\\xa1\\xef\\xbd\\xa5\\xcf\\x89\\xef\\xbd\\xa5\\xef\\xbd\\xa1)\\xef\\xbe\\x89' >>> s1 = s.decode('utf-8') >>> print s1 Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-5: ordinal not in range(128)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do 3 backslashes equal 4 in a Python string?",
        "A_Content": "  Basically, because python is slightly lenient in backslash processing. Quoting from https://docs.python.org/2.0/ref/strings.html :     Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., the backslash is left in the string.   (Emphasis in the original)  Therefore, in python, it isn't that three backslashes are equal to four, it's that when you follow backslash with a character like ?, the two together come through as two characters, because \\? is not a recognized escape sequence.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/35121288/why-do-3-backslashes-equal-4-in-a-python-string",
        "A_Votes": "84",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Could you tell me why '?\\\\\\?'=='?\\\\\\\\?' gives True? That drives me crazy and I can't find a reasonable answer...  >>> list('?\\\\\\?') ['?', '\\\\', '\\\\', '?'] >>> list('?\\\\\\\\?') ['?', '\\\\', '\\\\', '?']      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do 3 backslashes equal 4 in a Python string?",
        "A_Content": "  This is because backslash acts as an escape character for the character(s) immediately following it, if the combination represents a valid escape sequence. The dozen or so escape sequences are listed here. They include the obvious ones such as newline \\n, horizontal tab \\t, carriage return \\r and more obscure ones such as named unicode characters using \\N{...}, e.g. \\N{WAVY DASH} which represents unicode character \\u3030. The key point though is that if the escape sequence is not known, the character sequence is left in the string as is.  Part of the problem might also be that the Python interpreter output is misleading you. This is because the backslashes are escaped when displayed. However, if you print those strings, you will see the extra backslashes disappear.  >>> '?\\\\\\?' '?\\\\\\\\?' >>> print('?\\\\\\?') ?\\\\? >>> '?\\\\\\?' == '?\\\\?'    # I don't know why you think this is True??? False >>> '?\\\\\\?' == r'?\\\\?'   # but if you use a raw string for '?\\\\?' True >>> '?\\\\\\\\?' == '?\\\\\\?'  # this is the same string... see below True   For your specific examples, in the first case '?\\\\\\?', the first \\ escapes the second backslash leaving a single backslash, but the third backslash remains as a backslash because \\? is not a valid escape sequence. Hence the resulting string is ?\\\\?.  For the second case '?\\\\\\\\?', the first backslash escapes the second, and the third backslash escapes the fourth which results in the string ?\\\\?.  So that's why three backslashes is the same as four:  >>> '?\\\\\\?' == '?\\\\\\\\?' True   If you want to create a string with 3 backslashes you can escape each backslash:  >>> '?\\\\\\\\\\\\?' '?\\\\\\\\\\\\?' >>> print('?\\\\\\\\\\\\?') ?\\\\\\?   or you might find \"raw\" strings more understandable:  >>> r'?\\\\\\?' '?\\\\\\\\\\\\?' >>> print(r'?\\\\\\?') ?\\\\\\?   This turns of escape sequence processing for the string literal. See String Literals for more details.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/35121288/why-do-3-backslashes-equal-4-in-a-python-string",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Could you tell me why '?\\\\\\?'=='?\\\\\\\\?' gives True? That drives me crazy and I can't find a reasonable answer...  >>> list('?\\\\\\?') ['?', '\\\\', '\\\\', '?'] >>> list('?\\\\\\\\?') ['?', '\\\\', '\\\\', '?']      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do 3 backslashes equal 4 in a Python string?",
        "A_Content": "  Because \\x in a character string, when x is not one of the special backslashable characters like n, r, t, 0, etc, evaluates to a string with a backslash and then an x.  >>> '\\?' '\\\\?'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/35121288/why-do-3-backslashes-equal-4-in-a-python-string",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Could you tell me why '?\\\\\\?'=='?\\\\\\\\?' gives True? That drives me crazy and I can't find a reasonable answer...  >>> list('?\\\\\\?') ['?', '\\\\', '\\\\', '?'] >>> list('?\\\\\\\\?') ['?', '\\\\', '\\\\', '?']      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do 3 backslashes equal 4 in a Python string?",
        "A_Content": "  From the python lexical analysis page under string literals at: https://docs.python.org/2/reference/lexical_analysis.html  There is a table that lists all the recognized escape sequences.  \\\\ is an escape sequence that is === \\  \\? is not an escape sequence and is === \\?  so '\\\\\\\\' is '\\\\' followed by '\\\\' which is '\\\\' (two escaped \\)  and '\\\\\\' is '\\\\' followed by '\\' which is also '\\\\' (one escaped \\ and one raw \\)  also, it should be noted that python does not distinguish between single and double quotes surrounding a string literal, unlike some other languages.  So 'String' and \"String\" are the exact same thing in python, they do not affect the interpretation of escape sequences.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/35121288/why-do-3-backslashes-equal-4-in-a-python-string",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Could you tell me why '?\\\\\\?'=='?\\\\\\\\?' gives True? That drives me crazy and I can't find a reasonable answer...  >>> list('?\\\\\\?') ['?', '\\\\', '\\\\', '?'] >>> list('?\\\\\\\\?') ['?', '\\\\', '\\\\', '?']      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do 3 backslashes equal 4 in a Python string?",
        "A_Content": "  mhawke's answer pretty much covers it, I just want to restate it in a more concise form and with minimal examples that illustrate this behaviour.  I guess one thing to add is that escape processing moves from left to right, so that \\n first finds the backslash and then looks for a character to escape, then finds n and escapes it; \\\\n finds first backslash, finds second and escapes it, then finds n and sees it as a literal n; \\? finds backslash and looks for a char to escape, finds ? which cannot be escaped, and so treats \\ as a literal backslash.  As mhawke noted, the key here is that interactive interpreter escapes the backslash when displaying a string. I'm guessing the reason for that is to ensure that text strings copied from interpreter into code editor are valid python strings. However, in this case this allowance for convenience causes confusion.  >>> print('\\?') # \\? is not a valid escape code so backslash is left as-is \\? >>> print('\\\\?') # \\\\ is a valid escape code, resulting in a single backslash '\\?'  >>> '\\?' # same as first example except that interactive interpreter escapes the backslash \\\\? >>> '\\\\?' # same as second example, backslash is again escaped \\\\?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7"
        ],
        "URL": "https://stackoverflow.com/questions/35121288/why-do-3-backslashes-equal-4-in-a-python-string",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Could you tell me why '?\\\\\\?'=='?\\\\\\\\?' gives True? That drives me crazy and I can't find a reasonable answer...  >>> list('?\\\\\\?') ['?', '\\\\', '\\\\', '?'] >>> list('?\\\\\\\\?') ['?', '\\\\', '\\\\', '?']      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Rough answers:   Scala's static typing is helping it quite a bit here - this means that it uses the JVM pretty efficiently without too much extra effort. I'm not exactly sure on the Ruby/Python difference, but I suspect that (2...n).all? in the function is-prime? is likely to be quite well optimised in Ruby (EDIT: sounds like this is indeed the case, see Julian's answer for more detail...) Ruby 1.9.3 is just much better optimised Clojure code can certainly be accelerated a lot! While Clojure is dynamic by default, you can use type hints, primitive maths etc. to get close to Scala / pure Java speed in many cases when you need to.   Most important optimisation in the Clojure code would be to use typed primitive maths within is-prime?, something like:  (set! *unchecked-math* true) ;; at top of file to avoid using BigIntegers  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (zero? (mod n i))       false       (if (>= (inc i) n) true (recur (inc i))))))   With this improvement, I get Clojure completing 10k in 0.635 secs (i.e. the second fastest on your list, beating Scala)  P.S. note that you have printing code inside your benchmark in some cases - not a good idea as it will distort the results, especially if using a function like print for the first time causes initialisation of IO subsystems or something like that!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Here's a fast Clojure version, using the same basic algorithms:    (set! *unchecked-math* true)  (defn is-prime? [^long n]   (loop [i 2]     (if (zero? (unchecked-remainder-int n i))       false       (if (>= (inc i) n)         true         (recur (inc i))))))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :when (and (is-prime? x) (is-prime? (- x 6)))]     [(- x 6) x]))   It runs about 20x faster than your original on my machine. And here's a version that leverages the new reducers library in 1.5 (requires Java 7 or JSR 166):  (require '[clojure.core.reducers :as r]) ;'  (defn sexy-primes [m]   (->> (vec (range 11 (inc m)))        (r/filter #(and (is-prime? %) (is-prime? (- % 6))))        (r/map #(list (- % 6) %))        (r/fold (fn ([] []) ([a b] (into a b))) conj)))   This runs about 40x faster than your original. On my machine, that's 100k in 1.5 seconds.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  I'll answer just #2, since it's the only one I've got anything remotely intelligent to say, but for your Python code, you're creating an intermediate list in is_prime, whereas you're using .map in your all in Ruby which is just iterating.  If you change your is_prime to:  def is_prime(n):     return all((n%j > 0) for j in range(2, n))   they're on par.  I could optimize the Python further, but my Ruby isn't good enough to know when I've given more of an advantage (e.g., using xrange makes Python win on my machine, but I don't remember if the Ruby range you used creates an entire range in memory or not).  EDIT: Without being too silly, making the Python code look like:  import time  def is_prime(n):     return all(n % j for j in xrange(2, n))  def primes_below(x):     return [(j-6, j) for j in xrange(9, x + 1) if is_prime(j) and is_prime(j-6)]  a = int(round(time.time() * 1000)) print(primes_below(10*1000)) b = int(round(time.time() * 1000)) print(str((b-a)) + \" mils\")   which doesn't change much more, puts it at 1.5s for me, and, with being extra silly, running it with PyPy puts it at .3s for 10K, and 21s for 100K.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  You can make the Scala a lot faster by modifying your isPrime method to    def isPrime(n: Int, i: Int = 2): Boolean =      if (i == n) true      else if (n % i != 0) isPrime(n, i + 1)     else false   Not quite as concise but the program runs in 40% of the time!   We cut out the superfluous Range and anonymous Function objects, the Scala compiler recognizes the tail-recursion and turns it into a while-loop, which the JVM can turn into more or less optimal machine code, so it shouldn't be too far off the C version.  See also: How to optimize for-comprehensions and loops in Scala?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Here is my scala version in both parallel and no-parallel, just for fun: (In my dual core compute, the parallel version takes 335ms while the no-parallel version takes 655ms)  object SexyPrimes {   def isPrime(n: Int): Boolean =      (2 to math.sqrt(n).toInt).forall{ n%_ != 0 }    def isSexyPrime(n: Int): Boolean = isPrime(n) && isPrime(n-6)    def findPrimesPar(n: Int) {     for(k <- (11 to n).par)       if(isSexyPrime(k)) printf(\"%d %d\\n\",k-6,k)   }    def findPrimes(n: Int) {     for(k <- 11 to n)       if(isSexyPrime(k)) printf(\"%d %d\\n\",k-6,k)   }     def timeOf(call : =>Unit) {     val start = System.currentTimeMillis     call     val end = System.currentTimeMillis     println((end-start)+\" mils\")   }    def main(args: Array[String]) {     timeOf(findPrimes(100*1000))     println(\"------------------------\")     timeOf(findPrimesPar(100*1000))   } }   EDIT: According to Emil H's suggestion, I have changed my code to avoid the effects of IO and jvm warmup:  The result shows in my compute:     List(3432, 1934, 3261, 1716, 3229, 1654, 3214, 1700)   object SexyPrimes {   def isPrime(n: Int): Boolean =      (2 to math.sqrt(n).toInt).forall{ n%_ != 0 }    def isSexyPrime(n: Int): Boolean = isPrime(n) && isPrime(n-6)    def findPrimesPar(n: Int) {     for(k <- (11 to n).par)       if(isSexyPrime(k)) ()//printf(\"%d %d\\n\",k-6,k)   }    def findPrimes(n: Int) {     for(k <- 11 to n)       if(isSexyPrime(k)) ()//printf(\"%d %d\\n\",k-6,k)   }     def timeOf(call : =>Unit): Long = {     val start = System.currentTimeMillis     call     val end = System.currentTimeMillis     end - start    }    def main(args: Array[String]) {     val xs = timeOf(findPrimes(1000*1000))::timeOf(findPrimesPar(1000*1000))::              timeOf(findPrimes(1000*1000))::timeOf(findPrimesPar(1000*1000))::              timeOf(findPrimes(1000*1000))::timeOf(findPrimesPar(1000*1000))::              timeOf(findPrimes(1000*1000))::timeOf(findPrimesPar(1000*1000))::Nil     println(xs)   } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Never mind the benchmarks; the problem got me interested and I made some fast tweaks.  This uses the lru_cache decorator, which memoizes a function; so when we call is_prime(i-6) we basically get that prime check for free.  This change cuts the work roughly in half.  Also, we can make the range() calls step through just the odd numbers, cutting the work roughly in half again.  http://en.wikipedia.org/wiki/Memoization  http://docs.python.org/dev/library/functools.html  This requires Python 3.2 or newer to get lru_cache, but could work with an older Python if you install a Python recipe that provides lru_cache.  If you are using Python 2.x you should really use xrange() instead of range().  http://code.activestate.com/recipes/577479-simple-caching-decorator/  from functools import lru_cache import time as time_  @lru_cache() def is_prime(n):     return n%2 and all(n%i for i in range(3, n, 2))  def primes_below(x):     return [(i-6, i) for i in range(9, x+1, 2) if is_prime(i) and is_prime(i-6)]  correct100 = [(5, 11), (7, 13), (11, 17), (13, 19), (17, 23), (23, 29),         (31, 37), (37, 43), (41, 47), (47, 53), (53, 59), (61, 67), (67, 73),         (73, 79), (83, 89)] assert(primes_below(100) == correct100)  a = time_.time() print(primes_below(30*1000)) b = time_.time()  elapsed = b - a print(\"{} msec\".format(round(elapsed * 1000)))   The above took only a very short time to edit.  I decided to take it one step further, and make the primes test only try prime divisors, and only up to the square root of the number being tested.  The way I did it only works if you check numbers in order, so it can accumulate all the primes as it goes; but this problem was already checking the numbers in order so that was fine.  On my laptop (nothing special; processor is a 1.5 GHz AMD Turion II \"K625\") this version produced an answer for 100K in under 8 seconds.  from functools import lru_cache import math import time as time_  known_primes = set([2, 3, 5, 7])  @lru_cache(maxsize=128) def is_prime(n):     last = math.ceil(math.sqrt(n))     flag = n%2 and all(n%x for x in known_primes if x <= last)     if flag:         known_primes.add(n)     return flag  def primes_below(x):     return [(i-6, i) for i in range(9, x+1, 2) if is_prime(i) and is_prime(i-6)]  correct100 = [(5, 11), (7, 13), (11, 17), (13, 19), (17, 23), (23, 29),         (31, 37), (37, 43), (41, 47), (47, 53), (53, 59), (61, 67), (67, 73),         (73, 79), (83, 89)] assert(primes_below(100) == correct100)  a = time_.time() print(primes_below(100*1000)) b = time_.time()  elapsed = b - a print(\"{} msec\".format(round(elapsed * 1000)))   The above code is pretty easy to write in Python, Ruby, etc. but would be more of a pain in C.  You can't compare the numbers on this version against the numbers from the other versions without rewriting the others to use similar tricks.  I'm not trying to prove anything here; I just thought the problem was fun and I wanted to see what sort of easy performance improvements I could glean.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Don't forget Fortran!  (Mostly joking, but I would expect similar performance to C).  The statements with exclamation points are optional, but good style. (! is a comment character in fortran 90)  logical function isprime(n) IMPLICIT NONE ! integer :: n,i do i=2,n    if(mod(n,i).eq.0)) return .false. enddo return .true. end  subroutine findprimes(m) IMPLICIT NONE ! integer :: m,i logical, external :: isprime  do i=11,m    if(isprime(i) .and. isprime(i-6))then       write(*,*) i-6,i    endif enddo end  program main findprimes(10*1000) end      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  I couldn't resist to do a few of the most obvious optimizations for the C version which made the 100k test now take 0.3s on my machine (5 times faster than the C version in the question, both compiled with MSVC 2010 /Ox).  int isprime( int x ) {     int i, n;     for( i = 3, n = x >> 1; i <= n; i += 2 )         if( x % i == 0 )             return 0;     return 1; }  void findprimes( int m ) {     int i, s = 3; // s is bitmask of primes in last 3 odd numbers     for( i = 11; i < m; i += 2, s >>= 1 ) {         if( isprime( i ) ) {             if( s & 1 )                 printf( \"%d %d\\n\", i - 6, i );             s |= 1 << 3;         }     } }  main() {     findprimes( 10 * 1000 ); }   Here is the identical implemention in Java:  public class prime {     private static boolean isprime( final int x )     {         for( int i = 3, n = x >> 1; i <= n; i += 2 )             if( x % i == 0 )                 return false;         return true;     }      private static void findprimes( final int m )     {         int s = 3; // s is bitmask of primes in last 3 odd numbers         for( int i = 11; i < m; i += 2, s >>= 1 ) {             if( isprime( i ) ) {                 if( ( s & 1 ) != 0 )                     print( i );                 s |= 1 << 3;             }         }     }      private static void print( int i )     {         System.out.println( ( i - 6 ) + \" \" + i );     }      public static void main( String[] args )     {         // findprimes( 300 * 1000 ); // for some JIT training         long time = System.nanoTime();         findprimes( 10 * 1000 );         time = System.nanoTime() - time;         System.err.println( \"time: \" + ( time / 10000 ) / 100.0 + \"ms\" );     } }   With Java 1.7.0_04 this runs almost exactly as fast as the C version. Client or server VM doesn't show much difference, except that JIT training seems to help the server VM a bit (~3%) while it has almost no effect with the client VM. The output in Java seems to be slower than in C. If the output is replaced with a static counter in both versions, the Java version runs a little faster than the C version.  These are my times for the 100k run:   319ms C compiled with /Ox and output to >NIL: 312ms C compiled with /Ox and static counter 324ms Java client VM with output to >NIL: 299ms Java client VM with static counter   and the 1M run (16386 results):   24.95s C compiled with /Ox and static counter 25.08s Java client VM with static counter 24.86s Java server VM with static counter   While this does not really answer your questions, it shows that small tweaks can have a noteworthy impact on performance. So to be able to really compare languages you should try to avoid all algorithmic differences as much as possible.  It also gives a hint why Scala seems rather fast. It runs on the Java VM and thus benefits from its impressive performance.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  In Scala try using Tuple2 instead of List, it should go faster. Just remove the word 'List' since (x, y) is a Tuple2.  Tuple2 is specialized for Int, Long and Double meaning it won't have to box/unbox those raw datatypes. Tuple2 source. List isn't specialized. List source.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Here's the code for the Go (golang.org) version:  package main  import (     \"fmt\" )   func main(){     findprimes(10*1000) }  func isprime(x int) bool {     for i := 2; i < x; i++ {         if x%i == 0 {             return false         }     }     return true }  func findprimes(m int){     for i := 11; i < m; i++ {         if isprime(i) && isprime(i-6) {             fmt.Printf(\"%d %d\\n\", i-6, i)         }     } }   It ran just as fast as the C version.  Using an Asus u81a Intel Core 2 Duo T6500 2.1GHz, 2MB L2 cache, 800MHz FSB. 4GB RAM   The 100k version: C: 2.723s Go: 2.743s  With 1000000 (1M instead of 100K): C: 3m35.458s Go: 3m36.259s   But I think that it would be fair to use Go's built in multithreading capabilities and compare that version with the regular C version (without multithreading), just because it's almost too easy to do multithreading with Go.  Update: I did a parallel version using Goroutines in Go:  package main  import (   \"fmt\"   \"runtime\" )  func main(){     runtime.GOMAXPROCS(4)     printer := make(chan string)     printer2 := make(chan string)     printer3 := make(chan string)     printer4 := make(chan string)     finished := make(chan int)      var buffer, buffer2, buffer3 string      running := 4     go findprimes(11, 30000, printer, finished)     go findprimes(30001, 60000, printer2, finished)     go findprimes(60001, 85000, printer3, finished)     go findprimes(85001, 100000, printer4, finished)      for {       select {         case i := <-printer:           // batch of sexy primes received from printer channel 1, print them           fmt.Printf(i)         case i := <-printer2:           // sexy prime list received from channel, store it           buffer = i         case i := <-printer3:           // sexy prime list received from channel, store it           buffer2 = i         case i := <-printer4:           // sexy prime list received from channel, store it           buffer3 = i         case <-finished:           running--           if running == 0 {               // all goroutines ended               // dump buffer to stdout               fmt.Printf(buffer)               fmt.Printf(buffer2)               fmt.Printf(buffer3)               return           }       }     } }  func isprime(x int) bool {     for i := 2; i < x; i++ {         if x%i == 0 {             return false         }     }     return true }  func findprimes(from int, to int, printer chan string, finished chan int){     str := \"\"     for i := from; i <= to; i++ {         if isprime(i) && isprime(i-6) {             str = str + fmt.Sprintf(\"%d %d\\n\", i-6, i)       }     }     printer <- str     //fmt.Printf(\"Finished %d to %d\\n\", from, to)     finished <- 1 }   The parallelized version used in average 2.743 seconds, the exact same time that the regular version used.  The parallelized version completed in 1.706 seconds. It used less than 1.5 Mb RAM.  One odd thing: My dual core kubuntu 64bit never peaked in both cores.  It looked like Go was using just one core. Fixed with a call to runtime.GOMAXPROCS(4)  Update: I ran the paralellized version up to 1M numbers.  One of My CPU cores was at 100% all the time, while the other wasn't used at all (odd).  It took a whole minute more than the C and the regular Go versions. :(  With 1000000 (1M instead of 100K):   C: 3m35.458s Go: 3m36.259s Go using goroutines:3m27.137s2m16.125s   The 100k version:   C: 2.723s Go: 2.743s Go using goroutines: 1.706s     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Just for the fun of it, here is a parallel Ruby version.   require 'benchmark'  num = ARGV[0].to_i  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes_default(x)     (9..x).map do |i|         [i-6, i]     end.select do |j|         j.all?{|j| is_prime? j}     end end  def sexy_primes_threads(x)     partition = (9..x).map do |i|         [i-6, i]     end.group_by do |x|         x[0].to_s[-1]     end     threads = Array.new     partition.each_key do |k|        threads << Thread.new do             partition[k].select do |j|                 j.all?{|j| is_prime? j}             end         end     end     threads.each {|t| t.join}     threads.map{|t| t.value}.reject{|x| x.empty?} end  puts \"Running up to num #{num}\"  Benchmark.bm(10) do |x|     x.report(\"default\") {a = sexy_primes_default(num)}     x.report(\"threads\") {a = sexy_primes_threads(num)} end   On my 1.8GHz Core i5 MacBook Air, the performance results are:  # Ruby 1.9.3 $ ./sexyprimes.rb 100000 Running up to num 100000                  user     system      total        real default     68.840000   0.060000  68.900000 ( 68.922703) threads     71.730000   0.090000  71.820000 ( 71.847346)  # JRuby 1.6.7.2 on JVM 1.7.0_05 $ jruby --1.9 --server sexyprimes.rb 100000 Running up to num 100000                 user     system      total        real default    56.709000   0.000000  56.709000 ( 56.708000) threads    36.396000   0.000000  36.396000 ( 36.396000)  # JRuby 1.7.0.preview1 on JVM 1.7.0_05 $ jruby --server sexyprimes.rb 100000 Running up to num 100000              user     system      total        real default     52.640000   0.270000  52.910000 ( 51.393000) threads    105.700000   0.290000 105.990000 ( 30.298000)   It looks like the JVM's JIT is giving Ruby a nice performance boost in the default case, while true multithreading helps JRuby perform 50% faster in the threaded case. What's more interesting is that JRuby 1.7 improves the JRuby 1.6 score by a healthy 17%!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  Based on x4u's answer, I wrote a scala version using recursion, and I improved on it by only going to the sqrt instead of x/2 for the prime check function. I get ~250ms for 100k, and ~600ms for 1M. I went ahead and went to 10M in ~6s.  import scala.annotation.tailrec  var count = 0; def print(i:Int) = {   println((i - 6) + \" \" + i)   count += 1 }  @tailrec def isPrime(n:Int, i:Int = 3):Boolean = {   if(n % i == 0) return false;   else if(i * i > n) return true;   else isPrime(n = n, i = i + 2) }        @tailrec def findPrimes(max:Int, bitMask:Int = 3, i:Int = 11):Unit = {   if (isPrime(i)) {     if((bitMask & 1) != 0) print(i)     if(i + 2 < max) findPrimes(max = max, bitMask = (bitMask | (1 << 3)) >> 1, i = i + 2)   } else if(i + 2 < max) {     findPrimes(max = max, bitMask = bitMask >> 1, i = i + 2)   } }  val a = System.currentTimeMillis() findPrimes(max=10000000) println(count) val b = System.currentTimeMillis() println((b - a).toString + \" mils\")   I also went back and wrote a CoffeeScript (V8 JavaScript) version, which gets ~15ms for 100k, 250ms for 1M, and 6s for 10M, by using a counter (ignoring I/O). If I turn on the output it takes ~150ms for 100k, 1s for 1M, and 12s for 10M. Couldn't use tail recursion here, unfortunately, so I had to convert it back into loops.  count = 0; print = (i) ->   console.log(\"#{i - 6} #{i}\")   count += 1   return  isPrime = (n) ->   i = 3   while i * i < n     if n % i == 0       return false     i += 2   return true  findPrimes = (max) ->   bitMask = 3   for i in [11..max] by 2     prime = isPrime(i)     if prime       if (bitMask & 1) != 0         print(i)       bitMask |= (1 << 3)     bitMask >>= 1   return  a = new Date() findPrimes(1000000) console.log(count) b = new Date() console.log((b - a) + \" ms\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Interpreting a benchmark in C, Clojure, Python, Ruby, Scala and others [closed]",
        "A_Content": "  The answer to your question #1 is that Yes, the JVM is incredably fast and yes static typing helps.  The JVM should be faster than C in the long run, possibly even faster than \"Normal\" assembly language--Of course you can always hand optimize assembly to beat anything by doing manual runtime profiling and creating a separate version for each CPU, you just have to be amazingly good and knowledgable.  The reasons for Java's speed are:   The JVM can analyze your code while it runs and hand-optimize it--for instance, if you had a method that could be statically analyzed at compile time to be a true function and the JVM noticed that you were often calling it with the same parameters, it COULD actually eliminate the call completely and just inject the results from the last call (I'm not sure if Java actually does this exactly, but it doest a lot of stuff like this).   Due to static typing, the JVM can know a lot about your code at compile time, this lets it pre-optimize quite a bit of stuff.  It also lets the compiler optimize each class individually without knowledge of how another class is planning to use it.  Also Java doesn't have arbitrary pointers to memory location, it KNOWS what values in memory may and may not be changed and can optimize accordingly.  Heap allocation is MUCH more efficient than C, Java's heap allocation is more like C's stack allocation in speed--yet more versatile.  A lot of time has gone into the different algroithims used here, it's an art--for instance, all the objects with a short lifespan (like C's stack variables) are allocated to a \"known\" free location (no searching for a free spot with enough space) and are all freed together in a single step (like a stack pop).   The JVM can know quirks about your CPU architecture and generate machine code specifically for a given CPU.  The JVM can speed your code long after you shipped it.  Much like moving a program to a new CPU can speed it up, moving it to a new version of the JVM can also give you huge speed performances taylored to CPUs that didn't even exist when you initially compiled your code, something c physically cannot do without a recomiple.  By the way, most of the bad rep for java speed comes from the long startup time to load the JVM (Someday someone will build the JVM into the OS and this will go away!) and the fact that many developers are really bad at writing GUI code (especially threaded) which caused Java GUIs to often become unresponsive and glitchy.  Simple to use languages like Java and VB have their faults amplified by the fact that the capibilities of the average programmer tends to be lower than more complicated languages.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "scala",
            "clojure",
            "benchmarking"
        ],
        "URL": "https://stackoverflow.com/questions/11641098/interpreting-a-benchmark-in-c-clojure-python-ruby-scala-and-others",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Disclaimer  I know that artificial benchmarks are evil. They can show results only for very specific narrow situation. I don't assume that one language is better than the other because of the some stupid bench. However I wonder why results is so different. Please see my questions at the bottom.  Math benchmark description  Benchmark is simple math calculations to find pairs of prime numbers which differs by 6 (so called sexy primes) E.g. sexy primes below 100 would be: (5 11) (7 13) (11 17) (13 19) (17 23) (23 29) (31 37) (37 43) (41 47) (47 53) (53 59) (61 67) (67 73) (73 79) (83 89) (97 103)  Results table  In table: calculation time  in seconds Running: all except Factor was running in VirtualBox (Debian unstable amd64 guest, Windows 7 x64 host) CPU: AMD A4-3305M    Sexy primes up to:        10k      20k      30k      100k                   Bash                    58.00   200.00     [*1]      [*1]    C                        0.20     0.65     1.42     15.00    Clojure1.4               4.12     8.32    16.00    137.93    Clojure1.4 (optimized)   0.95     1.82     2.30     16.00    Factor                    n/a      n/a    15.00    180.00    Python2.7                1.49     5.20    11.00       119         Ruby1.8                  5.10    18.32    40.48    377.00    Ruby1.9.3                1.36     5.73    10.48    106.00    Scala2.9.2               0.93     1.41     2.73     20.84    Scala2.9.2 (optimized)   0.32     0.79     1.46     12.01   [*1] - I'm afraid to imagine how much time will it take  Code listings  C:  int isprime(int x) {   int i;   for (i = 2; i < x; ++i)     if (x%i == 0) return 0;   return 1; }  void findprimes(int m) {   int i;   for ( i = 11; i < m; ++i)     if (isprime(i) && isprime(i-6))       printf(\"%d %d\\n\", i-6, i); }  main() {     findprimes(10*1000); }   Ruby:  def is_prime?(n)   (2...n).all?{|m| n%m != 0 } end  def sexy_primes(x)   (9..x).map do |i|     [i-6, i]   end.select do |j|     j.all?{|j| is_prime? j}   end end  a = Time.now p sexy_primes(10*1000) b = Time.now puts \"#{(b-a)*1000} mils\"   Scala:  def isPrime(n: Int) =   (2 until n) forall { n % _ != 0 }  def sexyPrimes(n: Int) =    (11 to n) map { i => List(i-6, i) } filter { _ forall(isPrime(_)) }  val a = System.currentTimeMillis() println(sexyPrimes(100*1000)) val b = System.currentTimeMillis() println((b-a).toString + \" mils\")   Scala opimized isPrime (the same idea like in Clojure optimization):  import scala.annotation.tailrec  @tailrec // Not required, but will warn if optimization doesn't work def isPrime(n: Int, i: Int = 2): Boolean =    if (i == n) true    else if (n % i != 0) isPrime(n, i + 1)   else false   Clojure:  (defn is-prime? [n]   (every? #(> (mod n %) 0)     (range 2 n)))  (defn sexy-primes [m]   (for [x (range 11 (inc m))         :let [z (list (- x 6) x)]         :when (every? #(is-prime? %) z)]       z))  (let [a (System/currentTimeMillis)]   (println (sexy-primes (* 10 1000)))   (let [b (System/currentTimeMillis)]     (println (- b a) \"mils\")))   Clojure optimized is-prime?:  (defn ^:static is-prime? [^long n]   (loop [i (long 2)]      (if (= (rem n i) 0)       false       (if (>= (inc i) n) true (recur (inc i))))))   Python  import time as time_  def is_prime(n):   return all((n%j > 0) for j in xrange(2, n))  def primes_below(x):   return [[j-6, j] for j in xrange(9, x+1) if is_prime(j) and is_prime(j-6)]  a = int(round(time_.time() * 1000)) print(primes_below(10*1000)) b = int(round(time_.time() * 1000)) print(str((b-a)) + \" mils\")   Factor  MEMO:: prime? ( n -- ? ) n 1 - 2 [a,b] [ n swap mod 0 > ] all? ;  MEMO: sexyprimes ( n n -- r r ) [a,b] [ prime? ] filter [ 6 + ] map [ prime? ] filter dup [ 6 - ] map ;  5 10 1000 * sexyprimes . .   Bash(zsh):  #!/usr/bin/zsh function prime {   for (( i = 2; i < $1; i++ )); do     if [[ $[$1%i] == 0 ]]; then       echo 1       exit     fi   done   echo 0 }  function sexy-primes {   for (( i = 9; i <= $1; i++ )); do     j=$[i-6]     if [[ $(prime $i) == 0 && $(prime $j) == 0 ]]; then       echo $j $i     fi   done }  sexy-primes 10000   Questions   Why Scala is so fast? Is it because of static typing? Or it is just using JVM very efficiently? Why such a huge difference between Ruby and Python? I thought these two are not somewhat totally different. Maybe my code is wrong. Please enlighten me! Thanks. UPD Yes, that was error in my code. Python and Ruby 1.9 are pretty equal. Really impressive jump in productivity between Ruby versions. Can I optimize Clojure code by adding type declarations? Will it help?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Unittest setUp/tearDown for several tests",
        "A_Content": "  As of 2.7 (per the documentation) you get setUpClass and tearDownClass which execute before and after the tests in a given class are run, respectively.  Alternatively, if you have a group of them in one file, you can use setUpModule and tearDownModule (documentation).  Otherwise your best bet is probably going to be to create your own derived TestSuite and override run().  All other calls would be handled by the parent, and run would call your setup and teardown code around a call up to the parent's run method.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing"
        ],
        "URL": "https://stackoverflow.com/questions/8389639/unittest-setup-teardown-for-several-tests",
        "A_Votes": "110",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a function that is fired at the beginning/end of a scenario of tests? The functions setUp and tearDown are fired before/after every single test.  I typically would like to have this:  class TestSequenceFunctions(unittest.TestCase):      def setUpScenario(self):         start() #launched at the beginning, once      def test_choice(self):         element = random.choice(self.seq)         self.assertTrue(element in self.seq)      def test_sample(self):         with self.assertRaises(ValueError):             random.sample(self.seq, 20)         for element in random.sample(self.seq, 5):             self.assertTrue(element in self.seq)      def tearDownScenario(self):         end() #launched at the end, once   For now, these setUp and tearDown are unit tests and spread in all my scenarios (containing many tests), one is the first test, the other is the last test.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Unittest setUp/tearDown for several tests",
        "A_Content": "  I have the same scenario, for me setUpClass and tearDownClass methods works perfectly  import unittest  class Test(unittest.TestCase):     @classmethod     def setUpClass(cls):         cls._connection = createExpensiveConnectionObject()      @classmethod     def tearDownClass(cls):         cls._connection.destroy()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing"
        ],
        "URL": "https://stackoverflow.com/questions/8389639/unittest-setup-teardown-for-several-tests",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a function that is fired at the beginning/end of a scenario of tests? The functions setUp and tearDown are fired before/after every single test.  I typically would like to have this:  class TestSequenceFunctions(unittest.TestCase):      def setUpScenario(self):         start() #launched at the beginning, once      def test_choice(self):         element = random.choice(self.seq)         self.assertTrue(element in self.seq)      def test_sample(self):         with self.assertRaises(ValueError):             random.sample(self.seq, 20)         for element in random.sample(self.seq, 5):             self.assertTrue(element in self.seq)      def tearDownScenario(self):         end() #launched at the end, once   For now, these setUp and tearDown are unit tests and spread in all my scenarios (containing many tests), one is the first test, the other is the last test.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Unittest setUp/tearDown for several tests",
        "A_Content": "  For python 2.5, and when working with pydev, it's a bit hard. It appears that pydev doesn't use the test suite, but finds all individual test cases and runs them all separately.  My solution for this was using a class variable like this:  class TestCase(unittest.TestCase):     runCount = 0      def setUpClass(self):         pass # overridden in actual testcases      def run(self, result=None):         if type(self).runCount == 0:             self.setUpClass()          super(TestCase, self).run(result)         type(self).runCount += 1   With this trick, when you inherit from this TestCase (instead of from the original unittest.TestCase), you'll also inherit the runCount of 0. Then in the run method, the runCount of the child testcase is checked and incremented. This leaves the runCount variable for this class at 0.  This means the setUpClass will only be ran once per class and not once per instance.   I don't have a tearDownClass method yet, but I guess something could be made with using that counter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing"
        ],
        "URL": "https://stackoverflow.com/questions/8389639/unittest-setup-teardown-for-several-tests",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a function that is fired at the beginning/end of a scenario of tests? The functions setUp and tearDown are fired before/after every single test.  I typically would like to have this:  class TestSequenceFunctions(unittest.TestCase):      def setUpScenario(self):         start() #launched at the beginning, once      def test_choice(self):         element = random.choice(self.seq)         self.assertTrue(element in self.seq)      def test_sample(self):         with self.assertRaises(ValueError):             random.sample(self.seq, 20)         for element in random.sample(self.seq, 5):             self.assertTrue(element in self.seq)      def tearDownScenario(self):         end() #launched at the end, once   For now, these setUp and tearDown are unit tests and spread in all my scenarios (containing many tests), one is the first test, the other is the last test.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "  As of PyDev 2.3.0, pep8 is integrated in PyDev by default, even shipping with a default version of it.  Open Window > Preferences  It must be enabled in PyDev > Editor > Code Analysis > pep8.py  Errors/Warnings should be shown as markers (as other things in the regular code analysis).  In the event a file is not analyzed, see https://stackoverflow.com/a/31001619/832230.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "  I don't know how to integrate it for whole project, but I have used it as an external tool to analyze an individual file.  Note that the pycodestyle package is the official replacement for and is the newer version of the pep8 package. To install it, run:  $ sudo pip install --upgrade pycodestyle   Next, in Eclipse:   Select Run-External Tools-External Tools Configurations... Select Program root node. Press New launch configuration button. Enter Name for your launch configuration. I use pycodestyle. Fill following fields:  Location -- ${system_path:pycodestyle}  Working directory -- ${container_loc}  Arguments -- \"${resource_name}\" (This uses the currently active file.)   Go to Common tab and confirm that the Allocate Console checkbox is checked.  A benefit of this approach is that you can use a very up-to-date version of the package, and are not limited to the old version included with PyDev. And if you are curious about setting up pylint in a similar manner, see this answer.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "   Open your Eclipse Go to Help and select Install New Software Click the Add button and a \"Add Repository\" Dialog box will appear You can use any name you like for it. (I used PyDev) For the location, enter \"http://pydev.org/updates\" Click Ok. You are now in the process of installation. Just wait for it to finish. After the installation, close Eclipse and Open it again. Now that PyDev is installed in your Eclipse, go to Window->Preferences Choose PyDev->Editor->Code Analysis Go to pep8.py tab Choose the radio button for warning and click Ok.   That's it. Your Eclipse IDE is now integrated with PEP8. To run pep8.py automatically, right click on your project editor. Choose PyDev and click \"code analysis\". In your problems tab in your workspace, you will see warnings that points to the line that you have made a violation in the PEP8 (if you have violated).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "  CODE ANALYSIS :  In Eclipse (PyDev), if you want to code analysis using pep8 style then  Go to:Windows -> Preferences -> PyDev -> Editor -> Code Analysis -> pep8.py tab and select Warning click Apply and OK button.  In your python code if you validate pep8 coding style it will give you warning  AUTO CODE FORMATTING :  In Eclipse (PyDev), if you want to Auto Format python code using pep8 style then  Go to:Windows -> Preferences -> PyDev -> Editor -> Code Style -> Code Formatter -> click on check-box (Use autopep8.py for console formatting?) click Apply and OK button.  If you want to increase length of line(pep8 default is 79) below Use autopep8.py you can set parameter type --max-line-length=150 if you set max length to 150  If press auto-format shortcut ( Ctrl + Shift + f ) it will automatically format your python code like pep8 style      ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "  That does not yet appear to be fully integrated into Pydev.  As suggested in this post,       [it] would require changing the code within pydev -- a flexible option would be adding preferences to let the user choose to which patterns he wants to match for creating hyperlinks (and saying which group in the match is the line and which one is the file)...      Or, you can try it hard-coded playing with: org.python.pydev.debug.ui.PythonConsoleLineTracker (should be pretty easy to grasp).   A request does exist for just that, but it seems to be still open 1 year after its creation...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to integrate pep8.py in Eclipse?",
        "A_Content": "  You don't :) Instead you take advantage of very good integration with PyLint and configure PyLint to check all things PEP8 checks. See How to configure PyLint to check all things PEP8 checks?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "eclipse",
            "pydev",
            "pep8"
        ],
        "URL": "https://stackoverflow.com/questions/399956/how-to-integrate-pep8-py-in-eclipse",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    A little background:   PEP 8 is the Style Guide for Python Code. It contains the conventions all python programmers should follow. pep8.py is a (very useful) script that checks the code formating of a given python script, according to PEP 8. Eclipse is a great IDE. With the Pydev extension, it that can be used to develop Python   I run pep8.py manually when I'm scripting, but with bigger projects I prefer to use Eclipse. It would be really useful to integrate pep8.py in Eclipse/Pydev, so it can be run automatically in all the files in the project, and point to the lines containing the warnings. Maybe there is an obvious way to do it, but I haven't found it yet.  Question is: How to integrate pep8.py in Eclipse?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the pythonic way to unpack tuples? [duplicate]",
        "A_Content": "  Generally, you can use the func(*tuple) syntax. You can even pass a part of the tuple, which seems like what you're trying to do here:  t = (2010, 10, 2, 11, 4, 0, 2, 41, 0) dt = datetime.datetime(*t[0:7])   This is called unpacking a tuple, and can be used for other iterables (such as lists) too. Here's another example (from the Python tutorial):  >>> range(3, 6)             # normal call with separate arguments [3, 4, 5] >>> args = [3, 6] >>> range(*args)            # call with arguments unpacked from a list [3, 4, 5]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "tuples"
        ],
        "URL": "https://stackoverflow.com/questions/2238355/what-is-the-pythonic-way-to-unpack-tuples",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Unpack a list in Python?                                        3 answers                                          This is ugly. What's a more Pythonic way to do it?  import datetime  t= (2010, 10, 2, 11, 4, 0, 2, 41, 0) dt = datetime.datetime(t[0], t[1], t[2], t[3], t[4], t[5], t[6])      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the pythonic way to unpack tuples? [duplicate]",
        "A_Content": "  Refer https://docs.python.org/2/tutorial/controlflow.html#unpacking-argument-lists   dt = datetime.datetime(*t[:7])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "tuples"
        ],
        "URL": "https://stackoverflow.com/questions/2238355/what-is-the-pythonic-way-to-unpack-tuples",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Unpack a list in Python?                                        3 answers                                          This is ugly. What's a more Pythonic way to do it?  import datetime  t= (2010, 10, 2, 11, 4, 0, 2, 41, 0) dt = datetime.datetime(t[0], t[1], t[2], t[3], t[4], t[5], t[6])      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to create major and minor gridlines with different linestyles in Python",
        "A_Content": "  Actually, it is as simple as setting major and minor separately:  In [9]: plot([23, 456, 676, 89, 906, 34, 2345]) Out[9]: [<matplotlib.lines.Line2D at 0x6112f90>]  In [10]: yscale('log')  In [11]: grid(b=True, which='major', color='b', linestyle='-')  In [12]: grid(b=True, which='minor', color='r', linestyle='--')   The gotcha with minor grids is that you have to have minor tick marks turned on too.  In the above code this is done by yscale('log'), but it can also be done with plt.minorticks_on().       ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9127434/how-to-create-major-and-minor-gridlines-with-different-linestyles-in-python",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am currently using matplotlib.pyplot to create graphs and would like to have the major gridlines solid and black and the minor ones either greyed or dashed.  In the grid properties, which=both/major/mine, and then color and linestyle are defined simply by linestyle. Is there a way to specify minor linestyle only?  The appropriate code I have so far is  plt.plot(current, counts, 'rd', markersize=8) plt.yscale('log') plt.grid(b=True, which='both', color='0.65', linestyle='-')      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to create major and minor gridlines with different linestyles in Python",
        "A_Content": "  A simple DIY way would be to make the grid yourself:  import matplotlib.pyplot as plt  fig = plt.figure() ax = fig.add_subplot(111)  ax.plot([1,2,3], [2,3,4], 'ro')  for xmaj in ax.xaxis.get_majorticklocs():   ax.axvline(x=xmaj, ls='-') for xmin in ax.xaxis.get_minorticklocs():   ax.axvline(x=xmin, ls='--')  for ymaj in ax.yaxis.get_majorticklocs():   ax.axhline(y=ymaj, ls='-') for ymin in ax.yaxis.get_minorticklocs():   ax.axhline(y=ymin, ls='--') plt.show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/9127434/how-to-create-major-and-minor-gridlines-with-different-linestyles-in-python",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am currently using matplotlib.pyplot to create graphs and would like to have the major gridlines solid and black and the minor ones either greyed or dashed.  In the grid properties, which=both/major/mine, and then color and linestyle are defined simply by linestyle. Is there a way to specify minor linestyle only?  The appropriate code I have so far is  plt.plot(current, counts, 'rd', markersize=8) plt.yscale('log') plt.grid(b=True, which='both', color='0.65', linestyle='-')      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  Use Number from the numbers module to test isinstance(n, Number) (available since 2.6).  >>> from numbers import Number ... from decimal import Decimal ... from fractions import Fraction ... for n in [2, 2.0, Decimal('2.0'), complex(2,0), Fraction(2,1), '2']: ...     print '%15s %s' % (n.__repr__(), isinstance(n, Number))               2 True             2.0 True  Decimal('2.0') True          (2+0j) True  Fraction(2, 1) True             '2' False   This is, of course, contrary to duck typing.  If you are more concerned about how an object acts rather than what it is, perform your operations as if you have a number and use exceptions to tell you otherwise.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  You want to check if some object     acts like a number in certain   circumstances   If you're using Python 2.5 or older, the only real way is to check some of those \"certain circumstances\" and see.  In 2.6 or better, you can use isinstance with numbers.Number -- an abstract base class (ABC) that exists exactly for this purpose (lots more ABCs exist in the collections module for various forms of collections/containers, again starting with 2.6; and, also only in those releases, you can easily add your own abstract base classes if you need to).  Bach to 2.5 and earlier, \"can be added to 0 and is not iterable\" could be a good definition in some cases.  But, you really need to ask yourself, what it is that you're asking that what you want to consider \"a number\" must definitely be able to do, and what it must absolutely be unable to do -- and check.  This may also be needed in 2.6 or later, perhaps for the purpose of making your own registrations to add types you care about that haven't already be registered onto numbers.Numbers -- if you want to exclude some types that claim they're numbers but you just can't handle, that takes even more care, as ABCs have no unregister method [[for example you could make your own ABC WeirdNum and register there all such weird-for-you types, then first check for isinstance thereof to bail out before you proceed to checking for isinstance of the normal numbers.Number to continue successfully.  BTW, if and when you need to check if x can or cannot do something, you generally have to try something like:  try: 0 + x except TypeError: canadd=False else: canadd=True   The presence of __add__ per se tells you nothing useful, since e.g all sequences have it for the purpose of concatenation with other sequences.  This check is equivalent to the definition \"a number is something such that a sequence of such things is a valid single argument to the builtin function sum\", for example.  Totally weird types (e.g. ones that raise the \"wrong\" exception when summed to 0, such as, say, a ZeroDivisionError or ValueError &c) will propagate exception, but that's OK, let the user know ASAP that such crazy types are just not acceptable in good company;-); but, a \"vector\" that's summable to a scalar (Python's standard library doesn't have one, but of course they're popular as third party extensions) would also give the wrong result here, so (e.g.) this check should come after the \"not allowed to be iterable\" one (e.g., check that iter(x) raises TypeError, or for the presence of special method __iter__ -- if you're in 2.5 or earlier and thus need your own checks).  A brief glimpse at such complications may be sufficient to motivate you to rely instead on abstract base classes whenever feasible...;-).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  This is a good example where exceptions really shine. Just do what you would do with the numeric types and catch the TypeError from everything else.  But obviously, this only checks if a operation works, not whether it makes sense! The only real solution for that is to never mix types and always know exactly what typeclass your values belong to.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  Multiply the object by zero.  Any number times zero is zero.  Any other result means that the object is not a number (including exceptions)  def isNumber(x):     try:         return 0 == x*0     except:         return False   Using isNumber thusly will give the following output:  class A: pass   def foo(): return 1  for x in [1,1.4, A(), range(10), foo, foo()]:     answer = isNumber(x)     print '{answer} == isNumber({x})'.format(**locals())   Output:  True == isNumber(1) True == isNumber(1.4) False == isNumber(<__main__.A instance at 0x7ff52c15d878>) False == isNumber([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) False == isNumber(<function foo at 0x7ff52c121488>) True == isNumber(1)   There probably are some non-number objects in the world that define __mul__ to return zero when multiplied by zero but that is an extreme exception. This solution should cover all normal and sane code that you generate/encouter.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  To rephrase your question, you are trying to determine whether something is a collection or a single value. Trying to compare whether something is a vector or a number is comparing apples to oranges - I can have a vector of strings or numbers, and I can have a single string or single number. You are interested in how many you have (1 or more), not what type you actually have.  my solution for this problem is to check whether the input is a single value or a collection by checking the presence of __len__. For example:  def do_mult(foo, a_vector):     if hasattr(foo, '__len__'):         return sum([a*b for a,b in zip(foo, a_vector)])     else:         return [foo*b for b in a_vector]   Or, for the duck-typing approach, you can try iterating on foo first:  def do_mult(foo, a_vector):     try:         return sum([a*b for a,b in zip(foo, a_vector)])     except TypeError:         return [foo*b for b in a_vector]   Ultimately, it is easier to test whether something is vector-like than to test whether something is scalar-like. If you have values of different type (i.e. string, numeric, etc.) coming through, then the logic of your program may need some work - how did you end up trying to multiply a string by a numeric vector in the first place?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  Probably it's better to just do it the other way around: You check if it's a vector. If it is, you do a dot product and in all other cases you attempt scalar multiplication.  Checking for the vector is easy, since it should of your vector class type (or inherited from it). You could also just try first to do a dot-product, and if that fails (= it wasn't really a vector), then fall back to scalar multiplication.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  Just to add upon. Perhaps we can use a combination of isinstance and isdigit as follows to find whether a value is a number (int, float, etc)  if isinstance(num1, int) or isinstance(num1 , float) or num1.isdigit():     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  To summarize / evaluate existing methods:  Candidate    | type                      | delnan | mat | shrewmouse | ant6n ------------------------------------------------------------------------- 0            | <type 'int'>              |      1 |   1 |          1 |     1 0.0          | <type 'float'>            |      1 |   1 |          1 |     1 0j           | <type 'complex'>          |      1 |   1 |          1 |     0 Decimal('0') | <class 'decimal.Decimal'> |      1 |   0 |          1 |     1 True         | <type 'bool'>             |      1 |   1 |          1 |     1 False        | <type 'bool'>             |      1 |   1 |          1 |     1 ''           | <type 'str'>              |      0 |   0 |          0 |     0 None         | <type 'NoneType'>         |      0 |   0 |          0 |     0 '0'          | <type 'str'>              |      0 |   0 |          0 |     1 '1'          | <type 'str'>              |      0 |   0 |          0 |     1 []           | <type 'list'>             |      0 |   0 |          0 |     0 [1]          | <type 'list'>             |      0 |   0 |          0 |     0 [1, 2]       | <type 'list'>             |      0 |   0 |          0 |     0 (1,)         | <type 'tuple'>            |      0 |   0 |          0 |     0 (1, 2)       | <type 'tuple'>            |      0 |   0 |          0 |     0   (I came here by this question)  Code  #!/usr/bin/env python  \"\"\"Check if a variable is a number.\"\"\"  import decimal   def delnan_is_number(candidate):     import numbers     return isinstance(candidate, numbers.Number)   def mat_is_number(candidate):     return isinstance(candidate, (int, long, float, complex))   def shrewmouse_is_number(candidate):     try:         return 0 == candidate * 0     except:         return False   def ant6n_is_number(candidate):     try:         float(candidate)         return True     except:         return False  # Test candidates = (0, 0.0, 0j, decimal.Decimal(0),               True, False, '', None, '0', '1', [], [1], [1, 2], (1, ), (1, 2))  methods = [delnan_is_number, mat_is_number, shrewmouse_is_number, ant6n_is_number]  print(\"Candidate    | type                      | delnan | mat | shrewmouse | ant6n\") print(\"-------------------------------------------------------------------------\") for candidate in candidates:     results = [m(candidate) for m in methods]     print(\"{:<12} | {:<25} | {:>6} | {:>3} | {:>10} | {:>5}\"           .format(repr(candidate), type(candidate), *results))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  For the hypothetical vector class:  Suppose v is a vector, and we are multiplying it by x. If it makes sense to multiply each component of v by x, we probably meant that, so try that first. If not, maybe we can dot? Otherwise it's a type error.  EDIT -- the below code doesn't work, because 2*[0]==[0,0] instead of raising a TypeError. I leave it because it was commented-upon.  def __mul__( self, x ):     try:         return [ comp * x for comp in self ]     except TypeError:         return [ x * y for x, y in itertools.zip_longest( self, x, fillvalue = 0 )      ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  I had a similar issue, when implementing a sort of vector class. One way to check for a number is to just convert to one, i.e. by using  float(x)   This should reject cases where x cannot be converted to a number; but may also reject other kinds of number-like structures that could be valid, for example complex numbers.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is the most pythonic way to check if an object is a number?",
        "A_Content": "  You could use the isdigit() function.  >>> x = \"01234\" >>> a.isdigit() True >>> y = \"1234abcd\" >>> y.isdigit() False      ",
        "Language": "Python",
        "Tags": [
            "python",
            "types",
            "numbers"
        ],
        "URL": "https://stackoverflow.com/questions/3441358/what-is-the-most-pythonic-way-to-check-if-an-object-is-a-number",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Given an arbitrary python object, what's the best way to determine whether it is a number? Here is is defined as acts like a number in certain circumstances.  For example, say you are writing a vector class. If given another vector, you want to find the dot product. If given a scalar, you want to scale the whole vector.  Checking if something is int, float, long, bool is annoying and doesn't cover user-defined objects that might act like numbers. But, checking for __mul__, for example, isn't good enough because the vector class I just described would define __mul__, but it wouldn't be the kind of number I want.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  If its an OrderedDict() you can easily access the elements by indexing by getting the tuples of (key,value) pairs as follows  >>> import collections >>> d = collections.OrderedDict() >>> d['foo'] = 'python' >>> d['bar'] = 'spam' >>> d.items() [('foo', 'python'), ('bar', 'spam')] >>> d.items()[0] ('foo', 'python') >>> d.items()[1] ('bar', 'spam')   Note for Python 3.X  dict.items would return an iterable dict view object rather than a list. We need to wrap the call onto a list in order to make the indexing possible  >>> items = list(d.items()) >>> items [('foo', 'python'), ('bar', 'spam')] >>> items[0] ('foo', 'python') >>> items[1] ('bar', 'spam')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "117",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  Do you have to use an OrderedDict or do you specifically want a map-like type that's ordered in some way with fast positional indexing? If the latter, then consider one of Python's many sorted dict types (which orders key-value pairs based on key sort order). Some implementations also support fast indexing. For example, the sortedcontainers project has a SortedDict type for just this purpose.  >>> from sortedcontainers import SortedDict >>> sd = SortedDict() >>> sd['foo'] = 'python' >>> sd['bar'] = 'spam' >>> print sd.iloc[0] # Note that 'bar' comes before 'foo' in sort order. 'bar' >>> # If you want the value, then simple do a key lookup: >>> print sd[sd.iloc[1]] 'python'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  Here is a special case if you want the first entry (or close to it) in an OrderedDict, without creating a list:  >>> from collections import OrderedDict >>>  >>> d = OrderedDict() >>> d[\"foo\"] = \"one\" >>> d[\"bar\"] = \"two\" >>> d[\"baz\"] = \"three\" >>>  >>> d.iteritems().next() ('foo', 'one')   (The first time you say \"next()\", it really means \"first.\")  In my informal test in Python 2.7, iteritems().next() with a small OrderedDict is only a tiny bit faster than items()[0].  With an OrderedDict of 10,000 entries, iteritems().next() was about 200 times faster than items()[0].   BUT if you save the items() list once and then use the list a lot, that could be faster.  Or if you repeatedly { create an iteritems() iterator and step through it to to the position you want }, that could be slower.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  It is dramatically more efficient to use IndexedOrderedDict.  Following Niklas's comment, I have done a benchmark on OrderedDict and IndexedOrderedDict with 1000 entries.  In [1]: from numpy import * In [2]: from indexed import IndexedOrderedDict In [3]: id=IndexedOrderedDict(zip(arange(1000),random.random(1000))) In [4]: timeit id.keys()[56] 1000000 loops, best of 3: 969 ns per loop  In [8]: from collections import OrderedDict In [9]: od=OrderedDict(zip(arange(1000),random.random(1000))) In [10]: timeit od.keys()[56] 10000 loops, best of 3: 104 µs per loop   IndexedOrderedDict is ~100 times faster in indexing elements at specific position in this specific case.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  This community wiki attempts to collect existing answers.  Python 2.7  In python 2, the keys(), values(), and items() functions of OrderedDict return lists. Using values as an example, the simplest way is  d.values()[0]  # \"python\" d.values()[1]  # \"spam\"   For large collections where you only care about a single index, you can avoid creating the full list using the generator versions, iterkeys, itervalues and iteritems:  import itertools next(itertools.islice(d.itervalues(), 0, 1))  # \"python\" next(itertools.islice(d.itervalues(), 1, 2))  # \"spam\"   The indexed.py package provides IndexedOrderedDict, which is designed for this use case and will be the fastest option.  from indexed import IndexedOrderedDict d = IndexedOrderedDict({'foo':'python','bar':'spam'}) d.values()[0]  # \"python\" d.values()[1]  # \"spam\"   Using itervalues can be considerably faster for large dictionaries with random access:  $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 1000;   d = OrderedDict({i:i for i in range(size)})'  'i = randint(0, size-1); d.values()[i:i+1]' 1000 loops, best of 3: 259 usec per loop $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 10000;  d = OrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); d.values()[i:i+1]' 100 loops, best of 3: 2.3 msec per loop $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 100000; d = OrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); d.values()[i:i+1]' 10 loops, best of 3: 24.5 msec per loop  $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 1000;   d = OrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); next(itertools.islice(d.itervalues(), i, i+1))' 10000 loops, best of 3: 118 usec per loop $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 10000;  d = OrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); next(itertools.islice(d.itervalues(), i, i+1))' 1000 loops, best of 3: 1.26 msec per loop $ python2 -m timeit -s 'from collections import OrderedDict; from random import randint; size = 100000; d = OrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); next(itertools.islice(d.itervalues(), i, i+1))' 100 loops, best of 3: 10.9 msec per loop  $ python2 -m timeit -s 'from indexed import IndexedOrderedDict; from random import randint; size = 1000;   d = IndexedOrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); d.values()[i]' 100000 loops, best of 3: 2.19 usec per loop $ python2 -m timeit -s 'from indexed import IndexedOrderedDict; from random import randint; size = 10000;  d = IndexedOrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); d.values()[i]' 100000 loops, best of 3: 2.24 usec per loop $ python2 -m timeit -s 'from indexed import IndexedOrderedDict; from random import randint; size = 100000; d = IndexedOrderedDict({i:i for i in range(size)})' 'i = randint(0, size-1); d.values()[i]' 100000 loops, best of 3: 2.61 usec per loop  +--------+-----------+----------------+---------+ |  size  | list (ms) | generator (ms) | indexed | +--------+-----------+----------------+---------+ |   1000 | .259      | .118           | .00219  | |  10000 | 2.3       | 1.26           | .00224  | | 100000 | 24.5      | 10.9           | .00261  | +--------+-----------+----------------+---------+   Python 3.6  Python 3 has the same two basic options (list vs generator), but the dict methods return generators by default.  List method:  list(d.values())[0]  # \"python\" list(d.values())[1]  # \"spam\"   Generator method:  import itertools next(itertools.islice(d.values(), 0, 1))  # \"python\" next(itertools.islice(d.values(), 1, 2))  # \"spam\"   Python 3 dictionaries are an order of magnitude faster than python 2 and have similar speedups for using generators.  +--------+-----------+----------------+---------+ |  size  | list (ms) | generator (ms) | indexed | +--------+-----------+----------------+---------+ |   1000 | .0316     | .0165          | .00262  | |  10000 | .288      | .166           | .00294  | | 100000 | 3.53      | 1.48           | .00332  | +--------+-----------+----------------+---------+      ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Accessing Items In a ordereddict",
        "A_Content": "  It's a new era and with Python 3.6.1 dictionaries now retain their order. These semantics aren't explicit because that would require BDFL approval. But Raymond Hettinger is the next best thing (and funnier) and he makes a pretty strong case that dictionaries will be ordered for a very long time.  So now it's easy to create slices of a dictionary:  test_dict = {                 'first':  1,                 'second': 2,                 'third':  3,                 'fourth': 4             }  list(test_dict.items())[:2]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "collections",
            "dictionary",
            "python-3.x",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/10058140/accessing-items-in-a-ordereddict",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Lets say I have the following code:  import collections d = collections.OrderedDict() d['foo'] = 'python' d['bar'] = 'spam'   Is there a way I can access the items in a numbered manner, like:   d(0) #foo's Output d(1) #bar's Output      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Numpy: Get random set of rows from 2D array",
        "A_Content": "  >>> A = np.random.randint(5, size=(10,3)) >>> A array([[1, 3, 0],        [3, 2, 0],        [0, 2, 1],        [1, 1, 4],        [3, 2, 2],        [0, 1, 0],        [1, 3, 1],        [0, 4, 1],        [2, 4, 2],        [3, 3, 1]]) >>> idx = np.random.randint(10, size=2) >>> idx array([7, 6]) >>> A[idx,:] array([[0, 4, 1],        [1, 3, 1]])   Putting it together for a general case:  A[np.random.randint(A.shape[0], size=2), :]   For non replacement (numpy 1.7.0+):  A[np.random.choice(A.shape[0], 2, replace=False), :]   I do not believe there is a good way to generate random list without replacement before 1.7. Perhaps you can setup a small definition that ensures the two values are not the same.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array",
        "A_Votes": "112",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a very large 2D array which looks something like this:  a= [[a1, b1, c1],  [a2, b2, c2],  ...,  [an, bn, cn]]   Using numpy, is there an easy way to get a new 2D array with e.g. 2 random rows from the initial array a (without replacement)?  e.g.  b= [[a4,  b4,  c4],  [a99, b99, c99]]      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Numpy: Get random set of rows from 2D array",
        "A_Content": "  This is an old post, but this is what works best for me:  A[np.random.choice(A.shape[0], num_rows_2_sample, replace=False)]   change the replace=False to True to get the same thing, but with replacement.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a very large 2D array which looks something like this:  a= [[a1, b1, c1],  [a2, b2, c2],  ...,  [an, bn, cn]]   Using numpy, is there an easy way to get a new 2D array with e.g. 2 random rows from the initial array a (without replacement)?  e.g.  b= [[a4,  b4,  c4],  [a99, b99, c99]]      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Numpy: Get random set of rows from 2D array",
        "A_Content": "  Another option is to create a random mask if you just want to down-sample your data by a certain factor. Say I want to down-sample to 25% of my original data set, which is currently held in the array data_arr:  # generate random boolean mask the length of data # use p 0.75 for False and 0.25 for True mask = numpy.random.choice([False, True], len(data_arr), p=[0.75, 0.25])   Now you can call data_arr[mask] and return ~25% of the rows, randomly sampled.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a very large 2D array which looks something like this:  a= [[a1, b1, c1],  [a2, b2, c2],  ...,  [an, bn, cn]]   Using numpy, is there an easy way to get a new 2D array with e.g. 2 random rows from the initial array a (without replacement)?  e.g.  b= [[a4,  b4,  c4],  [a99, b99, c99]]      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Numpy: Get random set of rows from 2D array",
        "A_Content": "  If you need the same rows but just a random sample then,  import random new_array = random.sample(old_array,x)   Here x, has to be an 'int' defining the number of rows you want to randomly pick.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a very large 2D array which looks something like this:  a= [[a1, b1, c1],  [a2, b2, c2],  ...,  [an, bn, cn]]   Using numpy, is there an easy way to get a new 2D array with e.g. 2 random rows from the initial array a (without replacement)?  e.g.  b= [[a4,  b4,  c4],  [a99, b99, c99]]      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  To trigger a download you need to set Content-Disposition header:  from django.http import HttpResponse from wsgiref.util import FileWrapper  # generate the file response = HttpResponse(FileWrapper(myfile.getvalue()), content_type='application/zip') response['Content-Disposition'] = 'attachment; filename=myfile.zip' return response   If you don't want the file on disk you need to use StringIO  import cStringIO as StringIO  myfile = StringIO.StringIO() while not_finished:     # generate chunk     myfile.write(chunk)   Optionally you can set Content-Length header as well:  response['Content-Length'] = myfile.tell()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "103",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  You'll be happier creating a temporary file.  This saves a lot of memory.  When you have more than one or two users concurrently, you'll find the memory saving is very, very important.  You can, however, write to a StringIO object.  >>> import zipfile >>> import StringIO >>> buffer= StringIO.StringIO() >>> z= zipfile.ZipFile( buffer, \"w\" ) >>> z.write( \"idletest\" ) >>> z.close() >>> len(buffer.getvalue()) 778   The \"buffer\" object is file-like with a 778 byte ZIP archive.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  Why not make a tar file instead? Like so:  def downloadLogs(req, dir):     response = HttpResponse(content_type='application/x-gzip')     response['Content-Disposition'] = 'attachment; filename=download.tar.gz'     tarred = tarfile.open(fileobj=response, mode='w:gz')     tarred.add(dir)     tarred.close()      return response      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  Yes, you can use the zipfile module, zlib module or other compression modules to create a zip archive in memory.  You can make your view write the zip archive to the HttpResponse object that the Django view returns instead of sending a context to a template.  Lastly, you'll need to set the mimetype to the appropriate format to tell the browser to treat the response as a file.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  models.py  from django.db import models  class PageHeader(models.Model):     image = models.ImageField(upload_to='uploads')   views.py  from django.http import HttpResponse from StringIO import StringIO from models import * import os, mimetypes, urllib  def random_header_image(request):     header = PageHeader.objects.order_by('?')[0]     image = StringIO(file(header.image.path, \"rb\").read())     mimetype = mimetypes.guess_type(os.path.basename(header.image.name))[0]      return HttpResponse(image.read(), mimetype=mimetype)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  def download_zip(request,file_name):     filePath = '<path>/'+file_name     fsock = open(file_name_with_path,\"rb\")     response = HttpResponse(fsock, content_type='application/zip')     response['Content-Disposition'] = 'attachment; filename=myfile.zip'     return response   You can replace zip and content type as per your requirement.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  There is a code example at http://djangosnippets.org/snippets/365/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Generating file to download with Django",
        "A_Content": "  Same with in memory tgz archive:  import tarfile from io import BytesIO   def serve_file(request):     out = BytesIO()     tar = tarfile.open(mode = \"w:gz\", fileobj = out)     data = 'lala'.encode('utf-8')     file = BytesIO(data)     info = tarfile.TarInfo(name=\"1.txt\")     info.size = len(data)     tar.addfile(tarinfo=info, fileobj=file)     tar.close()      response = HttpResponse(out.getvalue(), content_type='application/tgz')     response['Content-Disposition'] = 'attachment; filename=myfile.tgz'     return response      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/908258/generating-file-to-download-with-django",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is it possible to make a zip archive and offer it to download, but still not save a file to the hard drive?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  Based on my experience, the numpy docstring conventions (PEP257 superset) are the most widely-spread followed conventions that are also supported by tools, such as Sphinx.   One example:  Parameters ---------- x : type     Description of parameter `x`.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  Since docstrings are free-form, it really depends on what you use to parse code to generate API documentation.  I would recommend getting familiar with the Sphinx markup, since it is widely used and is becoming the de-facto standard for documenting Python projects, in part because of the excellent readthedocs.org service. To paraphrase an example from the Sphinx documentation as a Python snippet:  def send_message(sender, recipient, message_body, priority=1):    '''    Send a message to a recipient     :param str sender: The person sending the message    :param str recipient: The recipient of the message    :param str message_body: The body of the message    :param priority: The priority of the message, can be a number 1-5    :type priority: integer or None    :return: the message id    :rtype: int    :raises ValueError: if the message_body exceeds 160 characters    :raises TypeError: if the message_body is not a basestring    '''   This markup supports cross-referencing between documents and more. Note that the Sphinx documentation uses (e.g.) :py:attr: whereas you can just use :attr: when documenting from the source code.  Naturally, there are other tools to document APIs. There's the more classic Doxygen which uses \\param commands but those are not specifically designed to document Python code like Sphinx is.  Note that there is a similar question with a similar answer in here...     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "57",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  Conventions:   PEP 257 Docstring Conventions PEP 287 reStructuredText Docstring Format   Tools:   Epydoc: Automatic API Documentation Generation for Python sphinx.ext.autodoc – Include documentation from docstrings PyCharm has some nice support for docstrings     Update: Since Python 3.5 you can use type hints which is a compact, machine-readable syntax:  from typing import Dict, Union  def foo(i: int, d: Dict[str, Union[str, int]]) -> int:     \"\"\"     Explanation: this function takes two arguments: `i` and `d`.     `i` is annotated simply as `int`. `d` is a dictionary with `str` keys     and values that can be either `str` or `int`.      The return type is `int`.      \"\"\"   The main advantage of this syntax is that it is defined by the language and that it's unambiguous, so tools like PyCharm can easily take advantage from it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "29",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  python doc strings are free-form, you can document it in any way you like.  Examples:  def mymethod(self, foo, bars):     \"\"\"     Does neat stuff!     Parameters:       foo - a foo of type FooType to bar with.       bars - The list of bars     \"\"\"   Now, there are some conventions, but python doesn't enforce any of them. Some projects have their own conventions. Some tools to work with docstrings also follow specific conventions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  If you plan to use Sphinx to document your code, it is capable of producing nicely formatted HTML docs for your parameters with their 'signatures' feature.  http://sphinx-doc.org/domains.html#signatures     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  The mainstream is, as other answers here already pointed out, probably going with the Sphinx way so that you can use Sphinx to generate those fancy documents later.  That being said, I personally go with inline comment style occasionally.  def complex(  # Form a complex number         real=0.0,  # the real part (default 0.0)         imag=0.0  # the imaginary part (default 0.0)         ):  # Returns a complex number.     \"\"\"Form a complex number.      I may still use the mainstream docstring notation,     if I foresee a need to use some other tools     to generate an HTML online doc later     \"\"\"     if imag == 0.0 and real == 0.0:         return complex_zero     other_code()   One more example here, with some tiny details documented inline:  def foo(  # Note that how I use the parenthesis rather than backslash \"\\\"           # to natually break the function definition into multiple lines.         a_very_long_parameter_name,             # The \"inline\" text does not really have to be at same line,             # when your parameter name is very long.             # Besides, you can use this way to have multiple lines doc too.             # The one extra level indentation here natually matches the             # original Python indentation style.             #             # This parameter represents blah blah             # blah blah             # blah blah         param_b,  # Some description about parameter B.             # Some more description about parameter B.             # As you probably noticed, the vertical alignment of pound sign             # is less a concern IMHO, as long as your docs are intuitively             # readable.         last_param,  # As a side note, you can use an optional comma for                      # your last parameter, as you can do in multi-line list                      # or dict declaration.         ):  # So this ending parenthesis occupying its own line provides a             # perfect chance to use inline doc to document the return value,             # despite of its unhappy face appearance. :)     pass   The benefits (as @mark-horvath already pointed out in another comment) are:   Most importantly, parameters and their doc always stay together, which brings the following benefits: Less typing (no need to repeat variable name) Easier maintenance upon changing/removing variable. There will never be some orphan parameter doc paragraph after you rename some parameter. and easier to find missing comment.    Now, some may think this style looks \"ugly\". But I would say \"ugly\" is a subjective word. A more neutual way is to say, this style is not mainstream so it may look less familiar to you, thus less comfortable. Again, \"comfortable\" is also a subjective word. But the point is, all the benefits described above are objective. You can not achieve them if you follow the standard way.  Hopefully some day in the future, there will be a doc generator tool which can also consume such inline style. That will drive the adoption.  PS: This answer is derived from my own preference of using inline comments whenever I see fit. I use the same inline style to document a dictionary too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to document a method with parameter(s)? [closed]",
        "A_Content": "  Docstrings are only useful within interactive environments, e.g. the Python shell. When documenting objects that are not going to be used interactively (e.g. internal objects, framework callbacks), you might as well use regular comments. Here’s a style I use for hanging indented comments off items, each on their own line, so you know that the comment is applying to:  def Recomputate \\   (     TheRotaryGyrator,       # the rotary gyrator to operate on     Computrons,       # the computrons to perform the recomputation with     Forthwith,       # whether to recomputate forthwith or at one's leisure   ) :   # recomputates the specified rotary gyrator with   # the desired computrons.   ... #end Recomputate   You can’t do this sort of thing with docstrings.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "documentation",
            "documentation-generation"
        ],
        "URL": "https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How to document methods with parameters using Python's documentation strings?  EDIT:  PEP 257 gives this example:  def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      Keyword arguments:     real -- the real part (default 0.0)     imag -- the imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Is this the convention used by most Python developers ?  Keyword arguments: <parameter name> -- Definition (default value if any)   I was expecting something a little bit more formal such as   def complex(real=0.0, imag=0.0):     \"\"\"Form a complex number.      @param: real The real part (default 0.0)     @param: imag The imaginary part (default 0.0)      \"\"\"     if imag == 0.0 and real == 0.0: return complex_zero     ...   Environement: Python 2.7.1     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  You need to use a raw string, double your slashes or use forward slashes instead:  r'C:\\Users\\expoperialed\\Desktop\\Python' 'C:\\\\Users\\\\expoperialed\\\\Desktop\\\\Python' 'C:/Users/expoperialed/Desktop/Python'   In regular python strings, the \\U character combination signals a extended Unicode codepoint escape.  You can hit any number of other issues, for any of the recognised escape sequences, such as \\a or t or \\x, etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "149",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  C:\\\\Users\\\\expoperialed\\\\Desktop\\\\Python This syntax worked for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  This usually happens in Python 3. One of the common reasons would be that while specifying your file path you need \"\\\\\" instead of \"\\\". As in:  filePath = \"C:\\\\User\\\\Desktop\\\\myFile\"   For Python 2, just using \"\\\" would work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  f = open('C:\\\\Users\\\\Pooja\\\\Desktop\\\\trolldata.csv')... Use '\\\\' for python program in python version 3 and above.. Error will be resolved..     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  All the three syntax work very well.  Another way is to first write  path = r'C:\\user\\...................' (whatever is the path for you)  and then passing it to os.chdir(path)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  Use this   os.chdir('C:/Users\\expoperialed\\Desktop\\Python')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
        "A_Content": "  I had the same error. Basically, I suspect that the path cannot start either with \"U\" or \"User\" after \"C:\\\". I changed my directory to \"c:\\file_name.png\" by putting the file that I want to access from python right under the 'c:\\' path.  In your case, if you have to access the \"python\" folder, perhaps reinstall the python, and change the installation path to something like \"c:\\python\". Otherwise, just avoid the \"...\\User...\" in your path, and put your project under C:.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "windows",
            "filenames"
        ],
        "URL": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The folder I want to get to is called python and is on my desktop.  I get the following error when I try to get to it  >>> os.chdir('C:\\Users\\expoperialed\\Desktop\\Python') SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Converting dict to OrderedDict",
        "A_Content": "  You are creating a dictionary first, then passing that dictionary to an OrderedDict. By the time you do that, the ordering is no longer going to be correct. dict is inherently not ordered.  Pass in a sequence of tuples instead:  ship = [(\"NAME\", \"Albatross\"),         (\"HP\", 50),         (\"BLASTERS\", 13),         (\"THRUSTERS\", 18),         (\"PRICE\", 250)] ship = collections.OrderedDict(ship)   What you see when you print the OrderedDict is it's representation, and it is entirely correct. OrderedDict([('PRICE', 250), ('HP', 50), ('NAME', 'Albatross'), ('BLASTERS', 13), ('THRUSTERS', 18)]) just shows you, in a reproducable representation, what the contents are of the OrderedDict.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/15711755/converting-dict-to-ordereddict",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am having some trouble using the collections.OrderedDict class. I am using Python 2.7 on Raspbian, the Debian distro for Raspberry Pi. I am trying to print two dictionaries in order for comparison (side-by-side) for a text-adventure. The order is essential to compare accurately. No matter what I try the dictionaries print in their usual unordered way.  Here's what I get when I do it on my RPi:  import collections  ship = {\"NAME\": \"Albatross\",          \"HP\":50,          \"BLASTERS\":13,          \"THRUSTERS\":18,          \"PRICE\":250}  ship = collections.OrderedDict(ship)  print ship # OrderedDict([('PRICE', 250), ('HP', 50), ('NAME', 'Albatross'), ('BLASTERS', 13), ('THRUSTERS', 18)])   Obviously there is something not right because it is printing the function call and putting the keys and value groups into a nested list...  This is what I got by running something similar on my PC:  import collections  Joe = {\"Age\": 28, \"Race\": \"Latino\", \"Job\": \"Nurse\"} Bob = {\"Age\": 25, \"Race\": \"White\", \"Job\": \"Mechanic\", \"Random\": \"stuff\"}  #Just for clarity: Joe = collections.OrderedDict(Joe) Bob = collections.OrderedDict(Bob)  print Joe # OrderedDict([('Age', 28), ('Race', 'Latino'), ('Job', 'Nurse')]) print Bob # OrderedDict([('Age', 25), ('Race', 'White'), ('Job', 'Mechanic'), ('Random', 'stuff')])   This time, it is in order, but it shouldn't be printing the other things though right? (The putting it into list and showing function call.)  Where am I making my error? It shouldn't be anything to do with the pi version of Python because it is just the Linux version.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Converting dict to OrderedDict",
        "A_Content": "  If you can't edit this part of code where your dict was defined you can still order it at any point in any way you want, like this:  from collections import OrderedDict  order_of_keys = [\"key1\", \"key2\", \"key3\", \"key4\", \"key5\"] list_of_tuples = [(key, your_dict[key]) for key in order_of_keys] your_dict = OrderedDict(list_of_tuples)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/15711755/converting-dict-to-ordereddict",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am having some trouble using the collections.OrderedDict class. I am using Python 2.7 on Raspbian, the Debian distro for Raspberry Pi. I am trying to print two dictionaries in order for comparison (side-by-side) for a text-adventure. The order is essential to compare accurately. No matter what I try the dictionaries print in their usual unordered way.  Here's what I get when I do it on my RPi:  import collections  ship = {\"NAME\": \"Albatross\",          \"HP\":50,          \"BLASTERS\":13,          \"THRUSTERS\":18,          \"PRICE\":250}  ship = collections.OrderedDict(ship)  print ship # OrderedDict([('PRICE', 250), ('HP', 50), ('NAME', 'Albatross'), ('BLASTERS', 13), ('THRUSTERS', 18)])   Obviously there is something not right because it is printing the function call and putting the keys and value groups into a nested list...  This is what I got by running something similar on my PC:  import collections  Joe = {\"Age\": 28, \"Race\": \"Latino\", \"Job\": \"Nurse\"} Bob = {\"Age\": 25, \"Race\": \"White\", \"Job\": \"Mechanic\", \"Random\": \"stuff\"}  #Just for clarity: Joe = collections.OrderedDict(Joe) Bob = collections.OrderedDict(Bob)  print Joe # OrderedDict([('Age', 28), ('Race', 'Latino'), ('Job', 'Nurse')]) print Bob # OrderedDict([('Age', 25), ('Race', 'White'), ('Job', 'Mechanic'), ('Random', 'stuff')])   This time, it is in order, but it shouldn't be printing the other things though right? (The putting it into list and showing function call.)  Where am I making my error? It shouldn't be anything to do with the pi version of Python because it is just the Linux version.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Converting dict to OrderedDict",
        "A_Content": "  Most of the time we go for OrderedDict when we required a custom order not a generic one like ASC etc.  Here is the proposed solution:  import collections ship = {\"NAME\": \"Albatross\",          \"HP\":50,          \"BLASTERS\":13,          \"THRUSTERS\":18,          \"PRICE\":250}  ship = collections.OrderedDict(ship)  print ship   new_dict = collections.OrderedDict() new_dict[\"NAME\"]=ship[\"NAME\"] new_dict[\"HP\"]=ship[\"HP\"] new_dict[\"BLASTERS\"]=ship[\"BLASTERS\"] new_dict[\"THRUSTERS\"]=ship[\"THRUSTERS\"] new_dict[\"PRICE\"]=ship[\"PRICE\"]   print new_dict   This will be output:  OrderedDict([('PRICE', 250), ('HP', 50), ('NAME', 'Albatross'), ('BLASTERS', 13), ('THRUSTERS', 18)]) OrderedDict([('NAME', 'Albatross'), ('HP', 50), ('BLASTERS', 13), ('THRUSTERS', 18), ('PRICE', 250)])   Note: The new sorted dictionaries maintain their sort order when entries are deleted. But when new keys are added, the keys are appended to the end and the sort is not maintained.(official doc)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ordereddictionary"
        ],
        "URL": "https://stackoverflow.com/questions/15711755/converting-dict-to-ordereddict",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am having some trouble using the collections.OrderedDict class. I am using Python 2.7 on Raspbian, the Debian distro for Raspberry Pi. I am trying to print two dictionaries in order for comparison (side-by-side) for a text-adventure. The order is essential to compare accurately. No matter what I try the dictionaries print in their usual unordered way.  Here's what I get when I do it on my RPi:  import collections  ship = {\"NAME\": \"Albatross\",          \"HP\":50,          \"BLASTERS\":13,          \"THRUSTERS\":18,          \"PRICE\":250}  ship = collections.OrderedDict(ship)  print ship # OrderedDict([('PRICE', 250), ('HP', 50), ('NAME', 'Albatross'), ('BLASTERS', 13), ('THRUSTERS', 18)])   Obviously there is something not right because it is printing the function call and putting the keys and value groups into a nested list...  This is what I got by running something similar on my PC:  import collections  Joe = {\"Age\": 28, \"Race\": \"Latino\", \"Job\": \"Nurse\"} Bob = {\"Age\": 25, \"Race\": \"White\", \"Job\": \"Mechanic\", \"Random\": \"stuff\"}  #Just for clarity: Joe = collections.OrderedDict(Joe) Bob = collections.OrderedDict(Bob)  print Joe # OrderedDict([('Age', 28), ('Race', 'Latino'), ('Job', 'Nurse')]) print Bob # OrderedDict([('Age', 25), ('Race', 'White'), ('Job', 'Mechanic'), ('Random', 'stuff')])   This time, it is in order, but it shouldn't be printing the other things though right? (The putting it into list and showing function call.)  Where am I making my error? It shouldn't be anything to do with the pi version of Python because it is just the Linux version.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is sys.maxint in Python 3?",
        "A_Content": "     The sys.maxint constant was removed, since there is no longer a limit   to the value of integers. However, sys.maxsize can be used as an   integer larger than any practical list or string index. It conforms to   the implementation’s “natural” integer size and is typically the same   as sys.maxint in previous releases on the same platform (assuming the   same build options).   http://docs.python.org/3.1/whatsnew/3.0.html#integers     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3",
        "A_Votes": "107",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've been trying to find out how to represent a maximum integer, and I've read to use \"sys.maxint\". However, in Python 3 when I call it I get:  AttributeError: module 'object' has no attribute 'maxint'      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is sys.maxint in Python 3?",
        "A_Content": "  As pointed out by others, Python 3's int does not have a maximum size, but if you just need something that's guaranteed to be higher than any other int value, then you can use the float value for Infinity, which you can get with float(\"inf\").     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been trying to find out how to represent a maximum integer, and I've read to use \"sys.maxint\". However, in Python 3 when I call it I get:  AttributeError: module 'object' has no attribute 'maxint'      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is sys.maxint in Python 3?",
        "A_Content": "  Python 3 ints do not have a maximum.  If your purpose is to determine the maximum size of an int in C when compiled the same way Python was, you can use the struct module to find out:  >>> import struct >>> platform_c_maxint = 2 ** (struct.Struct('i').size * 8 - 1) - 1   If you are curious about the internal implementation details of Python 3 int objects, Look at sys.int_info for bits per digit and digit size details. No normal program should care about these.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been trying to find out how to represent a maximum integer, and I've read to use \"sys.maxint\". However, in Python 3 when I call it I get:  AttributeError: module 'object' has no attribute 'maxint'      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is sys.maxint in Python 3?",
        "A_Content": "  Python 3 doesn't have limit on int. but you can use sys.maxsize as an integer larger than any practical list or string index.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been trying to find out how to represent a maximum integer, and I've read to use \"sys.maxint\". However, in Python 3 when I call it I get:  AttributeError: module 'object' has no attribute 'maxint'      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What is sys.maxint in Python 3?",
        "A_Content": "  Python 3.0 doesn't have sys.maxint any more since Python 3's ints are of arbitrary length. Instead of sys.maxint it has sys.maxsize; the maximum size of a positive sized size_t aka Py_ssize_t.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x"
        ],
        "URL": "https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been trying to find out how to represent a maximum integer, and I've read to use \"sys.maxint\". However, in Python 3 when I call it I get:  AttributeError: module 'object' has no attribute 'maxint'      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I tell Matplotlib to create a second (new) plot, then later plot on the old one?",
        "A_Content": "  If you find yourself doing things like this regularly it may be worth investigating the object-oriented interface to matplotlib. In your case:  import matplotlib.pyplot as plt import numpy as np  x = np.arange(5) y = np.exp(x) fig1, ax1 = plt.subplots() ax1.plot(x, y) ax1.set_title(\"Axis 1 title\") ax1.set_xlabel(\"X-label for axis 1\")  z = np.sin(x) fig2, (ax2, ax3) = plt.subplots(nrows=2, ncols=1) # two axes on figure ax2.plot(x, z) ax3.plot(x, -z)  w = np.cos(x) ax1.plot(x, w) # can continue plotting on the first axis   It is a little more verbose but it's much clearer and easier to keep track of, especially with several figures each with multiple subplots.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "figure"
        ],
        "URL": "https://stackoverflow.com/questions/6916978/how-do-i-tell-matplotlib-to-create-a-second-new-plot-then-later-plot-on-the-o",
        "A_Votes": "111",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to plot data, then create a new figure and plot data2, and finally come back to the original plot and plot data3, kinda like this:  import numpy as np import matplotlib as plt  x = arange(5) y = np.exp(5) plt.figure() plt.plot(x, y)  z = np.sin(x) plt.figure() plt.plot(x, z)  w = np.cos(x) plt.figure(\"\"\"first figure\"\"\") # Here's the part I need plt.plot(x, w)   FYI How do I tell matplotlib that I am done with a plot? does something similar, but not quite! It doesn't let me get access to that original plot.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I tell Matplotlib to create a second (new) plot, then later plot on the old one?",
        "A_Content": "  When you call figure, simply number the plot.  x = arange(5) y = np.exp(5) plt.figure(0) plt.plot(x, y)  z = np.sin(x) plt.figure(1) plt.plot(x, z)  w = np.cos(x) plt.figure(0) # Here's the part I need plt.plot(x, w)   Edit: Note that you can number the plots however you want (here, starting from 0) but if you don't provide figure with a number at all when you create a new one, the automatic numbering will start at 1 (\"Matlab Style\" according to the docs).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "figure"
        ],
        "URL": "https://stackoverflow.com/questions/6916978/how-do-i-tell-matplotlib-to-create-a-second-new-plot-then-later-plot-on-the-o",
        "A_Votes": "65",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to plot data, then create a new figure and plot data2, and finally come back to the original plot and plot data3, kinda like this:  import numpy as np import matplotlib as plt  x = arange(5) y = np.exp(5) plt.figure() plt.plot(x, y)  z = np.sin(x) plt.figure() plt.plot(x, z)  w = np.cos(x) plt.figure(\"\"\"first figure\"\"\") # Here's the part I need plt.plot(x, w)   FYI How do I tell matplotlib that I am done with a plot? does something similar, but not quite! It doesn't let me get access to that original plot.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I tell Matplotlib to create a second (new) plot, then later plot on the old one?",
        "A_Content": "  However, numbering starts at 1, so:  x = arange(5) y = np.exp(5) plt.figure(1) plt.plot(x, y)  z = np.sin(x) plt.figure(2) plt.plot(x, z)  w = np.cos(x) plt.figure(1) # Here's the part I need, but numbering starts at 1! plt.plot(x, w)   Also, if you have multiple axes on a figure, such as subplots, use the axes(h) command where h is the handle of the desired axes object to focus on that axes.  (don't have comment privileges yet, sorry for new answer!)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "figure"
        ],
        "URL": "https://stackoverflow.com/questions/6916978/how-do-i-tell-matplotlib-to-create-a-second-new-plot-then-later-plot-on-the-o",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to plot data, then create a new figure and plot data2, and finally come back to the original plot and plot data3, kinda like this:  import numpy as np import matplotlib as plt  x = arange(5) y = np.exp(5) plt.figure() plt.plot(x, y)  z = np.sin(x) plt.figure() plt.plot(x, z)  w = np.cos(x) plt.figure(\"\"\"first figure\"\"\") # Here's the part I need plt.plot(x, w)   FYI How do I tell matplotlib that I am done with a plot? does something similar, but not quite! It doesn't let me get access to that original plot.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I tell Matplotlib to create a second (new) plot, then later plot on the old one?",
        "A_Content": "  One way I found after some struggling is creating a function which gets data_plot matrix, file name and order as parameter to create boxplots from the given data in the ordered figure (different orders = different figures) and save it under the given file_name.  def plotFigure(data_plot,file_name,order):     fig = plt.figure(order, figsize=(9, 6))     ax = fig.add_subplot(111)     bp = ax.boxplot(data_plot)     fig.savefig(file_name, bbox_inches='tight')     plt.close()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "plot",
            "figure"
        ],
        "URL": "https://stackoverflow.com/questions/6916978/how-do-i-tell-matplotlib-to-create-a-second-new-plot-then-later-plot-on-the-o",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to plot data, then create a new figure and plot data2, and finally come back to the original plot and plot data3, kinda like this:  import numpy as np import matplotlib as plt  x = arange(5) y = np.exp(5) plt.figure() plt.plot(x, y)  z = np.sin(x) plt.figure() plt.plot(x, z)  w = np.cos(x) plt.figure(\"\"\"first figure\"\"\") # Here's the part I need plt.plot(x, w)   FYI How do I tell matplotlib that I am done with a plot? does something similar, but not quite! It doesn't let me get access to that original plot.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Python uses spacing at the start of the line to determine when code blocks start and end. Errors you can get are:  Unexpected indent. This line of code has more spaces at the start than the one before, but the one before is not the start of a subblock (e.g. if/while/for statement). All lines of code in a block must start with exactly the same string of whitespace. For instance:  >>> def a(): ...   print \"foo\" ...     print \"bar\" IndentationError: unexpected indent   This one is especially common when running python interactively: make sure you don't put any extra spaces before your commands. (Very annoying when copy-and-pasting example code!)  >>>   print \"hello\" IndentationError: unexpected indent   Unindent does not match any outer indentation level. This line of code has fewer spaces at the start than the one before, but equally it does not match any other block it could be part of. Python cannot decide where it goes. For instance, in the following, is the final print supposed to be part of the if clause, or not?  >>> if user == \"Joey\": ...     print \"Super secret powers enabled!\" ...   print \"Revealing super secrets\" IndendationError: unindent does not match any outer indentation level   Expected an indented block. This line of code has the same number of spaces at the start as the one before, but the last line was expected to start a block (e.g. if/while/for statement, function definition).  >>> def foo(): ... print \"Bar\" IndentationError: expected an indented block   If you want a function that doesn't do anything, use the \"no-op\" command pass:  >>> def foo(): ...     pass   Mixing tabs and spaces is allowed (at least on my version of Python), but Python assumes tabs are 8 characters long, which may not match your editor. Just say \"no\" to tabs. Most editors allow them to be automatically replaced by spaces.  The best way to avoid these issues is to always use a consistent number of spaces when you indent a subblock, and ideally use a good IDE that solves the problem for you. This will also make your code more readable.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "113",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  In Python, the spacing is very important, this gives the structure of your code blocks. This error happens when you mess up your code structure, for example like this :  def test_function() :    if 5 > 3 :    print \"hello\"   You may also have a mix of tabs and spaces in your file.  I suggest you use a python syntax aware editor like PyScripter, or Netbeans     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Run your code with the -tt option to find out if you are using tabs and spaces inconsistently      ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Turn on visible whitespace in whatever editor you are using and turn on replace tabs with spaces.  While you can use tabs with Python mixing tabs and space usually leads to the error you are experiencing. Replacing tabs with 4 spaces is the recommended approach for writing Python code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  By using correct indentation. Python is whitespace aware, so you need to follow its indentation guidlines for blocks or you'll get indentation errors.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Make sure you use the option \"insert spaces instead of tabs\" in your editor. Then you can choose you want a tab width of, for example 4. You can find those options in gedit under edit-->preferences-->editor.  bottom line: USE SPACES not tabs     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  This error can also occur when pasting something into the Python interpreter (terminal/console).   Note that the interpreter interprets an empty line as the end of an expression, so if you paste in something like  def my_function():     x = 3      y = 7   the interpreter will interpret the empty line before y = 7 as the end of the expression, i.e. that you're done defining your function, and the next line - y = 7 will have incorrect indentation because it is a new expression.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  If you're writing Python using Sublime and getting indentation errors,   view -> indentation -> convert indentation to spaces  The issue I'm describing is caused by the Sublime text editor. The same issue could be caused by other editors as well. Essentially, the issue has to do with Python wanting to treat indentations in terms of spaces versus various editors coding the indentations in terms of tabs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  There is a trick that always worked for me:  If you got and unexpected indent and you see that all the code is perfectly indented, try opening it with another editor and you will see what line of code is not indented.  It happened to me when used vim, gedit or editors like that.  Try to use only 1 editor for your code.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Simply copy your script and put under \"\"\" your entire code \"\"\" ...  specify this line in a variable.. like,  a = \"\"\" your python script \"\"\" print a.replace('here please press tab button it will insert some space\",\" here simply press space bar four times\") # here we replacing tab space by four char space as per pep 8 style guide..   now execute this code, in Sublime Editor using ctrl+b, now it will print indented code in console. that's it     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  If the indentation looks ok then have a look to see if your editor has a \"View Whitespace\" option. Enabling this should allow to find where spaces and tabs are mixed.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  Notepad++ was giving the tab space correct but the indentation problem was finally found in Sublime text editor.  Use Sublime text editor and go line by line     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  One issue which doesn't seem to have been mentioned is that this error can crop up due to a problem with the code that has nothing to do with indentation.  For example, take the following script:    def add_one(x):     try:         return x + 1 add_one(5)   This returns an IndentationError: unexpected unindent when the problem is of course a missing except: statement.  My point: check the code above where the unexpected (un)indent is reported!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "What to do with “Unexpected indent” in python?",
        "A_Content": "  All You need to do is remove spaces   or tab  spaces  from the start of following codes   from django.contrib import admin  # Register your models here. from .models import Myapp admin.site.register(Myapp)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-error"
        ],
        "URL": "https://stackoverflow.com/questions/1016814/what-to-do-with-unexpected-indent-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How do I rectify the error \"unexpected indent\" in python?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  It's used to send values into a generator that just yielded. Here is an artificial (non-useful) explanatory example:  >>> def double_inputs(): ...     while True: ...         x = yield ...         yield x * 2 ... >>> gen = double_inputs() >>> next(gen)       # run up to the first yield >>> gen.send(10)    # goes into 'x' variable 20 >>> next(gen)       # run up to the next yield >>> gen.send(6)     # goes into 'x' again 12 >>> next(gen)       # run up to the next yield >>> gen.send(94.3)  # goes into 'x' again 188.5999999999999   You can't do this just with yield.  As to why it's useful, one of the best use cases I've seen is Twisted's @defer.inlineCallbacks. Essentially it allows you to write a function like this:  @defer.inlineCallbacks def doStuff():     result = yield takesTwoSeconds()     nextResult = yield takesTenSeconds(result * 10)     defer.returnValue(nextResult / 10)   What happens is that takesTwoSeconds() returns a Deferred, which is a value promising a value will be computed later. Twisted can run the computation in another thread. When the computation is done, it passes it into the deferred, and the value then gets sent back to the doStuff() function. Thus the doStuff() can end up looking more or less like a normal procedural function, except it can be doing all sorts of computations & callbacks etc. The alternative before this functionality would be to do something like:  def doStuff():     returnDeferred = defer.Deferred()     def gotNextResult(nextResult):         returnDeferred.callback(nextResult / 10)     def gotResult(result):         takesTenSeconds(result * 10).addCallback(gotNextResult)     takesTwoSeconds().addCallback(gotResult)     return returnDeferred   It's a lot more convoluted and unwieldy.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "85",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  This function is to write coroutines  def coroutine():     for i in range(1, 10):         print(\"From generator {}\".format((yield i))) c = coroutine() c.send(None) try:     while True:         print(\"From user {}\".format(c.send(1))) except StopIteration: pass   prints  From generator 1 From user 2 From generator 1 From user 3 From generator 1 From user 4 ...   See how the control is being passed back and forth? Those are coroutines. They can be used for all kinds of cool things like asynch IO and similar.  Think of it like this, with a generator and no send, it's a one way street  ==========       yield      ======== Generator |   ------------> | User | ==========                  ========   But with send, it becomes a two way street  ==========       yield       ======== Generator |   ------------>  | User | ==========    <------------  ========                   send   Which opens up the door to the user customizing the generators behavior on the fly and the generator responding to the user.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "63",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  This may help someone. Here is a generator that is unaffected by send function. It takes in the number parameter on instantiation and is unaffected by send:  >>> def double_number(number): ...     while True: ...         number *=2  ...         yield number ...  >>> c = double_number(4) >>> c.send(None) 8 >>> c.next() 16 >>> c.next() 32 >>> c.send(8) 64 >>> c.send(8) 128 >>> c.send(8) 256   Now here is how you would do the same type of function using send, so on each iteration you can change the value of number:  def double_number(number):     while True:         number *= 2         number = yield number   Here is what that looks like, as you can see sending a new value for number changes the outcome:  >>> def double_number(number): ...     while True: ...         number *= 2 ...         number = yield number ... >>> c = double_number(4) >>>  >>> c.send(None) 8 >>> c.send(5) #10 10 >>> c.send(1500) #3000 3000 >>> c.send(3) #6 6   You can also put this in a for loop as such:  for x in range(10):     n = c.send(n)     print n   For more help check out this great tutorial.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "20",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  The send method implements coroutines.  If you haven't encountered Coroutines they are tricky to wrap your head around because they change the way a program flows. You can read a good tutorial for more details.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  Some use cases for using generator and send()  Generators with send() allow:   remembering internal state of the execution   what step we are at what is current status of our data  returning sequence of values receiving sequence of inputs   Here are some use cases:  Watched attempt to follow a recipe  Let us have a recipe, which expects predefined set of inputs in some order.  We may:   create a watched_attempt instance from the recipe let it get some inputs with each input return information about what is currently in the pot with each input check, that the input is the expected one (and fail if it is not)  def recipe():     pot = []     action = yield pot     assert action == (\"add\", \"water\")     pot.append(action[1])      action = yield pot     assert action == (\"add\", \"salt\")     pot.append(action[1])      action = yield pot     assert action == (\"boil\", \"water\")      action = yield pot     assert action == (\"add\", \"pasta\")     pot.append(action[1])      action = yield pot     assert action == (\"decant\", \"water\")     pot.remove(\"water\")      action = yield pot     assert action == (\"serve\")     pot = []     yield pot    To use it, first create the watched_attempt instance:  >>> watched_attempt = recipe()                                                                          >>> watched_attempt.next()                                                                                      []                                                                                                        The call to .next() is necessary to start execution of the generator.  Returned value shows, our pot is currently empty.  Now do few actions following what the recipe expects:  >>> watched_attempt.send((\"add\", \"water\"))                                                                      ['water']                                                                                               >>> watched_attempt.send((\"add\", \"salt\"))                                                                       ['water', 'salt']                                                                                       >>> watched_attempt.send((\"boil\", \"water\"))                                                                     ['water', 'salt']                                                                                       >>> watched_attempt.send((\"add\", \"pasta\"))                                                                      ['water', 'salt', 'pasta']                                                                              >>> watched_attempt.send((\"decant\", \"water\"))                                                                   ['salt', 'pasta']                                                                                       >>> watched_attempt.send((\"serve\"))                                                                             []    As we see, the pot is finally empty.  In case, one would not follow the recipe, it would fail (what could be desired outcome of watched attempt to cook something - just learning we did not pay enough attention when given instructions.  >>> watched_attempt = running.recipe()                                                                          >>> watched_attempt.next()                                                                                      []                                                                                                      >>> watched_attempt.send((\"add\", \"water\"))                                                                      ['water']                                                                                               >>> watched_attempt.send((\"add\", \"pasta\"))   --------------------------------------------------------------------------- AssertionError                            Traceback (most recent call last) <ipython-input-21-facdf014fe8e> in <module>() ----> 1 watched_attempt.send((\"add\", \"pasta\"))  /home/javl/sandbox/stack/send/running.py in recipe()      29      30     action = yield pot ---> 31     assert action == (\"add\", \"salt\")      32     pot.append(action[1])      33  AssertionError:   Notice, that:   there is linear sequence of expected steps the steps may differ (some are removing, some are adding to the pot) we manage to do all that by a functions/generator - no need to use complex class or similar strutures.   Running totals  We may use the generator to keep track of running total of values sent to it.  Any time we add a number, count of inputs and total sum is returned (valid for the moment previous input was send into it).  from collections import namedtuple  RunningTotal = namedtuple(\"RunningTotal\", [\"n\", \"total\"])   def runningtotals(n=0, total=0):     while True:         delta = yield RunningTotal(n, total)         if delta:             n += 1             total += delta   if __name__ == \"__main__\":     nums = [9, 8, None, 3, 4, 2, 1]      bookeeper = runningtotals()     print bookeeper.next()     for num in nums:         print num, bookeeper.send(num)   The output would look like:  RunningTotal(n=0, total=0) 9 RunningTotal(n=1, total=9) 8 RunningTotal(n=2, total=17) None RunningTotal(n=2, total=17) 3 RunningTotal(n=3, total=20) 4 RunningTotal(n=4, total=24) 2 RunningTotal(n=5, total=26) 1 RunningTotal(n=6, total=27)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  These confused me too.  Here is an example I made when trying to set up a generator which yields and accepts signals in alternating order (yield, accept, yield, accept)...  def echo_sound():      thing_to_say = '<Sound of wind on cliffs>'     while True:         thing_to_say = (yield thing_to_say)         thing_to_say = '...'.join([thing_to_say]+[thing_to_say[-6:]]*2)         yield None  # This is the return value of send.  gen = echo_sound()  print 'You are lost in the wilderness, calling for help.'  print '------' in_message = gen.next() print 'You hear: \"{}\"'.format(in_message) out_message = 'Hello!' print 'You yell \"{}\"'.format(out_message) gen.send(out_message)  print '------' in_message = gen.next() print 'You hear: \"{}\"'.format(in_message) out_message = 'Is anybody out there?' print 'You yell \"{}\"'.format(out_message) gen.send(out_message)  print '------' in_message = gen.next() print 'You hear: \"{}\"'.format(in_message) out_message = 'Help!' print 'You yell \"{}\"'.format(out_message) gen.send(out_message)   The output is:  You are lost in the wilderness, calling for help. ------ You hear: \"<Sound of wind on cliffs>\" You yell \"Hello!\" ------ You hear: \"Hello!...Hello!...Hello!\" You yell \"Is anybody out there?\" ------ You hear: \"Is anybody out there?...there?...there?\" You yell \"Help!\"      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "python generator “send” function purpose?",
        "A_Content": "  The send() method controls what the value to the left of the yield expression will be.  To understand how yield differs and what value it holds, lets first quickly refresh on the order python code is evaluated.  Section 6.15 Evaluation order     Python evaluates expressions from left to right. Notice that while evaluating an assignment, the right-hand side is evaluated before the left-hand side.   So an expression a = b the right hand side is evaluated first.  As the following demonstrates that a[p('left')] = p('right') the right hand side is evaluated first.  >>> def p(side): ...     print(side) ...     return 0 ...  >>> a[p('left')] = p('right') right left >>>  >>>  >>> [p('left'), p('right')] left right [0, 0]   What does yield do?, yield, suspends execution of the function and returns to the caller, and resumes execution at the same place it left off prior to suspending.  Where exactly is execution suspended? You might have guessed it already... the execution is suspended between the right and left side of the yield expression. So new_val = yield old_val the execution is halted at the = sign, and the value on the right (which is before suspending, and is also the value returned to the caller) may be something different then the value on the left (which is the value being assigned after resuming execution).   yield yields 2 values, one to the right and another to the left.  How do you control the value to the left hand side of the yield expression? via the .send() method.  6.2.9. Yield expressions     The value of the yield expression after resuming depends on the method which resumed the execution. If __next__() is used (typically via either a for or the next() builtin) then the result is None. Otherwise, if send() is used, then the result will be the value passed in to that method.      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Can someone give me an example of why the \"send\" function associated with Python generator function exists? I fully understand the yield function. However, the send function is confusing to me. The documentation on this method is convoluted:   generator.send(value)      Resumes the execution and “sends” a value into the generator function. The value argument becomes    the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value.   What does that mean? I thought value was the input to the function? The phrase \"The send() method returns the next value yielded by the generator\" seems to be also the exact purpose of the yield function; yield returns the next value yielded by the generator...  Can someone give me an example of a generator utilizing send that accomplishes something yield cannot?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  O(n):  The Counter() method is best (if your objects are hashable):  def compare(s, t):     return Counter(s) == Counter(t)   O(n log n):  The sorted() method is next best (if your objects are orderable):  def compare(s, t):     return sorted(s) == sorted(t)   O(n * n): If the objects are neither hashable, nor orderable, you can use equality:  def compare(s, t):     t = list(t)   # make a mutable copy     try:         for elem in s:             t.remove(elem)     except ValueError:         return False     return not t      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "152",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  You can sort both:  sorted(a) == sorted(b)   A counting sort could also be more efficient (but it requires the object to be hashable).  >>> from collections import Counter >>> a = [1, 2, 3, 1, 2, 3] >>> b = [3, 2, 1, 3, 2, 1] >>> print (Counter(a) == Counter(b)) True      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  If you know the items are always hashable, you can use a Counter() which is O(n) If you know the items are always sortable, you can use sorted() which is O(n log n)  In the general case you can't rely on being able to sort, or has the elements, so you need a fallback like this, which is unfortunately O(n^2)  len(a)==len(b) and all(a.count(i)==b.count(i) for i in a)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  The best way to do this is by sorting the lists and comparing them. (Using Counter won't work with objects that aren't hashable.) This is straightforward for integers:  sorted(a) == sorted(b)   It gets a little trickier with arbitrary objects. If you care about object identity, i.e., whether the same objects are in both lists, you can use the id() function as the sort key.  sorted(a, key=id) == sorted(b, key==id)   (In Python 2.x you don't actually need the key= parameter, because you can compare any object to any object. The ordering is arbitrary but stable, so it works fine for this purpose; it doesn't matter what order the objects are in, only that the ordering is the same for both lists. In Python 3, though, comparing objects of different types is disallowed in many circumstances -- for example, you can't compare strings to integers -- so if you will have objects of various types, best to explicitly use the object's ID.)  If you want to compare the objects in the list by value, on the other hand, first you need to define what \"value\" means for the objects. Then you will need some way to provide that as a key (and for Python 3, as a consistent type). One potential way that would work for a lot of arbitrary objects is to sort by their repr(). Of course, this could waste a lot of extra time and memory building repr() strings for large lists and so on.  sorted(a, key=repr) == sorted(b, key==repr)   If the objects are all your own types, you can define __lt__() on them so that the object knows how to compare itself to others. Then you can just sort them and not worry about the key= parameter. Of course you could also define __hash__() and use Counter, which will be faster.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  If the list contains items that are not hashable (such as a list of objects) you might be able to use the Counter Class and the id() function such as:  from collections import Counter ... if Counter(map(id,a)) == Counter(map(id,b)):     print(\"Lists a and b contain the same objects\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  If the comparison is to be performed in a testing context, use assertCountEqual(a, b) (py>=3.2) and assertItemsEqual(a, b) (2.7<=py<3.2).  Works on sequences of unhashable objects too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  https://docs.python.org/3.5/library/unittest.html#unittest.TestCase.assertCountEqual  assertCountEqual(first, second, msg=None)  Test that sequence first contains the same elements as second, regardless of their order. When they don’t, an error message listing the differences between the sequences will be generated.  Duplicate elements are not ignored when comparing first and second. It verifies whether each element has the same count in both sequences. Equivalent to: assertEqual(Counter(list(first)), Counter(list(second))) but works with sequences of unhashable objects as well.  New in version 3.2.   or in 2.7: https://docs.python.org/2.7/library/unittest.html#unittest.TestCase.assertItemsEqual     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  Let a,b lists  def ass_equal(a,b): try:     map(lambda x: a.pop(a.index(x)), b) # try to remove all the elements of b from a, on fail, throw exception     if len(a) == 0: # if a is empty, means that b has removed them all         return True  except:     return False # b failed to remove some items from a   No need to make them hashable or sort them.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to efficiently compare two unordered lists (not sets) in Python?",
        "A_Content": "  I hope the below piece of code might work in your case :-   if ((len(a) == len(b)) and    (all(i in a for i in b))):     print 'True' else:     print 'False'   This will ensure that all the elements in both the lists a & b are same, regardless of whether they are in same order or not.  For better understanding, refer to my answer in this question     ",
        "Language": "Python",
        "Tags": [
            "python",
            "algorithm",
            "list",
            "comparison"
        ],
        "URL": "https://stackoverflow.com/questions/7828867/how-to-efficiently-compare-two-unordered-lists-not-sets-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    a = [1, 2, 3, 1, 2, 3] b = [3, 2, 1, 3, 2, 1]   a & b should be considered equal, because they have exactly the same elements, only in different order.  The thing is, my actual lists will consist of objects (my class instances), not integers.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  Text printed to stderr will show up in httpd's error log when running under mod_wsgi. You can either use print directly, or use logging instead.  print >>sys.stderr, 'Goodbye, cruel world!'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "75",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  Here's a Django logging-based solution. It uses the DEBUG setting rather than actually checking whether or not you're running the development server, but if you find a better way to check for that it should be easy to adapt.  LOGGING = {     'version': 1,     'formatters': {         'verbose': {             'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'         },         'simple': {             'format': '%(levelname)s %(message)s'         },     },     'handlers': {         'console': {             'level': 'DEBUG',             'class': 'logging.StreamHandler',             'formatter': 'simple'         },         'file': {             'level': 'DEBUG',             'class': 'logging.FileHandler',             'filename': '/path/to/your/file.log',             'formatter': 'simple'         },     },     'loggers': {         'django': {             'handlers': ['file'],             'level': 'DEBUG',             'propagate': True,         },     } }  if DEBUG:     # make all loggers use the console.     for logger in LOGGING['loggers']:         LOGGING['loggers'][logger]['handlers'] = ['console']   see https://docs.djangoproject.com/en/dev/topics/logging/ for details.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "91",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  You can configure logging in your settings.py file.   One example:  if DEBUG:     # will output to your console     logging.basicConfig(         level = logging.DEBUG,         format = '%(asctime)s %(levelname)s %(message)s',     ) else:     # will output to logging file     logging.basicConfig(         level = logging.DEBUG,         format = '%(asctime)s %(levelname)s %(message)s',         filename = '/my_log_file.log',         filemode = 'a'     )   However that's dependent upon setting DEBUG, and maybe you don't want to have to worry about how it's set up. See this answer on How can I tell whether my Django application is running on development server or not? for a better way of writing that conditional. Edit: the example above is from a Django 1.1 project, logging configuration in Django has changed somewhat since that version.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "22",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  I use this:  logging.conf:  [loggers] keys=root,applog [handlers] keys=rotateFileHandler,rotateConsoleHandler  [formatters] keys=applog_format,console_format  [formatter_applog_format] format=%(asctime)s-[%(levelname)-8s]:%(message)s  [formatter_console_format] format=%(asctime)s-%(filename)s%(lineno)d[%(levelname)s]:%(message)s  [logger_root] level=DEBUG handlers=rotateFileHandler,rotateConsoleHandler  [logger_applog] level=DEBUG handlers=rotateFileHandler qualname=simple_example  [handler_rotateFileHandler] class=handlers.RotatingFileHandler level=DEBUG formatter=applog_format args=('applog.log', 'a', 10000, 9)  [handler_rotateConsoleHandler] class=StreamHandler level=DEBUG formatter=console_format args=(sys.stdout,)   testapp.py:  import logging import logging.config  def main():     logging.config.fileConfig('logging.conf')     logger = logging.getLogger('applog')      logger.debug('debug message')     logger.info('info message')     logger.warn('warn message')     logger.error('error message')     logger.critical('critical message')     #logging.shutdown()  if __name__ == '__main__':     main()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  You can do this pretty easily with tagalog (https://github.com/dorkitude/tagalog)  For instance, while the standard python module writes to a file object opened in append mode, the App Engine module (https://github.com/dorkitude/tagalog/blob/master/tagalog_appengine.py) overrides this behavior and instead uses logging.INFO.  To get this behavior in an App Engine project, one could simply do:  import tagalog.tagalog_appengine as tagalog tagalog.log('whatever message', ['whatever','tags'])   You could extend the module yourself and overwrite the log function without much difficulty.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python/Django: log to console under runserver, log to file under Apache",
        "A_Content": "  This works quite well in my local.py, saves me messing up the regular logging:  from .settings import *  LOGGING['handlers']['console'] = {     'level': 'DEBUG',     'class': 'logging.StreamHandler',     'formatter': 'verbose' } LOGGING['loggers']['foo.bar'] = {     'handlers': ['console'],     'propagate': False,     'level': 'DEBUG', }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "logging"
        ],
        "URL": "https://stackoverflow.com/questions/4558879/python-django-log-to-console-under-runserver-log-to-file-under-apache",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How can I send trace messages to the console (like print) when I'm running my Django app under manage.py runserver, but have those messages sent to a log file when I'm running the app under Apache?  I reviewed Django logging and although I was impressed with its flexibility and configurability for advanced uses, I'm still stumped with how to handle my simple use-case.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  Update:  Selenium team fixed in latest version. For almost all environments the fix is:      pip install -U selenium   Unclear at which version it was fixed (apparently r13122), but certainly by 2.26.0 (current at time of update) it is fixed.    This error means that _wait_until_connectable is timing out, because for some reason, the code cannot connect to the webdriver extension that has been loaded into the firefox.  I have just reported an error to selenium where I am getting this error because I'm trying to use a proxy and only 2 of the 4 configured changes in the profile have been accepted by firefox, so the proxy isn't configured to talk to the extension. Not sure why this is happening...  https://github.com/seleniumhq/selenium-google-code-issue-archive/issues/2061     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "131",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  I had the same issue after upgrading Ubuntu to 12.04.  The issue was on the package side and has been fixed in the latest version of the library. Just update the selenium library. For almost all Python environments this is:  pip install -U selenium      ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  I faced the same problem with FF 32.0 and Selenium selenium-2.42.1-py2.7.egg. Tried to update selenium, but it is already the latest version. The solution was to downgrade Firefox to version 30. Here is the process:  #Download version 30 for Linux (This is the 64 bit) wget http://ftp.mozilla.org/pub/mozilla.org/firefox/releases/30.0/linux-x86_64/en-US/firefox-30.0.tar.bz2  tar -xjvf firefox-30.0.tar.bz2 #Remove the old version sudo rm -rf /opt/firefox* sudo mv firefox /opt/firefox30.0 #Create a permanent link sudo ln -sf /opt/firefox30.0/firefox /usr/bin/firefox   This solved all the problems, and this combination works better !     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  As an extension to Jeff Hoye's answer, a more 'Pythonic' way would be to subclass webdriver.firefox.firefox_profile.FirefoxProfile as follows:  class CygwinFirefoxProfile(FirefoxProfile):     @property     def path(self):         path = self.profile_dir         # Do stuff to the path as described in Jeff Hoye's answer         return path   Then, to create your driver:  driver = webdriver.Firefox(firefox_profile=CygwinFirefoxProfile())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  If pip install -U selenium doesn't work (it didn't, in my case), try downgrading your Firefox to a previous version.  I had Firefox 49.0 and downgraded to 45.0 to make sure the version is supported by selenium. It worked perfectly then.  Here's a fast way to downgrade to Firefox 45.0:  sudo apt-get install firefox=45.0.2+build1-0ubuntu1   Hope this helps.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  If you are running webdriver from cygwin, the problem is that the path to the profile is still in POSIX format which confuses windows programs.  My solution uses cygpath to convert it into Windows format.  in this file/method: selenium.webdriver.firefox.firefox_binary.launch_browser():  replace:      self._start_from_profile_path(self.profile.path)   with:      from subprocess import Popen, PIPE     proc = Popen(['cygpath','-d',self.profile.path], stdout=PIPE, stderr=PIPE)     stdout, stderr = proc.communicate()     path = stdout.split('\\n', 1)[0]      self._start_from_profile_path(path)     #self._start_from_profile_path(self.profile.path)   Since Python is not even close to my primary programming language, if someone can recommend a more pythonic approach maybe we can push it into the distribution.  It sure would be handy if it worked in cygwin right out of the box.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  I had the same problem and believed it was the wrong combo of selenium / Firefox. Turned out that my .mozilla/ folder permissions were only accessible to the root user. Doing chmod 770 ~/.mozilla/ did the trick. I would suggest making sure this is not the issue before troubleshooting further.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  pip install -U selenium  I had this same issue with Firefox 34.0.5 (Dec 1, 2014) and upgrading Selenium from 2.42.1 to 2.44.0 resolved my issue.  However, I've have since seen this issue again, I think with 2.44.0, and another upgrade fixed it.  So I'm wondering if it might be fixed by simply uninstalling and then re-installing.  If so, I'm not sure what that would indicate the underlying problem is.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  I was using selenium 2.53 and firefox version 55.0. I solved this issue by installing the older version of firefox (46.0.1) since selenium 2.53 will not work for firefox version 47.0 & above.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Selenium: FirefoxProfile exception Can't load the profile",
        "A_Content": "  This is not a proper solution but worked for me, if somebody can improve I would be glad to know. I just run my script as root: sudo python myscript.py. I guess I can solve by changing the profile default file or directory could work.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "firefox",
            "selenium",
            "selenium-webdriver",
            "webdriver"
        ],
        "URL": "https://stackoverflow.com/questions/6682009/selenium-firefoxprofile-exception-cant-load-the-profile",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Per this previous question I updated Selenium to version 2.0.1 But now I have another error, even when the profile files exist under /tmp/webdriver-py-profilecopy:      File \"/home/sultan/Repository/Django/monitor/app/request.py\", line 236, in perform     browser = Firefox(profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/webdriver.py\", line 46, in __init__     self.binary, timeout),   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/extension_connection.py\", line 46, in __init__     self.binary.launch_browser(self.profile)   File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 44, in launch_browser     self._wait_until_connectable()    File \"/usr/local/lib/python2.7/dist-packages/selenium/webdriver/firefox/firefox_binary.py\", line 87, in _wait_until_connectable     raise WebDriverException(\"Can't load the profile. Profile Dir : %s\" % self.profile.path) selenium.common.exceptions.WebDriverException: Can't load the profile. Profile Dir : /tmp/webdriver-py-profilecopy   What is wrong? How can I resolve this issue?      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Handling very large numbers in Python",
        "A_Content": "  Python supports a \"bignum\" integer type which can work with arbitrarily large numbers. In Python 2.5+, this type is called long and is separate from the int type, but the interpreter will automatically use whichever is more appropriate. In Python 3.0+, the int type has been dropped completely.  That's just an implementation detail, though — as long as you have version 2.5 or better, just perform standard math operations and any number which exceeds the boundaries of 32-bit math will be automatically (and transparently) converted to a bignum.  You can find all the gory details in PEP 0237.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "optimization",
            "largenumber"
        ],
        "URL": "https://stackoverflow.com/questions/538551/handling-very-large-numbers-in-python",
        "A_Votes": "124",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've been considering fast poker hand evaluation in Python. It occurred to me that one way to speed the process up would be to represent all the card faces and suits as prime numbers and multiply them together to represent the hands. To whit:  class PokerCard:     faces = '23456789TJQKA'     suits = 'cdhs'     facePrimes = [11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 53, 59, 61]     suitPrimes = [2, 3, 5, 7]   AND      def HashVal(self):       return PokerCard.facePrimes[self.cardFace] * PokerCard.suitPrimes[self.cardSuit]   This would give each hand a numeric value that, through modulo could tell me how many kings are in the hand or how many hearts. For example, any hand with five or more clubs in it would divide evenly by 2^5; any hand with four kings would divide evenly by 59^4, etc.  The problem is that a seven-card hand like AcAdAhAsKdKhKs has a hash value of approximately 62.7 quadrillion, which would take considerably more than 32 bits to represent internally. Is there a way to store such large numbers in Python that will allow me to perform arithmetic operations on it?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Handling very large numbers in Python",
        "A_Content": "  python supports arbitrarily large integers naturally:  example:     >>> 10**1000 100000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   000000000000000000000000000000000000000000000000000000000000000000000000000000   00000000000000000000000000000000000000000000000000000000000000000   You could even get, for example of a huge integer value, fib(4000000).  But still it does not (for now) supports an arbitrarily large float !!  If you need one big, large, float then check up on the decimal Module. There are examples of use on these foruns: OverflowError: (34, 'Result too large')  Another reference: http://docs.python.org/2/library/decimal.html  You can even using the gmpy module if you need a speed-up (which is likely to be of your interest): Handling big numbers in code  Another reference: https://code.google.com/p/gmpy/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "optimization",
            "largenumber"
        ],
        "URL": "https://stackoverflow.com/questions/538551/handling-very-large-numbers-in-python",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been considering fast poker hand evaluation in Python. It occurred to me that one way to speed the process up would be to represent all the card faces and suits as prime numbers and multiply them together to represent the hands. To whit:  class PokerCard:     faces = '23456789TJQKA'     suits = 'cdhs'     facePrimes = [11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 53, 59, 61]     suitPrimes = [2, 3, 5, 7]   AND      def HashVal(self):       return PokerCard.facePrimes[self.cardFace] * PokerCard.suitPrimes[self.cardSuit]   This would give each hand a numeric value that, through modulo could tell me how many kings are in the hand or how many hearts. For example, any hand with five or more clubs in it would divide evenly by 2^5; any hand with four kings would divide evenly by 59^4, etc.  The problem is that a seven-card hand like AcAdAhAsKdKhKs has a hash value of approximately 62.7 quadrillion, which would take considerably more than 32 bits to represent internally. Is there a way to store such large numbers in Python that will allow me to perform arithmetic operations on it?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Handling very large numbers in Python",
        "A_Content": "  You could do this for the fun of it, but other than that it's not a good idea.  It would not speed up anything I can think of.   Getting the cards in a hand will be an integer factoring operation which is much more expensive than just accessing an array. Adding cards would be multiplication, and removing cards division, both of large multi-word numbers, which are more expensive operations than adding or removing elements from lists. The actual numeric value of a hand will tell you nothing.  You will need to factor the primes and follow the Poker rules to compare two hands.  h1 < h2 for such hands means nothing.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "optimization",
            "largenumber"
        ],
        "URL": "https://stackoverflow.com/questions/538551/handling-very-large-numbers-in-python",
        "A_Votes": "27",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been considering fast poker hand evaluation in Python. It occurred to me that one way to speed the process up would be to represent all the card faces and suits as prime numbers and multiply them together to represent the hands. To whit:  class PokerCard:     faces = '23456789TJQKA'     suits = 'cdhs'     facePrimes = [11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 53, 59, 61]     suitPrimes = [2, 3, 5, 7]   AND      def HashVal(self):       return PokerCard.facePrimes[self.cardFace] * PokerCard.suitPrimes[self.cardSuit]   This would give each hand a numeric value that, through modulo could tell me how many kings are in the hand or how many hearts. For example, any hand with five or more clubs in it would divide evenly by 2^5; any hand with four kings would divide evenly by 59^4, etc.  The problem is that a seven-card hand like AcAdAhAsKdKhKs has a hash value of approximately 62.7 quadrillion, which would take considerably more than 32 bits to represent internally. Is there a way to store such large numbers in Python that will allow me to perform arithmetic operations on it?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Handling very large numbers in Python",
        "A_Content": "  python supports arbitrarily large integers naturally:  In [1]: 59**3*61**4*2*3*5*7*3*5*7 Out[1]: 62702371781194950 In [2]: _ % 61**4 Out[2]: 0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "optimization",
            "largenumber"
        ],
        "URL": "https://stackoverflow.com/questions/538551/handling-very-large-numbers-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've been considering fast poker hand evaluation in Python. It occurred to me that one way to speed the process up would be to represent all the card faces and suits as prime numbers and multiply them together to represent the hands. To whit:  class PokerCard:     faces = '23456789TJQKA'     suits = 'cdhs'     facePrimes = [11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 53, 59, 61]     suitPrimes = [2, 3, 5, 7]   AND      def HashVal(self):       return PokerCard.facePrimes[self.cardFace] * PokerCard.suitPrimes[self.cardSuit]   This would give each hand a numeric value that, through modulo could tell me how many kings are in the hand or how many hearts. For example, any hand with five or more clubs in it would divide evenly by 2^5; any hand with four kings would divide evenly by 59^4, etc.  The problem is that a seven-card hand like AcAdAhAsKdKhKs has a hash value of approximately 62.7 quadrillion, which would take considerably more than 32 bits to represent internally. Is there a way to store such large numbers in Python that will allow me to perform arithmetic operations on it?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  I will refer you to paramiko  see this question  ssh = paramiko.SSHClient() ssh.connect(server, username=username, password=password) ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(cmd_to_execute)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "133",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  Or you can just use commands.getstatusoutput:     commands.getstatusoutput(\"ssh machine 1 'your script'\")   I used it extensively and it works great.  In Python 2.6+, use subprocess.check_output.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  Have you had a look at Fabric? It allows you to do all sorts of remote stuff over SSH using python.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "24",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  I found paramiko to be a bit too low-level, and Fabric not especially well-suited to being used as a library, so I put together my own library called spur that uses paramiko to implement a slightly nicer interface:  import spur  shell = spur.SshShell(hostname=\"localhost\", username=\"bob\", password=\"password1\") result = shell.run([\"echo\", \"-n\", \"hello\"]) print result.output # prints hello   If you need to run inside a shell:  shell.run([\"sh\", \"-c\", \"echo -n hello\"])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  All have already stated (recommended) using paramiko and I am just sharing a python code (API one may say) that will allow you to execute multiple commands in one go.  to execute commands on different node use : Commands().run_cmd(host_ip, list_of_commands)     You will see one TODO, which I have kept to stop the execution if any of the commands fails to execute, I don't know how to do it. please share your knowledge   #!/usr/bin/python  import os import sys import select import paramiko import time   class Commands:     def __init__(self, retry_time=0):         self.retry_time = retry_time         pass      def run_cmd(self, host_ip, cmd_list):         i = 0         while True:         # print(\"Trying to connect to %s (%i/%i)\" % (self.host, i, self.retry_time))         try:             ssh = paramiko.SSHClient()             ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())             ssh.connect(host_ip)             break         except paramiko.AuthenticationException:             print(\"Authentication failed when connecting to %s\" % host_ip)             sys.exit(1)         except:             print(\"Could not SSH to %s, waiting for it to start\" % host_ip)             i += 1             time.sleep(2)          # If we could not connect within time limit         if i >= self.retry_time:             print(\"Could not connect to %s. Giving up\" % host_ip)             sys.exit(1)         # After connection is successful         # Send the command         for command in cmd_list:             # print command             print \"> \" + command             # execute commands             stdin, stdout, stderr = ssh.exec_command(command)             # TODO() : if an error is thrown, stop further rules and revert back changes             # Wait for the command to terminate             while not stdout.channel.exit_status_ready():                 # Only print data if there is data to read in the channel                 if stdout.channel.recv_ready():                     rl, wl, xl = select.select([ stdout.channel ], [ ], [ ], 0.0)                     if len(rl) > 0:                         tmp = stdout.channel.recv(1024)                         output = tmp.decode()                         print output          # Close SSH connection         ssh.close()         return  def main(args=None):     if args is None:         print \"arguments expected\"     else:         # args = {'<ip_address>', <list_of_commands>}         mytest = Commands()         mytest.run_cmd(host_ip=args[0], cmd_list=args[1])     return   if __name__ == \"__main__\":     main(sys.argv[1:])   Thank you!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  I have used paramiko a bunch (nice) and pxssh (also nice).  I would recommend either.  They work a little differently but have a relatively large overlap in usage.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Perform commands over ssh with Python",
        "A_Content": "  Have a look at spurplus, a wrapper we developed around spur that provides type annotations and some minor gimmicks (reconnecting SFTP, md5 etc.): https://pypi.org/project/spurplus/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ssh"
        ],
        "URL": "https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm writing a script to automate some command line commands in Python. At the moment I'm doing calls thus:  cmd = \"some unix command\" retcode = subprocess.call(cmd,shell=True)   However I need to run some commands on a remote machine. Manually, I would log in using ssh and then run the commands. How would I automate this in Python? I need to log in with a (known) password to the remote machine, so I can't just use cmd = ssh user@remotehost, I'm wondering if there's a module I should be using?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  No. Python Strings are immutable.     >>> s='355879ACB6' >>> s[4:4] = '-' Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: 'str' object does not support item assignment   It is, however, possible to create a new string that has the inserted character:  >>> s[:4] + '-' + s[4:] '3558-79ACB6'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "159",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  This seems very easy:  >>> hash = \"355879ACB6\" >>> hash = hash[:4] + '-' + hash[4:] >>> print hash 3558-79ACB6   However if you like something like a function do as this:  def insert_dash(string, index):     return string[:index] + '-' + string[index:]  print insert_dash(\"355879ACB6\", 5)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  As strings are immutable another way to do this would be to turn the string into a list, which can then be indexed and modified without any slicing trickery.  However, to get the list back to a string you'd have to use .join() using an empty string.    >>> hash = '355879ACB6' >>> hashlist = list(hash) >>> hashlist.insert(4, '-') >>> ''.join(hashlist) '3558-79ACB6'   I am not sure how this compares as far as performance, but I do feel it's easier on the eyes than the other solutions. ;-)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  I have made a very useful method to add a string in a certain position in Python:  def insertChar(mystring, position, chartoinsert ):     longi = len(mystring)     mystring   =  mystring[:position] + chartoinsert + mystring[position:]      return mystring     for example:  a = \"Jorgesys was here!\"  def insertChar(mystring, position, chartoinsert ):     longi = len(mystring)     mystring   =  mystring[:position] + chartoinsert + mystring[position:]      return mystring     #Inserting some characters with a defined position:     print(insertChar(a,0, '-'))     print(insertChar(a,9, '@'))     print(insertChar(a,14, '%'))      we will have as an output:  -Jorgesys was here! Jorgesys @was here! Jorgesys was h%ere!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  Simple function to accomplish this:  def insert_str(string, str_to_insert, index):     return string[:index] + str_to_insert + string[index:]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Add string in a certain position in Python",
        "A_Content": "  If you want many inserts  from rope.base.codeanalyze import ChangeCollector  c = ChangeCollector(code) c.add_change(5, 5, '<span style=\"background-color:#339999;\">') c.add_change(10, 10, '</span>') rend_code = c.get_changed()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string"
        ],
        "URL": "https://stackoverflow.com/questions/5254445/add-string-in-a-certain-position-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there any function in Python that I can use to insert a value in a certain position of a string?  Something like this:  \"3655879ACB6\" then in position 4 add \"-\" to become \"3655-879ACB6\"     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python dict how to create key or append an element to key?",
        "A_Content": "  Use dict.setdefault():  dic.setdefault(key,[]).append(value)   help(dict.setdefault):      setdefault(...)         D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/12905999/python-dict-how-to-create-key-or-append-an-element-to-key",
        "A_Votes": "152",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'm new to Python. Not only am I learning its functions, types and such, but also I am trying to learn the Pythonic ways to do things and hence my question:  I have an empty dictionary. Name: dict_x It is to have keys of which values are lists.  From a separate iteration, I obtain a key (ex: key_123), and an item (a tuple) to place in the list of dict_x's value key_123.   If this key already exists, I want to append this item. If this key does not exist, I want to create it with an empty list and then append to it or just create it with a tuple in it.  In future when again this key comes up, since it exists, I want the value to be appended again.  My code consists of this:     Get key and value.      See if NOT key exists in dict_x.      and if not create it: dict_x[key] == []      Afterwards: dict_x[key].append(value)   Is this the way to do it? Shall I try to use try/except blocks?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python dict how to create key or append an element to key?",
        "A_Content": "  Here are the various ways to do this so you can compare how it looks and choose what you like.  I've ordered them in a way that I think is most \"pythonic\", and commented the pros and cons that might not be obvious at first glance:  Using collections.defaultdict:  import collections dict_x = collections.defaultdict(list)  ...  dict_x[key].append(value)   Pros: Probably best performance.  Cons: Not available in Python 2.4.x.  Using dict().setdefault():  dict_x = {}  ...  dict_x.setdefault(key, []).append(value)   Cons: Inefficient creation of unused list()s.  Using try ... except:  dict_x = {}  ...  try:     values = dict_x[key] except KeyError:     values = dict_x[key] = [] values.append(value)   Or:  try:     dict_x[key].append(value) except KeyError:     dict_x[key] = [value]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/12905999/python-dict-how-to-create-key-or-append-an-element-to-key",
        "A_Votes": "41",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python. Not only am I learning its functions, types and such, but also I am trying to learn the Pythonic ways to do things and hence my question:  I have an empty dictionary. Name: dict_x It is to have keys of which values are lists.  From a separate iteration, I obtain a key (ex: key_123), and an item (a tuple) to place in the list of dict_x's value key_123.   If this key already exists, I want to append this item. If this key does not exist, I want to create it with an empty list and then append to it or just create it with a tuple in it.  In future when again this key comes up, since it exists, I want the value to be appended again.  My code consists of this:     Get key and value.      See if NOT key exists in dict_x.      and if not create it: dict_x[key] == []      Afterwards: dict_x[key].append(value)   Is this the way to do it? Shall I try to use try/except blocks?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python dict how to create key or append an element to key?",
        "A_Content": "  You can use a defaultdict for this.   from collections import defaultdict d = defaultdict(list) d['key'].append('mykey')   This is slightly more efficient than setdefault since you don't end up creating new lists that you don't end up using. Every call to setdefault is going to create a new list, even if the item already exists in the dictionary.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/12905999/python-dict-how-to-create-key-or-append-an-element-to-key",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python. Not only am I learning its functions, types and such, but also I am trying to learn the Pythonic ways to do things and hence my question:  I have an empty dictionary. Name: dict_x It is to have keys of which values are lists.  From a separate iteration, I obtain a key (ex: key_123), and an item (a tuple) to place in the list of dict_x's value key_123.   If this key already exists, I want to append this item. If this key does not exist, I want to create it with an empty list and then append to it or just create it with a tuple in it.  In future when again this key comes up, since it exists, I want the value to be appended again.  My code consists of this:     Get key and value.      See if NOT key exists in dict_x.      and if not create it: dict_x[key] == []      Afterwards: dict_x[key].append(value)   Is this the way to do it? Shall I try to use try/except blocks?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Python dict how to create key or append an element to key?",
        "A_Content": "  You can use defaultdict in collections.  An example from doc:  s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = defaultdict(list) for k, v in s:     d[k].append(v)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-2.7",
            "python-3.x",
            "dictionary"
        ],
        "URL": "https://stackoverflow.com/questions/12905999/python-dict-how-to-create-key-or-append-an-element-to-key",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm new to Python. Not only am I learning its functions, types and such, but also I am trying to learn the Pythonic ways to do things and hence my question:  I have an empty dictionary. Name: dict_x It is to have keys of which values are lists.  From a separate iteration, I obtain a key (ex: key_123), and an item (a tuple) to place in the list of dict_x's value key_123.   If this key already exists, I want to append this item. If this key does not exist, I want to create it with an empty list and then append to it or just create it with a tuple in it.  In future when again this key comes up, since it exists, I want the value to be appended again.  My code consists of this:     Get key and value.      See if NOT key exists in dict_x.      and if not create it: dict_x[key] == []      Afterwards: dict_x[key].append(value)   Is this the way to do it? Shall I try to use try/except blocks?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  You'll probably want to consider implementing it another way. Are you aware of the weakref module?  (Edited) The Python weakref module lets you keep references, dictionary references, and proxies to objects without having those references count in the reference counter. They're like symbolic links.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  If the object is still there, this can be done by ctypes:  import ctypes a = \"hello world\" print ctypes.cast(id(a), ctypes.py_object).value   output:  hello world   If you don't know whether the object is still there, this is a recipe for undefined behavior and weird crashes or worse, so be careful.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  Short answer, you can't.  Long answer, you can maintain a dict for mapping IDs to objects, or look the ID up by exhaustive search of gc.get_objects(), but this will create one of two problems: either the dict's reference will keep the object alive and prevent GC, or (if it's a WeakValue dict or you use gc.get_objects()) the ID may be deallocated and reused for a completely different object.  Basically, if you're trying to do this, you probably need to do something differently.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  You can use the gc module to get all the objects currently tracked by the Python garbage collector.  import gc  def objects_by_id(id_):     for obj in gc.get_objects():         if id(obj) == id_:             return obj     raise Exception(\"No found\")      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "32",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  Just mentioning this module for completeness. This code by Bill Bumgarner includes a C extension to do what you want without looping throughout every object in existence.  The code for the function is quite straightforward. Every Python object is represented in C by a pointer to a PyObject struct. Because id(x) is just the memory address of this struct, we can retrieve the Python object just by treating x as a pointer to a PyObject, then calling Py_INCREF to tell the garbage collector that we're creating a new reference to the object.  static PyObject * di_di(PyObject *self, PyObject *args) {     PyObject *obj;     if (!PyArg_ParseTuple(args, \"l:di\", &obj))         return  NULL;      Py_INCREF(obj);     return obj; }   If the original object no longer exists then the result is undefined. It may crash, but it could also return a reference to a new object that's taken the location of the old one in memory.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  eGenix mxTools library does provide such a function, although marked as \"expert-only\": mx.Tools.makeref(id)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Get object by id()?",
        "A_Content": "  This will do:  a = 0 id_a = id(a) variables = {**locals(), **globals()} for var in variables:     exec('var_id=id(%s)'%var)     if var_id == id_a:         exec('the_variable=%s'%var) print(the_variable) print(id(the_variable))   But I suggest implementing a more decent way.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/1396668/get-object-by-id",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Let's say I have an id of a Python object, which I retrieved by doing id(thing). How do I find thing again by the id number I was given?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Every object has a __dict__ variable containing all the variables and its values in it.  Try this  >>> hi_obj = hi() >>> hi_obj.__dict__.keys()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Use vars()  class Foo(object):     def __init__(self):         self.a = 1         self.b = 2  vars(Foo()) #==> {'a': 1, 'b': 2} vars(Foo()).keys() #==> ['a', 'b']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "79",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  You normally can't get instance attributes given just a class, at least not without instantiating the class. You can get instance attributes given an instance, though, or class attributes given a class. See the 'inspect' module. You can't get a list of instance attributes because instances really can have anything as attribute, and -- as in your example -- the normal way to create them is to just assign to them in the __init__ method.  An exception is if your class uses slots, which is a fixed list of attributes that the class allows instances to have. Slots are explained in http://www.python.org/2.2.3/descrintro.html, but there are various pitfalls with slots; they affect memory layout, so multiple inheritance may be problematic, and inheritance in general has to take slots into account, too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Both the Vars() and dict methods will work for the example the OP posted, but they won't work for \"loosely\" defined objects like:  class foo:   a = 'foo'   b = 'bar'   To print all non-callable attributes, you can use the following function:  def printVars(object):     for i in [v for v in dir(object) if not callable(getattr(object,v))]:         print '\\n%s:' % i         exec('print object.%s\\n\\n') % i      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  You can also test if an object has a specific variable with:  >>> hi_obj = hi() >>> hasattr(hi_obj, \"some attribute\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Suggest  >>> print vars.__doc__ vars([object]) -> dictionary  Without arguments, equivalent to locals(). With an argument, equivalent to object.__dict__.   In otherwords, it essentially just wraps __dict__      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Your example shows \"instance variables\",  not really class variables.  Look in hi_obj.__class__.__dict__.items() for the class variables, along with other other class members like member functions and the containing module.  class Hi( object ):     class_var = ( 23, 'skidoo' ) # class variable     def __init__( self ):         self.ii = \"foo\" # instance variable         self.jj = \"bar\"   Class variables are shared by all instances of the class.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to get instance variables in Python?",
        "A_Content": "  Although not directly an answer to the OP question, there is a pretty sweet way of finding out what variables are in scope in a function. take a look at this code:  >>> def f(x, y):     z = x**2 + y**2     sqrt_z = z**.5     return sqrt_z  >>> f.func_code.co_varnames ('x', 'y', 'z', 'sqrt_z') >>>    The func_code attribute has all kinds of interesting things in it. It allows you todo some cool stuff. Here is an example of how I have have used this:  def exec_command(self, cmd, msg, sig):      def message(msg):         a = self.link.process(self.link.recieved_message(msg))         self.exec_command(*a)      def error(msg):         self.printer.printInfo(msg)      def set_usrlist(msg):         self.client.connected_users = msg      def chatmessage(msg):         self.printer.printInfo(msg)      if not locals().has_key(cmd): return     cmd = locals()[cmd]      try:         if 'sig' in cmd.func_code.co_varnames and \\                        'msg' in cmd.func_code.co_varnames:              cmd(msg, sig)         elif 'msg' in cmd.func_code.co_varnames:              cmd(msg)         else:             cmd()     except Exception, e:         print '\\n-----------ERROR-----------'         print 'error: ', e         print 'Error proccessing: ', cmd.__name__         print 'Message: ', msg         print 'Sig: ', sig         print '-----------ERROR-----------\\n'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "methods",
            "instance-variables"
        ],
        "URL": "https://stackoverflow.com/questions/109087/how-to-get-instance-variables-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Is there a built-in method in Python to get an array of all a class' instance variables? For example, if I have this code:  class hi:   def __init__(self):     self.ii = \"foo\"     self.kk = \"bar\"   Is there a way for me to do this:  >>> mystery_method(hi) [\"ii\", \"kk\"]   Edit: I originally had asked for class variables erroneously.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  Note that --pylab is deprecated and has been removed from newer builds of IPython, so the accepted answer will no longer work. The recommended way to enable inline plotting in the IPython Notebook is now to run:  %matplotlib inline import matplotlib.pyplot as plt   See this post from the ipython-dev mailing list for more details.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "161",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  Edit:Pylab has been deprecated please see the current accepted answer  Ok, It seems the answer is to start ipython notebook with --pylab=inline.  so ipython notebook --pylab=inline This has it do what I saw earlier and what I wanted it to do.  Sorry about the vague original question.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  With your import matplotlib.pyplot as plt just add  plt.show()   and it will show all stored plots.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "25",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  simple after importing the matplotlib you have execute one magic if you have started the ipython as like this   ipython notebook   %matplotlib inline    run this command everything will be shown perfectly      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  start ipython with ipython notebook --pylab inline ,then graph will show inline.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "in Ipython notebook / Jupyter, Pandas is not displaying the graph I try to plot",
        "A_Content": "  All you need to do is to import matplotlib.      import matplotlib.pyplot as plt       ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "ipython",
            "jupyter-notebook"
        ],
        "URL": "https://stackoverflow.com/questions/10511024/in-ipython-notebook-jupyter-pandas-is-not-displaying-the-graph-i-try-to-plot",
        "A_Votes": "-2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to plot some data using pandas in Ipython Notebook, and while it gives me the object, it doesn't actually plot the graph itself. So it looks like this:  In [7]:  pledge.Amount.plot()  Out[7]:  <matplotlib.axes.AxesSubplot at 0x9397c6c>   The graph should follow after that, but it simply doesn't appear. I have imported matplotlib, so that's not the problem. Is there any other module I need to import?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  print ', '.join(names)   This, like it sounds, just takes all the elements of the list and joins them with ', '.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "142",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  Here is a simple one.   names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print(*names, sep=\", \")   the star unpacks the list and return every element in the list.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "35",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  General solution, works on arrays of non-strings:  >>> print str(names)[1:-1] 'Sam', 'Peter', 'James', 'Julian', 'Ann'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  If the input array is Integer type then you need to first convert array into string type array and then use join method for joining with , or space whatever you want. e.g:  >>> arr = [1, 2, 4, 3] >>> print(\", \" . join(arr)) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: sequence item 0: expected string, int found >>> sarr = [str(a) for a in arr] >>> print(\", \" . join(sarr)) 1, 2, 4, 3 >>>   Direct using of join which will join the integer and string will throw error as show above.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  There are two answers , First is use 'sep' setting  >>> print(*names, sep = ', ')   The other is below  >>> print(', '.join(names))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  This is what you need  \", \".join(names)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  You need to loop through the list and use end=\" \"to keep it on one line  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]     index=0     for name in names:         print(names[index], end=\", \")         index += 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Print list without brackets in a single row",
        "A_Content": "  I don't know if this is efficient as others but simple logic always works:  import sys name = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] for i in range(0, len(names)):     sys.stdout.write(names[i])     if i != len(names)-1:         sys.stdout.write(\", \")   Output:     Sam, Peter, James, Julian, Ann      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list"
        ],
        "URL": "https://stackoverflow.com/questions/11178061/print-list-without-brackets-in-a-single-row",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a list in Python e.g.  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   I want to print the array in a single line without the normal \" []  names = [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"] print (names)   Will give the output as;  [\"Sam\", \"Peter\", \"James\", \"Julian\", \"Ann\"]   That is not the format I want instead I want it to be like this;  Sam, Peter, James, Julian, Ann   Note: It must be in a single row.     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is max slower than sort?",
        "A_Content": "  You have to be very careful when using the timeit module in Python.  python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'a.sort();a[-1]'   Here the initialisation code runs once to produce a randomised array a. Then the rest of the code is run several times. The first time it sorts the array, but every other time you are calling the sort method on an already sorted array. Only the fastest time is returned, so you are actually timing how long it takes Python to sort an already sorted array.  Part of Python's sort algorithm is to detect when the array is already partly or completely sorted. When completely sorted it simply has to scan once through the array to detect this and then it stops.  If instead you tried:  python -m timeit -s 'import random;a=range(100000);random.shuffle(a)' 'sorted(a)[-1]'   then the sort happens on every timing loop and you can see that the time for sorting an array is indeed much longer than to just find the maximum value.  Edit: @skyking's answer explains the part I left unexplained: a.sort() knows it is working on a list so can directly access the elements. max(a) works on any arbitrary iterable so has to use generic iteration.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "max",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/35014951/why-is-max-slower-than-sort",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I've found that max is slower than the sort function in Python 2 and 3.  Python 2  $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 239 usec per loop $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'max(a)'         1000 loops, best of 3: 342 usec per loop   Python 3  $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 252 usec per loop $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'max(a)' 1000 loops, best of 3: 371 usec per loop   Why is max (O(n)) slower than the sort function (O(nlogn))?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is max slower than sort?",
        "A_Content": "  First off, note that max() uses the iterator protocol, while list.sort() uses ad-hoc code. Clearly, using an iterator is an important overhead, that's why you are observing that difference in timings.  However, apart from that, your tests are not fair. You are running a.sort() on the same list more than once. The algorithm used by Python is specifically designed to be fast for already (partially) sorted data. Your tests are saying that the algorithm is doing its job well.  These are fair tests:  $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'max(a[:])' 1000 loops, best of 3: 227 usec per loop $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'a[:].sort()' 100 loops, best of 3: 2.28 msec per loop   Here I'm creating a copy of the list every time. As you can see, the order of magnitude of the results are different: micro- vs milliseconds, as we would expect.  And remember: big-Oh specifies an upper bound! The lower bound for Python's sorting algorithm is Ω(n). Being O(n log n) does not automatically imply that every run takes a time proportional to n log n. It does not even imply that it needs to be slower than a O(n) algorithm, but that's another story. What's important to understand is that in some favorable cases, an O(n log n) algorithm may run in O(n) time or less.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "max",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/35014951/why-is-max-slower-than-sort",
        "A_Votes": "88",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've found that max is slower than the sort function in Python 2 and 3.  Python 2  $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 239 usec per loop $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'max(a)'         1000 loops, best of 3: 342 usec per loop   Python 3  $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 252 usec per loop $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'max(a)' 1000 loops, best of 3: 371 usec per loop   Why is max (O(n)) slower than the sort function (O(nlogn))?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Why is max slower than sort?",
        "A_Content": "  This could be because l.sort is a member of list while max is a generic function. This means that l.sort can rely on the internal representation of list while max will have to go through generic iterator protocol.  This makes that each element fetch for l.sort is faster than each element fetch that max does.  I assume that if you instead use sorted(a) you will get the result slower than max(a).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "sorting",
            "max",
            "python-internals"
        ],
        "URL": "https://stackoverflow.com/questions/35014951/why-is-max-slower-than-sort",
        "A_Votes": "31",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I've found that max is slower than the sort function in Python 2 and 3.  Python 2  $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 239 usec per loop $ python -m timeit -s 'import random;a=range(10000);random.shuffle(a)' 'max(a)'         1000 loops, best of 3: 342 usec per loop   Python 3  $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'a.sort();a[-1]' 1000 loops, best of 3: 252 usec per loop $ python3 -m timeit -s 'import random;a=list(range(10000));random.shuffle(a)' 'max(a)' 1000 loops, best of 3: 371 usec per loop   Why is max (O(n)) slower than the sort function (O(nlogn))?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to do exponential and logarithmic curve fitting in Python? I found only polynomial fitting",
        "A_Content": "  For fitting y = A + B log x, just fit y against (log x).  >>> x = numpy.array([1, 7, 20, 50, 79]) >>> y = numpy.array([10, 19, 30, 35, 51]) >>> numpy.polyfit(numpy.log(x), y, 1) array([ 8.46295607,  6.61867463]) # y ≈ 8.46 log(x) + 6.62     For fitting y = AeBx, take the logarithm of both side gives log y = log A + Bx. So fit (log y) against x.   Note that fitting (log y) as if it is linear will emphasize small values of y, causing large deviation for large y. This is because polyfit (linear regression) works by minimizing ∑i (ΔY)2 = ∑i (Yi − Ŷi)2. When Yi = log yi, the residues ΔYi = Δ(log yi) ≈ Δyi / |yi|. So even if polyfit makes a very bad decision for large y, the \"divide-by-|y|\" factor will compensate for it, causing polyfit favors small values.  This could be alleviated by giving each entry a \"weight\" proportional to y. polyfit supports weighted-least-squares via the w keyword argument.  >>> x = numpy.array([10, 19, 30, 35, 51]) >>> y = numpy.array([1, 7, 20, 50, 79]) >>> numpy.polyfit(x, numpy.log(y), 1) array([ 0.10502711, -0.40116352]) #    y ≈ exp(-0.401) * exp(0.105 * x) = 0.670 * exp(0.105 * x) # (^ biased towards small values) >>> numpy.polyfit(x, numpy.log(y), 1, w=numpy.sqrt(y)) array([ 0.06009446,  1.41648096]) #    y ≈ exp(1.42) * exp(0.0601 * x) = 4.12 * exp(0.0601 * x) # (^ not so biased)   Note that Excel, LibreOffice and most scientific calculators typically use the unweighted (biased) formula for the exponential regression / trend lines. If you want your results to be compatible with these platforms, do not include the weights even if it provides better results.    Now, if you can use scipy, you could use scipy.optimize.curve_fit to fit any model without transformations.  For y = A + B log x the result is the same as the transformation method:  >>> x = numpy.array([1, 7, 20, 50, 79]) >>> y = numpy.array([10, 19, 30, 35, 51]) >>> scipy.optimize.curve_fit(lambda t,a,b: a+b*numpy.log(t),  x,  y) (array([ 6.61867467,  8.46295606]),   array([[ 28.15948002,  -7.89609542],         [ -7.89609542,   2.9857172 ]])) # y ≈ 6.62 + 8.46 log(x)   For y = AeBx, however, we can get a better fit since it computes Δ(log y) directly. But we need to provide an initialize guess so curve_fit can reach the desired local minimum.  >>> x = numpy.array([10, 19, 30, 35, 51]) >>> y = numpy.array([1, 7, 20, 50, 79]) >>> scipy.optimize.curve_fit(lambda t,a,b: a*numpy.exp(b*t),  x,  y) (array([  5.60728326e-21,   9.99993501e-01]),  array([[  4.14809412e-27,  -1.45078961e-08],         [ -1.45078961e-08,   5.07411462e+10]])) # oops, definitely wrong. >>> scipy.optimize.curve_fit(lambda t,a,b: a*numpy.exp(b*t),  x,  y,  p0=(4, 0.1)) (array([ 4.88003249,  0.05531256]),  array([[  1.01261314e+01,  -4.31940132e-02],         [ -4.31940132e-02,   1.91188656e-04]])) # y ≈ 4.88 exp(0.0553 x). much better.        ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "curve-fitting",
            "linear-regression"
        ],
        "URL": "https://stackoverflow.com/questions/3433486/how-to-do-exponential-and-logarithmic-curve-fitting-in-python-i-found-only-poly",
        "A_Votes": "135",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).  I use Python and Numpy and for polynomial fitting there is a function polyfit(). But I found no such functions for exponential and logarithmic fitting.   Are there any? Or how to solve it otherwise?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to do exponential and logarithmic curve fitting in Python? I found only polynomial fitting",
        "A_Content": "  You can also fit a set of a data to whatever function you like using curve_fit from scipy.optimize.  For example if you want to fit an exponential function (from the documentation):  import numpy as np import matplotlib.pyplot as plt from scipy.optimize import curve_fit  def func(x, a, b, c):     return a * np.exp(-b * x) + c  x = np.linspace(0,4,50) y = func(x, 2.5, 1.3, 0.5) yn = y + 0.2*np.random.normal(size=len(x))  popt, pcov = curve_fit(func, x, yn)   And then if you want to plot, you could do:  plt.figure() plt.plot(x, yn, 'ko', label=\"Original Noised Data\") plt.plot(x, func(x, *popt), 'r-', label=\"Fitted Curve\") plt.legend() plt.show()   (Note: the * in front of popt when you plot will expand out the terms into the a, b, and c that func is expecting.)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "curve-fitting",
            "linear-regression"
        ],
        "URL": "https://stackoverflow.com/questions/3433486/how-to-do-exponential-and-logarithmic-curve-fitting-in-python-i-found-only-poly",
        "A_Votes": "79",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).  I use Python and Numpy and for polynomial fitting there is a function polyfit(). But I found no such functions for exponential and logarithmic fitting.   Are there any? Or how to solve it otherwise?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to do exponential and logarithmic curve fitting in Python? I found only polynomial fitting",
        "A_Content": "  I was having some trouble with this so let me be very explicit so noobs like me can understand.  Lets say that we have a data file or something like that   # -*- coding: utf-8 -*-  import matplotlib.pyplot as plt from scipy.optimize import curve_fit import numpy as np import sympy as sym  \"\"\" Generate some data, let's imagine that you already have this.  \"\"\" x = np.linspace(0, 3, 50) y = np.exp(x)  \"\"\" Plot your data \"\"\" plt.plot(x, y, 'ro',label=\"Original Data\")  \"\"\" brutal force to avoid errors \"\"\"     x = np.array(x, dtype=float) #transform your data in a numpy array of floats  y = np.array(y, dtype=float) #so the curve_fit can work  \"\"\" create a function to fit with your data. a, b, c and d are the coefficients that curve_fit will calculate for you.  In this part you need to guess and/or use mathematical knowledge to find a function that resembles your data \"\"\" def func(x, a, b, c, d):     return a*x**3 + b*x**2 +c*x + d  \"\"\" make the curve_fit \"\"\" popt, pcov = curve_fit(func, x, y)  \"\"\" The result is: popt[0] = a , popt[1] = b, popt[2] = c and popt[3] = d of the function, so f(x) = popt[0]*x**3 + popt[1]*x**2 + popt[2]*x + popt[3]. \"\"\" print \"a = %s , b = %s, c = %s, d = %s\" % (popt[0], popt[1], popt[2], popt[3])  \"\"\" Use sympy to generate the latex sintax of the function \"\"\" xs = sym.Symbol('\\lambda')     tex = sym.latex(func(xs,*popt)).replace('$', '') plt.title(r'$f(\\lambda)= %s$' %(tex),fontsize=16)  \"\"\" Print the coefficients and plot the funcion. \"\"\"  plt.plot(x, func(x, *popt), label=\"Fitted Curve\") #same as line above \\/ #plt.plot(x, popt[0]*x**3 + popt[1]*x**2 + popt[2]*x + popt[3], label=\"Fitted Curve\")   plt.legend(loc='upper left') plt.show()   the result is: a = 0.849195983017 , b = -1.18101681765, c = 2.24061176543, d = 0.816643894816       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "curve-fitting",
            "linear-regression"
        ],
        "URL": "https://stackoverflow.com/questions/3433486/how-to-do-exponential-and-logarithmic-curve-fitting-in-python-i-found-only-poly",
        "A_Votes": "34",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).  I use Python and Numpy and for polynomial fitting there is a function polyfit(). But I found no such functions for exponential and logarithmic fitting.   Are there any? Or how to solve it otherwise?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How to do exponential and logarithmic curve fitting in Python? I found only polynomial fitting",
        "A_Content": "  Well I guess you can always use:  np.log   -->  natural log np.log10 -->  base 10 np.log2  -->  base 2     Slightly modifying IanVS's answer:  import numpy as np import matplotlib.pyplot as plt from scipy.optimize import curve_fit  def func(x, a, b, c):   #return a * np.exp(-b * x) + c   return a * np.log(b * x) + c  x = np.linspace(1,5,50)   # changed boundary conditions to avoid division by 0 y = func(x, 2.5, 1.3, 0.5) yn = y + 0.2*np.random.normal(size=len(x))  popt, pcov = curve_fit(func, x, yn)  plt.figure() plt.plot(x, yn, 'ko', label=\"Original Noised Data\") plt.plot(x, func(x, *popt), 'r-', label=\"Fitted Curve\") plt.legend() plt.show()   This results in the following graph:       ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy",
            "scipy",
            "curve-fitting",
            "linear-regression"
        ],
        "URL": "https://stackoverflow.com/questions/3433486/how-to-do-exponential-and-logarithmic-curve-fitting-in-python-i-found-only-poly",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).  I use Python and Numpy and for polynomial fitting there is a function polyfit(). But I found no such functions for exponential and logarithmic fitting.   Are there any? Or how to solve it otherwise?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  You can simply del your custom name to set it back to the default:  >>> True = False >>> True False >>> del True >>> True True >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "138",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  This works:  >>> True = False >>> True False >>> True = not False >>> True True   but fails if False has been fiddled with as well. Therefore this is better:  >>> True = not None   as None cannot be reassigned.  These also evaluate to True regardless of whether True has been reassigned to False, 5, 'foo', None, etc:  >>> True = True == True   # fails if True = float('nan') >>> True = True is True >>> True = not True or not not True >>> True = not not True if True else not True >>> True = not 0      ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "48",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  Another way:  >>> True = 1 == 1 >>> False = 1 == 2      ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "38",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  For completeness: Kevin mentions that you could also fetch the real True from __builtins__:  >>> True = False >>> True False >>> True = __builtins__.True >>> True True   But that True can also be overriden:  >>> __builtins__.True = False >>> __builtins__.True False   So better to go with one of the other options.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  Just do this:  True = bool(1)   Or, because booleans are essentially integers:  True = 1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "How do I undo True = False in python interactive mode? [duplicate]",
        "A_Content": "  Solutions that use no object literals but are as durable as 1 == 1. Of course, you can define False once True is defined, so I'll supply solutions as half pairs.  def f(): pass class A(): pass True = not f() False = A != A   False = not (lambda:_).__gt__(_) True = not (lambda:_).__doc__      ",
        "Language": "Python",
        "Tags": [
            "python",
            "boolean",
            "python-2.x"
        ],
        "URL": "https://stackoverflow.com/questions/30563716/how-do-i-undo-true-false-in-python-interactive-mode",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              Naming conflict with built-in function                                        7 answers                                          So I tried the \"evil\" thing Ned Deily mentioned in his answer here. Now I have that the type True is now always False. How would I reverse this within the interactive window?  Thing to not do:  True = False   Since True has now been completely overridden with False, there doesn't seem to be an obvious way to back-track. Is there a module that True comes from that I can do something like:  True = <'module'>.True      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Set Matplotlib colorbar size to match graph",
        "A_Content": "  You can do this easily with a matplotlib AxisDivider.  The example from the linked page also works without using subplots:  import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable import numpy as np  plt.figure() ax = plt.gca() im = ax.imshow(np.arange(100).reshape((10,10)))  # create an axes on the right side of ax. The width of cax will be 5% # of ax and the padding between cax and ax will be fixed at 0.05 inch. divider = make_axes_locatable(ax) cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)  plt.colorbar(im, cax=cax)        ",
        "Language": "Python",
        "Tags": [
            "python",
            "image",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph",
        "A_Votes": "122",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I cannot get the colorbar on imshow graphs like this one to be the same height as the graph, short of using Photoshop after the fact. How do I get the heights to match?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Set Matplotlib colorbar size to match graph",
        "A_Content": "  This combination (and values near to these) seems to \"magically\" work for me to keep the colorbar scaled to the plot, no matter what size the display.  plt.colorbar(im,fraction=0.046, pad=0.04)   It also does not require sharing the axis which can get the plot out of square.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "image",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph",
        "A_Votes": "115",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I cannot get the colorbar on imshow graphs like this one to be the same height as the graph, short of using Photoshop after the fact. How do I get the heights to match?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Set Matplotlib colorbar size to match graph",
        "A_Content": "  @bogatron already gave the answer suggested by the matplotlib docs, which produces the right height, but it introduces a different problem. Now the width of the colorbar (as well as the space between colorbar and plot) changes with the width of the plot. In other words, the aspect ratio of the colorbar is not fixed anymore.  To get both the right height and a given aspect ratio, you have to dig a bit deeper into the mysterious axes_grid1 module.  import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size import numpy as np  aspect = 20 pad_fraction = 0.5  ax = plt.gca() im = ax.imshow(np.arange(200).reshape((20, 10))) divider = make_axes_locatable(ax) width = axes_size.AxesY(ax, aspect=1./aspect) pad = axes_size.Fraction(pad_fraction, width) cax = divider.append_axes(\"right\", size=width, pad=pad) plt.colorbar(im, cax=cax)   Note that this specifies the width of the colorbar w.r.t. the height of the plot (in contrast to the width of the figure, as it was before).  The spacing between colorbar and plot can now be specified as a fraction of the width of the colorbar, which is IMHO a much more meaningful number than a fraction of the figure width.    UPDATE:  I created an IPython notebook on the topic, where I packed the above code into an easily re-usable function:  import matplotlib.pyplot as plt from mpl_toolkits import axes_grid1  def add_colorbar(im, aspect=20, pad_fraction=0.5, **kwargs):     \"\"\"Add a vertical color bar to an image plot.\"\"\"     divider = axes_grid1.make_axes_locatable(im.axes)     width = axes_grid1.axes_size.AxesY(im.axes, aspect=1./aspect)     pad = axes_grid1.axes_size.Fraction(pad_fraction, width)     current_ax = plt.gca()     cax = divider.append_axes(\"right\", size=width, pad=pad)     plt.sca(current_ax)     return im.axes.figure.colorbar(im, cax=cax, **kwargs)   It can be used like this:  im = plt.imshow(np.arange(200).reshape((20, 10))) add_colorbar(im)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "image",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I cannot get the colorbar on imshow graphs like this one to be the same height as the graph, short of using Photoshop after the fact. How do I get the heights to match?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Set Matplotlib colorbar size to match graph",
        "A_Content": "  When you create the colorbar try using the fraction and/or shrink parameters.  From the documents:     fraction  0.15; fraction of original axes to use for colorbar       shrink    1.0; fraction by which to shrink the colorbar      ",
        "Language": "Python",
        "Tags": [
            "python",
            "image",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I cannot get the colorbar on imshow graphs like this one to be the same height as the graph, short of using Photoshop after the fact. How do I get the heights to match?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Set Matplotlib colorbar size to match graph",
        "A_Content": "  All the above solutions are good, but I like @Steve's and @bejota's the best as they do not involve fancy calls and are universal.   By universal I mean that works with any type of axes including GeoAxes. For example, it you have projected axes for mapping:   projection = cartopy.crs.UTM(zone='17N') ax = plt.axes(projection=projection) im = ax.imshow(np.arange(200).reshape((20, 10)))   a call to   cax = divider.append_axes(\"right\", size=width, pad=pad)   will fail with: KeyException: map_projection  Therefore, the only universal way of dealing colorbar size with all types of axes is:  ax.colorbar(im, fraction=0.046, pad=0.04)   Work with fraction from 0.035 to 0.046 to get your best size. However, the values for the fraction and paddig will need to be adjusted to get the best fit for your plot and  will differ depending if the orientation of the colorbar is in vertical position or horizontal.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "image",
            "matplotlib"
        ],
        "URL": "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I cannot get the colorbar on imshow graphs like this one to be the same height as the graph, short of using Photoshop after the fact. How do I get the heights to match?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  The latest version of virtualenvwrapper is tested under Python3.2. Chances are good it will work with Python3.3 too.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "19",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  If you already have python3 installed as well virtualenvwrapper the only thing you would need to do to use python3 with the virtual environment is creating an environment using:  which python3 #Output: /usr/bin/python3 mkvirtualenv --python=/usr/bin/python3 nameOfEnvironment   Or, (at least on OSX using brew):   mkvirtualenv --python=`which python3` nameOfEnvironment   Start using the environment and you'll see that as soon as you type python you'll start using python3     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "189",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  You can make virtualenvwrapper use a custom Python binary instead of the one virtualenvwrapper is run with. To do that you need to use VIRTUALENV_PYTHON variable which is utilized by virtualenv:  $ export VIRTUALENV_PYTHON=/usr/bin/python3 $ mkvirtualenv -a myproject myenv Running virtualenv with interpreter /usr/bin/python3 New python executable in myenv/bin/python3 Also creating executable in myenv/bin/python (myenv)$ python Python 3.2.3 (default, Oct 19 2012, 19:53:16)  [GCC 4.7.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "40",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  virtualenvwrapper now lets you specify the python executable without the path.  So (on OSX at least)mkvirtualenv --python=python3 nameOfEnvironment will suffice.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  On Ubuntu; using mkvirtualenv -p python3 env_name loads the virtualenv with python3.  Inside the env, use python --version to verify.        ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  I find that running   export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3   and   export VIRTUALENVWRAPPER_VIRTUALENV=/usr/bin/virtualenv-3.4   in the command line on Ubuntu forces mkvirtualenv to use python3 and virtualenv-3.4. One still has to do   mkvirtualenv --python=/usr/bin/python3 nameOfEnvironment   to create the environment. This is assuming that you have python3 in /usr/bin/python3 and virtualenv-3.4  in /usr/local/bin/virtualenv-3.4.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  You can add this to your .bash_profile or similar:  alias mkvirtualenv3='mkvirtualenv --python=`which python3`'   Then use mkvirtualenv3 instead of mkvirtualenv when you want to create a python 3 environment.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "virtualenvwrapper and Python 3",
        "A_Content": "  This post on the bitbucket issue tracker of virtualenvwrapper may be of interest. It is mentioned there that most of virtualenvwrapper's functions work with the venv virtual environments in Python 3.3.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "python-3.x",
            "virtualenvwrapper"
        ],
        "URL": "https://stackoverflow.com/questions/16123459/virtualenvwrapper-and-python-3",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I installed python 3.3.1 on ubuntu lucid and successfully created a virtualenv as below  virtualenv envpy331 --python=/usr/local/bin/python3.3   this created a folder envpy331 on my home dir.  I also have virtualenvwrapper installed.But in the docs only 2.4-2.7 versions of python are supported..Has anyone tried to  organize the python3 virtualenv ? If so, can you tell me how ?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  You can use pyplot.matshow()  from matplotlib:  import matplotlib.pyplot as plt  plt.matshow(dataframe.corr())      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "129",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  Try this function, which also displays variable names for the correlation matrix:  def plot_corr(df,size=10):     '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.      Input:         df: pandas DataFrame         size: vertical and horizontal size of the plot'''      corr = df.corr()     fig, ax = plt.subplots(figsize=(size, size))     ax.matshow(corr)     plt.xticks(range(len(corr.columns)), corr.columns);     plt.yticks(range(len(corr.columns)), corr.columns);      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "59",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  Seaborn's heatmap version:  import seaborn as sns corr = dataframe.corr() sns.heatmap(corr,              xticklabels=corr.columns.values,             yticklabels=corr.columns.values)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "52",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  You can observe the relation between features either by drawing a heat map from seaborn or scatter matrix from pandas.   Scatter Matrix:  pd.scatter_matrix(dataframe, alpha = 0.3, figsize = (14,8), diagonal = 'kde');   If you want to visualize each feature's skewness as well - use seaborn pairplots.   sns.pairplot(dataframe)   Sns Heatmap:  import seaborn as sns  f, ax = pl.subplots(figsize=(10, 8)) corr = dataframe.corr() sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),             square=True, ax=ax)   The output will be a correlation map of the features. i.e. see the below example.     The correlation between grocery and detergents is high. Similarly:  Pdoducts With High Correlation:   Grocery and Detergents.    Products With Medium Correlation:   Milk and Grocery Milk and Detergents_Paper   Products With Low Correlation:   Milk and Deli Frozen and Fresh. Frozen and Deli.    From Pairplots: You can observe same set of relations from pairplots or scatter matrix. But from these we can say that whether the data is normally distributed or not.     Note: The above is same graph taken from the data, which is used to draw heatmap.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "42",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  If your main goal is to visualize the correlation matrix, rather than creating a plot per se, the convenient pandas styling options is a viable built-in solution:  import pandas as pd import numpy as np  rs = np.random.RandomState(0) df = pd.DataFrame(rs.rand(10, 10)) corr = df.corr() corr.style.background_gradient()     Note that this needs to be in a backend that supports rendering HTML, such as the JupyterLab Notebook. (The automatic light text on dark backgrounds is from an existing PR and not the latest released version, pandas 0.23).    Styling  You can easily limit the digit precision:  corr.style.background_gradient().set_precision(2)     Or get rid of the digits altogether if you prefer the matrix without annotations:  corr.style.background_gradient().set_properties(**{'font-size': '0pt'})     The styling documentation also includes instructions of more advanced styles, such as how to change the display of the cell the mouse pointer is hovering over. To save the output you could return the HTML by appending the render() method and then write it to a file (or just take a screenshot for less formal purposes).    Time comparison  In my testing, style.background_gradient() was 4x faster than plt.matshow() and 120x faster than sns.heatmap() with a 10x10 matrix. Unfortunately it doesn't scale as well as plt.matshow(): the two take about the same time for a 100x100 matrix, and plt.matshow() is 10x faster for a 1000x1000 matrix.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Correlation matrix using pandas",
        "A_Content": "  You can use imshow() method from matplotlib  import pandas as pd import matplotlib.pyplot as plt matplotlib.style.use('ggplot')  plt.imshow(X.corr(), cmap=plt.cm.Reds, interpolation='nearest') plt.colorbar() tick_marks = [i for i in range(len(X.columns))] plt.xticks(tick_marks, X.columns, rotation='vertical') plt.yticks(tick_marks, X.columns) plt.show()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "pandas",
            "matplotlib",
            "data-visualization",
            "information-visualization"
        ],
        "URL": "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a data set with huge number of features, so analysing the correlation matrix has become very difficult. I want to plot a correlation matrix which we get using dataframe.corr() function from pandas library. Is there any built-in function provided by the pandas library to plot this matrix?     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  you are looking for the modulo operator:  a % b   for example:  26 % 7   Of course, maybe they wanted you to implement it yourself, which wouldn't be too difficult either.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "128",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  The remainder of a division can be discovered using the operator %:  >>> 26%7 5   In case you need both the quotient and the modulo, there's the builtin divmod function:  >>> seconds= 137 >>> minutes, seconds= divmod(seconds, 60)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "156",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  26 % 7 (you will get remainder)  26 / 7 (you will get divisor can be float value )  26 // 7 (you will get divisor only integer value) )     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  If you want to avoid modulo, you can also use a combination of the four basic operations :)  26 - (26 // 7 * 7) = 5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  Modulo would be the correct answer, but if you're doing it manually this should work.  num = input(\"Enter a number: \") div = input(\"Enter a divisor: \")  while num >= div:     num -= div print num      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  From Python 3.7, there is a new math.remainder() function:  from math import remainder print(remainder(26,7))   Quoting the documentation:     math.remainder(x, y)      Return the IEEE 754-style remainder of x with   respect to y. For finite x and finite nonzero y, this is the   difference x - n*y, where n is the closest integer to the exact value   of the quotient x / y. If x / y is exactly halfway between two   consecutive integers, the nearest even integer is used for n. The   remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 *   abs(y).      Special cases follow IEEE 754: in particular, remainder(x, math.inf)   is x for any finite x, and remainder(x, 0) and remainder(math.inf, x)   raise ValueError for any non-NaN x. If the result of the remainder   operation is zero, that zero will have the same sign as x.      On platforms using IEEE 754 binary floating-point, the result of this   operation is always exactly representable: no rounding error is   introduced.   Issue29962 describes the rationale for creating the new function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  Use the % instead of the / when you divide. This will return the remainder for you. So in your case  26 % 7 = 5      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  I'd suggest looking up the modulo operator     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  We can solve this by using modulus operator (%)  26 % 7 = 5;  but  26 / 7 = 3 because it will give quotient but % operator will give remainder.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Find the division remainder of a number",
        "A_Content": "  If you want the remainder of your division problem, just use the actual remainder rules, just like in mathematics. Granted this won't give you a decimal output.  valone = 8 valtwo = 3 x = valone / valtwo r = valone - (valtwo * x) print \"Answer: %s with a remainder of %s\" % (x, r)   If you want to make this in a calculator format, just substitute valone = 8 with valone = int(input(\"Value One\")). Do the same with valtwo = 3, but different vairables obviously.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer-division"
        ],
        "URL": "https://stackoverflow.com/questions/5584586/find-the-division-remainder-of-a-number",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    How could I go about finding the division remainder of a number in Python?  For example: If the number is 26 and divided number is 7, then the division remainder is 5. (since 7+7+7=21 and 26-21=5.)     ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Local variables in Python nested functions",
        "A_Content": "  The nested function looks up variables from the parent scope when executed, not when defined.  The function body is compiled, and the 'free' variables (not defined in the function itself by assignment), are verified, then bound as closure cells to the function, with the code using an index to reference each cell. pet_function thus has one free variable (cage) which is then referenced via a closure cell, index 0. The closure itself points to the local variable cage in the get_petters function.  When you actually call the function, that closure is then used to look at the value of cage in the surrounding scope at the time you call the function. Here lies the problem. By the time you call your functions, the get_petters function is already done computing it's results. The cage local variable at some point during that execution was assigned each of the 'cow', 'dog', and 'cat' strings, but at the end of the function, cage contains that last value 'cat'. Thus, when you call each of the dynamically returned functions, you get the value 'cat' printed.  The work-around is to not rely on closures. You can use a partial function instead, create a new function scope, or bind the variable as a default value for a keyword parameter.   Partial function example, using functools.partial():  from functools import partial  def pet_function(cage=None):     print \"Mary pets the \" + cage.animal + \".\"  yield (animal, partial(gotimes, partial(pet_function, cage=cage)))  Creating a new scope example:  def scoped_cage(cage=None):     def pet_function():         print \"Mary pets the \" + cage.animal + \".\"     return pet_function  yield (animal, partial(gotimes, scoped_cage(cage)))  Binding the variable as a default value for a keyword parameter:  def pet_function(cage=cage):     print \"Mary pets the \" + cage.animal + \".\"  yield (animal, partial(gotimes, pet_function))    There is no need to define the scoped_cage function in the loop, compilation only takes place once, not on each iteration of the loop.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "scope",
            "closures",
            "nested-function"
        ],
        "URL": "https://stackoverflow.com/questions/12423614/local-variables-in-python-nested-functions",
        "A_Votes": "97",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Okay, bear with me on this, I know it's going to look horribly convoluted, but please help me understand what's happening.  from functools import partial  class Cage(object):     def __init__(self, animal):         self.animal = animal  def gotimes(do_the_petting):     do_the_petting()  def get_petters():     for animal in ['cow', 'dog', 'cat']:         cage = Cage(animal)          def pet_function():             print \"Mary pets the \" + cage.animal + \".\"          yield (animal, partial(gotimes, pet_function))  funs = list(get_petters())  for name, f in funs:     print name + \":\",      f()   Gives:  cow: Mary pets the cat. dog: Mary pets the cat. cat: Mary pets the cat.   So basically, why am I not getting three different animals? Isn't the cage 'packaged' into the local scope of the nested function? If not, how does a call to the nested function look up the local variables?  I know that running into these kind of problems usually means one is 'doing it wrong', but I'd like to understand what happens.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Local variables in Python nested functions",
        "A_Content": "  My understanding is that cage is looked for in the parent function namespace when the yielded  pet_function is actually called, not before.  So when you do   funs = list(get_petters())   You generate 3 functions which will find the lastly created cage.  If you replace your last loop with :  for name, f in get_petters():     print name + \":\",      f()   You will actually get :  cow: Mary pets the cow. dog: Mary pets the dog. cat: Mary pets the cat.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "scope",
            "closures",
            "nested-function"
        ],
        "URL": "https://stackoverflow.com/questions/12423614/local-variables-in-python-nested-functions",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Okay, bear with me on this, I know it's going to look horribly convoluted, but please help me understand what's happening.  from functools import partial  class Cage(object):     def __init__(self, animal):         self.animal = animal  def gotimes(do_the_petting):     do_the_petting()  def get_petters():     for animal in ['cow', 'dog', 'cat']:         cage = Cage(animal)          def pet_function():             print \"Mary pets the \" + cage.animal + \".\"          yield (animal, partial(gotimes, pet_function))  funs = list(get_petters())  for name, f in funs:     print name + \":\",      f()   Gives:  cow: Mary pets the cat. dog: Mary pets the cat. cat: Mary pets the cat.   So basically, why am I not getting three different animals? Isn't the cage 'packaged' into the local scope of the nested function? If not, how does a call to the nested function look up the local variables?  I know that running into these kind of problems usually means one is 'doing it wrong', but I'd like to understand what happens.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Local variables in Python nested functions",
        "A_Content": "  This stems from the following  for i in range(2):      pass  print i is 1   after iterating the value of i is lazily stored as its final value.  As a generator the function would work (i.e. printing each value in turn), but when transforming to a list it runs over the generator, hence all calls to cage (cage.animal) return cats.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "scope",
            "closures",
            "nested-function"
        ],
        "URL": "https://stackoverflow.com/questions/12423614/local-variables-in-python-nested-functions",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Okay, bear with me on this, I know it's going to look horribly convoluted, but please help me understand what's happening.  from functools import partial  class Cage(object):     def __init__(self, animal):         self.animal = animal  def gotimes(do_the_petting):     do_the_petting()  def get_petters():     for animal in ['cow', 'dog', 'cat']:         cage = Cage(animal)          def pet_function():             print \"Mary pets the \" + cage.animal + \".\"          yield (animal, partial(gotimes, pet_function))  funs = list(get_petters())  for name, f in funs:     print name + \":\",      f()   Gives:  cow: Mary pets the cat. dog: Mary pets the cat. cat: Mary pets the cat.   So basically, why am I not getting three different animals? Isn't the cage 'packaged' into the local scope of the nested function? If not, how does a call to the nested function look up the local variables?  I know that running into these kind of problems usually means one is 'doing it wrong', but I'd like to understand what happens.     ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  sudo /usr/local/mysql/support-files/mysql.server start    This worked for me. However, if this doesnt work then make sure that mysqld is running and try connecting.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "132",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  The relevant section of the MySQL manual is here. I'd start by going through the debugging steps listed there.  Also, remember that localhost and 127.0.0.1 are not the same thing in this context:   If host is set to localhost, then a socket or pipe is used. If host is set to 127.0.0.1, then the client is forced to use TCP/IP.   So, for example, you can check if your database is listening for TCP connections vi netstat -nlp. It seems likely that it IS listening for TCP connections because you say that mysql -h 127.0.0.1 works just fine. To check if you can connect to your database via sockets, use mysql -h localhost.   If none of this helps, then you probably need to post more details about your MySQL config, exactly how you're instantiating the connection, etc.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "66",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  For me the problem was I wasn't running mysql server. Run server first and then execute mysql.  $ mysql.server start $ mysql -h localhost -u root -p      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "58",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  I've seen this happen at my shop when my devs have a stack manager like MAMP installed that comes preconfigured with MySQL installed in a non standard place.  at your terminal run   mysql_config --socket   that will give you your path to the sock file. take that path and use it in your DATABASES HOST paramater.  What you need to do is point your    DATABASES = {     'default': {         'ENGINE': 'django.db.backends.mysql',         'NAME': 'test',         'USER': 'test',         'PASSWORD': 'test',         'HOST': '/Applications/MAMP/tmp/mysql/mysql.sock',         'PORT': '',     }, }   NOTE  also run which mysql_config if you somehow have multiple instances of mysql server installed on the machine you may be connecting to the wrong one.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  When, if you lose your daemon mysql in mac OSx but is present in other path for exemple in private/var do the following command  1)  ln -s /private/var/mysql/mysql.sock /tmp/mysql.sock   2) restart your connexion to mysql with :  mysql -u username -p -h host databasename   works also for mariadb     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  I just changed the HOST from localhost to 127.0.0.1 and it works fine:  DATABASES = {     'default': {         'ENGINE': 'django.db.backends.mysql',         'NAME': 'db_name',         'USER': 'username',         'PASSWORD': 'password',         'HOST': '127.0.0.1',         'PORT': '', },      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Check number of open files for the mysql process using lsof command.   Increase the open files limit and run again.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  After attempting a few of these solutions and not having any success, this is what worked for me:   Restart system mysql.server start Success!      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Run the below cmd in terminal      /usr/local/mysql/bin/mysqld_safe     Then restart the machine to take effect. It works!!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  This may be one of following problems.   Incorrect mysql lock. solution: You have to find out the correct mysql socket by,      mysqladmin -p variables | grep socket   and then put it in your db connection code:   pymysql.connect(db='db', user='user', passwd='pwd', unix_socket=\"/tmp/mysql.sock\")   /tmp/mysql.sock is the returned from grep  2.Incorrect mysql port   solution: You have to find out the correct mysql port:  mysqladmin -p variables | grep port   and then in your code:  pymysql.connect(db='db', user='user', passwd='pwd', host='localhost', port=3306)   3306 is the port returned from the grep  I think first option will resolve your problem.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  I think i saw this same behavior some time ago, but can't remember the details. In our case, the problem was the moment the testrunner initialises database connections relative to first database interaction required, for instance, by import of a module in  settings.py or some __init__.py. I'll try to digg up some more info, but this might already ring a bell for your case.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  I have two sneaky conjectures on this one  CONJECTURE #1  Look into the possibility of not being able to access the /tmp/mysql.sock file. When I setup MySQL databases, I normally let the socket file site in /var/lib/mysql. If you login to mysql as root@localhost, your OS session needs access to the /tmp folder. Make sure /tmp has the correct access rights in the OS. Also, make sure the sudo user can always read file in /tmp.  CONJECTURE #2  Accessing mysql via 127.0.0.1 can cause some confusion if you are not paying attention. How?  From the command line, if you connect to MySQL with 127.0.0.1, you may need to specify the TCP/IP protocol.  mysql -uroot -p -h127.0.0.1 --protocol=tcp   or try the DNS name  mysql -uroot -p -hDNSNAME   This will bypass logging in as root@localhost, but make sure you have root@'127.0.0.1' defined.  Next time you connect to MySQL, run this:  SELECT USER(),CURRENT_USER();   What does this give you?   USER() reports how you attempted to authenticate in MySQL CURRENT_USER() reports how you were allowed to authenticate in MySQL   If these functions return with the same values, then you are connecting and authenticating as expected. If the values are different, you may need to create the corresponding user root@127.0.0.1.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Had this same problem. Turned out mysqld had stopped running (I'm on Mac OSX). I restarted it and the error went away.  I figured out that mysqld was not running largely because of this link: http://dev.mysql.com/doc/refman/5.6/en/can-not-connect-to-server.html  Notice the first tip!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Make sure your /etc/hosts has 127.0.0.1 localhost in it and it should work fine     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Check that your mysql has not reached maximum connections, or is not in some sort of booting loop as happens quite often if the settings are incorrect in my.cnf.  Use ps aux | grep mysql to check if the PID is changing.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Looked around online too long not to contribute. After trying to type in the mysql prompt from the command line, I was continuing to receive this message:  ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)  This was due to the fact that my local mysql server was no longer running. In order to restart the server, I navigated to  shell> cd /user/local/bin   where my mysql.server was located. From here, simply type:   shell> mysql.server start   This will relaunch the local mysql server.  From there you can reset the root password if need be..  mysql> UPDATE mysql.user SET Password=PASSWORD('MyNewPass') ->                   WHERE User='root'; mysql> FLUSH PRIVILEGES;      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  The socket is located in /tmp. On Unix system, due to modes & ownerships on /tmp, this could cause some problem. But, as long as you tell us that you CAN use your mysql connexion normally, I guess it is not a problem on your system. A primal check should be to relocate mysql.sock in a more neutral directory.  The fact that the problem occurs \"randomly\" (or not every time) let me think that it could be a server problem.    Is your /tmp located on a standard disk, or on an exotic mount (like in the RAM) ? Is your /tmp empty ?  Does iotopshow you something wrong when you encounter the problem ?      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  I had to kill off all instances of mysql by first finding all the process IDs:     ps aux | grep mysql   And then killing them off:     kill -9 {pid}   Then:     mysql.server start   Worked for me.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Configure your DB connection in the 'Manage DB Connections dialog. Select 'Standard (TCP/IP)' as connection method.  See this page for more details  http://dev.mysql.com/doc/workbench/en/wb-manage-db-connections.html  According to this other page a socket file is used even if you specify localhost.     A Unix socket file is used if you do not specify a host name or if you   specify the special host name localhost.   It also shows how to check on your server by running these commands:     If a mysqld process is running, you can check it by trying the   following commands. The port number or Unix socket file name might be   different in your setup. host_ip represents the IP address of the   machine where the server is running.   shell> mysqladmin version  shell> mysqladmin variables  shell> mysqladmin -h `hostname` version variables  shell> mysqladmin -h `hostname` --port=3306 version  shell> mysqladmin -h host_ip version  shell> mysqladmin --protocol=SOCKET --socket=/tmp/mysql.sock version      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  in ubuntu14.04 you can do this to slove this problem.  zack@zack:~/pycodes/python-scraping/chapter5$ **mysqladmin -p variables|grep socket** Enter password:  | socket                                            | ***/var/run/mysqld/mysqld.sock***                                                                                            | zack@zack:~/pycodes/python-scraping/chapter5$***ln -s  /var/run/mysqld/mysqld.sock /tmp/mysql.sock*** zack@zack:~/pycodes/python-scraping/chapter5$ ll /tmp/mysql.sock  lrwxrwxrwx 1 zack zack 27 11月 29 13:08 /tmp/mysql.sock -> /var/run/mysqld/mysqld.sock=      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  For me, I'm sure mysqld is started, and command line mysql can work properly. But the httpd server show the issue(can't connect to mysql through socket).  I started the service with mysqld_safe&.  finally, I found when I start the mysqld service with service mysqld start, there are issues(selinux permission issue), and when I fix the selinux issue, and start the mysqld with \"service mysqld start\", the httpd connection issue disappear. But when I start the mysqld with mysqld_safe&, mysqld can be worked. (mysql client can work properly). But there are still issue when connect with httpd.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  If it's socket related read this file  /etc/mysql/my.cnf   and see what is the standard socket location. It's a line like:  socket = /var/run/mysqld/mysqld.sock   now create an alias for your shell like:  alias mysql=\"mysql --socket=/var/run/mysqld/mysqld.sock\"   This way you don't need root privileges.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  Simply try to run mysqld.   This was what was not working for me on mac. If it doesn't work try go to /usr/local/var/mysql/<your_name>.err to see detailed error logs.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  if you get an error like below :  django.db.utils.OperationalError: (2002, \"Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)\")   Then just find your mysqld.sock file location and add it to \"HOST\".  Like i am using xampp on linux so my mysqld.sock file is in another location. so it is not working for '/var/run/mysqld/mysqld.sock'  DATABASES = {      'default': {         'ENGINE': 'django.db.backends.mysql',         'NAME': 'asd',         'USER' : 'root',         'PASSWORD' : '',         'HOST' : '/opt/lampp/var/mysql/mysql.sock',         'PORT' : ''     } }      ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can't connect to local MySQL server through socket '/tmp/mysql.sock",
        "A_Content": "  To those who upgraded from 5.7 to 8.0 via homebrew, this error is likely caused by the upgrade not being complete. In my case, mysql.server start got me the following error:     ERROR! The server quit without updating PID file   I then checked the log file via cat /usr/local/var/mysql/YOURS.err | tail -n 50, and found the following:     InnoDB: Upgrade after a crash is not supported.    If you are on the same boat, first install mysql@5.7 via homebrew, stop the server, and then start the 8.0 system again.  brew install mysql@5.7  /usr/local/opt/mysql@5.7/bin/mysql.server start /usr/local/opt/mysql@5.7/bin/mysql.server stop   Then,  mysql.server start   This would get your MySQL (8.0) working again.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "mysql",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/16325607/cant-connect-to-local-mysql-server-through-socket-tmp-mysql-sock",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    When I attempted to connect to a local MySQL server during my test suite, it fails with the error:  OperationalError: (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\")   However, I'm able to at all times, connect to MySQL by running the command line mysql program. A ps aux | grep mysql shows the server is running, and stat /tmp/mysql.sock confirm that the socket exists. Further, if I open a debugger in except clause of that exception, I'm able to reliably connect with the exact same parameters.  This issue reproduces fairly reliably, however it doesn't appear to be 100%, because every once in a blue moon, my test suite does in fact run without hitting this error. When I attempted to run with sudo dtruss it did not reproduce.  All the client code is in Python, though I can't figure how that'd be relevant.  Switching to use host 127.0.0.1 produces the error:  DatabaseError: Can't connect to MySQL server on '127.0.0.1' (61)      ",
        "Q_Votes": "90"
    },
    {
        "Q_Title": "Can I add comments to a pip requirements file?",
        "A_Content": "  Sure, you can, based on pip docs:     A line that begins with # is treated as a comment and ignored. Whitespace followed by a # causes the # and the remainder of the line to be treated as a comment.   Go ahead!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "comments",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9159757/can-i-add-comments-to-a-pip-requirements-file",
        "A_Votes": "108",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I'd like to add comments for a few packages in a pip requirements file. (Just to explain why that package is on the list.) Can I do this?  I'm imagining something like  Babel==0.9.5 # translation CherryPy==3.2.0 # web server Creoleparser==0.7.1 # wiki formatting Genshi==0.5.1 # templating      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Can I add comments to a pip requirements file?",
        "A_Content": "  You can add comments (lines beginning with #)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "comments",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/9159757/can-i-add-comments-to-a-pip-requirements-file",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'd like to add comments for a few packages in a pip requirements file. (Just to explain why that package is on the list.) Can I do this?  I'm imagining something like  Babel==0.9.5 # translation CherryPy==3.2.0 # web server Creoleparser==0.7.1 # wiki formatting Genshi==0.5.1 # templating      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  When you type exit in the command line, it finds the variable with that name and calls __repr__ (or __str__) on it. Usually, you'd get a result like:  <function exit at 0x00B97FB0>   But they decided to redefine that function for the exit object to display a helpful message instead. Whether or not that's a stupid behavior or not, is a subjective question, but one possible reason why it doesn't \"just exit\" is:  Suppose you're looking at some code in a debugger, for instance, and one of the objects references the exit function. When the debugger tries to call __repr__ on that object to display that function to you, the program suddenly stops! That would be really unexpected, and the measures to counter that might complicate things further (for instance, even if you limit that behavior to the command line, what if you try to print some object that have exit as an attribute?)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "33",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  This works for me, best way to come out of python prompt.     exit()      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  This message is the __str__ attribute of exit  look at these examples :  1  >>> print exit Use exit() or Ctrl-D (i.e. EOF) to exit   2  >>> exit.__str__() 'Use exit() or Ctrl-D (i.e. EOF) to exit'   3  >>> getattr(exit, '__str__')() 'Use exit() or Ctrl-D (i.e. EOF) to exit'      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  I recommend you exit the Python interpreter with Ctrl-D.  This is the old ASCII code for end-of-file or end-of-transmission.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  Because the interpreter is not a shell where you provide commands, it's - well - an interpreter. The things that you give to it are Python code.  The syntax of Python is such that exit, by itself, cannot possibly be anything other than a name for an object. Simply referring to an object can't actually do anything (except what the read-eval-print loop normally does; i.e. display a string representation of the object).     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  In my python interpreter exit is actually a string and not a function -- 'Use Ctrl-D (i.e. EOF) to exit.'. You can check on your interpreter by entering type(exit)  In active python what is happening is that exit is a function. If you do not call the function it will print out the string representation of the object. This is the default behaviour for any object returned. It's just that the designers thought people might try to type exit to exit the interpreter, so they made the string representation of the exit function a helpful message. You can check this behaviour by typing str(exit) or even print exit.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  You can fix that.  Link PYTHONSTARTUP to a python file with the following   # Make exit work as expected type(exit).__repr__ = type(exit).__call__     How does this work?  The python command line is a read-evaluate-print-loop, that is when you type text it will read that text, evaluate it, and eventually print the result.   When you type exit() it evaluates to a callable object of type site.Quitter and calls its __call__ function which exits the system. When you type exit it evaluates to the same callable object, without calling it the object is printed which in turn calls __repr__ on the object.    We can take advantage of this by linking __repr__ to __call__ and thus get the expected behavior of exiting the sustem even when we type exit without parentheses.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  To exit from Python terminal, simply do:  exit()   Please pay attention it's a function which called as most user mix it with exit without calling, but new Pyhton terminal show a message...  or as a shortcut, press:  Ctrl + D   on your keyboard...       ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  If you stuck in python command line and none of above solutions worked for you, try exit(2)     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Exiting from python Command Line",
        "A_Content": "  \"exit\" is a valid variable name that can be used in your Python program. You wouldn't want to exit the interpreter when you're just trying to see the value of that variable.     ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/9730409/exiting-from-python-command-line",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    To exit from Python command line, I have to type exit(). If I type exit, it says   Use exit() or Ctrl-Z plus Return to exit   Usually when you type exit, you would want to exit the program. Why does the interpreter give me the above error when it knows I am trying to exit the command line? Why doesn't it just exit? I know it doesn't matter and its a silly question but I am curious.      ",
        "Q_Votes": "91"
    },
    {
        "Q_Title": "Compile (but do not run) a Python script [duplicate]",
        "A_Content": "  py_compile — Compile Python source files  import py_compile py_compile.compile('my_script.py')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-checking"
        ],
        "URL": "https://stackoverflow.com/questions/4537411/compile-but-do-not-run-a-python-script",
        "A_Votes": "44",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "       Possible Duplicate:   How can I check the syntax of Python script without executing it?       How do I compile a Python script without running it?  I just want to check the script for syntax errors.  I was hoping for a simple command line switch, but I didn't see anything in python --help.  I'd like an answer for both Python 2 and Python 3.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Compile (but do not run) a Python script [duplicate]",
        "A_Content": "  python -m py_compile script.py      ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-checking"
        ],
        "URL": "https://stackoverflow.com/questions/4537411/compile-but-do-not-run-a-python-script",
        "A_Votes": "318",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   How can I check the syntax of Python script without executing it?       How do I compile a Python script without running it?  I just want to check the script for syntax errors.  I was hoping for a simple command line switch, but I didn't see anything in python --help.  I'd like an answer for both Python 2 and Python 3.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Compile (but do not run) a Python script [duplicate]",
        "A_Content": "  You can use pylint to find syntax errors as well as more subtle errors, such as accessing undefined variables in some rarely-used conditional branch.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-checking"
        ],
        "URL": "https://stackoverflow.com/questions/4537411/compile-but-do-not-run-a-python-script",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   How can I check the syntax of Python script without executing it?       How do I compile a Python script without running it?  I just want to check the script for syntax errors.  I was hoping for a simple command line switch, but I didn't see anything in python --help.  I'd like an answer for both Python 2 and Python 3.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "Compile (but do not run) a Python script [duplicate]",
        "A_Content": "  One way is to do something like this (for test.py):  python -c \"__import__('compiler').parse(open('test.py').read())\"   This works for Python 2.x.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "syntax-checking"
        ],
        "URL": "https://stackoverflow.com/questions/4537411/compile-but-do-not-run-a-python-script",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "       Possible Duplicate:   How can I check the syntax of Python script without executing it?       How do I compile a Python script without running it?  I just want to check the script for syntax errors.  I was hoping for a simple command line switch, but I didn't see anything in python --help.  I'd like an answer for both Python 2 and Python 3.     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Use a list comprehension mixed with zip():.  [a*b for a,b in zip(lista,listb)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "196",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Since you're already using numpy, it makes sense to store your data in a numpy array rather than a list. Once you do this, you get things like element-wise products for free:  In [1]: import numpy as np  In [2]: a = np.array([1,2,3,4])  In [3]: b = np.array([2,3,4,5])  In [4]: a * b Out[4]: array([ 2,  6, 12, 20])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Use np.multiply(a,b):  import numpy as np a = [1,2,3,4] b = [2,3,4,5] np.multiply(a,b)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  You can try multiplying each element in a loop. The short hand for doing that is  ab = [a[i]*b[i] for i in range(len(a))]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "13",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Fairly intuitive way of doing this:  a = [1,2,3,4] b = [2,3,4,5] ab = []                        #Create empty list for i in range(0, len(a)):      ab.append(a[i]*b[i])      #Adds each element to the list      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Yet another answer:  -1 ... requires import +1 ... is very readable  import operator a = [1,2,3,4] b = [10,11,12,13]  list(map(operator.mul, a, b))   outputs [10, 22, 36, 52]     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  For large lists, we can do it the iter-way:  product_iter_object = itertools.imap(operator.mul, [1,2,3,4], [2,3,4,5])   product_iter_object.next() gives each of the element in the output list.  The output would be the length of the shorter of the two input lists.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  create an array of ones; multiply each list times the array;  convert array to a list  import numpy as np  a = [1,2,3,4] b = [2,3,4,5]  c = (np.ones(len(a))*a*b).tolist()  [2.0, 6.0, 12.0, 20.0]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  you can multiplication using lambda   foo=[1,2,3,4] bar=[1,2,5,55] l=map(lambda x,y:x*y,foo,bar)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  gahooa's answer is correct for the question as phrased in the heading, but if the lists are already numpy format or larger than ten it will be MUCH faster (3 orders of magnitude) as well as more readable, to do simple numpy multiplication as suggested by NPE. I get these timings:  0.0049ms -> N = 4, a = [i for i in range(N)], c = [a*b for a,b in zip(a, b)] 0.0075ms -> N = 4, a = [i for i in range(N)], c = a * b 0.0167ms -> N = 4, a = np.arange(N), c = [a*b for a,b in zip(a, b)] 0.0013ms -> N = 4, a = np.arange(N), c = a * b 0.0171ms -> N = 40, a = [i for i in range(N)], c = [a*b for a,b in zip(a, b)] 0.0095ms -> N = 40, a = [i for i in range(N)], c = a * b 0.1077ms -> N = 40, a = np.arange(N), c = [a*b for a,b in zip(a, b)] 0.0013ms -> N = 40, a = np.arange(N), c = a * b 0.1485ms -> N = 400, a = [i for i in range(N)], c = [a*b for a,b in zip(a, b)] 0.0397ms -> N = 400, a = [i for i in range(N)], c = a * b 1.0348ms -> N = 400, a = np.arange(N), c = [a*b for a,b in zip(a, b)] 0.0020ms -> N = 400, a = np.arange(N), c = a * b   i.e. from the following test program.  import timeit  init = [''' import numpy as np N = {} a = {} b = np.linspace(0.0, 0.5, len(a)) '''.format(i, j) for i in [4, 40, 400]                    for j in ['[i for i in range(N)]', 'np.arange(N)']]  func = ['''c = [a*b for a,b in zip(a, b)]''', '''c = a * b''']  for i in init:   for f in func:     lines = i.split('\\n')     print('{:6.4f}ms -> {}, {}, {}'.format(            timeit.timeit(f, setup=i, number=1000), lines[2], lines[3], f))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  The map function can be very useful here. Using map we can apply any function to each element of an iterable.  Python 3.x  >>> def my_mul(x,y): ...     return x*y ... >>> a = [1,2,3,4] >>> b = [2,3,4,5] >>> >>> list(map(my_mul,a,b)) [2, 6, 12, 20] >>>   Of course:   map(f, iterable)   is equivalent to   [f(x) for x in iterable]   So we can get our solution via:  >>> [my_mul(x,y) for x, y in zip(a,b)] [2, 6, 12, 20] >>>   In Python 2.x map() means: apply a function to each element of an iterable and construct a new list. In Python 3.x, map construct iterators instead of lists.   Instead of my_mul we could use  mul operator  Python 2.7  >>>from operator import mul # import mul operator >>>a = [1,2,3,4] >>>b = [2,3,4,5] >>>map(mul,a,b) [2, 6, 12, 20] >>>   Python 3.5+  >>> from operator import mul >>> a = [1,2,3,4] >>> b = [2,3,4,5] >>> [*map(mul,a,b)] [2, 6, 12, 20] >>>   Please note that since map() constructs an iterator we use * iterable unpacking operator to get a list. The unpacking approach is a bit faster then the list constructor:  >>> list(map(mul,a,b)) [2, 6, 12, 20] >>>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  Can use enumerate.  a = [1, 2, 3, 4] b = [2, 3, 4, 5]  ab = [val * b[i] for i, val in enumerate(a)]      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How to perform element-wise multiplication of two lists in Python?",
        "A_Content": "  To maintain the list type, and do it in one line (after importing numpy as np, of course):  list(np.array([1,2,3,4]) * np.array([2,3,4,5]))   or  list(np.array(a) * np.array(b))      ",
        "Language": "Python",
        "Tags": [
            "python",
            "list",
            "multiplying",
            "elementwise-operations"
        ],
        "URL": "https://stackoverflow.com/questions/10271484/how-to-perform-element-wise-multiplication-of-two-lists-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I want to perform an element wise multiplication, to multiply two lists together by value in Python, like we can do it in Matlab.  This is how I would do it in Matlab.  a = [1,2,3,4] b = [2,3,4,5] a .* b = [2, 6, 12, 20]   A list comprehension would give 16 list entries, for every combination x * y of x from a and y from b. Unsure of how to map this.  If anyone is interested why, I have a dataset, and want to multiply it by Numpy.linspace(1.0, 0.5, num=len(dataset)) =).     ",
        "Q_Votes": "88"
    },
    {
        "Q_Title": "How should I organize Python source code? [closed]",
        "A_Content": "  The article Eric pointed to is awesome because it covers details of organising large Python code bases.  If you've landed here from Google and are trying to find out how to split one large source file into multiple, more manageable, files I'll summarise the process briefly.  Assume you currently have everything in a file called main.py:   Create another source file in the same folder (let's call ours utils.py for this example) Move whatever classes, functions, statements, etc you need from main.py into utils.py In main.py add a single line at the top: import utils   Conceptually what this does is to create a new module called utils in another source file.  You can then import it wherever it's needed.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "code-organization"
        ],
        "URL": "https://stackoverflow.com/questions/1849311/how-should-i-organize-python-source-code",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting started with Python (it's high time I give it a shot), and I'm looking for some best practices.  My first project is a queue which runs command-line experiments in multiple threads. I'm starting to get a very long main.py file, and I'd like to break it up. In general, I'm looking for: How do python programmers organize multiple source files? Is there a particular structure that works for you?  My specific questions include:   Should each class be in a separate file? How should I organize unit tests relative to source code? Where should I put doc comments, specifically those for command-line operation? If I use multiple directories, how do I import classes between them?   I can probably draw some of my own conclusions here by trial and error, but I'd rather start from something good.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How should I organize Python source code? [closed]",
        "A_Content": "  The way you should organise your code and tests is exactly the same you would for any OO language.   Answers from the way I do it. It may not be right but works for me   Depends on how your functionality is split. For my main python app I have 1 file with classes for the entry points and then packages of different bits of functionality I use PyDev for eclipse and organise it like I would for Java.     >  Workspace >     | >     |-Src >     |   |-Package1 >     |   |-Package2 >     |   |-main.py >     |-Test >         |-TestPackage1 >         |-TestPackage2     Use DocString everywhere to keep track of everything After making sure that the relevant __init__.py files are in the folders. its just a simple case of from module import class      ",
        "Language": "Python",
        "Tags": [
            "python",
            "unit-testing",
            "code-organization"
        ],
        "URL": "https://stackoverflow.com/questions/1849311/how-should-i-organize-python-source-code",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I'm getting started with Python (it's high time I give it a shot), and I'm looking for some best practices.  My first project is a queue which runs command-line experiments in multiple threads. I'm starting to get a very long main.py file, and I'd like to break it up. In general, I'm looking for: How do python programmers organize multiple source files? Is there a particular structure that works for you?  My specific questions include:   Should each class be in a separate file? How should I organize unit tests relative to source code? Where should I put doc comments, specifically those for command-line operation? If I use multiple directories, how do I import classes between them?   I can probably draw some of my own conclusions here by trial and error, but I'd rather start from something good.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do you get PyPy, Django and PostgreSQL to work together?",
        "A_Content": "  psycopg2cffi (Updated 2015)  psycopg2cffi is yet another psycopg2-compatible replacement and should provide the best PostgreSQL performance with PyPy. Add this to your settings.py to remain compatible with both:  try:     import psycopg2 except ImportError:     # Fall back to psycopg2cffi     from psycopg2cffi import compat     compat.register()   psycopg2-ctypes (2012)     I also know that some people are using psycopg2-ctypes.   This is the easiest way; to stay compatible with both, just add this code in your Django settings.py:  try:     import psycopg2 except ImportError:     # Fall back to psycopg2-ctypes     from psycopg2ct import compat     compat.register()   I tested this a few releases ago; sadly in my experience, psycopg2-ctypes negates the small performance gains afforded by PyPy. But YMMV, it depends on how JIT-friendly your code is in general and what fraction of time you actually spend running Python code. And maybe PyPy has just improved since then.     and I don't think psycopg2-ctypes is ready for Windows yet   I haven't tried this, but ctypes is platform-independent. AFAICT you just have to make sure that the libpq.dll library is loadable (located in a directory in your PATH environment variable or local directory) and it should work on Windows just like in Linux.  pypy-postgresql     I do see that Alex Gaynor has made a fork of PyPy called pypy-postgresql.   I don't think this is a good choice in the long term. The branch hasn't been updated for more than a year and my attempts to build it have failed. And it seems wrong to hard-code a PostgreSQL driver in the interpreter anyway.  I believe there are no binaries out there of pypy-postgresql either, so if you want to use it, you'd need to build the whole PyPy branch yourself. Not for the faint of heart: it takes tens of minutes and a machine with at least 4 GB of memory. (Official instructions: http://pypy.org/download.html#building-from-source)  To build, you first need the source. If you have Mercurial installed, you can simply hg clone https://bitbucket.org/alex_gaynor/pypy-postgresql. If not, you can download the automagic \"tip\" zip file: https://bitbucket.org/alex_gaynor/pypy-postgresql/get/tip.zip  Open a command line, go into the decompressed directory, and then inside pypy/translator/goal  If you have PyPy installed, it's recommended to use that for building:  pypy translate.py -Ojit   Otherwise:  python translate.py -Ojit   Sadly this is where my knowledge ends. I get the error \"BytecodeCorruption: unimplemented opcode, ofs=234, code=203, name=BUILD_LIST_FROM_ARG\"     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "pypy"
        ],
        "URL": "https://stackoverflow.com/questions/9350422/how-do-you-get-pypy-django-and-postgresql-to-work-together",
        "A_Votes": "30",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What fork, or combination of packages should one to use to make PyPy, Django and PostgreSQL play nice together?  I know that PyPy and Django play nice together, but I am less certain about PyPy and PostgreSQL. I do see that Alex Gaynor has made a fork of PyPy called pypy-postgresql. I also know that some people are using psycopg2-ctypes.  Is there a difference between these forks? Or should we use the stable 1.9 PyPy and use psycopg2-ctypes? Using the ctypes options could hurt performance, see the comment below.  Also, has anyone experienced any pitfalls with using PyPy with pyscopg2? It seems easy enough to fall back on CPython if something isn't working right, but mostly I'm looking for things a programmer can do ahead of time to prepare.  I looked around, it doesn't seem that psycopg2 works natively with PyPy. Although, psycopg2-ctypes does seem to be working for some people,  there was a discussion on pypy-dev. I work on Windows, and I don't think psycopg2-ctypes is ready for Windows yet, sadly.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How do you get PyPy, Django and PostgreSQL to work together?",
        "A_Content": "  Some additional resources:   PyPy compatibility information: DB adaptors PostgreSQL page on the Python wiki psycopg2cffi by Konstantin Lopuhin: cffi based implementation of psycopg2 for PyPy 2.0 and newer (blog post, GitHub repo, PyPI page, pypy-dev thread) – this looks like the strongest candidate currently, but I haven't tested it yet psycopg2ct by Michael van Tellingen: ctypes based implementation of psycopg2 for PyPy 1.6 and newer (GitHub repo, PyPI page)  pypy-postgresql by Alex Gaynor: abandoned RPython port of psycopg2 implemented as a fork of PyPy (Bitbucket repo) pypq: \"Python PostgreSQL DBAPI 2.0 compliant driver using ctypes and libpq.so, works with PyPy\" (discussion, PyPI page) bpgsql: \"Barebones pure-python PostGreSQL client. Mostly DB-API 2.0 (PEP 249) compliant. Includes an experimental Django 1.0 backend\" (discussion, web page, Google Code page) pg8000: \"a DB-API 2.0 compatible Pure-Python interface to the PostgreSQL database engine [...] does not rely on any external libraries (such as a compiled python module, or PostgreSQL’s libpq library)\" (web page, GitHub repo, PyPI page)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "django",
            "postgresql",
            "psycopg2",
            "pypy"
        ],
        "URL": "https://stackoverflow.com/questions/9350422/how-do-you-get-pypy-django-and-postgresql-to-work-together",
        "A_Votes": "16",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    What fork, or combination of packages should one to use to make PyPy, Django and PostgreSQL play nice together?  I know that PyPy and Django play nice together, but I am less certain about PyPy and PostgreSQL. I do see that Alex Gaynor has made a fork of PyPy called pypy-postgresql. I also know that some people are using psycopg2-ctypes.  Is there a difference between these forks? Or should we use the stable 1.9 PyPy and use psycopg2-ctypes? Using the ctypes options could hurt performance, see the comment below.  Also, has anyone experienced any pitfalls with using PyPy with pyscopg2? It seems easy enough to fall back on CPython if something isn't working right, but mostly I'm looking for things a programmer can do ahead of time to prepare.  I looked around, it doesn't seem that psycopg2 works natively with PyPy. Although, psycopg2-ctypes does seem to be working for some people,  there was a discussion on pypy-dev. I work on Windows, and I don't think psycopg2-ctypes is ready for Windows yet, sadly.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Embedding Python in an iPhone app",
        "A_Content": "  It doesn't really matter how you build Python -- you don't need to build it in Xcode, for example -- but what does matter is the product of that build.  Namely, you are going to need to build something like libPython.a that can be statically linked into your application.  Once you have a .a, that can be added to the Xcode project for your application(s) and, from there, it'll be linked and signed just like the rest of your app.  IIRC (it has been a while since I've built python by hand) the out-of-the-box python will build a libPython.a (and a bunch of other libraries), if you configure it correctly.  Of course, your second issue is going to be cross-compiling python for ARM from your 86 box.  Python is an autoconf based project and autoconf is a pain in the butt for cross-compilation.  As you correctly state, making it small will be critical.  Not surprising, either, is that you aren't the first person to want to do this, but not for iOS.   Python has been squeezed into devices much less capable than those that run iOS.  I found a thread with a bunch of links when googling about;  it might be useful.  Also, you might want to join the pyobjc-dev list.   While you aren't targeting a PyObjC based application (which, btw, is a good idea -- PyObjC has a long way to go before it'll be iOS friendly), the PyObjC community has been discussing this and Ronald, of anyone, is probably the most knowledgeable person in this particular area.  Note that PyObjC will have to solve the embedded Python on iOS problem prior to porting PyObjC.  Their prerequisite is your requirement, as it were.     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "xcode"
        ],
        "URL": "https://stackoverflow.com/questions/3691655/embedding-python-in-an-iphone-app",
        "A_Votes": "28",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So it's a new millennium; Apple has waved their hand; it's now legal to include a Python interpreter in an iPhone (App Store) app.  How does one go about doing this? All the existing discussion (unsurprisingly) refers to jailbreaking. (Older question: Can I write native iPhone apps using Python)  My goal here isn't to write a PyObjC app, but to write a regular ObjC app that runs Python as an embedded library. The Python code will then call back to native Cocoa code. It's the \"control logic is Python code\" pattern.  Is there a guide to getting Python built in XCode, so that my iPhone app can link it? Preferably a stripped-down Python, since I won't need 90% of the standard library.  I can probably figure out the threading and Python-extension API; I've done that on MacOS. But only using command-line compilers, not XCode.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Embedding Python in an iPhone app",
        "A_Content": "  I've put a very rough script up on github that fetches and builds python2.6.5 for iPhone and simulator.  http://github.com/cobbal/python-for-iphone  Work in progress  Somewhat depressing update nearly 2 years later: (copied from README on github)     This project never really got python running on the iPhone to my   satisfaction, and I can't recommend using it for any serious project   at this stage.      Most notably missing is pyobjc support (which turns out to be much   harder to port to iPhone since it relies on more platform-specific   code)      Also missing is the ability to statically compile modules, (all are   currently built as dylibs which works for development, but to my   knowledge wouldn't be allowed in the App Store)      At this point this project is mostly meant to be a starting point for   anyone smarter than me who wants to and can tackle the above issues.      I really wish it were practical to write apps entirely in Python, but   at this point it seems impossible.      ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "xcode"
        ],
        "URL": "https://stackoverflow.com/questions/3691655/embedding-python-in-an-iphone-app",
        "A_Votes": "21",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So it's a new millennium; Apple has waved their hand; it's now legal to include a Python interpreter in an iPhone (App Store) app.  How does one go about doing this? All the existing discussion (unsurprisingly) refers to jailbreaking. (Older question: Can I write native iPhone apps using Python)  My goal here isn't to write a PyObjC app, but to write a regular ObjC app that runs Python as an embedded library. The Python code will then call back to native Cocoa code. It's the \"control logic is Python code\" pattern.  Is there a guide to getting Python built in XCode, so that my iPhone app can link it? Preferably a stripped-down Python, since I won't need 90% of the standard library.  I can probably figure out the threading and Python-extension API; I've done that on MacOS. But only using command-line compilers, not XCode.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Embedding Python in an iPhone app",
        "A_Content": "  I also started such a project. It comes with its own simplified compile script so there is no need to mess around with autoconf to get your cross compiled static library. It is able to build a completely dependency-free static library of Python with some common modules. It should be easily extensible.  https://github.com/albertz/python-embedded/     ",
        "Language": "Python",
        "Tags": [
            "iphone",
            "python",
            "xcode"
        ],
        "URL": "https://stackoverflow.com/questions/3691655/embedding-python-in-an-iphone-app",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    So it's a new millennium; Apple has waved their hand; it's now legal to include a Python interpreter in an iPhone (App Store) app.  How does one go about doing this? All the existing discussion (unsurprisingly) refers to jailbreaking. (Older question: Can I write native iPhone apps using Python)  My goal here isn't to write a PyObjC app, but to write a regular ObjC app that runs Python as an embedded library. The Python code will then call back to native Cocoa code. It's the \"control logic is Python code\" pattern.  Is there a guide to getting Python built in XCode, so that my iPhone app can link it? Preferably a stripped-down Python, since I won't need 90% of the standard library.  I can probably figure out the threading and Python-extension API; I've done that on MacOS. But only using command-line compilers, not XCode.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Why did pip upgrade from version 10 to version 18?",
        "A_Content": "  First point in the release notes:        Switch to a Calendar based versioning scheme.         https://pip.pypa.io/en/stable/news/   More about calendar versioning: https://calver.org/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "pip"
        ],
        "URL": "https://stackoverflow.com/questions/51476300/why-did-pip-upgrade-from-version-10-to-version-18",
        "A_Votes": "90",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    while running a pip install script I get the following warning:    You are using pip version 10.0.1, however version 18.0 is available   This is very strange. Did the pip project just upgrade from version 10 to version 18? Why?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  It is highly probable that re.finditer uses fairly minimal memory overhead.  def split_iter(string):     return (x.group(0) for x in re.finditer(r\"[A-Za-z']+\", string))   Demo:  >>> list( split_iter(\"A programmer's RegEx test.\") ) ['A', \"programmer's\", 'RegEx', 'test']   edit: I have just confirmed that this takes constant memory in python 3.2.1, assuming my testing methodology was correct. I created a string of very large size (1GB or so), then iterated through the iterable with a for loop (NOT a list comprehension, which would have generated extra memory). This did not result in a noticeable growth of memory (that is, if there was a growth in memory, it was far far less than the 1GB string).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "50",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  The most efficient way I can think of it to write one using the offset parameter of the str.find() method. This avoids lots of memory use, and relying on the overhead of a regexp when it's not needed.    [edit 2016-8-2: updated this to optionally support regex separators]  def isplit(source, sep=None, regex=False):     \"\"\"     generator version of str.split()      :param source:         source string (unicode or bytes)      :param sep:         separator to split on.      :param regex:         if True, will treat sep as regular expression.      :returns:         generator yielding elements of string.     \"\"\"     if sep is None:         # mimic default python behavior         source = source.strip()         sep = \"\\\\s+\"         if isinstance(source, bytes):             sep = sep.encode(\"ascii\")         regex = True     if regex:         # version using re.finditer()         if not hasattr(sep, \"finditer\"):             sep = re.compile(sep)         start = 0         for m in sep.finditer(source):             idx = m.start()             assert idx >= start             yield source[start:idx]             start = m.end()         yield source[start:]     else:         # version using str.find(), less overhead than re.finditer()         sepsize = len(sep)         start = 0         while True:             idx = source.find(sep, start)             if idx == -1:                 yield source[start:]                 return             yield source[start:idx]             start = idx + sepsize   This can be used like you want...  >>> print list(isplit(\"abcb\",\"b\")) ['a','c','']   While there is a little bit of cost seeking within the string each time find() or slicing is performed, this should be minimal since strings are represented as continguous arrays in memory.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  This is generator version of split() implemented via re.search() that does not have the problem of allocating too many substrings.  import re  def itersplit(s, sep=None):     exp = re.compile(r'\\s+' if sep is None else re.escape(sep))     pos = 0     while True:         m = exp.search(s, pos)         if not m:             if pos < len(s) or sep is not None:                 yield s[pos:]             break         if pos < m.start() or sep is not None:             yield s[pos:m.start()]         pos = m.end()   sample1 = \"Good evening, world!\" sample2 = \" Good evening, world! \" sample3 = \"brackets][all][][over][here\" sample4 = \"][brackets][all][][over][here][\"  assert list(itersplit(sample1)) == sample1.split() assert list(itersplit(sample2)) == sample2.split() assert list(itersplit(sample3, '][')) == sample3.split('][') assert list(itersplit(sample4, '][')) == sample4.split('][')   EDIT: Corrected handling of surrounding whitespace if no separator chars are given.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  Here is my implementation, which is much, much faster and more complete than the other answers here. It has 4 separate subfunctions for different cases.  I'll just copy the docstring of the main str_split function:    str_split(s, *delims, empty=None)   Split the string s by the rest of the arguments, possibly omitting empty parts (empty keyword argument is responsible for that). This is a generator function.  When only one delimiter is supplied, the string is simply split by it. empty is then True by default.  str_split('[]aaa[][]bb[c', '[]')     -> '', 'aaa', '', 'bb[c' str_split('[]aaa[][]bb[c', '[]', empty=False)     -> 'aaa', 'bb[c'   When multiple delimiters are supplied, the string is split by longest possible sequences of those delimiters by default, or, if empty is set to True, empty strings between the delimiters are also included. Note that the delimiters in this case may only be single characters.  str_split('aaa, bb : c;', ' ', ',', ':', ';')     -> 'aaa', 'bb', 'c' str_split('aaa, bb : c;', *' ,:;', empty=True)     -> 'aaa', '', 'bb', '', '', 'c', ''   When no delimiters are supplied, string.whitespace is used, so the effect is the same as str.split(), except this function is a generator.  str_split('aaa\\\\t  bb c \\\\n')     -> 'aaa', 'bb', 'c'     import string  def _str_split_chars(s, delims):     \"Split the string `s` by characters contained in `delims`, including the \\     empty parts between two consecutive delimiters\"     start = 0     for i, c in enumerate(s):         if c in delims:             yield s[start:i]             start = i+1     yield s[start:]  def _str_split_chars_ne(s, delims):     \"Split the string `s` by longest possible sequences of characters \\     contained in `delims`\"     start = 0     in_s = False     for i, c in enumerate(s):         if c in delims:             if in_s:                 yield s[start:i]                 in_s = False         else:             if not in_s:                 in_s = True                 start = i     if in_s:         yield s[start:]   def _str_split_word(s, delim):     \"Split the string `s` by the string `delim`\"     dlen = len(delim)     start = 0     try:         while True:             i = s.index(delim, start)             yield s[start:i]             start = i+dlen     except ValueError:         pass     yield s[start:]  def _str_split_word_ne(s, delim):     \"Split the string `s` by the string `delim`, not including empty parts \\     between two consecutive delimiters\"     dlen = len(delim)     start = 0     try:         while True:             i = s.index(delim, start)             if start!=i:                 yield s[start:i]             start = i+dlen     except ValueError:         pass     if start<len(s):         yield s[start:]   def str_split(s, *delims, empty=None):     \"\"\"\\ Split the string `s` by the rest of the arguments, possibly omitting empty parts (`empty` keyword argument is responsible for that). This is a generator function.  When only one delimiter is supplied, the string is simply split by it. `empty` is then `True` by default.     str_split('[]aaa[][]bb[c', '[]')         -> '', 'aaa', '', 'bb[c'     str_split('[]aaa[][]bb[c', '[]', empty=False)         -> 'aaa', 'bb[c'  When multiple delimiters are supplied, the string is split by longest possible sequences of those delimiters by default, or, if `empty` is set to `True`, empty strings between the delimiters are also included. Note that the delimiters in this case may only be single characters.     str_split('aaa, bb : c;', ' ', ',', ':', ';')         -> 'aaa', 'bb', 'c'     str_split('aaa, bb : c;', *' ,:;', empty=True)         -> 'aaa', '', 'bb', '', '', 'c', ''  When no delimiters are supplied, `string.whitespace` is used, so the effect is the same as `str.split()`, except this function is a generator.     str_split('aaa\\\\t  bb c \\\\n')         -> 'aaa', 'bb', 'c' \"\"\"     if len(delims)==1:         f = _str_split_word if empty is None or empty else _str_split_word_ne         return f(s, delims[0])     if len(delims)==0:         delims = string.whitespace     delims = set(delims) if len(delims)>=4 else ''.join(delims)     if any(len(d)>1 for d in delims):         raise ValueError(\"Only 1-character multiple delimiters are supported\")     f = _str_split_chars if empty else _str_split_chars_ne     return f(s, delims)   This function works in Python 3, and an easy, though quite ugly, fix can be applied to make it work in both 2 and 3 versions. The first lines of the function should be changed to:  def str_split(s, *delims, **kwargs):     \"\"\"...docstring...\"\"\"     empty = kwargs.get('empty')      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  I don't see any obvious benefit to a generator version of split().  The generator object is going to have to contain the whole string to iterate over so you're not going to save any memory by having a generator.  If you wanted to write one it would be fairly easy though:  import string  def gsplit(s,sep=string.whitespace):     word = []      for c in s:         if c in sep:             if word:                 yield \"\".join(word)                 word = []         else:             word.append(c)      if word:         yield \"\".join(word)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  Did some performance testing on the various methods proposed (I won't repeat them here). Some results:   str.split (default    = 0.3461570239996945 manual search (by character) (one of Dave Webb's answer's) = 0.8260340550004912 re.finditer (ninjagecko's answer)     = 0.698872097000276 str.find (one of Eli Collins's answers)      = 0.7230395330007013 itertools.takewhile (Ignacio Vazquez-Abrams's answer) = 2.023023967998597 str.split(..., maxsplit=1) recursion = N/A†   †The recursion answers (string.split with maxsplit = 1) fail to complete in a reasonable time, given string.splits speed they may work better on shorter strings, but then I can't see the use-case for short strings where memory isn't an issue anyway.  Tested using timeit on:  the_text = \"100 \" * 9999 + \"100\"  def test_function( method ):     def fn( ):         total = 0          for x in method( the_text ):             total += int( x )          return total      return fn   This raises another question as to why string.split is so much faster despite its memory usage.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  No, but it should be easy enough to write one using itertools.takewhile().  EDIT:  Very simple, half-broken implementation:  import itertools import string  def isplitwords(s):   i = iter(s)   while True:     r = []     for c in itertools.takewhile(lambda x: not x in string.whitespace, i):       r.append(c)     else:       if r:         yield ''.join(r)         continue       else:         raise StopIteration()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  I wrote a version of @ninjagecko's answer that behaves more like string.split (i.e. whitespace delimited by default and you can specify a delimiter).  def isplit(string, delimiter = None):     \"\"\"Like string.split but returns an iterator (lazy)      Multiple character delimters are not handled.     \"\"\"      if delimiter is None:         # Whitespace delimited by default         delim = r\"\\s\"      elif len(delimiter) != 1:         raise ValueError(\"Can only handle single character delimiters\",                         delimiter)      else:         # Escape, incase it's \"\\\", \"*\" etc.         delim = re.escape(delimiter)      return (x.group(0) for x in re.finditer(r\"[^{}]+\".format(delim), string))   Here are the tests I used (in both python 3 and python 2):  # Wrapper to make it a list def helper(*args,  **kwargs):     return list(isplit(*args, **kwargs))  # Normal delimiters assert helper(\"1,2,3\", \",\") == [\"1\", \"2\", \"3\"] assert helper(\"1;2;3,\", \";\") == [\"1\", \"2\", \"3,\"] assert helper(\"1;2 ;3,  \", \";\") == [\"1\", \"2 \", \"3,  \"]  # Whitespace assert helper(\"1 2 3\") == [\"1\", \"2\", \"3\"] assert helper(\"1\\t2\\t3\") == [\"1\", \"2\", \"3\"] assert helper(\"1\\t2 \\t3\") == [\"1\", \"2\", \"3\"] assert helper(\"1\\n2\\n3\") == [\"1\", \"2\", \"3\"]  # Surrounding whitespace dropped assert helper(\" 1 2  3  \") == [\"1\", \"2\", \"3\"]  # Regex special characters assert helper(r\"1\\2\\3\", \"\\\\\") == [\"1\", \"2\", \"3\"] assert helper(r\"1*2*3\", \"*\") == [\"1\", \"2\", \"3\"]  # No multi-char delimiters allowed try:     helper(r\"1,.2,.3\", \",.\")     assert False except ValueError:     pass   python's regex module says that it does \"the right thing\" for unicode whitespace, but I haven't actually tested it.  Also available as a gist.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  If you would also like to be able to read an iterator (as well as return one) try this:  import itertools as it  def iter_split(string, sep=None):     sep = sep or ' '     groups = it.groupby(string, lambda s: s != sep)     return (''.join(g) for k, g in groups if k)   Usage  >>> list(iter_split(iter(\"Good evening, world!\"))) ['Good', 'evening,', 'world!']      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  more_itertools.spit_at offers an analog to str.split for iterators.  >>> import more_itertools as mit   >>> list(mit.split_at(\"abcdcba\", lambda x: x == \"b\")) [['a'], ['c', 'd', 'c'], ['a']]  >>> \"abcdcba\".split(\"b\") ['a', 'cdc', 'a']   more_itertools is a third-party package.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  def split_generator(f,s):     \"\"\"     f is a string, s is the substring we split on.     This produces a generator rather than a possibly     memory intensive list.      \"\"\"     i=0     j=0     while j<len(f):         if i>=len(f):             yield f[j:]             j=i         elif f[i] != s:             i=i+1         else:             yield [f[j:i]]             j=i+1             i=i+1      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  I wanted to show how to use the find_iter solution to return a generator for given delimiters and then use the pairwise recipe from itertools to build a previous next iteration which will get the actual words as in the original split method.    from more_itertools import pairwise import re  string = \"dasdha hasud hasuid hsuia dhsuai dhasiu dhaui d\" delimiter = \" \" # split according to the given delimiter including segments beginning at the beginning and ending at the end for prev, curr in pairwise(re.finditer(\"^|[{0}]+|$\".format(delimiter), string)):     print(string[prev.end(): curr.start()])     note:    I use prev & curr instead of prev & next because overriding next in python is a very bad idea This is quite efficient      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  Need is for me, at least, with files used as generators.  This is version I did in preparation to some huge files with empty line separated blocks of text (this would need to be thoroughly tested for corner cases in case you would use it in production system):  from __future__ import print_function  def isplit(iterable, sep=None):     r = ''     for c in iterable:         r += c         if sep is None:             if not c.strip():                 r = r[:-1]                 if r:                     yield r                     r = ''                             elif r.endswith(sep):             r=r[:-len(sep)]             yield r             r = ''     if r:         yield r   def read_blocks(filename):     \"\"\"read a file as a sequence of blocks separated by empty line\"\"\"     with open(filename) as ifh:         for block in isplit(ifh, '\\n\\n'):             yield block.splitlines()             if __name__ == \"__main__\":     for lineno, block in enumerate(read_blocks(\"logfile.txt\"), 1):         print(lineno,':')         print('\\n'.join(block))         print('-'*40)      print('Testing skip with None.')     for word in isplit('\\tTony   \\t  Jarkko \\n  Veijalainen\\n'):         print(word)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Is there a generator version of `string.split()` in Python?",
        "A_Content": "  You can build one easily using str.split itself with a limit:  def isplit(s, sep=None):     while s:         parts = s.split(sep, 1)         if len(parts) == 2:             s = parts[1]         else:             s = ''         yield parts[0]   This way, you don't have to replicate strip()'s functionality and behaviour (e.g. when sep=None) and it depends on its possibly fast native implementation. I assume that string.split will stop scanning the string for separators once it has enough 'parts'.  As Glenn Maynard points out, this scales poorly for large strings (O(n^2)). I've confirmed this through 'timit' tests.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "string",
            "generator"
        ],
        "URL": "https://stackoverflow.com/questions/3862010/is-there-a-generator-version-of-string-split-in-python",
        "A_Votes": "-1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version?      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  py2exe is probably what you want, but it only works on Windows. PyInstaller works on Windows and Linux. Py2app works on the Mac.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "78",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  I found this presentation to be very helpfull.  How I Distribute Python applications on Windows - py2exe & InnoSetup  From the site:     There are many deployment options for   Python code. I'll share what has   worked well for me on Windows,   packaging command line tools and   services using py2exe and InnoSetup.   I'll demonstrate a simple build script   which creates windows binaries and an   InnoSetup installer in one step. In   addition, I'll go over common errors   which come up when using py2exe and   hints on troubleshooting them. This is   a short talk, so there will be a   follow-up Open Space session to share   experience and help each other solve   distribution problems.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "10",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  Also known as Frozen Binaries but not the same as as the output of a true compiler- they run byte code through a virtual machine (PVM). Run the same as a compiled program just larger because the program is being compiled along with the PVM. Py2exe can freeze standalone programs that use the tkinter, PMW, wxPython, and PyGTK GUI libraties; programs that use the pygame game programming toolkit; win32com client programs; and more.  The Stackless Python system is a standard CPython implementation variant that does not save state on the C language call stack. This makes Python more easy to port to small stack architectures, provides efficient multiprocessing options, and fosters novel programming structures such as coroutines. Other systems of study that are working on future development: Pyrex is working on the Cython system, the Parrot project, the PyPy is working on replacing the PVM altogether, and of course the founder of Python is working with Google to get Python to run 5 times faster than C with the Unladen Swallow project. In short, py2exe is the easiest and Cython is more efficient for now until these projects improve the Python Virtual Machine (PVM) for standalone files.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  Not on the freehackers list is gui2exe which can be used to build standalone Windows executables, Linux applications and Mac OS application bundles and plugins starting from Python scripts.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  See a short list of python packaging tools on FreeHackers.org.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  Use cx_Freeze to make exe your python program     ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I make an EXE file from a Python program? [duplicate]",
        "A_Content": "  py2exe:     py2exe is a Python Distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "exe",
            "executable"
        ],
        "URL": "https://stackoverflow.com/questions/49146/how-can-i-make-an-exe-file-from-a-python-program",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "          This question already has an answer here:                              How can I create a directly-executable cross-platform GUI app using Python?                                        10 answers                                                    How to deploy Python to Windows users?                                        4 answers                                                    Create a single executable from a Python project                                        2 answers                                          I've used several modules to make EXEs for Python, but I'm not sure if I'm doing it right.  How should I go about this, and why?  Please base your answers on personal experience, and provide references where necessary.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  My general rule is this - is the operation performed on the object or by the object?   if it is done by the object, it should be a member operation. If it could apply to other things too, or is done by something else to the object then it should be a function (or perhaps a member of something else).  When introducing programming, it is traditional (albeit implementation incorrect) to describe objects in terms of real-world objects such as cars. You mention a duck, so let's go with that.  class duck:      def __init__(self):pass     def eat(self, o): pass      def crap(self) : pass     def die(self)     ....   In the context of the \"objects are real things\" analogy, it is \"correct\" to add a class method for anything which the object can do. So say I want to kill off a duck, do I add a .kill() to the duck? No... as far as I know animals do not commit suicide. Therefore if I want to kill a duck I should do this:  def kill(o):     if isinstance(o, duck):         o.die()     elif isinstance(o, dog):         print \"WHY????\"         o.die()     elif isinstance(o, nyancat):         raise Exception(\"NYAN \"*9001)     else:        print \"can't kill it.\"   Moving away from this analogy, why do we use methods and classes? Because we want to contain data and hopefully structure our code in a manner such that it will be reusable and extensible in the future. This brings us to the notion of encapsulation which is so dear to OO design.   The encapsulation principal is really what this comes down to: as a designer you should hide everything about the implementation and class internals which it is not absolutely necessarily for any user or other developer to access. Because we deal with instances of classes, this reduces to \"what operations are crucial on this instance\". If an operation is not instance specific, then it should not be a member function.  TL;DR: what @Bryan said. If it operates on an instance and needs to access data which is internal to the class instance, it should be a member function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "64",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  Use a class when you want to:  1) Isolate calling code from implementation details -- taking advantage of abstraction and encapsulation.  2) When you want to be substitutable for other objects -- taking advantage of polymorphism.  3) When you want to reuse code for similar objects -- taking advantage of inheritance.  Use a function for calls that make sense across many different object types -- for example, the builtin len and repr functions apply to many kinds of objects.  That being said, the choice sometimes comes down to a matter of taste.  Think in terms of what  is most convenient and readable for typical calls.  For example, which would be better (x.sin()**2 + y.cos()**2).sqrt() or sqrt(sin(x)**2 + cos(y)**2)?     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "23",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  Here's a simple rule of thumb: if the code acts upon a single instance of an object, use a method. Even better: use a method unless there is a compelling reason to write it as a function.   In your specific example, you want it to look like this:  chessboard = Chessboard() ... chessboard.get_king_moves()   Don't over think it. Always use methods until the point comes where you say to yourself \"it doesn't make sense to make this a method\", in which case you can make a function.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  I usually think of an object like a person.  Attributes are the person's name, height, shoe size, etc.  Methods and functions are operations that the person can perform.  If the operation could be done by just any ol' person, without requiring anything unique to this one specific person (and without changing anything on this one specific person), then it's a function and should be written as such.  If an operation is acting upon the person (e.g. eating, walking, ...) or requires something unique to this person to get involved (like dancing, writing a book, ...), then it should be a method.  Of course, it is not always trivial to translate this into the specific object you're working with, but I find it is a good way to think of it.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "7",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  Generally I use classes to implement a logical set of capabilities for some thing, so that in the rest of my program I can reason about the thing, not having to worry about all the little concerns that make up its implementation.  Anything that's part of that core abstraction of \"what you can do with a thing\" should usually be a method. This generally includes everything that can alter a thing, as the internal data state is usually considered private and not part of the logical idea of \"what you can do with a thing\".  When you come to higher level operations, especially if they involve multiple things, I find they are usually most naturally expressed as functions, if they can be built out of the public abstraction of a thing without needing special access to the internals (unless they're methods of some other object). This has the big advantage that when I decide to completely rewrite the internals of how my thing works (without changing the interface), I just have a small core set of methods to rewrite, and then all the external functions written in terms of those methods will Just Work. I find that insisting that all operations to do with class X are methods on class X leads to over-complicated classes.  It depends on the code I'm writing though. For some programs I model them as a collection of objects whose interactions give rise to the behavior of the program; here most important functionality is closely coupled to a single object, and so is implemented in methods, with a scattering of utility functions. For other programs the most important stuff is a set of functions that manipulate data, and classes are in use only to implement the natural \"duck types\" that are manipulated by the functions.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "In Python, when should I use a function instead of a method?",
        "A_Content": "  You may say that, \"in the face of ambiguity, refuse the temptation to guess\".  However, it's not even a guess. You're absolutely sure that the outcomes of both approaches are the same in that they solve your problem.  I believe it is only a good thing to have multiple ways to accomplishing goals. I'd humbly tell you, as other users did already, to employ whichever \"tastes better\" / feels more intuitive, in terms of language.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "function",
            "coding-style",
            "methods"
        ],
        "URL": "https://stackoverflow.com/questions/8108688/in-python-when-should-i-use-a-function-instead-of-a-method",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    The Zen of Python states that there should only be one way to do things- yet frequently I run into the problem of deciding when to use a function versus when to use a method.  Let's take a trivial example- a ChessBoard object. Let's say we need some way to get all the legal King moves available on the board. Do we write ChessBoard.get_king_moves() or get_king_moves(chess_board)?  Here are some related questions I looked at:   Why does python use 'magic methods'? Is there a reason Python strings don't have a string length method?   The answers I got were largely inconclusive:     Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?      The major reason is history. Functions were used for those operations that were generic for a group of types and which were   intended to work even for objects that didn’t have methods at all   (e.g. tuples). It is also convenient to have a function that can   readily be applied to an amorphous collection of objects when you use   the functional features of Python (map(), apply() et al).      In fact, implementing len(), max(), min() as a built-in function is actually less code than implementing them as methods for each type.   One can quibble about individual cases but it’s a part of Python, and   it’s too late to make such fundamental changes now. The functions have   to remain to avoid massive code breakage.   While interesting, the above doesn't really say much as to what strategy to adopt.     This is one of the reasons - with custom methods, developers would be   free to choose a different method name, like getLength(), length(),   getlength() or whatsoever. Python enforces strict naming so that the   common function len() can be used.   Slightly more interesting. My take is that functions are in a sense, the Pythonic version of interfaces.  Lastly, from Guido himself:          Talking about the Abilities/Interfaces made me think about some of our     \"rogue\" special method names.  In the Language Reference, it says, \"A     class can implement certain operations that are invoked by special     syntax (such as arithmetic operations or subscripting and slicing) by     defining methods with special names.\"  But there are all these methods     with special names like __len__ or __unicode__ which seem to be     provided for the benefit of built-in functions, rather than for     support of syntax.  Presumably in an interface-based Python, these     methods would turn into regularly-named methods on an ABC, so that     __len__ would become  class container:   ...   def len(self):     raise NotImplemented           Though, thinking about it some more, I don't see why all syntactic     operations wouldn't just invoke the appropriate normally-named method     on a specific ABC.  \"<\", for instance, would presumably invoke     \"object.lessthan\" (or perhaps \"comparable.lessthan\").  So another     benefit would be the ability to wean Python away from this     mangled-name oddness, which seems to me an HCI improvement.         Hm. I'm not sure I agree (figure that :-).      There are two bits of \"Python rationale\" that I'd like to explain   first.      First of all, I chose len(x) over x.len() for HCI reasons (def   __len__() came much later). There are two intertwined reasons actually, both HCI:      (a) For some operations, prefix notation just reads better than   postfix -- prefix (and infix!) operations have a long tradition in   mathematics which likes notations where the visuals help the   mathematician thinking about a problem. Compare the easy with which we   rewrite a formula like x*(a+b) into x*a + x*b to the clumsiness of   doing the same thing using a raw OO notation.      (b) When I read code that says len(x) I know that it is asking for   the length of something. This tells me two things: the result is an   integer, and the argument is some kind of container. To the contrary,   when I read x.len(), I have to already know that x is some kind of   container implementing an interface or inheriting from a class that   has a standard len(). Witness the confusion we occasionally have when   a class that is not implementing a mapping has a get() or keys()   method, or something that isn't a file has a write() method.      Saying the same thing in another way, I see 'len' as a built-in   operation. I'd hate to lose that. I can't say for sure whether you meant that or not, but 'def len(self): ...' certainly sounds like you   want to demote it to an ordinary method. I'm strongly -1 on that.      The second bit of Python rationale I promised to explain is the reason   why I chose special methods to look __special__ and not merely   special. I was anticipating lots of operations that classes might want   to override, some standard (e.g. __add__ or __getitem__), some not so   standard (e.g. pickle's __reduce__ for a long time had no support in C   code at all). I didn't want these special operations to use ordinary   method names, because then pre-existing classes, or classes written by   users without an encyclopedic memory for all the special methods,   would be liable to accidentally define operations they didn't mean to   implement, with possibly disastrous consequences. Ivan Krstić   explained this more concise in his message, which arrived after I'd   written all this up.      --    --Guido van Rossum (home page: http://www.python.org/~guido/)   My understanding of this is that in certain cases, prefix notation just makes more sense (ie, Duck.quack makes more sense than quack(Duck) from a linguistic standpoint.) and again, the functions allow for \"interfaces\".  In such a case, my guess would be to implement get_king_moves based solely on Guido's first point. But that still leaves a lot of open questions regarding say, implementing a stack and queue class with similar push and pop methods- should they be functions or methods? (here I would guess functions, because I really want to signal a push-pop interface)  TLDR: Can someone explain what the strategy for deciding when to use functions vs. methods should be?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Specifying and saving a figure with exact size in pixels",
        "A_Content": "  Matplotlib doesn't work with pixels directly, but rather physical sizes and DPI. If you want to display a figure with a certain pixel size, you need to know the DPI of your monitor. For example this link will detect that for you.  If you have an image of 3841x7195 pixels it is unlikely that you monitor will be that large, so you won't be able to show a figure of that size (matplotlib requires the figure to fit in the screen, if you ask for a size too large it will shrink to the screen size). Let's imagine you want an 800x800 pixel image just for an example. Here's how to show an 800x800 pixel image in my monitor (my_dpi=96):  plt.figure(figsize=(800/my_dpi, 800/my_dpi), dpi=my_dpi)   So you basically just divide the dimensions in inches by your DPI.   If you want to save a figure of a specific size, then it is a different matter. Screen DPIs are not so important anymore (unless you ask for a figure that won't fit in the screen). Using the same example of the 800x800 pixel figure, we can save it in different resolutions using the dpi keyword of savefig. To save it in the same resolution as the screen just use the same dpi:  plt.savefig('my_fig.png', dpi=my_dpi)   To to save it as an 8000x8000 pixel image, use a dpi 10 times larger:  plt.savefig('my_fig.png', dpi=my_dpi * 10)   Note that the setting of the DPI is not supported by all backends. Here, the PNG backend is used, but the pdf and ps backends will implement the size differently. Also, changing the DPI and sizes will also affect things like fontsize. A larger DPI will keep the same relative sizes of fonts and elements, but if you want smaller fonts for a larger figure you need to increase the physical size instead of the DPI.   Getting back to your example, if you want to save a image with 3841 x 7195 pixels, you could do the following:  plt.figure(figsize=(3.841, 7.195), dpi=100) ( your code ...) plt.savefig('myfig.png', dpi=1000)   Note that I used the figure dpi of 100 to fit in most screens, but saved with dpi=1000 to achieve the required resolution. In my system this produces a png with 3840x7190 pixels -- it seems that the DPI saved is always 0.02 pixels/inch smaller than the selected value, which will have a (small) effect on large image sizes. Some more discussion of this here.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/13714454/specifying-and-saving-a-figure-with-exact-size-in-pixels",
        "A_Votes": "102",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Say I have an image of size 3841 x 7195 pixels. I would like to save the contents of the figure to disk, resulting in an image of the exact size I specify in pixels.  No axis, no titles. Just the image. I don't personally care about DPIs, as I only want to specify the size the image takes in the screen in disk in pixels.  I have read other threads, and they all seem to do conversions to inches and then specify the dimensions of the figure in inches and adjust dpi's in some way. I would like to avoid dealing with the potential loss of accuracy that could result from pixel-to-inches conversions.  I have tried with:  w = 7195 h = 3841 fig = plt.figure(frameon=False) fig.set_size_inches(w,h) ax = plt.Axes(fig, [0., 0., 1., 1.]) ax.set_axis_off() fig.add_axes(ax) ax.imshow(im_np, aspect='normal') fig.savefig(some_path, dpi=1)   with no luck (Python complains that width and height must each be below 32768 (?))  From everything I have seen, matplotlib requires the figure size to be specified in inches and dpi, but I am only interested in the pixels the figure takes in disk. How can I do this?  To clarify: I am looking for a way to do this with matplotlib, and not with other image-saving libraries.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Specifying and saving a figure with exact size in pixels",
        "A_Content": "  This worked for me, based on your code, generating a 93Mb png image with color noise and the desired dimensions:  import matplotlib.pyplot as plt import numpy  w = 7195 h = 3841  im_np = numpy.random.rand(h, w)  fig = plt.figure(frameon=False) fig.set_size_inches(w,h) ax = plt.Axes(fig, [0., 0., 1., 1.]) ax.set_axis_off() fig.add_axes(ax) ax.imshow(im_np, aspect='normal') fig.savefig('figure.png', dpi=1)   I am using the last PIP versions of the Python 2.7 libraries in Linux Mint 13.  Hope that helps!     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/13714454/specifying-and-saving-a-figure-with-exact-size-in-pixels",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have an image of size 3841 x 7195 pixels. I would like to save the contents of the figure to disk, resulting in an image of the exact size I specify in pixels.  No axis, no titles. Just the image. I don't personally care about DPIs, as I only want to specify the size the image takes in the screen in disk in pixels.  I have read other threads, and they all seem to do conversions to inches and then specify the dimensions of the figure in inches and adjust dpi's in some way. I would like to avoid dealing with the potential loss of accuracy that could result from pixel-to-inches conversions.  I have tried with:  w = 7195 h = 3841 fig = plt.figure(frameon=False) fig.set_size_inches(w,h) ax = plt.Axes(fig, [0., 0., 1., 1.]) ax.set_axis_off() fig.add_axes(ax) ax.imshow(im_np, aspect='normal') fig.savefig(some_path, dpi=1)   with no luck (Python complains that width and height must each be below 32768 (?))  From everything I have seen, matplotlib requires the figure size to be specified in inches and dpi, but I am only interested in the pixels the figure takes in disk. How can I do this?  To clarify: I am looking for a way to do this with matplotlib, and not with other image-saving libraries.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Specifying and saving a figure with exact size in pixels",
        "A_Content": "  Based on the accepted response by tiago, here is a small generic function that exports a numpy array to an image having the same resolution as the array:  import matplotlib.pyplot as plt import numpy as np  def export_figure_matplotlib(arr, f_name, dpi=200, resize_fact=1, plt_show=False):     \"\"\"     Export array as figure in original resolution     :param arr: array of image to save in original resolution     :param f_name: name of file where to save figure     :param resize_fact: resize facter wrt shape of arr, in (0, np.infty)     :param dpi: dpi of your screen     :param plt_show: show plot or not     \"\"\"     fig = plt.figure(frameon=False)     fig.set_size_inches(arr.shape[1]/dpi, arr.shape[0]/dpi)     ax = plt.Axes(fig, [0., 0., 1., 1.])     ax.set_axis_off()     fig.add_axes(ax)     ax.imshow(arr)     plt.savefig(f_name, dpi=(dpi * resize_fact))     if plt_show:         plt.show()     else:         plt.close()   As said in the previous reply by tiago, the screen DPI needs to be found first, which can be done here for instance: http://dpi.lv  I've added an additional argument resize_fact in the function which which you can export the image to 50% (0.5) of the original resolution, for instance.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "matplotlib",
            "scipy"
        ],
        "URL": "https://stackoverflow.com/questions/13714454/specifying-and-saving-a-figure-with-exact-size-in-pixels",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Say I have an image of size 3841 x 7195 pixels. I would like to save the contents of the figure to disk, resulting in an image of the exact size I specify in pixels.  No axis, no titles. Just the image. I don't personally care about DPIs, as I only want to specify the size the image takes in the screen in disk in pixels.  I have read other threads, and they all seem to do conversions to inches and then specify the dimensions of the figure in inches and adjust dpi's in some way. I would like to avoid dealing with the potential loss of accuracy that could result from pixel-to-inches conversions.  I have tried with:  w = 7195 h = 3841 fig = plt.figure(frameon=False) fig.set_size_inches(w,h) ax = plt.Axes(fig, [0., 0., 1., 1.]) ax.set_axis_off() fig.add_axes(ax) ax.imshow(im_np, aspect='normal') fig.savefig(some_path, dpi=1)   with no luck (Python complains that width and height must each be below 32768 (?))  From everything I have seen, matplotlib requires the figure size to be specified in inches and dpi, but I am only interested in the pixels the figure takes in disk. How can I do this?  To clarify: I am looking for a way to do this with matplotlib, and not with other image-saving libraries.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  int and long were \"unified\" a few versions back. Before that it was possible to overflow an int through math ops.  3.x has further advanced this by eliminating int altogether and only having long.  Python 2: sys.maxint contains the maximum value a Python int can hold.  Python 3: sys.maxsize contains the maximum value a Python int can hold.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "94",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  This PEP should help.   Bottom line is that you really shouldn't have to worry about it in python versions > 2.4     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "12",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  Interesting.  On my 64-bit (i7 Ubuntu) box:  >>> print type(0x7FFFFFFF) <type 'int'> >>> print type(0x7FFFFFFF+1) <type 'int'>   Guess it steps up to 64 bit ints on a larger machine.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  On my machine:  >>> print type(1<<30) <type 'int'> >>> print type(1<<31) <type 'long'> >>> print type(0x7FFFFFFF) <type 'int'> >>> print type(0x7FFFFFFF+1) <type 'long'>   Python uses ints (32 bit signed integers, I don't know if they are C ints under the hood or not) for values that fit into 32 bit, but automatically switches to longs (arbitrarily large number of bits - i.e. bignums)  for anything larger. I'm guessing this speeds things up for smaller values while avoiding any overflows with a seamless transition to bignums.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  Python 2.7.9 auto promotes numbers. For a case where one is unsure to use int() or long().  >>> a = int(\"123\") >>> type(a) <type 'int'> >>> a = int(\"111111111111111111111111111111111111111111111111111\") >>> type(a) <type 'long'>      ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  From python 3.x, the unified integer libries are even more smarter than older versions. On my (i7 Ubuntu) box I got the following,  >>> type(math.factorial(30)) <class 'int'>   For implementation details refer Include/longintrepr.h, Objects/longobject.c and Modules/mathmodule.c files. The last file is a dynamic module (compiled to an so file). The code is well commented to follow.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  It manages them because int and long are sibling class definitions.  They have appropriate methods for +, -, *, /, etc., that will produce results of the appropriate class.  For example  >>> a=1<<30 >>> type(a) <type 'int'> >>> b=a*2 >>> type(b) <type 'long'>   In this case, the class int has a __mul__ method (the one that implements *) which creates a long result when required.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How does Python manage int and long?",
        "A_Content": "  Python 2 will automatically set the type based on the size of the value. A guide of max values can be found below.  The Max value of the default Int in Python 2 is 65535, anything above that will be a long  For example:  >> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   In Python 3 the long datatype has been removed and all integer values are handled by the Int class. The default size of Int will depend on your CPU architecture.  For example:    32 bit systems the default datatype for integers will be 'Int32'  64 bit systems the default datatype for integers will be 'Int64'   The min/max values of each type can be found below:   Int8: [-128,127] Int16: [-32768,32767] Int32: [-2147483648,2147483647] Int64: [-9223372036854775808,9223372036854775807] Int128: [-170141183460469231731687303715884105728,170141183460469231731687303715884105727] UInt8: [0,255] UInt16: [0,65535] UInt32: [0,4294967295] UInt64: [0,18446744073709551615] UInt128: [0,340282366920938463463374607431768211455]   If the size of your Int exceeds the limits mentioned above, python will automatically change it's type and allocate more memory to handle this increase in min/max values. Where in Python 2, it would convert into 'long', it now just converts into the next size of Int.  Example: If you are using a 32 bit operating system, your max value of an Int will be 2147483647 by default. If a value of 2147483648 or more is assigned, the type will be changed to Int64.  There are different ways to check the size of the int and it's memory allocation. Note: In Python 3, using the built-in type() method will always return <class 'int'> no matter what size Int you are using.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "integer"
        ],
        "URL": "https://stackoverflow.com/questions/2104884/how-does-python-manage-int-and-long",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does anybody know how Python manage internally int and long types?    Does it choose the right type dynamically?  What is the limit for an int? I am using Python 2.6, Is is different with previous versions?   How should I understand the code below?  >>> print type(65535) <type 'int'> >>> print type(65536*65536) <type 'long'>   Update:   >>> print type(0x7fffffff) <type 'int'> >>> print type(0x80000000) <type 'long'>      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How can I perform two-dimensional interpolation using scipy?",
        "A_Content": "  Disclaimer: I'm mostly writing this post with syntactical considerations and general behaviour in mind. I'm not familiar with the memory and CPU aspect of the methods described, and I aim this answer at those who have reasonably small sets of data, such that the quality of the interpolation can be the main aspect to consider. I am aware that when working with very large data sets, the better-performing methods (namely griddata and Rbf) might not be feasible.  I'm going to compare three kinds of multi-dimensional interpolation methods (interp2d/splines, griddata and Rbf). I will subject them to two kinds of interpolation tasks and two kinds of underlying functions (points from which are to be interpolated). The specific examples will demonstrate two-dimensional interpolation, but the viable methods are applicable in arbitrary dimensions. Each method provides various kinds of interpolation; in all cases I will use cubic interpolation (or something close1). It's important to note that whenever you use interpolation you introduce bias compared to your raw data, and the specific methods used affect the artifacts that you will end up with. Always be aware of this, and interpolate responsibly.  The two interpolation tasks will be   upsampling (input data is on a rectangular grid, output data is on a denser grid) interpolation of scattered data onto a regular grid   The two functions (over the domain [x,y] in [-1,1]x[-1,1]) will be   a smooth and friendly function: cos(pi*x)*sin(pi*y); range in [-1, 1] an evil (and in particular, non-continuous) function: x*y/(x^2+y^2) with a value of 0.5 near the origin; range in [-0.5, 0.5]   Here's how they look:    I will first demonstrate how the three methods behave under these four tests, then I'll detail the syntax of all three. If you know what you should expect from a method, you might not want to waste your time learning its syntax (looking at you, interp2d).  Test data  For the sake of explicitness, here is the code with which I generated the input data. While in this specific case I'm obviously aware of the function underlying the data, I will only use this to generate input for the interpolation methods. I use numpy for convenience (and mostly for generating the data), but scipy alone would suffice too.  import numpy as np import scipy.interpolate as interp  # auxiliary function for mesh generation def gimme_mesh(n):     minval = -1     maxval =  1     # produce an asymmetric shape in order to catch issues with transpositions     return np.meshgrid(np.linspace(minval,maxval,n), np.linspace(minval,maxval,n+1))  # set up underlying test functions, vectorized def fun_smooth(x, y):     return np.cos(np.pi*x)*np.sin(np.pi*y)  def fun_evil(x, y):     # watch out for singular origin; function has no unique limit there     return np.where(x**2+y**2>1e-10, x*y/(x**2+y**2), 0.5)  # sparse input mesh, 6x7 in shape N_sparse = 6 x_sparse,y_sparse = gimme_mesh(N_sparse) z_sparse_smooth = fun_smooth(x_sparse, y_sparse) z_sparse_evil = fun_evil(x_sparse, y_sparse)  # scattered input points, 10^2 altogether (shape (100,)) N_scattered = 10 x_scattered,y_scattered = np.random.rand(2,N_scattered**2)*2 - 1 z_scattered_smooth = fun_smooth(x_scattered, y_scattered) z_scattered_evil = fun_evil(x_scattered, y_scattered)  # dense output mesh, 20x21 in shape N_dense = 20 x_dense,y_dense = gimme_mesh(N_dense)   Smooth function and upsampling  Let's start with the easiest task. Here's how an upsampling from a mesh of shape [6,7] to one of [20,21] works out for the smooth test function:    Even though this is a simple task, there are already subtle differences between the outputs. At a first glance all three outputs are reasonable. There are two features to note, based on our prior knowledge of the underlying function: the middle case of griddata distorts the data most. Note the y==-1 boundary of the plot (nearest the x label): the function should be strictly zero (since y==-1 is a nodal line for the smooth function), yet this is not the case for griddata. Also note the x==-1 boundary of the plots (behind, to the left): the underlying function has a local maximum (implying zero gradient near the boundary) at [-1, -0.5], yet the griddata output shows clearly non-zero gradient in this region. The effect is subtle, but it's a bias none the less. (The fidelity of Rbf is even better with the default choice of radial functions, dubbed multiquadratic.)  Evil function and upsampling  A bit harder task is to perform upsampling on our evil function:    Clear differences are starting to show among the three methods. Looking at the surface plots, there are clear spurious extrema appearing in the output from interp2d (note the two humps on the right side of the plotted surface). While griddata and Rbf seem to produce similar results at first glance, the latter seems to produce a deeper minimum near [0.4, -0.4] that is absent from the underlying function.  However, there is one crucial aspect in which Rbf is far superior: it respects the symmetry of the underlying function (which is of course also made possible by the symmetry of the sample mesh). The output from griddata breaks the symmetry of the sample points, which is already weakly visible in the smooth case.  Smooth function and scattered data  Most often one wants to perform interpolation on scattered data. For this reason I expect these tests to be more important. As shown above, the sample points were chosen pseudo-uniformly in the domain of interest. In realistic scenarios you might have additional noise with each measurement, and you should consider whether it makes sense to interpolate your raw data to begin with.  Output for the smooth function:    Now there's already a bit of a horror show going on. I clipped the output from interp2d to between [-1, 1] exclusively for plotting, in order to preserve at least a minimal amount of information. It's clear that while some of the underlying shape is present, there are huge noisy regions where the method completely breaks down. The second case of griddata reproduces the shape fairly nicely, but note the white regions at the border of the contour plot. This is due to the fact that griddata only works inside the convex hull of the input data points (in other words, it doesn't perform any extrapolation). I kept the default NaN value for output points lying outside the convex hull.2 Considering these features, Rbf seems to perform best.  Evil function and scattered data  And the moment we've all been waiting for:    It's no huge surprise that interp2d gives up. In fact, during the call to interp2d you should expect some friendly RuntimeWarnings complaining about the impossibility of the spline to be constructed. As for the other two methods, Rbf seems to produce the best output, even near the borders of the domain where the result is extrapolated.    So let me say a few words about the three methods, in decreasing order of preference (so that the worst is the least likely to be read by anybody).  scipy.interpolate.Rbf  The Rbf class stands for \"radial basis functions\". To be honest I've never considered this approach until I started researching for this post, but I'm pretty sure I'll be using these in the future.  Just like the spline-based methods (see later), usage comes in two steps: first one creates a callable Rbf class instance based on the input data, and then calls this object for a given output mesh to obtain the interpolated result. Example from the smooth upsampling test:  import scipy.interpolate as interp zfun_smooth_rbf = interp.Rbf(x_sparse, y_sparse, z_sparse_smooth, function='cubic', smooth=0)  # default smooth=0 for interpolation z_dense_smooth_rbf = zfun_smooth_rbf(x_dense, y_dense)  # not really a function, but a callable class instance   Note that both input and output points were 2d arrays in this case, and the output z_dense_smooth_rbf has the same shape as x_dense and y_dense without any effort. Also note that Rbf supports arbitrary dimensions for interpolation.  So, scipy.interpolate.Rbf   produces well-behaved output even for crazy input data supports interpolation in higher dimensions extrapolates outside the convex hull of the input points (of course extrapolation is always a gamble, and you should generally not rely on it at all) creates an interpolator as a first step, so evaluating it in various output points is less additional effort can have output points of arbitrary shape (as opposed to being constrained to rectangular meshes, see later) prone to preserving the symmetry of the input data supports multiple kinds of radial functions for keyword function: multiquadric, inverse, gaussian, linear, cubic, quintic, thin_plate and user-defined arbitrary   scipy.interpolate.griddata  My former favourite, griddata, is a general workhorse for interpolation in arbitrary dimensions. It doesn't perform extrapolation beyond setting a single preset value for points outside the convex hull of the nodal points, but since extrapolation is a very fickle and dangerous thing, this is not necessarily a con. Usage example:  z_dense_smooth_griddata = interp.griddata(np.array([x_sparse.ravel(),y_sparse.ravel()]).T,                                           z_sparse_smooth.ravel(),                                           (x_dense,y_dense), method='cubic')   # default method is linear   Note the slightly kludgy syntax. The input points have to be specified in an array of shape [N, D] in D dimensions. For this we first have to flatten our 2d coordinate arrays (using ravel), then concatenate the arrays and transpose the result. There are multiple ways to do this, but all of them seem to be bulky. The input z data also have to be flattened. We have a bit more freedom when it comes to the output points: for some reason these can also be specified as a tuple of multidimensional arrays. Note that the help of griddata is misleading, as it suggests that the same is true for the input points (at least for version 0.17.0):  griddata(points, values, xi, method='linear', fill_value=nan, rescale=False)     Interpolate unstructured D-dimensional data.      Parameters     ----------     points : ndarray of floats, shape (n, D)         Data point coordinates. Can either be an array of         shape (n, D), or a tuple of `ndim` arrays.     values : ndarray of float or complex, shape (n,)         Data values.     xi : ndarray of float, shape (M, D)         Points at which to interpolate data.   In a nutshell, scipy.interpolate.griddata   produces well-behaved output even for crazy input data supports interpolation in higher dimensions does not perform extrapolation, a single value can be set for the output outside the convex hull of the input points (see fill_value) computes the interpolated values in a single call, so probing multiple sets of output points starts from scratch can have output points of arbitrary shape supports nearest-neighbour and linear interpolation in arbitrary dimensions, cubic in 1d and 2d. Nearest-neighbour and linear interpolation use NearestNDInterpolator and LinearNDInterpolator under the hood, respectively. 1d cubic interpolation uses a spline, 2d cubic interpolation uses CloughTocher2DInterpolator to construct a continuously differentiable piecewise-cubic interpolator. might violate the symmetry of the input data   scipy.interpolate.interp2d/scipy.interpolate.bisplrep  The only reason I'm discussing interp2d and its relatives is that it has a deceptive name, and people are likely to try using it. Spoiler alert: don't use it (as of scipy version 0.17.0). It's already more special than the previous subjects in that it's specifically used for two-dimensional interpolation, but I suspect this is by far the most common case for multivariate interpolation.  As far as syntax goes, interp2d is similar to Rbf in that it first needs constructing an interpolation instance, which can be called to provide the actual interpolated values. There's a catch, however: the output points have to be located on a rectangular mesh, so inputs going into the call to the interpolator have to be 1d vectors which span the output grid, as if from numpy.meshgrid:  # reminder: x_sparse and y_sparse are of shape [6, 7] from numpy.meshgrid zfun_smooth_interp2d = interp.interp2d(x_sparse, y_sparse, z_sparse_smooth, kind='cubic')   # default kind is 'linear' # reminder: x_dense and y_dense are of shape [20, 21] from numpy.meshgrid xvec = x_dense[0,:] # 1d array of unique x values, 20 elements yvec = y_dense[:,0] # 1d array of unique y values, 21 elements z_dense_smooth_interp2d = zfun_smooth_interp2d(xvec,yvec)   # output is [20, 21]-shaped array   One of the most common mistakes when using interp2d is putting your full 2d meshes into the interpolation call, which leads to explosive memory consumption, and hopefully to a hasty MemoryError.  Now, the greatest problem with interp2d is that it often doesn't work. In order to understand this, we have to look under the hood. It turns out that interp2d is a wrapper for the lower-level functions bisplrep+bisplev, which are in turn wrappers for FITPACK routines (written in Fortran). The equivalent call to the previous example would be  kind = 'cubic' if kind=='linear':     kx=ky=1 elif kind=='cubic':     kx=ky=3 elif kind=='quintic':     kx=ky=5 # bisplrep constructs a spline representation, bisplev evaluates the spline at given points bisp_smooth = interp.bisplrep(x_sparse.ravel(),y_sparse.ravel(),z_sparse_smooth.ravel(),kx=kx,ky=ky,s=0) z_dense_smooth_bisplrep = interp.bisplev(xvec,yvec,bisp_smooth).T  # note the transpose   Now, here's the thing about interp2d: (in scipy version 0.17.0) there is a nice comment in interpolate/interpolate.py for interp2d:  if not rectangular_grid:     # TODO: surfit is really not meant for interpolation!     self.tck = fitpack.bisplrep(x, y, z, kx=kx, ky=ky, s=0.0)   and indeed in interpolate/fitpack.py, in bisplrep there's some setup and ultimately  tx, ty, c, o = _fitpack._surfit(x, y, z, w, xb, xe, yb, ye, kx, ky,                                 task, s, eps, tx, ty, nxest, nyest,                                 wrk, lwrk1, lwrk2)                    And that's it. The routines underlying interp2d are not really meant to perform interpolation. They might suffice for sufficiently well-behaved data, but under realistic circumstances you will probably want to use something else.  Just to conclude, interpolate.interp2d   can lead to artifacts even with well-tempered data is specifically for bivariate problems (although there's the limited interpn for input points defined on a grid) performs extrapolation creates an interpolator as a first step, so evaluating it in various output points is less additional effort can only produce output over a rectangular grid, for scattered output you would have to call the interpolator in a loop supports linear, cubic and quintic interpolation might violate the symmetry of the input data     1I'm fairly certain that the cubic and linear kind of basis functions of Rbf do not exactly correspond to the other interpolators of the same name. 2These NaNs are also the reason for why the surface plot seems so odd: matplotlib historically has difficulties with plotting complex 3d objects with proper depth information. The NaN values in the data confuse the renderer, so parts of the surface that should be in the back are plotted to be in the front. This is an issue with visualization, and not interpolation.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "scipy",
            "interpolation"
        ],
        "URL": "https://stackoverflow.com/questions/37872171/how-can-i-perform-two-dimensional-interpolation-using-scipy",
        "A_Votes": "123",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "       This Q&A is intended as a canonical(-ish) concerning two-dimensional (and multi-dimensional) interpolation using scipy. There are often questions concerning the basic syntax of various multidimensional interpolation methods, I hope to set these straight too.   I have a set of scattered two-dimensional data points, and I would like to plot them as a nice surface, preferably using something like contourf or plot_surface in matplotlib.pyplot. How can I interpolate my two-dimensional or multidimensional data to a mesh using scipy?  I've found the scipy.interpolate sub-package, but I keep getting errors when using interp2d or bisplrep or griddata or rbf. What is the proper syntax of these methods?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Django - Difference between import django.conf.settings and import settings",
        "A_Content": "  import settings   Will import settings(.py) module of your Django project (if you are writing this code from the \"root\" package of your application, of course)  from django.conf import settings   Will import settings object from django.conf package (Django's provided files). This is important, because     [..] note that your code should not import from either global_settings or your own settings file. django.conf.settings abstracts the concepts of default settings and site-specific settings; it presents a single interface. It also decouples the code that uses settings from the location of your settings.   UPDATE: if you want to define some own settings, see this part of the documentation     ",
        "Language": "Python",
        "Tags": [
            "python",
            "django"
        ],
        "URL": "https://stackoverflow.com/questions/8780756/django-difference-between-import-django-conf-settings-and-import-settings",
        "A_Votes": "124",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    What is the basic difference between the following import statements in a Django app?  import settings   and  from django.conf import settings      ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "`if __name__ == '__main__'` equivalent in Ruby",
        "A_Content": "  From the Ruby I've seen out in the wild (granted, not a ton), this is not a standard Ruby design pattern. Modules and scripts are supposed to stay separate, so I wouldn't be surprised if there isn't really a good, clean way of doing this.  EDIT: Found it.  if __FILE__ == $0     foo()     bar() end   But it's definitely not common.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "main"
        ],
        "URL": "https://stackoverflow.com/questions/2249310/if-name-main-equivalent-in-ruby",
        "A_Votes": "116",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am new to Ruby.  I'm looking to import functions from a module that contains a tool I want to continue using separately.  In Python I would simply do this:  def a():     ... def b():     ... if __name__ == '__main__':     a()     b()   This allows me to run the program or import it as a module to use a() and/or b() separately.  What's the equivalent paradigm in Ruby?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "`if __name__ == '__main__'` equivalent in Ruby",
        "A_Content": "  If stack trace is empty, we can start executing to the right and left. I don't know if that's used conventionally or unconventionally since I'm into Ruby for about a week.   if caller.length == 0   # do stuff end   Proof of concept:  file: test.rb  #!/usr/bin/ruby                                                                   if caller.length == 0   puts \"Main script\" end  puts \"Test\"   file: shmest.rb  #!/usr/bin/ruby -I .                                                              require 'test.rb'  puts \"Shmest\"   Usage:  $ ./shmest.rb  Test Shmest  $ ./test.rb Main script Test      ",
        "Language": "Python",
        "Tags": [
            "python",
            "ruby",
            "main"
        ],
        "URL": "https://stackoverflow.com/questions/2249310/if-name-main-equivalent-in-ruby",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am new to Ruby.  I'm looking to import functions from a module that contains a tool I want to continue using separately.  In Python I would simply do this:  def a():     ... def b():     ... if __name__ == '__main__':     a()     b()   This allows me to run the program or import it as a module to use a() and/or b() separately.  What's the equivalent paradigm in Ruby?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Google Authenticator implementation in Python",
        "A_Content": "  I wanted to set a bounty on my question, but I have succeeded in creating solution. My problem seemed to be connected with incorrect value of secret key (it must be correct parameter for base64.b32decode() function).  Below I post full working solution with explanation on how to use it.  Code  The following code is enough. I have also uploaded it to GitHub as separate module called onetimepass (available here: https://github.com/tadeck/onetimepass).  import hmac, base64, struct, hashlib, time  def get_hotp_token(secret, intervals_no):     key = base64.b32decode(secret, True)     msg = struct.pack(\">Q\", intervals_no)     h = hmac.new(key, msg, hashlib.sha1).digest()     o = ord(h[19]) & 15     h = (struct.unpack(\">I\", h[o:o+4])[0] & 0x7fffffff) % 1000000     return h  def get_totp_token(secret):     return get_hotp_token(secret, intervals_no=int(time.time())//30)   It has two functions:   get_hotp_token() generates one-time token (that should invalidate after single use), get_totp_token() generates token based on time (changed in 30-second intervals),   Parameters  When it comes to parameters:   secret is a secret value known to server (the above script) and client (Google Authenticator, by providing it as password within application), intervals_no is the number incremeneted after each generation of the token (this should be probably resolved on the server by checking some finite number of integers after last successful one checked in the past)   How to use it   Generate secret (it must be correct parameter for base64.b32decode()) - preferably 16-char (no = signs), as it surely worked for both script and Google Authenticator. Use get_hotp_token() if you want one-time passwords invalidated after each use. In Google Authenticator this type of passwords i  mentioned as based on the counter. For checking it on the server you will need to check several values of intervals_no (as you have no quarantee that user did not generate the pass between the requests for some reason), but not less than the last working intervals_no value (thus you should probably store it somewhere). Use get_totp_token(), if you want a token working in 30-second intervals. You have to make sure both systems have correct time set (meaning that they both generate the same Unix timestamp in any given moment in time). Make sure to protect yourself from brute-force attack. If time-based password is used, then trying 1000000 values in less than 30 seconds gives 100% chance of guessing the password. In case of HMAC-based passowrds (HOTPs) it seems to be even worse.   Example  When using the following code for one-time HMAC-based password:  secret = 'MZXW633PN5XW6MZX' for i in xrange(1, 10):     print i, get_hotp_token(secret, intervals_no=i)   you will get the following result:  1 448400 2 656122 3 457125 4 35022 5 401553 6 581333 7 16329 8 529359 9 171710   which is corresponding to the tokens generated by the Google Authenticator app (except if shorter than 6 signs, app adds zeros to the beginning to reach a length of 6 chars).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "security",
            "authentication",
            "one-time-password",
            "google-authenticator"
        ],
        "URL": "https://stackoverflow.com/questions/8529265/google-authenticator-implementation-in-python",
        "A_Votes": "125",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I am trying to use one-time passwords that can be generated using Google Authenticator application.  What Google Authenticator does  Basically, Google Authenticator implements two types of passwords:   HOTP - HMAC-based One-Time Password, which means the password is changed with each call, in compliance to RFC4226, and TOTP - Time-based One-Time Password, which changes for every 30-seconds period (as far as I know).   Google Authenticator is also available as Open Source here: code.google.com/p/google-authenticator  Current code  I was looking for existing solutions to generate HOTP and TOTP passwords, but did not find much. The code I have is the following snippet responsible for generating HOTP:  import hmac, base64, struct, hashlib, time  def get_token(secret, digest_mode=hashlib.sha1, intervals_no=None):     if intervals_no == None:         intervals_no = int(time.time()) // 30     key = base64.b32decode(secret)     msg = struct.pack(\">Q\", intervals_no)     h = hmac.new(key, msg, digest_mode).digest()     o = ord(h[19]) & 15     h = (struct.unpack(\">I\", h[o:o+4])[0] & 0x7fffffff) % 1000000     return h   The problem I am facing is that the password I generate using the above code is not the same as generated using Google Authenticator app for Android. Even though I tried multiple intervals_no values (exactly first 10000, beginning with intervals_no = 0), with secret being equal to key provided within the GA app.  Questions I have  My questions are:   What am I doing wrong? How can I generate HOTP and/or TOTP in Python? Are there any existing Python libraries for this?   To sum up: please give me any clues that will help me implement Google Authenticator authentication within my Python code.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Google Authenticator implementation in Python",
        "A_Content": "  I wanted a python script to generate TOTP password. So, I wrote the python script. This is my implementation. I have this info on wikipedia and some knowledge about HOTP and TOTP to write this script.  import hmac, base64, struct, hashlib, time, array  def Truncate(hmac_sha1):     \"\"\"     Truncate represents the function that converts an HMAC-SHA-1     value into an HOTP value as defined in Section 5.3.      http://tools.ietf.org/html/rfc4226#section-5.3      \"\"\"     offset = int(hmac_sha1[-1], 16)     binary = int(hmac_sha1[(offset * 2):((offset * 2) + 8)], 16) & 0x7fffffff     return str(binary)  def _long_to_byte_array(long_num):     \"\"\"     helper function to convert a long number into a byte array     \"\"\"     byte_array = array.array('B')     for i in reversed(range(0, 8)):         byte_array.insert(0, long_num & 0xff)         long_num >>= 8     return byte_array  def HOTP(K, C, digits=6):     \"\"\"     HOTP accepts key K and counter C     optional digits parameter can control the response length      returns the OATH integer code with {digits} length     \"\"\"     C_bytes = _long_to_byte_array(C)     hmac_sha1 = hmac.new(key=K, msg=C_bytes, digestmod=hashlib.sha1).hexdigest()     return Truncate(hmac_sha1)[-digits:]  def TOTP(K, digits=6, window=30):     \"\"\"     TOTP is a time-based variant of HOTP.     It accepts only key K, since the counter is derived from the current time     optional digits parameter can control the response length     optional window parameter controls the time window in seconds      returns the OATH integer code with {digits} length     \"\"\"     C = long(time.time() / window)     return HOTP(K, C, digits=digits)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "security",
            "authentication",
            "one-time-password",
            "google-authenticator"
        ],
        "URL": "https://stackoverflow.com/questions/8529265/google-authenticator-implementation-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I am trying to use one-time passwords that can be generated using Google Authenticator application.  What Google Authenticator does  Basically, Google Authenticator implements two types of passwords:   HOTP - HMAC-based One-Time Password, which means the password is changed with each call, in compliance to RFC4226, and TOTP - Time-based One-Time Password, which changes for every 30-seconds period (as far as I know).   Google Authenticator is also available as Open Source here: code.google.com/p/google-authenticator  Current code  I was looking for existing solutions to generate HOTP and TOTP passwords, but did not find much. The code I have is the following snippet responsible for generating HOTP:  import hmac, base64, struct, hashlib, time  def get_token(secret, digest_mode=hashlib.sha1, intervals_no=None):     if intervals_no == None:         intervals_no = int(time.time()) // 30     key = base64.b32decode(secret)     msg = struct.pack(\">Q\", intervals_no)     h = hmac.new(key, msg, digest_mode).digest()     o = ord(h[19]) & 15     h = (struct.unpack(\">I\", h[o:o+4])[0] & 0x7fffffff) % 1000000     return h   The problem I am facing is that the password I generate using the above code is not the same as generated using Google Authenticator app for Android. Even though I tried multiple intervals_no values (exactly first 10000, beginning with intervals_no = 0), with secret being equal to key provided within the GA app.  Questions I have  My questions are:   What am I doing wrong? How can I generate HOTP and/or TOTP in Python? Are there any existing Python libraries for this?   To sum up: please give me any clues that will help me implement Google Authenticator authentication within my Python code.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  Martijn's answer explains what None is in Python, and correctly states that the book is misleading.  Since Python programmers as a rule would never say     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   it's hard to explain what Briggs means in a way which makes sense and explains why no one here seems happy with it.  One analogy which may help:  In Python, variable names are like stickers put on objects.  Every sticker has a unique name written on it, and it can only be on one object at a time, but you could put more than one sticker on the same object, if you wanted to.  When you write  F = \"fork\"   you put the sticker \"F\" on a string object \"fork\".  If you then write  F = None   you move the sticker to the None object.  What Briggs is asking you to imagine is that you didn't write the sticker \"F\", there was already an F sticker on the None, and all you did was move it, from None to \"fork\".  So when you type F = None, you're \"reset[ting] it to its original, empty state\", if we decided to treat None as meaning empty state.  I can see what he's getting at, but that's a bad way to look at it.  If you start Python and type print(F), you see  >>> print(F) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'F' is not defined   and that NameError means Python doesn't recognize the name F, because there is no such sticker.  If Briggs were right and F = None resets F to its original state, then it should be there now, and we should see  >>> print(F) None   like we do after we type F = None and put the sticker on None.    So that's all that's going on.  In reality, Python comes with some stickers already attached to objects (built-in names), but others you have to write yourself with lines like F = \"fork\" and A = 2 and c17 = 3.14, and then you can stick them on other objects later (like F = 10 or F = None; it's all the same.)  Briggs is pretending that all possible stickers you might want to write were already stuck to the None object.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "64",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  None is just a value that commonly is used to signify 'empty', or 'no value here'. It is a signal object; it only has meaning because the Python documentation says it has that meaning.  There is only one copy of that object in a given Python interpreter session.  If you write a function, and that function doesn't use an explicit return statement, None is returned instead, for example. That way, programming with functions is much simplified; a function always returns something, even if it is only that one None object.  You can test for it explicitly:  if foo is None:     # foo is set to None  if bar is not None:     # bar is set to something *other* than None   Another use is to give optional parameters to functions an 'empty' default:  def spam(foo=None):     if foo is not None:         # foo was specified, do something clever!   The function spam() has a optional argument; if you call spam() without specifying it, the default value None is given to it, making it easy to detect if the function was called with an argument or not.  Other languages have similar concepts. SQL has NULL; JavaScript has undefined and null, etc.  Note that in Python, variables exist by virtue of being used. You don't need to declare a variable first, so there are no really empty variables in Python. Setting a variable to None is then not the same thing as setting it to a default empty value; None is a value too, albeit one that is often used to signal emptyness. The book you are reading is misleading on that point.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "45",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  This is what the Python documentation has got to say about None:     The sole value of types.NoneType. None is frequently used to represent   the absence of a value, as when default arguments are not passed to a   function.      Changed in version 2.4: Assignments to None are illegal and raise a   SyntaxError.      Note The names None and debug cannot be reassigned (assignments to   them, even as an attribute name, raise SyntaxError), so they can be   considered “true” constants.    Let's confirm the type of None first  print type(None) print None.__class__   Output  <type 'NoneType'> <type 'NoneType'>    Basically, NoneType is a data type just like int, float, etc. You can check out the list of default types available in Python in 8.15. types — Names for built-in types.   And, None is an instance of NoneType class. So we might want to create instances of None ourselves. Let's try that  print types.IntType() print types.NoneType()   Output  0 TypeError: cannot create 'NoneType' instances    So clearly, cannot create NoneType instances. We don't have to worry about the uniqueness of the value None.   Let's check how we have implemented None internally.  print dir(None)   Output  ['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__',   '__hash__', '__init__', '__new__', '__reduce__', '__reduce_ex__',  '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']    Except __setattr__, all others are read-only attributes. So, there is no way we can alter the attributes of None.   Let's try and add new attributes to None  setattr(types.NoneType, 'somefield', 'somevalue') setattr(None, 'somefield', 'somevalue') None.somefield = 'somevalue'   Output  TypeError: can't set attributes of built-in/extension type 'NoneType' AttributeError: 'NoneType' object has no attribute 'somefield' AttributeError: 'NoneType' object has no attribute 'somefield'    The above seen statements produce these error messages, respectively. It means that, we cannot create attributes dynamically on a None instance.   Let us check what happens when we assign something None. As per the documentation, it should throw a SyntaxError. It means, if we assign something to None, the program will not be executed at all.  None = 1   Output  SyntaxError: cannot assign to None    We have established that   None is an instance of NoneType None cannot have new attributes Existing attributes of None cannot be changed. We cannot create other instances of NoneType We cannot even change the reference to None by assigning values to it.   So, as mentioned in the documentation, None can really be considered as a true constant.  Happy knowing None :)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  The book you refer to is clearly trying to greatly simplify the meaning of None. Python variables don't have an initial, empty state – Python variables are bound (only) when they're defined. You can't create a Python variable without giving it a value.  >>> print(x) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'x' is not defined >>> def test(x): ...   print(x) ...  >>> test() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: test() takes exactly 1 argument (0 given) >>> def test(): ...   print(x) ...  >>> test() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 2, in test NameError: global name 'x' is not defined   but sometimes you want to make a function mean different things depending on whether a variable is defined or not. You can create an argument with a default value of None:  >>> def test(x=None): ...   if x is None: ...     print('no x here') ...   else: ...     print(x) ...  >>> test() no x here >>> test('x!') x!   The fact that this value is the special None value is not terribly important in this case. I could've used any default value:  >>> def test(x=-1): ...   if x == -1: ...     print('no x here') ...   else: ...     print(x) ...  >>> test() no x here >>> test('x!') x!   …but having None around gives us two benefits:   We don't have to pick a special value like -1 whose meaning is unclear, and Our function may actually need to handle -1 as a normal input.   >>> test(-1) no x here   oops!  So the book is a little misleading mostly in its use of the word reset – assigning None to a name is a signal to a programmer that that value isn't being used or that the function should behave in some default way, but to reset a value to its original, undefined state you must use the del keyword:  >>> x = 3 >>> x 3 >>> del x >>> x Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'x' is not defined      ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  None is a singleton object (meaning there is only one None), used in many places in the language and library to represent the absence of some other value.   For example: if d is a dictionary, d.get(k) will return d[k] if it exists, but None if d has no key k.  Read this info from a great blog: http://python-history.blogspot.in/     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  I love code examples (as well as fruit), so let me show you  apple = \"apple\" print(apple) >>> apple apple = None print(apple) >>> None   None means nothing, it has no value.  None evaluates to False.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "What is a None value?",
        "A_Content": "  Other answers have already explained meaning of None beautifully. However, I would still like to throw more light on this using an example.  Example:  def extendList(val, list=[]):     list.append(val)     return list  list1 = extendList(10) list2 = extendList(123,[]) list3 = extendList('a')  print \"list1 = %s\" % list1 print \"list2 = %s\" % list2 print \"list3 = %s\" % list3   Now try to guess output of above list. Well, the answer is surprisingly as below:  list1 = [10, 'a'] list2 = [123] list3 = [10, 'a']     But Why?  Many will mistakenly expect list1 to be equal to [10] and list3 to be equal to ['a'], thinking that the list argument will be set to its default value of [] each time extendList is called.  However, what actually happens is that the new default list is created only once when the function is defined, and that same list is then used subsequently whenever extendList is invoked without a list argument being specified. This is because expressions in default arguments are calculated when the function is defined, not when it’s called.  list1 and list3 are therefore operating on the same default list, whereas list2 is operating on a separate list that it created (by passing its own empty list as the value for the list parameter).    'None' the savior: (Modify example above to produce desired behavior)  def extendList(val, list=None):     if list is None:        list = []     list.append(val)     return list  list1 = extendList(10) list2 = extendList(123,[]) list3 = extendList('a')  print \"list1 = %s\" % list1 print \"list2 = %s\" % list2 print \"list3 = %s\" % list3   With this revised implementation, the output would be:  list1 = [10] list2 = [123] list3 = ['a']   Note - Example credit to toptal.com     ",
        "Language": "Python",
        "Tags": [
            "python",
            "variables",
            "if-statement"
        ],
        "URL": "https://stackoverflow.com/questions/19473185/what-is-a-none-value",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have been studying Python, and I read a chapter which describes the None value, but unfortunately this book isn't very clear at some points. I thought that I would find the answer to my question, if I share it there.  I want to know what the None value is and what do you use it for?  And also, I don't get this part of the book:     Assigning a value of None to a variable is one way to reset it to   its original, empty state.   What does that mean?  The answers were great, although I didn't understand most of answers due to my low knowledge of the computer world (I haven't learned about classes, objects, etc.). What does this sentence mean?     Assigning a value of None to a variable is one way to reset it   to its original, empty state.   Final:  Finally I've got my answer from looking to different answers. I must appreciate all the people who put their times to help me (especially Martijn Pieters and DSM), and I wish that I could choose all answers as the best, but the selection is limited to one. All of the answers were great.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  Use re.escape  re.escape(string) >>> re.escape('\\ a.*$') '\\\\\\\\\\\\ a\\\\.\\\\*\\\\$' >>> print(re.escape('\\ a.*$')) \\\\\\ a\\.\\*\\$ >>> re.escape('www.stackoverflow.com') 'www\\\\.stackoverflow\\\\.com' >>> print(re.escape('www.stackoverflow.com')) www\\.stackoverflow\\.com   See : http://docs.python.org/library/re.html#module-contents  Repeating it here:     re.escape(string)      Return string with all non-alphanumerics backslashed; this is useful if you want to match an arbitrary literal string that may have regular expression metacharacters in it.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "140",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  I'm surprised no one has mentioned using regular expressions via re.sub():  import re print re.sub(r'([\\\"])',    r'\\\\\\1', 'it\\'s \"this\"')  # it's \\\"this\\\" print re.sub(r\"([\\'])\",    r'\\\\\\1', 'it\\'s \"this\"')  # it\\'s \"this\" print re.sub(r'([\\\" \\'])', r'\\\\\\1', 'it\\'s \"this\"')  # it\\'s\\ \\\"this\\\"   Important things to note:   In the search pattern, include \\ as well as the character(s) you're looking for. You're going to be using \\ to escape your characters, so you need to escape that as well. Put parentheses around the search pattern, e.g. ([\\\"]), so that the substitution pattern can use the found character when it adds \\ in front of it. (That's what \\1 does: uses the value of the first parenthesized group.) The r in front of r'([\\\"])' means it's a raw string. Raw strings use different rules for escaping backslashes. To write ([\\\"]) as a plain string, you'd need to double all the backslashes and write '([\\\\\"])'. Raw strings are friendlier when you're writing regular expressions. In the substitution pattern, you need to escape \\ to distinguish it from a backslash that precedes a substitution group, e.g. \\1, hence r'\\\\\\1'. To write that as a plain string, you'd need '\\\\\\\\\\\\1' — and nobody wants that.      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "15",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  Use repr()[1:-1]. In this case, the double quotes don't need to be escaped. The [-1:1] slice is to remove the single quote from the beginning and the end.  >>> x = raw_input() I'm \"stuck\" :\\ >>> print x I'm \"stuck\" :\\ >>> print repr(x)[1:-1] I\\'m \"stuck\" :\\\\   Or maybe you just want to escape a phrase to paste into your program? If so, do this:  >>> raw_input() I'm \"stuck\" :\\ 'I\\'m \"stuck\" :\\\\'      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "9",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  As it was mentioned above, the answer depends on your case. If you want to escape a string for a regular expression then you should use re.escape(). But if you want to escape a specific set of characters then use this lambda function:  >>> escape = lambda s, escapechar, specialchars: \"\".join(escapechar + c if c in specialchars or c == escapechar else c for c in s) >>> s = raw_input() I'm \"stuck\" :\\ >>> print s I'm \"stuck\" :\\ >>> print escape(s, \"\\\\\", ['\"']) I'm \\\"stuck\\\" :\\\\      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  It's not that hard:  def escapeSpecialCharacters ( text, characters ):     for character in characters:         text = text.replace( character, '\\\\' + character )     return text  >>> escapeSpecialCharacters( 'I\\'m \"stuck\" :\\\\', '\\'\"' ) 'I\\\\\\'m \\\\\"stuck\\\\\" :\\\\' >>> print( _ ) I\\'m \\\"stuck\\\" :\\      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Python escape regex special characters",
        "A_Content": "  If you only want to replace some characters you could use this:  import re  print re.sub(r'([\\.\\\\\\+\\*\\?\\[\\^\\]\\$\\(\\)\\{\\}\\!\\<\\>\\|\\:\\-])', r'\\\\\\1', \"example string.\")      ",
        "Language": "Python",
        "Tags": [
            "python",
            "regex",
            "escaping"
        ],
        "URL": "https://stackoverflow.com/questions/4202538/python-escape-regex-special-characters",
        "A_Votes": "2",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    Does Python have a function that I can use to escape special characters in a regular expression?  For example, I'm \"stuck\" :\\ should become I\\'m \\\"stuck\\\" :\\\\.     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Suppress Scientific Notation in Numpy When Creating Array From Nested List",
        "A_Content": "  I guess what you need is np.set_printoptions(suppress=True), for details see here: http://pythonquirks.blogspot.fr/2009/10/controlling-printing-in-numpy.html  For SciPy.org numpy documentation, which includes all function parameters (suppress isn't detailed in the above link), see here: https://docs.scipy.org/doc/numpy/reference/generated/numpy.set_printoptions.html     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list",
        "A_Votes": "155",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I have a nested Python list that looks like the following:  my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],  [9.55, 116, 189688622.37, 260332262.0, 1.97],  [2.2, 768, 6004865.13, 5759960.98, 1.21],  [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],  [1.91, 474, 44555062.72, 44555062.72, 0.41],  [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],  [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],  [7.03, 116, 66252511.46, 81109291.0, 1.56],  [6.52, 116, 47674230.76, 57686991.0, 1.43],  [1.85, 623, 3002631.96, 2899484.08, 0.64],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]]   I then import Numpy, and set print options to (suppress=True). When I create an array:  my_array = numpy.array(my_list)   I can't for the life of me suppress scientific notation:  [[  3.74000000e+00   5.16200000e+03   1.36836288e+10   1.27833876e+10     1.81000000e+00]  [  9.55000000e+00   1.16000000e+02   1.89688622e+08   2.60332262e+08     1.97000000e+00]  [  2.20000000e+00   7.68000000e+02   6.00486513e+06   5.75996098e+06     1.21000000e+00]  [  3.74000000e+00   4.06200000e+03   3.26382212e+09   3.06686909e+09     1.93000000e+00]  [  1.91000000e+00   4.74000000e+02   4.45550627e+07   4.45550627e+07     4.10000000e-01]  [  5.80000000e+00   5.00600000e+03   8.25496892e+09   7.44678827e+09     3.25000000e+00]  [  4.50000000e+00   7.88700000e+03   3.00789716e+10   2.78149895e+10     2.18000000e+00]  [  7.03000000e+00   1.16000000e+02   6.62525115e+07   8.11092910e+07     1.56000000e+00]  [  6.52000000e+00   1.16000000e+02   4.76742308e+07   5.76869910e+07     1.43000000e+00]  [  1.85000000e+00   6.23000000e+02   3.00263196e+06   2.89948408e+06     6.40000000e-01]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]]   If I create a simple numpy array directly:  new_array = numpy.array([1.5, 4.65, 7.845])   I have no problem and it prints as follows:  [ 1.5    4.65   7.845]   Does anyone know what my problem is?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Suppress Scientific Notation in Numpy When Creating Array From Nested List",
        "A_Content": "  for 1D and 2D arrays you can use np.savetxt to print using a specific format string:  >>> import sys >>> x = numpy.arange(20).reshape((4,5)) >>> numpy.savetxt(sys.stdout, x, '%5.2f')  0.00  1.00  2.00  3.00  4.00  5.00  6.00  7.00  8.00  9.00 10.00 11.00 12.00 13.00 14.00 15.00 16.00 17.00 18.00 19.00   Your options with numpy.set_printoptions or numpy.array2string in v1.3 are pretty clunky and limited (for example no way to suppress scientific notation for large numbers). It looks like this will change with future versions, with numpy.set_printoptions(formatter=..) and numpy.array2string(style=..).     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list",
        "A_Votes": "17",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a nested Python list that looks like the following:  my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],  [9.55, 116, 189688622.37, 260332262.0, 1.97],  [2.2, 768, 6004865.13, 5759960.98, 1.21],  [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],  [1.91, 474, 44555062.72, 44555062.72, 0.41],  [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],  [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],  [7.03, 116, 66252511.46, 81109291.0, 1.56],  [6.52, 116, 47674230.76, 57686991.0, 1.43],  [1.85, 623, 3002631.96, 2899484.08, 0.64],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]]   I then import Numpy, and set print options to (suppress=True). When I create an array:  my_array = numpy.array(my_list)   I can't for the life of me suppress scientific notation:  [[  3.74000000e+00   5.16200000e+03   1.36836288e+10   1.27833876e+10     1.81000000e+00]  [  9.55000000e+00   1.16000000e+02   1.89688622e+08   2.60332262e+08     1.97000000e+00]  [  2.20000000e+00   7.68000000e+02   6.00486513e+06   5.75996098e+06     1.21000000e+00]  [  3.74000000e+00   4.06200000e+03   3.26382212e+09   3.06686909e+09     1.93000000e+00]  [  1.91000000e+00   4.74000000e+02   4.45550627e+07   4.45550627e+07     4.10000000e-01]  [  5.80000000e+00   5.00600000e+03   8.25496892e+09   7.44678827e+09     3.25000000e+00]  [  4.50000000e+00   7.88700000e+03   3.00789716e+10   2.78149895e+10     2.18000000e+00]  [  7.03000000e+00   1.16000000e+02   6.62525115e+07   8.11092910e+07     1.56000000e+00]  [  6.52000000e+00   1.16000000e+02   4.76742308e+07   5.76869910e+07     1.43000000e+00]  [  1.85000000e+00   6.23000000e+02   3.00263196e+06   2.89948408e+06     6.40000000e-01]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]]   If I create a simple numpy array directly:  new_array = numpy.array([1.5, 4.65, 7.845])   I have no problem and it prints as follows:  [ 1.5    4.65   7.845]   Does anyone know what my problem is?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Suppress Scientific Notation in Numpy When Creating Array From Nested List",
        "A_Content": "  Python Force-suppress all exponential notation when printing numpy ndarrays, wrangle text justification, rounding and print options:  What follows is an explanation for what is going on, scroll to bottom for code demos.  Passing parameter suppress=True to function set_printoptions works only for numbers that fit in the default 8 character space allotted to it, like this:  import numpy as np np.set_printoptions(suppress=True) #prevent numpy exponential                                     #notation on print, default False  #            tiny     med  large a = np.array([1.01e-5, 22, 1.2345678e7])  #notice how index 2 is 8                                            #digits wide  print(a)    #prints [ 0.0000101   22.     12345678. ]   However if you pass in a number greater than 8 characters wide, exponential notation is imposed again, like this:  np.set_printoptions(suppress=True)  a = np.array([1.01e-5, 22, 1.2345678e10])    #notice how index 2 is 10                                              #digits wide, too wide!  #exponential notation where we've told it not to! print(a)    #prints [1.01000000e-005   2.20000000e+001   1.23456780e+10]   numpy has a choice between chopping your number in half thus misrepresenting it, or forcing exponential notation, it chooses the latter.  Here comes set_printoptions(formatter=...) to the rescue to specify options for printing and rounding.  Tell set_printoptions to just print bare a bare float:  np.set_printoptions(suppress=True,    formatter={'float_kind':'{:f}'.format})  a = np.array([1.01e-5, 22, 1.2345678e30])  #notice how index 2 is 30                                            #digits wide.    #Ok good, no exponential notation in the large numbers: print(a)  #prints [0.000010 22.000000 1234567799999999979944197226496.000000]    We've force-suppressed the exponential notation, but it is not rounded or justified, so specify extra formatting options:  np.set_printoptions(suppress=True,    formatter={'float_kind':'{:0.2f}'.format})  #float, 2 units                                                 #precision right, 0 on left  a = np.array([1.01e-5, 22, 1.2345678e30])   #notice how index 2 is 30                                             #digits wide  print(a)  #prints [0.00 22.00 1234567799999999979944197226496.00]   The drawback for force-suppressing all exponential notion in ndarrays is that if your ndarray gets a huge float value near infinity in it, and you print it, you're going to get blasted in the face with a page full of numbers.    Full example Demo 1:  from pprint import pprint import numpy as np #chaotic python list of lists with very different numeric magnitudes my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],            [9.55, 116, 189688622.37, 260332262.0, 1.97],            [2.2, 768, 6004865.13, 5759960.98, 1.21],            [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],            [1.91, 474, 44555062.72, 44555062.72, 0.41],            [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],            [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],            [7.03, 116, 66252511.46, 81109291.0, 1.56],            [6.52, 116, 47674230.76, 57686991.0, 1.43],            [1.85, 623, 3002631.96, 2899484.08, 0.64],            [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],            [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]]  #convert python list of lists to numpy ndarray called my_array my_array = np.array(my_list)  #This is a little recursive helper function converts all nested  #ndarrays to python list of lists so that pretty printer knows what to do. def arrayToList(arr):     if type(arr) == type(np.array):         #If the passed type is an ndarray then convert it to a list and         #recursively convert all nested types         return arrayToList(arr.tolist())     else:         #if item isn't an ndarray leave it as is.         return arr  #suppress exponential notation, define an appropriate float formatter #specify stdout line width and let pretty print do the work np.set_printoptions(suppress=True,    formatter={'float_kind':'{:16.3f}'.format}, linewidth=130) pprint(arrayToList(my_array))   Prints:   array([[           3.740,         5162.000,  13683628846.640,  12783387559.860,            1.810],        [           9.550,          116.000,    189688622.370,    260332262.000,            1.970],        [           2.200,          768.000,      6004865.130,      5759960.980,            1.210],        [           3.740,         4062.000,   3263822121.390,   3066869087.900,            1.930],        [           1.910,          474.000,     44555062.720,     44555062.720,            0.410],        [           5.800,         5006.000,   8254968918.100,   7446788272.740,            3.250],        [           4.500,         7887.000,  30078971595.460,  27814989471.310,            2.180],        [           7.030,          116.000,     66252511.460,     81109291.000,            1.560],        [           6.520,          116.000,     47674230.760,     57686991.000,            1.430],        [           1.850,          623.000,      3002631.960,      2899484.080,            0.640],        [          13.760,         1227.000,   1737874137.500,   1446511574.320,            4.320],        [          13.760,         1227.000,   1737874137.500,   1446511574.320,            4.320]])   Full example Demo 2:  import numpy as np #chaotic python list of lists with very different numeric magnitudes my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],            [9.55, 116, 189688622.37, 260332262.0, 1.97],            [2.2, 768, 6004865.13, 5759960.98, 1.21],            [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],            [1.91, 474, 44555062.72, 44555062.72, 0.41],            [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],            [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],            [7.03, 116, 66252511.46, 81109291.0, 1.56],            [6.52, 116, 47674230.76, 57686991.0, 1.43],            [1.85, 623, 3002631.96, 2899484.08, 0.64],            [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],            [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]] import sys  #convert python list of lists to numpy ndarray called my_array my_array = np.array(my_list) #following two lines do the same thing, showing that np.savetxt can #correctly handle python lists of lists and numpy 2D ndarrays. np.savetxt(sys.stdout, my_list, '%16.2f') np.savetxt(sys.stdout, my_array, '%16.2f')      Prints:       3.74          5162.00   13683628846.64   12783387559.86             1.81     9.55           116.00     189688622.37     260332262.00             1.97     2.20           768.00       6004865.13       5759960.98             1.21     3.74          4062.00    3263822121.39    3066869087.90             1.93     1.91           474.00      44555062.72      44555062.72             0.41     5.80          5006.00    8254968918.10    7446788272.74             3.25     4.50          7887.00   30078971595.46   27814989471.31             2.18     7.03           116.00      66252511.46      81109291.00             1.56     6.52           116.00      47674230.76      57686991.00             1.43     1.85           623.00       3002631.96       2899484.08             0.64    13.76          1227.00    1737874137.50    1446511574.32             4.32    13.76          1227.00    1737874137.50    1446511574.32             4.32      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list",
        "A_Votes": "11",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a nested Python list that looks like the following:  my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],  [9.55, 116, 189688622.37, 260332262.0, 1.97],  [2.2, 768, 6004865.13, 5759960.98, 1.21],  [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],  [1.91, 474, 44555062.72, 44555062.72, 0.41],  [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],  [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],  [7.03, 116, 66252511.46, 81109291.0, 1.56],  [6.52, 116, 47674230.76, 57686991.0, 1.43],  [1.85, 623, 3002631.96, 2899484.08, 0.64],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]]   I then import Numpy, and set print options to (suppress=True). When I create an array:  my_array = numpy.array(my_list)   I can't for the life of me suppress scientific notation:  [[  3.74000000e+00   5.16200000e+03   1.36836288e+10   1.27833876e+10     1.81000000e+00]  [  9.55000000e+00   1.16000000e+02   1.89688622e+08   2.60332262e+08     1.97000000e+00]  [  2.20000000e+00   7.68000000e+02   6.00486513e+06   5.75996098e+06     1.21000000e+00]  [  3.74000000e+00   4.06200000e+03   3.26382212e+09   3.06686909e+09     1.93000000e+00]  [  1.91000000e+00   4.74000000e+02   4.45550627e+07   4.45550627e+07     4.10000000e-01]  [  5.80000000e+00   5.00600000e+03   8.25496892e+09   7.44678827e+09     3.25000000e+00]  [  4.50000000e+00   7.88700000e+03   3.00789716e+10   2.78149895e+10     2.18000000e+00]  [  7.03000000e+00   1.16000000e+02   6.62525115e+07   8.11092910e+07     1.56000000e+00]  [  6.52000000e+00   1.16000000e+02   4.76742308e+07   5.76869910e+07     1.43000000e+00]  [  1.85000000e+00   6.23000000e+02   3.00263196e+06   2.89948408e+06     6.40000000e-01]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]]   If I create a simple numpy array directly:  new_array = numpy.array([1.5, 4.65, 7.845])   I have no problem and it prints as follows:  [ 1.5    4.65   7.845]   Does anyone know what my problem is?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Suppress Scientific Notation in Numpy When Creating Array From Nested List",
        "A_Content": "  You could write a function that converts a scientific notation to regular, something like  def sc2std(x):     s = str(x)     if 'e' in s:         num,ex = s.split('e')         if '-' in num:             negprefix = '-'         else:             negprefix = ''         num = num.replace('-','')         if '.' in num:             dotlocation = num.index('.')         else:             dotlocation = len(num)         newdotlocation = dotlocation + int(ex)         num = num.replace('.','')         if (newdotlocation < 1):             return negprefix+'0.'+'0'*(-newdotlocation)+num         if (newdotlocation > len(num)):             return negprefix+ num + '0'*(newdotlocation - len(num))+'.0'         return negprefix + num[:newdotlocation] + '.' + num[newdotlocation:]     else:         return s      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list",
        "A_Votes": "0",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I have a nested Python list that looks like the following:  my_list = [[3.74, 5162, 13683628846.64, 12783387559.86, 1.81],  [9.55, 116, 189688622.37, 260332262.0, 1.97],  [2.2, 768, 6004865.13, 5759960.98, 1.21],  [3.74, 4062, 3263822121.39, 3066869087.9, 1.93],  [1.91, 474, 44555062.72, 44555062.72, 0.41],  [5.8, 5006, 8254968918.1, 7446788272.74, 3.25],  [4.5, 7887, 30078971595.46, 27814989471.31, 2.18],  [7.03, 116, 66252511.46, 81109291.0, 1.56],  [6.52, 116, 47674230.76, 57686991.0, 1.43],  [1.85, 623, 3002631.96, 2899484.08, 0.64],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32],  [13.76, 1227, 1737874137.5, 1446511574.32, 4.32]]   I then import Numpy, and set print options to (suppress=True). When I create an array:  my_array = numpy.array(my_list)   I can't for the life of me suppress scientific notation:  [[  3.74000000e+00   5.16200000e+03   1.36836288e+10   1.27833876e+10     1.81000000e+00]  [  9.55000000e+00   1.16000000e+02   1.89688622e+08   2.60332262e+08     1.97000000e+00]  [  2.20000000e+00   7.68000000e+02   6.00486513e+06   5.75996098e+06     1.21000000e+00]  [  3.74000000e+00   4.06200000e+03   3.26382212e+09   3.06686909e+09     1.93000000e+00]  [  1.91000000e+00   4.74000000e+02   4.45550627e+07   4.45550627e+07     4.10000000e-01]  [  5.80000000e+00   5.00600000e+03   8.25496892e+09   7.44678827e+09     3.25000000e+00]  [  4.50000000e+00   7.88700000e+03   3.00789716e+10   2.78149895e+10     2.18000000e+00]  [  7.03000000e+00   1.16000000e+02   6.62525115e+07   8.11092910e+07     1.56000000e+00]  [  6.52000000e+00   1.16000000e+02   4.76742308e+07   5.76869910e+07     1.43000000e+00]  [  1.85000000e+00   6.23000000e+02   3.00263196e+06   2.89948408e+06     6.40000000e-01]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]  [  1.37600000e+01   1.22700000e+03   1.73787414e+09   1.44651157e+09     4.32000000e+00]]   If I create a simple numpy array directly:  new_array = numpy.array([1.5, 4.65, 7.845])   I have no problem and it prints as follows:  [ 1.5    4.65   7.845]   Does anyone know what my problem is?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Conditional import of modules in Python",
        "A_Content": "  I've seen this idiom used a lot, so you don't even have to do OS sniffing:  try:     import json except ImportError:     import simplejson as json      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3496592/conditional-import-of-modules-in-python",
        "A_Votes": "140",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In my program I want to import simplejson or json based on whether the OS the user is on is Windows or Linux. I take the OS name as input from the user. Now, is it correct to do the following?  osys = raw_input(\"Press w for windows,l for linux\") if (osys == \"w\"):     import json as simplejson else:     import simplejson        ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Conditional import of modules in Python",
        "A_Content": "  Perfectly correct, tons of packages do this.  It's probably better to figure out the OS yourself instead of relying on the user; here's pySerial doing it as an example.  serial/__init__.py  import sys  if sys.platform == 'cli':     from serialcli import * else:     import os     # chose an implementation, depending on os     if os.name == 'nt': #sys.platform == 'win32':         from serialwin32 import *     elif os.name == 'posix':         from serialposix import *     elif os.name == 'java':         from serialjava import *     else:         raise Exception(\"Sorry: no implementation for your platform ('%s') available\" % os.name)      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3496592/conditional-import-of-modules-in-python",
        "A_Votes": "37",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In my program I want to import simplejson or json based on whether the OS the user is on is Windows or Linux. I take the OS name as input from the user. Now, is it correct to do the following?  osys = raw_input(\"Press w for windows,l for linux\") if (osys == \"w\"):     import json as simplejson else:     import simplejson        ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Conditional import of modules in Python",
        "A_Content": "  It is not advisable to use to bind json or simplejson with OS platform. simplejson is newer and advanced version of json so we should try to import it first.  Based on python version you can try below way to import json or simplejson  import sys if sys.version_info > (2, 7):     import simplejson as json else:     import json      ",
        "Language": "Python",
        "Tags": [
            "python"
        ],
        "URL": "https://stackoverflow.com/questions/3496592/conditional-import-of-modules-in-python",
        "A_Votes": "6",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    In my program I want to import simplejson or json based on whether the OS the user is on is Windows or Linux. I take the OS name as input from the user. Now, is it correct to do the following?  osys = raw_input(\"Press w for windows,l for linux\") if (osys == \"w\"):     import json as simplejson else:     import simplejson        ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to create a temporary directory and get the path / file name in Python",
        "A_Content": "  Use the mkdtemp() function from the tempfile module:  import tempfile import shutil  dirpath = tempfile.mkdtemp() # ... do stuff with dirpath shutil.rmtree(dirpath)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "temporary-files",
            "temporary-directory"
        ],
        "URL": "https://stackoverflow.com/questions/3223604/how-to-create-a-temporary-directory-and-get-the-path-file-name-in-python",
        "A_Votes": "150",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    how to create a temporary directory and get the path / file name in python     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to create a temporary directory and get the path / file name in Python",
        "A_Content": "  To expand on another answer, here is a fairly complete example which can cleanup the tmpdir even on exceptions:  import contextlib import os import shutil import tempfile  @contextlib.contextmanager def cd(newdir, cleanup=lambda: True):     prevdir = os.getcwd()     os.chdir(os.path.expanduser(newdir))     try:         yield     finally:         os.chdir(prevdir)         cleanup()  @contextlib.contextmanager def tempdir():     dirpath = tempfile.mkdtemp()     def cleanup():         shutil.rmtree(dirpath)     with cd(dirpath, cleanup):         yield dirpath  def main():     with tempdir() as dirpath:         pass # do something here      ",
        "Language": "Python",
        "Tags": [
            "python",
            "temporary-files",
            "temporary-directory"
        ],
        "URL": "https://stackoverflow.com/questions/3223604/how-to-create-a-temporary-directory-and-get-the-path-file-name-in-python",
        "A_Votes": "26",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    how to create a temporary directory and get the path / file name in python     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to create a temporary directory and get the path / file name in Python",
        "A_Content": "  In python 3.2 and later, there is a useful contextmanager for this in the stdlib https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryDirectory     ",
        "Language": "Python",
        "Tags": [
            "python",
            "temporary-files",
            "temporary-directory"
        ],
        "URL": "https://stackoverflow.com/questions/3223604/how-to-create-a-temporary-directory-and-get-the-path-file-name-in-python",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    how to create a temporary directory and get the path / file name in python     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "How to create a temporary directory and get the path / file name in Python",
        "A_Content": "  Use module tempfile.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "temporary-files",
            "temporary-directory"
        ],
        "URL": "https://stackoverflow.com/questions/3223604/how-to-create-a-temporary-directory-and-get-the-path-file-name-in-python",
        "A_Votes": "4",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    how to create a temporary directory and get the path / file name in python     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  numpy.where() is my favorite.  >>> x = numpy.array([1,0,2,0,3,0,4,5,6,7,8]) >>> numpy.where(x == 0)[0] array([1, 3, 5])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "146",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  You can search for any scalar condition with:  >>> a = np.asarray([0,1,2,3,4]) >>> a == 0 # or whatver array([ True, False, False, False, False], dtype=bool)   Which will give back the array as an boolean mask of the condition.     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "18",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  There is np.argwhere,  import numpy as np arr = np.array([[1,2,3], [0, 1, 0], [7, 0, 2]]) np.argwhere(arr == 0)   which returns all found indices as rows:  array([[1, 0],    # Indices of the first zero        [1, 2],    # Indices of the second zero        [2, 1]],   # Indices of the third zero       dtype=int64)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "14",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  You can also use nonzero() by using it on a boolean mask of the condition, because False is also a kind of zero.  >>> x = numpy.array([1,0,2,0,3,0,4,5,6,7,8])  >>> x==0 array([False, True, False, True, False, True, False, False, False, False, False], dtype=bool)  >>> numpy.nonzero(x==0)[0] array([1, 3, 5])   It's doing exactly the same as mtrw's way, but it is more related to the question ;)     ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "8",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  If you are working with a one-dimensional array there is a syntactic sugar:  >>> x = numpy.array([1,0,2,0,3,0,4,5,6,7,8]) >>> numpy.flatnonzero(x == 0) array([1, 3, 5])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "3",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  import numpy as np  x = np.array([1,0,2,3,6]) non_zero_arr = np.extract(x>0,x)  min_index = np.amin(non_zero_arr) min_value = np.argmin(non_zero_arr)      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Find indices of elements equal to zero in a NumPy array",
        "A_Content": "  I would do it the following way:  >>> x = np.array([[1,0,0], [0,2,0], [1,1,0]]) >>> x array([[1, 0, 0],        [0, 2, 0],        [1, 1, 0]]) >>> np.nonzero(x) (array([0, 1, 2, 2]), array([0, 1, 0, 1]))  # if you want it in coordinates >>> x[np.nonzero(x)] array([1, 2, 1, 1]) >>> np.transpose(np.nonzero(x)) array([[0, 0],        [1, 1],        [2, 0],        [2, 1])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "numpy"
        ],
        "URL": "https://stackoverflow.com/questions/4588628/find-indices-of-elements-equal-to-zero-in-a-numpy-array",
        "A_Votes": "1",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    NumPy has the efficient function/method nonzero() to identify the indices of non-zero elements in an ndarray object. What is the most efficient way to obtain the indices of the elements that do have a value of zero?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Get the current git hash in a Python script",
        "A_Content": "  The git describe command is a good way of creating a human-presentable \"version number\" of the code. From the examples in the documentation:     With something like git.git current tree, I get:      [torvalds@g5 git]$ git describe parent v1.0.4-14-g2414721       i.e. the current head of my \"parent\" branch is based on v1.0.4, but since it has a few commits on top of that, describe has added the number of additional commits (\"14\") and an abbreviated object name for the commit itself (\"2414721\") at the end.   From within Python, you can do something like the following:  import subprocess label = subprocess.check_output([\"git\", \"describe\"]).strip()      ",
        "Language": "Python",
        "Tags": [
            "python",
            "git",
            "git-hash"
        ],
        "URL": "https://stackoverflow.com/questions/14989858/get-the-current-git-hash-in-a-python-script",
        "A_Votes": "64",
        "_type": "dict",
        "isAccepted": "Yes",
        "Q_Content": "    I would like to include the current git hash in the output of a Python script (as a the version number of the code that generated that output).  How can I access the current git hash in my Python script?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Get the current git hash in a Python script",
        "A_Content": "  This post contains the command, Greg's answer contains the subprocess command.  import subprocess  def get_git_revision_hash():     return subprocess.check_output(['git', 'rev-parse', 'HEAD'])  def get_git_revision_short_hash():     return subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD'])      ",
        "Language": "Python",
        "Tags": [
            "python",
            "git",
            "git-hash"
        ],
        "URL": "https://stackoverflow.com/questions/14989858/get-the-current-git-hash-in-a-python-script",
        "A_Votes": "68",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to include the current git hash in the output of a Python script (as a the version number of the code that generated that output).  How can I access the current git hash in my Python script?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Get the current git hash in a Python script",
        "A_Content": "  No need to hack around getting data from the git command yourself. GitPython is a very nice way to do this and a lot of other git stuff. It even has \"best effort\" support for Windows.  After pip install gitpython you can do  import git repo = git.Repo(search_parent_directories=True) sha = repo.head.object.hexsha      ",
        "Language": "Python",
        "Tags": [
            "python",
            "git",
            "git-hash"
        ],
        "URL": "https://stackoverflow.com/questions/14989858/get-the-current-git-hash-in-a-python-script",
        "A_Votes": "64",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to include the current git hash in the output of a Python script (as a the version number of the code that generated that output).  How can I access the current git hash in my Python script?     ",
        "Q_Votes": "89"
    },
    {
        "Q_Title": "Get the current git hash in a Python script",
        "A_Content": "  numpy has a nice looking multi-platform routine in its setup.py:  import os import subprocess  # Return the git revision as a string def git_version():     def _minimal_ext_cmd(cmd):         # construct minimal environment         env = {}         for k in ['SYSTEMROOT', 'PATH']:             v = os.environ.get(k)             if v is not None:                 env[k] = v         # LANGUAGE is used on win32         env['LANGUAGE'] = 'C'         env['LANG'] = 'C'         env['LC_ALL'] = 'C'         out = subprocess.Popen(cmd, stdout = subprocess.PIPE, env=env).communicate()[0]         return out      try:         out = _minimal_ext_cmd(['git', 'rev-parse', 'HEAD'])         GIT_REVISION = out.strip().decode('ascii')     except OSError:         GIT_REVISION = \"Unknown\"      return GIT_REVISION      ",
        "Language": "Python",
        "Tags": [
            "python",
            "git",
            "git-hash"
        ],
        "URL": "https://stackoverflow.com/questions/14989858/get-the-current-git-hash-in-a-python-script",
        "A_Votes": "5",
        "_type": "dict",
        "isAccepted": "No",
        "Q_Content": "    I would like to include the current git hash in the output of a Python script (as a the version number of the code that generated that output).  How can I access the current git hash in my Python script?     ",
        "Q_Votes": "89"
    }
]